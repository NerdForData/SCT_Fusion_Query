{"id": "10.1515_comp-2020-0175.pdf::chunk_0", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 0, "text": "Open Access. ¬©2020 C. Gallo and V. Capozzi, published by De Gruyter. This work is licensed under the Creative Commons Attribution 4.0 License Open Comput. Sci. 2020; 10:231‚Äì245 Research Article Crescenzio Gallo* and Vito Capozzi A Wafer Bin Map \"Relaxed\" Clustering Algorithm for Improving Semiconductor Production Yield https://doi.org/10.1515/comp-2020-0175 Received Feb 10, 2020; accepted May 05, 2020 Abstract: The semiconductor manufacturing process in- volves long and complex activities, with intensive use of resources.Producerscompetethroughtheintroductionof new technologies for increasing yield and reducing costs. So, yield improvement is becoming increasingly impor- tant since advanced production technologies are complex and interrelated. In particular, Wafer Bin Maps (WBMs) presenting specific fault models provide crucial informa- tion to keep track of process problems in semiconduc- tor manufacturing. Production control is often based on the \"judgement\" of expert engineers who, however, carry out the analysis of map templates through simple visual exploration. In this way, existing studies are subjective, time consuming, and are also limited by the capacity of human recognit"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_1", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 1, "text": "however, carry out the analysis of map templates through simple visual exploration. In this way, existing studies are subjective, time consuming, and are also limited by the capacity of human recognition. This study proposes a network- baseddataminingapproach,whichintegratescorrelation graphswithclusteringanalysistoquicklyextractpatterns fromWBMsandthenbindthemtomanufacturingdefects. An empirical study has been conducted on real produc- tiondataforvalidatingtheproposedclusteringalgorithm, which showed a perfect correspondence between the mal- functionpatternsfoundbythealgorithmandthosediscov- ered by human experts, so confirming the validity of our approachinitsabilityofcorrectlyidentifyingactualdefec- tive patterns to help improving production yield. Keywords: Semiconductor manufacturing, Yield manage- ment, Clustering, Wafer Bin Maps *Corresponding Author: Crescenzio Gallo: Universit√†diFoggia ‚ÄìDipartimentodiMedicinaClinicaeSperimentale,Foggia,Italy; Email: crescenzio.gallo@unifg.it Vito Capozzi: Universit√†diFoggia,DipartimentodiMedicinaCli- nicaeSperimentale,Foggia,ItalyandIstitutoNazionalediFisica Nucleare ‚Äì Sezione di Bari, Italy; Email: vito.capozzi@unifg.it1Introduction Semic"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_2", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 2, "text": "ito Capozzi: Universit√†diFoggia,DipartimentodiMedicinaCli- nicaeSperimentale,Foggia,ItalyandIstitutoNazionalediFisica Nucleare ‚Äì Sezione di Bari, Italy; Email: vito.capozzi@unifg.it1Introduction Semiconductor production involves lengthy and complex processes, employing a significant amount of resources. Manufacturers contend by means of increasing research onnewtechnologiestoimproveintegratedcircuit(IC)pro- duction yield and to reduce manufacturing costs [1‚Äì3]. Yieldanalysis isanactivitycommontoallmanufactur- ing companies of semiconductor devices on an industrial scale.Itconsistsofidentifyingproblemsrelatedtothepro- ductioncyclebyanalysingthenumberanddistributionof defective chips on a wafer [4, 5]. This is an extremely ex- pensiveactivityfromthepointofviewoftheemployedhu- man resources because it requires the visual exploration of thousands of wafer maps (graphical representations of thedistributionofdefectivechipsonthesiliconwaferspro- duced)andanalysisofahugeamountof(notonly)electri- cal related data [6‚Äì8]. In any case, the objective is to increase production yield. This is accomplished in two phases: a) identifying yield \"detractors\"; b) changing the design processes, or modif"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_3", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 3, "text": "i- cal related data [6‚Äì8]. In any case, the objective is to increase production yield. This is accomplished in two phases: a) identifying yield \"detractors\"; b) changing the design processes, or modifying the equipment (maintenance, replacement) to eliminate these detractors from the production line. Ontheotherhand,yield(percentageofchipsworking on a wafer) analysis is absolutely essential, because it is linked directly to the marketing and the potential profit margin of produced devices. Schematically, this activity can lead to a problem of recognition of failure patterns in ahighnoiseenvironment,orhowtobindthedatatodiffer- entwafersbasedonpatternsthatarenotknown\"apriori\" (search for unknown problems, or clustering). In the past, this was done typically by means of tradi- tional statistical methods [9, 10], which are not much ef- ficient in detecting failure patterns related to production line drawbacks. On the other hand, today there are sev- eral \"intelligent\" machine learning algorithms which are much more suited to analyze wafer maps in order to dis- cover their failure patterns [3, 11‚Äì13]. In particular, Kang et al. [6] follow a data-driven approach which simplifies the analy"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_4", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 4, "text": "ithms which are much more suited to analyze wafer maps in order to dis- cover their failure patterns [3, 11‚Äì13]. In particular, Kang et al. [6] follow a data-driven approach which simplifies the analysis process because no domain knowledge is re- quired. They consider the die positions in a wafer to char- 232 /bar.twoC. Gallo and V. Capozzi acterize thefailure patterns (andthus the yield) related to the wafer center. Clustering methods Themethodofanalysispresentedinthispaperispartofa broader set of clustering algorithms, which aim at group- ing elements of a dataset into homogeneous groups (clus- ters) in such a way that elements belonging to the same group are similar or related to each other, and elements belonging to different groups are dissimilar or not related to each other [14]. Clusteringmethodscanbedividedintobasictypesac- cording to the logic of clustering construction: ‚ÄìPartitioning methods : they divide the dataset into a fixed and known knumber of non-empty clusters. They are applicable to medium-sized datasets. The most representative is the k-means clustering [15]. ‚ÄìHierarchical methods : they derive multiple cluster subdivisions, exploit the tree structure and use d"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_5", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 5, "text": "are applicable to medium-sized datasets. The most representative is the k-means clustering [15]. ‚ÄìHierarchical methods : they derive multiple cluster subdivisions, exploit the tree structure and use dif- ferentthresholdvalueswithineachclusterandinho- mogeneity thresholds between distinct clusters [16]. ‚ÄìDensity-based methods : they use local density for one observation, so that it considers not less than a prefixed number of neighbors (established by the decisionmaker);theyareabletoisolateoutliers[17]. ‚ÄìGraph-based methods : they use graph partitioning algorithms,anduseascatteredrepresentationofthe initial dataset [18]. Asecondbreakdownconcernsthewayinwhichobser- vations are allocated to individual clusters: ‚ÄìExclusive assignment : each observation is assigned to a single cluster. ‚ÄìSoft attribution : each observation can belong to sev- eral clusters with different degrees of belonging. ‚ÄìFull attribution : Each observation is assigned to at least one cluster. ‚ÄìPartial assignment : some observations may not be assigned to any cluster; they are very useful to iden- tify the presence of outliers in the dataset. Most clustering methods are heuristic in nature, gen- erating good quality "}
{"id": "10.1515_comp-2020-0175.pdf::chunk_6", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 6, "text": "observations may not be assigned to any cluster; they are very useful to iden- tify the presence of outliers in the dataset. Most clustering methods are heuristic in nature, gen- erating good quality clusters but it is difficult to speak of \"optimality\".Anexhaustivemethodforthesubdivisionsof mobservations into kclusters requires examining a (pro- hibitive)numberofsolutions[17].Itisthereforenecessary to use algorithms that do not follow a merely exhaustive approach; they should rather take into account the struc- tureofthedatasetinordertoperformclusteringefficiently and effectively. Beyond these considerations, clusteringmodels are based on a measure of similarity (or distance) betweenobservations.Byassigningadataset Dconsisting ofmobservations,itispossibletorepresenteachobserva- tionusingan n-dimensionalvector,where nrepresentsthe number of attributes measured for each observation. We can then represent the dataset through a rectangular ma- trixX= [m√ón]and compute the square symmetrical ma- trixS= [m√óm]where each element (i,k)represents the similarity (or distance) between the i-th and thek-th ele- ment.Thedefinitionofanappropriatenotionofsimilarity ordistancedependsonthenatureofth"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_7", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 7, "text": "l ma- trixS= [m√óm]where each element (i,k)represents the similarity (or distance) between the i-th and thek-th ele- ment.Thedefinitionofanappropriatenotionofsimilarity ordistancedependsonthenatureoftheattributesthatare measured in correspondence to the elements that belong to the dataset to be analyzed (e.g. Euclidean, Manhattan, Mahalanobis distance, etc. [17]). Itisusualtoevaluateclusteringmodelsbycalculating certain performance indicators. One of the most common is the silhouette coefficient [19], which combines the mea- surement of intra-cluster cohesion with the measurement of inter-cluster separation, varying in the range [‚àí1,+1]: positive values close to one are an index of ideal cluster- ing. The overall silhouette coefficient is computed as the average of the coefficients of the individual observations of the dataset. The interpretation of the large amounts of data pro- duced by semiconductor manufacturing requires new effi- cient strategies to reduce the sizes involved. Clustering al- gorithmstypicallygroupwafersintoclustersofsimilarpro- files in order to identify possible functional relationships betweenthem.Similarproblemsarefoundintheanalysis oflargenetworks,wherethesu"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_8", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 8, "text": "ering al- gorithmstypicallygroupwafersintoclustersofsimilarpro- files in order to identify possible functional relationships betweenthem.Similarproblemsarefoundintheanalysis oflargenetworks,wherethesubnetsthatmeetcertaincri- teriacanbeextracted(suchasthesearchforwebpageson the same subject) [20]. The clustering approach for discovering defective pat- terns in Wafer Bin Maps is a widely covered approach in literature. Kim et al. [21] analyse the detection and sep- aration of mixed-type defect patterns into clusters, with the aim of matching each cluster to a well-known defect typeordiscoveringanewdefectpattern.Inthispaper,au- thors propose the connected-path filtering method to re- move \"noise\" from WBMs; then the infinite warped mix- ture model is adopted for the clustering of mixed-type de- fectpatterns.Chia-YuHsu[22]uses\"clusteringensemble\", in which Wafer Bin Map pattern extraction is made in or- dertorecognizesystematicdefectpatternsefficiently.This approach integrates data transformation with k‚àímeans and particle swarm optimization (PSO) clustering algo- rithms,assessingresultsthroughadaptiveresponsetheory (ART) neural networks. In [23] Hang Dong et al.analyse the spatial patt"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_9", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 9, "text": "rmation with k‚àímeans and particle swarm optimization (PSO) clustering algo- rithms,assessingresultsthroughadaptiveresponsetheory (ART) neural networks. In [23] Hang Dong et al.analyse the spatial patterns of defective chips on Wafer Bin Maps, proposing a wafer yield prediction model that incorpo- rates the spatial clustering information in functional test- A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two233 ing.LiukkonenandHiltunen[24]combineSelf-Organizing Map(SOM)networkand k‚àímeansclusteringalgorithmfor analysing systematic defect patterns on spatially oriented wafer maps. Beyond the above clustering methods, we propose a method which belongs to the class of \"graph based\" clus- tering methods. It performs a non-exclusive (each wafer can be assigned to more than one cluster) and partial (somewafers‚Äîtypicallyoutliers‚Äîmaynotbelongtoany cluster)attribution.Inparticular,ourmethoddealswitha computationally simple method for clustering defect pat- ternsbasedona\"linearization\"ofthepositionsofthedies on the wafer map surface. This allows a generalization of the analysis, regardless of the individual spatial distribu- tionofdefectivechips,alsomitigatingtheeffectsof\"excur- sions\"thro"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_10", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 10, "text": "itionsofthedies on the wafer map surface. This allows a generalization of the analysis, regardless of the individual spatial distribu- tionofdefectivechips,alsomitigatingtheeffectsof\"excur- sions\"throughthemonitoringanddiagnosisofthecauses offailureduetoextraordinaryeventssuchasincorrectop- eration, malfunction of machinery or contamination. 2Materials and Methods 2.1Wafer manufacturing critical factors The critical factors that help maintaining a competitive advantage for semiconductor wafer factories include low- ering costs through the streamlining of production and increasing yield through a rapid response to excursions (when process or equipment shift out of specifications) [7, 25, 26]. In particular, the problems which originate de- fects have to be detected in time and the related causes should be resolved as soon as possible to reduce the large amount of wafers discarded. In addition to the in-line control for the detection of chip failures, some electrical tests are performed (circuit probe ‚Äî CP) on the final product. The tests are performed on all devices manufactured; each die undergoes a pre- determined ordered series of electrical measurements. As soon as a chip does n"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_11", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 11, "text": "(circuit probe ‚Äî CP) on the final product. The tests are performed on all devices manufactured; each die undergoes a pre- determined ordered series of electrical measurements. As soon as a chip does not pass a particular test it is marked and,exceptinspecialcases,itdoesnotundergoanyaddi- tional testing. Test results can be analyzed at different lev- els:\"die\"(foreachmoldofthewafertheparticular\"bin\"in chargeoftheeventisshown),\"wafer\"(eachwaferisasso- ciated with a vector containing, for each test, the number offaileddevices),\"lot\"(anaverageofthewafer-leveldata). A\"human\"analyzercanrecognizeasbelongingtothe sameclusterdefectiveslices:a)havingthe sameset offail- ures (electrical conductivity, etc. detected after thermal, mechanical and electrical stresses); b) with the same spa- tial arrangement (e.g. spatially adjacent defects, with var-ious shapes of random or repetitive type); c) in the same wafer area (this obviously does not apply well to random failures); d) with different spatial extensions . An operation often performed to investigate the prob- lems of a device is to run, on an adequate number of wafers,abargraphrepresentingtherelativefrequenciesof electrical failures in desce"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_12", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 12, "text": "xtensions . An operation often performed to investigate the prob- lems of a device is to run, on an adequate number of wafers,abargraphrepresentingtherelativefrequenciesof electrical failures in descending order, where the bin rela- tivetothefunctioningchipisremovedfromthegraph.This graphiscalled\"Paretobin\"(Figure1)andithelpstounder- stand which electrical failures weigh more and should be addressed first to try to understand their causes. Figure 1: ExampleofaParetobindiagramrepresentingtherelative frequencies of electrical failures. Thisdiagramisastrongdescriptivetoolforrandomde- fects. In addition, an electrical failure rarely occurs alone, but very often in conjunction with other ones (e.g. physi- calcorrosion,electricalleakageandshorts).So,incaseof problems, a single bin (i.e. a single failure configuration) rarely changes its position in the diagram. Moreover, yield learning is an activity that allows the identificationofyielddetractors;basically,itisaclassifica- tionofdefectsaffectingdevices.Theeventualresultofthis phaseisthecompilationofayieldParetodiagram(seeFig- ure2),usedbyengineerstoanalyzeandidentifythecauses of failure that may influence the yield by means of a de- tai"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_13", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 13, "text": "ctingdevices.Theeventualresultofthis phaseisthecompilationofayieldParetodiagram(seeFig- ure2),usedbyengineerstoanalyzeandidentifythecauses of failure that may influence the yield by means of a de- tailed list of defects, sorted by the impact that they have on the final result. A considerable amount of operational dataofelectricaltests[27]formsthebasisoftheactivityof yield learning. In semiconductor manufacturing there is an impor- tantcomputingneedforthefulfillmentofanexpertsystem capable of \"clustering\" [28] (i.e. putting together) wafers with similar sets of failures in similar zones, with similar shapes but with different variable spatial extensions. For 234 /bar.twoC. Gallo and V. Capozzi Figure 2: Example of a yield Pareto diagram. example, a \"half-moon\" pattern can be very small or very large,butitretainsthesameshapeanditislocatedinthe same area of the wafer: this identifies wafers belonging to the same cluster. These \"identified problems\" make up an important knowledge base (also known as rulesordefect patterns [23]) useful for dealing with manufacturing problems. Then,intheproductionline,awafer‚Äôsdefectscanbecom- pared with the set of known defect patterns [29] to ver- ify t"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_14", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 14, "text": "o known as rulesordefect patterns [23]) useful for dealing with manufacturing problems. Then,intheproductionline,awafer‚Äôsdefectscanbecom- pared with the set of known defect patterns [29] to ver- ify the possible presence of already known \"rules\": if the defective wafer does not belong to any known feature (at least with an acceptable degree of confidence), a new de- fect pattern is submitted to the attention of the analyst who,ifthatpatternisinternallyconsistent,formalisesthe recognition of a new yield issue (rule) and inserts it in the database of known issues. 2.2Wafer Bin Maps A largely used and useful tool for yield management are the Wafer Bin Maps (WBMs) [4, 13, 28, 30, 31]. Such maps present specific fault models and provide crucial infor- mation to keep track of process problems in semiconduc- tor manufacturing. Production monitoring often relies on the \"evaluation\" of experts who visually explore map tem- plates: such approach leads to a biased judgement, it is time consuming and it is also limited by the ability of hu- man perception. A Wafer Bin Map is the result of the \"circuit probe\" check of the dies on the wafer at the end of production. Figure 3 shows an example of "}
{"id": "10.1515_comp-2020-0175.pdf::chunk_15", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 15, "text": "and it is also limited by the ability of hu- man perception. A Wafer Bin Map is the result of the \"circuit probe\" check of the dies on the wafer at the end of production. Figure 3 shows an example of a WBM, which is a spatial representation of the (thermal, mechanical and/or electri-cal) test results, in which \"green\" devices have passed all tests and other colors represent various types of failures. WBMpatternscanprovideveryusefulinformationtomon- itor the production process and products [31]. Figure 3: AnexampleofWaferBinMap:greencolorshowsfunction- ingregions,whereastheothercoloursrepresentvarioustypes offailures(source:https://en.wikipedia.org/wiki/Substrate_ mapping). Since modern manufacturing facilities are equipped withC.I.M.(ComputerIntegratedManufacturing)systems, data collection is no longer an important issue. Moreover, there are also very widespread off-line data analysis sys- tems based on data warehouses [26, 32]. However, it re- mainstheproblemof\"scouring\"therelevantdatafromthe hugemassarisingfromtheanalysisofproductioninorder to obtain information that can help analysts in the timely resolution of problems and optimization of yield. Wafer Bin Maps are multi-dimensi"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_16", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 16, "text": "afromthe hugemassarisingfromtheanalysisofproductioninorder to obtain information that can help analysts in the timely resolution of problems and optimization of yield. Wafer Bin Maps are multi-dimensional and are equippedwithcomplexspatialstructures,abletoprovide information essential to identify problems in the produc- tion process. Figure 4 shows some examples of WBMs‚Äô patterns of defects [30] where different grey levels denote defective chips in different functional tests (dark = working chip, light = defective chip). WBM defect patterns can be clas- sified into three main categories [5, 8, 22]: Systematic defects: the positions of the defective chips in the wafer show the spatial correlation. For exam- ple,ring,board,checkerboardpatterns.Figure4(1‚Äì10) showssomesystematicpatternsoftenfoundinfactory, as defined by experts. Random defects: lack of spatial clustering or clearly identifiablepatterns.Defectivechipsarerandomlydis- A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two235 tributedinthetwo-dimensionalmap.Randomdefects are usually caused by environmental factors in the production process. Even in an almost sterile environ- ment, polluting particles can not be removed co"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_17", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 17, "text": " tributedinthetwo-dimensionalmap.Randomdefects are usually caused by environmental factors in the production process. Even in an almost sterile environ- ment, polluting particles can not be removed com- pletely.However,reducingthelevelofrandomdefects may improve the overall productivity in the manufac- ture of wafers. Mixed defects: they are made of random and systematic defects[21](lastpatterninFigure4):mostwafershave mapsofthistype.Itisappropriatetoseparaterandom fromsystematicdefectsinWBMs,sincesystematicde- fect patterns can reveal a process problem [33]. In some cases, due to the particular spatial distribu- tionofthedefectsonthesurfaceofthewafer,itisalsopos- sibletoformulatehypothesesastowhichproductionstep mayhavecausedthefault.Forexample,the checkerboard - like (also called repetitive ) faults are almost certainly due to a lithography process [13], so that the problem may be related to a particular pattern. Often, a view of wafer bin mapsofanentireproductionlotisused,obtaininganoise reduction. Fig. 2.4 (Hsu and Chien, 2007) (1) (2) (3) (4) (5) (6) (10) (7) (8) (9) Systematic Random Mixed Fig. 2.5 (Hsu and Chien, 2007) Figure 4: Examplesofpatternsofsystematic(1‚Äì10),randomand"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_18", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 18, "text": "noise reduction. Fig. 2.4 (Hsu and Chien, 2007) (1) (2) (3) (4) (5) (6) (10) (7) (8) (9) Systematic Random Mixed Fig. 2.5 (Hsu and Chien, 2007) Figure 4: Examplesofpatternsofsystematic(1‚Äì10),randomand mixeddefectsinwafermaps,wheredarkregionscorrespondto workingchipsandlightregionstodefectivechips (source:Hsuand Chien, 2007). 2.3Our approach In this work we present a data mining hybrid approach that integrates cluster analysis and spatial statistics [21‚Äì 24, 30, 34] to quickly extract patterns from WBMs and as- sociate them with manufacturing defects. The analysis oflarge amounts of data collected from production and the results can help engineers to make the right decision to classify failure patterns. Followinganetworkingapproach,wehavedeveloped a \"relaxed\" clustering algorithm which allows the rapid extraction of failure patterns in order to associate them withdefectivemanufacturingprocesses.Apracticalappli- cation of the clustering algorithm has been carried out on real production data for its validation, with encouraging results for a more complete development of an expert sys- tem aimed at the automated control of wafer production yield. The yield data used for testing our alg"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_19", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 19, "text": "ata for its validation, with encouraging results for a more complete development of an expert sys- tem aimed at the automated control of wafer production yield. The yield data used for testing our algorithm have been acquired from 1817 wafers coming from 78 lots, indi- cating ‚Äì for each chip ‚Äì the relative bin value. Each wafer isdividedinto577chipsforatotalof1,048,409chips,each of which is accompanied by the following information: a) LotId; b)WaferId; c)DieX/Y coordinates (see Figure 5); d)Binvalue(seethesupplementalfileinSection4,which shows the dataset without the batch references). Binvaluesareintherange0‚Äì56,with0=workingchip and 1‚Äì56 corresponding to 56 different failure configura- tions. Each bin (which was originally a pair of alphanu- meric characters representative of a particular combina- tion of chip malfunctions) was encoded as follows: ‚Äì value 0 has been assigned to the most frequent bin (which corresponds to the working chips); ‚Äì whole numbers 1 to 56 were progressively assigned tothesuccessivebinsintherelativefrequencyscale, so that the value 56 corresponds to the rarest bin (malfunction). Allbinvaluesaresortedbyprogressiverelativefrequency; and each chip is assigned"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_20", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 20, "text": "ssigned tothesuccessivebinsintherelativefrequencyscale, so that the value 56 corresponds to the rarest bin (malfunction). Allbinvaluesaresortedbyprogressiverelativefrequency; and each chip is assigned the bin value given by the most frequent one from all maps in the corresponding position. The bi-dimensional coordinate system (Die X‚àà [‚àí9,17], DieY‚àà[0,26]) was uniquely mapped ‚Äî for sim- plicity ‚Äî to a one-dimensional array (indexed between 1 and 577), while maintaining [24, 34] the concept of \"adja- cent chips\" (see, for example, the two patterns shown in Figure6)orsameelectricalfailureswithdifferentpatterns asshowninFigure7.This isomorphic transformationofco- ordinatesystemsdoesnotaffectthesearchforpatternsbe- cause the interrelationship between the single portions of the wafer map is preserved. For the implementation of the clustering algorithm we run the Mathematica 10 andOrangedata mining soft- wareonanApplemacOSserverwithdualIntelQuad-Xeon and 12GB of RAM. In particular, numerical and matrix manipulation functions, bi- and tri- dimensional graphic packages,graphmanagementlibrariesandtheNeuralNet- 236 /bar.twoC. Gallo and V. Capozzi Figure 5: Therealwaferspatialcoordinatesystemo"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_21", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 21, "text": "and matrix manipulation functions, bi- and tri- dimensional graphic packages,graphmanagementlibrariesandtheNeuralNet- 236 /bar.twoC. Gallo and V. Capozzi Figure 5: Therealwaferspatialcoordinatesystemonwhichour model is based, where the four corners do not belong to the pattern. Figure 6: Someexamplesof\"adjacent\"chips(defectivechipsare shown in red). Figure 7: Examplesofelectricalfailureswithdifferentspatialpat- terns (defective chips are shown in red). works module have been used. When possible and neces- sary, calculations were performed in parallel (up to 8 ker- nels)usingthenativeparallelprocessingcapacityof Math- ematica . 3The Relaxed Clustering Algorithm Theclustering algorithm steps are:1. Read the input bi-dimensional array Xmade ofn rows, one row per wafer, and mcolumns, one for eachchipofthewafer.Thearray Xisobtainedfrom eachwaferbinmapofthedataset,puttinginits(577) columns the bin values corresponding to the wafer chips, according to the system coordinates in Fig. 5 (see also the attached supplemental file, which shows the actual 1817 wafers of the dataset, each with its 577 bin values.) 2. Then√óncorrelationmatrix Cisdefinedonallwafer (m‚àídimensional vector) pairs (xk,xl)"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_22", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 22, "text": "o the attached supplemental file, which shows the actual 1817 wafers of the dataset, each with its 577 bin values.) 2. Then√óncorrelationmatrix Cisdefinedonallwafer (m‚àídimensional vector) pairs (xk,xl),k,l= 1...n, whose elements are computed using the Spearman correlationcoefficient œÅ,definedasthePearsoncor- relation coefficient between the ranked variables [35].Themrawscoresforeachvector xareconverted toranksrandthecorrelationcoefficientbetween xk andxlis computed as ck,l= 1‚àí6‚àëÔ∏Äm j=1d2 j (n2‚àí1)n‚àà[‚àí1,1] wheredj=xk(j)‚àíxl(j). The coefficient ck,lis dis- carded if it does not pass the statistical significance test on the random variable z=‚àöÔ∏Ä œÅ(N‚àí1)(the test isapplicable[35,36]sincethesamplesizeisgreater than 20). Note that the correlation coefficient is ap- plied in absolute value. In fact, in the next step of the algorithm two nodes kandlare connected only if the absolute value of their correlation coefficient ck,lis equal or higher than the threshold Œ∏1. 3. LetŒ∏1be a fixed threshold defining an open inter- val of symmetrical comparison (‚àíŒ∏1,Œ∏1)and let us buildtheadjacencymatrix Abetweenwaferswhose elementsak,l,k,l= 1...n, are defined as follows: ak,l={Ô∏É 0ifck,l‚àà(‚àíŒ∏1,Œ∏1) 1otherwise 4."}
{"id": "10.1515_comp-2020-0175.pdf::chunk_23", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 23, "text": "ning an open inter- val of symmetrical comparison (‚àíŒ∏1,Œ∏1)and let us buildtheadjacencymatrix Abetweenwaferswhose elementsak,l,k,l= 1...n, are defined as follows: ak,l={Ô∏É 0ifck,l‚àà(‚àíŒ∏1,Œ∏1) 1otherwise 4. Anundirected(correlation)graph Gisbuiltfromthe adjacencymatrix,withedgeweightsequaltothecor- relation coefficients ck,l. This graph has one node for each selected wafer; links between nodes corre- spondtothepresenceofacorrelationbetweenthem (see Figures A5 and A6). 5. Aclusteringcoefficient kiisassociatedtoeachnode ibelonging to the correlation graph: ki=2Œ± ùõæ(ùõæ‚àí1)‚àà[0,1] whereŒ±is the number of triangles (a triangle is a cluster of three directly and fully connected nodes) having node ias one vertex and ùõæis the number of nodes directly linked to i. A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two237 6. Le us fixŒ∏2‚àà[0,1]as a clustering threshold. From the graphGwe induce a subgraph Hmade of all nodesi‚ààG(and related edges e) withrelaxedclus- tering coefficient greater than or equal to Œ∏2:H= {nodesi‚ààGand related edges e:ki‚â•Œ∏2}. The relaxed clustering coefficient of a node iis given by the maximum clustering coefficient among kiand thoseofthenodesdirectlyconnectedtoituptoapre- determ"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_24", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 24, "text": "Œ∏2:H= {nodesi‚ààGand related edges e:ki‚â•Œ∏2}. The relaxed clustering coefficient of a node iis given by the maximum clustering coefficient among kiand thoseofthenodesdirectlyconnectedtoituptoapre- determinedmaximumdistance Œ¥:thisgivesa\"drag- ging\"effectbythesurroundingnodes,bettertaking into account the complex structure of the relations between the graph nodes (wafers) than the simple clustering coefficient of each node. 7. Fromthissubgraphweextractallconnectedcompo- nents (made of at least two linked nodes) represent- ing the clusters corresponding to the values chosen for thresholds Œ∏1andŒ∏2. Theaboveillustratedalgorithmisbasedoncorrelation coefficients,combininganetworkanalysistechniquewith the classical clustering for the study of wafer failures. It usestwoparameters( correlation thresholdŒ∏1andcluster- ingthresholdŒ∏2, as specified in the steps 3 and 6 of the algorithm), resulting in a flexible and effective ability to analyzethesensitivityoftheresultsinresponsetothepar- ticular configuration chosen. Onthecontrary,the k‚àímeansclusteringalgorithm[24] requires the a prioridefinition of the number kof clusters tobesearched;thisisamethodthatgraduallydefinesclus- ters by partitioning obs"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_25", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 25, "text": "uration chosen. Onthecontrary,the k‚àímeansclusteringalgorithm[24] requires the a prioridefinition of the number kof clusters tobesearched;thisisamethodthatgraduallydefinesclus- ters by partitioning observations around an average dis- tance between them (centroid). This method is different and not comparable to our algorithm, which in the first phaseeliminatesthecorrelationsbelowthreshold Œ∏1(pos- sibly taking into account only the significant coefficients according to a proper statistical test). Then, in a second phase, our method computes ‚Äî for each remaining node of the correlation graph ‚Äî its \"relaxed\" clustering coeffi- cient, removing those below the threshold Œ∏2. Inthissecondphase,ouralgorithmintroducesavaria- tionwithrespecttotheclassicmethodofperformingclus- tering,avariationfromwhichthealgorithmtakesitsname. In fact, the single clustering coefficients are \"relaxed\" (i.e. made equal) to the value of the maximum clustering coef- ficient of all the nodes connected ‚Äî at a prefixed distance Œ¥, usually 1 ‚Äî to the node under examination. In this way, the \"relaxed\" clustering algorithm takes into account all nodes connected to a given node up to distance Œ¥; if any of theŒ¥‚àínear nodes"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_26", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 26, "text": "istance Œ¥, usually 1 ‚Äî to the node under examination. In this way, the \"relaxed\" clustering algorithm takes into account all nodes connected to a given node up to distance Œ¥; if any of theŒ¥‚àínear nodes has a clustering coefficient greater or equal to the threshold Œ∏2the given node will not be elim- inated. In essence, there is a dragging effect of the nodes withalowclusteringcoefficientbythosewithahigheroneanddirectlyconnectedtoit,asshownintheexamplespro- vided in Section 5. Ouralgorithm(whichhasbeenalsoapplied,initssim- pledoublethresholdform,inabiologicalcontextwithpos- itive results [37, 38]) is based on the concept of curvature [20, 39] applied to the network (aka correlation graph , see Figures A5 and A6 in Section 5) of related wafers, where nodes represent devices and edges represent correlations betweenthem.TypicallytheSpearmanrankcorrelationco- efficientœÅisusedbecauseitisnotlimitedtoalinearcorre- lation [10] and it is less sensitive to possible high outliers in the tails of both samples. On the contrary, if a normal behavior is observed in data, then it would be preferable to use Pearson‚Äôs correlation coefficient because it is sim- pler and less computationally expensive. I"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_27", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 27, "text": "h samples. On the contrary, if a normal behavior is observed in data, then it would be preferable to use Pearson‚Äôs correlation coefficient because it is sim- pler and less computationally expensive. In our case not alldistributionsofbinvalueswerenormal,sowechoseto use Spearman‚Äôs rank correlation coefficient. Whichevercorrelationmethodisused,ithastobefol- lowed by computing each coefficient, and a statistical sig- nificancetesthastobepassedaswell.Possibletestsforas- sessing correlations [35, 36] are z‚àí,t‚àíorF‚àítest according to the correlation method chosen. We adopted the z‚àítest (which is based on the random variable z=‚àöÔ∏Ä œÅ(N‚àí1)) fornormaldistributions,andthe t‚àítest(whichisbasedon therandomvariable t=œÅ/‚àöÔ∏Ä (1‚àíœÅ2)/(N‚àí2))forotherdis- tributions. These tests are simpler than F‚àítest but still ef- fectiveforalargesamplesize( N>>20),whichisthecase in this type of applications. Themainobjectiveofthealgorithmistoverify\"inreal time\" a batch of wafers coming from a specific device of the production line, to test the malfunctioning of that de- vice and intervene on the production as soon as possible. Therefore, the algorithm does not address \"big data\", but instead it wants to identify with suff"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_28", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 28, "text": " line, to test the malfunctioning of that de- vice and intervene on the production as soon as possible. Therefore, the algorithm does not address \"big data\", but instead it wants to identify with sufficient speed and pre- cision the most important patterns of production defects (clusters)andpresentthemtotheproductionlinemanager to correct the malfunctions of the devices involved. Never- theless, the characteristics of the algorithm (subsequent use ofthe twothresholds, which allowto quickly andpro- gressively discard a high number of nodes not relevant in thecorrelationgraph)makeitsuitablealsofortheprocess- ing of a high number (hundreds of thousands) of wafers. In particular, in the first phase the (theoretical) computa- tional complexity of the algorithm is O(n2), having to cal- culate a (square) correlation matrix of nelements, with n being the number of wafers to be processed. In practice, thecorrelationmatrixiscomputedandstoredina\"sparse\" way, which significantly reduces the calculation time and memoryoccupation.Moreover,aftertheapplicationofthe firstthreshold,theinitialcorrelationgraphisconsiderably reduced, and for the remaining nodes (which may be at 238 /bar.twoC. Gallo and"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_29", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 29, "text": "ation time and memoryoccupation.Moreover,aftertheapplicationofthe firstthreshold,theinitialcorrelationgraphisconsiderably reduced, and for the remaining nodes (which may be at 238 /bar.twoC. Gallo and V. Capozzi mostnbut are normally many less) the order of the clus- tering index calculation is O(k¬∑n)withk=Œ±/ùõæ2, where Œ±is the average number of \"triangles\" connected to each nodeand ùõæistheaveragenumberofnodesdirectlylinked to the node itself. The wafer bin clusters are the densest regions of the correlation graph, which correspond to defect patterns. It should be noted that the clustering coefficient, intro- duced in step 5 of our method, is typically extremely low in random graphs that have a small average degree com- pared to the number of nodes [39]. Clusters of correlation graphs with high clustering coefficients are thus highly non-randomstructureswhicharedifficulttoextractwhen the nodes are randomly distributed, and this point can be a limitation of our method. An application of the algorithm is illustrated in Sec- tion 5. The algorithm‚Äôs \"metaphor\" To better understand the operation of our relaxed double- threshold clustering algorithm we can think of the initial correlationgr"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_30", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 30, "text": "e algorithm is illustrated in Sec- tion 5. The algorithm‚Äôs \"metaphor\" To better understand the operation of our relaxed double- threshold clustering algorithm we can think of the initial correlationgraphasaseabedconformationcorresponding to a particular Œ∏1value. That is, the correlation graph G dependsonthechosen Œ∏1valueanditdepictsthecorrela- tion structure between nodes (wafers) extracted from the correlationmatrixthatwecanmetaphoricallyassociateto a particular seabed conformation. ThresholdŒ∏2corresponds figuratively to sea level andclustersareemergingislands.Varyingthecorrelation thresholdŒ∏1resultsinchangingtheseabedlandscape(as in the example shown in Figure 8), while the clustering thresholdŒ∏2moves only the sea level and, consequently, it changes the existence and relative size of clusters. 4Results and Discussion The two thresholds used in our algorithm are intended to progressivelyrefinethecorrelationgraph(asillustratedin Section 3), gradually eliminating the less closely related wafers. In particular, the first threshold aims to define the initial correlation graph containing the clusters of wafers withacorrelationcoefficientatleastequaltothethreshold itself.Oncetheinitialc"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_31", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 31, "text": "d wafers. In particular, the first threshold aims to define the initial correlation graph containing the clusters of wafers withacorrelationcoefficientatleastequaltothethreshold itself.Oncetheinitialcorrelationgraphisobtained,which containsoneormoreconnectedcomponents(i.e.clusters), each of these components is further thinned by eliminat- ing the nodes (wafers) that do not have a clustering index at least equal to the second threshold. (a) (b) Figure 8: The\"seabed\"metaphor.Thetwolandscapesin(a)cor- respondbyanalogytotwocorrelationstructures(wherepeaks representallpossibleclusters)obtainedwithtwodifferent Œ∏1val- ues;(b)showstheremainingclusters(peaksemergingabovesea level) after applying a particular Œ∏2value. The clustering index in practice represents the capac- ityofagraphnodetobean\"aggregation\"hubfortheother nodes directly connected to it, as it is normally calculated inclassiccorrelationgraphs:inouralgorithm,instead,the clusteringindexofanode(wafer)isequaltothemaximum clustering index of the nodes \"close\" to it up to a prefixed maximumdistance Œ¥(asshownintheexamplesinSection 5).Thischaracterizestheconceptof\"relaxation\",allowing to keep nodes (wafers) which ‚Äî in a traditional clu"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_32", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 32, "text": "ex of the nodes \"close\" to it up to a prefixed maximumdistance Œ¥(asshownintheexamplesinSection 5).Thischaracterizestheconceptof\"relaxation\",allowing to keep nodes (wafers) which ‚Äî in a traditional clustering algorithm‚Äîwouldbediscarded.Moreover,inthepresent work,unliketheinitialbiologicalimplementation,thedis- tanceŒ¥has been used with a value of at least one, which has increased the \"dragging\" effect of the neighbor nodes allowingtoheuristicallycalibratethebehaviorofthealgo- rithm according to the data under examination. Inparticular,thethresholds Œ∏1andŒ∏2weresetempir- ically; forŒ∏1the value 0.6 was used in order to keep the wafers with a Spearman correlation coefficient of at least 60% in the same cluster. Subsequently, a progressive se- ries of values of the threshold Œ∏2was applied to the ini- tially obtained clusters (related components of the corre- lation graph). Further, the nodes with a clustering index greater than the chosen threshold were removed. Eventu- ally,thevalueof Œ∏2(inourcase,0.3)correspondingtothe A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two239 bestoverallaveragesilhouetteindexofthecorresponding clustering was considered. In the clustering process we fir"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_33", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 33, "text": "urcase,0.3)correspondingtothe A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two239 bestoverallaveragesilhouetteindexofthecorresponding clustering was considered. In the clustering process we first aimed to \"discover\" the spatial distribution of the bins for each wafer, in or- dertohaveanempiricalproofoftheelectricalfailuresdis- tribution. In our specific case, this was accomplished by plotting the bin values of the 27√ó27matrix correspond- ingtoasinglewafer,wherethewhitesquaresarethework- ing chips (bin value=0), whereas a higher bin value corre- sponds to a more marked color for different failure config- urations. Figure 9 illustrates an example map of some bin values for all \"overlapped\" wafers in relation to the posi- tion of the chip. 5312867bin numberfrequency0 02 212 1216 16 531frequencybin number28 6 720 20 5(a)(b) Figure 9: Someexamplebinvaluesofthesyntheticmapderived fromasubsetof(ideallyoverlapping)waferbinmaps.White squares(binvalue=0)representtheworkingchips;colorsquares (binvalues2,12,16and20)correspondtoanexampleofdifferent failureconfigurations.Thecolorofasinglechipinaparticularposi- tionisgivenbythemostfrequentbinofall\"overlapped\"waferbin maps. Theresultsofthew"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_34", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 34, "text": "es (binvalues2,12,16and20)correspondtoanexampleofdifferent failureconfigurations.Thecolorofasinglechipinaparticularposi- tionisgivenbythemostfrequentbinofall\"overlapped\"waferbin maps. Theresultsofthewaferbinmapsobtainedforthefirst 9binvaluesareillustratedinFigure10.Inthispicture,for each chip the highest frequency of the relative bin value on all the sample‚Äôs wafer maps is highlighted: this can be consideredfirstlyasoverlappingallthewafermapsofthe samplewithonlyaparticularbinmarked,andthenobserv- ing the overlapped maps from the top. Figure 11 shows the complete three-dimensional his- togramofthefrequenciesofthebinvaluesforeachoneof the 577 chips of the reference coordinate system shown in Figure 5. Theclusteringperformedonthe1817wafersaccording to the algorithm illustrated in the previous section (with Œ∏1= 0 .60andŒ∏2= 0 .30)showsthe\"spatial\"regularityof some defective patterns, i.e. homologous sets of electrical failures that occur in same areas of the wafers. The wafer mapsshowninFigure12wereobtainedbyoverlappingthe mapsofallwafersbelongingtothecluster,inordertovisu- Bin 0Bin 1Bin 2 Bin 3Bin 4Bin 5 Bin 6Bin 7Bin 8Figure 10: The waferbin mapscorresponding tothe first 9bin values o"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_35", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 35, "text": "ure12wereobtainedbyoverlappingthe mapsofallwafersbelongingtothecluster,inordertovisu- Bin 0Bin 1Bin 2 Bin 3Bin 4Bin 5 Bin 6Bin 7Bin 8Figure 10: The waferbin mapscorresponding tothe first 9bin values oftheinitialdatasetfromthemanufacturingline(thefourcorners do not belong to the maps). Chip Freq. Bin01.00.50.002040200400 Figure 11: Thefrequencydistributionofthe57binvaluesforeach oneofthe577chipsinthewafermapsoftheinitialdatasetfromthe manufacturing line. allyexposethepatternsfoundbytheclusteringalgorithm. In particular, the maps of the large number of the ex- amined wafers highlight some different configurations of electrical failures or rulescorresponding to systematic or mixed defects: ‚Äì Rule 1 \" ring\": clusters #1 and #4 of Figure 12. 240 /bar.twoC. Gallo and V. Capozzi ‚Äì Rule 2 \" sector\": clusters #2 and #3 of Figure 12. ‚Äì Rule3\" stripe\":clusters#5(shaded)and#6(strong) of Figure 12. These early findings have been examined and con- firmedbytheengineersofthefactorywherethetestshave been carried out, and coincided with the results of the vi- sual inspections made by the experts. The above results justify the viability of the \"clustering\" approach in classi- fying defect patterns of"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_36", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 36, "text": "en carried out, and coincided with the results of the vi- sual inspections made by the experts. The above results justify the viability of the \"clustering\" approach in classi- fying defect patterns of WBMs. (#1) (#2) (#3) (#4) (#5) (#6) Figure 12: Figureshowsthefirstsixclustersobtainedbyourrelaxed clusteringalgorithmreportedinSection3(thefourcornersdonot belongtothepatterns).Theaggregationfunctionusedtoobtainthe sixclustermapsisthe\"mode\";infacteachchipiscoloredaccording tothemostfrequentbininitspositionforalltheoverlappedwafer bin maps constituting the cluster.5Conclusion This investigation presents a hybrid clustering algorithm for automatic extraction of failure patterns in the wafer bin maps resulting from the production of wafer semicon- ductors.Theproposedmethodisabletoidentifythemaps with spatial correlation and it provides, in a short time, useful information to support decisions that improve the production yield. Compared to the initial version used for the biologi- cal analysis of gene correlation networks [37, 38], the pro- posedalgorithmhasbeenappliedtotheindustrialfieldto controltheyieldofsemiconductorwafersbyextendingthe \"double threshold\" clustering approach. This met"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_37", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 37, "text": "s of gene correlation networks [37, 38], the pro- posedalgorithmhasbeenappliedtotheindustrialfieldto controltheyieldofsemiconductorwafersbyextendingthe \"double threshold\" clustering approach. This method has been extended through the \"relaxed\" computation of the clusteringindex,consideringadistanceofatleast1\"neigh- bor\" nodes (wafers), thus allowing to verify the generaliz- ability of the proposed clustering algorithm. The results obtained both from the visual analysis of thewafermapsandour\"relaxed\"clusteringalgorithmcon- firm the effectiveness of the applied method. This rein- forces the applied methodology, and encourages to carry on a further series of experiments by properly fine-tuning the clustering thresholds in order to optimally calibrate the model. The future research objective will be to start from the identification of a set of \"synthetic\" parameters (clusters of defects‚Äô patterns), in order to detect similarities among processed wafers by using the results obtained in the di- rection of the implementation of one (or more) automatic classifiers(neuralnetworksorsimilarmachinelearningal- gorithms). Such an issue is aimed at the recognition of ex- isting \"defect rules\" in "}
{"id": "10.1515_comp-2020-0175.pdf::chunk_38", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 38, "text": "di- rection of the implementation of one (or more) automatic classifiers(neuralnetworksorsimilarmachinelearningal- gorithms). Such an issue is aimed at the recognition of ex- isting \"defect rules\" in the manufactured wafers or at the discovery of new rules to increase the knowledge base. It could be then worth exploring the possibility to dis- cover such new configurations (spatial distributions) of Wafer Bin Map failures by processing a large number of maps with a big-data approach, for developing an auto- mated expert system able to identify manufacturing de- fects in order to facilitate yield management. References [1]Chien C.F., Hsu C.Y., Chang K.H., Overall Wafer Effectiveness (OWE):Anovelindustrystandardforsemiconductorecosystem as a whole,Computers & Industrial Engineering, 65,2013, 117‚Äì 127, 10.1016.j.cie.2011.11.024 [2]GardnerR.,BiekerJ.,ElwellS.,Solvingtoughsemiconductorman- ufacturing problems using data mining., IEEE/SEMI Advanced Semiconductor Manufacturing Conference 2000., 2000 A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two241 [3]Soenjaya J., Hsu W., Lee M.L., Lee T., Mining wafer fabrication: frameworkandchallenges,NextGenerationofData-MiningAp- plication, "}
{"id": "10.1515_comp-2020-0175.pdf::chunk_39", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 39, "text": "., 2000 A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two241 [3]Soenjaya J., Hsu W., Lee M.L., Lee T., Mining wafer fabrication: frameworkandchallenges,NextGenerationofData-MiningAp- plication, John Wiley & Sons, New York, 2005, 17‚Äì40 [4]Chien C.F., Hsu S.C., Chen Y.J., A system for online detection and classificationofwaferbinmapdefectpatternsformanufacturing intelligence, International Journal of Production Research, 51(8), 2013, 2324‚Äì2338, http://dx.doi.org/10.1080/00207543.2012. 737943 [5]Taam W., Hamada M., Detecting spatial effects from factorial ex- periments:anapplicationfromintegrated-circuitmanufacturing., Technometrics, 35(2), 1993, 149‚Äì160 [6]KangS.,ChoS.,AnD.,RimJ.,Usingwafermapfeaturestobet- ter predict die-level failures in final test, IEEE Transactions on Semiconductor Manufacturing, 28(3), 2015, 431‚Äì437 [7]LeachmanR.,HodgesD.,Benchmarkingsemiconductormanu- facturing.,IEEETransactionsonSemiconductorManufacturing, 9(2), 1996, 158‚Äì169 [8]Stapper C., LSI yield modeling and process monitoring., IBM Journal of Research and Development, 44(2), 2000, 112‚Äì118 [9]MontgomeryD.C.,Introductiontostatisticalqualitycontrol,John Wiley & Sons, 2007 [10]Myers J., Well A., Resea"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_40", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 40, "text": "ng and process monitoring., IBM Journal of Research and Development, 44(2), 2000, 112‚Äì118 [9]MontgomeryD.C.,Introductiontostatisticalqualitycontrol,John Wiley & Sons, 2007 [10]Myers J., Well A., Research Design and Statistical Analysis (2nd ed.), Lawrence Erlbaum, 2003 [11]ArnoldN.N.A.,Waferdefectpredictionwithstatisticalmachine learning, Ph.D. thesis, Massachusetts Institute of Technology, 2016 [12]Jang S.J., Lee J.H., Kim T.W., Kim J.S., Lee H.J., Lee J.B., A wafer mapyieldmodelbasedondeeplearningforwaferproductivity enhancement, in SEMI Advanced Semiconductor Manufacturing Conference (ASMC), 2018 29th Annual, IEEE, 2018, 29‚Äì34 [13]Palma F.D., Nicolao G.D., Miraglia G., Donzelli O.M., Process diagnosis via electrical-wafer-sorting maps classification., in ProceedingsoftheFifthIEEEInternationalConferenceonData Mining., 2005 [14]Gan G., Ma C., Wu J., Data clustering: theory, algorithms, and applications, volume 20, Siam, 2007 [15]PraveenP.,RamaB.,AnempiricalcomparisonofClusteringusing hierarchical methods and K-means, in 2016 2nd International ConferenceonAdvancesinElectrical,Electronics,Information, CommunicationandBio-Informatics(AEEICB),IEEE,2016,445‚Äì 449 [16]DabhiD.P.,PatelM.R."}
{"id": "10.1515_comp-2020-0175.pdf::chunk_41", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 41, "text": "hierarchical methods and K-means, in 2016 2nd International ConferenceonAdvancesinElectrical,Electronics,Information, CommunicationandBio-Informatics(AEEICB),IEEE,2016,445‚Äì 449 [16]DabhiD.P.,PatelM.R.,Extensivesurveyonhierarchicalcluster- ing methods in data mining, International Research Journal of Engineering and Technology (IRJET), 3, 2016, 659‚Äì665 [17]XuR.,WunschD.C.,II,Clustering.Hoboken,NJ:Wiley/IEEEPress, 6, 2009, 583‚Äì617 [18]YinH.,BensonA.R.,LeskovecJ.,GleichD.F.,Localhigher-order graphclustering,inProceedingsofthe23rdACMSIGKDDInter- nationalConferenceonKnowledgeDiscoveryandDataMining, 2017, 555‚Äì564 [19]Thinsungnoena T., Kaoungkub N., Durongdumronchaib P., Kerd- prasopbK.,KerdprasopbN.,Theclusteringvaliditywithsilhou- ette and sum of squared errors, learning, 3(7), 2015 [20]Eckmann J., Moses E., Curvature of co-links uncovers hidden thematic layers in the world wide web., in Proc NatL Acad Sci USA, volume 99, 2002, 5825‚Äì5829 [21]Kim J., Lee Y., Kim H., Detection and clustering of mixed-type defectpatternsinwaferbinmaps,IISETransactions,50(2),2018, 99‚Äì111[22]Hsu C.Y., Clustering ensemble for identifying defective wafer bin mapinsemiconductormanufacturing,MathematicalProblems"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_42", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 42, "text": "of mixed-type defectpatternsinwaferbinmaps,IISETransactions,50(2),2018, 99‚Äì111[22]Hsu C.Y., Clustering ensemble for identifying defective wafer bin mapinsemiconductormanufacturing,MathematicalProblems in Engineering, 2015, 2015 [23]Dong H., Chen N., Wang K., Wafer yield prediction using derived spatial variables, Quality and Reliability Engineering Interna- tional, 33(8), 2017, 2327‚Äì2342 [24]Liukkonen M., Hiltunen Y., Recognition of Systematic Spatial Patterns in Silicon Wafers Based on SOM and K-means, IFAC- PapersOnLine, 51(2), 2018, 439‚Äì444 [25]LeachmanR.C.,DingS.,Excursionyieldlossandcycletimere- ductioninsemiconductormanufacturing,IEEETransactionson Automation science and engineering, 8(1), 2011, 112‚Äì117 [26]Peng C., Chien C., Data value development to enhance yield and maintain competitive advantage for semiconductor manufactur- ing., International Journal of Service Technology and Manage- ment, 4(6), 2003, 365‚Äì383 [27]Cunningham S., Spanos C., Voros K., Semiconductor yield im- provement: Results and best practices., IEEE Transactions on Semiconductor Manufacturing, 8(2), 1995, 103‚Äì109 [28]Wang C.H., Separation of composite defect patterns on wafer bin map using support vecto"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_43", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 43, "text": "rovement: Results and best practices., IEEE Transactions on Semiconductor Manufacturing, 8(2), 1995, 103‚Äì109 [28]Wang C.H., Separation of composite defect patterns on wafer bin map using support vector clustering, Expert Systems with Applications,36,2009,2554‚Äì2561,10.1016/j.eswa.2008.01.057 [29]Wang C.H., Recognition of semiconductor defect patterns using spatial filtering and spectral clustering, Expert Systems with Applications, 34, 2008, 1914‚Äì1923, 10.1016/j.eswa.2007.02.014 [30]Hsu S.C., Chien C.F., Hybrid data mining approach for pattern extractionfromwaferbinmaptoimproveyieldinsemiconductor manufacturing, Int. J. Production Economics, 107, 2007, 88‚Äì103, 10.1016/j.ijpe.2006.05.015 [31]LiuC.W.,ChienC.F.,Anintelligentsystemforwaferbinmapdefect diagnosis: An empirical study for semiconductor manufacturing, EngineeringApplicationsofArtificialIntelligence,26,2013,1479‚Äì 1486, 10.1016/j.engappai.2012.11.009 [32]Chien C., Wang W., Cheng J., Data mining for yield enhancement in semiconductor manufacturing and an empirical study., Expert Systems with Applications, 33(1), 2007, 1‚Äì7 [33]FriedmanD.,HansenM.,NairV.,JamesD.,Model-freeestimation of defect clustering in integrated circuit fabr"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_44", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 44, "text": "or manufacturing and an empirical study., Expert Systems with Applications, 33(1), 2007, 1‚Äì7 [33]FriedmanD.,HansenM.,NairV.,JamesD.,Model-freeestimation of defect clustering in integrated circuit fabrication., IEEE Trans- actions onSemiconductor Manufacturing, 10(3), 1997, 344‚Äì359 [34]Li T.S., Huang C.L., Defect spatial pattern recognition using a hybrid SOM‚ÄìSVM approach in semiconductor manufactur- ing, Expert Systems with Applications, 36, 2009, 374‚Äì385, 10.1016/j.eswa.2007.09.023 [35]ZarJ.H.,SignificancetestingoftheSpearmanrankcorrelationco- eflcient,JournaloftheAmericanStatisticalAssociation,67(339), 1972, 578‚Äì580 [36]Student, An experimental determination of the probable error of DrSpearman‚Äôscorrelationcoeflcients,Biometrika,1921,263‚Äì 282 [37]Di Salle P., Colantuono C., Gallo C., Traini A., Frusciante L., Chiu- sanoM.,Modelingmolecularpathwaysbasedongeneexpres- sion and social network analyses: an example from Arabidopsis Thaliana.,in56thAnnualCongressSociet√†ItalianadiGenetica Agraria, Perugia, 2012 [38]Gallo C., Capozzi V., Clustering techniques for revealing gene expressionpatterns,inEncyclopediaofInformationScienceand Technology, Third Edition, IGI Global, 2015, 438‚Äì447 [39"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_45", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 45, "text": "aria, Perugia, 2012 [38]Gallo C., Capozzi V., Clustering techniques for revealing gene expressionpatterns,inEncyclopediaofInformationScienceand Technology, Third Edition, IGI Global, 2015, 438‚Äì447 [39]WattsD.,StrogatzS.,Collectivedynamicsof‚Äôsmall-world‚Äônet- works., Nature, 393, 1998, 440‚Äì442 242 /bar.twoC. Gallo and V. Capozzi Appendix ‚Äì Application examples 1Clustering performance analysis Our algorithm is comparable with the classical clustering methodsdescribedattheendofSection1,bothfromathe- oretical (how clusters are obtained) and practical (the ob- tained clusters) point of view. The classical methods (hi- erarchical,k‚àíMeans) are not generally applicable to the domainoftheproblemwithrelevantresults,becausethey have ‚Äî first of all ‚Äî to define a priori the number of ex- pectedclusters( k‚àíMeans)ortoobtaintheclustersbysub- sequentagglomeration(hierarchical);therefore,thesetwo classicalmethodsinvolveaconsiderablecomputingeffort compared to our method. Further, the classical clustering methods suffer from the inability to \"refine\" progressively the clusters obtained, since the results are based exclu- sively on the matrix of distances initially calculated. Theperformanceofouralgori"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_46", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 46, "text": " methods suffer from the inability to \"refine\" progressively the clusters obtained, since the results are based exclu- sively on the matrix of distances initially calculated. Theperformanceofouralgorithmwascomparedwith the above mentioned classical methods by computing (with the software tools Mathematica ¬πandOrange ¬≤) the Figure A1: TheOrangeworkflowforcomputingthesilhouettein- dexesoftheclusteringmethods(adescriptionandaninitialpartof the dataset is also shown). 1https://www.wolfram.com/mathematica/ 2https://orange.biolab.sisilhouette coefficients of the clusters obtained from the dataset (see Figures A1-A4). Figure A2 shows the silhouette plot for the hierarchi- calclusteringobtainedwiththeWarddistancemetricand a dendrogram threshold limited to 6 clusters. The related maximum silhouette coefficient is less than 0.2. Figure A3 shows the results from the k‚àíMeans clustering with a pre- fixed number of 6 clusters. The related maximum silhou- ette coefficient is slightly greater than the one obtained fromthehierarchicalclustering.InFigureA4theresultsof theapplicationofourmethodareillustrated;inparticular, thetop6clusterswereselected,withanoverallsilhouette indexgreaterthan0.4(abouttw"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_47", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 47, "text": " one obtained fromthehierarchicalclustering.InFigureA4theresultsof theapplicationofourmethodareillustrated;inparticular, thetop6clusterswereselected,withanoverallsilhouette indexgreaterthan0.4(abouttwicetheclassicalmethods). Figure A2: Thesilhouetteplotofthehierarchicalclusteringmethod (linkagemethod:Ward;forcedto6clusters;maximumsilhouette coeflcient less than 0.2). A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two243 Figure A3: Thesilhouetteplotofthek-meansclusteringmethod (fixed to 6 clusters; maximum coeflcient ‚â•0.2). Figure A4: Thesilhouetteplotof the\"relaxed\"clusteringmethod(top 6 clusters; maximum coeflcient ‚â•0.4). 2Example 1: A simple example of the \"relaxed\" clustering algorithm. Supposeyouwanttoidentifythesimilarityclustersamong six given wafer bin maps a‚Äìf(which correspond to the nodes in Figure A5), whose bin value sequences make the arrayXof step 1 of our algorithm from Section 3. From ar- rayXweobtain,forexample,thecorrelationmatrix C(see step 2 of our algorithm) shown in Table A1. Table A1: Theexamplecorrelationmatrix Cbetweennodes a‚Äìf reported in Figure A5. a b c d e f a‚Äì ‚àí0.80 0.35 0.40 0.82 0.74 b‚àí0.80 ‚Äì 0.91 ‚àí0.92 0.81 0.68 c0.35 0.91 ‚Äì 0.77 0.83 0.55 d0.40"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_48", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 48, "text": "own in Table A1. Table A1: Theexamplecorrelationmatrix Cbetweennodes a‚Äìf reported in Figure A5. a b c d e f a‚Äì ‚àí0.80 0.35 0.40 0.82 0.74 b‚àí0.80 ‚Äì 0.91 ‚àí0.92 0.81 0.68 c0.35 0.91 ‚Äì 0.77 0.83 0.55 d0.40 ‚àí0.92 0.77 ‚Äì 0.94 0.18 e0.82 0.81 0.83 0.94 ‚Äì ‚àí0.33 f0.74 0.68 0.55 0.18 ‚àí0.33 ‚ÄìFrom this correlation matrix in the first phase of our algorithm reported in Section 3 we derive the initial corre- lationgraphshowninFigureA5,wheretheonly(absolute) correlation values above a predefined correlation thresh- oldŒ∏1= 0 .70areshownandtheinitialsingleclusteriden- tified consists of all six nodes. fab edc0.74-0.800.820.810.910.770.83-0.920.940.330.671.00 1.000.670.00 Figure A5: Phase1‚ÄîTheinitialcorrelationgraphcomingfromTable A1.Eachnodeisassociated(initalics)withthecorrespondingclus- teringcoeflcient,whileeachedgeshowsthecorrelationcoeflcient between the two connected nodes. Inthesecondphase,foreachnode iitsclusteringcoef- ficientkiis computed, given by the number of \"triangles\" (clusters of three directly and fully connected nodes com- prisingi) as shown in step 5 of our algorithm. In this ex- ample, the six clustering coefficients (shown in italics in Figure A5) are: ka= 0 .33,kb=ke= 0 .67,kc"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_49", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 49, "text": "directly and fully connected nodes com- prisingi) as shown in step 5 of our algorithm. In this ex- ample, the six clustering coefficients (shown in italics in Figure A5) are: ka= 0 .33,kb=ke= 0 .67,kc=kd= 1 .00, kf= 0 .00. Then a minimum threshold Œ∏2is established, for the elimination of nodes having clustering coefficients lower than this fixed threshold. When removing a node iwithki<Œ∏2, ourrelaxed al- gorithmalsotakesintoaccountthenodesclosetoit(upto a predetermined distance Œ¥). If any of the Œ¥‚àíneighboring nodes has a clustering coefficient ‚â•Œ∏2then nodeiwill be maintained.Inessence,thereisa dragging effectofanode withaclusteringcoefficientlowerthanthethreshold Œ∏2by the nodes with a higher clustering coefficient and directly connected to it up to a distance Œ¥. Now, we report some examples of relaxed clustering for different values of Œ∏2applied to the initial correlation graph, with the assumption Œ¥= 1. Œ∏2= 0 .30 For the clustering threshold Œ∏2= 0 .30there are no nodes to be removed, and the corresponding final clustering graph is identical to the initial one: 244 /bar.twoC. Gallo and V. Capozzi Note that node fis maintained (dragged by node aat distanceŒ¥= 1),whereasitshouldhavetob"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_50", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 50, "text": "nd the corresponding final clustering graph is identical to the initial one: 244 /bar.twoC. Gallo and V. Capozzi Note that node fis maintained (dragged by node aat distanceŒ¥= 1),whereasitshouldhavetoberemoved becauseitsclusteringcoefficient kf= 0 .00islessthan Œ∏2= 0 .30. Œ∏2= 0 .50 ForŒ∏2= 0 .50there is one node out of six to be removed (f), and the corresponding final clustering graph becomes: In this case we note that node ais retained (dragged bynodesbandeatdistanceŒ¥= 1),whereasitshould have to be removed because its clustering coefficient ka= 0 .33is less thanŒ∏2= 0 .50. Œ∏2= 0 .70 Now, there are two out of six nodes to be removed ( a, f), and the corresponding final cluster is: Notethatthenodes bandearekept(draggedbynodes candd),whereastheyshouldhavetoberemoved,due to their clustering coefficient being kb=ke= 0 .66 < Œ∏2= 0 .70. Œ∏2= 1 .00 Eventually,for Œ∏2= 1 .00therearethesametwooutof six nodes to be removed ( a,f) from the previous case, with the same final cluster. Also in this case nodes bandeare maintained (dragged by nodes candd), whereas they should have to be removed. It is worth noting that both the initial and final corre- lation graphs show only one cluster, given the si"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_51", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 51, "text": " nodes bandeare maintained (dragged by nodes candd), whereas they should have to be removed. It is worth noting that both the initial and final corre- lation graphs show only one cluster, given the simplicity of our example. In the next example two clusters are ob- tained due to the different conformation of the connectedcomponents in the starting graph and the corresponding correlation and clustering coefficients. 3Example2:Amorecompleteapplicationof the \"relaxed\" clustering algorithm. Suppose you want now to identify the similarity clusters among eight given wafer bin maps (nodes) a‚Äìh(making theanalogousarray Xasintheaboveexample)fromwhich we obtain the correlation matrix Cshown in Table A2. From this correlation matrix in the first phase of our algorithm reported in Section 3 we derive the initial corre- lationgraphshowninFigureA6,whereonlythe(absolute) correlation values above or equal to a predefined correla- tion threshold Œ∏1= 0 .40are shown and the initial single cluster identified consists of all eight nodes. -0.800.400.820.810.770.550.860.780.88abdecfgh0.331.000.000.001.000.331.001.00 Figure A6: Phase1 ‚ÄîTheinitial correlationgraphcoming fromTable A2.Thecorrespondingcluster"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_52", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 52, "text": "ied consists of all eight nodes. -0.800.400.820.810.770.550.860.780.88abdecfgh0.331.000.000.001.000.331.001.00 Figure A6: Phase1 ‚ÄîTheinitial correlationgraphcoming fromTable A2.Thecorrespondingclusteringcoeflcient(initalics)isassociated toeachnode,whereaseachedgeshowsthecorrelationcoeflcient between the two connected nodes. Inthesecondphase,foreachnode iitsclusteringcoef- ficientkiis computed (shown in italics in Figure A6): kc= kd= 0 .00,ka=kf= 0 .33,kb=ke=kg=kh= 1 .00. Then a minimum threshold Œ∏2is established, for the elimina- tionofnodeswithalowerclusteringcoefficient.Asalready shown, our algorithm takes also into account ‚Äî when re- moving a node ‚Äî the nodes close to it (up to a predeter- mined distance Œ¥). Now wereport someexamples of\"relaxed\" clustering for different values of Œ∏2applied to the initial correlation graph of Figure A6, with the assumption Œ¥= 1. Œ∏2= 0 .30 For the clustering threshold Œ∏2= 0 .30there are no nodestoberemoved,andthecorrespondingfinalclus- tering graph is identical to the initial one: aebfhgcd Note that nodes canddare retained (\"dragged\" by nodesfandaatdistanceŒ¥= 1),whereastheyshould A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two245 Table A2:"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_53", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 53, "text": " identical to the initial one: aebfhgcd Note that nodes canddare retained (\"dragged\" by nodesfandaatdistanceŒ¥= 1),whereastheyshould A Wafer Bin Map \"Relaxed\" Clustering Algorithm /bar.two245 Table A2: The example correlation matrix Cbetween nodes a‚Äìh reported in Figure A6. a b c d e f g h a ‚Äì ‚àí0.80 0.35 0.40 0.82 0.24 0.00 0.00 b ‚àí0.80 ‚Äì 0.11 ‚àí0.11 0.81 0.38 0.00 0.00 c 0.35 0.11 ‚Äì 0.77 0.13 0.55 0.00 0.00 d 0.40 ‚àí0.11 0.77 ‚Äì 0.14 0.18 0.00 0.00 e 0.82 0.81 0.13 0.14 ‚Äì ‚àí0.33 0.00 0.00 f 0.24 0.38 0.55 0.18 ‚àí0.33 ‚Äì 0.86 0.78 g 0.00 0.00 0.00 0.00 0.00 0.86 ‚Äì 0.88 h 0.00 0.00 0.00 0.00 0.00 0.78 0.88 ‚Äì havetoberemovedbecausetheirclusteringcoefficient kc=kd= 0 .00<Œ∏2= 0 .30. Œ∏2= 0 .50 ForŒ∏2= 0 .50the two nodes canddare removed (in fact, their clustering coefficients are kc=kd= 0 .00 and their \"relaxed\" clustering coefficients are 0.33 < Œ∏2= 0 .50), and the corresponding final clustering graph defines two clusters: aebfhg In this case let‚Äôs note that nodes aandfare retained (dragged by nodes bandeandgandhat distance Œ¥= 1with clustering coefficient equal to 1), whereas they should have to be removed because their cluster- ing coefficient ka=kf= 0 .33<Œ∏2= 0 .50. 4Supplemental file The (a"}
{"id": "10.1515_comp-2020-0175.pdf::chunk_54", "source": "10.1515_comp-2020-0175.pdf", "chunk_index": 54, "text": "es bandeandgandhat distance Œ¥= 1with clustering coefficient equal to 1), whereas they should have to be removed because their cluster- ing coefficient ka=kf= 0 .33<Œ∏2= 0 .50. 4Supplemental file The (anonymized) dataset is available under this link: https://www.crescenziogallo.it/unifg/pub/ic-yield_ supplemental_file.xlsx"}
{"id": "134263P.pdf::chunk_0", "source": "134263P.pdf", "chunk_index": 0, "text": "Method for reducing false positives using pattern binning based on unsupervised learning Minoru Haradaa, Takehiro Maedaa, and Hajime Kawanob aHitachi, Ltd., Yokohama Research Lab., 292 Yoshida-cho, Totsuka-ku, Yokohama, Kanagawa 244-817, Japan bHitachi High-Tech Corp., 552-53 Shinkou-chou, Hitachinaka, Ibaraki 312-8504, Japan ABSTRACT Semiconductor inspections face the challenge of maintaining high sensitivity for detecting defects while mini- mizing false positives. Distinguishing small defects from manufacturing variations such as line edge roughness becomes increasingly diÔ¨Écult as process shrinking continues. To eÔ¨Äectively address this challenge, it is essen- tial to adjust the detection sensitivity in accordance with the characteristics of the circuit pattern. We have developed a method for classifying circuit patterns using unsupervised segmentation techniques applied to SEM images. This approach enables automatic discrimination of areas such as memory cell regions and peripheral circuit pattern regions without requiring design data. By adjusting the sensitivity depending on the pattern region, the proposed method is able to reduce false positives by over 90% for memory device"}
{"id": "134263P.pdf::chunk_1", "source": "134263P.pdf", "chunk_index": 1, "text": "circuit pattern regions without requiring design data. By adjusting the sensitivity depending on the pattern region, the proposed method is able to reduce false positives by over 90% for memory devices. Keywords: Visual Inspection, False Positive Reduction, Image Segmentation, Unsupervised Learning 1. INTRODUCTION In-line wafer inspection systems are utilized to detect defects and identify the causes of abnormalities that occur early in the manufacturing process.1In these systems, an imaging device with a microscope captures and detects defects from images. The importance of using a scanning electron microscope (SEM) for visual inspection to detect small defects in semiconductor manufacturing is increasingly recognized. In general, when the sensitivity of defect detection is increased to identify small defects on the nanometer scale, it often results in a higher number of false positives due to manufacturing variations in the circuit pattern. The main challenge in defect inspection is how to suppress false positives caused by manufacturing variations while detecting defects with high sensitivity. Distinguishing small defects from manufacturing variations, such as line edge roughnes"}
{"id": "134263P.pdf::chunk_2", "source": "134263P.pdf", "chunk_index": 2, "text": "how to suppress false positives caused by manufacturing variations while detecting defects with high sensitivity. Distinguishing small defects from manufacturing variations, such as line edge roughness, becomes more chal- lenging as processes continue to shrink. Therefore, this research aims to develop image processing technology capable of achieving both highly sensitive defect detection and eÔ¨Äective false positive suppression. 2. REDUCING FALSE POSITIVES USING PATTERN BINNING Defect inspection equipment identiÔ¨Åes the locations of defects in captured images through image processing. A common approach is to calculate the gray-level diÔ¨Äerence between the input image and the reference image and then extract areas where this diÔ¨Äerence exceeds a deÔ¨Åned criteria as candidate defects. For the extracted candidate defects, the system discriminates between real defects and false positives, outputting only those iden- tiÔ¨Åed as real defects. A simple processing method involves quantifying the likelihood of a defect candidate being an actual defect as an anomaly score and then discriminating by applying a threshold to score. However, as critical defects become smaller and more similar in size "}
{"id": "134263P.pdf::chunk_3", "source": "134263P.pdf", "chunk_index": 3, "text": "elihood of a defect candidate being an actual defect as an anomaly score and then discriminating by applying a threshold to score. However, as critical defects become smaller and more similar in size to manufacturing variations, it is increasingly diÔ¨Écult to suÔ¨Éciently reduce false positives using only threshold-based processing of anomaly scores. A discriminator, particularly one utilizing supervised machine learning, is eÔ¨Äective in reducing false positives. However, reducing annotation costs remains a signiÔ¨Åcant challenge, as user annotation is often required for many Further author information: (Send correspondence to Minoru Harada) Minoru Harada: E-mail: minoru.harada.by@hitachi.comMetrology, Inspection, and Process Control XXXIX, edited by Matthew J. Sendelbach, Nivea G. Schuch, Proc. of SPIE Vol. 13426, 134263P ¬∑ ¬© 2025 SPIE 0277-786X ¬∑ doi: 10.1117/12.3048535 Proc. of SPIE Vol. 13426 134263P-1 defects to enhance classiÔ¨Åcation accuracy. In addition, a method has been demonstrated that focuses on the characteristic that the required inspection sensitivity varies depending on the inspection area.2It adjusts the sensitivity according to inspection areas classiÔ¨Åed based on design"}
{"id": "134263P.pdf::chunk_4", "source": "134263P.pdf", "chunk_index": 4, "text": " that focuses on the characteristic that the required inspection sensitivity varies depending on the inspection area.2It adjusts the sensitivity according to inspection areas classiÔ¨Åed based on design information to improve detection accuracy. In this study, we propose machine learning-based segmentation technology to classify inspection areas without requiring additional information such as design data or user annotations. By adjusting sensitivity for each segment, it becomes possible to achieve both enhanced detection sensitivity and reduced false positives. Fig. 1illustrates the Ô¨Çow of the defect detection process with sensitivity adjustment applied using this method. The image is divided into multiple segments based on the appearance of the circuit pattern such as the cell area, peripheral circuit, and intermediate area. Since false positives frequently occur in areas with signiÔ¨Åcant manufacturing variations, such as the intermediate area, lowering the detection sensitivity of the segments corresponding to the intermediate area can eÔ¨Äectively reduce the occurrence of false positives. Defect (anomalous) Non-defective (normal) Reference image Pattern binning (segmentation) Defect"}
{"id": "134263P.pdf::chunk_5", "source": "134263P.pdf", "chunk_index": 5, "text": "segments corresponding to the intermediate area can eÔ¨Äectively reduce the occurrence of false positives. Defect (anomalous) Non-defective (normal) Reference image Pattern binning (segmentation) Defect Non-defective Sensitivity adjustment (parameter tuning)HighComparing inspection Inspection result Input image Low SegmentMemory cellPeripheral Figure 1. False positive reduction based on segmentation technique 3. PATTERN BINNING METHOD BASED ON UNSUPERVISED LEARNING In recent years, deep neural networks have led to signiÔ¨Åcant advancements in performance for many tasks, in- cluding image classiÔ¨Åcation and segmentation. However, achieving a high performance requires a large amount of user-provided data with accurate labels. In particular, image segmentation requires precise pixel-level annota- tion, which is an extremely labor-intensive and costly process. In the context of this research, which focuses on circuit pattern segmentation, accurate pixel annotation based on the appearance of various elements like memory cells, peripheral areas, and intermediate areas is essential. Circuit patterns vary in appearance depending on the device and layer, and these appearances are likely to evolv"}
{"id": "134263P.pdf::chunk_6", "source": "134263P.pdf", "chunk_index": 6, "text": "ious elements like memory cells, peripheral areas, and intermediate areas is essential. Circuit patterns vary in appearance depending on the device and layer, and these appearances are likely to evolve with changes in the manufacturing process. Consequently, it is impractical to pre-learn all circuit patterns, making it necessary to adapt learning directly on the production line. Given the high cost associated with manual annotation for segmentation, it is impractical to adapt on supervised learning methods. Therefore, leveraging image segmentation technology that utilizes unsupervised learning becomes crucial to reduce false positives and manage costs eÔ¨Äectively. Invariant information clustering (IIC),3which utilizes mutual information, has been proposed as a technique for clustering and segmenting images without the need for user annotations. IIC employs a deep neural network as the discriminator to achieve high classiÔ¨Åcation accuracy and can be trained to optimize mutual information without user-provided labels. In this study, we have developed an image segmentation process for semiconductorProc. of SPIE Vol. 13426 134263P-2 Discriminator Superpixel estimator GeneratorIIC Loss S"}
{"id": "134263P.pdf::chunk_7", "source": "134263P.pdf", "chunk_index": 7, "text": " without user-provided labels. In this study, we have developed an image segmentation process for semiconductorProc. of SPIE Vol. 13426 134263P-2 Discriminator Superpixel estimator GeneratorIIC Loss Structure Loss (Cross-entropy) Reconstruction Loss (MSE+SSIM)Corrected segments Reconstruction imageSegmentsLosses for discriminator Input Segment correction Superpixels Figure 2. Training architecture of proposed segmentation process. circuit patterns utilizing the IIC method. This approach allows us to eÔ¨Äectively segment complex patterns without relying on extensive manual labeling, thereby streamlining the process in a cost-eÔ¨Äective manner. Fig. 2shows the architecture of the proposed segmentation process, where the discriminator Dplays a crucial role. To enhance segmentation accuracy, we devised three learning losses for the discriminator: (a) IIC loss, (b) segment correction error, and (c) reconstruction error. The speciÔ¨Åc formulations for these learning losses are detailed in Eq. ( 1). Each loss will be thoroughly explained in the subsequent sections. Ldiscriminator =LIIC+Lstructure +Lrecon (1) 3.1 IIC Loss LIIC P(z' |x')P(z| x) P(z, z') I(z, z')Pixelwise probabilitiesDiscriminato"}
{"id": "134263P.pdf::chunk_8", "source": "134263P.pdf", "chunk_index": 8, "text": ". Each loss will be thoroughly explained in the subsequent sections. Ldiscriminator =LIIC+Lstructure +Lrecon (1) 3.1 IIC Loss LIIC P(z' |x')P(z| x) P(z, z') I(z, z')Pixelwise probabilitiesDiscriminator ùíü Transform Invert transformx x' Figure 3. Calculation Ô¨Çow of mutual information for IIC based image segmentation. The IIC method3assesses the mutual information between the classiÔ¨Åcation results of two paired images. The process for calculating mutual information developed in this study is depicted in Fig. 3. To generate a pair of images, an image transformation is applied to the input image xto generate x‚Ä≤. In this example, the image is rotated by 180 degrees, but it can also be rotated by 90 degrees or Ô¨Çipped vertically or horizontally. The output of the discriminator Dc(x)‚àà[0,1]Ccan be interpreted as the probability distribution of a discrete variable zover Cclasses. Formally, it is expressed as P(z=c|x) =Dc(x). At this stage, P(z‚Ä≤=c|x‚Ä≤) is inverse-transformed to align with P(z=c|x). Now, consider a pair of segment assignment variables, zandProc. of SPIE Vol. 13426 134263P-3 z‚Ä≤, corresponding to two inputs, xand x‚Ä≤. Their conditional joint distribution is expressed as P(z=c;z‚Ä≤= c"}
{"id": "134263P.pdf::chunk_9", "source": "134263P.pdf", "chunk_index": 9, "text": " Now, consider a pair of segment assignment variables, zandProc. of SPIE Vol. 13426 134263P-3 z‚Ä≤, corresponding to two inputs, xand x‚Ä≤. Their conditional joint distribution is expressed as P(z=c;z‚Ä≤= c‚Ä≤|x, x‚Ä≤) =Dc(x)Dc‚Ä≤(x‚Ä≤): The mutual information I(z, z‚Ä≤) is calculated using Eq. ( 2) based on the conditional joint distribution P. By maximizing the mutual information, the discriminator is trained to uniformly classify each pixel in the xand x‚Ä≤images into the same class. We deÔ¨Åne Eq. ( 3) as the loss function for the discriminator, enabling it to be optimized using SGD or Adam optimizers in combination with other loss terms. I(z, z‚Ä≤) =C‚àë c=1C‚àë c‚Ä≤=1Pcc‚Ä≤lnPcc‚Ä≤ PcPc‚Ä≤(2) LIIC=‚àíI(z, z‚Ä≤) (3) 3.2 Structural Loss Lstruct ReÔ¨Åning the segmentation results using image processing techniques is an eÔ¨Äective method for generating spa- tially continuous segments while minimizing the occurrence of small, noisy areas. One approach we explored involves the reÔ¨Ånement of segments by using superpixels, which are calculated from the input image through the superpixel estimator P. Superpixels can also be estimated using a fully convolutional network.4As a result of our investigation, we decided to reÔ¨Åne the"}
{"id": "134263P.pdf::chunk_10", "source": "134263P.pdf", "chunk_index": 10, "text": "are calculated from the input image through the superpixel estimator P. Superpixels can also be estimated using a fully convolutional network.4As a result of our investigation, we decided to reÔ¨Åne the segments output by the discriminator using superpixels. We incorporated the error before and after reÔ¨Ånement into the discriminator‚Äôs loss function. Consequently, the discriminator is trained to directly output segments that have been reÔ¨Åned using superpixels. This methodology not only ensures more accurate segmentation but also eliminates the need to calculate superpixels during the prediction step, eÔ¨Äectively reducing processing time. The error before and after segment reÔ¨Ånement is calculated using cross-entropy, as deÔ¨Åned in Eq. ( 4). Lstruct =‚àíN‚àë n=1F(D(xn),P) log(D(xn)) (4) 3.3 Reconstruction Loss Lrecon If the segmentation result accurately reÔ¨Çects the structure of the circuit pattern, the input image can be re- constructed from the segmentation result. We developed an image generator that takes the segmentation result as input and produces a grayscale image as output. The grayscale diÔ¨Äerence between the input image and the reconstructed image serves as the reconstruction error,"}
{"id": "134263P.pdf::chunk_11", "source": "134263P.pdf", "chunk_index": 11, "text": "or that takes the segmentation result as input and produces a grayscale image as output. The grayscale diÔ¨Äerence between the input image and the reconstructed image serves as the reconstruction error, denoted as Lrecon. Both the discriminator and the image generator are trained to minimize this error. The grayscale diÔ¨Äerence is quantiÔ¨Åed by Eq. ( 5), where Gis the image generator, MSE is the mean squared error, and SSIM is the structural similarity.5Consequently, the training of the discriminator Dis enhanced to produce segmentation results from which the image generator G can accurately reconstruct the input image. Lrecon =N‚àë n=1(MSE( xn,G(D(xn))) + (1 .0‚àíSSIM( xn,G(D(xn))))) (5) 4. EVALUATION RESULTS 4.1 Example of Segmentation Results The processing results for diÔ¨Äerent segment counts Care shown in Fig. 4. Increasing the number of segments enables a more detailed classiÔ¨Åcation of Ô¨Åne structures. The number of segments, which is a user-deÔ¨Åned pa- rameter, can initially be set to a high value to capture detailed structures. Later, to reduce false positives, these segments can be merged during the sensitivity adjustment process.Proc. of SPIE Vol. 13426 134263P-4 (a) Input (b) S = 2"}
{"id": "134263P.pdf::chunk_12", "source": "134263P.pdf", "chunk_index": 12, "text": "gh value to capture detailed structures. Later, to reduce false positives, these segments can be merged during the sensitivity adjustment process.Proc. of SPIE Vol. 13426 134263P-4 (a) Input (b) S = 2 (c) S = 4 (d) S = 6 (e) S = 8 (f) S = 10 Figure 4. Processing results for diÔ¨Äerent segment counts C. 4.2 False Positive Reduction We evaluated the eÔ¨Äectiveness of the proposed method using images of real devices. The conditions for training and evaluation are summarized in Tables 1and2. Table 1. Training conditions. Device type No. of images Image size [pixel] No. of segs. CTraining epochs Memory 214,720 600√ó600 20 20 Logic 30,030 600√ó600 20 20 Table 2. Evaluation conditions. Device type No. of images No. of DOIs Memory 53,680 5 Logic 3,604,370 40 Since all defect candidates appearing in segments without defects of interest (DOIs) are considered false positives, the detection sensitivity for such segments can be reduced. While various methods can be utilized for adjusting the detection sensitivity we chose to multiply the abnormality degree calculated for each defect candidate by a coeÔ¨Écient, Œ±s(s‚àà {1, ..., C }). Other methods of sensitivity adjustment include modifying the abnormalit"}
{"id": "134263P.pdf::chunk_13", "source": "134263P.pdf", "chunk_index": 13, "text": "nsitivity we chose to multiply the abnormality degree calculated for each defect candidate by a coeÔ¨Écient, Œ±s(s‚àà {1, ..., C }). Other methods of sensitivity adjustment include modifying the abnormality oÔ¨Äset for each segment and tweaking the image processing parameters used in the defect candidate extraction process for each segment. The segments of interest which may contain DOIs are identiÔ¨Åed from the segmentation results. For non- interest segments, the Œ±svalue was set to 0.5, eÔ¨Äectively halving the sensitivity. The receiver operating characteristic (ROC) curve, which visualizes the performance evaluation of false pos- itive identiÔ¨Åcation, is shown in Fig. 5. The ROC curve plots the relationship between the false positive rate and the defect detection rate (recall) as the detection threshold is varied, with the false positive rate on the horizontal axis and the defect detection rate on the vertical axis. The closer the curve is to the top-left corner (false positive rate 0, detection rate 100%), the better the performance is considered to be. By adjusting the sensitivity for each segment, the slope of the curve improved for both memory devices and logic devices. While ensuring n"}
{"id": "134263P.pdf::chunk_14", "source": "134263P.pdf", "chunk_index": 14, "text": "n rate 100%), the better the performance is considered to be. By adjusting the sensitivity for each segment, the slope of the curve improved for both memory devices and logic devices. While ensuring no defects of interest were overlooked, false positives were reduced by 96.5% for memory devices and 56.6% for logic devices. As stated above, the proposed method enables segmentation based on the type of circuit pattern without requiring user annotations or design data. We conÔ¨Årmed that false positives can be eÔ¨Äectively reduced by adjusting the defect detection sensitivity for each segment.Proc. of SPIE Vol. 13426 134263P-5 False positive rate False positive rateTrue positive rate [%] (/5) True positive rate [%] (/40) 0.03596.5% 0.43456.6% (a) Memory device (b) Logic deviceSensitivity adjustment AppliedNOT appliedFigure 5. Results of performance evaluation for false positive identiÔ¨Åcation using ROC curves. 5. CONCLUSION We proposed a method to reduce false positives through pattern binning based on unsupervised learning. This method segments captured images into regions, such as memory cells, peripheral circuits, and intermediate areas, based on the appearance of circuit patterns. By t"}
{"id": "134263P.pdf::chunk_15", "source": "134263P.pdf", "chunk_index": 15, "text": " based on unsupervised learning. This method segments captured images into regions, such as memory cells, peripheral circuits, and intermediate areas, based on the appearance of circuit patterns. By tailoring the sensitivity for each region, false positives can be eÔ¨Äectively reduced. In the evaluation, assuming no drop in DOI detection, false positives were reduced by 96.5% for a memory device and 56.6% for a logic device. These results demonstrate the eÔ¨Äectiveness of the proposed method in segmenting circuit patterns and reducing false positives. REFERENCES [1]Guldi, R., ‚ÄúIn-line defect reduction from a historical perspective and its implications for future integrated circuit manufacturing,‚Äù IEEE Transactions on Semiconductor Manufacturing 17(4), 629‚Äì640 (2004). [2]Tolle, I. and Jain, A., ‚ÄúInnovative scalable design based care area methodology for defect monitoring in production,‚Äù in [ 2017 28th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC) ], 144‚Äì148 (2017). [3]Ji, X., Vedaldi, A., and Henriques, J., ‚ÄúInvariant information clustering for unsupervised image classiÔ¨Åcation and segmentation,‚Äù in [ 2019 IEEE/CVF International Conference on Computer Vision (ICCV) ]"}
{"id": "134263P.pdf::chunk_16", "source": "134263P.pdf", "chunk_index": 16, "text": "i, X., Vedaldi, A., and Henriques, J., ‚ÄúInvariant information clustering for unsupervised image classiÔ¨Åcation and segmentation,‚Äù in [ 2019 IEEE/CVF International Conference on Computer Vision (ICCV) ], 9864‚Äì9873 (2019). [4]Yang, F., Sun, Q., Jin, H., and Zhou, Z., ‚ÄúSuperpixel segmentation with fully convolutional networks,‚Äù in [2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) ], 13961‚Äì13970 (2020). [5]Wang, Z., Bovik, A., Sheikh, H., and Simoncelli, E., ‚ÄúImage quality assessment: from error visibility to structural similarity,‚Äù IEEE Transactions on Image Processing 13(4), 600‚Äì612 (2004).Proc. of SPIE Vol. 13426 134263P-6"}
{"id": "A production planning model for sc industry.pdf::chunk_0", "source": "A production planning model for sc industry.pdf", "chunk_index": 0, "text": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/346610576 A Production Planning Model for the Semiconductor Industry with Processing Capabilities Conf erence Paper ¬∑ Mar ch 2017 CITATIONS 0READS 1,055 1 author: Cenk √áal ƒ± ≈ü kan Utah V alle y Univ ersity 39 PUBLICA TIONS 241 CITATIONS SEE PROFILE All c ontent f ollo wing this p age was uplo aded b y Cenk √áal ƒ± ≈ü kan on 03 Dec ember 2020. The user has r equest ed enhanc ement of the do wnlo aded file. A PRODUCTION PLANNING MODEL FOR THE SEMICONDUCTOR INDUSTRY WITH PROCESSING CAPABILITIES Cenk C ¬∏alƒ±¬∏ skan, Woodbury School of Business, Utah Valley U niversity, 800 W. University Pkwy, Orem, UT 84058, (801) 863-6487, cenk.caliskan@uvu.e du ABSTRACT Production planning in the semiconductor industry has challenges du e to complicating fac- tors such as binning and downgrading and the use of overlapping pro duction capabilities instead of individual machines or machine types as resources. Binnin g is due to the in- herent variability in semiconductor manufacturing processes. The output of manufacturing processes that produce integrated circuits (IC) is highly variable in"}
{"id": "A production planning model for sc industry.pdf::chunk_1", "source": "A production planning model for sc industry.pdf", "chunk_index": 1, "text": " as resources. Binnin g is due to the in- herent variability in semiconductor manufacturing processes. The output of manufacturing processes that produce integrated circuits (IC) is highly variable in terms of clock speed, memory and other characteristics. A process that is started with the objective of producing a speciÔ¨Åc IC with a desired speed may produce both faster and slowe r ones, as well as the desired ones. Faster ones are frequently downgraded to the des ired speed level, in order to satisfy the demand at that level. Another complicating factor is the use of process capabili- ties. A process plan for producing a given product may require a spe ciÔ¨Åc type of equipment, or a speciÔ¨Åc processing capability that may exist on diÔ¨Äerent types o f machines. This creates an overlap between diÔ¨Äerent types of machines, creating bundle co nstraints that complicates the problem further. We propose a mixed integer program that acc ounts for these compli- cating factors and creates an aggregate production plan, as the higher level of a two-level planning approach. Keywords: production planning, semiconductor, mixed inte ger programming, process capabil- ities 1. INTRODUCTION Productionpla"}
{"id": "A production planning model for sc industry.pdf::chunk_2", "source": "A production planning model for sc industry.pdf", "chunk_index": 2, "text": "te production plan, as the higher level of a two-level planning approach. Keywords: production planning, semiconductor, mixed inte ger programming, process capabil- ities 1. INTRODUCTION Productionplanninginthesemiconductor industry ischallenging duet ocomplicating factors such as binning and downgrading, and the use of process capabilities as resources, instead of speciÔ¨Åc equipment units or equipment types. A silicon wafer consis ts of a number of integrated circuits (IC) put together in a circular disk. The equipme nt that is used in man- ufacturing silicon wafers is expensive. This necessitates using the e quipment for a large number of processing steps. For this reason, process Ô¨Çows in sem iconductor manufacturing are re-entrant, i.e. wafers visit the same type of machine many time s during their manu- facture. Binning is another challenge that complicates the problem b y adding uncertainty to the output of the production process, not only in the form of va riable output quantity, but also in the form of variable output product types. Downgrading is the practice of as- signing higher quality (higher speed or memory) products to lesser q uality demand, since additional demand fo"}
{"id": "A production planning model for sc industry.pdf::chunk_3", "source": "A production planning model for sc industry.pdf", "chunk_index": 3, "text": "but also in the form of variable output product types. Downgrading is the practice of as- signing higher quality (higher speed or memory) products to lesser q uality demand, since additional demand for the higher quality product does not exist and /or the demand for the lesser quality ones must be urgently satisÔ¨Åed. Average bin fraction s for a process plan are -761- usually known. The usual practice is to plan for the average bin frac tions rather than the intended output. Another complicating factor is the use of process capabilities. A pro cess plan for producing a given product may require a speciÔ¨Åc type of equipment, or a speciÔ¨Å c processing capability, which may exist on diÔ¨Äerent types of machines. This creates an over lap between diÔ¨Äerent types of machines, which complicates the problem further, by addin g bundle constraints. In this paper, we propose a mixed-integer programming model that accounts for these com- plexities that we mentioned and produces an executable aggregate production plan, which will be an input to the lower-level planning process, i.e. detailed sched uling. 2. LITERATURE REVIEW Overthedecades, manyapproacheswereproposedtotacklepro ductionplanningandsche"}
{"id": "A production planning model for sc industry.pdf::chunk_4", "source": "A production planning model for sc industry.pdf", "chunk_index": 4, "text": "roduction plan, which will be an input to the lower-level planning process, i.e. detailed sched uling. 2. LITERATURE REVIEW Overthedecades, manyapproacheswereproposedtotacklepro ductionplanningandschedul- ing problems in semiconductor manufacturing. Uzsoy et al. (1992, 1 994) provide a detailed description of the semiconductor manufacturing process, includin g discussions of production planning, scheduling, control and performance evaluation. M¬® onc h et al. (2013) provide a comprehensive summary of the literature on production planning mo dels in semiconductor manufacturing. Gupta et al. (2006) discuss all aspects of planning and control in semicon- ductor manufacturing and describe the state of the art in the liter ature. Gallego et al. (2006) propose models to tackle the issue of binning and downgrading in an inv entory management context and present two heuristics. Pfund et al. (2006) consider the practical aspects of the problems and surveys industrial planning and control practice s and situations in the semiconductor industry. Hung & Leachman (1996) suggest automated production planning b ased on iterative LP op- timization and discrete-event simulation while Lee et al. (199"}
{"id": "A production planning model for sc industry.pdf::chunk_5", "source": "A production planning model for sc industry.pdf", "chunk_index": 5, "text": "e s and situations in the semiconductor industry. Hung & Leachman (1996) suggest automated production planning b ased on iterative LP op- timization and discrete-event simulation while Lee et al. (1997) prese nt a model based on LP techniques considering variable cycle times. Chou & Hong (2000) pro pose a mixed integer programming model for product mix decisions in a semiconductor fou ndry and develop a bottleneck-based procedure, and Chen (2003) presents a fuzz y LP model for monthly pro- duction planning in a wafer fabrication facility. Hwang & Chang (2003) propose a two-level hierarchical planning andscheduling approach, which consists ofme dium termandlongterm models. Asmundsson et al. (2006) develop a nonlinear programming m odel for production planning in a wafer fabrication facility. Venkateswaran & Son (2005) provides a review of the literature in h ierarchical (multi-level) production planning approaches. Shanthikumar & Sargent (1983) classify these hierarchical approaches in which diÔ¨Äerent levels use diÔ¨Äerent modeling methodolog ies. Byrne & Bakir (1999) propose a hybrid method in which an LP model and a simulation m odel are used iteratively, while Kim & Kim (2001) use t"}
{"id": "A production planning model for sc industry.pdf::chunk_6", "source": "A production planning model for sc industry.pdf", "chunk_index": 6, "text": "which diÔ¨Äerent levels use diÔ¨Äerent modeling methodolog ies. Byrne & Bakir (1999) propose a hybrid method in which an LP model and a simulation m odel are used iteratively, while Kim & Kim (2001) use the workload and utilization of eac h machine for validating and updating parameters and data in the LP model. Byrne & Hossain (2005) modify the model of Kim & Kim (2001) by allowing split lots. Venkateswar an & Son (2005) propose a hierarchical production planning and scheduling method u sing a system dynamics model and a discrete-event simulation model in the two levels. -762- Jornsten & Leisten (1995) suggest an aggregation-disaggregat ion approach and present an iterative procedure for connecting the aggregate and disaggreg ate levels. Leisten (1998) discusses how a suboptimal or infeasible solution can be optimized in th is iterative process. Vicens et al. (2001) propose an iterative aggregation-disaggrega tion scheme in which the processing times of aggregated product types can be adjusted a t each iteration. Sel¬∏ cuk et al. (2006) show that excessive frequent updating of data in the aggr egate model deteriorates the quality of production plans and schedules. Bang & Kim (2010) pro"}
{"id": "A production planning model for sc industry.pdf::chunk_7", "source": "A production planning model for sc industry.pdf", "chunk_index": 7, "text": "usted a t each iteration. Sel¬∏ cuk et al. (2006) show that excessive frequent updating of data in the aggr egate model deteriorates the quality of production plans and schedules. Bang & Kim (2010) pro pose a two-level productionplanningmethodwithLP-basedaggregateplanningandd iscrete-event simulation based scheduling in the two levels. None of the aforementioned models incorporate the complexities ad ded to the problem by overlapping processing capabilities. In this paper, we propose a mixe d-integer programming basedmodel thatsuccessfully incorporatesbinning, downgrading andprocessing capabilities. Our model generates an aggregateplanas part of a two level hiera rchical modeling approach. In future research, we will add a simulation based scheduling model in the lower level. 3. PROBLEM DESCRIPTION As it is common in aggregate planning, we assume a Ô¨Ånite planning horizo n with discrete planning intervals. The model is intended to be re-optimized on a rolling -horizon, typically on a daily basis. The following parameters represent the range of ind ices in our model: T= the number of intervals in the planning horizon, P= the number of process plans that are in use at the facility, K= "}
{"id": "A production planning model for sc industry.pdf::chunk_8", "source": "A production planning model for sc industry.pdf", "chunk_index": 8, "text": "ly basis. The following parameters represent the range of ind ices in our model: T= the number of intervals in the planning horizon, P= the number of process plans that are in use at the facility, K= the number of products manufactured at the facility, R= the number of resources (equipment types and processing capa bilities), Q= the number of equipment units (individual machines) at the facility. A process plan is a set of processing steps that is intended to produ ce a certain product, but it results in a set of products that diÔ¨Äer by memory, clock speed , etc., due to binning. Note that each of the output items that result from a process plan that diÔ¨Äer by at least one characteristic is a diÔ¨Äerent product. The manufacturing reso urces that are used in the facility are represented by ‚Äúequipment types‚Äù and ‚Äúprocessing ca pabilities‚Äù in our model. One machine is capable of performing a number of diÔ¨Äerent steps, ea ch of which represents a ‚Äúprocessing capability.‚Äù Some process plan steps specify a certain e quipment type, whereas others specify a certain capability. The following parameters link the equipment units to equipment types and processing capabilities: ET(q) = the type of e"}
{"id": "A production planning model for sc industry.pdf::chunk_9", "source": "A production planning model for sc industry.pdf", "chunk_index": 9, "text": " specify a certain e quipment type, whereas others specify a certain capability. The following parameters link the equipment units to equipment types and processing capabilities: ET(q) = the type of equipment unit q, EK(q) = the set of processing capabilities that the equipment unit qhas, EU(r) = the set of equipment units that this resource is deÔ¨Åned on. Binning and downgrading (downward substitution) are represente d by the following param- eters. We assume constant binning fractions that are calculated f rom historical production -763- statistics. Any product can be (downward) substituted or downg raded to a lesser product, and this downgrading relationship is user-deÔ¨Åned. O(p) = the set of output products for process plan p, G(k) = the set of products downgradeable to product k, including itself œÜkp= binning fraction for product k, using process plan p, We assume a constant deterministic demand for each product in eac h time interval. On a rolling horizon, the model is adjusted with changes in the demand and in the conditions of the machines and the progress of the existing production lots. The following are the param- eters representing the demand and process plans: Dkt= the d"}
{"id": "A production planning model for sc industry.pdf::chunk_10", "source": "A production planning model for sc industry.pdf", "chunk_index": 10, "text": "h changes in the demand and in the conditions of the machines and the progress of the existing production lots. The following are the param- eters representing the demand and process plans: Dkt= the demand for product kin period t, œÑp= the total cycle time for process plan p, Œªp= the lot size for process plan p, Each processing step of each process plan consumes a speciÔ¨Åc res ource, i.e. an equipment type or processing capability. The following parameters deÔ¨Åne this r elationship between process plans and resources as well as the capacities of the resou rces. Capacities are deÔ¨Åned on individual equipment units. œÄrp= the amount of resource rrequired for process plan p, Œ∏rp= the time resource ris required for process plan pfrom the start, Uqt= the capacity of equipment unit qin period t, We consider the manufacturing costs, inventory holding costs, an d backordering costs for the products. The manufacturing costs are deÔ¨Åned for each exe cution of each process plan, and this includes the cost of input parts and raw materials, the cost of labor and the cost of resources consumed by the process plan execution, which really is a ‚Äúlot start‚Äù on that process plan. These cost parameters are"}
{"id": "A production planning model for sc industry.pdf::chunk_11", "source": "A production planning model for sc industry.pdf", "chunk_index": 11, "text": "cost of input parts and raw materials, the cost of labor and the cost of resources consumed by the process plan execution, which really is a ‚Äúlot start‚Äù on that process plan. These cost parameters are deÔ¨Åned as follows: CœÄ p= the cost of process plan pper lot, Cœà k= the cost of inventory holding per unit of product k, CŒ≤ k= the cost of backordering per unit of product k. The decision variables of the model are deÔ¨Åned as follows. Xtp= the number of times process plan pis started in period t, Ikt= the number of units of product kcarried in the inventory at the end of period t, Bkt= the number of units of product kbackordered at the end of period k, Yrqt= the amount of resource rthat is used up on equipment unit qin period t Inourmodel, ourobjectiveistodetermineaminimumcostaggregate planthatminimizesthe manufacturing, inventory holding and backordering costs. There fore, our objective function -764- is as follows: Z=T/summationdisplay t=1P/summationdisplay p=1CœÄ pXtp+T/summationdisplay t=1K/summationdisplay k=1Cœà kIkt+T/summationdisplay t=1K/summationdisplay k=1CŒ≤ kBkt (1) For products k= 1,2,...,K, in periods t= 1,2,...,T, the initial inventory plus the pro- duction output in that pe"}
{"id": "A production planning model for sc industry.pdf::chunk_12", "source": "A production planning model for sc industry.pdf", "chunk_index": 12, "text": "1K/summationdisplay k=1Cœà kIkt+T/summationdisplay t=1K/summationdisplay k=1CŒ≤ kBkt (1) For products k= 1,2,...,K, in periods t= 1,2,...,T, the initial inventory plus the pro- duction output in that period minus any inventory left at the end of t hat period should be equal to the demand in that period plus backordered amount at the beginning of that period minus any backordering left at the end of the period. This results in t he following constraint: Ik(t‚àí1)+P/summationdisplay p=1/summationdisplay i‚ààG(k)‚à©O(p)ŒªpœÜipX(t‚àíœÑp)p‚àíIkt=Bk(t‚àí1)+Dkt‚àíBkt (2) For each resource r= 1,2,...,R, in each time period t= 1,2,...,T, process plans consume a certain amount and they add up to the consumption of that resou rce in that period. This results in the following set of constraints which link process plans with resources: P/summationdisplay p=1œÄrpX(t‚àíŒ∏rp)p=/summationdisplay q‚ààEU(r)Yrqt (3) The total consumption of all resources (equipment type and capa bilities) on each equipment unit cannot exceed its capacity for equipment units q= 1,2,...,Q, in time periods t= 1,2,...,T. This ensures that consumption of equipment types and processin g capabilities will not be multiply allocated to individual equi"}
{"id": "A production planning model for sc industry.pdf::chunk_13", "source": "A production planning model for sc industry.pdf", "chunk_index": 13, "text": "capacity for equipment units q= 1,2,...,Q, in time periods t= 1,2,...,T. This ensures that consumption of equipment types and processin g capabilities will not be multiply allocated to individual equipment units. This results in the following set of constraints: /summationdisplay r‚ààET(q)‚à™EK(q)Yrqt‚â§Uqt (4) Finally, all decision variables must be nonnegative and production lot s tarts, or the number of times each process plan is executed ( Xvariables) should be integer: Xtp‚â•0 (5) and integer , t= 1,2,...,T, p = 1,2,...,P (6) Ikt,Bkt‚â•0, k= 1,2,...,K, t = 1,2,...,T (7) Yrt,Yrqt‚â•0, r= 1,2,...,R, q = 1,2,...,Q, t = 1,2,...,T (8) -765- 4. SOLUTION METHODOLOGY We applied the proposed mixed integer program on a real fab data fr om our industrial partner, and solved it using CPLEX. In our preliminary tests, we obs erved that the model is solvableinreasonable time(less than20minutes of CPUtime) when the fabislightly loaded, i.e. when the total demand only consumes up to 65% of the fab capac ity. For loads heavier than 65%, the CPU time becomes excessive. For this reason, we will e xplore decomposition and heuristic approaches based on partitioning and relaxation of th e capacity constraints. "}
{"id": "A production planning model for sc industry.pdf::chunk_14", "source": "A production planning model for sc industry.pdf", "chunk_index": 14, "text": "For loads heavier than 65%, the CPU time becomes excessive. For this reason, we will e xplore decomposition and heuristic approaches based on partitioning and relaxation of th e capacity constraints. In this preliminary stage, we were able to optimize aggregate plans fo r up to 100 process plans, 50 products, 40 equipment types, and 150 process capabilit ies. In future research, we will explore ways to solve bigger, more realistic size problems, and w e will also develop simulation based models, to be used for detailed scheduling of the res ources, as part of a two-level hierarchical planning approach. 5. CONCLUSIONS In this research, we develop a mixed integer programming model for the medium term pro- duction planning of a semiconductor manufacturing facility that inco rporates the challenges inherent in the semiconductor production planning. Production plan ning in the semiconduc- tor manufacturing industry is challenging due to complexities caused by variable output as a result of the phenomenon of binning, as well as re-entrant Ô¨Çows th at is caused by expensive equipment that have to be used for a large number of processing st eps, resulting in wafers visiting the same equipme"}
{"id": "A production planning model for sc industry.pdf::chunk_15", "source": "A production planning model for sc industry.pdf", "chunk_index": 15, "text": "the phenomenon of binning, as well as re-entrant Ô¨Çows th at is caused by expensive equipment that have to be used for a large number of processing st eps, resulting in wafers visiting the same equipment many times during diÔ¨Äerent stages of its m anufacturing process. For this reason, resources are deÔ¨Åned as ‚Äúprocessing capabilities ‚Äù that cause overlap of dif- ferent equipment types and make capacity planning more diÔ¨Écult. We propose a model that successfully and realistically models binning and overlapping processin g capabilities. The model is promising as it was successfully optimized for a real wafer fa b with a 65% capacity utilization. Future research will address decomposition and heurist ic approaches to optimize the mixed integer program for larger datasets and higher workload s. References Asmundsson, J., Rardin, R. L., & Uzsoy, R. (2006). Tractable nonlin ear production planning models for semiconductor wafer fabrication facilities. IEEE Transactions on Semiconduc- tor Manufacturing , 19, 95‚Äì111. Bang, J. & Kim, Y. (2010). Hierarchical production planning for sem iconductor wafer fab- rication based on linear programming and discrete-event simulation. IEEE Transactions o"}
{"id": "A production planning model for sc industry.pdf::chunk_16", "source": "A production planning model for sc industry.pdf", "chunk_index": 16, "text": "acturing , 19, 95‚Äì111. Bang, J. & Kim, Y. (2010). Hierarchical production planning for sem iconductor wafer fab- rication based on linear programming and discrete-event simulation. IEEE Transactions on Automation Science and Engineering , 7(2), 326‚Äì336. Byrne, M. D. & Bakir, M. A. (1999). Production planning using a hybr id simulation- analytical approach. International Journal of Production Economics , 59, 305‚Äì311. -766- Byrne, M. D. & Hossain, M. M. (2005). Production planning: Animpro ved hybrid approach. International Journal of Production Economics , 93, 225‚Äì229. Chen, T. (2003). A fuzzy mid-term single-fab production planning m odel.Journal of Intel- ligent Manufacturing , 14, 273‚Äì285. Chou, Y.C. &Hong, I.H.(2000). Amethodologyforproductmixpla nninginsemiconductor foundry manufacturing. IEEE Transactions on Semiconductor Manufacturing , 13, 278‚Äì 285. Gallego, G., Katirciglu, K., & Ramachandran, B. (2006). Semiconduct or inventory man- agement with multiple grade parts and downgrading. Production Planning and Control , 17(7), 689‚Äì700. Gupta, J., Ruiz, R., Fowler, J., & Mason, S. (2006). Operational plan ning and control of semiconductor wafer production. Production Planning an"}
{"id": "A production planning model for sc industry.pdf::chunk_17", "source": "A production planning model for sc industry.pdf", "chunk_index": 17, "text": "ding. Production Planning and Control , 17(7), 689‚Äì700. Gupta, J., Ruiz, R., Fowler, J., & Mason, S. (2006). Operational plan ning and control of semiconductor wafer production. Production Planning and Control , 17(7), 639‚Äì647. Hung, Y. & Leachman, R. (1996). A production planning methodolog y for semiconductor manufacturing based on iterative simulation and linear programming c alculations. IEEE Transactions on Semiconductor Manufacturing , 9(2), 257‚Äì269. Hwang, T.-K. & Chang, S.-C. (2003). Design of a lagrangian relaxatio n based hierarchical production scheduling environment for semiconductor wafer fabr ication.IEEE Transac- tions on Robotics and Automation , 19, 566‚Äì578. Jornsten, K. & Leisten, R. (1995). Linear programming aggregat ion: A heuristic for hierar- chical production planning. Asia-PaciÔ¨Åc Journal of Operational Research , 12, 161‚Äì177. Kim, B. K.&Kim, S. Y.(2001). Extended model forahybrid product ionplanningapproach. International Journal of Production Economics , 73, 165‚Äì173. Lee, Y., Kim, S., Yea, S., & Kim, B. (1997). Production planning in semico nductor wafer fab considering variable cycle times. Computers and Industrial Engineering , 33, 713‚Äì716. Leisten, R. ("}
{"id": "A production planning model for sc industry.pdf::chunk_18", "source": "A production planning model for sc industry.pdf", "chunk_index": 18, "text": "65‚Äì173. Lee, Y., Kim, S., Yea, S., & Kim, B. (1997). Production planning in semico nductor wafer fab considering variable cycle times. Computers and Industrial Engineering , 33, 713‚Äì716. Leisten, R. (1998). An LP-aggregation view on aggregation in multi- level production plan- ning.Annals of Operations Research , 82, 413‚Äì434. M¬® onch, L., Fowler, J. W., & Mason, S. J. (2013). Production Planning and Control for Semiconductor Wafer Fabrication Facilities , volume 52 of Operations Research/Computer Science Interfaces . New York: Springer. Pfund, M., Mason, S., & Fowler, J. (2006). Semiconductor manufac turing scheduling and dispatching. In J. W. Herrmann (Ed.), Handbook of Production Scheduling (pp. 213‚Äì242). New York: Springer. Sel¬∏ cuk, B., Fransoo, J. C., & Kok, A. G. D. (2006). The eÔ¨Äect of up dating lead times on the performance of hierarchical planning systems. International Journal of Production Economics , 104, 427‚Äì440. -767- Shanthikumar, J. G. & Sargent, R. G. (1983). A unifying view of hyb rid simulation/analytic models and modeling. Operations Research , 31, 10301052. Uzsoy, R., Lee, C., & Martin-Vega, L. (1992). A review of productio n planning and schedul- ing models in"}
{"id": "A production planning model for sc industry.pdf::chunk_19", "source": "A production planning model for sc industry.pdf", "chunk_index": 19, "text": "g view of hyb rid simulation/analytic models and modeling. Operations Research , 31, 10301052. Uzsoy, R., Lee, C., & Martin-Vega, L. (1992). A review of productio n planning and schedul- ing models in the semiconductor industry part i: System characteris tics, performance evaluation and production planning. IEE Transactions , 24(4), 47‚Äì60. Uzsoy, R.,Lee, C., &Martin-Vega,L.(1994). Areviewofproductio nplanningandscheduling models in the semiconductor industry part i: Shop-Ô¨Çoor control. IEE Transactions , 26(5), 44‚Äì55. Venkateswaran, J. & Son, Y.-J. (2005). Hybrid system dynamic-d iscrete event simulation- based architecture for hierarchical production planning. International Journal of Produc- tion Research , 43, 4397‚Äì4429. Vicens, E., Alemany, M. E., Andres, C., & Guarch, J. J. (2001). A des ign and application methodologyforhierarchicalproductionplanningdecisionsupport systemsinanenterprise integration context. International Journal of Production Economics , 74, 5‚Äì20. -768- View publication stats"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_0", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 0, "text": "Expert Systems With Applications 249 (2024) 123601 Available online 4 March 2024 0957-4174/¬© 2024 Published by Elsevier Ltd. Contents lists available at ScienceDirect Expert Systems With Applications journal homepage: www.elsevier.com/locate/eswa A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification Yi Wanga, Dong Nia,‚àó, Zhenyu Huangb, Puyang Chenb aCollege of Control Science and Engineering, Zhejiang University, Hangzhou 310027, China bIntel Corporation, Dalian 116630, China A R T I C L E I N F O Keywords: Self-supervised learning Masked autoencoder Complex wafer bin map Automatic defect classification Semiconductor manufacturingA B S T R A C T Wafer bin map (WBM) automatic classification is one of the critical challenges for semiconductor intelligent manufacturing. Many deep learning-based classification models have performed well in WBM classification, but all require a large amount of labeled data for training. Since real-world WBMs are highly complex and can be labeled correctly only by seasoned engineers, such requirements undermine the practical value of those methods. Several self-supervised learning methods have recently "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_1", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 1, "text": "Ms are highly complex and can be labeled correctly only by seasoned engineers, such requirements undermine the practical value of those methods. Several self-supervised learning methods have recently been proposed for WBM to improve classification performance. However, they still require much labeled data for fine-tuning and are only adapted for binary WBM with a single gross failure area. To address these limitations, this study introduces a self- supervised framework based on masked autoencoder (MAE) for complex WBMs with mixed bin signatures and multiple gross failure area patterns. A patchMC encoder is proposed to improve MAE‚Äôs representation ability for complex WBMs with mixed bin signatures. Moreover, the pre-trained MAE encoder with a multi- label classifier fine-tuned by labeled WBMs enables a few-shot classification of complex WBMs with multiple gross failure areas. Experimental validation of the proposed method is performed on a real-world complex WBM dataset from Intel Corporation. The results demonstrate that the proposed method can make good use of unlabeled WBMs and reduce the demand for labeled data to a few-shot level and, at the same time, guarantees a classificati"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_2", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 2, "text": "ration. The results demonstrate that the proposed method can make good use of unlabeled WBMs and reduce the demand for labeled data to a few-shot level and, at the same time, guarantees a classification accuracy of more than 90%. By comparing MAE with other self-supervised learning methods, MAE outperforms other existing self-supervised methods for WBM data. 1. Introduction As the complexity of semiconductor manufacturing processes esca- lates, the defects in wafers generated during production have become more diverse and intricate. A wafer bin map (WBM) displays the test results for each chip on a wafer, based on the chip probe test failure mode and the chip‚Äôs position (die). The chip probe test, a crucial final evaluation after the entire manufacturing process, assesses the performance and functionality of each chip. During this test, each die undergoes multiple probe test modes, with the first failure mode being recorded as the bin result. Throughout the wafer fabrication process, various manufacturing issues may cause multiple dies on a wafer to be defective. These defects often cluster in one or several areas on the wafer, forming spatial patterns known as gross failure areas "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_3", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 3, "text": "arious manufacturing issues may cause multiple dies on a wafer to be defective. These defects often cluster in one or several areas on the wafer, forming spatial patterns known as gross failure areas (GFAs). These patterns, including common types like ring, scratch, loc, and centers, are indicative of specific process-related issues and contain valuable data for improving yield and quality ( Kim & Kang , 2021 ). The classification of GFAs is instrumental for engineers to identify and rectify problems in the ‚àóCorresponding author. E-mail addresses: 11732019@zju.edu.cn (Y. Wang), dni@zju.edu.cn (D. Ni), zhenyu.huang@intel.com (Z. Huang), puyang.chen@intel.com (P. Chen).production process, thereby reducing costs and enhancing yield ( Hsu & Chien , 2007 ). With the growing intricacy of production environ- ments, the need for automated WBM GFA classification has become increasingly critical. Complex WBMs are those containing multiple gross failure areas (GFAs) and diverse bin categories, typically visualized using various colors. Fig. 1 illustrates an example of a complex WBM, detailing both the bin categories and the GFAs present. Furthermore, Fig. 2 showcases additional real-world com"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_4", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 4, "text": "pically visualized using various colors. Fig. 1 illustrates an example of a complex WBM, detailing both the bin categories and the GFAs present. Furthermore, Fig. 2 showcases additional real-world complex WBMs, each featuring different types of GFAs and assorted bin mixtures. In practical settings, complex WBMs are most prevalent. However, for simplification, early research primar- ily concentrated on binary WBMs, which are derived from multi-bin WBMs based on the passing or failing bin categories ( Alawieh, Boning, & Pan , 2020 ; Nakazawa & Kulkarni , 2019 ; Saqlain, Jargalsaikhan, & Lee, 2019 ; Wang & Ni , 2019 ; Wu, Jang, & Chen , 2015 ; Yu & Lu , 2016 ). In recent years, there has been a notable shift toward more nuanced classifications. Several studies have been dedicated to multi-GFA binary WBM classification ( Chiu & Chen , 2021 ; Kim, Lee, & Kim , 2018 ; Kong https://doi.org/10.1016/j.eswa.2024.123601 Received 1 September 2023; Received in revised form 28 February 2024; Accepted 1 March 2024 Expert Systems With Applications 249 (2024) 123601 2Y. Wang et al. Fig. 1. Presentation of bin and GFA of an example complex WBM. & Ni, 2020a ) and single GFA multi-bin WBMs ( Chen et a"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_5", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 5, "text": "d 1 March 2024 Expert Systems With Applications 249 (2024) 123601 2Y. Wang et al. Fig. 1. Presentation of bin and GFA of an example complex WBM. & Ni, 2020a ) and single GFA multi-bin WBMs ( Chen et al. , 2020 ; Kim, Mo, Park, Kim, & Kang , 2019 ; Li & Tsai , 2020 ; Wang & Ni , 2019 ). Most recently, the first deep learning-based method specifically tailored for complex WBMs was introduced ( Wang and Ni , 2023 ). Deep learning methods typically depend on extensive labeled datasets for model training, a requirement that becomes even more pronounced with the intricate nature of complex WBMs. The sophis- tication of these maps substantially escalates the complexity of model structures, necessitating substantial labeled data to attain satisfactory results ( Sun, Shrivastava, Singh, & Gupta , 2017 ). In the real-world scenario of wafer fabrication, the availability of labeled data is consid- erably limited due to the laborious and time-intensive nature of manual labeling. This challenge is particularly acute with WBM data, where numerous GFA categories exist, each with only a few samples. Further- more, a significant portion of WBMs remains unlabeled. Consequently, effectively leveragin"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_6", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 6, "text": "particularly acute with WBM data, where numerous GFA categories exist, each with only a few samples. Further- more, a significant portion of WBMs remains unlabeled. Consequently, effectively leveraging the vast amount of unlabeled data to enhance the model‚Äôs classification performance with minimal labeled data is not only crucial but also profoundly significant for the semiconductor manufacturing industry. In response to the aforementioned requirements, this study intro- duces a self-supervised learning framework utilizing a masked autoen- coder (MAE) for complex WBM classification. MAE, recognized as an effective self-supervised method ( He et al. , 2021 ), employs vision trans- formers (ViT) as both encoder and decoder, marking its first application to WBMs. Employing MAE for self-supervised learning substantially enhances WBM classification by leveraging large-scale unlabeled data for pre-training, coupled with a modest amount of labeled data for fine- tuning. Initially, we present a patchMC encoder specifically designed for the multi-bin nature of complex WBMs. This encoder utilizes a con- volutional neural network (CNN) preceding the MAE to bolster feature extraction capabilit"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_7", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 7, "text": "a patchMC encoder specifically designed for the multi-bin nature of complex WBMs. This encoder utilizes a con- volutional neural network (CNN) preceding the MAE to bolster feature extraction capabilities for intricate WBMs. Additionally, to address the multi-GFA challenge, a multi-label fine-tuning method is implemented, facilitating both single- and multi-GFA classification. The efficacy of the proposed method is substantiated using real-world complex WBM datasets. Our experiments reveal that this method can attain over 96% classification precision with a limited number of labeled samples for complex WBMs. Furthermore, we benchmarked MAE against other prevailing self-supervised methods. The comparative results affirm that employing MAE for WBM self-supervised learning substantially amelio- rates performance while concurrently curbing the reliance on labeled data. The contributions of this article are summarized as follows: 1. A masked autoencoder (MAE) is introduced for WBM self- supervised learning, facilitating its application in classification tasks.This framework effectively harnesses large-scale unlabeled WBMs, sub- stantially reducing the dependency on labeled data. 2. A con"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_8", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 8, "text": "rvised learning, facilitating its application in classification tasks.This framework effectively harnesses large-scale unlabeled WBMs, sub- stantially reducing the dependency on labeled data. 2. A convolutional neural network (CNN) is integrated preceding the ViT encoder in the MAE. This combination markedly enhances the MAE‚Äôs feature extraction capability and significantly elevates the classification accuracy of complex WBMs. 3. The MAE encoder, pre-trained and then fine-tuned with a multi- label classifier using a small subset of labeled WBMs, ensures reliable classification performance for multi-GFA WBMs. 4. The proposed method undergoes experimental validation on a real-world complex WBM dataset provided by Intel, achieving a re- markable 96.7% classification precision on this intricate dataset with minimal labeled data. 5. Comparative analysis of MAE with other contemporary self- supervised learning methods demonstrates its superior performance for WBM data. The remainder of this paper is structured as follows: Section 2 introduces the related work in unsupervised and self-supervised learn- ing. Section 3 delineates the proposed framework and its components in detail. Section "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_9", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 9, "text": "paper is structured as follows: Section 2 introduces the related work in unsupervised and self-supervised learn- ing. Section 3 delineates the proposed framework and its components in detail. Section 4 discusses the experimental results, and finally, Section 5 concludes the paper and outlines directions for future work. 2. Related work Over recent decades, numerous unsupervised learning methods have emerged, leveraging large-scale unlabeled data for feature represen- tation learning ( Ciresan, Meier, Gambardella, & Schmidhuber , 2010 ; Donoho & Grimes , 2003 ; Erhan et al. , 2010 ; Goodfellow, Courville, & Bengio , 2011 ; Olshausen & Field , 1996 ; Ranzato, Boureau, & LeCun , 2007 ; Rifai, Vincent, Muller, Glorot, & Bengio , 2011 ; Roweis , 1997 ; Roweis & Saul , 2000 ; Seide, Li, & Yu , 2011 ; Vincent, Larochelle, Bengio, & Manzagol , 2008 ; Weinberger & Saul , 2004 ). Additionally, semi- supervised learning combines a small subset of labeled data with a vast array of unlabeled data. In the context of WBM classification, Kong and Ni (2020b ) advocated a semi-supervised framework to efficiently utilize unlabeled data. More recently, self-supervised learning, a subset of unsupervise"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_10", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 10, "text": "In the context of WBM classification, Kong and Ni (2020b ) advocated a semi-supervised framework to efficiently utilize unlabeled data. More recently, self-supervised learning, a subset of unsupervised learning, has demonstrated superior performance in learning from extensive unlabeled datasets. These methods typically define a pretext task, use an encoder to learn visual features, and then transfer the learned features to downstream tasks like classifi- cation through fine-tuning with limited labeled data ( Jing & Tian , 2021 ). Current self-supervised approaches for image visual features fall into four categories: generation-based ( Goodfellow et al. , 2014 ; Ledig et al. , 2016 ; Pathak, Krahenbuhl, Donahue, Darrell, & Efros , 2016 ; Zhang, Isola, & Efros , 2016 ; Zhu, Park, Isola, & Efros , 2017 ), context- based ( Caron, Bojanowski, Joulin, & Douze , 2018 ; Doersch, Gupta, & Efros , 2015 ; Jing & Tian , 2018 ; Li et al. , 2016 ; Noroozi & Favaro , 2016 ; Noroozi, Vinjimoor, Favaro, & Pirsiavash , 2018 ), contrastive- based ( Caron et al. , 2020 ; Chen, Xie, & He , 2021 ; Grill, Strub, Altche, Tallec, & Richemond , 2020 ; He, Fan, Wu, Xie, & Girshick , 2020 ; van den Oord, Li, "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_11", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 11, "text": ", & Pirsiavash , 2018 ), contrastive- based ( Caron et al. , 2020 ; Chen, Xie, & He , 2021 ; Grill, Strub, Altche, Tallec, & Richemond , 2020 ; He, Fan, Wu, Xie, & Girshick , 2020 ; van den Oord, Li, & Vinyals , 2018 ; Wu, Xiong, Yu, & Lin , 2018 ), and reconstruction-based (e.g., masked autoencoder) ( He et al. , 2021 ). In the WBM field, several self-supervised learning methods have emerged. Geng, Yang, Zeng, and Yu (2021 ), Kahng and Kim (2021 ), and Wang, Ni and Huang (2023 ) have employed contrastive learning for WBM classification, utilizing unlabeled data to enhance feature Fig. 2. Examples of more complex WBMs with different GFA types. Expert Systems With Applications 249 (2024) 123601 3Y. Wang et al. Fig. 3. The proposed method consisting of two separate steps: a self-supervised learning step and a fine-tuning step. Fig. 4. The diagram of patchMC encoder. representation learning and, subsequently, classification accuracy. De- spite these advancements, current self-supervised learning approaches have notable limitations. Primarily, they do not substantially diminish the need for labeled data. During the fine-tuning phase, a significant amount of labeled data is still requir"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_12", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 12, "text": "earning approaches have notable limitations. Primarily, they do not substantially diminish the need for labeled data. During the fine-tuning phase, a significant amount of labeled data is still required to attain high classification performance. As noted in Dosovitskiy et al. (2021 ) and Vaswani et al. (2017 ), classification performance deteriorates markedly with reduced labeled data, which constrains the practicality of these methods. Addi- tionally, existing strategies primarily address single GFA binary WBMs, limiting their applicability as most real-world WBMs are complex, encompassing multiple bin categories and GFAs. To overcome these challenges, this study introduces a self-supervised learning framework tailored for complex WBMs, requiring only minimal annotations. 3. Proposed method 3.1. Overall framework The proposed framework for complex WBM self-supervised learning and classification is depicted in Fig. 3. It consists of two primary stages: self-supervised learning and fine-tuning. For complex WBMs, the self- supervised learning stage includes a patchMC encoder block and an MAE block. During self-supervision, large-scale unlabeled WBMs are utilized for visual representa"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_13", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 13, "text": "-tuning. For complex WBMs, the self- supervised learning stage includes a patchMC encoder block and an MAE block. During self-supervision, large-scale unlabeled WBMs are utilized for visual representation learning. Initially, the patchMC encoder encodes complex WBMs into feature embeddings, producing embeddings for each patch. Subsequently, the MAE engages in masking and recon- structing blocks to further enhance WBM representations using a ViTencoder. The masking block obscures a portion of the patches, while the ViT encoder transforms the remaining unmasked patches into final embeddings. The ViT decoder then reconstructs the masked patches. Post self-supervised learning, the patchMC and ViT encoder are fine- tuned with a small labeled dataset for classification. The subsequent sections detail each component. 3.2. PatchMC encoder block The patchMC encoder, designed for complex WBMs with multiple bin categories, transforms a two-dimensional matrix representing a chip‚Äôs failure test mode into a series of feature maps. These maps are then converted into randomly masked sequences incorporating one- hot encoding, multi-channel 2DCNN, patch embedding, and position embedding. One-hot enc"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_14", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 14, "text": "e into a series of feature maps. These maps are then converted into randomly masked sequences incorporating one- hot encoding, multi-channel 2DCNN, patch embedding, and position embedding. One-hot encoding and multi-channel 2DCNN are pivotal innovations of this process. The encoder‚Äôs diagram is shown in Fig. 4. In a complex WBM, each matrix element signifies a bin category, a categorical variable without numerical meaning. We employ one-hot encoding to transform each bin category into a vector, converting the WBM into multi-channel 2D data (Eq. (1)): ùëãùëúùëõùëí‚Ñéùëúùë° =ùëÇùëõùëí‚Ñéùëúùë° (ùëã);ùëã‚ààùëÖùêª√óùëä, ùëãùëúùëõùëí‚Ñéùëúùë° ‚ààùëÖùêª√óùëä√óùê∂(1) Here, ùëãrepresents the original WBM of size ùêª√óùëä, and ùëãùëúùëõùëí‚Ñéùëúùë° denotes the transformed multi-channel 2D data, with ùê∂being the total number of bin categories. For multi-channel WBMs, the x- and y-axes indicate spatial dimen- sions, while the ùëß-axis represents the bin dimension. Complex WBMs exhibit distinct spatial features and bin mixtures across different GFAs. Expert Systems With Applications 249 (2024) 123601 4Y. Wang et al. The coupling of spatial and bin features is vital for identifying com- plex WBM GFAs. Therefore, this study uses multi-channel 2DCNN for feature extraction before MAE,"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_15", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 15, "text": "49 (2024) 123601 4Y. Wang et al. The coupling of spatial and bin features is vital for identifying com- plex WBM GFAs. Therefore, this study uses multi-channel 2DCNN for feature extraction before MAE, as its convolution filters can extract these coupled features. The convolution filter‚Äôs x- and y-axes extract spatial features, while the ùëß-axis focuses on bin features. Adding one- hot encoding and multi-channel 2DCNN has significantly enhanced classification performance, as detailed in Section 4.2. For the multi-channel 2D CNN layer, we employ a kernel of size (3,3,31,8) to transform the input data into feature maps (Eq. (2)): ùëãùëìùëíùëéùë°ùë¢ùëüùëí =ùê∂ùëúùëõùë£ (ùëãùëúùëõùëí‚Ñéùëúùë° );ùëãùëìùëíùëéùë°ùë¢ùëüùëí ‚ààùëÖùêª ùëÉ√óùëä ùëÉ√óùëì(2) In this equation, ùëãùëìùëíùëéùë°ùë¢ùëüùëí is the CNN output, ùëÉis the patch size (also the stride), and ùëìis the filter number. Optimal values for ùëÉandùëì were determined to be three and eight, respectively, as shown in the experimental section. Subsequently, these feature maps are converted into a sequence of flattened patches and mapped to embeddings ùê∏ùëùùëé(Eq. (3)), utilizing a network architecture comprising a linear layer of dimensions (8,96): ùê∏ùëùùëé=ùê∏ùëöùëè(ùëãùëìùëíùëéùë°ùë¢ùëüùëí );ùê∏ùëùùëé‚ààùëÖùêª√óùëä ùëÉ2√óùê∑(3) ùê∑in this equation represents the patch embedding "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_16", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 16, "text": "apped to embeddings ùê∏ùëùùëé(Eq. (3)), utilizing a network architecture comprising a linear layer of dimensions (8,96): ùê∏ùëùùëé=ùê∏ùëöùëè(ùëãùëìùëíùëéùë°ùë¢ùëüùëí );ùê∏ùëùùëé‚ààùëÖùêª√óùëä ùëÉ2√óùê∑(3) ùê∑in this equation represents the patch embedding dimension. Each patch encompasses coupled features of bin categories and spatial distributions. For optimal performance, values for ùëÉandùê∑are set to three and 96, respectively, as discussed in the experiment section. Following the approach in Dosovitskiy et al. (2021), a learnable class embedding ùê∏ùëêùëôùëêis appended to the sequence of patch embeddings, and positional embeddings ùê∏ùëùùëúùë†are integrated by addition to the retain spatial information: ùê∏=ùëêùëúùëõùëêùëéùë° (ùê∏ùëùùëé, ùê∏ùëêùëôùëê) +ùê∏ùëùùëúùë†;ùëãùëêùëôùëê‚ààùëÖ1√óùê∑, ùê∏ùëùùëúùë†‚ààùëÖ(ùêª√óùëä ùëÉ2+1)√óùê∑(4) The patch embeddings ùê∏serve as the input for the subsequent MAE block. 3.3. MAE block The MAE comprises the masking block, ViT encoder, and ViT de- coder. In the masking block, one part of the patches is randomly sampled as masked patches, and the remaining patches are unmasked. In this study, similar to He et al. (2021), 75% of the patch embeddings (tokens) are randomly masked, and the remaining 25% are input to the ViT encoder. Namely, the analysis has shown that different masking ratios hav"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_17", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 17, "text": "ilar to He et al. (2021), 75% of the patch embeddings (tokens) are randomly masked, and the remaining 25% are input to the ViT encoder. Namely, the analysis has shown that different masking ratios have little effect on the results. Therefore, the masking ratio is set to the default value of 0.25. The masking formula is as follows: ùê∏ùëöùëéùë†ùëò =ùëöùëéùë†ùëò (ùê∏);ùê∏ùëöùëéùë†ùëò ‚ààùëÖ(ùëüùëéùë°ùëñùëú √ó(ùêª√óùëä ùëÉ2+1))√ó ùê∑(5) Then, the ViT encoder processes only visible, unmasked patches. The backbone of the ViT encoder is multi-head self-attention, and the depth was set to eight; the head number was assigned to three; the multi-layer perceptron dimension was set to 512, whereas the embed- ding dimension was 96. Hyperparameter optimization is described in the experiment part. The encoder maps the visible patches to a latent representation that uses eight multi-headed self-attention (MSA) layers, each containing three heads. More details about these processes can be found in Vaswani et al. (2017), the paper on self-attention. The expression of the basic MSA module is as follows: ùëí‚Ä≤ ùëô=ùëÄùëÜùê¥ (ùêøùëÅ(ùëíùëô‚àí1)) +ùëíùëô‚àí1, ùëô= 1...ùêø (6) ùëíùëô=ùëÄùêøùëÉ (ùêøùëÅ(ùëí‚Ä≤ ùëô)) +ùëí‚Ä≤ ùëô, ùëô= 1...ùêø (7) ùë¶=ùêøùëÅ(ùëí0 ùêø) (8) The MAE decoder is used only in the self-supervised learnin"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_18", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 18, "text": "pression of the basic MSA module is as follows: ùëí‚Ä≤ ùëô=ùëÄùëÜùê¥ (ùêøùëÅ(ùëíùëô‚àí1)) +ùëíùëô‚àí1, ùëô= 1...ùêø (6) ùëíùëô=ùëÄùêøùëÉ (ùêøùëÅ(ùëí‚Ä≤ ùëô)) +ùëí‚Ä≤ ùëô, ùëô= 1...ùêø (7) ùë¶=ùêøùëÅ(ùëí0 ùêø) (8) The MAE decoder is used only in the self-supervised learning step for masked patch reconstruction. The input data of the MAE decoder includes a complete set of tokens consisting of encoded visible patchesand masked tokens (He et al., 2021), and the output data of the decoder is the reconstructed WBMs. The backbone of the ViT decoder is multi- head self-attention. The depth was set to one; the head number was assigned to eight; the multi-layer perceptron dimension was set to 64, whereas the embedding dimension was 256. In this study, The decoder reconstructs the input complex WBM by predicting the bin categories for each masked die. The bin categories differ from image pixels in the original MAE because the bin category is a categorical variable. The reconstruction of each bin is analogous to a die-level classification. Therefore, the decoder‚Äôs architecture and reconstruction target is changed. After the ViT of the decoder, a linear projection layer is added to the last layer to map the decoder‚Äôs output embedding to aùê∂-dimension embedding, wher"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_19", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 19, "text": "hitecture and reconstruction target is changed. After the ViT of the decoder, a linear projection layer is added to the last layer to map the decoder‚Äôs output embedding to aùê∂-dimension embedding, where ùê∂equals the total number of bin categories. Then, a softmax layer is added to the end of the linear projection layer to obtain the predicted bin category of each die. The softmax activation function is defined as follows: ùëùùëê(ùë•) = exp( ùëéùëê(ùë•))‚àï(ùê∂‚àë ùëê‚Ä≤exp(ùëéùëê‚Ä≤(ùë•))) (9) where ùëéùëê(ùë•)denotes the activation function in the bin dimension ùëê at the die position ùë•, where ùë•‚ààùëãùëúùë¢ùë°ùëùùë¢ùë°;ùëùùëê(ùë•)is the approximated maximum-function. The baseline MAE method is used for images with RGB pixels, and the reconstruction process is based on pixel-level prediction. Since an RGB is a continuous numerical value, the mean square error (MSE) function is selected as the loss function (He et al., 2021). In this study, the element is the bin category of each die. Thus, we proposed to use a die-level cross-entropy loss to compute the cross-entropy between the reconstructed and original WBMs in the die-level on masked dice instead of the mean square error (MSE) loss in the baseline MAE. The loss function is given by: ùêøùëúùë†ùë†ùëëùëñ"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_20", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 20, "text": "ute the cross-entropy between the reconstructed and original WBMs in the die-level on masked dice instead of the mean square error (MSE) loss in the baseline MAE. The loss function is given by: ùêøùëúùë†ùë†ùëëùëñùëí_ùê∂ùê∏=ùëÅ‚àë ùë•=1ùê∂‚àë ùëñ=1ùúî(ùë•)(ùëñ) logùëù(ùë•)(ùëñ) (10) where ùúî(ùë•)is the one-hot encoding of the true bin category of the ùë•th die and ùëù(ùë•)(ùëñ)denotes the ùëñth bin prediction probability of the ùë•th die. ùëÅequals the total number of die on a wafer bin map and ùê∂equals the total number of bin category. 3.4. Multi-label fine-tuning block A multi-GFA WBM has multiple GFA types, as shown in Fig. 3(b). Typically, after the self-supervised pre-training phase, a dataset labeled for a single class per instance is employed for the downstream classi- fication task. The loss function used in this scenario is cross-entropy, and the activation function in the final layer is softmax, referred to as the ‚Äò‚Äòsingle-label fine-tuning‚Äô‚Äô method in this study. However, employ- ing single-label fine-tuning for multi-GFA WBMs might significantly affect the classification performance, leading to a decrease in overall accuracy. To address the multi-GFA classification problem, this study applies a multi-label fine-tuning method. The"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_21", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 21, "text": "ignificantly affect the classification performance, leading to a decrease in overall accuracy. To address the multi-GFA classification problem, this study applies a multi-label fine-tuning method. The multi-label classifier consists of a patchMC encoder, a ViT encoder, and a classification head with a linear layer and an activation function. The patchMC and ViT encoders‚Äô initialization weights are transferred from the MAE self-supervised pre-training, while the classification head‚Äôs weights are randomly initialized. The ViT decoder of MAE is not utilized during the fine-tuning period. The multi-label fine-tuning differs from single-label fine-tuning in three ways. First, the ground truth is a multi-hot vector, compared to the one-hot vector in single-label fine-tuning. In a multi-hot vector, ones indicate existing GFA types, while zeros represent non-existent ones. Second, the activation function is sigmoid instead of softmax, mapping each value in an ùëõ-dimensional vector to the range of (0,1), allowing for independent values unlike softmax. This function enables Expert Systems With Applications 249 (2024) 123601 5Y. Wang et al. the simultaneous assessment of multiple classes‚Äô exis"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_22", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 22, "text": "of (0,1), allowing for independent values unlike softmax. This function enables Expert Systems With Applications 249 (2024) 123601 5Y. Wang et al. the simultaneous assessment of multiple classes‚Äô existence. The sigmoid function is defined as (Eq. (11)): ùëùùëõ(ùë•) =1 1 + exp(‚àí ùëéùëõ(ùë•))(11) Here, ùëéùëõ(ùë•)is the activation in the class dimension ùëõ, and ùëùùëõ(ùë•)is the predicted probability vector. After applying the sigmoid function, each predicted value represents the likelihood of a particular GFA type‚Äôs existence. To determine if a GFA exists, each predicted value is compared with a threshold. If the value exceeds 0.5, the predicted label for that GFA is set to one, indicating its presence: ùêøùëõ(ùë•) ={1, ùëùùëõ(ùë•)‚â•0.5 0, ùëùùëõ(ùë•)<0.5(12) Third, the loss function employs binary cross-entropy (BCE) instead of cross-entropy, adding a penalty for non- 1predictions and maxi- mizing the value at the ‚Äò‚Äò 1‚Äô‚Äô position while minimizing others. BCE is suitable for binary targets (0 or 1) and is defined as (Eq. (13)): ùêøùëúùë†ùë†ùêµùê∂ùê∏ = ‚àí1 ùëõùëõ‚àë ùë•=1(ùë§(ùë•) log(ùëù(ùë•)) + (1 ‚àí ùë§(ùë•)) log(1 ‚àí ùëù(ùë•))) (13) Here, ùëõis the total number of classes, ùë§(ùë•)is the true label of ùë•th class (0 or 1) and ùëù(ùë•)is the predicted probability that belong "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_23", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 23, "text": "ùëúùë†ùë†ùêµùê∂ùê∏ = ‚àí1 ùëõùëõ‚àë ùë•=1(ùë§(ùë•) log(ùëù(ùë•)) + (1 ‚àí ùë§(ùë•)) log(1 ‚àí ùëù(ùë•))) (13) Here, ùëõis the total number of classes, ùë§(ùë•)is the true label of ùë•th class (0 or 1) and ùëù(ùë•)is the predicted probability that belong to class ùë•. In the inference phase, the multi-label classifier maps each input WBM to an ùëõ-dimensional predicted vector. The patchMC and MAE encoders transform a WBM into a feature embedding, and the classifier outputs the predicted vector. Each value is compared with a preset threshold to determine the classification results. 4. Experimental results 4.1. Data and experimental setup In the experiments, we utilized a real-world complex WBM dataset collected by Intel to verify the performance of the proposed framework and conduct an ablation study on the patchMC encoder and multi-label fine-tuning. The complex WBM dataset comprises 180,000 unlabeled WBMs for self-supervised learning and 2070 labeled WBMs spanning 12 GFA types for the fine-tuning period. For IP protection, this paper does not disclose the categories and examples of the 12 GFAs in the dataset. Many WBMs in the dataset feature multiple GFA types labeled by experienced engineers. The 2070 labeled dataset represented a mix of"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_24", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 24, "text": " disclose the categories and examples of the 12 GFAs in the dataset. Many WBMs in the dataset feature multiple GFA types labeled by experienced engineers. The 2070 labeled dataset represented a mix of multi- and single-label WBMs. To assess the classification performance with small-scale labeled data for fine-tuning, we randomly sampled 240 labeled data (20 to 40 for each GFA) from all labeled datasets as training data for the fine-tuning period, with the remaining labeled data serving as test data. The total number of labels for each GFA is 31, 27, 28, 29, 22, 41, 31, 24, 25, 20, 20, 20, respectively. We acknowledge that 20 to 40 labels are a manageable amount for manual labeling by engineers in practice. Additionally, we sampled two few-shot trainsets to evaluate the few-shot classification performance of the proposed method, with details presented later. A complex WBM is a 39 √ó26 2D matrix. We resized the original complex WBM to 39 √ó39 square matrices, and the total number of bin categories is 31. Thus, after one- hot encoding, a complex WBM transformed into multi-channel 2D data with the size of 39 √ó39√ó31, with each channel indicating one bin category. The patch size was set to"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_25", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 25, "text": "tegories is 31. Thus, after one- hot encoding, a complex WBM transformed into multi-channel 2D data with the size of 39 √ó39√ó31, with each channel indicating one bin category. The patch size was set to three, corresponding to 3 √ó3 dies. The hyperparameters of the patchMC and ViT encoders are utilized in both self-supervised learning and fine-tuning periods. Thus, we opti- mized them by comparing classification performance after fine-tuning with varying hyperparameters. For the patchMC encoder, we compared different CNN depths and widths following Wang, Ni (2023). The results indicate that two convolution layers with 8 and 16 filters and a 3√ó3 filter size lead to better classification performance. For the ViTencoder, we compared classification performance with various multi- layer perceptron dimensions, embedding dimensions, head numbers, and the number of multi-head self-attention layers. The results suggest optimal performance with ùëöùëôùëù= 512 ,ùëëùëñùëö= 96,‚Ñéùëíùëéùëë = 3, and ùëëùëíùëùùë°‚Ñé = 8. In the self-supervised pre-training process, the batch size was 2048; the optimizer was Adam, and the learning rate was 3e ‚àí4. The pa- rameter selection was based on experimental results, optimizing the model‚Äôs "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_26", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 26, "text": "-supervised pre-training process, the batch size was 2048; the optimizer was Adam, and the learning rate was 3e ‚àí4. The pa- rameter selection was based on experimental results, optimizing the model‚Äôs classification performance. The self-supervised method was implemented using Python 3.8.2 and Pytorch 1.9.0 on four Nvidia V100 GPUs with 16 GB memory each. The patchMC and ViT encoders were initialized for the fine-tuning period with weights learned during self-supervised pre-training. The classification block parameters were randomly initialized. The output vector‚Äôs dimension equals 12, the total number of GFA types. In the fine-tuning process, the batch size was 64, the optimizer was Adam, and the learning rate was 3e ‚àí4. The classification precision, recall, and F1-score were selected as evaluation indices and calculated af- ter fine-tuning to assess both self-supervised learning and fine-tuning performance. The definitions of precision, recall, and F1-score are as follows: ùëÉ ùëüùëíùëêùëñùë†ùëñùëúùëõ =ùëá ùëÉ ùëá ùëÉ+ùêπùëÉ(14) Reùëêùëéùëôùëô=ùëá ùëÉ ùëá ùëÉ+ùêπùëÅ(15) ùêπ1 ‚àíùë†ùëêùëúùëüùëí =2 ‚àó Pr ùëíùëêùëñùë†ùëñùëúùëõ ‚àó Reùëêùëéùëôùëô Prùëíùëêùëñùë†ùëñùëúùëõ + Reùëêùëéùëôùëô(16) In these equations, ùëá ùëÉdenotes the number of positive samples correctly identified; ùêπùëÉis the number of n"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_27", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 27, "text": "=ùëá ùëÉ ùëá ùëÉ+ùêπùëÉ(14) Reùëêùëéùëôùëô=ùëá ùëÉ ùëá ùëÉ+ùêπùëÅ(15) ùêπ1 ‚àíùë†ùëêùëúùëüùëí =2 ‚àó Pr ùëíùëêùëñùë†ùëñùëúùëõ ‚àó Reùëêùëéùëôùëô Prùëíùëêùëñùë†ùëñùëúùëõ + Reùëêùëéùëôùëô(16) In these equations, ùëá ùëÉdenotes the number of positive samples correctly identified; ùêπùëÉis the number of negative samples incorrectly labeled as positive; ùêπùëÅis the number of positive samples incorrectly labeled as negative. To confirm the advantages of MAE over existing WBM self- supervised learning methods, we compared MAE with two repre- sentative existing works. For a fair comparison, we used the same WM-811K dataset as the existing methods. WM-811K contains only single-label binary WBMs. Examples of nine GFA types in WM-811K are illustrated in Fig. 5. Further experiment details are provided in Section 4.5. Furthermore, mixedWM38 is a publicly available binary WBM dataset characterized by mixed-type defect patterns. To evaluate the classification performance of our proposed method on binary WBMs with multi-label capabilities, we conducted additional experiments on this dataset. The specific details of these experiments are elaborated in Section 4.6. 4.2. Ablation study for patchMC encoder on complex WBM To assess the effectiveness of the proposed patchMC encoder for complex WBMs, we com"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_28", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 28, "text": " details of these experiments are elaborated in Section 4.6. 4.2. Ablation study for patchMC encoder on complex WBM To assess the effectiveness of the proposed patchMC encoder for complex WBMs, we compared two self-supervised learning scenarios: MAE with the patchMC encoder and MAE without it. Initially, the unlabeled complex WBM dataset was used for self-supervised learning. Subsequently, the labeled training set was employed for multi-label fine-tuning, and the test set was utilized to calculate classification precision, reflecting the performance of self-supervised learning. When MAE is without the patchMC encoder, a complex WBM is transformed into a three-channel, 64 √ó64 pixel RGB image, and the complex WBMs are input directly into the ViT encoder of MAE without one-hot encoding and multi-channel 2DCNN. The overall classification precision of the test set for the two cases are 0.956 and 0.558, respectively. These results demonstrate that the patchMC encoder significantly enhances self-supervised learning per- formance for complex WBMs, thereby improving MAE‚Äôs representation capability. This improvement is primarily due to one-hot encoding, which effectively expresses bin inform"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_29", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 29, "text": "elf-supervised learning per- formance for complex WBMs, thereby improving MAE‚Äôs representation capability. This improvement is primarily due to one-hot encoding, which effectively expresses bin information by transforming each bin category into a vector, and the multi-channel 2DCNN, which extracts bin and spatial dimension coupling features using convolution filters. Expert Systems With Applications 249 (2024) 123601 6Y. Wang et al. Fig. 5. Examples of nine GFA types in WM-811K. Fig. 6. Visualization of 12 GFA types representation with and without patchMC encoder using t-SNE. Such feature extraction is crucial for complex WBM as it consists of multiple bin categories with core information residing in the coupling of bin and spatial features. Without the patchMC encoder, classification accuracy drops considerably as categorical bins are treated as numer- ical RGB values, and the coupling features between bin and spatial dimensions cannot be effectively extracted. To elucidate the differences between MAE with and without the patchMC encoder for each GFA type, post fine-tuning, the embedding distribution of the 12 GFA types after the ViT encoder of MAE is visualized using t-SNE, a tec"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_30", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 30, "text": "ences between MAE with and without the patchMC encoder for each GFA type, post fine-tuning, the embedding distribution of the 12 GFA types after the ViT encoder of MAE is visualized using t-SNE, a technique for dimensionality reduction ( vander Maaten & Hinton , 2008 ). As depicted in Fig. 6, with the patchMC encoder, the 12 GFA types are well-separated, enabling precise clas- sification. Without the patchMC encoder, there is confusion between classes 5 and 10, with many samples incorrectly classified as classes 7 and 9. These results confirm that the patchMC encoder enhances MAE‚Äôs feature representation ability for GFAs that are challenging to distinguish. Furthermore, to evaluate the impact of one-hot encoding within the patchMC encoder, we compared performance between patchMC embedding on raw bin values (without one-hot) and one-hot encoding vectors (with one-hot). The macro F1-scores for these methods are 0.929 and 0.974, respectively, indicating a 4.5 percent improvement with one-hot encoding. Notably, for GFA4 and GFA7, the F1 scores improved by 11.7 percent and 15.4 percent, respectively. 4.3. Comparison with existing methods on complex WBMs To verify the advantages of the p"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_31", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 31, "text": "hot encoding. Notably, for GFA4 and GFA7, the F1 scores improved by 11.7 percent and 15.4 percent, respectively. 4.3. Comparison with existing methods on complex WBMs To verify the advantages of the proposed method over other existing self-supervised learning approaches for complex WBM datasets, we compared it with several established self-supervised algorithms and CNN-based supervised methods, respectively. For comparing with existing self-supervised methods on complex WBMs, we selected two highly representative and well-known methods for comparison: momentum contrastive learning (MoCo) ( He et al. , 2020 ) and BYOL ( Grill et al. , 2020 ), both utilizing the CNN baseline model. For MoCo and BYOL, random rotation was applied during the data augmentation period. In the fine-tuning period, all comparison methods employed the multi-label classification strategy introduced in Section 3.4. The same with the proposed method, 180,000 unlabeled WBMs were used for MoCo and BYOL pre-training, and the labeled training and test sets were used for the fine-tuning period. The comparison results with existing methods are shown in Ta- ble 1. The results indicate that our proposed MAE-based self-s"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_32", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 32, "text": "nd the labeled training and test sets were used for the fine-tuning period. The comparison results with existing methods are shown in Ta- ble 1. The results indicate that our proposed MAE-based self-supervised method surpasses the performance of these established self-supervised learning approaches, further substantiating the efficacy and potential of our methodology. For comparison with CNN-based supervised methods, a previously proposed CNN-based classification method for complex WBMs ( Wang, Ni, 2023 ) consists of two 3 √ó3 convolution layers with eight and 16 filters, respectively, with stride and padding set to one. Additionally, two 2 √ó2 max-pooling layers follow the convolution layers. We first compared the proposed method with this CNN baseline. Furthermore, given that a robust data augmentation strategy can significantly en- hance classification performance, especially for limited and complex real-world labeled WBM datasets, we also implemented CNN with data augmentation for comparison. We adopted four standard data augmen- tation techniques for WBMs: rotation, flip, crop, and denoising. For the augmented CNN scenario, the labeled training dataset containing 240 samples was"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_33", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 33, "text": "mparison. We adopted four standard data augmen- tation techniques for WBMs: rotation, flip, crop, and denoising. For the augmented CNN scenario, the labeled training dataset containing 240 samples was expanded to 1680 labeled samples, and the CNN model was trained on this augmented dataset. Meanwhile, the non-augmented CNN model was trained using only the initial 240 labeled samples. During the testing phase, the same test set was employed to assess the multi-label classification performance of both CNN models. The comparison results with CNN baselines are presented in Table 2, demonstrating that data augmentation indeed enhances CNN classifi- cation performance. Moreover, the results confirm that our proposed method outperforms the CNN-based supervised learning approach in terms of classification effectiveness. 4.4. Few-shot classification performance evaluation for complex WBMs To evaluate the proposed method‚Äôs classification performance in few-shot scenarios, we randomly sampled 5 and 3 labeled data for each GFA from the labeled complex WBM dataset as training data for the fine-tuning period. The remaining labeled data from the complex WBM dataset were used as test data. Followi"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_34", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 34, "text": "nd 3 labeled data for each GFA from the labeled complex WBM dataset as training data for the fine-tuning period. The remaining labeled data from the complex WBM dataset were used as test data. Following self-supervised learning using Expert Systems With Applications 249 (2024) 123601 7Y. Wang et al. Table 1 The GFA-level classification performance comparison with existing methods on complex WBM dataset. GFA types MoCo (He et al., 2020) BYOL (Grill et al., 2020) Ours Precision Recall F1-score Precision Recall F1-score Precision Recall F1-score 1 0.852 0.795 0.823 0.880 0.943 0.910 0.995 0.991 0.993 2 1.000 0.979 0.989 0.974 0.966 0.970 1.000 1.000 1.000 3 0.989 0.895 0.940 0.939 0.840 0.887 1.000 0.950 0.974 4 0.789 0.808 0.798 0.726 0.784 0.754 0.845 0.960 0.899 5 0.990 0.975 0.983 0.995 1.000 0.998 1.000 1.000 1.000 6 0.807 0.880 0.842 0.921 0.930 0.925 1.000 0.970 0.985 7 0.920 0.752 0.828 0.815 0.626 0.708 0.979 0.825 0.845 8 0.982 1.000 0.991 0.991 0.986 0.989 1.000 1.000 1.000 9 0.942 0.942 0.942 0.972 0.904 0.937 1.000 0.995 0.997 10 0.969 0.959 0.964 0.965 1.000 0.982 0.990 0.995 0.997 11 1.000 0.953 0.976 0.981 0.972 0.977 0.991 1.000 0.995 12 0.994 0.989 0.992 0.968 0.995 "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_35", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 35, "text": ".942 0.942 0.942 0.972 0.904 0.937 1.000 0.995 0.997 10 0.969 0.959 0.964 0.965 1.000 0.982 0.990 0.995 0.997 11 1.000 0.953 0.976 0.981 0.972 0.977 0.991 1.000 0.995 12 0.994 0.989 0.992 0.968 0.995 0.981 1.000 1.000 1.000 Macro 0.936 0.911 0.922 0.927 0.912 0.918 0.983 0.974 0.974 Table 2 The GFA-level classification performance comparison with CNN baselines on complex WBM dataset. GFA types CNN (Wang, Ni, 2023) CNN_aug Ours Precision Recall F1-score Precision Recall F1-score Precision Recall F1-score 1 0.861 0.886 0.873 0.985 0.938 0.961 0.995 0.991 0.993 2 0.910 0.983 0.945 0.908 0.996 0.950 1.000 1.000 1.000 3 0.943 0.920 0.932 0.965 0.960 0.962 1.000 0.950 0.974 4 0.690 0.640 0.664 0.614 0.904 0.731 0.845 0.960 0.899 5 0.980 0.975 0.978 0.985 0.984 0.983 1.000 1.000 1.000 6 0.839 0.940 0.887 0.979 0.950 0.964 1.000 0.970 0.985 7 0.955 0.256 0.404 0.976 0.167 0.285 0.979 0.825 0.845 8 0.896 0.977 0.935 0.969 0.982 0.975 1.000 1.000 1.000 9 0.945 0.915 0.930 0.963 0.963 0.963 1.000 0.995 0.997 10 0.889 0.907 0.898 0.963 0.938 0.950 0.990 0.995 0.997 11 0.693 0.888 0.779 0.980 0.935 0.957 0.991 1.000 0.995 12 0.956 0.962 0.959 0.952 0.989 0.970 1.000 1.000 1.000 Macro 0.880 0.85"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_36", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 36, "text": " 0.995 0.997 10 0.889 0.907 0.898 0.963 0.938 0.950 0.990 0.995 0.997 11 0.693 0.888 0.779 0.980 0.935 0.957 0.991 1.000 0.995 12 0.956 0.962 0.959 0.952 0.989 0.970 1.000 1.000 1.000 Macro 0.880 0.854 0.849 0.937 0.892 0.888 0.983 0.974 0.974 Table 3 The 5-shot classification performance for complex WBM (%). GFA type F1-score GFA type F1-score 1 97.6 7 79.0 2 97.6 8 100 3 96.1 9 99.5 4 84.7 10 98.7 5 98.3 11 96.1 6 96.4 12 99.7 an unlabeled complex WBM dataset, 5-shot and 3-shot classifications were conducted. The GFA-level classification accuracy test results are presented in Tables 3 and 4. The results show that both 3-shot and 5-shot classification perfor- mances are above 91%, based on MAE‚Äôs self-supervised pre-training. The F1-scores for 3-shot and 5-shot are close, indicating that the complex WBM classifier, fine-tuned with only three labeled data for each GFA, can achieve over 90% classification accuracy. This finding demonstrates that our proposed self-supervised method can effectively utilize unlabeled data to learn a precise representation of complex WBM and significantly reduce the demand for labeled data to a few- shot level without additional design. The performance f"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_37", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 37, "text": "fectively utilize unlabeled data to learn a precise representation of complex WBM and significantly reduce the demand for labeled data to a few- shot level without additional design. The performance for GFA4 and GFA7 is relatively lower, likely because these GFAs often co-occur in a WBM, making multi-GFA classification more challenging due to mutual interference. 4.5. Comparison with existing methods on single-label binary WBM dataset TSM‚Äô21 (Kahng & Kim, 2021) and ICCAD‚Äô21 (Geng et al., 2021) are two notable works published in recent years that focus on self- supervised learning methods for WBM classification. Consequently, we selected these works for comparison with our MAE to evaluate theTable 4 The 3-shot classification performance for complex WBM (%). GFA type F1-score GFA type F1-score 1 97.9 7 79.4 2 97.2 8 100 3 97.2 9 99.7 4 86.5 10 98.7 5 99.0 11 90.3 6 98.0 12 98.9 performance of self-supervised learning. Both works utilize the WM- 811K dataset, which contains only single-label binary WBMs. To ensure a fair comparison, we also used the same labeled and unlabeled data in our method. For the WM-811K dataset, we employed MAE for binary WBM self-supervised learning, omitting"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_38", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 38, "text": "bel binary WBMs. To ensure a fair comparison, we also used the same labeled and unlabeled data in our method. For the WM-811K dataset, we employed MAE for binary WBM self-supervised learning, omitting the patchMC encoder. For each comparison method, the unlabeled data in WM-811K were first used for self-supervised pre-training. Then, the classifier was fine-tuned with labeled data, and test data were used to calculate classification perfor- mance, evaluating the self-supervised learning method‚Äôs effectiveness. A detailed description of the comparison methods and results are presented in the following. The first comparison method is TSM‚Äô21 (Kahng & Kim, 2021), where self-supervision is achieved by minimizing a contrastive loss function that encourages features extracted from the original, non-augmented WBM, and its augmented counterparts to cluster together. A memory bank is utilized to mitigate the computational burden of negative sam- pling in the context of noise contrastive estimation (NCE). Following the work in Kahng and Kim (2021), the entire labeled data were split into training, validation, and test sets in a 0.8:0.1:0.1 ratio. The amount of labeled training data varied fro"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_39", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 39, "text": "on (NCE). Following the work in Kahng and Kim (2021), the entire labeled data were split into training, validation, and test sets in a 0.8:0.1:0.1 ratio. The amount of labeled training data varied from a minimum of 1383 samples (1% of the total training data) to a maximum of 138,360 samples (100%). These data are used to investigate how the proposed method scales at Expert Systems With Applications 249 (2024) 123601 8Y. Wang et al. Table 5 Classification accuracy comparison of TSM‚Äô21 and our proposed method for self-supervison. Methods Labeled data 1% 5% 10% 25% 50% All Supervised TSM‚Äô21 ( Kahng & Kim , 2021 ) 0.554 0.681 0.711 0.782 0.846 0.897 Self-supervised TSM‚Äô21 ( Kahng & Kim , 2021 ) 0.741 0.815 0.839 0.864 0.880 0.897 Supervised ours 0.508 0.789 0.804 0.819 0.838 0.878 Self-supervised ours 0.813 0.865 0.874 0.886 0.905 0.924 Fig. 7. The classification accuracy comparison after TSM‚Äô21 and the proposed method. different amounts of labeled data. The results are also compared with the supervised baselines of TSM‚Äô21 and our proposed method. The classification results of TSM‚Äô21, the proposed method, and the corresponding supervised baseline are shown in Table 5. The re- sults ind"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_40", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 40, "text": "the supervised baselines of TSM‚Äô21 and our proposed method. The classification results of TSM‚Äô21, the proposed method, and the corresponding supervised baseline are shown in Table 5. The re- sults indicate that the proposed method macro-averagely outperformed TSM‚Äô21 with a 7.2% improvement at 1% labeled data, 5.0% improve- ment at 5% labeled data, 3.5% improvement at 10% labeled data, 2.2% improvement at 25% labeled data, 2.5% improvement at 50% labeled data, and 2.7% improvement in macro F1-score at all labeled data. Thus, performance improved significantly for different labeled data scales consistently. This advantage is even more apparent with fewer labeled data samples. Additionally, the number of fine-tuning epochs for TSM‚Äô21 was 100, while that for the proposed method was only 30. This indicates that the proposed classification model could converge quickly and effectively reduce calculation time. The results of the four comparison methods at different labeled data scales are presented in Fig. 7, illustrating that MAE pre-training can learn a good representation for WBM and reduce the command for labeled data. The second comparison method is ICCAD‚Äô21 ( Geng et al. , 2021 ), wh"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_41", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 41, "text": "ented in Fig. 7, illustrating that MAE pre-training can learn a good representation for WBM and reduce the command for labeled data. The second comparison method is ICCAD‚Äô21 ( Geng et al. , 2021 ), which employs an end-to-end wafer defect classifier combining few- shot learning and self-supervised learning algorithms. ICCAD‚Äô21 ad- dresses two primary tasks: one focuses on prototypical network-based few-shot classification to mitigate the wafer data imbalance issue, and the other leverages contrastive learning-based self-supervised learning on unlabeled WBMs. Following the approach in Geng et al. (2021 ), 50,000 unlabeled data from WM-811K were randomly selected for un- supervised pre-training. The labeled dataset was divided into training and test sets with a 0.6:0.4 ratio. Precision, recall, and F1-score were calculated for each GFA to quantitatively assess the WBM classification performance. To evaluate the performance on the imbalanced dataset, the macro-average was used to calculate the average evaluating index of all GFA types. The comparison results of ICCAD‚Äô21 on the WM-811K dataset are presented in Table 6. These results aim to highlight theTable 6 Classification performanc"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_42", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 42, "text": "e the average evaluating index of all GFA types. The comparison results of ICCAD‚Äô21 on the WM-811K dataset are presented in Table 6. These results aim to highlight theTable 6 Classification performance comparison of the proposed method with ICCAD‚Äô 21 for self-supervison. GFA types ICCAD‚Äô21 ( Geng et al. , 2021 ) Ours Precision Recall F1-score Precision Recall F1-score Center 0.736 0.950 0.830 0.911 0.991 0.984 Donut 0.806 0.842 0.824 0.909 0.788 0.844 Edge-Loc 0.647 0.802 0.716 0.971 0.981 0.976 Edge-Ring 0.992 0.921 0.955 1.000 0.999 0.999 Location 0.605 0.720 0.658 0.919 0.938 0.928 Near-Full 0.810 0.867 0.840 0.947 0.900 0.923 Random 0.816 0.652 0.724 0.988 0.893 0.938 Scratch 0.474 0.701 0.565 0.671 0.593 0.629 None 0.986 0.967 0.977 1.000 1.000 1.000 Macro 0.764 0.825 0.788 0.931 0.898 0.914 efficacy of the proposed method in handling imbalanced datasets and its superiority in self-supervised learning for WBM classification. The evaluation metrics, including precision, recall, and F1-score along with their corresponding macro-averaged values, were calcu- lated for the three methods. The results reveal that the proposed method surpasses ICCAD‚Äô21, demonstrating significant impro"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_43", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 43, "text": " F1-score along with their corresponding macro-averaged values, were calcu- lated for the three methods. The results reveal that the proposed method surpasses ICCAD‚Äô21, demonstrating significant improvements in the macro-averaged precision, recall, and F1-score by 16.7%, 7.3%, and 12.6% respectively. Although ICCAD‚Äô21 adopted a combination of few-shot learning and self-supervised learning to address the issue of imbalanced training datasets, our proposed self-supervised method‚Äôs classification performance still substantially outperforms it. Further- more, our method is characterized by its simplicity, speed, and ef- ficiency, distinguishing it from other published WBM self-supervised learning methods. This makes it not only effective but also practical for real-world application scenarios where rapid and reliable classification is essential. Moreover, we compared MAE with two of the well-known and effec- tive self-supervised learning methods, momentum contrastive learning Expert Systems With Applications 249 (2024) 123601 9Y. Wang et al. Table 7 Classification performance comparison of two well-known self-supervised learning methods. Amount of labeled data MAE (He et al., 2021) MoC"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_44", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 44, "text": "s With Applications 249 (2024) 123601 9Y. Wang et al. Table 7 Classification performance comparison of two well-known self-supervised learning methods. Amount of labeled data MAE (He et al., 2021) MoCo (He et al., 2020) BYOL (Grill et al., 2020) 20 each class (0.1%) 0.733 0.725 0.718 30 each class (0.15%) 0.764 0.738 0.744 50 each class (0.25%) 0.803 0.772 0.771 100 each class (0.5%) 0.820 0.794 0.814 200 each class (1%) 0.880 0.826 0.857 All (100%) 0.917 0.910 0.907 (MoCo) (He et al., 2020; Wang, Ni, Huang, 2023) and BYOL (Grill et al., 2020). Referring to Wang, Ni, Huang (2023), the baseline of the comparison methods is a 2D convolution neural network (CNN) consisting of two 5 √ó5 convolution layers with filter numbers of eight and 16, respectively. Two 2 √ó2 max-pooling layers are added after the convolution layers. Random rotation is applied in the data aug- mentation period. 50,000 unlabeled data of WM-811K were randomly sampled and used for self-supervised pre-training. The labeled data were randomly split into the training and test sets according to the ratio of 0.8:0.2. Several small-scale balanced labeled datasets for eight GFA types, except the ‚Äò‚Äònone‚Äô‚Äô type, were randomly "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_45", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 45, "text": " data were randomly split into the training and test sets according to the ratio of 0.8:0.2. Several small-scale balanced labeled datasets for eight GFA types, except the ‚Äò‚Äònone‚Äô‚Äô type, were randomly sampled from the training set for fine-tuning. The number of training data was increased from 20 for each GFA type (0.1% of the total training set) to all of the training set (100%) of WM-811K. The comparison results are presented in Table 7. The findings reveal that employing MAE for WBM self-supervised learning and fine- tuning with just 1% of all labeled data leads to over 80% classification accuracy, outperforming other self-supervised methods. Notably, the performance at 1% of all labeled training data reaches 88%, closely approaching the 91% obtained with the entire labeled dataset. Further- more, the classification accuracy exceeds 73% with only 0.1% of all labeled training data. This underlines that MAE pre-training can learn an exceptional visual representation, significantly alleviating the need for labeled data. 4.6. Performance evaluation on multi-label binary WBM dataset MixedWM38 is a publicly available binary WBM dataset charac- terized by mixed-type defect patterns. To "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_46", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 46, "text": "viating the need for labeled data. 4.6. Performance evaluation on multi-label binary WBM dataset MixedWM38 is a publicly available binary WBM dataset charac- terized by mixed-type defect patterns. To evaluate the classification performance of our proposed method on binary WBMs with such complex defect patterns, we conducted experiments on this dataset. Originally published by Wang, Xu, et al. (2020), MixedWM38 in- cludes one fault-free pattern, eight single defect patterns, thirteen 2 mixed-type patterns, twelve 3 mixed-type defect patterns, and four 4 mixed-type defects, totaling 38,015 WBMs. For WBMs with a sin- gle defect pattern, the ground truth is represented by 8-dimensional one-hot vectors. In contrast, for WBMs with multiple defect patterns, 8-dimensional multi-hot vectors are used, where ones indicate the presence of specific defect patterns, and zeros denote their absence. The dataset consists of WBMs of 52 √ó52 dimensions, which we resized to 64 √ó64 for our method. In the pre-training phase, all 38,015 data were utilized. As MixedWM38 contains binary WBMs, we trained the MAE directly without the patchMC encoder. After pre-training, we applied the multi-label fine-tuning "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_47", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 47, "text": "e-training phase, all 38,015 data were utilized. As MixedWM38 contains binary WBMs, we trained the MAE directly without the patchMC encoder. After pre-training, we applied the multi-label fine-tuning method based on the pre-trained ViT encoder for classification. The data were randomly split into an 8:2 ratio for training and testing. Table 8 presents the classification performance. Similar to Table 1, we provided the defect-level classification precision, recall, and F1- score for the eight defect patterns, illustrating the classification perfor- mance of each defect pattern within the WBMs containing them. The results show that our proposed MAE pre-training and multi-label fine- tuning method can effectively classify binary WBMs with mixed-type defects, achieving a macro precision of 0.973, a macro recall of 0.972, and a macro F1-score of 0.972. These findings demonstrate the efficacy of our method in handling binary WBMs with mixed-type defects.Table 8 Classification performance evaluation of the proposed method on MixedWM38 dataset. Defect pattern Precision Recall F1-score Center 0.983 0.994 0.988 Donut 1.000 0.993 0.997 Edge-Loc 0.944 0.959 0.952 Edge-Ring 0.971 0.966 0.969 Lo"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_48", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 48, "text": "luation of the proposed method on MixedWM38 dataset. Defect pattern Precision Recall F1-score Center 0.983 0.994 0.988 Donut 1.000 0.993 0.997 Edge-Loc 0.944 0.959 0.952 Edge-Ring 0.971 0.966 0.969 Location 0.980 0.963 0.971 Near-Full 0.963 0.963 0.963 Scratch 0.954 0.942 0.947 Random 0.988 0.994 0.991 Macro 0.973 0.972 0.972 4.7. Discussion From the experiment results for complex WBMs, employing large- scale unlabeled data for self-supervised learning with an enhanced MAE and a patchMC encoder, a multi-label classifier fine-tuned with a small set of labeled data achieves a 96.7% classification precision. Further- more, when comparing MAE with established self-supervised learning methods and CNN-based supervised baselines, our results support that MAE outperforms these comparative methods for complex WBM data. The few-shot classification results reveal that both 3-shot and 5- shot classification accuracies exceed 90%, indicating that as few as 3 or 5 labeled data for each GFA type are sufficient to fine-tune an effective classifier. This finding demonstrates that the proposed method can effectively learn from large-scale unlabeled WBMs, significantly reducing the reliance on labele"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_49", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 49, "text": "sufficient to fine-tune an effective classifier. This finding demonstrates that the proposed method can effectively learn from large-scale unlabeled WBMs, significantly reducing the reliance on labeled data without necessitating additional design. Minimizing the need for labeled data is essential, especially for real-world applications. In comparison with existing self-supervised learning methods on single-label binary WBM dataset WM-811K, our proposed approach demonstrated substantial improvements in the quality of self- supervised learning. Notably, there was a +7.2% macro F1-score im- provement for classification with only 1% of the total training labels compared to TSM‚Äô21. Additionally, our method achieved a +12.6% macro F1-score improvement compared to ICCAD‚Äô 21. Moreover, for the multi-label binary WBM dataset MixedWM38, our proposed ap- proach also exhibited effective classification performance, achieving a macro F1-score of 0.972. These results underscore the superior efficacy and potential of our proposed methodology. 5. Conclusion Large-scale unlabeled WBMs are available in real-world semicon- ductor manufacturing, and labeled WBMs are challenging to obtain. Therefore, us"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_50", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 50, "text": "and potential of our proposed methodology. 5. Conclusion Large-scale unlabeled WBMs are available in real-world semicon- ductor manufacturing, and labeled WBMs are challenging to obtain. Therefore, using large-scale unlabeled data and reducing the demand for labeled data is essential for WBM analysis. Existing WBM self- supervised methods learn WBM representation from unlabeled data but still need a large amount of labeled data to fine-tune an ideal classifi- cation model. This study leverages a self-supervised learning approach based on MAE that can improve classification accuracy with only a few labeled data for fine-tuning. Complex WBMs are the most common data in wafer fabrication, containing multiple bin categories and GFA types. This study first proposes a complex WBM self-supervised learning Expert Systems With Applications 249 (2024) 123601 10Y. Wang et al. method. For the multi-bin problem, we proposed a patchMC encoder to improve MAE‚Äôs feature representation capability for complex WBM. In addition, after self-supervised learning, a multi-label fine-tuning method is proposed for multi-GFA WBM classification. The performance of the proposed framework is evaluated on a real-"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_51", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 51, "text": "mplex WBM. In addition, after self-supervised learning, a multi-label fine-tuning method is proposed for multi-GFA WBM classification. The performance of the proposed framework is evaluated on a real-world complex WBM dataset. Ablation studies prove the necessity and effectiveness of patchMC encoder. Few-shot classification results indicate that the proposed framework can achieve a high classifica- tion accuracy with few labeled data. Moreover, by comparing MAE with other existing self-supervised learning methods, we proved that using MAE for WBM self-supervised learning outperforms other existing self-supervised learning approaches. Finally, future work will focus on the object detection approaches combined with self-supervised learning and few-shot learning to de- tect more complex GFA with local features and very weak signals to improve the classification performance for complex WBMs. CRediT authorship contribution statement Yi Wang: Conceptualization, Methodology, Software, Validation, Writing ‚Äì original draft, Writing ‚Äì review & editing. Dong Ni: Con- ceptualization, Supervision, Project administration, Writing ‚Äì review & editing, Funding acquisition. Zhenyu Huang: Methodology"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_52", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 52, "text": "ion, Writing ‚Äì original draft, Writing ‚Äì review & editing. Dong Ni: Con- ceptualization, Supervision, Project administration, Writing ‚Äì review & editing, Funding acquisition. Zhenyu Huang: Methodology, Data cura- tion, Visualization, Resources, Investigation. Puyang Chen: Software, Formal analysis, Validation. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability The data that has been used is confidential. Acknowledgments The authors would like to acknowledge the financial support from the National Natural Science Foundation of China (Grant No. 62173298). References Alawieh, M. B., Boning, D., & Pan, D. Z. (2020). Wafer map defect patterns classification using deep selective learning. In ACM/IEEE design automation conference (pp. 1‚Äì6). Caron, M., Bojanowski, P., Joulin, A., & Douze, M. (2018). Deep clustering for unsupervised learning of visual features. In European conference on computer vision . Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., & Joulin, A. (2020). Unsupervised learning of visual fea"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_53", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 53, "text": "upervised learning of visual features. In European conference on computer vision . Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., & Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. In Neural information processing systems (neurIPS) . Chen, X., Xie, S., & He, K. (2021). An empirical study of training self-supervised vision transformers. In IEEE conference on computer vision and pattern recognition . Chen, L. L.-Y., et al. (2020). TestDNA-E: Wafer defect signature for pattern recognition by ensemble learning. In IEEE international test conference . Chiu, M., & Chen, T. (2021). Applying data augmentation and mask R-CNN- based instance segmentation method for mixed-type wafer maps defect patterns classification. IEEE Transactions on Semiconductor Manufacturing ,34(4), 455‚Äì463. Ciresan, D., Meier, U., Gambardella, L., & Schmidhuber, J. (2010). Deep big simple neural nets for handwritten digit recognition. Neural Computation ,22, 1‚Äì14. Doersch, C., Gupta, A., & Efros, A. A. (2015). Unsupervised visual representation learning by context prediction. In IEEE international conference on computer vision (pp. 1422‚Äì1430). Donoho, D., "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_54", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 54, "text": "‚Äì14. Doersch, C., Gupta, A., & Efros, A. A. (2015). Unsupervised visual representation learning by context prediction. In IEEE international conference on computer vision (pp. 1422‚Äì1430). Donoho, D., & Grimes, C. (2003). Hessian Eigenmaps: New Locally Linear Embedding Techniques for High-Dimensional Data :Technical Report 2003‚Äì08 , Dept. of Statistics, Stanford Univ.. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., et al. (2021). An image is worth 16x16 words: Transformers for image recognition at scale. In International conference on learning representations . ICLR.Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., & Bengio, S. (2010). Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research ,11, 625‚Äì660. Geng, H., Yang, F., Zeng, X., & Yu, B. (2021). When wafer failure pattern classification meets few-shot learning and self-supervised learning. In IEEE international conference on computer aided design . Goodfellow, I., Courville, A., & Bengio, Y. (2011). Spike-and-slab sparse coding for unsupervised feature discovery. arXiv preprint arXiv:1201.3382. Goodfellow, I., Pouget-Abadie, J., Mirza"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_55", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 55, "text": "d design . Goodfellow, I., Courville, A., & Bengio, Y. (2011). Spike-and-slab sparse coding for unsupervised feature discovery. arXiv preprint arXiv:1201.3382. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., et al. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672‚Äì2680). Grill, J. B., Strub, F., Altche, F., Tallec, C., & Richemond, P. (2020). Bootstrap your own latent: A new approach to self-supervised learning. In Advances in neural information processing systems . He, K., Chen, X., Xie, S., Li, Y., Dollar, P., & Girshick, R. (2021). Masked autoencoders are scalable vision learners. In IEEE conference on computer vision and pattern recognition . He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In IEEE conference on computer vision and pattern recognition . Hsu, S. C., & Chien, C. F. (2007). Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing. International Journal of Production Economics ,107(1), 88‚Äì103. Jing, L., & Tian, Y. (2018). Self-supervised spatiotemp"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_56", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 56, "text": "rn extraction from wafer bin map to improve yield in semiconductor manufacturing. International Journal of Production Economics ,107(1), 88‚Äì103. Jing, L., & Tian, Y. (2018). Self-supervised spatiotemporal feature learning by video geometric transformations. In IEEE conference on computer vision and pattern recognition . Jing, L., & Tian, Y. (2021). Self-supervised visual feature learning with deep neural networks: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 43(11), 4037‚Äì4058. Kahng, H., & Kim, S. B. (2021). Self-supervised representation learning for wafer bin map defect pattern classification. IEEE Transactions on Semiconductor Manufacturing , 34(1), 74‚Äì86. Kim, D., & Kang, P. (2021). Dynamic clustering for wafer map patterns using self-supervised learning on convolutional autoencoders. IEEE Transactions on Semiconductor Manufacturing ,34(4), 444‚Äì454. Kim, J., Lee, Y., & Kim, H. (2018). Detection and clustering of mixed-type defect patterns in wafer bin maps. IISE Transactions ,50(2), 99‚Äì111. Kim, J., Mo, K., Park, J., Kim, H., & Kang, P. (2019). Bin2Vec: A better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_57", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 57, "text": "maps. IISE Transactions ,50(2), 99‚Äì111. Kim, J., Mo, K., Park, J., Kim, H., & Kang, P. (2019). Bin2Vec: A better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer classification. Applied Sciences ,597(9). Kong, Y., & Ni, D. (2020a). Qualitative and quantitative analysis of multi-pattern wafer bin maps. IEEE Transactions on Semiconductor Manufacturing ,33(4), 578‚Äì586. Kong, Y., & Ni, D. (2020b). A semi-supervised and incremental modeling framework for wafer map classification. IEEE Transactions on Semiconductor Manufacturing ,33(1), 62‚Äì71. Ledig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., et al. (2016). Photo-realistic single image super-resolution using a generative adversarial network. InIEEE conference on computer vision and pattern recognition (pp. 4681‚Äì4690). Li, D., Hung, W.-C., Huang, J.-B., Wang, S., Ahuja, N., & Yang, M.-H. (2016). Unsupervised visual representation learning by graph-based consistent constraints. InEuropean conference on computer vision . Li, K. S., & Tsai, N. C. (2020). TestDNA: Novel wafer defect signature for diagnosis and pattern recognition. IEEE Transactions on Semiconductor Manufacturing"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_58", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 58, "text": "nEuropean conference on computer vision . Li, K. S., & Tsai, N. C. (2020). TestDNA: Novel wafer defect signature for diagnosis and pattern recognition. IEEE Transactions on Semiconductor Manufacturing ,33(3), 383‚Äì390. Nakazawa, T., & Kulkarni, D. V. (2019). Anomaly detection and segmentation for wafer defect patterns using deep convolutional encoder‚Äìdecoder neural network architectures in semiconductor manufacturing. IEEE Transactions on Semiconductor Manufacturing ,32(2), 250‚Äì256. Noroozi, M., & Favaro, P. (2016). Unsupervised learning of visual representations by solving jigsaw puzzles. In European conference on computer vision . Noroozi, M., Vinjimoor, A., Favaro, P., & Pirsiavash, H. (2018). Boosting self-supervised learning via knowledge transfer. ArXiv preprint arXiv:1805.00385. Olshausen, B., & Field, D. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature ,381, 607‚Äì609. Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., & Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In IEEE conference on computer vision and pattern recognition (pp. 2536‚Äì2544). Ranzato, M., Boureau, Y., & LeCun, Y. (2007"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_59", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 59, "text": " T., & Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In IEEE conference on computer vision and pattern recognition (pp. 2536‚Äì2544). Ranzato, M., Boureau, Y., & LeCun, Y. (2007). Sparse feature learning for deep belief networks. In Advances in neural information processing systems . Rifai, S., Vincent, P., Muller, X., Glorot, X., & Bengio, Y. (2011). Contractive auto- encoders: Explicit invariance during feature extraction. In Int‚Äôl conf. machine learning . Roweis, S. (1997). EM Algorithms for PCA and Sensible PCA :Technical Report CNS-TR-97-02 , California Institute of Technology. Roweis, S., & Saul, L. (2000). Nonlinear dimensionality reduction by locally linear embedding. Science ,290(5500), 2323‚Äì2326. Saqlain, M., Jargalsaikhan, B., & Lee, J. Y. (2019). A voting ensemble classifier for wafer map defect patterns identification in semiconductor manufacturing. IEEE Transactions on Semiconductor Manufacturing ,32(2), 171‚Äì182. Expert Systems With Applications 249 (2024) 123601 11Y. Wang et al. Seide, F., Li, G., & Yu, D. (2011). Conversational speech transcription using context- dependent deep neural networks. In Conference international speech communication "}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_60", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 60, "text": " (2024) 123601 11Y. Wang et al. Seide, F., Li, G., & Yu, D. (2011). Conversational speech transcription using context- dependent deep neural networks. In Conference international speech communication association (pp. 437‚Äì440). Sun, C., Shrivastava, A., Singh, S., & Gupta, A. (2017). Revisiting unreasonable effectiveness of data in deep learning era. In ICCV . van den Oord, A., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv:1807.03748. van der Maaten, L., & Hinton, G. E. (2008). Visualizing high-dimensional data using t-SNE. Journal of Machine Learning Research ,9, 2579‚Äì2605. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., et al. (2017). Attention is all you need. In Advances in neural information processing systems (neurIPS) . Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P. A. (2008). Extracting and composing robust features with denoising autoencoders. In Int‚Äôl conf. machine learning . Wang, Y., & Ni, D. (2019). Multi-bin wafer maps defect patterns classification. In International symposium on semiconductor manufacturing intelligence . Wang, Y., & Ni, D. (2023). A deep learning analysis framewor"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_61", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 61, "text": "i, D. (2019). Multi-bin wafer maps defect patterns classification. In International symposium on semiconductor manufacturing intelligence . Wang, Y., & Ni, D. (2023). A deep learning analysis framework for complex wafer bin map classification. IEEE Transactions on Semiconductor Manufacturing ,36(3), 367‚Äì377. Wang, Y., Ni, D., & Huang, Z. (2023). A momentum contrastive learning framework for low-data wafer defect classification in semiconductor manufacturing. Applied Sciences ,13(5894).Wang, J., Xu, C., et al. (2020). Deformable convolutional networks for efficient mixed-type wafer defect pattern recognition. IEEE Transactions on Semiconductor Manufacturing ,33(4), 587‚Äì596. Weinberger, K., & Saul, L. (2004). Unsupervised learning of image manifolds by semidefinite programming. In IEEE conf. computer vision and pattern recognition (pp. 988‚Äì995). Wu, M.-J., Jang, J.-S. R., & Chen, J.-L. (2015). Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Transactions on Semiconductor Manufacturing ,28(1), 1‚Äì12. Wu, Z., Xiong, Y., Yu, S., & Lin, D. (2018). Unsupervised feature learning via non- parametric instance discrimination. In IEEE conference on co"}
{"id": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf::chunk_62", "source": "A self-supervised learning framework based on masked autoencoder for complex wafer bin map classification.pdf", "chunk_index": 62, "text": "ansactions on Semiconductor Manufacturing ,28(1), 1‚Äì12. Wu, Z., Xiong, Y., Yu, S., & Lin, D. (2018). Unsupervised feature learning via non- parametric instance discrimination. In IEEE conference on computer vision and pattern recognition . Yu, J., & Lu, X. (2016). Wafer map defect detection and recognition using joint local and nonlocal linear discriminant analysis. IEEE Transactions on Semiconductor Manufacturing ,29(1), 33‚Äì43. Zhang, R., Isola, P., & Efros, A. A. (2016). Colorful image colorization. In European conference on computer vision (pp. 649‚Äì666). Springer. Zhu, J.-Y., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired image-to-image translation using cycle-consistent adversarial networks. In IEEE international conference on computer vision (pp. 2223‚Äì2232)."}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_0", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 0, "text": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/220863500 A Process Monitor Based Speed Binning and Die Matching Algorithm Conf erence Paper in Proceedings of the Asian T est Symposium ¬∑ No vember 2011 DOI: 10.1109/ ATS.2011.96 ¬∑ Sour ce: DBLP CITATIONS 3READS 171 1 author: Sreejit Chakr avarty LSI Corpor ation 136 PUBLICA TIONS 1,762 CITATIONS SEE PROFILE All c ontent f ollo wing this p age was uplo aded b y Sreejit Chakr avarty on 22 Januar y 2015. The user has r equest ed enhanc ement of the do wnlo aded file. A Process Monitor Based Speed Binning and Die Matching Algorithm Sreejit Chakravarty LSI Corporation Milpitas, CA, USA Abstract ‚Äî Speed binning groups ICs with similar performance and price point. Die matching matches dice with similar performance for system and 3D integration. A hybrid test flow combining process monitor readings and search using manufacturing test is presenteds. This flow eliminates error due to process monitor data inaccuracies and reduces test time of manufacturing test based search. Silicon data is presented. Keywords: Process Monitor, Speed Binning, Die Matching, 3D Integration I. "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_1", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 1, "text": "due to process monitor data inaccuracies and reduces test time of manufacturing test based search. Silicon data is presented. Keywords: Process Monitor, Speed Binning, Die Matching, 3D Integration I. INTRODUCTION When integrating systems, it is important to match dice with similar performance. This results in systems with wider performance range which can then be binned for different price points. Similarly, in 3D layouts, as shown in Figure 1, 2 or more dice are stacked on top of each other. The stacked dice are connected using through silicon via (TSV) and finally packaged. Stacked dice should match in their performance. Thus dice are binned into performance bins before stacking. This problem is similar to the speed-binning problem. Figure 1. Example of one form of 3D Layout Speed binning has been studied in the context of binning microprocessors, DSP etc. We address the problem of test time optimization for speed binning. The motivation is to reduce test cost. It is difficult to find published papers on binning. The standard methodology for speed binning is to use max frequency search. It uses at-speed manufacturing tests to search for the max frequency. Tests used are system te"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_2", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 2, "text": "d published papers on binning. The standard methodology for speed binning is to use max frequency search. It uses at-speed manufacturing tests to search for the max frequency. Tests used are system tests for system assembly, functional tests for microprocessors, and structural tests for ASICs. The search for max frequency is very time consuming and smaller speed-binning subset of the tests is used to reduce the test time. This paper proposes an alternative approach to speed binning that reduces test time without sacrificing accuracy. We first investigate using on-chip process monitor (PM) data for max frequency prediction. PMs have been proposed for a variety of applications [1][2][3]. It has also been proposed for speed characterization [4]. For process characterization [4] process monitor accuracy may be adequate. Our interest is in its use in high volume manufacturing for mature processes for which the accuracy requirement are very different. In Section II silicon evaluation of several algorithms using process monitor reading only are presented. Data shows that the purely process monitor based algorithm needs correction, even if we increase the bin size to 10% of the base freque"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_3", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 3, "text": "ral algorithms using process monitor reading only are presented. Data shows that the purely process monitor based algorithm needs correction, even if we increase the bin size to 10% of the base frequency. A hybrid flow combining process monitor reading with search using manufacturing tests is presented in Section III. Such an approach has also been used for voltage binning [6]. In Section IV silicon evaluation of the hybrid algorithm is presented. Result show that the hybrid algorithm reduces test time drastically without sacrificing accuracy. II. PROCESS MO NITOR BASED METHODOLOGY ASICs have inbuilt process monitors (PMs) and a variety of them that have been discussed in the literature. In this paper we assume that PMs are ring-oscillator driving the clock pin of a counter for a fixed duration of time. This count C is read out during test. The value of C for a faster die is larger than the value of C for a slower die. A normalized value of C, given by K = Q/C, is used in our study. The value of Q is a constant and chosen such that K is close to 1 for a nominal die. If K is small (large) then we have a fast (slow) die. The inverters in the ring oscillator used in this study uses no"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_4", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 4, "text": "e value of Q is a constant and chosen such that K is close to 1 for a nominal die. If K is small (large) then we have a fast (slow) die. The inverters in the ring oscillator used in this study uses nominal V T transistor cells. We refer to these PMs as NOMY and use the K values from NOMY. NOMY is used to determine the max frequency of a die as follows. First a model for mapping K to F MAX, the max frequency, is developed using a small sample of the die, as described below in subsection A. This model is modified to determine the speed bin for a die as described in subsection B. The binning algorithm so derived is used to bin dice flowing through the production flow. Silicon evaluation of this PM based flow is presented in subsection C. A. A First Pass Process Monitor Based Algorithm The first algorithm builds a model directly mapping the K value to the F MAX value for each clock domain. We use a sample of dice, with different K values, and determine the FMAX of each die. To build this model a golden reference for F MAX of a die is required. If systems with sockets are available system tests can be used to determine F MAX. For ASICs this poses a problem. ASIC vendors often do not hav"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_5", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 5, "text": "odel a golden reference for F MAX of a die is required. If systems with sockets are available system tests can be used to determine F MAX. For ASICs this poses a problem. ASIC vendors often do not have access to socketed systems. Also, ASICs are often used in different end products. In such a scenario the model will have to be built by the ASIC vendor for each of these end systems. Functional manufacturing tests to determine the golden FMAX data. Functional test suites are typically not part of the ASIC manufacturing test suite and are more appropriate for microprocessors and DSP chips for which such test suites are available. 2011 Asian Test Symposium 1081-7735/11 $26.00 ¬© 2011 IEEE DOI 10.1109/ATS.2011.96311 For ASICs used in our study F MAX was determined using at-speed manufacturing structural tests. Let T = {T 1, T2‚Ä¶ T N} be the set of all TDF and PDF tests for a clock domain C. Let F(d, T j) be the maximum frequency at which die d passes test Tj. Then, FMES(d, C), the measured maximum frequency for die d for clock domain C is Min{F(d, T j): T j/g787/g787T}. Here, we assume that all the max frequency measurement is done at nominal voltage. Lower operating voltages can also be "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_6", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 6, "text": "ximum frequency for die d for clock domain C is Min{F(d, T j): T j/g787/g787T}. Here, we assume that all the max frequency measurement is done at nominal voltage. Lower operating voltages can also be used, based on the end application of the die. Table 1 Sample (385) Total (3986) LOT1 10 118 LOT2 75 764 LOT3 75 773 LOT4 75 784 LOT5 75 783 LOT6 75 764 In a production environment we assume that an initial set of die is used to build such a model. In our study we use the sample shown in Table 1. The total dice population was 3986 dice which were picked from different lots spanning the process spread. About 10% of the die, selected randomly from each lot as shown in Table 1, was used to build the model. Figure 2. Model for FAST This design had three clock domains, FAST, SLOW and VERY SLOW. This study built two models, one each for FAST and SLOW clock domain, to understand the accuracy of the process monitor data. Simple linear models, shown in Figure 2 and Figure 3, which fit the NOMY reading with the FMES data were used. The model for FAST was FCALC = -122.75 * K + 539.45; R2 = 0.854 (1) The model for SLOW was FCALC = -211.99 * K + 472.71; R2 = 0.7968 (2) An important question is: How"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_7", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 7, "text": "ing with the FMES data were used. The model for FAST was FCALC = -122.75 * K + 539.45; R2 = 0.854 (1) The model for SLOW was FCALC = -211.99 * K + 472.71; R2 = 0.7968 (2) An important question is: How does FMES compare with FCALC. We next investigate that question. Figure 3. Model for SLOW Figure 4. Absolute error for FAST Errors observed for this sample data is analyzed in two different ways. For FAST we plot the absolute difference between FCALC and FMES in Figure 4. The plot is for the entire die population not just the sample used to build the model. If we target 5% accuracy then 16% of the die population does not satisfy the accuracy requirement. If we increase the accuracy requirement to 3.5% then 33% of the die population does not meet the requirement. Figure 5. Error profile for FAST In Figure 5 and Figure 6 we plot the difference between FCALC and F MES for the two clock domains. The most important message from these two figures is that the difference between F CALC and F MES can be both positive and negative. The second message is that, for some die, the error can be rather large. -10.000-8.000-6.000-4.000-2.0000.0002.0004.0006.0008.00010.00012.000 -10.000-8.000-6.000-4.0"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_8", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 8, "text": "can be both positive and negative. The second message is that, for some die, the error can be rather large. -10.000-8.000-6.000-4.000-2.0000.0002.0004.0006.0008.00010.00012.000 -10.000-8.000-6.000-4.000-2.0000.0002.0004.0006.0008.00010.00012.000 0.0005.00010.00015.00020.000 33% 3.5% 5%16% Die Count0.0005.00010.00015.00020.000 33% 3.5% 5%16% 0.0005.00010.00015.00020.000 33% 3.5% 5%16% Die CountFrequency NOMYFrequency Frequency NOMY Frequency NOMYFrequency Frequency NOMY 312 Figure 6. Error profile for SLOW B. The Final Process Monitor Based Algorithm We next investigate a different algorithm that attempts to cancel out the errors across clock domains. For that we formally define the notion of a bin. Base frequency of a clock domain is the target frequency for that clock domain. For simplicity, assume two clock domains C1, C2 and with base frequency F1, F2. The frequency range for a bin is based on the bin size as a percentage of the base frequency. If the bin size is m% of the base frequency, then the frequency range of the bins, for clock domain C1, is as defined below. BIN0 F1 = {F1, (1+0.01*m)*F1} (3) BIN1 F1 = {(1+0.01*m)*F1, (1+0.02*m)*F1} BIN2 F1 = ... Similarly, the frequency"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_9", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 9, "text": "uency, then the frequency range of the bins, for clock domain C1, is as defined below. BIN0 F1 = {F1, (1+0.01*m)*F1} (3) BIN1 F1 = {(1+0.01*m)*F1, (1+0.02*m)*F1} BIN2 F1 = ... Similarly, the frequency range of the bins, for clock domain C2, is as defined below. BIN0 F2 = {F2, (1+0.01*m)*F2} (4) BIN1 F2 = {(1+0.01*m)*F1, (1+0.02*m)*F1} BIN2 F2 = ... The frequency range for the rest of the bins can be similarly defined. Define the measured FMAX of a die d for these clock domains to be F1MES(d), F2 MES(d). Define the calculated FMAX of a die d for these clock domains to be F1CALC(d), F2CALC(d). Recall that the calculated F MAX is the F MAX estimated using the NOMY data and models similar to equations (1) and (2). For a given die d, let BIN F1(MES, d), BIN F2(MES, d) be the bins for clock domains C1, C2 determined using FMES(d). Similarly, let BIN F1(CALC, d), BIN F2(CALC, d) be the bins for clock domains C1, C2 determined using FCALC(d). Then, BIN(MES, d) = min{BIN F1(MES, d), BIN F2(MES, d)} (5) BIN(CALC, d) = min{BIN F1(CALC, d), BIN F2(CALC, d)} (6) Equation (5) gives the measured bin for die d, whereas equation (6) gives the calculated bin for die d. The new PM based binning algor"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_10", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 10, "text": " d)} (5) BIN(CALC, d) = min{BIN F1(CALC, d), BIN F2(CALC, d)} (6) Equation (5) gives the measured bin for die d, whereas equation (6) gives the calculated bin for die d. The new PM based binning algorithm uses the following steps. We use a sample Q of dice in the steps outlined below. ‚Ä¢ Use this sample Q to derive models similar to equations (1), (2). ‚Ä¢ For each die d in Q, for each clock domain, compute FCALC using models similar to equations (1), (2). ‚Ä¢ For each die d in Q, calculate BIN(CALC,d) using equation (6) ‚Ä¢ For each die d in Q, calculate BIN(MES,d) using equation (5) ‚Ä¢ For the set of points { ( BIN(CALC,d), BIN(MES,d) ): d in Q} find the best fit linear correlation. Non-linear models could be used but the linear model was found to be adequate. Let the model derived be BIN(MES, d) = A * BIN(CALC,d) + B (7) Here A, B are constants. Since BIN(CALC,d) can be calculated from F CALC from equations similar to (1), (2), equations (1), (2) and (8) is a model for calculating the bin from the process monitor reading K. For the sample data of Table 1 we derived the model using the above steps. It turned out that we had a perfect correlation with A = 1 and B = 0, when we used 5% as w"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_11", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 11, "text": "rom the process monitor reading K. For the sample data of Table 1 we derived the model using the above steps. It turned out that we had a perfect correlation with A = 1 and B = 0, when we used 5% as well as 10% for the bin sizes. That is, BIN(d) = BIN(CALC,d) (8) Note that in spite of randomness in the process monitor data the binning data had a perfect correlation. C. Silicon Evaluation of the Process Monitor Based Algorithm We next evaluate the effectiveness of the above model. Calculations and measurements are done on the rest of the dice which are not used to build the model. We pick a value of m, i. e. the bin size, and calculate the value of BIN(d) using equations (1), (2) and (8). For each die, and each clock domain C we measure FMES(d, C). From the FMES(d, C) we derive the value of BIN(MES, d) using equations (3), (4). We next calculate and plot the difference given by equation (9). DIFF(d) = BIN(MES, d) ‚Äì BIN(d) (9) The difference plot derived using equation (9), for two bin sizes, viz. 5% and 10%, for the data of Table 1 are shown in Figure 7 and Figure 8. In Figure 7 and Figure 8 the X-axis represents the NOMY reading in increasing order. Note that in spite of the perfec"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_12", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 12, "text": "izes, viz. 5% and 10%, for the data of Table 1 are shown in Figure 7 and Figure 8. In Figure 7 and Figure 8 the X-axis represents the NOMY reading in increasing order. Note that in spite of the perfect correlation while building the model there are a fair number of die for which the model given by equation (9) fails to predict the correct bin. There are a number of observations to be made. The error could be both positive and negative and it is equally likely. In addition, the error is spread across the entire process range. However, the data shows that the new algorithm is pretty close to predicting the right bin. Most of the time the calculated bin matches the measured bin or the two of them differ by one. We use this observation in the hybrid algorithm described in Section III. III. A HYBRID ALGORITHM FOR SPEED BINNING As shown in Figure 9, the algorithm first predicts the bin using NOMY and refines it using structural test. We first explain the notations. Assume M clock domains C1, C 2... C M with base frequency F1, F2‚Ä¶ F M. The bin size is the percentage m of -15.000-10.000-5.0000.0005.00010.00015.000 -15.000-10.000-5.0000.0005.00010.00015.000 313 the base frequency. From this"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_13", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 13, "text": " C 2... C M with base frequency F1, F2‚Ä¶ F M. The bin size is the percentage m of -15.000-10.000-5.0000.0005.00010.00015.000 -15.000-10.000-5.0000.0005.00010.00015.000 313 the base frequency. From this the frequency range of the bins in the respective clock domain is defined as in equations (3), (4). Notation [fJ] of BIN J denotes the vector: [fJ] = {f 1, f2‚Ä¶ f M}, where (10) fP= F P * (1 + J * 0.01 * m); J = 1, 2‚Ä¶ and P = 1, 2‚Ä¶ M Figure 7. Bin difference plot for bin size of 5% Figure 8. Bin difference plot for bin size of 10% A die belongs to BIN J if the die passes all tests for clock domain CP applied at frequency fP, defined by equation (10), where P = 1, 2‚Ä¶ M . The correct bin for a die is BIN J iff the die can belong to BIN J but cannot belong to BIN J+1. We use the term ‚Äúpass @ [f I]‚Äù for test block SJ. Let the clock domain for test block SJ be CP. Given this, the term implies that tests for clock domain CP was run at frequency fP and the die passed the test. Similarly, we use the term ‚Äúfail @ [f I]‚Äù for test block SJ. Let the clock domain for test block SJ be CP. Given this, the term implies that tests for clock domain CP was run at frequency fP and the die failed the test."}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_14", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 14, "text": "he term ‚Äúfail @ [f I]‚Äù for test block SJ. Let the clock domain for test block SJ be CP. Given this, the term implies that tests for clock domain CP was run at frequency fP and the die failed the test. The term ‚ÄúIncrement [f J]‚Äù implies that [fJ] is replaced by [fJ+1] and the next round of test will try to ascertain whether or not the die belong to BIN J+1, i. e. one bin higher than BIN J. The term ‚Äúdecrement [f J]‚Äù implies that [fJ] is replaced by [fJ-1] and the next round of test will try to ascertain whether or not the die belong to BIN J-1, i. e. one bin lower than BIN J. In the first step Figure Figure 9 of we determine an initial bin BIN INIT based on the models described in Section II. This initial bin, BIN INIT is close but may be higher or lower than the correct bin. We next perform a local search to determine the correct bin starting from BIN INIT as described below. Figure 9. Optimal Hybrid Algorithm The local search for the correct bin is done using structural tests. Structural tests differ in their effectiveness in determining the correct bin. If a test block S is the best structural test block to determine the correct bin then we use that block first in the test flow. "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_15", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 15, "text": "ral tests differ in their effectiveness in determining the correct bin. If a test block S is the best structural test block to determine the correct bin then we use that block first in the test flow. When we say that S is the best test block it implies that for the largest number of dice, compared to the other test blocks, the bin determined by S is the correct bin for that die. We assume N structural test blocks and <S1, S2‚Ä¶ S N> is the optimal ordering of these tests. Here, SI is more effective than SJ provided I < J . The die under test passes through the set of test blocks in the order B1, B2‚Ä¶ B N. Test block B j uses structural test S j. The intuition behind this is that if we determine the correct bin using the most effective test block S first then we will, with a high probability, have to run the rest of the structural test blocks only once to determine the correct bin. This one pass through all the structural tests is needed in any case since we have to certify that the die is defect free and runs at the identified bin frequency. The methodology to determine the optimal ordering of the set of structural tests S = {T 1, T2‚Ä¶ T N} is as follows. The same sample Q of die used "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_16", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 16, "text": " defect free and runs at the identified bin frequency. The methodology to determine the optimal ordering of the set of structural tests S = {T 1, T2‚Ä¶ T N} is as follows. The same sample Q of die used to build the model described in Section Error! Reference source not found. is used for this purpose. Assume m to be the bin size. For each die d in /g1167Q, measure FMAX(Tj, d) the maximum frequency determined by a search using structural test Tj. From that we compute BIN(MES, T j, d) the measured bin using structural test Tj. BIN(MES,d) = min { BIN(MES, T j, d) }, j = 1, 2, ‚Ä¶, N. If Tj determines BIN(MES,d) for most of the dice d in Q then Tj is the most effective structural test for determining the correct bin and we set S1 to Tj. The next most effective structural test is set as S2 and so on. In our experiment we used a slight variation of the above algorithm to determine the ordering of the structural tests. For each test we calculated the average bin number given by equation (11). In equation (11), | Q| is the cardinality of the sample set of dice Q. BIN AVE(Tj) = (SUM d in Q {BIN(MES, T j, d)})/|Q| (11) Figure 10 processes block B1, which uses the most effective test block S1. As"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_17", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 17, "text": "equation (11), | Q| is the cardinality of the sample set of dice Q. BIN AVE(Tj) = (SUM d in Q {BIN(MES, T j, d)})/|Q| (11) Figure 10 processes block B1, which uses the most effective test block S1. Assume test S1 is in clock domain CP. Then fP, which is a component of [fTEST], is the frequency at which the die is tested using test S1. If the die passes the test Calculate [fINIT] [fTEST] = [fINIT] Test Block B1Test Block BJTest Block BN [fFINAL] = [fTEST]Determine BININIT using K value from NOMY Determine BINFINAL from [fFINAL]Calculate [fINIT] [fTEST] = [fINIT] Test Block B1Test Block BJTest Block BN [fFINAL] = [fTEST]Determine BININIT using K value from NOMY Determine BINFINAL from [fFINAL] -1.500-1.000-0.5000.0000.5001.0001.5002.0002.500 NOMYDIFF -1.500-1.000-0.5000.0000.5001.0001.5002.0002.500 NOMYDIFF-2.500-2.000-1.500-1.000-0.5000.0000.5001.0001.5002.0002.500 NOMYDIFF -2.500-2.000-1.500-1.000-0.5000.0000.5001.0001.5002.0002.500 NOMYDIFF 314 then the PM based algorithm have determined a bin that is lower than the correct bin.. We check this and, if required, increase the bin. This is done by repeatedly increasing the test frequency and hopping to the next higher bin until the t"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_18", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 18, "text": "ned a bin that is lower than the correct bin.. We check this and, if required, increase the bin. This is done by repeatedly increasing the test frequency and hopping to the next higher bin until the test fails. At this point the test frequency is decreased to the previous passing frequency. This now becomes the starting test frequency for the next block. Figure 10. Details of block B 1 On the other hand, if the PM based algorithm determines the bin to be higher than the correct bin for the die then test S1 will fail. In that case, the bin calculation needs to be corrected by reducing the test frequency by repeatedly hopping to the next lower bin until the die passes test S1. The first passing frequency is the starting test frequency for the next block. Details of the rest of the blocks BJ that uses structural test SJ is shown in Figure 11. This flow is quite different from the one for block B1. The reason for this is that the correct bin will never be higher than the bin computed by the previous blocks and can only decrease. The above algorithm can be further by making it more adaptive. For each block we keep count of the number of dice that goes through the fail loop and lead to a"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_19", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 19, "text": "e previous blocks and can only decrease. The above algorithm can be further by making it more adaptive. For each block we keep count of the number of dice that goes through the fail loop and lead to a decrease in the value of [fTEST]. Let those values be X1, X 2‚Ä¶ X N. At periodic intervals we inspect these count values and reorder the test blocks depending on the relative values of these counts. The block with the largest count value goes to the front of the test flow and the block with the lowest count value is put at the end of the test flow. We evaluated the non-adaptive optimal algorithm using the silicon data of Table 1. We compare its performance with three versions of purely structural test base binning: VERY_SIMPLE, SIMPLE and SIMPLE_ORDERED. A. Structural Test Based Binning Algorithm VERY_SIMPLE. For each die d run each structural test T J starting with the base frequency for that clock domain. If d passes the test we increase the test frequency to the next bin and re-test d at the higher frequency. If it passes we continue the process after increasing the test frequency one more notch to the next bin. If the test fails we terminate the process for test block T J and note "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_20", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 20, "text": "t the higher frequency. If it passes we continue the process after increasing the test frequency one more notch to the next bin. If the test fails we terminate the process for test block T J and note the last passing frequency and the corresponding bin BIN(MES,T J,d). Finally, BIN(d) = min (BIN(MES,T 1,d), ‚Ä¶, BIN(MES,T N,d)). Figure 11. Details of block B J IV. EXPERIMENTAL RESULTS SIMPLE. This is also a purely structural test based approach. In VERY_SIMPLE we determine the bin of each die d using a structural test independent of the bin that was determined by the structural tests processed prior to it. In SIMPLE, for T1 we determine bin BIN 1 as in VERY_SIMPLE. The frequency [f1] corresponding to BIN 1 is the starting frequency for test T2. Starting from this, the bin is lowered for test T2 while test T2 keeps failing in a manner similar to the process described in Figure 11. At the end of this we end with bin BIN 2. The frequency [f2] corresponding to BIN 2 is the starting frequency for test T3. This process continues till we have completed processing the last structural test TN. SIMPLE_ORDERED. This algorithm is similar to algorithm SIMPLE with the difference that the structural"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_21", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 21, "text": "for test T3. This process continues till we have completed processing the last structural test TN. SIMPLE_ORDERED. This algorithm is similar to algorithm SIMPLE with the difference that the structural tests are processed in the order of their effectiveness. The set of structural tests S = {T 1, T2‚Ä¶ T N} is first ordered with respect to their effectiveness as was discussed in the context of the optimal hybrid algorithm that uses the process monitor data. A. Silicon Results For the silicon data of Table 1, we had 9 structural tests {T1, T2, T3, T4, T5, T6, T7, T8, and T9 }. These tests were ordered using the sample used to build the models of Section II. The average bin size computed by these tests for bin sizes given by 5% and 10% are shown in Table 2. Table 2. Average bin data for the sample subset of dice T1 T2 T3 T4 T5 T6 5% 11.48 11.47 10.27 11.44 11.48 11.43 10% 5.72 5.72 5.18 5.71 5.72 5.72 T7 T8 T9 5% 11.46 11.17 6.82 10% 5.72 5.61 3.57 From this table, for both 5% and 10% bin sizes, the ordering of the tests derived was: { T9, T3, T8, T6, T4, T7, T2, T1 and T4}. Table 3. Average bin data for the entire set of dice T1 T2 T3 T4 T5 T6 5% 11.52 11.51 10.19 11.43 11.51 11.35 10% "}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_22", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 22, "text": "zes, the ordering of the tests derived was: { T9, T3, T8, T6, T4, T7, T2, T1 and T4}. Table 3. Average bin data for the entire set of dice T1 T2 T3 T4 T5 T6 5% 11.52 11.51 10.19 11.43 11.51 11.35 10% 5.75 5.74 5.09 5.72 5.74 5.68 FAIL SJ @ [fTEST]? Decrease [fTEST]YESNO FAIL SJ @ [fTEST]?FAIL SJ @ [fTEST]? Decrease [fTEST]YESNO FAIL S1 @ [fTEST]? Decrease [fTEST]YESNOPASS S1 @ [fTEST]?Increase [fTEST] YES NO PASS S1 @ [fTEST]? Decrease [fTEST]NO YES FAIL S1 @ [fTEST]?FAIL S1 @ [fTEST]? Decrease [fTEST]YESNOPASS S1 @ [fTEST]?PASS S1 @ [fTEST]?Increase [fTEST] YES NO PASS S1 @ [fTEST]?PASS S1 @ [fTEST]? Decrease [fTEST]NO YES 315 T7 T8 T9 5% 11.51 11.35 5.08 10% 5.74 5.68 3.48 We use tj to denote the test time for structural test Tj. The average bin size for the entire population of dice for VERY_SIMPLE is tabulated in Table 3. The number of times each test is executed is one more than the average size. The total time for VERY_SIMPLE is given by equations (12), (13) for 5% and 10% bin sizes respectively. VERY_SIMPLE(5%) = 12.48 * t1 + 12.47 * t2 + 11.27 * t3 + 12.44 * t4 + 12.48 * t5 + 12.43 * t6 + 12.46 * t7 + 12.17 * t8 + 7.82 * t9 (12) VERY_SIMPLE(10%) = 6.72 * t1 + 6.72 * t2 + 6."}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_23", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 23, "text": "zes respectively. VERY_SIMPLE(5%) = 12.48 * t1 + 12.47 * t2 + 11.27 * t3 + 12.44 * t4 + 12.48 * t5 + 12.43 * t6 + 12.46 * t7 + 12.17 * t8 + 7.82 * t9 (12) VERY_SIMPLE(10%) = 6.72 * t1 + 6.72 * t2 + 6.18 * t3 + 6.71 * t4 + 6.72 * t5 + 6.72 * t6 + 6.72 * t7 + 6.61 * t8 + 4.57 * t9 (13) SIMPLE uses knowledge of the bin determined by the previous test. We use the random ordering T1... T9 . The untime is given by equations (14), (15) for two bin sizes. SIMPLE(5%) = 12.48 * t1 + t2 + 2 * t3 + t4 + t5 + t6 + t7 + t8 + 4.65 * t9 (14) SIMPLE(10%) = 6.72 * t1 + t2 + t3 + t4 + t5 + t6 + t7 + t8 + 3.15 * t9 (15) Note that by forwarding the knowledge of the bin computed in the previous step the search time for the correct bin has reduced considerably. The next algorithm uses the optimal ordering determined above. The test time for this algorithm are given by equations (16) and (17). SIMPLE_ORDERED(5%) = 7.82 * t9 + t3 + t8 + t6 + t4 + t7 + t2 + t1 + t5 (16) SIMPLE_ORDERED(10%) = 4.57 * t9 + t3 + t8 + t6 + t4 + t7 + t2 + t1 + t5 (17) Note that for the silicon data we used one test, viz. t9 was extremely effective in determining the correct bin for the entire set of dice. As a result, once that p"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_24", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 24, "text": " + t6 + t4 + t7 + t2 + t1 + t5 (17) Note that for the silicon data we used one test, viz. t9 was extremely effective in determining the correct bin for the entire set of dice. As a result, once that pattern was used to determine the bin all other tests were used only once. This may not occur all the time and the gains observed in equation (16), (17) may not be as significant for other test cases. The optimal algorithm, that uses knowledge of the process monitor data attempts to reduce this further. The test times for the optimal algorithm are given by equations (18), (19). OPTIMAL(5%) = 1.25 * t9 + t3 + t8 + t6 + t4 + t7 + t2 + t1 + t5 (18) OPTIMAL(10%) = 1.19 * t9 + t3 + t8 + t6 + t4 + t7 + t2 + t1 + t5 (19) If we compare equation (18) with equation (16) the gain in test time is in the number of times test T9 is used on an average once the process monitor reading is used for an initial guess. Correction is required for about 20 to 25% of the die and one or two extra passes are adequate for correction. Similarly, the gain between equations (17), (19) should be fairly obvious. In any manufacturing flow each test will have to be used at least once in order to certify that the part is"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_25", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 25, "text": "e for correction. Similarly, the gain between equations (17), (19) should be fairly obvious. In any manufacturing flow each test will have to be used at least once in order to certify that the part is operational at the stated bin frequency. From equations (18), (19) we note that except for T9 all other patterns are executed only once. So, the added test time for finding the correct bin is 0.25*t9 and 0.19*t9 respectively for the 5% and 10% case. V. SUMMARY In this paper we studied the problem of determining the correct bin using process monitor data. An algorithm based on process monitor data only was presented, analyzed and evaluated using silicon data. Results show that this algorithm requires some refinements. A hybrid algorithm that combines the process monitor based algorithm with manufacturing test was presented. We presented silicon data that showed that this algorithm improved the test time when compared with other purely manufacturing test based algorithms. One improvement that can be made in a future study is to collect similar results where max frequency search using memory tests are also included. ACKNOWLEDGMENT We acknowledge the contribution of Joel Lurkins and AJ Ha"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_26", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 26, "text": "at can be made in a future study is to collect similar results where max frequency search using memory tests are also included. ACKNOWLEDGMENT We acknowledge the contribution of Joel Lurkins and AJ Haas for providing us with the max frequency measurements REFERENCES [1] K. Brand, S. Mitra, E. Volkerink, E. McCluskey, \"Speed Clustering of Integrated Circuits\", in Proceedings 2004 IEEE International Test Conference , Oct. 2004, pp. 1128-1137. [2] Lohit S. Dutta and Thomas Hillmann-Ruge, ‚ÄúApplication of Ring Oscillators to Characterize Transmission Lines in VLSI Circuits‚Äù, IEEE TRANSACTIONS ON COMPONENTS, PACKAGING, AND MANUFACIZTRING TECHNOLOGY-PART B , VOL. 18, NO. 4, NOVEMBER 1995. [3] Benjamin Jun and Paul Kocher, ‚ÄúThe Intel Random Number Generator,‚Äù white paper 1999, [Online] http://cryptography.com/resources/whitepapers/IntelRNG.pdf [4] Linda Milor, Larry Vu, and Bill Liu, ‚ÄúLOGIC PRODUCT SPEED EVALUATION AND FORECASTING DURING THE EARLY PHASES OF PROCESS TECHNOLOGY DEVELOPMENT USING RING OSCILLATOR DATA,‚Äù 2nd International Workshop on Statistical Metrology, 1997 pp. 20 ‚Äì 23 [5] Niiyama, T.; Piao Zhe; Ishida, K.; Murakata, M.; Takamiya, M.; Sakurai, T, ‚ÄúDependence of Minimum Oper"}
{"id": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf::chunk_27", "source": "A_Process_Monitor_Based_Speed_Binning_and_Die_Matc.pdf", "chunk_index": 27, "text": " RING OSCILLATOR DATA,‚Äù 2nd International Workshop on Statistical Metrology, 1997 pp. 20 ‚Äì 23 [5] Niiyama, T.; Piao Zhe; Ishida, K.; Murakata, M.; Takamiya, M.; Sakurai, T, ‚ÄúDependence of Minimum Operating Voltage (V DDmin ) on Block Size of 90-nm CMOS Ring Oscillators and its Implications in Low Power DFM‚Äù 9th International Symposium on Quality Electronic Design , 2008, pp.133 ‚Äì 136 [6] N . P ar r is , J. H e al ey , C. H aw kin s, \" A S im pl e A ppr o ach to D iag no se Localized Thermal and IR Drop Effects on a Microprocessor Core Using On- Chip Synthesizable Ring Oscillators\", Proceedings of the First Silicon Debug and Diagnosis Workshop , Session 3.1, May 2004. [7] J. Rearick, \"Calibrating Clock Stretch during AC Scan Testing\", in Proceedings 2005 IEEE International Test Conference , November 2005. [8] S. Chakravarty, B. Dang, D. Escovedo, A. J. Haas, ‚ÄúOptimal Manufacturing Flow to Determine Minimum Operating Voltage,‚Äù to appear, IEEE International Test Conference, 2011 . 316 View publication stats"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_0", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 0, "text": "2/ Binning forICQuality: Experimental Studies onthe SEMATECH* Data AditD.Singh DavidR.LakinII Gaurav Sinha Electrical Engineering Department Aubum University Aubum, AL36849 E-mail: adsingh@eng.auburn.eduPhilNigh Microelectronics Division IBM EssexJunction, VT05452 Extended Summary 1Introduction Screening basedonthelocality ofdefects haslongbeeninformally practiced inthe industry, whereby diefromwafers, orpartsofthewafer,thatdisplay ahighincidence offailures arediscarded. Morerecently wehaverefined thisapproach suchthattestsresultsfor neighboring dieonthewaferarealsoconsidered inevaluating testresultsforaparticular die[l]. Ithasbeenshown[2-4]thatbyexploiting information aboutdefectclustering onthewafer,test costcanbeoptimized andlowdefects levelsachieved forcomplex VLSIcircuits. Aparticularly usefulcapability ofthisnewapproach istheabilitytobindice(orchips)following testingsoas toseparate outahighquality binwithdefectlevels(duetotestescapes) uptoanorderof magnitude betterthantheaverage forthelot.Furthermore, suchastrategy mayalsobeableto screenforpotential burn-in failures, thereby eliminating theneedforexpensive burn-in ofbare dice.Itisimportant tonotethatthisproposed approach isor"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_1", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 1, "text": "forthelot.Furthermore, suchastrategy mayalsobeableto screenforpotential burn-in failures, thereby eliminating theneedforexpensive burn-in ofbare dice.Itisimportant tonotethatthisproposed approach isorthogonal toothertechniques for improving testeffectiveness (e.g.increased faultcoverage, addition ofIDDQtests,etc.),andcan probably screenfordefectlevelsuptoanorderofmagnitude betterthancanbeotherwise achieved without exploiting defectclustering information. Because ofthedifficulty ofobtaining defectmapdatafromsemiconductor manufacturers, theeffectiveness ofthisnewapproach wasinitially established in[1-4]through detailed analytical analysis. Themathematical models employed werebasedonwidelyaccepted negative-binomial defectdistributions firstintroduced byStapper [5].Recently wepresented the firstexperimental studytopractically demonstrate theviability oftheproposed approach based ontestresultsfromafewwatersfromanolderIBMbipolar process [7].Inthispaper wepresent thefirstresultsontheeffectiveness ofdiescreening foramodern submicron CJ/lOSprocess. The datacomesfromtheSEMATECH testmethods experiments conducted byIBMonaproduction ASIC(144Kgates)in0.5_mprocess. The18,466CMOS dietestedinthisex"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_2", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 2, "text": "ness ofdiescreening foramodern submicron CJ/lOSprocess. The datacomesfromtheSEMATECH testmethods experiments conducted byIBMonaproduction ASIC(144Kgates)in0.5_mprocess. The18,466CMOS dietestedinthisexperiment provide anorderofmagnitude moredatathantheearlierbipolar studyandforthefirsttimeallows validation oftheanalytical models in[2-4]. ‚Ä¢ThisdatacomesfromtheworkofthetestthrustatSEMATECH, ProjectS121.Theanalysis hereisthe workofthisuniversity, theconclusions areourownanddonotnecessarily represent theviewsof SEMATECH oritsmember companies. Therestofthisextendedsummaryisorganizedasfollows.Section2reviewsthedie screeningapproachbasedondefectclustering. InSection 3weoutline theexperimental approach andprovide detailsofthetestdata.Results arepresented inSection 4.Weconclude withSection 5.Thecomplete paperwilladditionally include amorecomprehensive comparison oftheexperimentally observed datawiththetheoretical predictions in[3,4]. 2Review oftheDieScreening Approach Thebasicideaheretakesadvantage ofthefactthatdefectlevelsintestedcomponents (testescapes) depend notonlyonthequality ofthetestapplied, butalsoontheyieldofthe incoming components, i.e.howmanyofthemanufactured components aregoodto"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_3", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 3, "text": "age ofthefactthatdefectlevelsintestedcomponents (testescapes) depend notonlyonthequality ofthetestapplied, butalsoontheyieldofthe incoming components, i.e.howmanyofthemanufactured components aregoodtobeginwith. Thus,ifyieldisveryhigh,evenapoortestwillresultinmostlygoodpartsbeingshipped. Onthe otherhand,ifyieldisverylow,thenapoortestwillletthrough manyfaultyparts.Forexample, ifyieldis90%,evenapoortestthatfailstodetectfaultsin10%ofthebadcomponents willonly letthrough, onaverage, onebadpartforevery90goodpartsadefectlevel(DL)of1.1%. However, ifthemanufacturing yieldis10%,thenthesamepoortestwillbeapplied to90bad partsoutofevery100,andwillletthrough 9badpartsalongwiththetengoodones.Inthislatter case,usingthesametest,thedefectlevelinthepartsbeingshipped is47%,almost45times higherthaninthefirstcase. Because oftheobserved clustering ofdefects insemiconductor wafers, notalldiceona fabricated waferhavethesameprobability ofbeingdefective iftestresultsforotherdiceinthe neighborhood areknown. Adienexttoanother diethatisknowntobedefective hasahighera prioriprobability ofbeingdefective, andalowerexpected yieldthanadiewithgoodneighbors. Nowifdicethattestgoodarebinnedbasedonthese aprioriyields,thedi"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_4", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 4, "text": "xttoanother diethatisknowntobedefective hasahighera prioriprobability ofbeingdefective, andalowerexpected yieldthanadiewithgoodneighbors. Nowifdicethattestgoodarebinnedbasedonthese aprioriyields,thedifferent binscanbeexpected todisplay defectlevelsthatreflecttheincoming yieldvariations. Binswithhighapriori yieldswillcontain dicewithlowdefectlevels. Inthescheme described in[1]eachdiethattestsgo,)dduringthewafer-probe testis binned intooneofnineseparate binsbasedonhowmanyofthedie'sadjacent neighbors (0-8)on the_afertestedfaulty. Although onlydiesthattestgoodarebinned, eachbincanbeexpected to contain somefaultydiesasaresultoftestescapes (i.e.havehigherdetectlevels). Thisis because, duetotheclustering ofdefects, alargerfraction ofdieswithfaultyneighbors arelikely tobefaultytobeginwithwhencompared todieswithzerooronlyafewfaultyneighbors. Assuming thatthetestisequally effective indetecting faulWdiesfromallneighborhood classes, alargerfraction offaultydiceinthetestedsample willresutinalargerfraction offaultescapes andtherefore higherdetectlevels. Thustheninebinscontaningthediesthattestedgoodat waferprobetimecanbeexpected tohavesignificantly diffe'ent defectlevelsdepending onthe extentofth"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_5", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 5, "text": "raction offaultescapes andtherefore higherdetectlevels. Thustheninebinscontaningthediesthattestedgoodat waferprobetimecanbeexpected tohavesignificantly diffe'ent defectlevelsdepending onthe extentofthedefectclustering existing onthewater. These:lifferent defectlevelsimplydiffering likelihood's ofarandom diebeingdefective ineachofthevinebins. Analytical analysis in[3,4]basedonnegative binomial yieldstatistics hasshowndefect levelsinthebestbinuptoanorderofmagnitude betterthattheaverage forthelot.In[7]we present theresultsfromactualwafertestdatacollected atILMforabipolar process. Dicewere binnedbasedontheresultsofabasicDCfunctional test.T,:stescapes werethenuncovered usingamorecomprehensive testwhichincluded delaytesti_g. Itwasobserved thatwhileallthe binstakentogetherhadan8%escaperate,thebestbincontainednotestescapesatall.However, duetothelimitedamountofavailabledata(approximately 1200gooddicefrom23wafers) binningonlyconsidered adie'sNorth,South,EastandWestneighbors(5bins);andeventhen thebestbinswereverysparselypopulated. 3TheExperiments Datafortheexperiments presented herecomesfromtheSEMATECH \"TestMethods Evaluation\" [6]study.Thiswasanexperiment todetermine therelative meritsofsever"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_6", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 6, "text": "ebestbinswereverysparselypopulated. 3TheExperiments Datafortheexperiments presented herecomesfromtheSEMATECH \"TestMethods Evaluation\" [6]study.Thiswasanexperiment todetermine therelative meritsofseveral test methodologies oftenusedbySEMATECH member companies andotherICmanufacturers. The experiment wasdesigned todetermine thefollowing: givenXseconds ofVLSItesttime,how shouldthattimebeoptimally allocated amongthevarious testtechniques currently employed by ICmanufacturers. Aspreviously mentioned, theexperiment wasconducted byIBMon approximately 18,500diefrom75wafersofaproduction ASIC(144Kgates)in0.5_tmprocess. Fourmajortestmethods wereselected thatareincommon usewithinthemember companies. Thesemethods were: ‚Ä¢Functional test,e.g.,designverification patterns ‚Ä¢Scan-based stuck-at faulttests ‚Ä¢Scan-based transition (delay) faulttests ‚Ä¢IDDQtests Figure 1showsatypical wafermap.Thelegendindicates theseveral different possible resultsfromthevarious testsandthetestresultsforeachdiesite.Dotsindicate missing diceor locations forwhichtestresultswerenotavailable. Basedonthiswafermapdataweconstructed threeexperiments tostudytheeffectsof defectclustering ontestescapes. Inthefirstexperiment we\"assume"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_7", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 7, "text": "e missing diceor locations forwhichtestresultswerenotavailable. Basedonthiswafermapdataweconstructed threeexperiments tostudytheeffectsof defectclustering ontestescapes. Inthefirstexperiment we\"assume\" thatonlythefunctional test andIDDQtestswererunatwaferprobe. Thismeansthatalldicemarked $$(allpass),IP(failed delayexclusive), 1T(failedstuck-at exclusive) and2B(failedbothdelayandstuck-at tests)will be\"passed\" asgood.Wecannowlookuponthedicemarked IP,ITand2Bastestescapes for thefunctional andIDDQtestsandstudyhowtheyarebinned. Allthediethatpassedthe functional andIDDQtestswerethenbinnedbasedonthe8neighbor testresults. Bin0then contains thosediewhichpassedthefunctional andIDDQtestswithnofaultydiceamongthe die'seightadjacent neighbors; bin1dicehaveonly1faultyneighbor; bin2dicehavetwofaulty neighbors, etc.uptobin8inwhichthedicehavealleightneighbors faulty. Similarly, thesecondexperiment assumes thatonlythestuck-at testandIDDQwererun atwaferprobe. Thisresultsinalldicemarked $$,IP,1F(failedfunctional exclusive) and2A (failed bothdelayandstuck-at tests)willbepassedasgooddiceandtherefore endupastest escapes inthesubsequent binning. Finally, inthethirdexperiment weassume thattheonlytestnotavai"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_8", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 8, "text": "tional exclusive) and2A (failed bothdelayandstuck-at tests)willbepassedasgooddiceandtherefore endupastest escapes inthesubsequent binning. Finally, inthethirdexperiment weassume thattheonlytestnotavailable atwaferprobe timeistheIDDQtest.InthiscasetheIDDQonlyfailures constitute thetestescapes. Sincethere werealargenumber ofthese,theyprovide significantly moredata.Onethingtonotehereisthat intheSEMATECH studya5j,tAthreshold wasusedtodeclare IDDQfailures. Thisresulted ina substantial number ofdicewhichotherwise passedalltestbuthadanIDDQlevelabove5_A. Forourthirdbinningexperiment weraisedtheIDDQthresholdto1001aA.Therefore,dicewhich hadatestresultof1I(failedIDDQexclusive)andhadanIDDQlevelabove100FtAweretaken tobefailureswhilethosedicewhichweret1buthadanIDDQlevelof100_tAorbelowwere passedandresultedintestescapes. Afterbinningforeachexperiment basedontheavailablewafermapdataweinvestigate thedifferentbinsforthetotalnumberoftestescapesoutof:hetotalnumberofdiceineachbinto obtaindefectlevels. 4Results Oneofthedecisions tobemadebeforecompiling theresultsisinthehandling ofdicefor whichsomeneighborhood testresultsaremissing. Alldiceontheperiphery ofthewaferfallin thiscategory, alongwithsomeintern"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_9", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 9, "text": "ults Oneofthedecisions tobemadebeforecompiling theresultsisinthehandling ofdicefor whichsomeneighborhood testresultsaremissing. Alldiceontheperiphery ofthewaferfallin thiscategory, alongwithsomeinternal diceasshowninFigure1.Forthepurposes ofour experiments weconsidered thesemissing dicetobefailures Thisisbecause diceonthe periphery ofthewafertypically haveahighdefectrate. Table1showstheresultswhenfailures detected exclusively bythestuck-at anddelay testsareconsidered escapes. Observe thatthebestbin,withalleightgoodneighbors, hasonly onetestescapeandadefectlevelof0.17%. Thefraction oftestescapes (stuck-at anddelay failures) generally increases asthenumber offaultyneighbors forabinincrease, although there isareversal forsomebins.Thisismostlikelyastatistical aberration because ofthesmallsample size.Theoverall defectlevelis102defective diceoutof11,881or0.86%, whichis5timesthat forthebestbin. Table2showstheresultswhenfailures detected exclusively bythefunctional anddelay testsareconsidered escapes. Againobserve thatthebestbil_hasonlyonetestescapeanda defectlevelof0.17%. AsseeninTablel,thefraction ofte._tescapes (functional anddelay failures) generally increases asthenumber offaultyneigh"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_10", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 10, "text": "escapes. Againobserve thatthebestbil_hasonlyonetestescapeanda defectlevelof0.17%. AsseeninTablel,thefraction ofte._tescapes (functional anddelay failures) generally increases asthenumber offaultyneighbc, rsincrease, although thereisa reversal forsomebins.Inthiscasetheoverall defectlevelis56defective diceoutofI1,881or 0.47%, whichis2.75timesthatforthebestbin. Similarly Table3showstheresultswhenfailures detected exclusively byonlytheIDDQ testsareconsidered escapes. ForthiscasethebestbinendeJupwith43testescapes andadefect levelof3.45%. Thetraction oftestescapes continues toincrease through bin7withbin8having theonlyreversal. Again.thisisprobably astatistical aberration duetothesmallsample sizein bin8.Theoverall defectleveliscomputed as766outof12,649or6.06%, whichisalmosttwice thatofthebestbin. Forcomparison, wehaveincluded inTable4there:;ultsfromthebipolar datapresented in[7].Inthisinstance aDCfunctional testwasapplied atvafersortandtestescapes werethose dicewhichfailedmoreelaborate DCfunctional testsdelaylests.Theseresultsshowasimilar trendtowhatwehaveseeninTables 1-3.Theseresultsar.‚Ä¢lessstablebecause ofthesmaller number ofdiceusedinthatstudy. Theearliersmaller bipolar studydidnotpro"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_11", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 11, "text": "ctional testsdelaylests.Theseresultsshowasimilar trendtowhatwehaveseeninTables 1-3.Theseresultsar.‚Ä¢lessstablebecause ofthesmaller number ofdiceusedinthatstudy. Theearliersmaller bipolar studydidnotprovide ahighenough bin0population to directly observe testescapes andthereby estimate defectlevelsforthebestbin.Results presented hereindicate thatthebestbincanbereasonably expected toshowa2-5factor improvement indetectlevelsovertheaverage forthelotformoderate tohighyields(theoverall yieldfortheseexperiments wasapproximately 65%).Theexperiments alsoconfirm the dependence ofthebestbinquality ontesttransparency. Thedefectlevelimprovement ispoorer forthecaseofIDDQescapes wherethetestsapplied hadamuchhigherescape rate.Overall experimental resultsareconsistent withanalytical projections fortypical valuesoftheclustering parameter in[9].Thefinalversion ofthispaperwillinclude extensive analysis tovalidate the analytical models basedonthisdata. 5Conclusion Theprimary contribution ofthispaperistheanalysis ofactualsubmicron CMOS experimental testdatatovalidate thepotential ofthedefectclusterbaseddiescreening approach. Waferdefectmapsforstateoftheartprocesses areverydifficult toobtainforpublished st"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_12", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 12, "text": "ysis ofactualsubmicron CMOS experimental testdatatovalidate thepotential ofthedefectclusterbaseddiescreening approach. Waferdefectmapsforstateoftheartprocesses areverydifficult toobtainforpublished studies; theavailability oftheSEMATECH experimental datahasbeeninvaluable. Theexperimental studypresented herehasconclusively established theeffectiveness of defectclustering basedstrategies inscreening dice(andchips)withverylowdefectlevels. Because thisapproach isorthogonal toallothertechniques forimproving testeffectiveness, it canprovide quality levelsthatcannotbeachieved without exploiting defectclustering information. Defectlevelimprovements ofuptoafactorof5canpotentially beachieved for moderate tohighyielding dice,andperhaps evenmoreforlargecomplex dicewithlowyields. Observe thatthisscreening approach isequally effective inscreening outIDDQfailures asitisforDCfunctional failures anddelayfaults.Thisisbecause theunderlying physical mechanism thatourapproach reliesonisdefectclustering. Defects, ingeneral, cancausearange offaultswithdifferent manifestations. Forthisreason, binning canbeexpected tobeequally effective inscreening diceforotherfaulttypes,suchas\"'faults\" thatarelikelytoresu"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_13", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 13, "text": "fects, ingeneral, cancausearange offaultswithdifferent manifestations. Forthisreason, binning canbeexpected tobeequally effective inscreening diceforotherfaulttypes,suchas\"'faults\" thatarelikelytoresultinburn-in failures. Thisisanimportant potential application forthisdiescreening approach. References [i]A.D.SinghandC.M.Krishna, \"OnOptimizing Wafer-Probe Testing forProduct Quality UsingDie-Yield Prediction,\" International TestConference, 1991. [2]A.D.SinghandC.M.Krishna, \"'ChipTestOptimization UsingDetectClustering Information,\" 22nd[EEE[nternational Symposium onFaultTolerant Computing. 1992. [3]A.D.SinghandC.M.Krishna, \"'OnOptimizing VLSITesting forProduct Quality UsingDie-Yield Prediction,\" [EEETransactions onCADVol12.No5,May 1993,pp.695-709. [41A.D.SinghandC.M.Krishna. \"'OntheEffectofDefectClustering onTestTransparency andICTestOptimization,\" [EEETransactions onComputers, Vol45,No6,June1996, pp.753-757. [5]C.H.Stapper, \"Correlation Analysis ofParticle Clusters onIntegrated Circuit Wafers, \"IBMJ. Research andDevelopment, Vol31,No.6,1987. [6] P.Nigh,W.Needham, K.Butler, P.Maxwell, andR.Aitken, \"AnExperimental Study Comparing theRelative Effectiveness ofFunctionai, Scan,IDDQ,andDel"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_14", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 14, "text": "afers, \"IBMJ. Research andDevelopment, Vol31,No.6,1987. [6] P.Nigh,W.Needham, K.Butler, P.Maxwell, andR.Aitken, \"AnExperimental Study Comparing theRelative Effectiveness ofFunctionai, Scan,IDDQ,andDelayTesting, \" Proceedings 1997IEEEVLSITestSymposium, April1997,pp.459-464 [7] A.D.Singh,P.Nigh,andC.M.Krishna, \"Screening forKnown GoodDieBasedon DefectClustering: AnExperimental Study,\" Proceedings 1997International Test Conference, November 1997. [8]E.J.McCluskey, \"ICQuality andTestTransparency,\" International Test Conference, 1990. [9] S.CSethandV.D.Agrawal, \"Characterizing theLSIYieldEquation fromWafer TestData,\"IEEETransactions Computer-Aided Design, Vol.CAD-3, 1984. [lO]T.W.Williams andN.C.Brown, \"Defect LevelasaFunction ofFaultCoverage,\" IEEETransactions Computers, VolC-30,1981. Wafer Map Legend $$=Pass All Tests IO=Shorts/Open Fail SP=Softpower Fail AF=All Fail IT=Failed Stuck-at Exclusive IF=Failed Functional Exclusive IP=Failed Delay Exclusive iI=Failed IDDQ Exclusive 3T=Failed All EXCEPT Stuck-at 3F=Failed All EXCEPT Functional 3P=Failed All EXCEPT Delay 3I=Failed All EXCEPT iDDQ 2A=Failed Functional Test and Delay test Only 2B=Failed Stuck-at Test and Delay test Only 2C=Fail"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_15", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 15, "text": "l EXCEPT Stuck-at 3F=Failed All EXCEPT Functional 3P=Failed All EXCEPT Delay 3I=Failed All EXCEPT iDDQ 2A=Failed Functional Test and Delay test Only 2B=Failed Stuck-at Test and Delay test Only 2C=Failed Stuck-at Test and IDDQ test Only 2D=Failed Functional Test and IDDQ test Only 2E=Failed Functional Test and Stuck-at test Only 2F=Failed IDDQ Test and Delay test Only XX=Test was not applied 0 1 2 3 4 5 6 7 8 9i0 Ii 12 13 14 15 16 17 18 19 20 21 0 ........................................... 1 ................ $$ $$ AF AF $$ 3F ............... 2............ 3P $$ AF iI iI $$ $$ $$ $$ $$ AF ......... 3 ........ iI $$ $$ AF $$ $$ $$ AF 2E $$ AF AF ......... 4 ........ 3F S$ $S $$ $$ $$ $$ $$ $$ .- 3F AF II $$ AF ..... 5 .... $$ $$ AF $$ $S AF AF 3F $$ $$ $$ $$ $$ $$ 3F $$ $$ AF .. 6 .... S$ $$ $$ $$ SS $$ $S $$ $$ $$ 3F $$ $$ $$ AF $$ AF AF .. 7 ...... $$ $$ AF $S $$ $$ $S AF .. $$ AF $$ 3F $$ $$ $$ $$ 8 .. AF AF $$ AF AF $$ $$ $$ $S $$ $$ $S AF $$ $$ $$ AF 3F 9 .... $S $$ $$ $$ $$ $$ $$ ., 3F $$ $$ $$ $$ $$ $$ $$ $$ $$ Am I0 ,. $S $$ AF $$ AF $$ $S AF $$ 3F $$ $$ $$ AE $$ $$ $$ $$ $$ II .... 2EiI 3F $$ 3F $$ $$ 3F $$ $$ .. $$ $$ $$ 3F S$ 3F AF 3F 12 .... 3F S$ AF AF .. $$ $$ $$ II $$ "}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_16", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 16, "text": ", 3F $$ $$ $$ $$ $$ $$ $$ $$ $$ Am I0 ,. $S $$ AF $$ AF $$ $S AF $$ 3F $$ $$ $$ AE $$ $$ $$ $$ $$ II .... 2EiI 3F $$ 3F $$ $$ 3F $$ $$ .. $$ $$ $$ 3F S$ 3F AF 3F 12 .... 3F S$ AF AF .. $$ $$ $$ II $$ __ $$ AF $$ $$ $$ .. $$ .. 13 .... SS AF $S 3F $$ AF $$ $$ $$ AF $$ AF S$ $$ AF $$ AF ..... 14 ........ $S AF SS __ AF __ AF $$ AF .. $$ $$ SS $$ ....... l_........ ssAv_ssss3FssAF__A_AF..SS......... 16 .......... $$ ..$$ S$ S$ ,. 3F S$ AF AF ..AF ......... 17 ................ AF ........ AF AF ............. Figure 1.Typical WaterMap Bin 0No.Passing Functional &It_Do 6OODelay__ndStuck-at Failures%Failsafter Functional andIDt_ 0.17 1 1584 15 0.94 2 2378 19 0.79 3 2533 15 0.59 4 2109 23 1.08 5 1468 12 0.81 6 814 11 1.33 7 308 5 1.60 8 87 1 1.14 LotAverage 11881 56 0.86 Table1\"BinningresultsforExperiment #1 Bin 7 8 LotAverageNo.PassingStuck-at &ID_ 590 1547 2379 2526 2110 1506 824 312 87 11881Delayand %FailsafterStuck-at Functional Failures andIDoq 1 0.17 9 12 11 7 90.58 0.13 0.47 0.52 0.46 1.08 3 0.95 1 1.14 56 0.47 Table2:Binning results forExperiment #2 Bin No.PassingStuck-at &IDoQDelayand Functional Failures 43%FailsafterStuck-at andIDr_ 3.45 0 1205 1 2322 117 4.80 2 2746 164 5.64 3 2"}
{"id": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf::chunk_17", "source": "Binning for IC Quality_Experimental Studies on the Sematech Data.pdf", "chunk_index": 17, "text": ".08 3 0.95 1 1.14 56 0.47 Table2:Binning results forExperiment #2 Bin No.PassingStuck-at &IDoQDelayand Functional Failures 43%FailsafterStuck-at andIDr_ 3.45 0 1205 1 2322 117 4.80 2 2746 164 5.64 3 2491 149 5.64 4 1824 120 6.17 5 1203 98 7.53 6 611 48 7.28 7 198 24 10.81 8 49 3 5.77 LotAverage 12649 766 6.06 Table3:Binning results forExperiment #3 Bin No.Passing DC Failures a_erDC %Fails afterDCTests Tests Tests 0 1 0 0.00 1 9 1 11.11 2 39 0 0.00 3 108 9 8.33 4 224 14 6.25 5 297 21 7.07 6 324 41 12.70 7 194 31 16.0 8 91 19 20.9 LotAverage 1287 136 10.57 Table4.Results from[7]with9Bins"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_0", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 0, "text": "Vol.:(0123456789)The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 https://doi.org/10.1007/s00170-023-12939-0 ORIGINAL ARTICLE Contrastive deep clustering for detecting new defect patterns in wafer bin maps Insung Baek1 ¬∑ Seoung Bum Kim1 Received: 26 July 2023 / Accepted: 28 December 2023 / Published online: 5 January 2024 ¬© The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024 Abstract Wafer bin maps (WBMs) data, presented as images, play a critical role in identifying defects in the semiconductor industry. Thus, accurately classifying WBM defect patterns is essential to maintain high quality and enhance the overall yield. How - ever, the task of labeling and classifying WBM data, which are generated daily in the tens of thousands or more, presents a challenge for experts. Recently, with advancements in artificial intelligence research, there has been a surge in efforts to automatically classify WBM defect patterns. Nevertheless, existing studies have primarily focus on classifying known defect patterns using labels. However, in the real-world semiconductor industry, new defect patterns are constantly "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_1", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 1, "text": " patterns. Nevertheless, existing studies have primarily focus on classifying known defect patterns using labels. However, in the real-world semiconductor industry, new defect patterns are constantly emerging in addition to the known patterns. In this study, we propose the contrastive deep clustering (CODEC) for wafer bin maps that identifies new defective patterns in WBMs while simultaneously clustering these patterns into multiple defects without using labels. We use a contrastive loss function to address the challenges associated with a limited number of novel defect patterns. We demonstrate the effectiveness of our proposed methodology in accurately classifying new defect patterns using open data WM-811 k. Keywords Semiconductor manufacturing ¬∑ Wafer bin map ¬∑ Deep clustering ¬∑ New defect pattern classification ¬∑ Contrastive learning ¬∑ Deep learning 1 Introduction The wafer, integral to the semiconductor manufacturing process, serves as the substrate upon which semiconduc- tor devices are fabricated [1 , 2]. A single wafer contains hundreds of semiconductor chips. To ensure high yield and quality, it is crucial to swiftly identify and address defects [3 , 4]. Industry engineers"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_2", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 2, "text": "ces are fabricated [1 , 2]. A single wafer contains hundreds of semiconductor chips. To ensure high yield and quality, it is crucial to swiftly identify and address defects [3 , 4]. Industry engineers conduct inspections, such as electri- cal die sorting (EDS), to detect defective wafers [5 ‚Äì7]. EDS generates the wafer bin map (WBM) data representing the defect status of each chip on the wafer. As shown in Fig. 1, WBM data is presented as an image, indicating each chip defects or not. These images reveal patterns associated with the causes of defects, aiding in tracing their root causes. However, because of the large volume of WBMs produced daily, it is impractical for engineers to manually classify them. Recent studies have used machine learning and deep learning algorithms to automate the classification of such large volumes of WBM data [8 ‚Äì10]. However, existing studies have limitations in encompass- ing all practical issues related to the WBM defect classifica- tion. First, in the semiconductor industry, both known and new defect patterns constantly emerge in actual WBM data [5, 6, 9]. When a known defect pattern occurs, experts can identify the cause and take appropriate actio"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_3", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 3, "text": "semiconductor industry, both known and new defect patterns constantly emerge in actual WBM data [5, 6, 9]. When a known defect pattern occurs, experts can identify the cause and take appropriate action based on their experience. However, when a novel defect pattern appears, it becomes more challenging to promptly determine its cause. This increases the time required to trace the root cause of the defect and take corrective action, thereby increasing the risk of quality incidents. Hence, models should be capable of detecting both known and new defect patterns. Second, multiple new defect patterns can appear simultaneously. Therefore, the model needs to accurately group and clas- sify identical patterns among the new defects to identify process paths that lead to such defects [ 11]. By accurately identifying new fault patterns, the root cause of the fault can be pinpointed, minimizing defect occurrence and preventing * Seoung Bum Kim sbkim1@korea.ac.kr Insung Baek insung_baek01@korea.ac.kr 1 School of Industrial and Management Engineering, Korea University, Seoul 02841, Republic of Korea 3562 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 potentia"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_4", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 4, "text": "kr 1 School of Industrial and Management Engineering, Korea University, Seoul 02841, Republic of Korea 3562 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 potential incidents. Finally, unlike known defect patterns that have already been directly inspected by engineers and assigned labels, these new defect patterns lack label infor - mation [6 , 9]. Ultimately, the timely detection of new defect patterns and the simultaneous clustering of multiple defect patterns are highly important for preventing major quality accidents in the semiconductor industry. Therefore, for the automatic classification of WBM defects, it is important to develop methods that can detect and classify novel defects without labels. However, previous studies on WBM analy - sis are limited to classifying known patterns using labels or detecting the existence of a new defect pattern [1, 5, 6, 8, 9]. Existing WBM studies focus on enhancing the performance of known defective patterns, even when using unlabeled data [8]. Moreover, in situations involving new defect patterns, some studies focus solely on detecting their presence based on their differences from existing ones [5 , 9]"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_5", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 5, "text": ", even when using unlabeled data [8]. Moreover, in situations involving new defect patterns, some studies focus solely on detecting their presence based on their differences from existing ones [5 , 9]. In contrast, this study proposes a method capable of identifying new defect patterns while simultaneously clustering these pat- terns into multiple defects without relying on label informa- tion. In this situation, deep clustering techniques, commonly used in computer vision, can effectively identity and clas- sify new patterns. Deep clustering groups similar patterns based on image features, without using labels, enabling the classification of patterns with different characteristics [12, 13]. Deep clustering uses a deep learning model to extract features from unlabeled images and subsequently conducts clustering. During this process, the clustering performance is enhanced by learning to group similar images together while distinguishing those with different characteristics. Deep clustering differs from zero-shot learning, which involves using labels for learning and subsequently detecting unseen classes that were not included the training set. Deep clustering is typically used for g"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_6", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 6, "text": "ing differs from zero-shot learning, which involves using labels for learning and subsequently detecting unseen classes that were not included the training set. Deep clustering is typically used for general image data with a sufficient volume of data. However, in the case of real WBM data, the number of new defect patterns is small. In this study, we propose the contrastive deep clustering (CODEC) for wafer bin maps that combines deep clustering with contrastive learning to enhance the classifying perfor - mance of very few new patterns [14, 15]. Our methodology extends the work of Huang et al. (2022), which used two different loss functions to train a deep clustering model [16]. They implemented an approach where samples with similar characteristics are trained to be closer, while the centers of dissimilar clusters, based on the pseudo labels, are trained to move apart. However, their study had limitations in that the performance was good only on general image data with a substantial number of samples. Consequently, we propose a methodology that incorporate a contrastive loss function to improve the classifying performance of new patterns. The use of a contrastive loss function wi"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_7", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 7, "text": "number of samples. Consequently, we propose a methodology that incorporate a contrastive loss function to improve the classifying performance of new patterns. The use of a contrastive loss function with negative samples enhances the effectiveness of classifying a small number of novel patterns. We use a traditional convolutional neural net- works (CNN) model to classify whether a pattern is known or new. Subsequently, the proposed CODEC is applied to the data predicted by the new patterns to group several of them. There are studies that classify previously new classes through multiple stages [17‚Äì 19]. Ren and Li (2021) pro- posed a two-stage method for addressing the open-set prob- lem in acoustic scene classification (ASC). After identifying the unknown scenes, the classification process proceeds to categorize the defined acoustic scene [17]. Wu et al. (2022) proposed a two-stage object detector that first determines whether a new object class or an existing object class and then distinguishes between multiple new class objects [18]. Guo et al. (2019) proposed a study to classify new classes in the radio frequency and Twitter data using a multi-stage deep classifier [19]. We condu"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_8", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 8, "text": "inguishes between multiple new class objects [18]. Guo et al. (2019) proposed a study to classify new classes in the radio frequency and Twitter data using a multi-stage deep classifier [19]. We conduct experiments across various scenarios to confirm the effectiveness of our proposed meth- odology in accurately classifying effectively classifies novel patterns when the number of new defect patterns is small. Specifically, with the use of the open data WM-811 K, we select certain classes as new patterns and conduct experi- ments by sampling a small number of them. Consequently, we demonstrate that the proposed methodology effectively classifies several new patterns, even in the absence of label Fig. 1 Examples of a wafer bin map 3563 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 information and with few new patterns data. The main con- tributions of this study are as follows: ‚Ä¢ A hybrid loss function that combines contrastive loss function with a deep clustering algorithm is proposed. The use of a contrastive loss function with negative sam- ples enhances the effectiveness of classifying a small number of novel patterns. Given the limited quanti"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_9", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 9, "text": "ep clustering algorithm is proposed. The use of a contrastive loss function with negative sam- ples enhances the effectiveness of classifying a small number of novel patterns. Given the limited quantity of new patterns in the WBMs, the probability of choosing negative samples with the same attributes as the input data is reduced. Consequently, the inclusion of negative samples facilitates the efficient classification of novel patterns by distinguishing data belonging to a distinct class from the input image. ‚Ä¢ The proposed method enables the classification of new patterns solely based on WBM image characteristics without label information. By using a deep clustering strategy that does not require label information, it facili- tates the grouping of WBM data with similar character - istics. ‚Ä¢ Before applying the proposed CODEC algorithm, it is necessary to classify patterns as either known or new. The traditional CNN model used for these classification tasks can be used without requiring any additional modi - fications to the existing model. The structure of this paper is as follows. Section 2 reviews existing studies on WBM classification and deep cluster - ing. Section 3 illustrate"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_10", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 10, "text": " any additional modi - fications to the existing model. The structure of this paper is as follows. Section 2 reviews existing studies on WBM classification and deep cluster - ing. Section 3 illustrates the details of the proposed CODEC method. Section 4 presents the qualitative and quantitative experimental results. Section 5 contains our concluding remarks and directions for future research. 2 Related works 2.1 Wafer bin map classification The classification of WBMs is significant in the semicon- ductor industry, and various algorithms have been used for studying this issue. Wu et al. (2015) publicly released the ‚ÄúWM-811 K‚Äù WBM dataset and used a support vector machine algorithm for classifying wafer defects [1 ]. Piao et al. (2018) used a radon transform to extract wafer fea- tures and used a multiple decision tree ensemble method for defect classification [20]. However, these methods face challenges in maintaining classification precision as the complexity of wafer defect patterns increases. Recently, sub- stantial advancements have been made in using CNN for the analysis of WBM image data. Lee et al. (2017) accurately identified wafer defect patterns using a CNN model [21]. Nak"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_11", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 11, "text": "ncreases. Recently, sub- stantial advancements have been made in using CNN for the analysis of WBM image data. Lee et al. (2017) accurately identified wafer defect patterns using a CNN model [21]. Nakazawa and Kulkarni (2018) achieved promising results in recognizing intricate patterns in both real and simulated wafer map image data using a CNN model [19]. Kyeong and Kim (2018) proposed a strategy for defect classification that considers multiple patterns on a wafer, in contrast to conventional methods that focus on a singular pattern [22]. However, these studies used supervised learning, requiring labels, and did not consider potential new defect patterns in the WBM. In the semiconductor industry, new defect pat- terns without labels constantly appear, making it essential to develop an approach that can accommodate them. Shim et al. (2020) demonstrated that using uncertainty- based sample selection methods that prioritize samples with the highest influence on performance can yield high classifi- cation results even with limited labeled data [23]. Kahng and Kim (2021) proposed using pretext-invariant representation learning, which is one of the self-supervised learning frame- works"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_12", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 12, "text": "h classifi- cation results even with limited labeled data [23]. Kahng and Kim (2021) proposed using pretext-invariant representation learning, which is one of the self-supervised learning frame- works incorporating CNNs for efficient classification using unlabeled data [8 ]. While these studies leverage unlabeled data, they overlook the potential emergence of new patterns in real-world scenarios. Jang et al. (2020) addressed this issue by proposing the support weighted ensemble model, specifically designed to detect new patterns [5 ]. Jang and Lee (2023) introduced an open-set recognition model using probability scores obtained from computed reconstruction errors and random network errors [6 ]. Although these stud- ies make progress in identifying new patterns within WBMs, they are less effective in simultaneously classifying multiple new patterns. Jin et al. (2019) proposed a pattern clustering technique for WBMs using density-based spatial cluster - ing of applications with noise (DBSCAN) [24]. Park et al. (2021) introduced a classification method that includes label reassignment based on a Siamese network approach [11]. While pattern clustering and label reassignment methods hav"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_13", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 13, "text": "SCAN) [24]. Park et al. (2021) introduced a classification method that includes label reassignment based on a Siamese network approach [11]. While pattern clustering and label reassignment methods have shown potential in identifying new patterns, there is a lack of classifying new defect patterns tailored to the unique characteristics of WBMs, such as feature similarity across classes and limited quantities of new pattern data. In this study, we propose a CODEC that can accurately classify multiple new patterns by effectively solving the problems caused by the similarity between WBM classes and the scar - city of new pattern data. 2.2 Deep clustering Deep clustering methods extract vectors that summarizes the high-dimensional data such as image data using deep learning algorithms [25]. Xie et al. (2016) introduced deep embedded clustering that applies k-means clustering to vec- tors representing image features obtained from an autoen- coder model [26]. Gou et al. (2016) proposed an improved version of the deep embedded clustering that incorporates a clustering loss in addition to the reconstruction loss com- puted in the autoencoder [27]. Huang et al. (2020) proposed the partition "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_14", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 14, "text": "roved version of the deep embedded clustering that incorporates a clustering loss in addition to the reconstruction loss com- puted in the autoencoder [27]. Huang et al. (2020) proposed the partition confidence maximization (PICA) algorithm that 3564 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 maximizes confidence by forming clusters with similar sam- ples [28]. The PICA algorithm assigns a confidence value of one when all images in a cluster belong to the same class, while the confidence value decreases if the cluster includes images from diverse classes. Therefore, they essentially aim to maximize this confidence value by effectively creating clusters. However, this study has a limitation in that it solely relies on clustering by confidence and disregards both the distances between distinct clusters and the distances between disparate clusters. Recently, the advancement of self-supervised learn- ing methods, capable of extracting salient features from input data without labels, has improved the performance of deep clustering. Especially, in computer vision area, self- supervised learning has demonstrated it effectiveness in extracting featu"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_15", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 15, "text": "es from input data without labels, has improved the performance of deep clustering. Especially, in computer vision area, self- supervised learning has demonstrated it effectiveness in extracting feature vectors for clustering. This is achieved by brining similar samples closer together in the embedding space while keeping dissimilar sample far apart. Li et al. (2021) introduced contrastive clustering (CC) that integrates contrastive learning at both the sample and cluster levels [29]. They performed contrastive learning using vectors and pseudo labels that well-summarized samples within a batch. In the embedding space, different clusters are trained to be farther apart, which improves clustering performance. Huang et al. (2022) identified an issue known as ‚Äúclass col- lision‚Äù in contrastive learning that negatively impacts clus- tering performance [16]. The class collision problem arises when semantically identical samples are mistakenly included in the negative samples. To address this, they proposed pro - totype scattering and positive sampling (ProPos) that com- bines a contrastive learning loss function to separate clusters and a bootstrap your own latent (BYOL) loss function f"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_16", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 16, "text": "s, they proposed pro - totype scattering and positive sampling (ProPos) that com- bines a contrastive learning loss function to separate clusters and a bootstrap your own latent (BYOL) loss function for to aggregate similar samples [30]. While these methods have demonstrated strong performance on large datasets such as CIFAR-10, CIFAR-20, STL-10, and ImageNet, they may not be well-suited for clustering new patterns in WBM because of the limited amount of data. Therefore, in this study, we propose CODEC that combines the contrastive loss function with the two loss functions used in ProPos. This approach aims to accurately distinguish new patterns occurring in small numbers. 3 Proposed method‚ÄîCODEC In practical industrial settings, it is crucial to determine whether newly collected test data represents a novel defect pattern or one that is already known. This uncertainty neces- sitates a reliable approach to distinguish between the two. To address this, we initially develop a standard CNN model based on ResNet-18, specifically designed for the classifi- cation of both known defective patterns and potential new patterns. The CNN model is trained using labeled data of previously known "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_17", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 17, "text": "N model based on ResNet-18, specifically designed for the classifi- cation of both known defective patterns and potential new patterns. The CNN model is trained using labeled data of previously known defective patterns. During the prediction phase, the CNN model generates a logit vector, which is then used to determine whether the test data represents a new defect pattern or one of the known patterns. To make this determination, we calculate the median of the logit vector for each class. Next, we compute the distance between this median and all data points within the corresponding class. These distances are then sorted by class. To establish a ref- erence distance, we identify any distance that exceeds 70% from the center. If the new test data surpasses this reference distance for all classes, it is identified as new defect pat - tern data. This method provides a systematic way to discern whether the test data represents a novel defect pattern or one that is already known, aiding in the accurate classification of the data. The proposed CODEC aims to cluster and differentiate multiple new defect patterns in the WBM process of the semiconductor industry. An overview of the CODEC meth"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_18", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 18, "text": "e accurate classification of the data. The proposed CODEC aims to cluster and differentiate multiple new defect patterns in the WBM process of the semiconductor industry. An overview of the CODEC method is presented in Fig. 2. The loss function used in CODEC builds upon the ProPos method, which has demonstrated superior performance among deep clustering methods for general image data [ 16]. The ProPos loss function combines two components: the prototype scattering loss (PSL) and positive sampling alignment (PSA), both of which contrib- ute to improving clustering performance. The PSL encour - ages the centers of different clusters to be more distant from each other while ensuring that the calculated centroids of the same cluster, as derived from the query encoder and key encoder, learn to be close to each other. Concurrently, the PSA enables samples with similar characteristics to cluster together. However, the effectiveness of the ProPos algorithm on new and rare defect patterns in WBM, which are inher - ently scarce, may not be optimal. To address this limita- tion, we propose the CODEC loss function, which combines the ProPos loss function with a contrastive loss component [14‚Äì1"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_19", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 19, "text": "M, which are inher - ently scarce, may not be optimal. To address this limita- tion, we propose the CODEC loss function, which combines the ProPos loss function with a contrastive loss component [14‚Äì16]. The inclusion of the contrastive loss function aims to enhance the clustering of a small number of new pattern data in WBMs. Equation 1 represents the loss function of the proposed CODEC method, with /u1D6FCpsl , /u1D6FCpsa , and /u1D6FCc repre - senting hyperparameters that can be adjusted to control the importance of each component in the overall loss function. Below, we provide a more detailed explanation of each com- ponent of the loss function. The first loss function used in the CODEC is the PSL. The PSL function calculates the distances between the centroids of clusters formed during the learning process. Pseudo-labels for PSL are generated using the k-means algo- rithm applied within a batch. In our study, we set the value of ‚Äú k ‚Äù in the k-means algorithm to seven, which corresponds to the total number of predicted new defect patterns. The (1) L=/u1D6FCpslLpsl+/u1D6FCpsaLpsa+/u1D6FCcLc, 3565 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì357"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_20", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 20, "text": "sponds to the total number of predicted new defect patterns. The (1) L=/u1D6FCpslLpsl+/u1D6FCpsaLpsa+/u1D6FCcLc, 3565 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 computation of PSL is defined by Eq. 2, which incorporates the values of /u1D707k and /u1D707/uni2032.var k . Here, /u1D707k represents the cluster center computed using the vector of the query network, while /u1D707/uni2032.var k corresponds to the cluster center calculated using the vector of the key network. Similar to the loss used in traditional contrastive learning, the PSL aims to minimize the distance between /u1D707k and /u1D707/uni2032.var k for samples within the same cluster. Simultaneously, it encourages the centers derived from dif- ferent clusters to be distant from each other. This encourages distinct clustering of samples belonging to different defect patterns while promoting compactness within each cluster. (2)Lpsl=1 KKÔøΩ k=1‚àílogexpÔøΩ/u1D707T k/u1D707ÔøΩ k /u1D70FÔøΩ expÔøΩ/u1D707T k/u1D707ÔøΩ k /u1D70FÔøΩ +‚àëK j=1 j‚â†kexpÔøΩ/u1D707T k/u1D707j /u1D70FÔøΩ, (3) /u1D707k=‚àë x‚àà/u1D6FDp(kÔøΩx)f(x) ‚Äñ‚àë x‚àà/u1D6FDp(kÔøΩx)f(x)‚Äñ2,In addition to the PSL, the CODEC incorporates the PSA loss function, "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_21", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 21, "text": "707T k/u1D707ÔøΩ k /u1D70FÔøΩ +‚àëK j=1 j‚â†kexpÔøΩ/u1D707T k/u1D707j /u1D70FÔøΩ, (3) /u1D707k=‚àë x‚àà/u1D6FDp(kÔøΩx)f(x) ‚Äñ‚àë x‚àà/u1D6FDp(kÔøΩx)f(x)‚Äñ2,In addition to the PSL, the CODEC incorporates the PSA loss function, which aims to bring samples with simi- lar characteristics closer together in the embedding space. The formulation of the PSA loss function is inspired by the loss function used in BYOL (bootstrap your own latent), one of the noncontrastive-based self-supervised learning methods [30]. The PSA loss function, as depicted in Eq. 5, calculates the mean squared error loss between the vector generated by the predictor in the overall model architecture and the vector produced by the target network. Notably, these vectors represent augmented versions of the same source image. By minimizing the PSA loss, the model learns representations that encourage samples with simi- lar attributes to cluster together in the embedding space. This promotes the grouping of samples sharing common characteristics, facilitating effective pattern recognition and clustering of defect patterns in the WBM process.(4) /u1D707ÔøΩ k=‚àë x‚àà/u1D6FDp(kÔøΩx)fÔøΩ(x) ‚Äñ‚àë x‚àà/u1D6FDp(kÔøΩx)fÔøΩ(x)‚Äñ2. Fig. 2 Overview of the CODEC algorithm 3"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_22", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 22, "text": "acilitating effective pattern recognition and clustering of defect patterns in the WBM process.(4) /u1D707ÔøΩ k=‚àë x‚àà/u1D6FDp(kÔøΩx)fÔøΩ(x) ‚Äñ‚àë x‚àà/u1D6FDp(kÔøΩx)fÔøΩ(x)‚Äñ2. Fig. 2 Overview of the CODEC algorithm 3566 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 To enhance the model‚Äôs ability to discriminate a small number of new patterns, the CODEC incorporates a con - trastive loss function based on the MoCo algorithm [14, 15]. The contrastive learning process, illustrated in Fig. 3, involves a query encoder and a key encoder. Pairs of data obtained through two different augmentations of the same sample are designated as positive pairs. One pair is pro- cessed by the query encoder to generate a query vector, and the other pair is fed into the key encoder to generate a posi- tive key. Furthermore, a subset of the remaining samples is selected as negative samples, and their representations are computed using the key encoder. These representations are stored in a dictionary of negative keys. The learning objec- tive of contrastive learning is twofold: to bring the query and positive keys closer together in the embedding space and to push the query and negati"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_23", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 23, "text": "a dictionary of negative keys. The learning objec- tive of contrastive learning is twofold: to bring the query and positive keys closer together in the embedding space and to push the query and negative keys apart. By training the model with this objective, the encoder learns representa- tions that facilitate the discrimination of positive pairs from negative pairs. One important consideration in contrastive learning is the selection of negative samples. In our meth - odology, negative samples are chosen from all other sam- ples, excluding the sample itself that has undergone different augmentations. Given the numerical scarcity of data corre- sponding to the new patterns per class, the negative samples have a higher likelihood of encompassing data from different classes. This approach proves effective in classifying new (5) Lpsa=‚Äñg(v)‚àífÔøΩÔøΩx+ÔøΩ‚Äñ2 2, (6) v=f(x)+/u1D70E/u1D716,where/u1D716 ‚àºN(0,I)WBM defect patterns by training the model to separate a small number of new defect patterns. In Eq. 7, q represents the query representation, k+ denotes the representation of the positive key, and k‚àí refers to the representation of the negative keys. /u1D70F represents a temperature hyperparam"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_24", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 24, "text": "n Eq. 7, q represents the query representation, k+ denotes the representation of the positive key, and k‚àí refers to the representation of the negative keys. /u1D70F represents a temperature hyperparameter that controls the scale of the similarity scores in the follow - ing contrastive loss function: 4 Experiments and results 4.1 Data In our experiments, we use the WM-811 K dataset, which is an open dataset containing real WBM samples. The dataset comprises a total of 811,457 WBMs, out of which 172,950 WBMs have labeled data. To focus on classifying new defect patterns, we exclude the ‚Äúnone‚Äù class that represents samples without a specific pattern. We also exclude the ‚Äúnear-full‚Äù class, which closely resembles the random class and lacks meaningful patterns. Our experiment involves seven defect patterns: edge-ring, edge-loc, center, loc, scratch, random, and donut. Because the WBM data represent categorical information, where values of zero, one, or two indicate the background or defect status for each chip, we preprocess the data into a one-hot vector representation. Furthermore, we standardize the sample size to 32 √ó 32 pixels to ensure (7) Lc=‚àílogexp(q‚àôk+‚àï/u1D70F) exp(q‚àôk+‚àï/u1D70F"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_25", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 25, "text": "status for each chip, we preprocess the data into a one-hot vector representation. Furthermore, we standardize the sample size to 32 √ó 32 pixels to ensure (7) Lc=‚àílogexp(q‚àôk+‚àï/u1D70F) exp(q‚àôk+‚àï/u1D70F)+‚àë k‚àíexp(q‚àôk‚àí‚àï/u1D70F). Fig. 3 Structure of contrastive learning in WBM data 3567 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 consistency across all samples. Finally, each sample is trans- formed into an image with dimensions of 3 √ó 32 √ó 32, which served as the input data for our experiments. The aim of this study is to achieve accurate classification performance despite the limited availability of new defect pattern data in the semiconductor industry. To simulate this scenario, we sample 3%, 4%, and 5% of the total data for known defect patterns to represent the quantity of new defect pattern data. Furthermore, we establish four different scenarios to simulate various combinations of new defect patterns encountered in real-world situations. In Scenario A, the selected new patterns are scratch, donut, and random. Scenario B includes loc, scratch, and random as new pat- terns. For Scenario C, we choose center, edge-loc, and loc as new patterns, a"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_26", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 26, "text": "ario A, the selected new patterns are scratch, donut, and random. Scenario B includes loc, scratch, and random as new pat- terns. For Scenario C, we choose center, edge-loc, and loc as new patterns, and Scenario D consists of edge-loc, loc, and random as new patterns. Figure 4 provides an overview of each scenario‚Äôs known and new pattern dat. To conduct the experiments, we divide the data into training, validation, and testing sets, with proportions of 80%, 10%, and 10%, respectively for each scenario. Table 1 presents the number of samples used for training, validation, and testing in Sce- nario A, emphasizing the scarcity of data for each new defect pattern compared to the data for known defect patterns used in training and testing. The objective of these experiments is to assess the effectiveness of the proposed methodology in accurately distinguishing new patterns, even when the number of new pattern data is extremely limited. 4.2 Experimental setting During the optimization process, we used the adaptive moment estimation (ADAM) optimizer. Specifically, we set the learning rate to 0.001 and the weight decay factor to 0.00005. The batch size was chosen as 128, and the total numb"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_27", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 27, "text": "s, we used the adaptive moment estimation (ADAM) optimizer. Specifically, we set the learning rate to 0.001 and the weight decay factor to 0.00005. The batch size was chosen as 128, and the total number of learning epochs was set to 1000. When incor - porating the momentum contrastive learning component, Fig. 4 Overview of known and new patterns in experiment scenarios. The new pattern reflects the possibility of various combinations occurring Table 1 Number of data in the model that classifies known and new patterns in Scenario AKnown/new Patterns (classes) Original data Train Validation Test Known patterns Edge-Ring 9680 7744 968 968 Edge-Loc 5189 4151 519 519 Center 4294 3434 430 430 Loc 3593 2875 359 359 New patterns Scratch 1193 0 0 546 Random 866 0 0 546 Donut 555 0 0 546 Total 25,370 18,204 2276 3914 3568 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 the dictionary size was determined based on the sampling ratio. For a sampling ratio of 0.05, the dictionary size was set to 1024. For sampling ratios of 0.04 and 0.03, the dic- tionary size was adjusted to 512. These adjustments were made to accommodate the total data volume according to th"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_28", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 28, "text": ", the dictionary size was set to 1024. For sampling ratios of 0.04 and 0.03, the dic- tionary size was adjusted to 512. These adjustments were made to accommodate the total data volume according to the sampling ratio. To ensure the robustness and reliability of the results, each method was tested five times across differ - ent scenarios, with the seed value varied for each run. This variability in the seed value helps account for any potential bias introduced by the random initialization of the model. The hyperparameters /u1D6FCpsl and /u1D6FCpsa in the loss function of the proposed CODEC were matched with those used in the ProPos study [16]. Additionally, the hyperparameter /u1D6FCc was set to 0.1 to balance the contribution of the contrastive loss component. For evaluation, we used the accuracy metric, which is widely used in multiclass classification problems. Accuracy is calculated as the ratio of data correctly clustered into their actual class to the total number of data. It provides a measure of the model‚Äôs performance in correctly classify - ing samples into their respective defect patterns. 4.3 Results Table 2 presents the classification performance for both gen- eral know"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_29", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 29, "text": "ides a measure of the model‚Äôs performance in correctly classify - ing samples into their respective defect patterns. 4.3 Results Table 2 presents the classification performance for both gen- eral known patterns and new patterns. The average accu- racy for known classes and the accuracy for new classes in each scenario exceeded 0.6, indicating the initial success of the conventional CNN model in distinguishing between known and new patterns. This step is crucial because it iso- lates the new patterns for further analysis using CODEC. Table 3 provides insights into the quantity of data classified as unknown. As the sampling ratio decreases from 0.05 to 0.03, the volume of data per scenario also decreases. This reduction in data quantity aligns with the nature of WBM data, where new patterns are relatively rare. Hence, Table 2 and 3 collectively demonstrate that the experimental setup is appropriately configured for the classification of minority novel patterns, taking into account the scarcity of such pat- terns in the WBM data. Table 4 displays the accuracy results for each scenario and sampling ratio using the applied methodology. Nota- bly, CODEC achieved the highest performance i"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_30", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 30, "text": "arcity of such pat- terns in the WBM data. Table 4 displays the accuracy results for each scenario and sampling ratio using the applied methodology. Nota- bly, CODEC achieved the highest performance in 11 out of the 12 scenarios, demonstrating its superiority over other methods. PICA [28], which used confidence values within clusters, exhibited the weakest performance across most sce- narios. Similarly, CC [29], which incorporated contrastive learning for both samples and clusters, demonstrated rela- tively low performance in most scenarios, except for Sce- nario A. These results suggest that both PICA and CC are not well-suited for situations with a small number of class- specific data. Although ProPos [16] outperformed PICA and CC in the majority of scenarios, its performance remained inferior compared to the proposed CODEC. This indicates that ProPos may not be the optimal choice for clustering new WBM patterns when dealing with limited data per class. In contrast, the CODEC consistently demonstrated superior performance in most scenarios. This highlights the effective- ness of CODEC in accurately classifying a small number of new patterns into their respective clusters in the W"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_31", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 31, "text": "ently demonstrated superior performance in most scenarios. This highlights the effective- ness of CODEC in accurately classifying a small number of new patterns into their respective clusters in the WBM process. These findings affirm the superiority of CODEC over other methods and its potential to handle the challenges posed by limited data for new defect patterns in the semi- conductor industry. To provide qualitative validation of the classification ability of CODEC, t-SNE visualization was used. Figure 5 displays the t-SNE visualization results for PICA, CC, Pro- Pos, and CODEC. These results align with the quantitative findings, illustrating the performance of each method in clas - sifying patterns when data volumes are limited per class. PICA and CC struggled to achieve effective classification, as evidenced by the substantial overlaps observed in their t-SNE visualizations. This indicates a difficulty in achieving clear class differentiation when faced with limited data. Pro- Pos demonstrated relatively better classification compared to PICA and CC, but there were still noticeable overlaps, suggesting a certain level of ambiguity in class separation. In contrast, CODEC exhibi"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_32", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 32, "text": " demonstrated relatively better classification compared to PICA and CC, but there were still noticeable overlaps, suggesting a certain level of ambiguity in class separation. In contrast, CODEC exhibited improved class separation com- pared to ProPos, as indicated by the t-SNE visualization. Table 2 Known and new class accuracy by sampling ratioSampling ratio Known/unknown Scenario A Scenario B Scenario C Scenario D Average 0.05 Known class 0.620 0.660 0.767 0.750 0.699 New class 0.584 0.616 0.669 0.734 0.651 0.04 Known class 0.648 0.693 0.717 0.722 0.695 New class 0.564 0.676 0.687 0.638 0.641 0.03 Known class 0.609 0.708 0.673 0.726 0.695 New class 0.609 0.629 0.642 0.688 0.642Table 3 Number of data predicted by new patterns Sampling ratio Scenario A Scenario B Scenario C Scenario D 0.05 2197 2118 1270 1790 0.04 1975 1825 1113 1453 0.03 1859 1464 969 1204 3569 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 This qualitative validation further supports the effective - ness of CODEC in accurately clustering new patterns in the WBM process, even when the data quantity for each class is small. The t-SNE visualizations provide additional evidence of"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_33", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 33, "text": "rts the effective - ness of CODEC in accurately clustering new patterns in the WBM process, even when the data quantity for each class is small. The t-SNE visualizations provide additional evidence of CODEC‚Äôs ability to handle the challenges posed by lim- ited data and reinforce its superiority over other methods in achieving robust and distinct class separation. 5 Conclusions and future research The detection and accurate classification of new defect pat- terns in the semiconductor industry are of utmost impor - tance to prevent quality failures and ensure product reliabil- ity. This study has highlighted the significance of timely identification and resolution of these new patterns. By effectively applying the contrastive loss method, we have demonstrated the capability to classify new patterns even when the number of samples per class is limited. The use of contrastive loss enables tracking shared histories among wafers exhibiting new patterns, thereby preventing potential quality issues. This research marks a pioneering applica- tion of deep clustering, a commonly used method in general image analysis, to the specific domain of WBM data. Lev - eraging the WM-811 K open dataset,"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_34", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 34, "text": "ssues. This research marks a pioneering applica- tion of deep clustering, a commonly used method in general image analysis, to the specific domain of WBM data. Lev - eraging the WM-811 K open dataset, we have successfully showcased the feasibility of classifying emerging patterns, even with a scarcity of samples. Specifically, our proposed CODEC algorithms showcase enhanced classification of a limited number of new patterns through the application of the contrastive loss. This enhancement is attributed to the reduced probability of selecting a small set of new pattern data as the negative sample. As a result, when compared to established deep clustering methods, we provide both quan- titative and qualitative evidence supporting the effectiveness of our approach in effectively distinguishing and classifying each minority new pattern. The findings of this study make a valuable contribution to the advancement of quality control processes in the semiconductor industry. The early identi- fication and resolution of emerging issues facilitated by the accurate classification of new defect patterns can signifi- cantly improve overall product quality and reliability. This research serves as "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_35", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 35, "text": "cation and resolution of emerging issues facilitated by the accurate classification of new defect patterns can signifi- cantly improve overall product quality and reliability. This research serves as a stepping stone toward enhancing quality assurance practices, enabling proactive measures to ensure the continued excellence of semiconductor products. In our future studies, we plan to investigate techniques that can enhance the selection of negative samples for improved identification and categorization of novel pat - terns. Currently, the contrastive loss function considers all samples, excluding the input data itself, as potential negative samples. However, this approach has limitations because the negative samples may still include data from the same class as the input, which can hinder accurate clas- sification. To address this limitation, we intend to develop a strategy for selecting negative samples that possess Table 4 Accuracy of the predicted unknown class by methodology and sampling ratio (For each sampling ratio, the accuracy of the best-performing deep clustering method in each scenario is highlighted in bold, and the value in parentheses represents the standard deviatio"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_36", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 36, "text": "mpling ratio (For each sampling ratio, the accuracy of the best-performing deep clustering method in each scenario is highlighted in bold, and the value in parentheses represents the standard deviation from five repetitions.)Sampling ratio Methodology Scenario A Scenario B Scenario C Scenario D Average 0.05 PICA 0.384 (0.02)0.384 (0.05)0.410 (0.02)0.440 (0.02)0.404 CC 0.482 (0.03)0.448 (0.03)0.395 (0.03)0.398 (0.03)0.431 ProPos 0.468 (0.04)0.442 (0.04)0.429 (0.05)0.419 (0.03)0.439 CODEC (proposed) 0.484 (0.03)0.477 (0.04)0.430 (0.05)0.448 (0.03)0.460 0.04 PICA 0.411 (0.03)0.347 (0.02)0.455 (0.05)0.428 (0.07)0.410 CC 0.513 (0.04)0.450 (0.03)0.426 (0.03)0.420 (0.03)0.452 ProPos 0.468 (0.01)0.443 (0.02)0.460 (0.06)0.512 (0.08)0.471 CODEC (proposed) 0.522 (0.04)0.452 (0.03)0.487 (0.05)0.520 (0.09)0.495 0.03 PICA 0.414 (0.04)0.327 (0.01)0.452 (0.06)0.437 (0.03)0.407 CC 0.544 (0.02)0.458 (0.02)0.465 (0.04)0.442 (0.07)0.477 ProPos 0.483 (0.02)0.473 (0.01)0.562 (0.04)0.452 (0.04)0.492 CODEC (proposed) 0.519 (0.03)0.475 (0.01)0.571 (0.04)0.504 (0.04)0.517 3570 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 significantly contrasting properties compared to"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_37", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 37, "text": "roposed) 0.519 (0.03)0.475 (0.01)0.571 (0.04)0.504 (0.04)0.517 3570 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 significantly contrasting properties compared to the input data. The contrastive loss function becomes meaningful when data points with different labels but close distances in the embedding space are separated. Therefore, we aim to approach this by generating pseudo-labels based on deep clustering. Initially, we intend to select data with different pseudo-labels and then calculate the similarity to desig- nate data within a certain distance as negative samples. By incorporating this refined selection method into the con- trastive loss function, we anticipate an enhanced ability to identify and classify unfamiliar patterns. This approach will enable the model to focus on learning discriminative features that differentiate between the input data and nega- tive samples, leading to improved performance in detect- ing and categorizing novel patterns. Through these future research efforts, we aim to advance the state-of-the-art in pattern recognition and contribute to the development of more robust and effective methodologies for the dete"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_38", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 38, "text": "patterns. Through these future research efforts, we aim to advance the state-of-the-art in pattern recognition and contribute to the development of more robust and effective methodologies for the detection and classification of new defect patterns in the semiconduc - tor industry.Author contribution All authors equally contributed to this study: design, experiment, and data analysis. Funding This work was supported in part by the Korea Institute for Advancement of Technology (KIAT) grant funded by the Korea Government (MOTIE) (The Competency Development Program for Industry Specialist) under Grant P0008691 and the National Research Foundation of Korea grant funded by the Korea government (RS-2022‚Äì00144190). Data availability All data are fully available without restriction. The dataset used in this study is available from the following website: https:// www. kaggle. com/ datas ets/ qingyi/ wm811k- wafer- map. Declarations Ethics approval Not applicable. Consent to participate We hereby voluntarily agree to participate in this research. Consent for publication We all give our consents for this research to be published in IJAMT. Competing interests The authors declare no competing in"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_39", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 39, "text": " voluntarily agree to participate in this research. Consent for publication We all give our consents for this research to be published in IJAMT. Competing interests The authors declare no competing interests. Fig. 5 Comparing representations of PICA, CC, ProPos, and CODEC using T-SNE 3571 The International Journal of Advanced Manufacturing Technology (2024) 130:3561‚Äì3571 References 1. Wu MJ, Jang JSR, Chen JL (2014) Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Trans Semicond Manuf 28(1):1‚Äì12. https:// doi. org/ 10. 1109/ TSM. 2014. 23642 37 2. Arif M, Rahman M, San WY (2012) A state-of-the-art review of ductile cutting of silicon wafers for semiconductor and microelec- tronics industries. Intl J Adv Manuf Technol 63:481‚Äì504. https:// doi. org/ 10. 1007/ s00170- 012- 3937-2 3. Tong LI, Wang CH, Chen DL (2007) Development of a new clus- ter index for wafer defects. Intl J Adv Manuf Technol 31:705‚Äì715. https:// doi. org/ 10. 1007/ s00170- 005- 0240-5 4. Wang, J., Chun, H., Kim, J., & Lee, C. (2023). Wafer particle inspection technique using computer vision based on color space transform model. Intl J Adv Manuf Technol. https:// doi. org/"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_40", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 40, "text": "5- 0240-5 4. Wang, J., Chun, H., Kim, J., & Lee, C. (2023). Wafer particle inspection technique using computer vision based on color space transform model. Intl J Adv Manuf Technol. https:// doi. org/ 10. 1007/ s00170- 023- 11888-y 5. Jang J, Seo M, Kim CO (2020) Support weighted ensemble model for open set recognition of wafer map defects. IEEE Trans Semicond Manuf 33(4):635‚Äì643. https:// doi. org/ 10. 1109/ TSM. 2020. 30121 83 6. Jang J, Lee GT (2023) Decision fusion approach for detecting unknown wafer bin map patterns based on a deep multitask learning model. Expert Syst Appl 215:119363. https:// doi. org/ 10. 1016/j. eswa. 2022. 119363 7. Chu M, Park S, Jeong J, Joo K, Lee Y, Kang J (2022) Recognition of unknown wafer defect via optimal bin embedding technique. Intl J Adv Manuf Technol 121(5‚Äì6):3439‚Äì3451. https:// doi. org/ 10. 1007/ s00170- 022- 09447-y 8. Kahng H, Kim SB (2020) Self-supervised representation learning for wafer bin map defect pattern classification. IEEE Trans Semicond Manuf 34(1):74‚Äì86. https:// doi. org/ 10. 1109/ TSM. 2020. 30381 65 9. Kong Y, Ni D (2021) A one-shot learning approach for similarity retrieval of wafer bin maps with unknown failure pattern. "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_41", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 41, "text": "micond Manuf 34(1):74‚Äì86. https:// doi. org/ 10. 1109/ TSM. 2020. 30381 65 9. Kong Y, Ni D (2021) A one-shot learning approach for similarity retrieval of wafer bin maps with unknown failure pattern. IEEE Trans Semicond Manuf 35(1):40‚Äì49. https:// doi. org/ 10. 1109/ TSM. 2021. 31232 90 10. Zheng X, Zheng S, Kong Y, Chen J (2021) Recent advances in surface defect inspection of industrial products using deep learn- ing techniques. Intl J Adv Manuf Technol 113:35‚Äì58. https:// doi. org/ 10. 1007/ s00170- 021- 06592- 8s 11. Park S, Jang J, Kim CO (2021) Discriminative feature learning and cluster-based defect label reconstruction for reducing uncer - tainty in wafer bin map labels. J Intell Manuf 32:251‚Äì263. https:// doi. org/ 10. 1007/ s10845- 020- 01571-4 12. Ren Y, Pu J, Yang Z, Xu J, Li G, Pu X ... He L (2022) Deep clus- tering: a comprehensive survey. arXiv preprint arXiv: 2210. 04142. https:// doi. org/ 10. 48550/ arXiv. 2210. 04142 13. Zhou S, Xu H, Zheng Z, Chen J, Bu J, Wu J ... Ester M (2022) A comprehensive survey on deep clustering: taxonomy, challenges, and future directions. arXiv preprint arXiv: 2206. 07579. https:// doi. org/ 10. 48550/ arXiv. 2206. 07579 14. He K, Fan "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_42", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 42, "text": "ster M (2022) A comprehensive survey on deep clustering: taxonomy, challenges, and future directions. arXiv preprint arXiv: 2206. 07579. https:// doi. org/ 10. 48550/ arXiv. 2206. 07579 14. He K, Fan H, Wu Y, Xie S, Girshick R (2020) Momentum contrast for unsupervised visual representation learning, In Proceedings of the IEEE/CVF conference on computer vision and pattern recog- nition, 9729‚Äì9738. https:// doi. org/ 10. 48550/ arXiv. 1911. 05722 15. Chen X, Fan H, Girshick R, He K (2020) Improved baselines with momentum contrastive learning. arXiv preprint arXiv: 2003. 04297. https:// doi. org/ 10. 48550/ arXiv. 2003. 04297 16. Huang Z, Chen J, Zhang J, Shan H (2022) Learning representa- tion for clustering via prototype scattering and positive sampling. IEEE Trans Pattern Anal Mach Intell. https:// doi. org/ 10. 1109/ TPAMI. 2022. 32164 54 17. Ren C, Li S (2021) Two-stage classification learning for open set acoustic scene classification. In Proceedings of the 8th Conference on Sound and Music Technology: Selected Papers from CSMT (pp. 124‚Äì133). Springer Singapore 18. Wu Z, Lu Y, Chen X, Wu Z, Kang L, Yu J (2022) UC-OWOD: unknown-classified open world object detection. In European "}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_43", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 43, "text": "nd Music Technology: Selected Papers from CSMT (pp. 124‚Äì133). Springer Singapore 18. Wu Z, Lu Y, Chen X, Wu Z, Kang L, Yu J (2022) UC-OWOD: unknown-classified open world object detection. In European Conference on Computer Vision (pp. 193‚Äì210). Cham: Springer Nature Switzerland 19. Guo X, Alipour-Fanid A, Wu L, Purohit H, Chen X, Zeng K, Zhao L (2019) Multi-stage deep classifier cascades for open world recognition. In Proceedings of the 28th ACM Interna- tional Conference on Information and Knowledge Management (pp. 179‚Äì188) 20. Piao M, Jin CH, Lee JY, Byun JY (2018) Decision tree ensemble- based wafer map failure pattern recognition based on radon trans- form-based features. IEEE Trans Semicond Manuf 31(2):250‚Äì 257. https:// doi. org/ 10. 1109/ TSM. 2018. 28069 31 21. Lee KB, Cheon S, Kim CO (2017) A convolutional neural network for fault classification and diagnosis in semiconductor manufac- turing processes. IEEE Trans Semicond Manuf 30(2):135‚Äì142. https:// doi. org/ 10. 1109/ TSM. 2017. 26762 45 22. Kyeong K, Kim H (2018) Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks. IEEE Trans Semicond Manuf 31(3):395‚Äì402. https:// doi. org"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_44", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 44, "text": "2017. 26762 45 22. Kyeong K, Kim H (2018) Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks. IEEE Trans Semicond Manuf 31(3):395‚Äì402. https:// doi. org/ 10. 1109/ TSM. 2018. 28414 16 23. Shim J, Kang S, Cho S (2020) Active learning of convolutional neural network for cost-effective wafer map pattern classification. IEEE Trans Semicond Manuf 33(2):258‚Äì266. https:// doi. org/ 10. 1109/ TSM. 2020. 29748 67 24. Jin CH, Na HJ, Piao M, Pok G, Ryu KH (2019) A novel DBSCAN- based defect pattern detection and classification framework for wafer bin map. IEEE Trans Semicond Manuf 32(3):286‚Äì292. https:// doi. org/ 10. 1109/ TSM. 2019. 29168 35 25. Min E, Guo X, Liu Q, Zhang G, Cui J, Long J (2018) A survey of clustering with deep learning: from the perspective of network architecture. IEEE Access 6:39501‚Äì39514. https:// doi. org/ 10. 1109/ ACCESS. 2018. 28554 37 26. Xie J, Girshick R, Farhadi A (2016) Unsupervised deep embed- ding for clustering analysis. In International conference on machine learning (pp. 478‚Äì487). PMLR. https:// proce edings. mlr. press/ v48/ xieb16. html 27. Guo X, Gao L, Liu X, Yin J (2017) Improved deep embedded clus- teri"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_45", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 45, "text": "lysis. In International conference on machine learning (pp. 478‚Äì487). PMLR. https:// proce edings. mlr. press/ v48/ xieb16. html 27. Guo X, Gao L, Liu X, Yin J (2017) Improved deep embedded clus- tering with local structure preservation. In Ijcai (pp. 1753‚Äì1759) 28. Huang J, Gong S, Zhu X (2020) Deep semantic clustering by partition confidence maximisation. In Proceedings of the IEEE/ CVF conference on computer vision and pattern recognition (pp. 8849‚Äì8858) 29. Li Y, Hu P, Liu Z, Peng D, Zhou JT, Peng X (2021) Contrastive clustering. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 10, pp. 8547‚Äì8555). https:// doi. org/ 10. 1609/ aaai. v35i10. 17037 30. Grill JB, Strub F, Altch√© F, Tallec C, Richemond P, Buchatskaya E ... Valko M (2020) Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information process- ing systems, 33, 21271‚Äì21284 31. Nakazawa T, Kulkarni DV (2018) Wafer map defect pattern clas - sification and image retrieval using convolutional neural network. IEEE Trans Semicond Manuf 31(2):309‚Äì314. https:// doi. org/ 10. 1109/ TSM. 2018. 27954 66 Publisher's Note Springer Nature remains neutral with regard"}
{"id": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf::chunk_46", "source": "Contrastive deep clustering for detecting new defect patterns in wafer bin maps.pdf", "chunk_index": 46, "text": "age retrieval using convolutional neural network. IEEE Trans Semicond Manuf 31(2):309‚Äì314. https:// doi. org/ 10. 1109/ TSM. 2018. 27954 66 Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law."}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_0", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 0, "text": "Academic Editor: Pavlos Lazaridis Received: 8 January 2025 Revised: 12 February 2025 Accepted: 18 February 2025 Published: 19 February 2025 Citation: Yin, S.; Zhang, Y.; Wang, R. Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition. Sensors 2025 ,25, 1272. https://doi.org/ 10.3390/s25041272 Copyright: ¬© 2025 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/ licenses/by/4.0/). Article Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition Shantong Yin, Yangkun Zhang and Rui Wang * School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen 518055, China; styin0425@gmail.com (S.Y.); zhangyangkun@hit.edu.cn (Y.Z.) *Correspondence: r.wang@hit.edu.cn Abstract: Recognizing defect patterns in semiconductor wafer bin maps (WBMs) poses a critical challenge in the integrated circuit (IC) manufacturing industry. The accurate classification and segmentation of these defect patterns are of utmost significance as they"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_1", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 1, "text": "n maps (WBMs) poses a critical challenge in the integrated circuit (IC) manufacturing industry. The accurate classification and segmentation of these defect patterns are of utmost significance as they are key to tracing the root causes of defects, thereby reducing costs and enhancing both product efficiency and quality. As the manufacturing process grows in complexity, the WBM becomes intricate when multiple defect patterns coexist on a single wafer, making the recognition task increasingly complicated. In addition, traditional supervised learning methods require a large number of labeled samples, which is labor-intensive. In this paper, we present a self-supervised contrastive learning framework for the classification and segmentation of mixed-type WBM defect patterns. Our model incorporates a global module for contrastive learning that captures image-level representations, alongside a local module that targets the comprehension of regional details, which is helpful for the segmentation of defective patterns. Experimental results demonstrate that our model performs effectively in scenarios where there is a limited number of labeled examples and a wealth of unlabeled ones. Keywords"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_2", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 2, "text": "on of defective patterns. Experimental results demonstrate that our model performs effectively in scenarios where there is a limited number of labeled examples and a wealth of unlabeled ones. Keywords: pattern classification and segmentation; contrastive learning; wafer bin map 1. Introduction The production of semiconductor devices is a complex and highly detailed operation, involving hundreds of steps to fabricate integrated circuit (IC) chips on silicon wafers. After wafer fabrication, the wafer needs to be inspected. Common inspection methods include a probing test, scanning electron microscopy (SEM), transmission electron mi- croscopy (TEM), X-ray inspection, and automatic optical inspection (AOI), each generating information at different levels. For probing tests, the electrical performance of each die is tested using wafer probes. Dies that meet quality requirements are cut off from the wafer and utilized as final qualified chips. As the worldwide need for these devices grows, manufacturers are concentrating their efforts on boosting manufacturing efficiency by employing techniques such as maximizing the number of chips per wafer. Nevertheless, the enhanced complexity of the"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_3", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 3, "text": "anufacturers are concentrating their efforts on boosting manufacturing efficiency by employing techniques such as maximizing the number of chips per wafer. Nevertheless, the enhanced complexity of these advanced techniques also gives rise to various defects, which are inevitable during the manufacturing processes. Therefore, the results of wafer test are stored in wafer bin maps (WBMs) for defect analysis, contributing to reducing defect rates and ensuring market competitiveness [1]. WBM defect pattern recognition is crucial for detecting systemic manufacturing is- sues, as the accurate classification and segmentation results of WBM defect patterns can effectively infer the root causes of defects in the manufacturing process [ 2]. The defects Sensors 2025 ,25, 1272 https://doi.org/10.3390/s25041272 Sensors 2025 ,25, 1272 2 of 18 on the wafer can generally be divided into two categories: random errors and systematic faults. When dealing with wafer defect patterns, the analysis of systematic faults is gen- erally the main focus, as the defect patterns caused by random errors are irregular and difficult to eliminate. As shown in Figure 1a, the typical single defect patterns contain th"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_4", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 4, "text": "atic faults is gen- erally the main focus, as the defect patterns caused by random errors are irregular and difficult to eliminate. As shown in Figure 1a, the typical single defect patterns contain the following: ‚ÄúCenter‚Äù, ‚ÄúDonut‚Äù, ‚ÄúEdgeLoc‚Äù, ‚ÄúEdgeRing‚Äù, ‚ÄúLoc‚Äù, ‚ÄúNearFull‚Äù, ‚ÄúScratch‚Äù, and ‚ÄúRandom‚Äù [ 3]. With the ongoing advancement in the IC industry, the complexity of manufacturing raises the likelihood of mixed-type WBM defect patterns appearing on the same wafer [ 4,5], as shown in Figure 1b. These defect patterns may interact with each other, resulting in more intricate issues. Consequently, accurate classification and segmentation of these mixed-type WBM defect patterns are essential for effective quality control. Figure 1. (a) Eight common single-type WBM defect patterns. ( b) Examples of mixed-type WBM defect patterns. Given the intricate nature of mixed-type WBM defect patterns, manual inspection becomes increasingly labor-intensive and time-consuming [ 6]. Alternative solutions are required in industrial production. Recent studies have explored the application of artificial intelligence and computer vision models for defect pattern analysis [ 2]. However, existing research "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_5", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 5, "text": " are required in industrial production. Recent studies have explored the application of artificial intelligence and computer vision models for defect pattern analysis [ 2]. However, existing research mainly focuses on image classification and cannot accurately identify the size and location of mixed-type defect patterns. In addition, training a model to recognize defect patterns often requires a large number of labeled samples and undoubtedly wastes manpower and resources. Self-supervised learning can learn from unlabeled data, which is particularly attractive in situations where it is difficult to obtain large amounts of labeled data [ 7]. Although self-supervised learning is currently mainly used for image classification tasks, our work is based on the intuition that the WBM defect pattern segmentation can also benefit from representations learned through self-supervised learning from unlabeled data. This study centers on contrastive learning, a branch of self-supervised learning [ 8,9]. According to our research, most existing contrastive learning approaches prioritize global representations, which are not optimal for segmentation tasks that require pixel-level distinctions [ 10"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_6", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 6, "text": ",9]. According to our research, most existing contrastive learning approaches prioritize global representations, which are not optimal for segmentation tasks that require pixel-level distinctions [ 10]. If local regions of images are extracted for contrastive learning, then local representations can be adequately learned [ 11] for segmentation tasks. Consequently, we propose a self-supervised contrastive learning model that integrates both global and local contrastive learning modules, with queue mechanisms introduced to decouple the sample size from mini-batch constraints. Specifically, the global contrastive learning module focuses on the learning of global representations, while the local contrastive learning Sensors 2025 ,25, 1272 3 of 18 module is used to learn pixel-level discrimination. With the introduction of queues, each module receives a sufficient number of negative samples, improving the contrastive loss computation. To the best of our knowledge, this is the first application of contrastive learning to both the classification and segmentation of WBM defect patterns. The primary contributions of this paper are as follows: (1) We employ self-supervised contrastive learni"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_7", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 7, "text": "ion of contrastive learning to both the classification and segmentation of WBM defect patterns. The primary contributions of this paper are as follows: (1) We employ self-supervised contrastive learning for both the classification and seg- mentation of mixed-type defect patterns. In this way, we can obtain more precise information about the types and locations of different defect patterns. (2) Our proposed model integrates global and local contrastive learning modules, en- abling the learning of both image-level and pixel-level features directly from unlabeled data. This approach provides a robust foundation for downstream classification and segmentation tasks using only a limited amount of labeled data. (3) Experimental evaluations on the mixed-type WBM defect pattern dataset demonstrate that our framework outperforms existing self-supervised methods. The remainder of this paper is organized as follows: Section 2 presents a brief overview of recent studies on mixed-type WBM defect pattern classification and segmentation. Section 3 details the proposed methodology. Section 4 discusses the experimental re- sults and analysis. Finally, Section 5 contains concluding remarks and direct"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_8", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 8, "text": "tern classification and segmentation. Section 3 details the proposed methodology. Section 4 discusses the experimental re- sults and analysis. Finally, Section 5 contains concluding remarks and directions for future research. 2. Related Works 2.1. WBM Defect Pattern Recognition WBM defect pattern analysis is crucial for identifying the root cause of process failures in semiconductor manufacturing. The current research mainly focuses on the classification of single defect patterns and can be roughly divided into three categories. The first category mainly monitors defect patterns on WBMs by constructing statistical information [12,13] , which can successfully separate normal and abnormal graphic patterns, but it is difficult to distinguish different defect patterns. The second category is model-based clustering meth- ods. For example, Wang et al. [ 14] used Gaussian EM to detect elliptical and linear patterns and used the shell algorithm to estimate annular patterns. Yuan and Kuo [ 15] proposed a mixed model describing the distribution of defects and used Bayesian inference to estimate parameters. The last category is machine learning methods that have received more and more attenti"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_9", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 9, "text": "proposed a mixed model describing the distribution of defects and used Bayesian inference to estimate parameters. The last category is machine learning methods that have received more and more attention in recent years. Wang and Chen [ 16] trained a multilayer perceptron (MLP) on a set of hand-crafted spatial filters that reflect the rotational invariance property of WBM. Kulkarni [ 3] applied CNNs to classify defect patterns based on a synthesized WBM dataset. Kang et al. [ 17] presented a semi-supervised representation learning method, which fully utilizes the information in both unlabeled and labeled wafer maps. Most of the above research relies on large WBM databases and has problems with unsatisfactory performance and high computational costs. The composition of mixed-type WBM defect patterns is more complex, as the combi- nation of defect patterns can vary greatly. Thus, research on the classification of mixed-type WBM defect patterns is less extensive than that on single WBM defect patterns. In these studies, Byun and Baek [ 18] proposed a new approach using a convolutional autoencoder to initialize the weights of a CNN. Tello et al. [ 19] used feature rules to determine whe"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_10", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 10, "text": "ect patterns. In these studies, Byun and Baek [ 18] proposed a new approach using a convolutional autoencoder to initialize the weights of a CNN. Tello et al. [ 19] used feature rules to determine whether a wafer map has mixed-type patterns and then used a stochastic general regression neural network (GRNN) and a deep structured CNN for classification. Kyeong and Kim [ 20] applied a CNN to classify WBM defects with mixed-type defect patterns. Wang et al. [ 5] proposed DC-Net, which used a deformable convolutional network (DC-Net) to classify mixed-type defect patterns. These methods are unable to recognize and locate mixed-type Sensors 2025 ,25, 1272 4 of 18 defect patterns on WBMs simultaneously, and the research on the separation of multiple defect patterns is still insufficient. Compared with classification, image segmentation can provide more detailed informa- tion and better understand the content of the image. For mixed-type WBM defect pattern segmentation, Nag et al. [ 21] recently proposed a novel network based on an encoder‚Äì decoder architecture for the simultaneous classification and segmentation of single and mixed defect patterns. Chiu et al. [ 2] proposed a method base"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_11", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 11, "text": "tly proposed a novel network based on an encoder‚Äì decoder architecture for the simultaneous classification and segmentation of single and mixed defect patterns. Chiu et al. [ 2] proposed a method based on Mask R-CNN [ 22] to identify WBM defect patterns. Yan et al. [ 23] presented a new U-Net framework that used semantic segmentation methods to segment different defect patterns on WBMs. However, existing research tends to focus more on global image representation while overlooking the powerful auxiliary role that local information plays in image segmentation tasks. 2.2. Self-Supervised Contrastive Learning Self-supervised learning mainly uses auxiliary tasks to mine its own supervision infor- mation from large-scale unsupervised data and trains the network through this constructed supervision information [ 7,24]. As shown in Figure 2, the core idea of the self-supervised learning paradigm is to first learn knowledge from unlabeled samples by designing self- supervised signals and then transfer it to downstream tasks. As a branch of self-supervised learning, contrastive learning [ 25] focuses on learning the common features between in- stances of the same class and distinguishing th"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_12", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 12, "text": "transfer it to downstream tasks. As a branch of self-supervised learning, contrastive learning [ 25] focuses on learning the common features between in- stances of the same class and distinguishing the differences between instances of different classes. Contrastive learning can effectively utilize unlabeled data for training [ 9,26] and has been widely applied in the field of natural image processing. In the field of WBM defect pattern classification, Kwak et al. [ 27] applied a method (SWaCo) for safe WBM classi- fication with self-supervised contrastive learning to effectively exploit unlabeled data. Kahng et al. [ 28] presented a self-supervised learning framework that fully utilizes unla- beled data to pre-learn rich visual representations for data-efficient WBM defect pattern classification. Hu et al. [ 29] proposed a contrastive learning framework for semi-supervised learning and prediction of WBM defect patterns. It can be seen that self-supervised con- trastive learning methods do not heavily rely on the number of labeled samples and are mostly used for the classification of WBM defect patterns, but there is still little research on segmentation tasks. The urgent challenge "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_13", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 13, "text": " do not heavily rely on the number of labeled samples and are mostly used for the classification of WBM defect patterns, but there is still little research on segmentation tasks. The urgent challenge lies in establishing a self-supervised con- trastive learning model that possesses both classification and segmentation capabilities for mixed-type WBM defect patterns. Figure 2. The self-supervised learning paradigm. Sensors 2025 ,25, 1272 5 of 18 3. Methodology 3.1. Overview In this paper, we propose a classification and segmentation model for mixed-type WBM defect patterns based on self-supervised contrastive learning. In our problem setting, we consider a set of WBM data including Nlabeled data and Munlabeled data, where N‚â™M. For simplicity, the unlabeled set is defined as Du={xi}M i=1, and the labeled set is defined as Dl={xi,yi}M+N i=M+1. As shown in Figure 3, the framework consists of a self- supervised pre-training stage and a supervised fine-tuning stage. In pre-training, global contrastive learning module is designed to learn image-level representation, while the local contrastive learning module is used to better understand the structure of local regions, which contributes t"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_14", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 14, "text": "ontrastive learning module is designed to learn image-level representation, while the local contrastive learning module is used to better understand the structure of local regions, which contributes to the image segmentation task. To distinguish extracted features with different connotations, we apply the concept of a query and a key to describe encoders and decoders, although they have the same structure respectively. A query can be understood as the target to be searched for, and a key is the template. The model is built by matching the query to a dictionary of keys, which is a queue of the encoded representations of data samples that is updated with each mini-batch. In fine-tuning, pre-trained weights are transferred to the downstream classification and segmentation tasks and fine-tuned with a limited number of labeled samples. This section describes the proposed framework in detail. Figure 3. The overall framework of our proposed model. Note that the figure omits the display of negative samples. In the self-supervised pre-training stage, we pre-train the network using a large amount of unlabeled data xi‚ààDu. After that, we transfer the knowledge embedded in the query encoder and"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_15", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 15, "text": "ative samples. In the self-supervised pre-training stage, we pre-train the network using a large amount of unlabeled data xi‚ààDu. After that, we transfer the knowledge embedded in the query encoder and query decoder to the downstream task and fine-tune the network with few labeled samples {xi,yi} ‚ààDl. 3.2. Data Augmentation In contrastive learning, the model is trained by enforcing similarity between positive sample pairs and dissimilarity between negative sample pairs. Therefore, the core of con- trastive learning is the construction of positive and negative samples. In practice, different augmented views of the same sample after data augmentation are seen as positive samples, while other samples are defined as negative samples. Supported by data augmentation, the model can learn better feature representations of the data, capture the fundamental Sensors 2025 ,25, 1272 6 of 18 structure and relationships between samples, and effectively prevent over-fitting. As shown in Figure 4, we perform data augmentation operators, i.e., random rotation, flipping, and random noise on samples for learning the rotational invariance of WBMs and improving the robustness and generalization ability o"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_16", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 16, "text": "rform data augmentation operators, i.e., random rotation, flipping, and random noise on samples for learning the rotational invariance of WBMs and improving the robustness and generalization ability of the model. Regarding the noise addition operations in data augmentation, given that noise in semiconductor manufacturing environments (such as dust, light variations, etc.) can affect the performance of detection systems, we introduce different types of artificial noise (Gaussian Noise, Salt-and-Pepper Noise, and Poisson Noise) to simulate real-world production noise conditions. Specifically, given unlabeled sample xi‚ààDu, two augmented WBMs xI iand xII iare generated by data aug- mentation t1andt2, i.e., xI i=t1(xi)andxII i=t2(xi). These two augmented views are then used for the illustration of subsequent feature extraction. Figure 4. Illustration of the data augmentation operators. 3.3. Global Contrastive Learning Module The global contrastive learning module mainly promotes the model to learn the ability of extracting global features. Since global features provide the context information of the image, the designing of this module contributes to the effective comprehension of the ov"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_17", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 17, "text": "o learn the ability of extracting global features. Since global features provide the context information of the image, the designing of this module contributes to the effective comprehension of the overall structure of mixed-type WBMs. Specifically, key and query encoders are used to extract high-dimensional key and query global features. Then, these high-dimensional features are mapped to lower-dimensional hidden spaces for a more compact representation through the global projection head. After that, the global queue that is a unique form of a linear list is employed to dynamically manage key features. The construction of the global contrastive learning module is similar to MoCo v2 [ 8]; we provide a detailed description as follows. 3.3.1. Global Feature Extraction Global features refer to the overall attributes of an image, capable of capturing the global information and understanding the image from a holistic perspective. We apply the concept of a query and a key to describe encoders for distinguishing extracted features with different connotations. As given a series of key features and a query feature, con- trastive learning is to find the unique key feature that matches the qu"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_18", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 18, "text": "s for distinguishing extracted features with different connotations. As given a series of key features and a query feature, con- trastive learning is to find the unique key feature that matches the query feature the most and enforce them to be similar while distancing from others. Firstly, a key encoder ek(¬∑)and a query encoder eq(¬∑)are used to obtain global key feature GI iand global query feature GII ifrom the augmented sample instances, respectively. The procedure can be formulated as GI i=¬µ\u0010 ek\u0010 xI i\u0011\u0011 ,GII i=¬µ\u0010 eq\u0010 xII i\u0011\u0011 , (1) where ¬µ(¬∑)represents the average value of each channel in the feature map, i.e., the global average pooling. ek(¬∑)denotes the key encoder and eq(¬∑)denotes the query encoder, which have the same structure as the downstream encoder e(¬∑). In addition, the global projection head hG(¬∑)is an MLP with one hidden layer (with ReLU) in this module, whose presence has been proven to be beneficial to push the dissim- ilar samples away from each other and obtain more useful information for downstream tasks [ 9]. The global projection head can map the high-dimensional features GI iand GII i Sensors 2025 ,25, 1272 7 of 18 to lower-dimensional hidden spaces for a more"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_19", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 19, "text": "seful information for downstream tasks [ 9]. The global projection head can map the high-dimensional features GI iand GII i Sensors 2025 ,25, 1272 7 of 18 to lower-dimensional hidden spaces for a more compact representation, encouraging our model to learn more abstract and informative features. Therefore, we obtain the final global key feature gI iand global query feature gII iby passing GI iandGII ithrough the global projection head hG(¬∑)to further calculate the global contrastive loss. The conversion can be formulated as follows: gI i=hG\u0010 GI i\u0011 =W(2) GRG\u0010 W(1) GGI i\u0011 , (2) gII i=hG\u0010 GII i\u0011 =W(2) GRG\u0010 W(1) GGII i\u0011 , (3) where W(1) GandW(2) Gare linear transformation matrices, and RGis a ReLU nonlinearity. Furthermore, the global queue that is a unique form of a linear list for dynamically managing vectors is introduced, as shown in Figure 3. Since the core of contrastive learn- ing is to construct sufficient negative sample pairs, we design the global queue to store abundant negative vectors (i.e., key features) generated by the key encoder. The size of key features in the global queue can far exceed the capacity of a single batch, which can increase the diversity of training and "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_20", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 20, "text": "vectors (i.e., key features) generated by the key encoder. The size of key features in the global queue can far exceed the capacity of a single batch, which can increase the diversity of training and improve the generalization ability of the model. Therefore, the introduction of the queue can decouple the negative vector size from the mini-batch size. In the dynamic management of the global queue, the current mini-batch of encoded key features is enqueued into the queue and the oldest key features are dequeued from the queue. This process ensures that the model is always learning from the latest data by a dynamic and efficient management of key features. 3.3.2. Global Contrastive Loss Global contrastive loss is a measure of the similarities between global features in a representation space and promotes the model to learn global representations. In contrastive learning, if a query feature (generated by query encoder) is given, only a unique key feature in the global queue can match it. So, the idea of contrastive learning is to compare the query feature with all the key features in the queue and hope that the query feature is as similar as possible to its matching key feature, and t"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_21", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 21, "text": "So, the idea of contrastive learning is to compare the query feature with all the key features in the queue and hope that the query feature is as similar as possible to its matching key feature, and then it stays away from others. Consider an encoded query feature gII iand a set of encoded samples {gI 0,. . .gI i,. . .gI K}that contains K+1key features in the global queue. Obviously, there is a single key feature (denoted asgI i) that matches gII i. Then, the contrastive loss function, called InfoNCE [ 30], is used to expect matching pairs to be similar and mismatching pairs to be dissimilar, as follows: LG=1 NGNG ‚àë i=1‚àílogexp\u0000 gII i¬∑gI i/œÑg\u0001 ‚àëK k=0exp\u0000 gII i¬∑gI k/œÑg\u0001, (4) where œÑgis a temperature hyper-parameter, and NGdenotes the number of samples from a mini-batch. The sum in the denominator is calculated over one positive key feature gI i and other Knegative key features. Intuitively, the InfoNCE loss tries to classify the query feature gII ias its corresponding positive key feature gI irather than others. 3.4. Local Contrastive Learning Module The local contrastive learning module is a local contrastive representation space for computing the contrastive loss associated with th"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_22", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 22, "text": "e gI irather than others. 3.4. Local Contrastive Learning Module The local contrastive learning module is a local contrastive representation space for computing the contrastive loss associated with the local regions of a WBM. For a WBM with mixed-type defect patterns, the segmentation task is more complex due to the inter- connected nature of defects and their variability in quantity, position, and type, etc. While global features can effectively capture the overall information of an image, relying solely on global features to measure WBM defect patterns will result in the neglect of crucial local details. This approach may not be optimal for segmentation tasks that require pixel-level discrimination. To address this issue, we design the local contrastive learning module to Sensors 2025 ,25, 1272 8 of 18 learn the representation of local regions. We separate the WBM into multiple regions, selec- tively identify relevant regions, and subsequently perform position matching and feature extraction for local contrastive learning. This method ensures that the segmentation process benefits from both the global context and the fine-grained local information, enhancing the overall accuracy "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_23", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 23, "text": "traction for local contrastive learning. This method ensures that the segmentation process benefits from both the global context and the fine-grained local information, enhancing the overall accuracy and effectiveness of defect recognition. The details are as follows: 3.4.1. Local Region Selection and Matching Randomly selected local regions will be biased towards the more dominant feature categories, as the ‚Äúbackground‚Äù category accounts for a large proportion in mixed-type WBM defect patterns. Therefore, we need to make the selection of local regions reasonable to contain more valuable feature categories. For example, as shown in Figure 5, flipping and rotating operations are performed on xi, and two augmented views xI iandxII iare obtained respectively. The selected local regions are then matched according to their positions. Figure 5. Process of local region selection and matching. The local region selection and matching is performed by the selection of appropriate regions in xI iat first, and then by the determination of the local regions in xII ithat match with the selected regions. The appropriateness of each local region to be selected is evaluated by its weight, which is c"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_24", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 24, "text": "t first, and then by the determination of the local regions in xII ithat match with the selected regions. The appropriateness of each local region to be selected is evaluated by its weight, which is calculated by a convolutional layer with the kernel size being the same as the local region size ns√óns. Specifically, xI iis input into the convolutional layer, and the weight of each local region is calculated and recorded by sliding the kernel. We select the local region with the maximum weight from xI i, and then the position of the matching local region in xII iis determined. To minimize overlap, after each local region selection, the region is excluded so that the centers of subsequently selected regions do not fall into the previously selected local regions. This weighted selection and matching process is repeated nrtimes, selecting distinct local regions in each iteration to obtain nr pairs of matched local regions from images xI iandxII i. 3.4.2. Local Feature Extraction Local features lI jand lII jthat capture the pixel-level discrimination of WBM defect patterns are extracted by the following steps. Firstly, feature maps dk(ek(xI i))anddq(eq(xII i)) of a positive pair ( xI i,x"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_25", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 25, "text": "res lI jand lII jthat capture the pixel-level discrimination of WBM defect patterns are extracted by the following steps. Firstly, feature maps dk(ek(xI i))anddq(eq(xII i)) of a positive pair ( xI i,xII i) are obtained from a key and query encoder‚Äìdecoder network. Here, ek(¬∑)andeq(¬∑)are key and query encoders while dk(¬∑)anddq(¬∑)are key and query decoders, which have the same structure as the downstream encoder‚Äìdecoder network, respectively. Then, the j-th(j=1,. . .,nr)pair of matching local region feature maps LI j andLII jis extracted according to the idea of local region selection and matching. After that, average pooling ¬µ(¬∑)is performed on local region feature maps LI jandLII j, and the results then pass through the local projection head hL(¬∑). Therefore, the final local features can be defined as follows: lI j=hL\u0010 ¬µ\u0010 LI j\u0011\u0011 =W(2) LRL\u0010 W(1) L¬µ\u0010 LI j\u0011\u0011 , (5) lII j=hL\u0010 ¬µ\u0010 LII j\u0011\u0011 =W(2) LRL\u0010 W(1) L¬µ\u0010 LII j\u0011\u0011 , (6) Sensors 2025 ,25, 1272 9 of 18 where feature maps dk(ek(xI i))anddq(eq(xII i))have the same size as the original image. The local projection head hL(¬∑)can contribute to making the model better capture the differences between local regions. ¬µrepresents calculating the ave"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_26", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 26, "text": "xII i))have the same size as the original image. The local projection head hL(¬∑)can contribute to making the model better capture the differences between local regions. ¬µrepresents calculating the average value of each channel in feature maps, W(1) Land W(2) Lare linear transformation matrices, and RLis a ReLU nonlinearity. Similar to the global contrastive learning, the queue is also applied to dynamically store and manage local region vectors in the training of the model, as shown in Figure 3. 3.4.3. Local Contrastive Loss The local contrastive loss updates the network by forcing the feature representations of matching local regions to be similar and the feature representations of different local regions to be dissimilar. Specifically, considering a local query feature lII jand a set of vectors {lI 0,. . .lI j,. . .lI Œì}that contain Œì+1key features in the local queue, there is a single key feature (denoted as lI j) that matches lII j. Then, the local contrastive loss can also be calculated by InfoNCE as follows: LL=1 NLNL ‚àë j=1‚àílogexp\u0010 lII j¬∑lI j/œÑl\u0011 ‚àëŒì Œ≥=0exp\u0010 lII j¬∑lIŒ≥/œÑl\u0011, (7) where œÑlis a temperature hyper-parameter, NLindicates the number of pairs of matched local regions in"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_27", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 27, "text": "ulated by InfoNCE as follows: LL=1 NLNL ‚àë j=1‚àílogexp\u0010 lII j¬∑lI j/œÑl\u0011 ‚àëŒì Œ≥=0exp\u0010 lII j¬∑lIŒ≥/œÑl\u0011, (7) where œÑlis a temperature hyper-parameter, NLindicates the number of pairs of matched local regions in a mini-batch, and Œìrepresents the number of key features in the local queue. 3.5. Network Updating 3.5.1. Self-Supervised Pre-Training In the pre-training period, the total contrastive loss function to update the query encoder parameters Œ∏eqand query decoder parameters Œ∏dqis defined as follows: LP=Œª1LG+ (1‚àíŒª1)LL, (8) where LGrepresents the global contrastive loss in Equation (4), and LLrepresents the local contrastive loss in Equation (7). Although using queues allows for the size of negative vectors to be larger, it also poses difficulties for updating the key encoder and key decoder via back-propagation, since the gradient should propagate to all samples in the queue. To address this issue, a momentum update approach is utilized for the key encoder and decoder, which accumulates exponen- tial moving averages of the key network to ensure a stable and efficient update manner. To be specific, the query encoder parameters Œ∏eqand the decoder parameters Œ∏dqare updated via back-propagation"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_28", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 28, "text": "- tial moving averages of the key network to ensure a stable and efficient update manner. To be specific, the query encoder parameters Œ∏eqand the decoder parameters Œ∏dqare updated via back-propagation by Equation (8), while the key encoder parameters Œ∏ekand decoder parameters Œ∏dkare updated by the momentum equations: Œ∏ek‚ÜêŒ±1Œ∏ek+ (1‚àíŒ±1)Œ∏eq, (9) and Œ∏dk‚ÜêŒ±2Œ∏dk+ (1‚àíŒ±2)Œ∏dq, (10) where Œ±1andŒ±2‚àà[0, 1)are the momentum coefficients. The momentum updating makes parameters Œ∏ekandŒ∏dkevolve more smoothly than Œ∏eqandŒ∏dq. Therefore, although the keys in the queue are generated by different encoders and decoders, the differences between these encoders and decoders can be ignored. 3.5.2. Supervised Fine-Tuning Supervised fine-tuning refers to training the model on a smaller and task-specific labeled dataset. The purpose of this stage is to make the model adapt to the specific Sensors 2025 ,25, 1272 10 of 18 requirements of the given task. In detail, the model retains the knowledge learned in the pre-training stage while also learning additional information relevant to the specific task. In our problem, given labeled data {xi,yi} ‚ààDl, we fine-tune the whole network through a segmentation loss LSand c"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_29", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 29, "text": "ining stage while also learning additional information relevant to the specific task. In our problem, given labeled data {xi,yi} ‚ààDl, we fine-tune the whole network through a segmentation loss LSand classification loss LC. For the computation of the segmentation loss LS, we employ the cross-entropy loss function [ 31], which computes the pixel-level difference between segmented defect patterns and the ground truth. However, merely calculating the loss value of pixels may result in over-segmentation. It is still necessary to compute the loss value associated with the type of defect. We use a C-bit one-hot value to represent the predicted types of WBM defect patterns and calculate the corresponding binary cross entropy loss LC. Since we need to simultaneously focus on the classification and segmentation of WBM defect patterns, the total loss function in the fine-tuning period is defined as follows: LF=Œª2LS+ (1‚àíŒª2)LC, (11) where LSrepresents the segmentation loss and LCrepresents the classification loss. 4. Experimental Results 4.1. Data Description A wafer bin map (WBM) is the result of the circuit probing process, recording the spatial distribution of defective chips on the wafer. T"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_30", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 30, "text": "sification loss. 4. Experimental Results 4.1. Data Description A wafer bin map (WBM) is the result of the circuit probing process, recording the spatial distribution of defective chips on the wafer. The WBMs dataset collection system is shown in Figure 6. The primary method of wafer testing involves the coordination between the tester and the probe stage [ 32]. During the testing process, the tester cannot directly measure the wafer under test. Instead, it relies on the probes in the probe card to make electrical contact with the pads or bumps on the wafer. The test signals measured by the probes are then sent to the automatic test equipment (ATE) for analysis and judgment, thereby obtaining the electrical characteristics test results for each die on the wafer. All samples are collected in actual industrial scenarios by the wafer probe testing station. We standardized the image size to 52 √ó52. Figure 6. Wafer probe testing station. As shown in Table 1, the defect types contain 8 kinds of single defect patterns and 29 kinds of mixed-type defect patterns (13 kinds of double mixed-type defect patterns, 12 kinds of triple mixed-type defect patterns, and 4 kinds of quadruple mixed-type "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_31", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 31, "text": "of single defect patterns and 29 kinds of mixed-type defect patterns (13 kinds of double mixed-type defect patterns, 12 kinds of triple mixed-type defect patterns, and 4 kinds of quadruple mixed-type defect patterns). We represent each type of defect using the uppercase initial letter of its name as shown in Figure 1. It is worth noting that Random and NearFull defects do not significantly point to specific manufacturing roots, and their impact in practice is minimal. Also, these two types of patterns are not suitable for generating mixed defects with other single defect patterns, so we do not consider the synthesis of these two types. Furthermore, we consider the WBMs of the normal category (C0) into the model training process, and there are 37 kinds of defect patterns and 1 kind of normal category in total. In the final dataset, we collected 19,000 WBMs with 500 instances for each defect pattern. In our problem setting, the original WBMs have only pixel values 0, 1, and 2, so xi‚àà{0, 1, 2}H√óWmentioned earlier is the WBM; yi=\b(mi,si)|mi‚àà {0, 1}C√óH√óW,si‚àà {0, 1}C is the corresponding Sensors 2025 ,25, 1272 11 of 18 ground truth category label, where Cdenotes the number of pattern typ"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_32", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 32, "text": "1, 2}H√óWmentioned earlier is the WBM; yi=\b(mi,si)|mi‚àà {0, 1}C√óH√óW,si‚àà {0, 1}C is the corresponding Sensors 2025 ,25, 1272 11 of 18 ground truth category label, where Cdenotes the number of pattern types; miis the pixel label map of the i-th sample; and sirepresents the C-bit one-hot label. Table 1. Description of mixed-type WBM defect patterns. Single-TypeC (C1) D (C2) EL (C3) ER (C4) L (C5) S (C6) NF (C7) R (C8) Two-Mixed-TypeC + EL (C9) C + ER (C10) C + L (C11) C + S (C12) D + EL (C13) D + ER (C14) D + L (C15) D + S (C16) EL + L (C17) EL + S (C18) ER + L (C19) ER + S (C20) L + S (C21) - - - Three-Mixed-TypeC + EL + L (C22) C + EL + S (C23) C + ER + L (C24) C + ER + S (C25) D + EL + L (C26) D + EL + S (C27) D + ER + L (C28) D + ER + S (C29) C + L + S (C30) D + L + S (C31) EL + L + S (C32) ER + L + S (C33) Four-Mixed-Type C + L + EL + S (C34) C + L + ER + S (C35) D + L + EL + S (C36) D + L + ER + S (C37) 4.2. Model Evaluation In this paper, we focus on both the segmentation and classification performance of mixed-type WBM defect patterns. Specifically, we use Pacc (pixel predicted accuracy) and IoU (Intersection over Union) to evaluate the results of semantic segmentation, which ca"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_33", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 33, "text": "ication performance of mixed-type WBM defect patterns. Specifically, we use Pacc (pixel predicted accuracy) and IoU (Intersection over Union) to evaluate the results of semantic segmentation, which can be defined for a specific class cas follows: Paccc i=Area(ÀÜmc i‚à©mc i) H√óW, (12) IoUc i=Area(ÀÜmc i‚à©mc i) Area(ÀÜmc i‚à™mc i), (13) where mc iand ÀÜmc idenote the actual and predicted pixel label maps of the c-th pattern in the i-th WBM. For mixed-type patterns, the mean IoU (mIoU ) and the mean Pacc (mPacc ) are used to evaluate the model segmentation performance. For the evaluation of classification results, we use Accuracy to measure the classi- fication accuracy of mixed-type WBM defect patterns. To evaluate the performance in the false classification of WBMs, Precision and Recall are employed in our experiments. The definitions of the indices are shown as follows: Accuracy =TP+TN TP+TN+FP+FN, (14) Precision =TP TP+FP, (15) Recall =TP TP+FN. (16) where TPdenotes the true positives, TNis the true negatives, FPrepresents the false positives, and FNrepresents false negatives. 4.3. Performance and Analysis 4.3.1. Implementation Details In this work, the encoders and decoders designed in ou"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_34", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 34, "text": "e true negatives, FPrepresents the false positives, and FNrepresents false negatives. 4.3. Performance and Analysis 4.3.1. Implementation Details In this work, the encoders and decoders designed in our model have the same structure as those in DeepLab v3+ [ 33]. During the pre-training period, we used an abundant amount of unlabeled WBMs to pre-train the encoder and decoder for 350 epochs with a batch size Sensors 2025 ,25, 1272 12 of 18 of 64. We optimized the parameters with Adam optimizer, and the initial learning rate was set as 0.01 with the cosine decay schedule. In addition, we selected 6local regions of size 12√ó12from each sample in the local region selection and matching process ( i.e.,ns=12, nr=6). The hyper-parameter Œª1in Equation (8) was set to 0.5 to balance the global contrast loss and local contrast loss. Following [ 8], the momentum coefficients Œ±1andŒ±2were all set to 0.999, and the size of the queues was set to 2048. After pre-training, the model with the lowest loss was saved for the downstream segmentation task. In the fine-tuning period, we trained our model using a small amount of labeled WBMs for a total of 150 epochs, with a batch size of 32. The initial lear"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_35", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 35, "text": "as saved for the downstream segmentation task. In the fine-tuning period, we trained our model using a small amount of labeled WBMs for a total of 150 epochs, with a batch size of 32. The initial learning rate was set to 0.001, which decreased to 98% per epoch. The hyper-parameter Œª2in Equation (11) is used to balance pixel loss and one-hot prediction loss, so we also set it to a default 0.5. In addition, the experiment was implemented on an equipment with an Intel(R) Xeon(R) Gold 6226R @ 2.90 GHz CPU and an NVIDIA RTX A6000 GPU by Python 3.8.3. 4.3.2. Model Performance In our experimental setting, we randomly split the dataset into three subsets: 80% for pre-training, 10% for fine-tuning, and 10% for testing. We obtained the Pacc ,IoU,Accuracy , Precision , and Recall for 38 kinds of defect patterns to demonstrate the performance of our model. Table 2 primarily displays the segmentation and classification results for the normal pattern and the single-type defect patterns, Table 3 shows the segmentation results for the mixed-type defect patterns, and Table 4 presents the classification results for the mixed-type defect patterns. As shown in Table 2, the horizontal axis represents d"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_36", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 36, "text": "s the segmentation results for the mixed-type defect patterns, and Table 4 presents the classification results for the mixed-type defect patterns. As shown in Table 2, the horizontal axis represents different categories (C0 to C8), while the vertical axis displays various evaluation metrics for segmentation and classification. The average Pacc ,IoU,Accuracy ,Precision , and Recall of our proposed model for C0‚ÄìC8 are 95.78%, 93.87%, 96.80%, 94.61%, and 94.89%. In Tables 3 and 4, to facilitate the presentation of the experimental results, the horizontal axis represents various evaluation metrics for segmentation and classification, respectively, while the vertical axis corresponds to different categories (C9 to C37). The average Pacc , IoU,Accuracy ,Precision , and Recall for C9‚ÄìC37 are 95.40%, 90.51%, 92.34%, 94.45%, and 94.66%. From an overall perspective, the more the defect classes that appear on the same WBM, the more difficult it is to recognize and segment. However, whether it is a mixture of two defects, three defects, or four defects, our model accurately accomplished the recognition and segmentation of WBMs in the testing set. Table 2. Segmentation and classification result"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_37", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 37, "text": "a mixture of two defects, three defects, or four defects, our model accurately accomplished the recognition and segmentation of WBMs in the testing set. Table 2. Segmentation and classification results for normal and single-type defect patterns (%). Category C0 C1 C2 C3 C4 C5 C6 C7 C8 SegmentationPacc - 98.69 96.40 95.95 98.02 96.90 91.49 98.74 90.11 IoU - 96.21 94.19 93.23 95.88 96.05 89.35 97.55 88.46 ClassificationAccuracy 98.75 98.67 95.83 96.89 98.41 97.04 94.54 98.72 92.32 Precision 96.66 97.24 93.46 91.89 98.74 97.30 92.07 95.41 88.74 Recall 93.19 92.95 95.20 96.11 97.68 94.69 96.38 92.88 95.01 Table 3. Segmentation results for mixed-type defect patterns (%). CategoryC D EL ER L S Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU C9 98.57 96.12 - - 95.94 93.23 - - - - - - C10 98.66 96.19 - - - - 97.94 95.48 - - - - C11 98.49 96.10 - - - - - - 96.88 96.01 - - C12 98.48 96.10 - - - - - - - - 91.48 89.35 C13 - - 96.23 93.89 95.66 93.10 - - - - - - Sensors 2025 ,25, 1272 13 of 18 Table 3. Cont. CategoryC D EL ER L S Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU C14 - - 96.31 94.08 - - 97.91 95.47 - - - - C15 - - 96.20 93.88 - - - - 96.79 95.12 - - C16 - - 96.22 93.85"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_38", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 38, "text": "8 Table 3. Cont. CategoryC D EL ER L S Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU Pacc IoU C14 - - 96.31 94.08 - - 97.91 95.47 - - - - C15 - - 96.20 93.88 - - - - 96.79 95.12 - - C16 - - 96.22 93.85 - - - - - - 91.46 89.34 C17 - - - - 95.21 92.16 - - 96.20 95.03 - - C18 - - - - 95.29 92.17 - - - - 91.34 89.19 C19 - - - - - - 97.82 95.40 96.77 95.13 - - C20 - - - - - - 97.77 95.35 - - 91.22 89.15 C21 - - - - - - - - 96.18 94.99 90.79 88.94 C22 98.43 96.02 - - 95.32 92.20 - - 96.14 94.90 - - C23 98.42 96.02 - - 95.32 92.21 - - - - 90.19 88.03 C24 98.45 96.04 - - - - 97.52 95.06 96.02 94.78 - - C25 98.45 96.03 - - - - 97.55 95.07 - - 90.12 87.94 C26 - - 95.18 91.98 93.40 91.03 - - 94.99 92.11 - - C27 - - 95.15 91.90 93.39 91.03 - - - - 90.10 89.90 C28 - - 95.20 91.92 - - 96.18 94.89 95.03 92.12 - - C29 - - 95.18 91.97 - - 96.15 94.87 - - 90.10 87.89 C30 98.39 95.95 - - - - - - 94.95 92.03 90.02 87.86 C31 - - 95.11 91.86 - - - - 94.92 92.02 90.01 87.85 C32 - - - - 93.08 90.02 - - 94.86 91.95 89.90 87.80 C33 - - - - - - 96.05 94.80 94.87 91.95 89.90 87.81 C34 97.98 95.07 - - 92.11 89.20 - - 93.87 90.26 88.40 85.98 C35 98.00 95.08 - - - - 95.11 93.57 93.89 90.27 88.41 85.98 C36 - - 93."}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_39", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 39, "text": "1.95 89.90 87.80 C33 - - - - - - 96.05 94.80 94.87 91.95 89.90 87.81 C34 97.98 95.07 - - 92.11 89.20 - - 93.87 90.26 88.40 85.98 C35 98.00 95.08 - - - - 95.11 93.57 93.89 90.27 88.41 85.98 C36 - - 93.85 90.07 92.03 88.79 - - 93.08 89.88 88.16 85.21 C37 - - 93.90 90.10 - - 94.79 93.14 93.11 89.95 88.18 85.25 Table 4. Classification results for mixed-type defect patterns (%). Category Accuracy Precision Recall C9 95.62 98.67 93.30 C10 96.19 97.98 94.02 C11 94.45 97.56 93.88 C12 93.87 92.43 98.14 C13 91.92 93.00 97.44 C14 93.85 94.86 95.12 C15 91.68 96.33 92.88 C16 91.61 91.44 98.05 C17 94.31 97.87 93.30 C18 92.41 91.55 97.20 C19 92.84 92.34 94.99 C20 92.69 90.59 96.22 C21 91.88 96.81 91.74 C22 92.45 89.84 93.10 C23 89.97 95.44 92.13 C24 91.93 98.01 90.74 C25 90.76 93.71 89.67 C26 90.55 91.35 97.28 C27 89.68 91.55 96.98 C28 92.61 90.24 98.00 C29 89.77 99.01 92.74 C30 90.18 98.12 94.17 C31 89.11 94.38 96.05 C32 90.56 97.35 93.69 C33 90.34 92.44 96.77 C34 88.76 88.29 95.13 C35 89.52 91.30 93.27 C36 87.41 96.66 89.35 C37 88.49 87.80 94.06 Figure 7 presents several mixed-type WBM segmentation results achieved with our proposed model. We randomly selected eight experimental samples, each d"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_40", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 40, "text": "3.27 C36 87.41 96.66 89.35 C37 88.49 87.80 94.06 Figure 7 presents several mixed-type WBM segmentation results achieved with our proposed model. We randomly selected eight experimental samples, each displaying the original mixed-type WBM, label map, and corresponding segmentation output. We can see that the segmentation maps obtained using our model are smooth, complete, and robust to Sensors 2025 ,25, 1272 14 of 18 noise. Even in the cases where several mixed defect patterns are overlapped, our model can still distinguish them based on the different characteristics of each defect pattern. For all these defect patterns, the CandERclasses are best classified and segmented. This is because the location and shape of the Cand ERdefect patterns are relatively fixed and easier to distinguish. Even for the Sclass, which may easily interact with other pattern classes, our model still has an excellent segmentation performance. Therefore, our model has great potential and application value in the field of WBMs classification and segmentation. Figure 7. Examples of visualization results obtained using our proposed model. 4.3.3. Comparison with Other Methods In this section, we compare the per"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_41", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 41, "text": "e field of WBMs classification and segmentation. Figure 7. Examples of visualization results obtained using our proposed model. 4.3.3. Comparison with Other Methods In this section, we compare the performance of our proposed model with other self- supervised learning models, including Jigsaw [ 34], SimCLR [ 9], and MoCo v2 [ 8]. These are all relatively successful contrastive learning models. To ensure fairness in comparison, all models used in the experiments have the same dataset and division ratio as in the previous section. As shown in Table 5, the horizontal axis represents the overall evaluation metrics for seg- mentation and classification, including mPacc ,mIoU (used for segmentation), and Accuracy , Precision , and Recall (used for classification), while the vertical axis displays the numerical results for each method across these metrics. The overall mPacc ,mIoU ,Accuracy ,Precision , andRecall values of our model are as high as 95.59%, 92.19%, 93.57%, 94.43%, and 94.78%, respectively. These indicators are far superior to the other three self-supervised contrastive learning methods. SimCLR performs the worst, with the overall IoUandAccuracy values only being 75.85% and 80"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_42", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 42, "text": "pectively. These indicators are far superior to the other three self-supervised contrastive learning methods. SimCLR performs the worst, with the overall IoUandAccuracy values only being 75.85% and 80.41%. This is related to the fact that SimCLR relies more on large batch data, and the model cannot learn more useful knowledge from limited data. Although self- supervised contrastive learning is widely used in the field of image classification, research on segmentation tasks is still somewhat lacking. The other three common contrastive learning methods used for comparison only focus on global representations; thus, they ignore the local information, which is important for segmentation tasks. So, even after the fine-tuning period, their performance is still not excellent. However, our approach is designed to focus on both the global and local information of the image. Therefore, the proposed model can perform well whether the WBM defect patterns are easy or difficult to distinguish. Table 5. Comparison with other methods using limited labeled data on WBM defect pattern recogni- tion and segmentation task (%). MethodsSegmentation (Overall) Recognition (Overall) mPacc mIoU Accuracy Prec"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_43", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 43, "text": " 5. Comparison with other methods using limited labeled data on WBM defect pattern recogni- tion and segmentation task (%). MethodsSegmentation (Overall) Recognition (Overall) mPacc mIoU Accuracy Precision Recall Jigsaw 83.66 76.19 80.94 78.44 81.71 SimCLR 83.43 75.85 80.41 75.96 78.13 MoCo v2 84.11 78.52 82.46 80.08 83.25 Ours 95.59 92.19 93.57 94.43 94.78 Sensors 2025 ,25, 1272 15 of 18 4.4. Discussion 4.4.1. Effectiveness of the Amount of Self-Supervised Unlabeled Data Self-supervised pre-training needs to use a large amount of unlabeled data, and an abundance of unlabeled WBMs is readily accessible in the industrial manufacturing pro- cess. Therefore, this section investigates the potential of more self-supervised pre-training unlabeled data improving the performance of the model. Building upon our WBM dataset, we randomly utilized 1%, 25%, 50%, 75%, and 100% pre-training unlabeled WBMs. As pre- sented in Table 6, the horizontal axis represents different amounts of pre-training unlabeled data, while the vertical axis displays various evaluation metrics for segmentation and classification. The experimental results indicate an overall upward trend as the amount of unlabeled data "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_44", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 44, "text": "abeled data, while the vertical axis displays various evaluation metrics for segmentation and classification. The experimental results indicate an overall upward trend as the amount of unlabeled data increases. This is because more unlabeled pre-training data contain richer features, so the model can learn more distinctive feature representations, thereby improving the generalization ability. Hence, it can be anticipated that the proposed method may yield even greater benefits when applied to a larger dataset for self-supervised pre-training. Table 6. Experimental results with different amounts of pre-training unlabeled data (%). Different Amounts of Pre-Training 1% 25% 50% 75% 100% Unlabeled Data (152) (3800) (7600) (11,400) (15,200) Segmentation results (Overall)mPacc 31.12 40.55 72.64 89.33 95.59 mIoU 29.33 40.17 63.81 82.30 92.19 Classification results (Overall)Accuracy 27.94 38.55 70.66 86.45 93.57 Precision 28.60 41.07 70.23 85.04 94.43 Recall 30.41 45.02 71.38 88.10 94.78 4.4.2. Effectiveness of the Amount of Fine-Tuning Labeled Data This section examines the influence of utilizing additional labeled data for fine-tuning on model performance. Initially, we expanded the fine-"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_45", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 45, "text": " Effectiveness of the Amount of Fine-Tuning Labeled Data This section examines the influence of utilizing additional labeled data for fine-tuning on model performance. Initially, we expanded the fine-tuning labeled dataset to the same size as the pre-training unlabeled dataset. Then, we fine-tuned the model using varying proportions of labeled data, specifically 1%, 5%, 10%, 25%, 50%, and 100% of the self-supervised unlabeled data. The results, presented in Table 7, indicate that as the amount of labeled fine-tuning data increased, the evaluation metrics exhibited an upward trend, although at a diminishing rate. This can be attributed to the model‚Äôs ability to learn more information with an increasing number of labels but with a diminishing rate for each additional label. When the amount of labeled data reaches 25% of the self- supervised unlabeled data, the model achieves outstanding performance, and almost all of the evaluation metrics reach a fairly satisfactory result. Therefore, our proposed self- supervised contrastive learning model is not heavily dependent on the size of the labeled data but still remains effective even when a large amount of labeled data are available. Tab"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_46", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 46, "text": "ur proposed self- supervised contrastive learning model is not heavily dependent on the size of the labeled data but still remains effective even when a large amount of labeled data are available. Table 7. Experimental results with different amounts of fine-tuning labeled data (%). Different Amounts of Fine-T uning 1% 5% 10% 25% 50% 100% Labeled Data (152) (760) (1520) (3800) (7600) (15,200) Segmentation results (Overall)mPacc 56.32 70.92 88.25 95.54 95.72 95.80 mIoU 48.67 63.11 81.55 92.10 92.19 92.23 Classification results (Overall)Accuracy 57.08 71.10 87.55 93.49 93.60 93.64 Precision 58.68 75.43 89.02 94.38 94.92 95.17 Recall 52.87 74.16 85.39 94.77 95.06 95.33 Sensors 2025 ,25, 1272 16 of 18 4.4.3. Ablation Study In this section, we describe ablation experiments we conducted to investigate the effec- tiveness of the modules in our proposed method. Our proposed model mainly consists of three parts: global contrastive learning module, local contrastive learning module, and fine- tuning module. We chose to remove one or two modules separately for experimental research. The experimental results are shown in Table 8. We present the results of the abla- tive experiments conducted to"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_47", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 47, "text": "ing module. We chose to remove one or two modules separately for experimental research. The experimental results are shown in Table 8. We present the results of the abla- tive experiments conducted to assess the effectiveness of different modules. The horizontal axis represents the evaluation metrics, while the vertical axis lists various combinations of the modules. When there is only the global contrastive learning module or only the local contrastive learning module, the performance is slightly inferior to the experimental results obtained from the complete network. This indicates that both the global information and local information are beneficial for our segmentation and recognition task from different perspectives. Therefore, when removing both the global and local modules, the model performance becomes extremely poor. The purpose of the fine-tuning module is to make the self supervised pre-trained model better adapt to the specific downstream task. Hence, when the fine-tuning module is removed, the model does not adapt well to the recognition and segmentation of mixed-type WBM defect patterns. To sum up, each module is proven to be crucial for the performance of the model t"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_48", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 48, "text": "odule is removed, the model does not adapt well to the recognition and segmentation of mixed-type WBM defect patterns. To sum up, each module is proven to be crucial for the performance of the model through the ablation experiments. Table 8. Results of ablation experiments on exploring the effectiveness of each module (%). Modules Segmentation (Overall) Classification (Overall) Global Local Fine-T uning mPacc mIoU Accuracy Precision Recall ‚àö ‚àö ‚àö95.59 92.19 93.57 94.43 94.78 ‚àö ‚àö75.09 71.54 72.64 75.16 71.81‚àö ‚àö84.11 78.52 82.46 80.08 83.25‚àö ‚àö86.44 80.22 84.10 80.59 85.67‚àö52.76 45.28 50.49 49.77 55.01 5. Conclusions In this paper, we introduce a self-supervised contrastive learning model designed for the classification and segmentation of mixed-type WBM defect patterns. The experi- mental results indicate that our model surpasses other self-supervised contrastive learning approaches. Furthermore, we demonstrate that the performance of our proposed model does not heavily depend on labeled data, but more self-supervised unlabeled pre-training data can improve the model‚Äôs performance. And the ablation study further assesses the contribution of each model component to the overall performa"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_49", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 49, "text": "data, but more self-supervised unlabeled pre-training data can improve the model‚Äôs performance. And the ablation study further assesses the contribution of each model component to the overall performance. In practical scenarios where large amounts of unlabeled WBM data can be easily obtained, our proposed model will have significant real-world applications. However, in the process of chip manufactur- ing, even minor defects can lead to chip failure or performance degradation. Therefore, the requirements for defect detection are extremely stringent. We will focus on improving the detection performance with a limited number of labeled samples. In future research, we aim to integrate network architecture optimizations with self-supervised learning to increase model evaluation accuracy, reduce processing time, and lower computational resource demands. We also plan to extend the application of our model to other fields, such as medical image segmentation and remote sensing image analysis. Author Contributions: All authors contributed to the study conception and design. Material prepa- ration, data collection, and analysis were performed by S.Y., Y.Z. and R.W. The first draft of the manu"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_50", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 50, "text": "uthor Contributions: All authors contributed to the study conception and design. Material prepa- ration, data collection, and analysis were performed by S.Y., Y.Z. and R.W. The first draft of the manuscript was written by S.Y., and all authors commented on previous versions of the manuscript. All authors have read and agreed to the published version of the manuscript. Sensors 2025 ,25, 1272 17 of 18 Funding: This work was supported in part by the National Natural Science Foundation of China under Grant 72101065; in part by the Guangdong Basic and Applied Basic Research Foundation under Grants 2021A1515110336, 2020A1515110246; and in part by the Shenzhen Science and Technology Program under Grant RCBS20221008093124063. Institutional Review Board Statement: Not applicable. Informed Consent Statement: Not applicable. Data Availability Statement: The datasets used in this study are available from the corresponding author upon reasonable request. These data were used under license for the current study and cannot be redistributed without permission from the data provider. Conflicts of Interest: The authors declare that they have no known competing financial interests or personal relatio"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_51", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 51, "text": "urrent study and cannot be redistributed without permission from the data provider. Conflicts of Interest: The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References 1. Shin, E.; Yoo, C.D. Efficient Convolutional Neural Networks for Semiconductor Wafer Bin Map Classification. Sensors 2023 , 23, 1926. [CrossRef] [PubMed] 2. Chiu, M.-C.; Chen, T.-M. Applying Data Augmentation and Mask R-CNN-Based Instance Segmentation Method for Mixed-Type Wafer Maps Defect Patterns Classification. IEEE Trans. Semicond. Manuf. 2021 ,34, 455‚Äì463. [CrossRef] 3. Nakazawa, T.; Kulkarni, D.V . Wafer Map Defect Pattern Classification and Image Retrieval Using Convolutional Neural Network. IEEE Trans. Semicond. Manuf. 2018 ,31, 309‚Äì314. [CrossRef] 4. Lee, H.; Kim, H. Semi-Supervised Multi-Label Learning for Classification of Wafer Bin Maps With Mixed-Type Defect Patterns. IEEE Trans. Semicond. Manuf. 2020 ,33, 653‚Äì662. [CrossRef] 5. Wang, J.; Xu, C.; Yang, Z.; Zhang, J.; Li, X. Deformable Convolutional Networks for Efficient Mixed-Type Wafer Defect Pattern Recognition. IEEE Trans. Semic"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_52", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 52, "text": "nd. Manuf. 2020 ,33, 653‚Äì662. [CrossRef] 5. Wang, J.; Xu, C.; Yang, Z.; Zhang, J.; Li, X. Deformable Convolutional Networks for Efficient Mixed-Type Wafer Defect Pattern Recognition. IEEE Trans. Semicond. Manuf. 2020 ,33, 587‚Äì596. [CrossRef] 6. Liu, C.W.; Chien, C.F. An intelligent system for wafer bin map defect diagnosis: An empirical study for semiconductor manufacturing. Eng. Appl. Artif. Intell. 2013 ,26, 1479‚Äì1486. [CrossRef] 7. Qian, Y.; Tang, S.-K. Multi-Scale Contrastive Learning with Hierarchical Knowledge Synergy for Visible-Infrared Person Re- Identification. Sensors 2025 ,25, 192. [CrossRef] 8. Chen, X.; Fan, H.; Girshick, R.; He, K. Improved baselines with momentum contrastive learning. arXiv 2020 , arXiv:2003.04297. 9. Chen, T.; Kornblith, S.; Norouzi, M.; Hinton, G. A simple framework for contrastive learning of visual representations. In Proceedings of the International Conference on Machine Learning, Los Angeles, CA, USA, 12‚Äì18 July 2020; pp. 1597‚Äì1607. 10. Zhang, Y.; Zhang, Q. Semantic Segmentation of Traffic Scene Based on DeepLabv3+ and Attention Mechanism. In Proceedings of the International Conference on Neural Networks, Information and Communication Engineer"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_53", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 53, "text": " Zhang, Q. Semantic Segmentation of Traffic Scene Based on DeepLabv3+ and Attention Mechanism. In Proceedings of the International Conference on Neural Networks, Information and Communication Engineering, Guangzhou, China, 10‚Äì12 December 2023; pp. 542‚Äì547. 11. Li, H.; Li, Y.; Zhang, G.; Liu, R.; Huang, H.; Zhu, Q.; Tao, C. Global and Local Contrastive Self-Supervised Learning for Semantic Segmentation of HR Remote Sensing Images. IEEE Trans. Geosci. Remote Sens. 2022 ,60, 5618014. [CrossRef] 12. Tong, L.I.; Wang, C.H.; Huang, C.L. Monitoring defects in IC fabrication using a Hotelling T/sup 2/ control chart. IEEE Trans. Semicond. Manuf. 2005 ,18, 140‚Äì147. [CrossRef] 13. Kim, B.; Jeong, Y.S.; Tong, S.H.; Chang, I.K.; Jeong, M.K. Step-Down Spatial Randomness Test for Detecting Abnormalities in DRAM Wafers with Multiple Spatial Maps. IEEE Trans. Semicond. Manuf. 2016 ,29, 57‚Äì65. [CrossRef] 14. Wang, C.H.; Kuo, W.; Bensmail, H. Detection and classification of defect patterns on semiconductor wafers. IIE Trans. 2006 , 38, 1059‚Äì1068. [CrossRef] 15. Yuan, T.; Kuo, W. Spatial defect pattern recognition on semiconductor wafers using model-based clustering and Bayesian inference. Eur. J. Ope"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_54", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 54, "text": "or wafers. IIE Trans. 2006 , 38, 1059‚Äì1068. [CrossRef] 15. Yuan, T.; Kuo, W. Spatial defect pattern recognition on semiconductor wafers using model-based clustering and Bayesian inference. Eur. J. Oper. 2008 ,190, 228‚Äì240. [CrossRef] 16. Wang, R.; Che, N. Wafer Map Defect Pattern Recognition Using Rotation-Invariant Features. IEEE Trans. Semicond. Manuf. 2019 , 32, 596‚Äì604. [CrossRef] 17. Kang, H.; Kang, S. Semi-supervised rotation-invariant representation learning for wafer map pattern analysis. Eng. Appl. Artif. Intell. 2023 ,120, 105864. [CrossRef] 18. Byun, Y.; Baek, J.G. Mixed Pattern Recognition Methodology on Wafer Maps with Pre-trained Convolutional Neural Networks. In Proceedings of the International Conference on Agents and Artificial Intelligence, Lisbon, Portugal, 19‚Äì21 February 2020; pp. 53‚Äì62. 19. Tello, G.; Al-Jarrah, O.Y.; Yoo, P .D.; Al-Hammadi, Y.; Muhaidat, S.; Lee, U. Deep-Structured Machine Learning Model for the Recognition of Mixed-Defect Patterns in Semiconductor Fabrication Processes. IEEE Trans. Semicond. Manuf. 2018 ,31, 315‚Äì322. [CrossRef] Sensors 2025 ,25, 1272 18 of 18 20. Kyeong, K.; Kim, H. Classification of Mixed-Type Defect Patterns in Wafer Bin Ma"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_55", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 55, "text": "r Fabrication Processes. IEEE Trans. Semicond. Manuf. 2018 ,31, 315‚Äì322. [CrossRef] Sensors 2025 ,25, 1272 18 of 18 20. Kyeong, K.; Kim, H. Classification of Mixed-Type Defect Patterns in Wafer Bin Maps Using Convolutional Neural Networks. IEEE Trans. Semicond. Manuf. 2018 ,31, 395‚Äì402. [CrossRef] 21. Nag, S.; Makwana, D.; Mittal, S.; Mohan, C.K. Wafersegclassnet‚ÄîA light-weight network for classification and segmentation of semiconductor wafer defects. Comput. Ind. 2022 ,142, 103720. [CrossRef] 22. He, K.; Gkioxari, G.; Doll√°r, P .; Girshick, R. Mask r-cnn. In Proceedings of the IEEE International Conference on Computer Vision, Washington, DC, USA, 22‚Äì29 October 2017; pp. 33‚Äì42. 23. Yan, J.; Sheng, Y.; Piao, M. Semantic Segmentation-Based Wafer Map Mixed-Type Defect Pattern Recognition. IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst. 2023 ,42, 4065‚Äì4074. [CrossRef] 24. Wang, Y.; Liu, G. Self-Supervised Dam Deformation Anomaly Detection Based on Temporal‚ÄìSpatial Contrast Learning. Sensors 2024 ,24, 5858. [CrossRef] [PubMed] 25. Kumari, P .; Kern, J.; Raedle, M. Self-Supervised and Zero-Shot Learning in Multi-Modal Raman Light Sheet Microscopy. Sensors 2024 ,24, 8143. [CrossRef"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_56", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 56, "text": " Sensors 2024 ,24, 5858. [CrossRef] [PubMed] 25. Kumari, P .; Kern, J.; Raedle, M. Self-Supervised and Zero-Shot Learning in Multi-Modal Raman Light Sheet Microscopy. Sensors 2024 ,24, 8143. [CrossRef] 26. Wu, Z.; Xiong, Y.; Yu, S.X.; Lin, D. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18‚Äì22 June 2018; pp. 3733‚Äì3742. 27. Kwak, M.G.; Lee, Y.J.; Kim, S.B. SWaCo: Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning. IEEE Trans. Semicond. Manuf. 2023 ,6, 416‚Äì424. [CrossRef] 28. Kahng, H.; Kim, S.B. Self-supervised representation learning for wafer bin map defect pattern classification. IEEE Trans. Semicond. Manuf. 2020 ,34, 74‚Äì86. [CrossRef] 29. Hu, H.; He, C.; Li, P . Semi-supervised Wafer Map Pattern Recognition using Domain-Specific Data Augmentation and Contrastive Learning. In Proceedings of the 2021 IEEE International Test Conference, Anaheim, CA, USA, 1‚Äì4 November 2021; pp. 113‚Äì122. 30. Oord, A.V .D.; Li, Y.; Vinyals, O. Representation learning with contrastive predictive coding. arXiv 2018 , arXiv:1807.03748. 31. Jadon, "}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_57", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 57, "text": "ference, Anaheim, CA, USA, 1‚Äì4 November 2021; pp. 113‚Äì122. 30. Oord, A.V .D.; Li, Y.; Vinyals, O. Representation learning with contrastive predictive coding. arXiv 2018 , arXiv:1807.03748. 31. Jadon, S. A survey of loss functions for semantic segmentation. In Proceedings of the 2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology, Via del Mar, Chile, 3‚Äì5 August 2020; pp. 1‚Äì7. 32. Mann, W.R.; Taber, F.L.; Seitzer, P .W.; Broz, J.J. The leading edge of production wafer probe test technology. In Proceedings of the 2004 International Conferce on Test, Charlotte, NC, USA, 25‚Äì29 April 2004; pp. 1168‚Äì1195. 33. Chen, L.C.; Papandreou, G.; Schroff, F.; Adam, H. Rethinking atrous convolution for semantic image segmentation. arXiv 2017 , arXiv:1706.05587. 34. Noroozi, M.; Favaro, P . Unsupervised learning of visual representations by solving jigsaw puzzles. In Proceedings of the European Conference on Computer Vision, Amsterdam, The Netherlands, 8‚Äì16 October 2016; pp. 69‚Äì84. Disclaimer/Publisher‚Äôs Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or"}
{"id": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf::chunk_58", "source": "Contrastive Learning with Global and Local Representation for Mixed-Type Wafer Defect Recognition.pdf", "chunk_index": 58, "text": "ber 2016; pp. 69‚Äì84. Disclaimer/Publisher‚Äôs Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_0", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 0, "text": "Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 https://doi.org/10.1007/s10845-024-02351-0 CowSSL: contrastive open-world semi-supervised learning for wafer bin map Insung Baek1¬∑Sung Jin Hwang2¬∑Seoung Bum Kim1 Received: 21 June 2023 / Accepted: 19 February 2024 / Published online: 29 March 2024 ¬© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024 Abstract In the semiconductor industry, wafer bin maps (WBMs) refer to image data that reveal the defect of each chip positionedon that wafer. The WBMs provide crucial information that can facilitate the identiÔ¨Åcation of underlying causes for any defects present on a wafer. With the advent of artiÔ¨Åcial intelligence (AI), a signiÔ¨Åcant amount of research has been conducted leveraging machine learning and deep learning techniques to automatically classify wafer bin map defects. Although therehave been various attempts to enhance performance by using both unlabeled and labeled data, current research is constrainedby its narrow focus on improving the detection of known defect patterns. However, in the real world, multiple novel patterns frequently arise that have not been previo"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_1", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 1, "text": ", current research is constrainedby its narrow focus on improving the detection of known defect patterns. However, in the real world, multiple novel patterns frequently arise that have not been previously encountered. Hence, AI models must exhibit the capacity to detect not only existing known defect patterns but also newly emerging defect patterns, while ensuring effective classiÔ¨Åcation of these newpatterns among themselves. In this study, we propose the contrastive open-world semi-supervised learning that can classify multiple novel patterns in WBMs simultaneously. We introduce a contrastive loss function to address the challenges associated with the existence of signiÔ¨Åcantly fewer new defect patterns than existing patterns in the WBM problem. We conÔ¨Årm that theproposed methodology effectively detects and classiÔ¨Åes diverse new patterns separately in real-world open data, WM-811 K. Moreover, we demonstrate that the proposed method outperforms other existing open-world semi-supervised learning in WBM classiÔ¨Åcation. Keywords Semiconductor manufacturing ¬∑Defect patterns classiÔ¨Åcation ¬∑Wafer bin map ¬∑Open-world recognition ¬∑ Semi-supervised learning ¬∑Contrastive learning Introduction "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_2", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 2, "text": "learning in WBM classiÔ¨Åcation. Keywords Semiconductor manufacturing ¬∑Defect patterns classiÔ¨Åcation ¬∑Wafer bin map ¬∑Open-world recognition ¬∑ Semi-supervised learning ¬∑Contrastive learning Introduction In the semiconductor manufacturing industry, a wafer is a thin disk made of silicon and includes hundreds of semi-conductor chips. In the wafer fabrication process, attaining Insung Baek and Sung Jin Hwang have contributed equally to this work. B Seoung Bum Kim sbkim1@korea.ac.kr Insung Baek insung_baek01@korea.ac.kr Sung Jin Hwang sj90.hwang@samsung.com 1School of Industrial and Management Engineering, Korea University, Seoul 02841, Republic of Korea 2Memory Defect Science & Engineering Group, Samsung Electronics, Hwaseong 18448, Republic of Koreaoptimal yield and quality requires minimizing the occur- rence of defects, rapidly identifying the causative factors, and implementing corrective measures when defects arise (Choudhary et al., 2009 ; Jang et al., 2020 ; Jang & Lee, 2023 ; Kang, 2020 ). Thus, engineers conduct an array of inspections to assess the condition of the wafers and determine whether any defects are present. For example, electrical die sorting(EDS) serves as a method "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_3", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 3, "text": "020 ). Thus, engineers conduct an array of inspections to assess the condition of the wafers and determine whether any defects are present. For example, electrical die sorting(EDS) serves as a method of verifying the proper functioning of each chip on a wafer, yielding wafer bin map (WBM) data. A WBM constitutes a format of image data that illustratesthe position of each chip and designates its defective or non-defective status, as shown in Fig. 1. WBM patterns exhibit distinct variations depending on the underlying causes of the failure, serving as crucial indicators for estimating the originof the malfunction (Jin et al., 2020 ; Kong & Ni, 2021 ). Hence, the classiÔ¨Åcation of failure patterns in WBMs represents an essential process that serves as the foundation of yield qual-ity management. Indeed, the manual classiÔ¨Åcation of each 123 2164 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 Fig. 1 E x a m p l eo faw a f e rb i nm a p WBM, generated at high volumes, is a labor-intensive and costly endeavor for engineers, necessitating the developmentof a model capable of performing automated classiÔ¨Åcation. However, building an automated model to classify wafer defects poses a "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_4", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 4, "text": "ensive and costly endeavor for engineers, necessitating the developmentof a model capable of performing automated classiÔ¨Åcation. However, building an automated model to classify wafer defects poses a signiÔ¨Åcant challenge because of the followingcharacteristics of WBM. First, the scarcity of labeled data for model training poses a signiÔ¨Åcant challenge (Kahng & Kim, 2021 ). Obtaining labels is costly and time-consuming because WBM generated in real industries necessitates theinvolvement of numerous specialized engineers to perform manual inspection and assign accurate labels. Moreover, maintaining a continuous labeling process for the vastamount of newly generated WBMs is nearly impossible because of accumulating tens of thousands of WBMs. There- fore, leveraging not only a limited pool of labeled data butalso a considerable amount of unlabeled data becomes nec- essary. Second, actual WBMs have the potential to produce novel failure patterns that have not been previously identi-Ô¨Åed (Jang et al., 2020 ; Jang & Lee, 2023 ; Kong & Ni, 2021 ). Engineers can promptly take appropriate measures when a previously known defect pattern emerges because of their accumulated experience in identif"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_5", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 5, "text": " et al., 2020 ; Jang & Lee, 2023 ; Kong & Ni, 2021 ). Engineers can promptly take appropriate measures when a previously known defect pattern emerges because of their accumulated experience in identifying the root cause of thedefect and taking the appropriate actions to address it. How- ever, when a novel defect pattern emerges, its root cause may not be immediately apparent. In such cases, tracing the causeof the defect is essential to mitigate the risk of potential qual- ity incidents. Hence, developing a model capable of not only classifying known patterns but also detecting diverse emerg-ing new defect patterns is necessary. Finally, although a newdefect pattern may be identiÔ¨Åed, various patterns may exist in this new defect pattern. In the semiconductor industry, identifying and categorizing new defect patterns is crucialbecause engineers group wafers with the same new pattern to Ô¨Ånd process paths that cause defects. By tracing the root cause of the defect and implementing appropriate correc-tive measures when a defect pattern is clearly identiÔ¨Åed, it is possible to minimize the incidence of defects and prevent potential accidents from occurring. Consequently, an auto-mated mo"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_6", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 6, "text": "iate correc-tive measures when a defect pattern is clearly identiÔ¨Åed, it is possible to minimize the incidence of defects and prevent potential accidents from occurring. Consequently, an auto-mated model for wafer defect classiÔ¨Åcation must be capableof detecting diverse new patterns and classifying them into the appropriate categories. As shown in Fig. 2, developing a predictive model that can classify novel patterns using a signiÔ¨Åcant amount of unlabeled data is essential to achieving this goal. However, existing research on classifying WBM defect patterns has been limited to simply classifying defect pat- terns or detecting new ones (Hsu & Chien, 2022 ; Jang et al., 2020 ; Jang & Lee, 2023 ; Kahng & Kim, 2021 ; Kong & Ni, 2021 ). Therefore, in this study, we use open-world semi- supervised learning that can detect and classify new patterns by utilizing a substantial quantity of unlabeled data (Caoet al., 2021 ; Rizve et al., 2022a ,2022b ). Open-world semi- supervised learning represents an approach that amalgamates open-world recognition and semi-supervised learning. Open-world recognition allows models to simultaneously detectand classify multiple unknown classes (Bendale & Bou"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_7", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 7, "text": "ents an approach that amalgamates open-world recognition and semi-supervised learning. Open-world recognition allows models to simultaneously detectand classify multiple unknown classes (Bendale & Boult, 2015 ;P a r m a re ta l . , 2023 ). This means that when a new defect pattern occurs in the WBM, it can be considered as mul-tiple unknown classes. Semi-supervised learning uses both labeled and unlabeled data when training a model to improve prediction performance (Chapelle et al., 2009 ; V an Engelen & Hoos, 2020 ). This methodology can better reÔ¨Çect the char- acteristics of WBM data, in which a small number of labeled data and a large number of unlabeled data are collected. In this research, we proposed an approach called con- trastive open-world semi-supervised learning (CowSSL) for defect classiÔ¨Åcation of WBMs. We built upon the work of Cao et al. ( 2021 ), which used three different loss functions to train a model on an image dataset containing labeled and unlabeled data classiÔ¨Åed as new classes. Nonetheless, the previous study exhibits limitations in demonstrating its per-formance for general image data where the number of data per class maintains balance. Our approach aims "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_8", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 8, "text": "d as new classes. Nonetheless, the previous study exhibits limitations in demonstrating its per-formance for general image data where the number of data per class maintains balance. Our approach aims to address the challenges of extreme class imbalance in the semiconductorÔ¨Åeld, whereby the number of known pattern classes is over-whelmingly large compared to the number of new patterns that have not been identiÔ¨Åed. This often leads to overÔ¨Åtting to the overwhelmingly known classes, signiÔ¨Åcantly reducingthe performance of new pattern detection and classiÔ¨Åcation accuracy. To overcome this challenge, we introduce a con- trastive loss function to enhance the ability of the model toseparate new patterns from existing patterns and distinguish among different new patterns (Chen et al., 2020a ,2020b ;H e et al., 2020 ). As a result, we propose a methodology that is capable of detecting and classifying new patterns, even when the number of new patterns is comparably small. The main contributions of this study can be summarized as follows: ‚Ä¢The proposed CowSSL method is designed based on the momentum contrastive learning (MoCo) algorithm (Chenet al., 2020a ,2020b ; He et al., 2020 ), which use"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_9", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 9, "text": "of this study can be summarized as follows: ‚Ä¢The proposed CowSSL method is designed based on the momentum contrastive learning (MoCo) algorithm (Chenet al., 2020a ,2020b ; He et al., 2020 ), which uses negative 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2165 Fig. 2 Schematization of open-world semi-supervised learning samples to enhance the detection of very few novel pat- terns in the WBMs. It has been demonstrated that knownand new patterns can be efÔ¨Åciently segregated because theprobability of selecting a small number of novel patterns as negative samples is minimal. ‚Ä¢The effectiveness of the proposed CowSSL loss func- tion that integrates the contrastive loss function into the open-world semi-supervised loss function is validated in the classiÔ¨Åcation of novel patterns corresponding to fewdata. The proposed CowSSL loss function enhances the classiÔ¨Åcation performance of novel patterns in WBMs by clustering new patterns with similar characteristics in theembedding space, while simultaneously separating othernew patterns exhibiting dissimilar characteristics. The reminder of the paper is organized as follows. \"Related works \" Section consists of a review of the st"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_10", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 10, "text": "ace, while simultaneously separating othernew patterns exhibiting dissimilar characteristics. The reminder of the paper is organized as follows. \"Related works \" Section consists of a review of the stud- ies on WBM classiÔ¨Åcation and open-world semi-supervisedlearning. \" Methodology \" Section illustrates the details of the proposed CowSSL method. \" Experiments and results \" Section presents the qualitative and quantitative experimen- tal results. Finally, \" Results \" Section contains our concluding remarks and directions for future research. Related works Wafer bin map classification The WBM classiÔ¨Åcation problem holds signiÔ¨Åcant impor- tance in the semiconductor industry and has been widely studied using a variety of algorithms. Recently, the evolu-tion of machine learning has led to the exploration of this problem using several models with remarkable classiÔ¨Åcation performance. Wu et al. ( 2015 ) released the wafer bin map data ‚ÄúWM-811K,‚Äù publicly available. The authors employed a support vector machine algorithm to analyze this dataset. Piao et al. ( 2018 ) extracted wafer features using a radon trans- form and used a multiple decision tree ensemble method forclassiÔ¨Åcation. Noneth"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_11", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 11, "text": "ort vector machine algorithm to analyze this dataset. Piao et al. ( 2018 ) extracted wafer features using a radon trans- form and used a multiple decision tree ensemble method forclassiÔ¨Åcation. Nonetheless, these techniques suffer from the limitation of reduced classiÔ¨Åcation accuracy with increas-ing intricacy of the wafer pattern shape. Recently, there hasbeen signiÔ¨Åcant progress in the utilization of convolutional neural networks (CNN) to analyze WBM image data. Lee et al. ( 2017 ) introduced an FDC-CNN model aimed at clas- sifying one normal class and Ô¨Åve fault classes using wafer data collected from an on-site chemical vapor deposition (CVD) tool. The model achieved an impressive accuracy of97.9%. Nakazawa and Kulkarni generated a set of 22 defect classes using synthetic wafers and subsequently trained a CNN model using 15,400 samples as the training data. Themodel achieved a high classiÔ¨Åcation accuracy of 98.2%.Kyeong and Kim ( 2018 ) proposed an approach for defect classiÔ¨Åcation that considers multiple patterns on a wafer, as opposed to traditional methods that focus on a single pattern.However, the aforementioned studies are based on supervised learning, which requires a con"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_12", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 12, "text": "that considers multiple patterns on a wafer, as opposed to traditional methods that focus on a single pattern.However, the aforementioned studies are based on supervised learning, which requires a considerable amount of labeled data for training. However, obtaining adequate labeled datain the semiconductor industry requires signiÔ¨Åcant resources. Therefore, there is a pressing need for a methodology that can effectively utilize the abundant amounts of unlabeleddata present for the classiÔ¨Åcation of WBM failure patterns. Shim et al. ( 2020 ) demonstrated that high classiÔ¨Åcation performance can be achieved with a limited amount of labeled data by utilizing uncertainty-based sample selec-tion techniques that prioritize samples having the greatest impact on performance. Kahng and Kim ( 2021 ) proposed a self-supervised learning model involving CNNs and pretext-invariant representation learning to effectively classify WBM defect patterns. Although these studies have the advantage of utilizing unlabeled data, they do not consider the possibilityof new patterns that may emerge in practice. Jang et al. ( 2020 ) introduced the support weighted ensemble model for detect- ing a new pattern. Jan"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_13", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 13, "text": " unlabeled data, they do not consider the possibilityof new patterns that may emerge in practice. Jang et al. ( 2020 ) introduced the support weighted ensemble model for detect- ing a new pattern. Jang and Lee ( 2023 ) proposed an open-set recognition model that employs probability scores derivedfrom the calculated reconstruction errors and random net- work errors. Although these studies have achieved success 123 2166 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 in detecting new patterns in WBM, they fall short in classi- fying multiple new patterns simultaneously. Jin et al. ( 2019 ) introduced a pattern clustering method for WBMs by using DBSCAN (density based spatial clustering of applications with noise). Park et al. ( 2021 ) used a classiÔ¨Åcation tech- nique that involves label reassignment based on a Siamesenetwork approach. Although pattern clustering and label reassignment techniques have demonstrated the potential for identifying new patterns, there is a dearth of open-worldlearning studies that cater to the speciÔ¨Åc characteristics of WBM, such as similarity of features across classes and smaller amounts of new pattern data. In this study, we pro-posed the CowSS"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_14", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 14, "text": "pen-worldlearning studies that cater to the speciÔ¨Åc characteristics of WBM, such as similarity of features across classes and smaller amounts of new pattern data. In this study, we pro-posed the CowSSL method, which effectively addresses the challenges posed by similarity among WBM classes and a limited number of new pattern data, enabling the accurateclassiÔ¨Åcation of multiple new patterns. Open-world semi-supervised learning The present study addresses a multifaceted problem, aim- ing to develop a model that not only accurately classiÔ¨Åes WBM data but also leverages unlabeled data, effectivelydetects novel patterns, and distinguishes between these pat-terns across multiple classes. Achieving these objectives requires the integration of various research areas in machine learning. Machine learning methodologies that leverage bothlabeled and unlabeled data include semi-supervised learn- ing, open-set recognition for detecting new patterns, and open-world recognition for classifying each class withinnew patterns. Traditional semi-supervised learning studies have conducted under the assumption that labeled and unla- beled data share an equal number of classes (Chapelle et al.,2009 ). Ho"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_15", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 15, "text": "lass withinnew patterns. Traditional semi-supervised learning studies have conducted under the assumption that labeled and unla- beled data share an equal number of classes (Chapelle et al.,2009 ). However, this assumption is frequently violated in practice, as unlabeled data may include new classes hereto- fore not considered. Scheirer et al. ( 2012 ) proposed an open-set recognition approach that assigns samples with dis-tinct features from the recognized classes to novel classes. Although such an approach is capable of detecting new pat- terns, it is not equipped to perform classiÔ¨Åcation betweenthese new classes. Bendale et al. ( 2015 ) introduced the notion of open-world recognition that addresses these limitations by enabling new classes to be identiÔ¨Åed through humanintervention, empowering the model to continually learnnew classes. However, these methods ultimately necessitate human intervention. Cao et al. ( 2021 ) presented the ORCA (open-world with uncertainty-based adaptive margin) algorithm that inte- grates three distinct loss functions to effectively discriminate between multiple novel patterns in unlabeled data. Fol-lowing pre-training with SimCLR (simple framework fo"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_16", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 16, "text": "argin) algorithm that inte- grates three distinct loss functions to effectively discriminate between multiple novel patterns in unlabeled data. Fol-lowing pre-training with SimCLR (simple framework for contrastive learning of visual representations), the model was trained using a loss function that combined three distinct lossfunctions, exhibiting excellent performance across a diverserange of datasets, including MNIST, CIFAR10, CIFAR100, and ImageNet. The ORCA algorithm is based on an open-world semi-supervised learning approach and is noteworthy for its capability to identify and differentiate new classes exclusively through model learning, without the need forhuman intervention. Rizve et al. ( 2022a ,2022b ) noted that the OpenLDN (learning to discover novel classes for open- world semi-supervised learning) method, which involves pre-training with ORCA, is computationally demanding.They proposed an enhancement that incorporates pairwise similarity loss and cross-entropy loss with pseudo-labeling, resulting in improved performance and reduced computa-tional requirements. In the same year, Rizve et al. ( 2022a , 2022b ) proposed TRSSL (toward realistic semi-supervised learning), w"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_17", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 17, "text": "eudo-labeling, resulting in improved performance and reduced computa-tional requirements. In the same year, Rizve et al. ( 2022a , 2022b ) proposed TRSSL (toward realistic semi-supervised learning), which employed pseudo-labeling for training pur-poses and optimized the Sinkhorn‚ÄìKnopp algorithm toenhance the probability distribution between classes. They also presented a method for scaling the uncertainty of the results as the model underwent repeated training to achievesuperior performance. These studies all exhibited strong per- formance on conventional image datasets, such as MNIST, CIFAR10, CIFAR100, and ImageNet. However, unlike con-ventional image data, WBMs exhibit a considerably lower proportion of data points as unknown classes relative to known classes, in addition to the relatively comparable pat-terns across classes. Thus, in this study, we develop anapproach that merges open-world semi-supervised learning with contrastive learning to effectively discriminate a lim- ited number of novel patterns at once, while simultaneouslyaccounting for the unique attributes of WBMs. Methodology Data preprocessing The dataset we used for our experimentation, WM-811K, is publicly avail"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_18", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 18, "text": "mber of novel patterns at once, while simultaneouslyaccounting for the unique attributes of WBMs. Methodology Data preprocessing The dataset we used for our experimentation, WM-811K, is publicly available and encompasses 811,457 WBMs from the real-world. The WM-811K dataset, introduced by Wuet al. ( 2015 ) is renowned for its reliability because it orig- inates from real-world fabrication processes and has been meticulously labeled by domain experts. This inspectionand labeling process is shown in Fig. 3. The WM-811K dataset has been widely used in many studies (Hsu & Chien, 2022 ; Kahng & Kim, 2021 ; Piao et al., 2018 ; Wu et al., 2015 ). Among these, 172,950 wafers were annotated according todefect pattern and were leveraged for experimental valida- tion. Furthermore, we omitted the none class, which does not have any distinct pattern, from our study. The datasetcomprised eight types of patterns including center, edge- loc, edge-ring, loc, scratch, random, donut, and near-full. WBM data is classiÔ¨Åed as either ‚Äònormal‚Äô or ‚Äòfail based onthe inspection of multiple chips on a single wafer. Each chip 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2167 Fig. 3 Test process"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_19", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 19, "text": "ata is classiÔ¨Åed as either ‚Äònormal‚Äô or ‚Äòfail based onthe inspection of multiple chips on a single wafer. Each chip 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2167 Fig. 3 Test process to determine WBM defect pattern is assigned a value of 1 for ‚Äônormal‚Äô or 2 for ‚Äôfail‚Äô results. Throughout this process, the defect patterns are categorized based on how the ‚Äôfail‚Äô chips cluster together. These defec-tive patterns are classiÔ¨Åed by domain experts according totheir shape. For example, a ‚Äôcenter‚Äô pattern indicates that defective chips are concentrated in the middle of the WBM, forming a central shape. Conversely, an ‚Äôedge-ring‚Äô patterndescribes a form where bad chips are arranged in the shape of a ring around the outer edge of the WBM. Given that the near-full pattern is nearly identical to the random pat-tern, it is deemed unnecessary and subsequently removed in this study. Ultimately, as illustrated in Fig. 4, known patterns encompassed four classes, and new patterns composed threeclasses, namely, scratch, random, and donut. Among variouscombinations of selecting known and unknown patters, our choice is based on industry practices in the semiconductor Ô¨Åeld. Given the am"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_20", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 20, "text": "ed threeclasses, namely, scratch, random, and donut. Among variouscombinations of selecting known and unknown patters, our choice is based on industry practices in the semiconductor Ô¨Åeld. Given the ample availability of known pattern data, weselected a sizable sample of edge-ring, edge-loc, center, and loc patterns. In contrast, because of the small amount of data for the new patterns, we selected smaller sample sizes for thescratch, random, and donut classes. To standardize the data, we initially resized each wafer to a consistent size of 32 √ó 32. Because the pixel value represents categorical data thatis categorized as 0 (no wafer area), 1 (good chip), and 2 (badchip), we converted it into three channels through one-hot encoding. Finally, we formed a 3 √ó32√ó32 dimensional image serving as input data. We partitioned the total WM-811 K dataset into training and test sets, with 90% of the data used for training and the remaining 10% for testing. We further divided the trainingdata into labeled and unlabeled sets, with only 20% of the data labeled and the remaining 80% characterized as unlabeled data by masking the original labeling data. Table 1shows the number of labeled, unlabeled,"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_21", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 21, "text": "abeled and unlabeled sets, with only 20% of the data labeled and the remaining 80% characterized as unlabeled data by masking the original labeling data. Table 1shows the number of labeled, unlabeled, and test data records per class.As shown in Table 1, the number of samples in the three new classes, scratch, random, and donut, is smaller than that of the known classes. Finally, we experimentally veriÔ¨Åed thatthe proposed methodology can accurately detect and classify new patterns in a situation in which the amount of unlabeled data is relatively larger than the amount of labeled data andthe number of new patterns is smaller than the number of known patterns. CowSSL Before the training process, we conducted learning with a pre-trained model using the SimCLR algorithm to learn the underlying features of the data (Chen et al., 2020a ,2020b ). For this purpose, we utilized the entire training dataset asinput data for the pre-trained model, without the presence ofany labels. The SimCLR model was designed to learn from the similarity score of input pairs of samples in which high similarity between the two samples indicates that the pres-ence of similar features. When training with a pre-"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_22", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 22, "text": "l was designed to learn from the similarity score of input pairs of samples in which high similarity between the two samples indicates that the pres-ence of similar features. When training with a pre-trained model, generating improved representations becomes possi- ble. This not only improves the models in classifying knownWBM patterns but also helps them perform better in identi- fying new WBM patterns. The designed model in our study learns by utilizing both labeled and unlabeled data, building on a pre-trained 123 2168 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 Fig. 4 Examples of known and new patterns of WBM data in our study Table 1 Description of the dataset. New patterns are not included in the labeled dataKnown/new Patterns (classes) Total Labeled Unlabeled Test Known patterns Edge-Ring 9680 1746 6980 954 Edge-Loc 5189 938 3740 511 Center 4294 771 3100 423 Loc 3593 649 2590 354 New patterns Scratch 1193 0 1076 117 Random 866 781 85 Donut 555 500 55 Total 25,370 4104 18,767 2499 model using SimCLR. In addition, we designed a model that uses a ResNet-18 structure and employs a key encoder to apply a contrastive loss function based on the MoCo algo- rithm (Chen e"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_23", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 23, "text": "04 18,767 2499 model using SimCLR. In addition, we designed a model that uses a ResNet-18 structure and employs a key encoder to apply a contrastive loss function based on the MoCo algo- rithm (Chen et al., 2020a ,2020b ; He et al., 2020 ). Existing open-world semi-supervised learning algorithms, such asORCA, OpenLDN, and TRSSL, used the ResNet-18 model, except for the ImageNet-100 dataset. To ensure an equi- table comparison with these existing algorithms, we alsoused the ResNet-18 model. Figure 5shows an overview of the proposed CowSSL algorithm which was learned via the weighted sum of four loss functions. As shown in Fig. 5, SimCLR pretrain was performed excluding labels from all data (labeled dataset and unlabeled dataset) to learn image features. Subsequently, we trained a query encoder based onthe ResNet-18 model using the initial weight values from the pre-trained model. During this phase, we used the ORCA methodology, which can leverage both labeled and unla- beled datasets. Additionally, to improve the classiÔ¨Åcationof new defective patterns, we used a key encoder that usesnegative samples. During the learning process, the weight of the key encoder was updated at each iter"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_24", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 24, "text": "dditionally, to improve the classiÔ¨Åcationof new defective patterns, we used a key encoder that usesnegative samples. During the learning process, the weight of the key encoder was updated at each iteration using the momentum update method, which combined the weight ofthe query encoder and the key encoder. The key encoder was exclusively used for extracting feature vectors from negative samples during model training and was not usedduring the actual testing stage. Below, we explained a more detailed explanation of the four losses used in CowSSL. Three of the proposed loss functions came from the ORCA 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2169 Fig. 5 Overview of the CowSSL algorithm. (SimCLR pretraining is conducted on all datasets without the use of labels. Subsequently, aquery encoder based on the ORCA methodology is trained using thepre-trained weights as initial values. Furthermore, to enhance the perfor- mance of new pattern classiÔ¨Åcation, a key encoder is used with negativesamples. Consequently, CowSSL is trained using a total of four lossfunctions) method and included the following (Cao et al., 2021 ): (1) The supervised objective with uncertainty adapti"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_25", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 25, "text": "d with negativesamples. Consequently, CowSSL is trained using a total of four lossfunctions) method and included the following (Cao et al., 2021 ): (1) The supervised objective with uncertainty adaptive margin loss function ( Ls) used the uncertainty of the model proba- bility values within the cross-entropy loss to distinguish newpatterns from known patterns. (2) The pairwise binary cross-entropy (BCE) loss function ( L p) grouped similar patterns by facilitating the bringing together of the two pairs with the closest cosine similarity in the batch. (3) Entropy regulariza-tion ( R) ensured that the model did not overÔ¨Åt to any speciÔ¨Åc class. In the ORCA research, just these three loss functions were satisfactory at classifying new patterns but only for reg-ular image data in which the number of classes was the same for all classes and there were clear differences between the features of each class. However, for WBM semiconductordata, the performance in classifying new patterns was notsatisfactory because of the large number of known patterns and relatively few new patterns. Therefore, we designed the CowSSL loss function, adding a contrastive loss function(Œ± c) to the ORCA loss fun"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_26", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 26, "text": "atisfactory because of the large number of known patterns and relatively few new patterns. Therefore, we designed the CowSSL loss function, adding a contrastive loss function(Œ± c) to the ORCA loss function, which improves the abil- ity to distinguish a relatively small number of new patterns from the existing known patterns. In this study, we used acontrastive loss function that enables contrastive learning by making a different negative sample from the input data (Chen et al., 2020a ,2020b ;H ee ta l . , 2020 ). Finally, we proposed the CowSSL loss function as a mix of four loss functions: threeORCA loss functions and one contrastive loss function, as shown in Eq. ( 1).Œ± s,Œ±p,Œ±randŒ±care hyperparameters. By optimizing the model using this loss function, both known and new patterns in WBMs can be classiÔ¨Åed at once. L/equal1Œ±sLs+Œ±pLp+Œ±rR+Œ±cLc. (1) Each component of the proposed loss function is described in detail below. First, the uncertainty adaptive margin loss function ( Ls) considers the uncertainty adaptive margin cal- culated from the model‚Äôs output probability value within the general cross-entropy loss, which is used to learn labeled data with known patterns. This loss funct"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_27", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 27, "text": "s the uncertainty adaptive margin cal- culated from the model‚Äôs output probability value within the general cross-entropy loss, which is used to learn labeled data with known patterns. This loss function aids in distinguish-ing new patterns from known patterns by using an adaptivemargin. In Eq. ( 3),¬ØŒºis calculated by taking the average of the largest probability values output by the model, sub- tracted by one. The larger the uncertainty value is, the morelikely the model is to predict multiple patterns with equal probabilities, rather than a single pattern with high probabil- ity. Ultimately, when substituting Eq. ( 3) into Eq. ( 2), if the model predicts a new pattern that differs from the known pat- tern, the probability values become more evenly distributed, causing the uncertainty to increase accordingly and enablingthe identiÔ¨Åcation of the new pattern. In Eq. ( 2),y irepresents 123 2170 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 the labeled data and Wdenotes optimized weights. Further- more, the feature representation vector is denoted by zi,Œªis a hyperparameter, and smeans a scaling parameter. Ls/equal11 n/summationdisplay zi‚ààZl‚àíloges(WTyi¬∑zi+Œª¬ØŒº) es(WTyi¬∑zi+Œª¬Ø"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_28", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 28, "text": "ed weights. Further- more, the feature representation vector is denoted by zi,Œªis a hyperparameter, and smeans a scaling parameter. Ls/equal11 n/summationdisplay zi‚ààZl‚àíloges(WTyi¬∑zi+Œª¬ØŒº) es(WTyi¬∑zi+Œª¬ØŒº)+/summationtext j/negationslash/equal1iesWTyi¬∑zi,( 2 ) ¬ØŒº/equal11 |Du|/summationdisplay xi‚ààDu1‚àímax k(Pr(Y/equal1k|X/equal1xi)). (3) The second pairwise BCE loss function uses both labeled and unlabeled data, selecting the pair of samples in the batch with the highest cosine similarity in their representations. Thegoal is to minimize the BCE loss function for these samples,encouraging the model to classify them as the same pattern. This implies that the representation encourages samples with the same pattern to be clustered together through the clus-tering of close neighbors. For the unlabeled data, the loss function is calculated based on the nearest sample. However, for labeled data, because there is a ground truth, the loss func-tion is computed by comparing it to the ground truth, rather than comparing it to a separate nearby sample. In conclusion, the pairwise loss function, as deÔ¨Åned in Eq. ( 4), facilitates the clustering of different patterns together. In Eq. ( 5),Z lindi- cat"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_29", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 29, "text": "her than comparing it to a separate nearby sample. In conclusion, the pairwise loss function, as deÔ¨Åned in Eq. ( 4), facilitates the clustering of different patterns together. In Eq. ( 5),Z lindi- cates the feature representations in the labeled dataset, Zu denotes the feature representations in the unlabeled dataset, mdenotes the number of labeled data, and nindicates the number of unlabeled data. Lp/equal11 m+n/summationdisplay zi,z/prime i‚àà (Zl‚à™Zu,Z/prime l‚à™Z/prime u)‚àílog<œÉ/parenleftBig WT¬∑zi/parenrightBig ,œÉ/parenleftBig WT¬∑z/prime i/parenrightBig >. (4) The third regularization term, as given in Eq. ( 5), serves as a regulatory measure to prevent the model from overÔ¨Åttingand classifying everything into a single class during train-ing. This calculation employs the Kullback‚ÄìLeibler ( KL) divergence to ensure that the model‚Äôs predicted probability distribution remains similar to the prior probability distribu-tion. R/equal1KL‚éõ ‚éù1 m+n/summationdisplay zi‚àà(Zl‚à™Zu)œÉ/parenleftBig WT¬∑zi/parenrightBig /bardblP(¬Øy)‚éû ‚é†. (5) Finally, we applied a contrast loss function based on the MoCo algorithm to improve the model‚Äôs ability to discrim- inate a small number of new patterns from many know"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_30", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 30, "text": "renrightBig /bardblP(¬Øy)‚éû ‚é†. (5) Finally, we applied a contrast loss function based on the MoCo algorithm to improve the model‚Äôs ability to discrim- inate a small number of new patterns from many knownpatterns and to classify new patterns (Chen et al., 2020a , 2020b ; He et al., 2020 ). The MoCo algorithm is one of the self-supervised learning methods that uses a contrastive losswith negative samples. This approach facilitates the learningof the features of input data without relying on labels. As the learning progresses, samples with similar features in thefeature space tend to be together, while samples with dissim- ilar features tend to move farther apart. As shown in Fig. 6, the contrastive loss function performs contrastive learningby employing a query encoder and a key encoder. In thisprocess, data that has undergone two augmentations on the same sample is placed into positive pairs. One of these pairs is input to the query encoder to create a query vector, andthe other is fed into the key encoder to generate a positive key. In addition, some of the remaining samples are chosen as negative samples, and their representations are computedusing the key encoder. These representat"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_31", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 31, "text": "to the key encoder to generate a positive key. In addition, some of the remaining samples are chosen as negative samples, and their representations are computedusing the key encoder. These representations are then stored as a dictionary of negative keys. The query and positive keys are trained to become closer together in the feature space,whereas the query and negative keys are trained to move fur-ther apart. An important aspect to note here is that the negative sample selection comes from all other samples, excluding the sample itself, which has undergone different augmenta-tions. Consequently, data from a new class containing a small number of samples are less likely to be selected as a negative sample, whereas data from a known class containing a largenumber of samples are more likely to be chosen as a negative sample. Therefore, the majority class (known class) is more likely to be selected as a negative sample and is further dis-tanced from the minority class (new class), thereby increasingthe probability of separation between the two classes. Addi- tionally, classiÔ¨Åcation performance among minority classes improves because a small number of new classes exhibit ahigher likeli"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_32", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 32, "text": " increasingthe probability of separation between the two classes. Addi- tionally, classiÔ¨Åcation performance among minority classes improves because a small number of new classes exhibit ahigher likelihood of crowding out other new classes as neg- ative samples. Consequently, the contrastive loss function proves highly effective in separating new classes from knownclasses in WBM data and classifying new patterns. In Eq. ( 6), qrepresents a query representation, k +denotes the represen- tation of the positive key, and k‚àírefers to the representation of the negative keys. œÑis a temperature hyperparameter. Lc/equal1‚àí logexp( q¬∑k+/œÑ) exp( q¬∑k+/œÑ)+/summationtext k‚àíexp( q¬∑k‚àí/œÑ). (6) Experiments and results Experimental setting To optimize the model, we used stochastic gradient descent with momentum as the algorithm, with the following hyper-parameters: learning rate at 0.005, momentum at 0.9, and weight decay. The batch size for the input data was 512, and we used a key dictionary size of 2,048 for MoCo. WesetŒ± s,Œ±p, andŒ±rare 1.0 like the ORCA paper. Œ±cset to 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2171 Fig. 6 Structure of MoCo using WBM data Table 2 The confusion matr"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_33", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 33, "text": "8 for MoCo. WesetŒ± s,Œ±p, andŒ±rare 1.0 like the ORCA paper. Œ±cset to 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2171 Fig. 6 Structure of MoCo using WBM data Table 2 The confusion matrix for calculating evaluation indicators Ground truth True False Predicted Positive True positives False positives Negative False negatives True negatives 0.7 in Ô¨Årst 100 epochs and 0.3 in last 50 epochs. We ran a total of 150 epochs, and all experiments were repeated ten times with different randomization settings for each samplingstrategy, with the average value used. Our experiments wereimplemented with PyTorch 1.8.0 and conducted on a single NVIDIA GeForce RTX 3090 GPU and an i-9 10900KF CPU. We have mainly used the F1-score for comparison becausethe ‚ÄôWM-811K‚Äô dataset used in our study exhibits signiÔ¨Å- cant data imbalance. The most prevalent pattern, ‚Äôedge-ring,‚Äô representing 38.1% of the entire dataset, while the leastprevalent, ‚Äôdonut,‚Äô constitutes only 2.2%. Therefore, in the context of this data imbalance, performance evaluation is conducted using the F1-score, as it takes into account bothrecall and precision. Table 2shows a standard confusionmatrix. The F1-score is calculated"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_34", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 34, "text": "t of this data imbalance, performance evaluation is conducted using the F1-score, as it takes into account bothrecall and precision. Table 2shows a standard confusionmatrix. The F1-score is calculated as the harmonic mean of precision and recall, as shown in Eq. ( 9), with a value between 0 and 1. The higher F1-score correspond to better classiÔ¨Åcation performance of the model. We optimized the process of Ô¨Åtting the Ô¨Ånal clustered class of the model againstthe correct answer using the Hungarian algorithm. Precision /equal1True Po siti ves True Po siti ves+False Positi ves,( 7 ) Recall /equal1True Po siti ves True Po siti ves+False Negati ves,( 8 ) F1 - score /equal12√óPrecision √óRecall Precision +Recall. (9) Results In this section, we discuss the classiÔ¨Åcation performance of both the open-world semi-supervised learning methodol- ogy and the proposed CowSSL methodology when appliedto existing and new patterns. In conclusion, our proposed 123 2172 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 Table 3 Comparison of F1-score between the open-world semi-supervised methodologies Method Known patterns (classes) New patterns (classes) Total Center Edge-Loc Edge-Ring Loc Scratch R"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_35", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 35, "text": "5) 36:2163‚Äì2175 Table 3 Comparison of F1-score between the open-world semi-supervised methodologies Method Known patterns (classes) New patterns (classes) Total Center Edge-Loc Edge-Ring Loc Scratch Random Donut Average OpenLDN Rizve et al. ( 2022a ,2022b )0.9107 (0.01)0.8276 (0.03)0.9663 (0.01)0.7125 (0.01)0.0016 (0.00)0.1014 (0.16)0.0034 (0.01)0.5034 TRSSL Rizve et al. ( 2022a ,2022b )0.8394 (0.04)0.7892 (0.03)0.7422 (0.05)0.6715 (0.02)0.2397 (0.04)0.2785 (0.09)0.0119 (0.03)0.5103 ORCA Cao et al. ( 2021 )0.9393 (0.01)0.8457 (0.01)0.9427 (0.01)0.7355 (0.01)0.2204 (0.25)0.7934 (0.10)0.4637 (0.38)0.7058 CowSSL (proposed)0.9397 (0.01)0.8508 (0.01)0.9576 (0.01)0.7387 (0.01)0.4588 (0.02)0.8057 (0.04)0.6404 (0.12)0.7702 This scenario consists of four known patterns (center, edge-loc, edge-ring, loc) and three new patterns (scratch, random, donut) Bold values indicate the highest F1 score among the methods CowSSL outperformed other methodologies in terms of per- formance. Table 3displays the F1-scores for each pattern across different methodologies. Upon examining the over- all average values, the traditional ORCA achieved a score of 0.7058, whereas the performance signiÔ¨Åcantly improved "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_36", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 36, "text": " F1-scores for each pattern across different methodologies. Upon examining the over- all average values, the traditional ORCA achieved a score of 0.7058, whereas the performance signiÔ¨Åcantly improved to0.7702 with our proposed method, surpassing both TRSSLand OpenLDN. It is evident that known patterns exhibit a con- sistent level of performance across all models, whereas new patterns demonstrate substantial divergence. The OpenLDNmodel predicted the novel pattern as a solitary cluster, whereas TRSSL exhibited poor performance by detecting only two out of the three new patterns. While the existingORCA seemed to detect three new patterns on average, we observed that it underperformed the proposed CowsSSL and exhibited a very large standard deviation. This implies thatthe probability of correctly detecting all of the new patterns ishighly variable from experiment to experiment. However, the proposed CowSSL method demonstrated excellent perfor- mance in correctly classifying all the new patterns. Notably,the CowSSL excelled in accurately identifying the scratch pattern, which is highly similar to the loc pattern and can be challenging to differentiate. Additionally, it exhibited thehig"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_37", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 37, "text": "tterns. Notably,the CowSSL excelled in accurately identifying the scratch pattern, which is highly similar to the loc pattern and can be challenging to differentiate. Additionally, it exhibited thehighest accuracy in classifying the donut pattern, despite its relatively small sample size. Consequently, our Ô¨Åndings demonstrate that the contrast loss function integrated into theproposed CowSSL successfully separates the minority pat-terns from the majority patterns, thereby facilitating a more precise classiÔ¨Åcation of the novel patterns. We conducted supplementary experiments to validate the suitability of our proposed methodology. For this purpose, we deliberately created a scenario where the known pat- tern dataset is large, while the new pattern dataset is small.We selected center, edge-loc, and edge-ring patterns because of their relatively abundant data as known patterns, while loc, scratch, random, and donut patterns were chosen as thenew patterns. As illustrated in Table 4, the results demon- strated that the proposed CowSSL algorithm exhibits thehighest performance. These results were very similar to those in Table 3. It was conÔ¨Årmed that the proposed CowSSL in preparation fo"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_38", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 38, "text": "sults demon- strated that the proposed CowSSL algorithm exhibits thehighest performance. These results were very similar to those in Table 3. It was conÔ¨Årmed that the proposed CowSSL in preparation for OpenLDN, TRSSL, and ORCA classi- Ô¨Åed each of the four new patterns well. Consequently, our Ô¨Åndings conÔ¨Årmed that the CowSSL method effectively clas-siÔ¨Åes the small number of new patterns in the WBM dataset.The proposed CowSSL methodology applies contrastive loss to ORCA, an open-world semi-supervised learning algo- rithm. To ascertain whether the application of contrastive lossimproves the classiÔ¨Åcation of new patterns with low quanti- ties in other open-world semi-supervised learning methods, we conducted an experiment in which contrastive loss wasapplied to OpenLDN. Table 5presents the performance results of OpenLDN both with and without contrastive loss. Incorporating contrastive loss into the OpenLDN methodresulted in an average performance enhancement. Notably,a signiÔ¨Åcant performance improvement was observed in the ‚Äòrandom‚Äô class among new patterns. We conÔ¨Årmed the effec- tiveness of contrastive loss in accurately separating a smallnumber of novel patterns in the WBM. We veriÔ¨Åe"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_39", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 39, "text": "ce improvement was observed in the ‚Äòrandom‚Äô class among new patterns. We conÔ¨Årmed the effec- tiveness of contrastive loss in accurately separating a smallnumber of novel patterns in the WBM. We veriÔ¨Åed the learn- ing efÔ¨Åciency of the proposed CowSSL by assessing learning times. As presented in Table 6, it is evident that the intro- duction of contrastive loss to ORCA does not result in a signiÔ¨Åcant change in learning time. Moreover, we observed that the time required for one epoch was shorter comparedto OpenLDN and TRSSL. To better visualize this, we examined the representation of each model. Figure 7displays a representation of the OpenLDN, TRSSL, ORCA, and CowSSL models through t-SNE (t-distributed stochastic neighbor embedding) analysis. t-SNE is a methodology used to reduce the dimensionality of high-dimensional data to facilitate the visualization. Ourobjective of using t-SNE visualization was aimed at evaluat- ing the degree to which defect patterns with distinct features could be effectively separated in the feature space. When therepresentation predicted by the model is drawn for the test 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2173 Table 4 Comparison o"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_40", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 40, "text": "e effectively separated in the feature space. When therepresentation predicted by the model is drawn for the test 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2173 Table 4 Comparison of F1-score between the open-world semi-supervised methodologies Method Known patterns (classes) New patterns (classes) Total Center Edge-Loc Edge-Ring Loc Scratch Random Donut Average OpenLDN Rizve et al. ( 2022a ,2022b )0.8080 (0.03)0.6827 (0.01)0.9681 (0.01)0.0398 (0.03)0.0098 (0.01)0.0000 (0.00)0.0676 (0.12)0.3680 TRSSL Rizve et al. ( 2022a ,2022b )0.7925 (0.01)0.6877 (0.06)0.7760 (0.03)0.3381 (0.03)0.0549 (0.09)0.2841 (0.09)0.0921 (0.11)0.4322 ORCA Cao et al. ( 2021 )0.9322 (0.01)0.8468 (0.01)0.9697 (0.01)0.4147 (0.03)0.3303 (0.03)0.6760 (0.03)0.1043 (0.11)0.6106 CowSSL (proposed)0.9380 (0.01)0.8459 (0.01)0.9679 (0.00)0.4336 (0.01)0.3752 (0.04)0.7541 (0.05)0.4111 (0.05)0.6751 This scenario consists of three known patterns (center, edge-loc, edge-ring) and four new patterns (loc, scratch, random, donut) Bold values indicate the highest F1 score among the methods Table 5 Comparison of F1-score between the OpenLDN andOpenLDN(with contrastive loss)Method Known patterns (classes) New pa"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_41", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 41, "text": "h, random, donut) Bold values indicate the highest F1 score among the methods Table 5 Comparison of F1-score between the OpenLDN andOpenLDN(with contrastive loss)Method Known patterns (classes) New patterns (classes) Total Center Edge- LocEdge- RingLoc Scratch Random Donut Average OpenLDN 0.9107 (0.01)0.8276 (0.03)0.9663 (0.01)0.7125 (0.01)0.002 (0.00)0.1014 (0.16)0.0034 (0.01)0.5034 TRSSL (withcon-trastiveloss)0.9289 (0.01)0.8285 (0.02)0.9231 (0.05)0.6883 (0.03)0.0696 (0.07)0.4840 (0.17)0.0000 (0.00)0.5604 Bold values indicate the highest F1 score among the methods Table 6 Comparison of time required for one epoch trainingby methodologiesOpenLDN TRSSL ORCA CowSSL (proposed) Time 47 s 2100 s 37 s 38 s sample for each class, it can be seen that they are distin- guished from each other. In particular, when examining the representation visualization results for all models, we con- Ô¨Årmed that a relatively large number of known patterns werewell distinguished. However, as shown in Table 3, OpenLDN and TRSSL were unable to distinguish new patterns, which are small in number. In the case of ORCA, clusters of newpatterns are segregated compared to known patterns, but it is evident that new"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_42", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 42, "text": "OpenLDN and TRSSL were unable to distinguish new patterns, which are small in number. In the case of ORCA, clusters of newpatterns are segregated compared to known patterns, but it is evident that new patterns are clustered together, as illus- trated by the blue circle. This suggests that in situations withsevere class imbalance like WBM, distinguishing small pat-terns using conventional loss functions is challenging. On the other hand, the proposed CowSSL was more effective at separating random and donut patterns corresponding tothe new, small-number patterns, as shown by the red circles. Consequently, our Ô¨Åndings demonstrate that the contrastive loss function proposed in this study effectively distances newpatterns from the majority of known patterns and separates between new patterns, resulting in enhanced discrimination of the minority new patterns.Conclusions With tens of thousands of WBM data pieces produced eachday, it is crucial to quickly detect and identify new defects.In the industrial Ô¨Åeld, spotting new patterns during the fab- rication process is important because they can indicate a new issue that was not previously known. Neglecting theseissues can lead to major qual"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_43", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 43, "text": " industrial Ô¨Åeld, spotting new patterns during the fab- rication process is important because they can indicate a new issue that was not previously known. Neglecting theseissues can lead to major quality incidents. Therefore, obtain- ing new pattern samples that have the same morphology is vital to determining the common history of problematicwafers. Our study shows that it is possible to detect andclassify new patterns within large amounts of unlabeled data using the contrastive loss function, even if the num- ber of new patterns is tiny. This is the Ô¨Årst study to applyopen-world semi-supervised learning to WBM data, demon- strating that it is possible to learn a robust model despite the challenges of class imbalance and unlabeled data. In par-ticular, our proposed CowSSL algorithms demonstrate the 123 2174 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 Fig. 7 Comparing representations of OpenLDN, TRSSL, ORCA, and CowSSL using t-SNE improved classiÔ¨Åcation of a small number of new patterns using the MoCo-based contrastive loss. This improvement is because of the lower likelihood of selecting a small numberof new patterns data as the negative sample. Consequently, in compa"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_44", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 44, "text": "f new patterns using the MoCo-based contrastive loss. This improvement is because of the lower likelihood of selecting a small numberof new patterns data as the negative sample. Consequently, in comparison to existing open-world semi-supervised learning methods, we substantiate both quantitatively and qualita-tively that our approach effectively separates and classiÔ¨Åeseach minority new pattern. In future research, we aim to investigate methods for selecting negative samples with distinctly different character-istics from the input data when employing a contrastive loss function to enhance the classiÔ¨Åcation of new patterns. The currently proposed contrastive loss function merely consid-ers all samples, excluding the input data, as candidates for negative samples during selection. However, this approach has a limitation in that negative samples may encompassdata from the same class as the input data. Therefore, bydeveloping a method to select negative samples exhibiting signiÔ¨Åcantly distinct characteristics from the input data, we anticipate that the contrastive loss function will work moreeffectively in detecting and classifying new patterns. Fur- thermore, the proposed methodology "}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_45", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 45, "text": "inct characteristics from the input data, we anticipate that the contrastive loss function will work moreeffectively in detecting and classifying new patterns. Fur- thermore, the proposed methodology holds promise for the classiÔ¨Åcation of mixed patterns in the WBM dataset. Thesemixed patterns can be intentionally designed to appear as new patterns. However, our current methodology was devel- oped with a focus on single patterns where the distinctionbetween existing defect patterns and new defect patterns wasrelatively clear. Therefore, as part of our future research, we intend to develop a model capable of effectively classifying mixed patterns by incorporating known single patterns andutilizing them as training data. Author contributions Conceptualization: IB, SH, SBK. Formal analy- sis: IB, SH. Methodology: IB, SH, SBK. Supervision: SBK. V alidation:IB, SH. Writing‚Äîoriginal draft: IB, SH. Writing‚Äîreview & editing: SBKim. Funding This work was supported by Samsung Advanced Institute of Technology, Brain Korea 21 FOUR, the Ministry of Science andICT (MSIT) in Korea under the ITRC support program supervisedby the Institute for Information Communication Technology Plan-ning and Evalu"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_46", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 46, "text": "f Technology, Brain Korea 21 FOUR, the Ministry of Science andICT (MSIT) in Korea under the ITRC support program supervisedby the Institute for Information Communication Technology Plan-ning and Evaluation (IITP-2020-0-01749), and the National ResearchFoundation of Korea grant funded by the Korea government (RS-2022-00144190). 123 Journal of Intelligent Manufacturing (2025) 36:2163‚Äì2175 2175 Data availability All data are fully available without restriction. The dataset used in this study is available from the following website: https:// www.kaggle.com/datasets/qingyi/wm811k-wafer-map . Declarations Competing interest The authors have declared that no competing inter- ests exist. References Bendale, A., & Boult, T. (2015). Towards open world recognition. Pro- ceedings of the IEEE conference on computer vision and patternrecognition (pp. 1893‚Äì1902). Cao, K., Brbic, M., & Leskovec, J. (2021). Open-world semi-supervised learning. arXiv preprint arXiv:2102.03526. https://doi.org/10.48 550/arXiv.2102.03526 . Chapelle, O., Scholkopf, B., & Zien, A. (2009). Semi-supervised learn- ing In: chapelle, O., Scholkopf, B., & Zien, A. (Eds), (2006) [bookreviews]. IEEE Transactions on Neural Netwo"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_47", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 47, "text": "arXiv.2102.03526 . Chapelle, O., Scholkopf, B., & Zien, A. (2009). Semi-supervised learn- ing In: chapelle, O., Scholkopf, B., & Zien, A. (Eds), (2006) [bookreviews]. IEEE Transactions on Neural Networks 20 (3):542‚Äì542. https://doi.org/10.1109/TNN.2009.2015974 . Chen, X., Fan, H., Girshick, R., & He, K. (2020a). Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297. https://doi.org/10.48550/arXiv.2003.04297 . Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020b). A sim- ple framework for contrastive learning of visual representations.International conference on machine learning (pp. 1597‚Äì1607). PMLR. Choudhary, A. K., Harding, J. A., & Tiwari, M. K. (2009). Data mining in manufacturing: A review based on the kind of knowledge. Jour- nal of Intelligent Manufacturing ,20, 501‚Äì521. https://doi.org/10. 1007/s10845-008-0145-x . He, K., Fan, H., Wu, Y ., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. Pro- ceedings of the IEEE/CVF conference on computer vision andpattern recognition (pp. 9729‚Äì9738). https://doi.org/10.48550/ar Xiv.1911.05722 . Hsu, C. Y ., & Chien, J. C. (2022). Ensemble convolutiona"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_48", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 48, "text": "o- ceedings of the IEEE/CVF conference on computer vision andpattern recognition (pp. 9729‚Äì9738). https://doi.org/10.48550/ar Xiv.1911.05722 . Hsu, C. Y ., & Chien, J. C. (2022). Ensemble convolutional neural networks with weighted majority for wafer bin map pattern clas-siÔ¨Åcation. Journal of Intelligent Manufacturing ,33(3), 831‚Äì844. https://doi.org/10.1007/s10845-020-01687-7 . Jang, J., & Lee, G. T. (2023). Decision fusion approach for detecting unknown wafer bin map patterns based on a deep multitask learn-ing model. Expert Systems with Applications ,215, 119363. https:// doi.org/10.1016/j.eswa.2022.119363 . Jang, J., Seo, M., & Kim, C. O. (2020). Support weighted ensemble model for open set recognition of wafer map defects. IEEE Trans- actions on Semiconductor Manufacturing ,33(4), 635‚Äì643. https:// doi.org/10.1109/TSM.2020.3012183 . Jin, C. H., Na, H. J., Piao, M., Pok, G., & Ryu, K. H. (2019). A novel DBSCAN-based defect pattern detection and classiÔ¨Åcationframework for wafer bin map. IEEE Transactions on Semiconduc- tor Manufacturing ,32(3), 286‚Äì292. https://doi.org/10.1109/TSM. 2019.2916835 . Jin, C. H., Kim, H. J., Piao, Y ., Li, M., & Piao, M. (2020). Wafer map defect patt"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_49", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 49, "text": "map. IEEE Transactions on Semiconduc- tor Manufacturing ,32(3), 286‚Äì292. https://doi.org/10.1109/TSM. 2019.2916835 . Jin, C. H., Kim, H. J., Piao, Y ., Li, M., & Piao, M. (2020). Wafer map defect pattern classiÔ¨Åcation based on convolutional neuralnetwork features and error-correcting output codes. Journal of Intelligent Manufacturing ,31(8), 1861‚Äì1875. https://doi.org/10. 1007/s10845-020-01540-x . Kahng, H., & Kim, S. B. (2021). Self-supervised representation learning for wafer bin map defect pattern classiÔ¨Åcation. IEEE Transactions on Semiconductor Manufacturing ,34(1), 74‚Äì86. https://doi.org/ 10.1109/TSM.2020.3038165 .Kang, S. (2020). Joint modeling of classiÔ¨Åcation and regression for improving faulty wafer detection in semiconductor manufacturing. Journal of Intelligent Manufacturing ,31(2), 319‚Äì326. https://doi. org/10.1007/s10845-018-1447-2 . Kong, Y ., & Ni, D. (2021). A one-shot learning approach for similarity retrieval of wafer bin maps with unknown failure pattern. IEEE Transactions on Semiconductor Manufacturing ,35(1), 40‚Äì49. https://doi.org/10.1109/TSM.2021.3123290 . Kyeong, K., & Kim, H. (2018). ClassiÔ¨Åcation of mixed-type defect pat- terns in wafer bin maps using con"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_50", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 50, "text": "actions on Semiconductor Manufacturing ,35(1), 40‚Äì49. https://doi.org/10.1109/TSM.2021.3123290 . Kyeong, K., & Kim, H. (2018). ClassiÔ¨Åcation of mixed-type defect pat- terns in wafer bin maps using convolutional neural networks. IEEE Transactions on Semiconductor Manufacturing ,31(3), 395‚Äì402. https://doi.org/10.1109/TSM.2018.2841416 . Lee, K. B., Cheon, S., & Kim, C. O. (2017). A convolutional neural network for fault classiÔ¨Åcation and diagnosis in semiconductormanufacturing processes. IEEE Transactions on Semiconduc- tor Manufacturing, 30 (2), 135‚Äì142. https://doi.org/10.1109/TSM. 2017.2676245 Park, S., Jang, J., & Kim, C. O. (2021). Discriminative feature learn- ing and cluster-based defect label reconstruction for reducinguncertainty in wafer bin map labels. Journal of Intelligent Man- ufacturing ,32, 251‚Äì263. https://doi.org/10.1007/s10845-020-01 571-4 . Parmar, J., Chouhan, S., Raychoudhury, V ., & Rathore, S. (2023). Open- world machine learning: Applications, challenges, and opportuni-ties. ACM Computing Surveys ,55(10), 1‚Äì37. https://doi.org/10. 1145/3561381 . Piao, M., Jin, C. H., Lee, J. Y ., & Byun, J. Y . (2018). Decision tree ensemble-based wafer map failure pattern re"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_51", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 51, "text": "ortuni-ties. ACM Computing Surveys ,55(10), 1‚Äì37. https://doi.org/10. 1145/3561381 . Piao, M., Jin, C. H., Lee, J. Y ., & Byun, J. Y . (2018). Decision tree ensemble-based wafer map failure pattern recognition based onradon transform-based features. IEEE Transactions on Semicon- ductor Manufacturing ,31(2), 250‚Äì257. https://doi.org/10.1109/ TSM.2018.2806931 . Rizve, M. N., Kardan, N., & Shah, M. (2022a). Towards realistic semi-supervised learning. European Conference on Computer Vision (pp. 437‚Äì455). Cham: Springer https://doi.org/10.1007/ 978-3-031-19821-2_25 . Rizve, M. N., Kardan, N., Khan, S., Shahbaz Khan, F., & Shah, M. (2022b). Openldn: Learning to discover novel classes foropen-world semi-supervised learning. European Conference on Computer Vision (pp. 382‚Äì401). Cham: Springer https://doi.org/ 10.1007/978-3-031-19821-2_22 . Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., & Boult, T. E. (2012). Toward open set recognition. IEEE Transactions on Pat- tern Analysis and Machine Intelligence ,35(7), 1757‚Äì1772. https:// doi.org/10.1109/TPAMI.2012.256 . Shim, J., Kang, S., & Cho, S. (2020). Active learning of convolutional neural network for cost-effective wafer map pattern cla"}
{"id": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf::chunk_52", "source": "CowSSL contrastive open-world semi-supervised learning for wafer bin map.pdf", "chunk_index": 52, "text": "Intelligence ,35(7), 1757‚Äì1772. https:// doi.org/10.1109/TPAMI.2012.256 . Shim, J., Kang, S., & Cho, S. (2020). Active learning of convolutional neural network for cost-effective wafer map pattern classiÔ¨Åca-tion. IEEE Transactions on Semiconductor Manufacturing ,33(2), 258‚Äì266. https://doi.org/10.1109/TSM.2020.2974867 . V an Engelen, J. E., & Hoos, H. H. (2020). A survey on semi-supervised learning. Machine Learning ,109 (2), 373‚Äì440. https://doi.org/10. 1007/s10994-019-05855-6 . Wu, M. J., Jang, J. S. R., & Chen, J. L. (2015). Wafer map failure pattern recognition and similarity ranking for large-scale data sets.IEEE Transactions on Semiconductor Manufacturing ,28(1), 1‚Äì12. https://doi.org/10.1109/TSM.2014.2364237 . Publisher‚Äôs Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional afÔ¨Åliations. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with theauthor(s) or other rightsholder(s); author self-archiving of the acceptedmanuscript version of this article is solely governed by the terms of suchpublishing agreement and applicable law. 123"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_0", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 0, "text": "392 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 Design-Phase Buffer Allocation for Post-Silicon Clock Binning by Iterative Learning Grace Li Zhang, Bing Li, Jinglan Liu, Yiyu Shi, Senior Member, IEEE , and Ulf Schlichtmann, Member, IEEE Abstract ‚ÄîAt submicrometer manufacturing technology nodes, process variations affect circuit performance signiÔ¨Åcantly. Tocounter these variations, engineers are reserving more timing margin to maintain yield, leading to an unaffordable overdesign. Most of these margins, however, are wasted after manufactur-ing, because process variations cause only some chips to be reallyslow, while other chips can easily meet given timing speciÔ¨Åcations.To reduce this pessimism, we can reserve less timing margin andtune failed chips after manufacturing with clock buffers to makethem meet timing speciÔ¨Åcations. With this post-silicon clock tun-ing, critical paths can be balanced with neighboring paths ineach chip speciÔ¨Åcally to counter the effect of process variations.Consequently, chips with timing failures can be rescued and theyield can thus be improved. This is specially useful in high-performance de"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_1", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 1, "text": " chip speciÔ¨Åcally to counter the effect of process variations.Consequently, chips with timing failures can be rescued and theyield can thus be improved. This is specially useful in high-performance designs, e.g., high-end CPUs, where clock binningmakes chips with higher performance much more proÔ¨Åtable. Inthis paper, we propose a method to determine where to insertpost-silicon tuning buffers during the design phase to improve theoverall proÔ¨Åt with clock binning. This method learns the bufferlocations with a Sobol sequence iteratively and reduces the bufferranges afterward with tuning concentration and buffer grouping.Experimental results demonstrate that the proposed method canachieve a proÔ¨Åt improvement of about 14% on average and upto 26%, with only a small number of tuning buffers inserted intothe circuit. Index Terms ‚ÄîClock binning, iterative learning, post-silicon tuning, process variations, yield. I. I NTRODUCTION AT ADV ANCED technology nodes, process variations have become relatively larger, and thus caused expen- sive overdesign due to timing margins reserved during the design phase. To meet the challenges imposed by process Manuscript received July 28, 2016; revised Decemb"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_2", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 2, "text": "ively larger, and thus caused expen- sive overdesign due to timing margins reserved during the design phase. To meet the challenges imposed by process Manuscript received July 28, 2016; revised December 19, 2016; accepted April 26, 2017. Date of publication May 9, 2017; date of current versionJanuary 19, 2018. This work was supported in part by the German Research Foundation (DFG) as part of the Transregional Collaborative Research Centre ‚ÄúInvasive Computing‚Äù (SFB/TR 89). A preliminary version of this paperwas published in the Proceedings of the Design, Automation and Testin Europe Conference, 2016 [ 1]. The major improvement of this paper over [ 1] is to process multiple samples with an iterative learning procedure using a low-discrepancy sample sequence (Sobol sequence). This paper wasrecommended by Associate Editor P. Gupta. G. L. Zhang, B. Li, and U. Schlichtmann are with the Institute for Electronic Design Automation, Technical University of Munich, 80333 Munich, Germany (e-mail: grace-li.zhang@tum.de ;b.li@tum.de ; ulf.schlichtmann@tum.de ). J. Liu and Y . Shi are with the Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556 USA (e-ma"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_3", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 3, "text": "grace-li.zhang@tum.de ;b.li@tum.de ; ulf.schlichtmann@tum.de ). J. Liu and Y . Shi are with the Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556 USA (e-mail: jliu16@nd.edu ;yshi4@nd.edu ). Color versions of one or more of the Ô¨Ågures in this paper are available online at http://ieeexplore .ieee.org. Digital Object IdentiÔ¨Åer 10.1109/TCAD.2017.2702632Fig. 1. Post-silicon tuning buffer in [ 4] with three conÔ¨Åguration bits. variations, previous methods model process variations as ran- dom variables and incorporate them into timing analysis directly, leading to a boom of research on statistical static timing analysis (SSTA) in the last decade [ 2]. With the knowl- edge of the distributions of process variations, SSTA methods produce a performance-yield curve with which designers have a chance to make a tradeoff between different design goals.To alleviate the effect of process variations, many researchers have also worked on circuit structure level to introduce special devices and mechanisms. For instance, the Razor method [ 3] boosts circuit performance up to the limit where timing errors occur during circuit operation. Another technique to c"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_4", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 4, "text": "l to introduce special devices and mechanisms. For instance, the Razor method [ 3] boosts circuit performance up to the limit where timing errors occur during circuit operation. Another technique to counter process variations is to use post-silicon tuning devices to adaptchips individually according to the effect of process variations after manufacturing. A widely used post-silicon tuning technique is clock tun- ing with delay buffers. For example, the structure of the delay buffer used in [ 4] is illustrated in Fig. 1. The delay of this buffer can be changed by setting the conÔ¨Åguration bits in the three registers. In high-performance designs, tuning buffers like this are inserted during the design phase. After manu-facturing, the delay values of these buffers are conÔ¨Ågured to allot critical paths more timing budget by shifting clock edges toward the stages with smaller combinational delays. Thesecritical paths might be different in individual chips due to process variations, so that only post-silicon tuning can coun- terbalance them efÔ¨Åciently. By balancing delay budgets acrossconsecutive register stages, chips that might have failed to meet timing speciÔ¨Åcations can be revitalized"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_5", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 5, "text": "nly post-silicon tuning can coun- terbalance them efÔ¨Åciently. By balancing delay budgets acrossconsecutive register stages, chips that might have failed to meet timing speciÔ¨Åcations can be revitalized, leading to an increased yield at the expense of additional area taken bythese buffers. This post-silicon tuning technique works seam- lessly with other optimization techniques, e.g., gate/wire sizing and timing-driven placement, since it mainly deals with delayimbalance introduced in manufacturing by process variations instead of during the design phase. 0278-0070 c/circlecopyrt2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttp://www.ieee.org/publications_standards/publications/rights/index.html for more information. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 393 Post-silicon clock tuning buffers have various implementa- tions and characteristics. The tuning buffer proposed in [ 5] provides precise adjustable delays of less than 30 ps"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_6", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 6, "text": "BY ITERATIVE LEARNING 393 Post-silicon clock tuning buffers have various implementa- tions and characteristics. The tuning buffer proposed in [ 5] provides precise adjustable delays of less than 30 ps by voltage-controlled driver strength. The design in [ 6]u s e sa delay line to generate delays with 1-ps resolution. The de-skewbuffer in [ 7] consists of CMOS inverters and arrays of passive loads and is capable of creating a 170-ps tunable delay range in 8.5-ps steps. The controlled contention design [ 4] provides a 140-ps delay range with eight steps. After manufacturing, these delays can be adjusted through the test access port to tune individual chips. In recent years, several methods have been proposed for statistical timing analysis and optimization of circuits with post-silicon clock tuning buffers. In [ 8], a clock scheduling method is developed and clock tuning buffers are selectively inserted to balance the skews due to process variations. In [ 9], algorithms are proposed to insert buffers into the clock tree to guarantee a given yield, while either the number of buffers or the total area of all buffers is minimized. The optimizationproblem is solved by evaluating the yiel"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_7", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 7, "text": "nsert buffers into the clock tree to guarantee a given yield, while either the number of buffers or the total area of all buffers is minimized. The optimizationproblem is solved by evaluating the yield gradient with simul- taneous perturbation and Monte Carlo simulation. In [ 10], the yield loss due to process variations and the total costof clock tuning buffers are formulated together for gate siz- ing. The resulting optimization problem is solved using a stochastic cutting-plane method with an STA scheme based onMonte Carlo simulation. In [ 11], the placement of clock tuning buffers is investigated and a considerable beneÔ¨Åt is observed when the clock tree is designed using the proposed tuningsystem. In addition, the work in [ 12] proposes an efÔ¨Åcient post-silicon tuning method by searching a conÔ¨Åguration tree combined with graph pruning, and an insertion algorithm to group buffers into clusters. The yield of a circuit with clock tuning buffers can be evaluated efÔ¨Åciently using the methodin [13], and post-silicon testing methods for such circuits have been discussed in [ 14] and [ 15]. The methods above are applied as presilicon optimization or post-silicon adjustment before shipp"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_8", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 8, "text": "thodin [13], and post-silicon testing methods for such circuits have been discussed in [ 14] and [ 15]. The methods above are applied as presilicon optimization or post-silicon adjustment before shipping the manufactured chips to customers. Several other methods have exploited these tuning buffers to improve circuit performance and reliabilityonline, i.e., while the circuit is running. The method in [ 16] adjusts clock skews when the circuit is running according to timing errors to achieve a better performance in timing-speculative circuits. The method in [ 17] explores the insertion of clock tuning buffers and in-system conÔ¨Åguration to reduce performance degradation due to aging. In addition, the methodin [18] applies clock tuning buffers to compensate dynamic delay variations induced by temperature. In order to take advantage of post-silicon tuning, these buffers should be inserted into the circuit during the design phase. Since they take die area and require special treat- ment during physical design, the number of tuning buffers in the circuit should be small to provide a good yield/proÔ¨Åt improvement. This is essentially a statistical optimizationproblem when process variations"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_9", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 9, "text": "ng physical design, the number of tuning buffers in the circuit should be small to provide a good yield/proÔ¨Åt improvement. This is essentially a statistical optimizationproblem when process variations are considered. Previous methods [ 9], [10] solve this problem by path search or the cutting plane method. In these methods, yield values of dif-ferent combinations of buffer locations are evaluated using Monte Carlo simulation. New combinations of buffer locationsare then selected to evaluate according to the yield gradient. This is in fact a statistical extension of linear programming.Since Monte Carlo simulation is used at many branching points, this direct extension requires a large runtime to deter- mine buffer locations, though the calculated buffer locationsmay still fall into a local optimum in the problem space due to the nature of path search. In this paper, we propose a method to determine buffer loca- tions by iterative learning. In each iteration we try to capture the buffers that are important to the yield/proÔ¨Åt of the circuit. Afterward, we reÔ¨Åne the identiÔ¨Åed buffer locations and com-press buffer ranges to reduce area cost. The contributions of the proposed method are "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_10", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 10, "text": " that are important to the yield/proÔ¨Åt of the circuit. Afterward, we reÔ¨Åne the identiÔ¨Åed buffer locations and com-press buffer ranges to reduce area cost. The contributions of the proposed method are as follows. 1) Instead of searching along a few paths in the problem space to Ô¨Ånd a set of buffer locations, we use rep- resentative sample points to identify the buffers thatare important to the yield/proÔ¨Åt directly. Using a low- discrepancy sample sequence, the proposed method can identify the proper buffer locations efÔ¨Åciently. 2) We introduce a new way to model yield in representative samples to convert a statistical optimization problem into an ILP problem, so that heuristic statistical optimizationcan be avoided. 3) We model the overall proÔ¨Åt optimization problem instead of the yield at a given clock period. Consequently, the produced method can determine the buffer locations with respect to multiple clock bins in high-performance designs. When only one bin is used,this method is equivalent to the yield improvement problem with respect to a single clock period. 4) The proposed sampling-based method produces tuning values in the representative chip samples. With these values, buff"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_11", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 11, "text": "ivalent to the yield improvement problem with respect to a single clock period. 4) The proposed sampling-based method produces tuning values in the representative chip samples. With these values, buffers can be grouped according to their tuningcorrelation to reduce area cost further. 5) Compared with other methods, the proposed method is much faster, thanks to several acceleration techniques,even when the intermediate sample batches are not parallelized The rest of this paper is organized as follows. We give an overview of timing constraints for circuits with post-silicon clock tuning buffers in Section IIand formulate the buffer allocation problem in Section III. We explain the proposed method in detail in Section IV. Experimental results are shown in Section V. The conclusion and future work are given in Section VI. II. T IMING CONSTRAINTS WITHCLOCK BUFFERS In a circuit with post-silicon tuning buffers, the delays of clock paths to Ô¨Çip-Ô¨Çops can be adjusted after manufacturing for each chip individually. The concept of this tuning can be explained using the example in Fig. 2(a), where four Ô¨Çip-Ô¨Çops are connected into a loop by combinational paths. Withoutpost-silicon clock tuning,"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_12", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 12, "text": "h chip individually. The concept of this tuning can be explained using the example in Fig. 2(a), where four Ô¨Çip-Ô¨Çops are connected into a loop by combinational paths. Withoutpost-silicon clock tuning, the minimum clock period of this circuit is 8. If clock edges can be moved by adjusting the delays of these tuning buffers, the minimum clock period canbe reduced to 5.5. For example, the buffer value x 2shifts the launching clock edge at F2 0.5 units later and the buffer Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 394 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 Fig. 2. Performance improvement using post-silicon tuning buffers. Minimum achievable clock period is 5.5. Tuning values in (a) and (b) are constrai ned in [0, 4]. Setup time and hold time are assumed as 0 for simplicity. (a) Tuning conÔ¨Åguration without reduction. (b) Reduced tuning conÔ¨Åguration. (c) Redu ced tuning conÔ¨Åguration with negative tuning values. value x3shifts the launching clock edge at F3 3 units later. Therefore, with a clock period of 5.5, the combi"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_13", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 13, "text": "Reduced tuning conÔ¨Åguration. (c) Redu ced tuning conÔ¨Åguration with negative tuning values. value x3shifts the launching clock edge at F3 3 units later. Therefore, with a clock period of 5.5, the combinational path between F2 and F3 now has 5 .5‚àí0.5+3=8 time units to Ô¨Ån- ish signal propagation. This shifting of the clock edge reducesthe timing budget of the path between F3 and F4b y3u n i t s , but this path still works with the clock period 5.5 because the buffer value x 4moves the clock edge at F4 further later. The timing imbalance between combinational paths as in Fig. 2(a) potentially appears when process variations become large in advanced technology nodes. For an individual chip, this post-silicon clock tuning is similar to the concept of useful clock skews [ 19]. The difference is that the tuning values are speciÔ¨Åc to each individual chip after manufacturing, so that the effects of process variations can be dealt with speciÔ¨Åcally for each chip. If the skew schedule problem in [ 19]i sf o r m u l a t e d with process variations, the skew to a Ô¨Çip-Ô¨Çop should still be identical in all manufactured chips, so that there is no chance to tune the chips with respect to the individua"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_14", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 14, "text": "19]i sf o r m u l a t e d with process variations, the skew to a Ô¨Çip-Ô¨Çop should still be identical in all manufactured chips, so that there is no chance to tune the chips with respect to the individual effect of processvariations after manufacturing. In Fig. 2(a), four tuning buffers are used. However, all the delays of the buffers can be reduced by 0.5 time units andthe circuit still works with the clock period 5.5. This way, the number of buffers can be reduced by one, as shown in Fig. 2(b). Furthermore, we can reduce the number of buffers even to two, if we can move the clock edge at F2 2.5 time units earlier, so that the timing slack of the path betweenF1 and F2 can be shifted to the path between F2 and F3 directly, as in Fig. 2(c). This negative delay can be imple- mented by shortening the original clock path in advance tointroduce a negative delay in reference to the predeÔ¨Åned arrival time of clock signals. With negative clock delays allowed, tim- ing budgets can be balanced in both clockwise direction andcounterclockwise direction, so that the number of required buffers can be lowered to reduce area and post-silicon con- Ô¨Åguration cost. The task of buffer allocation during t"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_15", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 15, "text": "oth clockwise direction andcounterclockwise direction, so that the number of required buffers can be lowered to reduce area and post-silicon con- Ô¨Åguration cost. The task of buffer allocation during the designphase is thus to identify the smallest set of buffers with which chips after manufacturing can be tuned to a higher performance. The timing constraints with clock tuning buffers can be explained using Fig. 3, where two Ô¨Çip-Ô¨Çops with buffers are connected by a combinational circuit. Assume that the clock signal switches at reference time 0. Then the clock events at Ô¨Çip-Ô¨Çops iand jhappen at time x iand xj, respectively.Fig. 3. Timing of circuits with tuning buffers. To meet the setup time and hold time constraints, the following inequations must be satisÔ¨Åed: xi+dij‚â§xj+T‚àísj (1) xi+dij‚â•xj+hj (2) where xiandxjare delay values of tuning buffers, dij(dij)i s the maximum (minimum) delay of the combinational circuit between Ô¨Çip-Ô¨Çops iandj,sj(hj) is the setup (hold) time of Ô¨Çip-Ô¨Çop j, and Tis the clock period. Here the clock buffers introduce two delay variables into the constraints ( 1) and ( 2). Without them, the two inequations fall back to the normaltiming constraints of digital cir"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_16", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 16, "text": "is the clock period. Here the clock buffers introduce two delay variables into the constraints ( 1) and ( 2). Without them, the two inequations fall back to the normaltiming constraints of digital circuits. Owing to area constraints, the conÔ¨Ågurable delay of a clock buffer usually has a limited range. Assume that the lower bound of the tuning values of buffer iisr iand the upper bound is ri+œÑi, where œÑiis the size of the buffer. The delay value of buffer ican thus be constrained by a range window as ri‚â§xi‚â§ri+œÑi. (3) Unlike [ 9], we model the range window of the tuning values as asymmetrical with respect to 0 to achieve a maximal Ô¨Çex- ibility. Furthermore, ximay take only discrete values due to implementation limitations. To guarantee the proper function of a circuit with clock tuning buffers, the constraints ( 1)‚Äì(3) are created for each Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 395 pair of Ô¨Çip-Ô¨Çops. For a chip after manufacturing, the vari- ables dij,dij,sjand hjin (1) and ( 2) becom"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_17", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 17, "text": "et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 395 pair of Ô¨Çip-Ô¨Çops. For a chip after manufacturing, the vari- ables dij,dij,sjand hjin (1) and ( 2) become Ô¨Åxed values. These delays and timing properties in manufactured chips can be measured using frequency stepping [ 20], such as in [14], [15], and [ 21]. A detailed discussion of this tech- nique can be found, e.g., in [ 21]. After the delays and timing properties are measured, the values of xiandxjthat make a chip work with a given clock period Tcan be found eas- ily using the Bellman‚ÄìFord algorithm [ 22] or using linear programming. In this paper, we only focus on determining buffer locations during the design phase. Consequently, the path delays, setup times and hold times should be considered as random vari- ables modeled using data provided by foundries. With process variations considered, the tuning delays xiandxjalso become statistical, because the clock buffers are subject to process vari-ations too. These variations can be decomposed and merged with the random variables representing dij,dij,sj, and hj, e.g., using the canonical form in [ 23]. For convenience, we assume that a "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_18", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 18, "text": "ss vari-ations too. These variations can be decomposed and merged with the random variables representing dij,dij,sj, and hj, e.g., using the canonical form in [ 23]. For convenience, we assume that a tuning delay can be conÔ¨Ågured to a Ô¨Åxed value in the following discussion. The task of buffer allocation is thus to determine the locations of buffers that can make as many chipsas possible meet the given timing speciÔ¨Åcation after manufac- turing, using only the statistical timing information available during the design phase. III. P ROBLEM FORMULATION In applying the post-silicon tuning technique, we need to insert the buffers after logic synthesis is Ô¨Ånished and before physical design is started. Since buffers take precious die area, and require additional test to conÔ¨Ågure them, the num- ber of buffers in a design should be limited. In addition, theranges of the buffers should be reduced as much as possi- ble. Furthermore, in high-performance designs such as CPUs, chips are tested after manufacturing and assigned into bins ofdifferent performance grades, and the price of a chip from a bin of high speed is higher than that from a low-speed bin. In this scenario, it is more important t"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_19", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 19, "text": "manufacturing and assigned into bins ofdifferent performance grades, and the price of a chip from a bin of high speed is higher than that from a low-speed bin. In this scenario, it is more important to improve the overallproÔ¨Åt of all bins than to improve the yield of the circuit with respect to a single clock period. The important notations that appear in this paper are listed in Table I, and the problem of buffer allocation is formulated as follows. Input:1) circuit structure and statistical path delays; 2) buffer speciÔ¨Åcation, including the maximum allowed sizeœÑ iof buffers deÔ¨Åned in ( 3) and the number of discrete steps in the tunable delay range; 3) the maximum number of buffers allowed in the cir- cuitNb; 4) the number of performance bins Np.F o rt h e mth bin, an upper bound Tm,uand a lower bound Tm,lare deÔ¨Åned by the designer. After manufacturing, a chip with a clock period Tassigned to the mth bin should meet Tm,l<T‚â§ Tm,u. For a chip in the mth bin, the average proÔ¨Åt is given aspm. For convenience, we order the bins from high performance to low performance, so that Tm,u=Tm+1,l.TABLE I NOTATIONS Output: 1) a set of Ô¨Çip-Ô¨Çops at which tuning buffers should be inserted on the t"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_20", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 20, "text": "spm. For convenience, we order the bins from high performance to low performance, so that Tm,u=Tm+1,l.TABLE I NOTATIONS Output: 1) a set of Ô¨Çip-Ô¨Çops at which tuning buffers should be inserted on the their clock paths; 2) the sizes of the buffers inserted into the circuit. These sizes must be no larger than the given maximum size œÑi. Constraints: 1) for any pair of Ô¨Çip-Ô¨Çops iandjwith combinational paths between them, the constraints ( 1)‚Äì(3) hold; 2) the number of buffers inserted in the circuit must not exceed Nb. Objectives: 1) maximize the overall proÔ¨Åt P=Np/summationdisplay m=1pmym (4) where ymis the percentage of the chips that are assigned into the mth bin after manufacturing; 2) reduce the sizes of the inserted buffers while maintaining the overall proÔ¨Åt P. In the deÔ¨Ånition of bins, the Ô¨Årst bin has the highest performance, and it has no lower bound for the clock periodT, so that T 1,lcan be set to any value no larger than zero. After manufacturing, if a chip cannot be assigned to any of those bins, i.e., T>TNp,u, this chip is considered as a part of yield loss. The deÔ¨Ånition ( 4) is very general. If only one bin is used, this problem falls back to the yield improvement probl"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_21", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 21, "text": "o any of those bins, i.e., T>TNp,u, this chip is considered as a part of yield loss. The deÔ¨Ånition ( 4) is very general. If only one bin is used, this problem falls back to the yield improvement problem with respect to a single clock period. In the problem formulation above, we do not include the number of tuning buffers as a part of the optimization objec-tive, because the relation between proÔ¨Åt and the number of buffers is very complex. With our formulation, designers can generate several combinations of buffer number and proÔ¨Åt,and select the most appropriate setting according to their own cost model. If necessary, however, the number of buffers can Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 396 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 also be moved from a constraint into the optimization objec- tive ( 4), and the proposed method can still work with only a slight modiÔ¨Åcation. The predominant challenge in solving the optimization problem above comes from the random variables in ( 1) and ( 2), because only statistic"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_22", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 22, "text": "posed method can still work with only a slight modiÔ¨Åcation. The predominant challenge in solving the optimization problem above comes from the random variables in ( 1) and ( 2), because only statistical timing information are available dur- ing the design phase when the buffers are allocated. The proÔ¨Åt in (4) is thus deÔ¨Åned similar to an expected value, which is slightly larger than the actual proÔ¨Åt after manufacturing because statistical delays and timing properties cannot be mea- sured exactly [ 21]. Another challenge is that the variables xi andxjin (1) and ( 2) may take only discrete values in the range window deÔ¨Åned by ( 3). For example, the de-skew buffer in [ 7] can be conÔ¨Ågured to only 20 discrete delays. In this case, inte- ger linear programming (ILP) becomes almost the only method available to deal with the constraint set deÔ¨Åned by ( 1)‚Äì(3)a f t e r the random variables are Ô¨Åxed by sampling. To deal with the large number of samples in the problem space, learning-based methods have been applied in the designautomation Ô¨Åeld extensively, e.g., for statistical path selection considering large process variations [ 24], for sensor placement in dynamic noise management systems "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_23", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 23, "text": "s have been applied in the designautomation Ô¨Åeld extensively, e.g., for statistical path selection considering large process variations [ 24], for sensor placement in dynamic noise management systems [ 25], and for paramet- ric yield estimation for analog/mixed signal circuits [ 26]. In the following section, we will introduce an efÔ¨Åcient iterative learning-based method to capture buffer locations for yieldimprovement. IV . B UFFER ALLOCATION USING REPRESENTATIVE SAMPLING The buffer allocation problem is essentially a statistical opti- mization problem. In the linear constraints in ( 1)‚Äì(3) the path delays, setup times and hold times are correlated random vari- ables. Instead of using path search or the cutting plane methodas in previous methods, we solve this problem using statistical sampling. The basic idea is that we use a set of representative samples and model the numbers of samples in the differentperformance bins directly. We then determine buffer loca- tions by maximizing the overall proÔ¨Åt calculated from the yield values of these bins and the proÔ¨Åt per chip for eachbin. By sampling the random variables directly we can trans- form the statistical optimization problem into "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_24", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 24, "text": "overall proÔ¨Åt calculated from the yield values of these bins and the proÔ¨Åt per chip for eachbin. By sampling the random variables directly we can trans- form the statistical optimization problem into an ILP problem. Therefore, the relation between the statistical variables and theproÔ¨Åt of the circuit can be established directly. With this rela- tion, we can then capture buffer locations that are sensitive to yield/proÔ¨Åt. The Ô¨Çow of the proposed method is illustrated in Fig. 4.I n this Ô¨Çow, we Ô¨Årst generate a low-discrepancy sample sequence(Sobol sequence) and Ô¨Ålter out the samples that are not affected by any buffers. Thereafter, we try to capture buffer locations and reÔ¨Åne them iteratively. The ranges of buffers arecompressed and the number of buffers is reduced by grouping in the end to reduce area cost. This Ô¨Çow will be explained in detail in the following sections. A. Sampling-Based ILP Modeling Between Statistical Delays and ProÔ¨Åt Consider the case that we generate N ssamples from the joint distribution of all the random variables in the optimizationFig. 4. PreÔ¨Åltering and iterative buffer allocation Ô¨Çow. problem. If Nsis large enough, these samples can actually emulate the ch"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_25", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 25, "text": " the joint distribution of all the random variables in the optimizationFig. 4. PreÔ¨Åltering and iterative buffer allocation Ô¨Çow. problem. If Nsis large enough, these samples can actually emulate the chips after manufacturing. If we have tuningbuffers at the clock paths to some Ô¨Çip-Ô¨Çops, we can intro- duce intentional clock skews customized for each sample, or emulated chip, individually, to make the failing samples work again, or to move low-performance samples into high- performance bins. For each emulated chip we can now evaluatehow performance can be improved because the statistical vari- ables in the constraints become Ô¨Åxed in the samples. This way, we can establish the relation between buffer locations and theproÔ¨Åt, and use an ILP solver to determine the optimal buffer allocation. For the kth sample from the N ssamples, the con- straints ( 1)‚Äì(3) become xk i+dk ij‚â§xk j+Tk‚àísk j (5) xk i+dk ij‚â•xk j+hk j (6) ri‚â§xk i‚â§ri+œÑi (7) where dk ij,dk ij,sk j, and hk jare the kth sample values of random variables dij,dij,sj, and hj;xk iand xk jare intentional clock skews for this speciÔ¨Åc sample introduced by conÔ¨Åguring the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_26", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 26, "text": "f random variables dij,dij,sj, and hj;xk iand xk jare intentional clock skews for this speciÔ¨Åc sample introduced by conÔ¨Åguring the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 397 corresponding tuning buffers after manufacturing to improve the performance, in other words, to reduce the minimum clockperiod T k.N o t ei n( 7)riandœÑiare not indexed by k, because if a buffer is inserted on the clock path to a Ô¨Çip-Ô¨Çop, it appears in all the chips after manufacturing, and its range in all chipsis also the same. To indicate whether there is a buffer inserted on the clock path to the ith Ô¨Çip-Ô¨Çop, we assign a binary variable c ito it. If there is no buffer inserted, ciis set to 0; otherwise, ciis set to 1. Because a post-silicon clock skew can be added only when a buffer appears, the skew or the tuning value of thebuffer at the ith Ô¨Çip-Ô¨Çop can be written as x k i=/braceleftbigg0i f ci=0 any value ‚àà[ri,ri+œÑi]when ci=1.(8) According to the deÔ¨Ånition of ci, we need only to force xk i to be 0 to disa"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_27", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 27, "text": "ng value of thebuffer at the ith Ô¨Çip-Ô¨Çop can be written as x k i=/braceleftbigg0i f ci=0 any value ‚àà[ri,ri+œÑi]when ci=1.(8) According to the deÔ¨Ånition of ci, we need only to force xk i to be 0 to disable the potential clock tuning when ciis equal to 0. The constraint ( 8) can thus be transformed to xk i‚â§ci/Gamma1 (9) ‚àíxk i‚â§ci/Gamma1 (10) where /Gamma1is very large constant. If ciis set to 0, xk imust be set to 0 to meet ( 9) and ( 10). Ifciis set to 1, these two constraints have no effect because /Gamma1is a predetermined constant larger than any possible value of xk ior‚àíxk i. In this case, xk iis actually constrained by ( 7). With cideÔ¨Åned to indicate the appearance of a buffer at theith Ô¨Çip-Ô¨Çop, we can constrain the number of buffers in the circuit easily as /summationdisplay ici‚â§Nb (11) where the sum on the left adds the civariables for all Ô¨Çip-Ô¨Çops in the circuit together, and Nbis the given upper bound of the number of buffers allowed in the circuit. To evaluate the performance of an emulated chip, we need to compare the minimum clock period Tkof the kth sample with the upper and lower bounds of the performance bins. If Tkfalls into the mth bin by meeting Tm,l<Tk‚â§Tm,u, the num"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_28", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 28, "text": " an emulated chip, we need to compare the minimum clock period Tkof the kth sample with the upper and lower bounds of the performance bins. If Tkfalls into the mth bin by meeting Tm,l<Tk‚â§Tm,u, the number of the chips in this bin is increased by one. Instead of comparing Tkwith the bounds of the bins directly, we take advantage of the fact that the yield values of the circuit in different binsare a part of the optimization objective deÔ¨Åned in ( 4) and the price of a chip in a high performance bin is higher than that in a low performance bin. We deÔ¨Åne the 0-1 variables g k m,m=1,..., Npto represent whether the minimum clock period Tkof the kth sample is smaller than the upper bound of the mth bin. Therefore, gk mcan be constrained as gk m=1‚áê‚áí Tk‚â§Tm,u,m=1,2,..., Np. (12) We then use gk mto deÔ¨Åne another 0-1 variable bk mwhich indi- cates whether the kth sample falls into the mth bin meeting Tm,l<Tk‚â§Tm,u,a s bk m=/braceleftbigggk m m=1 gk m‚àígk m‚àí1m=2,..., Np.(13)The constraint ( 12) can be transformed into Tk‚àíTm,u‚â§/parenleftBig 1‚àígk m/parenrightBig /Gamma1,m=1,2,..., Np (14) where /Gamma1is very large positive constant. The constraints ( 13) and ( 14) can be explained as follows. IfTki"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_29", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 29, "text": " transformed into Tk‚àíTm,u‚â§/parenleftBig 1‚àígk m/parenrightBig /Gamma1,m=1,2,..., Np (14) where /Gamma1is very large positive constant. The constraints ( 13) and ( 14) can be explained as follows. IfTkis no larger than the upper bound of the mth bin Tm,u, the left side of ( 14) is negative, so that gk mcan be either 0 or 1; otherwise, gk mmust be 0. Since the objective of the optimization problem is to increase the numbers of chips in high-performance bins as much as possible, the solver will assign all gk m,gk m+1,..., gk Npt o1i f Tk‚â§Tm,u, because the bins are arranged in the high performance to low performance order so that Tkis also smaller than Tm+1,u,..., TNp,u. Therefore, the constraint ( 13) only keeps the bk mfor the fastest bin to which the sample can be assigned to be 1, and for the slower bins it is set to 0. Consequently, bk mrepresents whether the chip is assigned to the mth bin. With bk mwe can calculate the numbers of emulated chips in all bins easily, and the yield or the percentage ymfor the mth bin can be expressed as ym=Ns/summationdisplay k=1bk m/slashbigg Ns (15) where Nsis the total number of samples. With the constraints deÔ¨Åned above, the problem to optimize t"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_30", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 30, "text": "e percentage ymfor the mth bin can be expressed as ym=Ns/summationdisplay k=1bk m/slashbigg Ns (15) where Nsis the total number of samples. With the constraints deÔ¨Åned above, the problem to optimize the overall proÔ¨Åt can be expressed as maximizeNp/summationdisplay m=1pmym (16) s.t. ( 5)‚Äì(7),(9)‚Äì(11),and ( 13)‚Äì(15) with respect to all Ô¨Çip-Ô¨Çops pair indexed by (i,j) andk=1,..., Ns. (17) The basic idea of this formulation is that we use a given number of samples to emulate chips after manufacturing and model the bin assignment process. We then use an ILP solver to maximize the proÔ¨Åt in this simulated scenario to deter-mine which Ô¨Çip-Ô¨Çops should have buffers. Since the relation between the locations of buffers and the yield assignment is established in this formulation, we can determine the locationsof buffers directly by solving the optimization problem above. In previous methods [ 9], [10], the relation between buffer loca- tions and yield is not analyzed directly. Instead, these methodsconsider this relation as a separate evaluation problem, and the yield values for different combinations of buffer locations are calculated using Monte Carlo simulation, and only usedas a metric to de"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_31", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 31, "text": "consider this relation as a separate evaluation problem, and the yield values for different combinations of buffer locations are calculated using Monte Carlo simulation, and only usedas a metric to determine the next decision points in the path search or cutting plane methods. Consequently, Monte Carlo simulation have to be executed many times, resulting in a large runtime. If the number of emulated samples N sin the integer linear optimization problem ( 16), (17) is large enough, the proÔ¨Åt can be modeled accurately and the values of ciin the solution indicate the optimal locations to insert tuning buffers for themaximum proÔ¨Åt. However, a large N smay increase the number of constraints in ( 17) to the degree that the size of the ILP Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 398 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 problem exceeds the capacity of all existing ILP solvers. To deal with this scalability problem, we apply two techniques. 1) We reduce the number of emulated samples Nsby using a low-discrepancy sampl"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_32", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 32, "text": "problem exceeds the capacity of all existing ILP solvers. To deal with this scalability problem, we apply two techniques. 1) We reduce the number of emulated samples Nsby using a low-discrepancy sample sequence instead of a purely random sampling sequence. 2) We split the problem ( 16), (17) into subsets and use them to learn the locations of buffers iteratively. After each iteration, the candidates of buffer locations can bereÔ¨Åned. B. Reducing the Number of Emulation Samples Using Low-Discrepancy Sequence The sampling-based concept above requires a large num- ber of samples to guarantee the quality of the resulting buffer locations. Consider the extreme case where we use only twosamples, which have different probabilities to appear in the manufactured chips. In the formulation ( 16), (17), however, we do not differentiate these two samples with respect to theirprobabilities so that the two samples have the same inÔ¨Çuence on the selection of buffers. Consequently, the formulation loses accuracy because the calculated optimal proÔ¨Åt deviates fromthe real proÔ¨Åt. In traditional Monte Carlo simulation methods, this discrep- ancy problem is solved by using a large number of samples.Since "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_33", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 33, "text": "accuracy because the calculated optimal proÔ¨Åt deviates fromthe real proÔ¨Åt. In traditional Monte Carlo simulation methods, this discrep- ancy problem is solved by using a large number of samples.Since the samples are generated according to the joint dis- tribution of the variables, the number of points falling into a part of the sampling space corresponds to the probabilityof that region. The effect of probability can thus be handled by (16) and ( 17) implicitly, because samples from regions with large probabilities in the problem space appear more often than samples from other regions. Another way to solve this discrepancy problem is to use the probability of representa-tive samples as further coefÔ¨Åcients of the yield values in the objective ( 16) directly. But it is not clear how many samples should be generated to guarantee the quality of the result. The third method to solve the problem of a large sampling number is to use a low-discrepancy sequence such as stud- ied in [ 27]. In such a sequence, the number of samples in a given part of the sampling space is proportional to the prob- ability of that region. The advantage of such a sequence is that this quasi-random sequence ensu"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_34", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 34, "text": "ch a sequence, the number of samples in a given part of the sampling space is proportional to the prob- ability of that region. The advantage of such a sequence is that this quasi-random sequence ensures the low discrepancyeven with a small number of samples, so that it is widely used in quasi-Monte Carlo methods to reduce runtime. In statisti- cal timing analysis, this method also demonstrates a strongadvantage, e.g., more than 20 times acceleration has been achieved in [ 28]. In this paper, we use the Sobol sequence in [29] to reduce the number of samples N s. The effect of this sequence can be demonstrated using the examples in Fig. 5, where Fig. 5(a) shows a purely random number sequence of 256 samples for two uniform-distributed variables. Fig. 5(b) demonstrate that the Sobol sequence with the same number of samples spreads more evenly in the space. The originalSobol sequence follows uniform distribution, and it can be transformed to other distributions easily using methods such as the Box-Muller transform [ 30]. In our method, we use 1000 samples in the Sobol sequence, which are one tenth of the usu- ally used 10 000 samples of random variables in SSTA [ 2]. InFig. 5. Purely "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_35", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 35, "text": "s the Box-Muller transform [ 30]. In our method, we use 1000 samples in the Sobol sequence, which are one tenth of the usu- ally used 10 000 samples of random variables in SSTA [ 2]. InFig. 5. Purely random sequence and Sobol low-discrepancy sequence. Two hundred Ô¨Åfty-six random samples of (a) two uniform variables and (b) Sobol sequence for two uniform variables. (c) First 128 samples from the Sobolsequence in (b). (d) Next 128 samples from the Sobol sequence in (b). practice, test cases can converge even earlier with fewer than 1000 samples. C. Buffer Allocation With PreÔ¨Åltering and Iterative Learning In the Nssamples, some might be fast enough to be assigned into the fastest bin without tuning; others might be too slow to be tuned into the slowest bin, even with all Ô¨Çop-Ô¨Çops con- nected with tuning buffers. In both scenarios, tuning buffers play no role in improving the overall proÔ¨Åt. Therefore, we exclude these samples from the ILP formulation ( 16), (17)t o reduce the number of variables and constraints. To Ô¨Ålter out the samples of the Ô¨Årst type, we need only to set all values of tuning buffers, xk iand xk jin (5) and ( 6) to 0, and calculate the clock period Tk minfor this sa"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_36", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 36, "text": "riables and constraints. To Ô¨Ålter out the samples of the Ô¨Årst type, we need only to set all values of tuning buffers, xk iand xk jin (5) and ( 6) to 0, and calculate the clock period Tk minfor this sample as Tk min=max i,j{dk ij+sk j}.I fTk minis smaller than the upper bound of the fastest bin, this sample is fast enough and no tuning is required. The constraint ( 6) is checked similarly. If all these constraints can be met without tuning buffers, this sample is excluded. To Ô¨Ålter out the samples that are too slow to be assigned to a bin even with extensive buffer tuning, we evaluate each path delay in a sample by verifying whether it is possible to tune this path to meet the upper bound of the slowest bin without considering the other paths. In the constraint ( 5), the sum of the path delay dk ij+sk jandxk i‚àíxk jshould be no larger than Tk. We set buffer values xk iandxk jto the smallest and the largest values that are possible according to buffer speci- Ô¨Åcations, respectively, and check whether the resulting clock period Tkis smaller than the upper bound of the slowest bin. If this still does not hold, there is no chance that this sam- ple can be assigned to one of the bins and t"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_37", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 37, "text": "eck whether the resulting clock period Tkis smaller than the upper bound of the slowest bin. If this still does not hold, there is no chance that this sam- ple can be assigned to one of the bins and the corresponding Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 399 sample is not included in the proÔ¨Åt optimization problem. We repeat this preÔ¨Åltering checking using ( 6) to exclude samples that do not work in any case due to unavoidable hold time violations. After preÔ¨Åltering, the remaining samples are used to determine buffer locations by solving the optimization problem ( 16), (17). The number of these remaining sam- ples is denoted as Nf. For a large circuit, the number of remaining variables and constraints in this ILP problem may still be too large to be dealt with by a modern solver. To reduce the scale of the ILP problem further, we split the ILPproblem ( 16), (17) into subproblems and determine the buffer locations with an iterative Ô¨Çow based on: 1) a subsequence of a Sobol sequence"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_38", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 38, "text": "educe the scale of the ILP problem further, we split the ILPproblem ( 16), (17) into subproblems and determine the buffer locations with an iterative Ô¨Çow based on: 1) a subsequence of a Sobol sequence still exhibits a good low discrepancy as shown in Fig. 5(c) and (d) and 2) in a circuit only a small number of buffers can be inserted due to area cost. The iterative Ô¨Çowis illustrated in Fig. 4. The Ô¨Årst fact above shows that we may solve the ILP problem ( 16), (17) with only a part of the Sobol sequence, meaning that we can capture the buffer locations only using a subset of samples. Therefore, we partition the whole Sobol sequence into several parts so that each part con-tains N tsamples which are processed together in one ILP problem ( 16), (17). We call the samples processed in one ILP problem a batch. In our implementation, the number ofsamples N tin one batch is determined by evaluating the num- bers of variables and constraints and the capacity of the ILP solver. Since variables in an ILP problem deÔ¨Åne the dimen-sion of the problems space, they carry more complexity into the ILP problem than constraints. Therefore, we consider the complexity of a variable to be Ô¨Åve times that "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_39", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 39, "text": "n an ILP problem deÔ¨Åne the dimen-sion of the problems space, they carry more complexity into the ILP problem than constraints. Therefore, we consider the complexity of a variable to be Ô¨Åve times that of a constraint, and the total number of the equivalent constraints should be smaller than a constant, 2 √ó10 6for Gurobi [ 31] used in our experiments. Though the samples in subsequences generally have lower discrepancy compared with a purely random sequence, thereare still some slight patterns in these subsequences because of the small number of samples in one subsequence, as shown in Fig. 5(c) and (d). Consequently, a subsequence with a limited number of samples may not capture all the buffer locations. We alleviate this problem by combining the buffer locations cap- tured by different subsequences into a buffer set B /prime. Once we Ô¨Ånish solving ( 16) and ( 17) with all sample batches, the buffer locations in B/primeare the possible locations to insert buffers, as shown in the inner loop in Fig. 4. In this loop, we also relax the number of buffers from NbtoŒ≤Nbin the constraint ( 11) (Œ≤=1.5 in our experiments) to increase the coverage of potential buffer locations captured by the su"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_40", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 40, "text": "op in Fig. 4. In this loop, we also relax the number of buffers from NbtoŒ≤Nbin the constraint ( 11) (Œ≤=1.5 in our experiments) to increase the coverage of potential buffer locations captured by the subsequences. Wewill use a group technique to reduce the number of buffers back to N bafter all location candidates are captured. The inner iterative Ô¨Çow stops if no new buffer is added into the buffer setB/primein the past three iterations. After processing all sample batches in the inner loop, we execute the iterative buffer allocation Ô¨Çow as the outer loop in Fig. 4. In these iterations, only the buffer candidates in Bneed to be modeled with variables cias in ( 8) and only the delays of paths connected to these buffer candidates need to be sampled as ( 5)‚Äì(7). Consequently, more samples canbe processed in one iteration so that the number of batches ‚åàNf/Nt‚åâcan be reduced. With these outer iterations, buffer locations are gradually reÔ¨Åned and the outer loop Ô¨Ånishes if the number of batches cannot be decreased. D. Reducing Buffer Area by Tuning Concentration and Grouping The iterative optimization Ô¨Çow in Fig. 4only determines the locations to insert buffers for proÔ¨Åt improvement after ma"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_41", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 41, "text": "cannot be decreased. D. Reducing Buffer Area by Tuning Concentration and Grouping The iterative optimization Ô¨Çow in Fig. 4only determines the locations to insert buffers for proÔ¨Åt improvement after manu- facturing. But the sizes of the buffers are not addressed. In thissection, we introduce a method to concentrate tuning values toward each other and to group buffers thereafter. The concept of area reduction can be explained using Fig. 6. After executing the iterative buffer allocation in Fig. 4,t h e tuning values of a buffer in all samples may be scattered in a wide range such as in Fig. 6(a), because the solver only minimizes the number of buffers, but does not consider the relation between the tuning values of different samples, sothat it only returns one of the many feasible tuning combi- nations. If we can concentrate the tuning values toward each other, the real ranges of the buffers which cover all the tuningvalues appearing in the samples can be reduced. In addition, the concentrated tuning values may exhibit a high correlation by forming similar trends of tuning values as in Fig. 6(c). This resemblance can thus be used to group buffers. To push the scattered tuning values "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_42", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 42, "text": "trated tuning values may exhibit a high correlation by forming similar trends of tuning values as in Fig. 6(c). This resemblance can thus be used to group buffers. To push the scattered tuning values into a narrower range, we minimize their absolute values in the optimization, as illus-trated in Fig. 6(a). In this way, the solver tries to return the buffer values around 0 as much as possible using only the buffer candidates in Band guaranteeing the proÔ¨Åt Pcalculated by executing the Ô¨Çow in Fig. 4. This process is formulated as follows: minimize/summationdisplay i‚ààIB,k|xk i| (18) s.t. ( 5)‚Äì(7),(9)‚Äì(11),and ( 13)‚Äì(15) with respect to all Ô¨Çip-Ô¨Çops pair indexed by (i,j) andk=1,...Nf, and (19) Np/summationdisplay m=1pmym‚â•P (20) where IBis the index set of all buffer locations in B.T h e objective function ( 18) can be transformed into a linear form easily as explained in [ 32]. The difference between the optimization problem ( 18)‚Äì(20) and the optimization problem ( 16), (17) includes: 1) the objec- tive becomes the sum of the absolute values of all tuningvalues; 2) the buffer candidates are narrowed as the buffer setBreturned by the Ô¨Çow in Fig. 4; and 3) the proÔ¨Åt becomes a constraint "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_43", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 43, "text": "he objec- tive becomes the sum of the absolute values of all tuningvalues; 2) the buffer candidates are narrowed as the buffer setBreturned by the Ô¨Çow in Fig. 4; and 3) the proÔ¨Åt becomes a constraint to guarantee the tuning range concentration does not affect the proÔ¨Åt. By solving the problem ( 18)‚Äì(20), all tun- ing values are pushed toward zero as illustrated in Fig. 6(b), so that the buffer ranges become more compact. Another technique to reduce area cost is to group buffers that have similar tuning patterns into one buffer. For example,if two buffers have very similar tuning values in all samples, only one buffer needs to be built in the circuit and the delayed Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 400 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 Fig. 6. Concentrating tuning values of a buffer in all samples. The x-axis represents the adjusted delays of the buffer in all samples, and the y-axis the number of occurrences of the discrete delay values. (a) Scattered tuning values. (b) Tuning values concentrated to"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_44", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 44, "text": "-axis represents the adjusted delays of the buffer in all samples, and the y-axis the number of occurrences of the discrete delay values. (a) Scattered tuning values. (b) Tuning values concentrated toward zero. (c) Reduced buffer rang e after concentrating tuning values toward the average. clock signal is connected to two Ô¨Çip-Ô¨Çops. To make the pat- terns in buffer tuning more obvious, we Ô¨Årst calculate the weighted average of all tuning values of a buffer after solv- ing ( 18)‚Äì(20). Afterward, the buffer tuning values are pushed further toward this average. This process makes the number of different tuning values smaller, so that it is easier for two buffers to have similar tuning patterns. The result of this stepis that buffer tuning values may form a peak at the tuning aver- age as illustrated in Fig. 6(c). This step is very similar to the problem formulation in ( 18)‚Äì(20), except that the optimization objective is replaced by minimize/summationdisplay i‚ààIB,k/vextendsingle/vextendsingle/vextendsinglexk i‚àíxavg,i/vextendsingle/vextendsingle/vextendsingle (21) where x avg,iis the weighted average of all tuning values calculated from the result of solving ( 18)‚Äì(20). After tuning val"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_45", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 45, "text": "gle/vextendsinglexk i‚àíxavg,i/vextendsingle/vextendsingle/vextendsingle (21) where x avg,iis the weighted average of all tuning values calculated from the result of solving ( 18)‚Äì(20). After tuning values are concentrated, we try to cover all the tuning values using the smallest range window. The upperbound of the size of this range window is predeÔ¨Åned as œÑ i in (3). As shown in Fig. 6(c), the range window slides along thex-axis. Since the y-axis represents the numbers of the cor- responding tuning value occurrences in all samples, the total number of buffer tunings covered by the window is the sum of the tuning occurrences in the window. For yield improvement,we select the range window that covers the largest number of tunings, meaning that these tuning values are feasible in post-silicon conÔ¨Åguration. The other values that fall out of thewindow are discarded. With this step, both buffer size œÑ iand lower bound riin (3) are determined. In the last step of buffer insertion, we group buffers with similar tuning values to reduce the number of buffers inserted into the circuit. Buffers in the same group are implemented by only one physical buffer and the tuning values are sharedby all "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_46", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 46, "text": "fers with similar tuning values to reduce the number of buffers inserted into the circuit. Buffers in the same group are implemented by only one physical buffer and the tuning values are sharedby all the Ô¨Çip-Ô¨Çops connected to the buffer. The concept of grouping is illustrated in Fig. 7. In grouping buffers, we Ô¨Årst calculate the correlation coefÔ¨Åcients of tuning values of buffer pairs. If the mutual cor- relation coefÔ¨Åcients between several buffers are all above thethreshold r(i,j)and their distance is smaller than d(i,j),t h e y are grouped together and implemented with only one physical buffer. In practice, designers can also constrain the total num-ber of buffers in the circuit as N b. If the number of buffers after grouping still exceeds the speciÔ¨Åed number, the buffers withFig. 7. Buffer grouping according to tuning correlation and distance. Correlation threshold r(i,j)is set to 0.8. Distance threshold d(i,j)between buffers is set to ten times of the minimum distance between Ô¨Çip-Ô¨Çops. the fewest tunings are removed until the number of buffers meets the speciÔ¨Åcation. E. Acceleration Techniques To improve the efÔ¨Åciency of the proposed method, we sample statistical delays between"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_47", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 47, "text": "ops. the fewest tunings are removed until the number of buffers meets the speciÔ¨Åcation. E. Acceleration Techniques To improve the efÔ¨Åciency of the proposed method, we sample statistical delays between Ô¨Çip-Ô¨Çops directly instead of sampling delays of combinational gates. For example, thedelays in ( 1) and ( 2) are calculated using a statistical timing engine only once. We then generate a Sobol sequence from these statistical delays directly, instead of executing a static timing analysis algorithm for each sample. In addition, we Ô¨Ålter connections between Ô¨Çip-Ô¨Çops accord- ing to their statistical distributions. If the 3 œÉdelay of a path is still small enough not to affect the circuit performance, this path is not included when creating the constraints ( 1) and ( 2). For example, in the constraint ( 1) we Ô¨Årst set x ito the largest value and xjto the smallest value in the range windows, respectively, and dijandsjto their 3 œÉvalues. If this extreme setting still allows this path to work with a clock period in the fastest bin, this path is simply discarded from the problem formulation. Similarly, we also Ô¨Ålter hold time constraints ( 2) according to the ‚àí3œÉvalues of path delays. V. E XPE"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_48", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 48, "text": "h a clock period in the fastest bin, this path is simply discarded from the problem formulation. Similarly, we also Ô¨Ålter hold time constraints ( 2) according to the ‚àí3œÉvalues of path delays. V. E XPERIMENTAL RESULTS The proposed method was implemented in C ++and tested using a 3.20-GHz CPU with one thread. We demonstrate theresults using circuits from the ISCAS89 benchmark set and from the TAU 2013 variation-aware timing analysis contest. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 401 TABLE II RESULTS OF BUFFER ALLOCATION FOR POST-SILICON BINNING The number of Ô¨Çip-Ô¨Çops and the number of logic gates are shown in the columns nsandngin Table II, respectively. The benchmark circuits in our experiments were sized using a 45-nm library. We assumed that the maximum allowed bufferranges were 1/8 of the original clock period and tuning delays of the buffers were discrete with 20 steps, as in [ 7]. The stan- dard deviations of transistor length, transistor width and oxidethickness were set to 1"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_49", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 49, "text": "of the original clock period and tuning delays of the buffers were discrete with 20 steps, as in [ 7]. The stan- dard deviations of transistor length, transistor width and oxidethickness were set to 15.7%, 11.1%, and 5.3% of the nom- inal values, respectively. We used Gurobi [ 31]t os o l v et h e optimization problems in the proposed method. We used three bins in the experiments to improve the overall proÔ¨Åt. The boundaries between these bins were set to Œº T,ŒºT+ 0.5œÉT, andŒºT+œÉT, where ŒºTandœÉTare the mean value and the standard deviation of the clock period of the original circuit without clock buffers. Chips with clock period larger than ŒºT+ œÉTwere considered as yield loss. With this setting, the original yield values of these three bins without tuning buffers are 50%, 19.15%, and 14.98%, respectively. In all these test cases, the numbers of allocated buffers Nbwere constrained as lower than 1% of the numbers of Ô¨Çip-Ô¨Çops in the circuits, as shown in the nbcolumn. After allocating post-silicon tuning buffers using the proposed method, we ran Monte Carlo simulation with these circuits to verify the yield improvement. In the simulation, we generated 10 000 samples. For each sample wec"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_50", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 50, "text": "silicon tuning buffers using the proposed method, we ran Monte Carlo simulation with these circuits to verify the yield improvement. In the simulation, we generated 10 000 samples. For each sample wecalculated its minimum clock period using an ILP solver due to the appearance of tuning buffers, and assigned the sample to one of the performance bins. The yield value of a circuit in abin is the number of samples in that bin divided by 10 000. The samples in our experiments are conceptually different from the samples discussed in Section IV, because they were only used to emulate post-silicon measurements. For each sample, we verify whether a chip can be assigned into a bin by solving the classical skew scheduling problem in [ 19]. In reality, the delays and timing properties cannot be measured exactly from the manufactured chips, so that the actual yield is slightly smaller than the reported yield, as discussed in [ 21]. This yield, however, still serves as a good indicator to determine buffer locations. The yield values of the three bins are shown in the columns Y b1,Yb2, and Yb3in Table II, respectively. Compared with the yield values without clock buffers, we can see that the yiel"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_51", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 51, "text": "buffer locations. The yield values of the three bins are shown in the columns Y b1,Yb2, and Yb3in Table II, respectively. Compared with the yield values without clock buffers, we can see that the yield inthe Ô¨Årst bin is increased signiÔ¨Åcantly but the yield values of the other two bins are smaller, because with tuning buffers chipshave a better chance to be tuned to a higher performance. Adding the yield values of the three bins together, we can calculate the yield of a circuit with respect to Œº T+œÉT, shown in the YŒºT+œÉTcolumn. Compared with the original yield 84.13%, the yield increase is shown in the column Yinc, with an average 4.23%. With these yield values in the three bins, we can calcu- late the proÔ¨Åt using ( 4). In the experiments, we set the proÔ¨Åt per chip of the three bins to 6, 2, and 1, respectively. The overall proÔ¨Åt increase is shown in the column Pinc, with an average 14.29%. If we compare the column Pincand the col- umn Yinc, we can see that the improvement of proÔ¨Åt is much more signiÔ¨Åcant than the overall yield improvement due to theintroduced tuning buffers and clock binning. To achieve this proÔ¨Åt improvement, the number of buffers in the circuit is still less than"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_52", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 52, "text": "uch more signiÔ¨Åcant than the overall yield improvement due to theintroduced tuning buffers and clock binning. To achieve this proÔ¨Åt improvement, the number of buffers in the circuit is still less than 1% of the number of Ô¨Çip-Ô¨Çops. If we assume that abuffer takes ten times area of a Ô¨Çip-Ô¨Çop and Ô¨Çip-Ô¨Çops take 5% of the die area, the area cost of these buffers is about 0.5% of the die area. Therefore, we can expect a good overall rev- enue improvement, even when we consider the potential cost of post-silicon conÔ¨Åguration. A concrete evaluation of this costwill be our future work. In the proposed method, we also reduced the buffer sizes by concentrating tuning values. The average buffer sizes inthe benchmark circuits are shown in the column s b. Compared with the maximum allowed size 20, the buffer sizes have been reduced effectively by the proposed method while maintaininga good proÔ¨Åt improvement. The execution time of the proposed method is shown in the last column of Table II. The largest execution time of the proposed method is 1816.81 s, which isalready acceptable because the proposed method is executed ofÔ¨Çine only for a few times. Since the runtime of solving an ILP problem depen"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_53", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 53, "text": "st execution time of the proposed method is 1816.81 s, which isalready acceptable because the proposed method is executed ofÔ¨Çine only for a few times. Since the runtime of solving an ILP problem depends on the structure of constraints as well as their relations, it is difÔ¨Åcult to analyze the scalability of the proposed method theoreti- cally. Instead, we tested this method by Ô¨Åxing the number of samples in each batch to solve the buffer insertion problem with respect to a given clock period Œº T+œÉTas used in Table II. The relation between the number of samples in a batch and the runtime is illustrated in Fig. 8.pci_bridge32 did not Ô¨Ånish due to memory limitation, so that it was notincluded in this evaluation. According to these results, the runtime increases exponentially with respect to the number Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 402 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 Fig. 8. Scalability trend of the proposed method with a Ô¨Åxed number of samples in each batch. (a) (b) Fig. 9. Yield and runtime compar"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_54", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 54, "text": "OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 Fig. 8. Scalability trend of the proposed method with a Ô¨Åxed number of samples in each batch. (a) (b) Fig. 9. Yield and runtime comparison between the proposed method and the brute-force method with 10 000 samples. (a) Yield comparison. (b) Runtime comparison. of samples, especially with large circuits. In the proposed method, the number of samples in each batch is limited toN tas discussed in Section IV-C . This limitation might lead to a yield degradation because the optimization problem is split into several small problems. To verify the quality of the resultsproduced by the proposed method, we compared them with the yield results of a brute-force method processing 10 000 sam- ples as a whole, as shown in Fig. 9(a). With this comparison, it can be observed that the yield degradation of the proposed method is negligible, because the proposed work Ô¨Çow in Fig. 4 Ô¨Årst tries to capture all the buffer locations that have a poten- tial to affect the yield. Afterward, only these locations are considered in further iterations so that a batch can containmore samples, still leading to a good yield result. The run- time of th"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_55", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 55, "text": "poten- tial to affect the yield. Afterward, only these locations are considered in further iterations so that a batch can containmore samples, still leading to a good yield result. The run- time of the brute-force method, however, is much larger than the proposed method, as shown in Fig. 9(b). In the proÔ¨Åt deÔ¨Ånition ( 4), if we use only one bin, the problem formulation becomes the problem to improve the Fig. 10. Yield improvement with clock tuning buffers with respect to ŒºT, ŒºT+0.5œÉT,a n d ŒºT+œÉT, compared with the yield values without tuning buffers. (a) (b) Fig. 11. Yield increase with respect to different numbers of tuning buffers. Target clock period is set to (a) ŒºTand (b) ŒºT+œÉT. yield with respect to a single clock period. In our experiments, we tested this single-bin setting using ŒºT,ŒºT+0.5œÉT, and ŒºT+œÉTas the upper bounds of the single bins, respectively. The results of yield improvement are shown in Fig. 10.I na l l these test cases, the yield values have been improved effec-tively, up to 18.19% for the circuit s15850 in the Œº Tbin. In these test cases, the yield improvement is consistently better for bins with higher performance, because in these bins theoriginal yield valu"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_56", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 56, "text": "ely, up to 18.19% for the circuit s15850 in the Œº Tbin. In these test cases, the yield improvement is consistently better for bins with higher performance, because in these bins theoriginal yield values without tuning buffers are lower so that there is a large potential for the tuning buffers to take effect. In our experiments, we constrained the number of buffers to be smaller than 1% of the number of the Ô¨Çip-Ô¨Çops. If this number can be increased, we can expect an increase of yieldbecause there are more chances to tune the chips after manu- facturing. To show the effect of more tuning buffers, we tested the numbers of buffers equal to 1%, 3%, and 5% of the numberof Ô¨Çip-Ô¨Çops. For each of these buffer numbers, we calculated the yield values with respect to the single clock periods Œº T Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 403 TABLE III RUNTIME COMPARISON WITHOUT AND WITH ACCELERATION TECHNIQUES TABLE IV YIELD COMPARISON WITH[9] andŒºT+œÉT, respectively. The results are shown in Fig. "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_57", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 57, "text": "N CLOCK BINNING BY ITERATIVE LEARNING 403 TABLE III RUNTIME COMPARISON WITHOUT AND WITH ACCELERATION TECHNIQUES TABLE IV YIELD COMPARISON WITH[9] andŒºT+œÉT, respectively. The results are shown in Fig. 11. According to these experiments, we can see that the yield gen- erally increases when the number of buffers inserted into thecircuit increases. Similar to the trend of the yield improve- ment with respect to different clock periods in Fig. 10,t h e yield improvement with respect to Œº Tin Fig. 11(a) is more obvious compared with the yield improvement with respect to ŒºT+œÉTin Fig. 11(b). For the former, the average improve- ment of the 5% setting to the 1% setting is 6.78%, but forthe latter this improvement is only 2.75%. Consequently, we can conclude that post-silicon buffers are more useful in high- performance designs, specially with clock binning, where thepotential for proÔ¨Åt/yield improvement is large. To reduce the execution time of the proposed method, we introduced several acceleration techniques. With the Sobol sequence, the inner loop of the iterative Ô¨Çow in Fig. 4con- verged with the test cases usb_funct andpci_bridge32 , while the other cases used up all the samples. To de"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_58", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 58, "text": "ation techniques. With the Sobol sequence, the inner loop of the iterative Ô¨Çow in Fig. 4con- verged with the test cases usb_funct andpci_bridge32 , while the other cases used up all the samples. To demonstrate the efÔ¨Åciency of the acceleration techniques, we disable all of them and show the execution time in Table III. According to this comparison, it is obvious that the proposed acceleration techniques can shorten the execution time effectively. The buffer insertion problem is also addressed in [ 9] with a direct statistical model. For comparison, we show the results from their paper and the results of our method applied to the same set of circuits in Table IV.T h e N 1column shows the number of buffers in [ 9], and the N2column that of our method. Note their method is designed for a clock network with a tree structure and they do not group buffers as we do.Consequently, there is a large difference between the num- bers of buffers. The columns Y 1andY2show the yield values from their method and our method with the same clock periodsetting. In this comparison, the proposed method outperforms the method in [ 9] with a higher yield, while the number of clock tuning buffers is much sm"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_59", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 59, "text": "method and our method with the same clock periodsetting. In this comparison, the proposed method outperforms the method in [ 9] with a higher yield, while the number of clock tuning buffers is much smaller. Furthermore, we have implemented the method in [ 12] and the yield comparison is shown in Fig. 12. In this comparison, the numbers of inserted buffers are equal, so that we can conclude that the proposed method outperforms the method in [ 12] consistently. In the last step of the proposed method, we group buffers according to the correlation between tuning values. This cor- relation information is a natural result of the sampling-based Fig. 12. Yield comparison with the buffer insertion method in [ 12]. TABLE V YIELD COMPARISON OF DIFFERENT GROUPING ALGORITHMS (a) (b) Fig. 13. Comparison with [ 1]. (a) Yield improvement with the same setting. (b) Comparison of execution time of both methods. method. In [ 12], a grouping algorithm is also proposed accord- ing to circuit structure and distances between Ô¨Çip-Ô¨Çops. Wecompare the results of our correlation-based grouping method with theirs and the results are shown in Table V, where Y 1 is the yield with the grouping algorithm in [ 12"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_60", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 60, "text": " distances between Ô¨Çip-Ô¨Çops. Wecompare the results of our correlation-based grouping method with theirs and the results are shown in Table V, where Y 1 is the yield with the grouping algorithm in [ 12] and Y2is the yield with the proposed correlation-based grouping. For comparison, we have changed the numbers of buffers in the proposed method so that they are equal to the ones in [ 12]. From this comparison, we can see that our method produces a better yield, because we have the correlation information fromemulated samples. The method proposed in [ 1] uses the same concept in this paper, but it captures the locations of buffers by process-ing emulated samples once at a time. Therefore, the relation between tuning values in different samples is not incorporated. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. 404 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 37, NO. 2, FEBRUARY 2018 In addition, the method in [ 1] uses a purely random sequence so that the number of samples is still large. To verify theimprovement of the proposed method, we mapped the "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_61", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 61, "text": "OL. 37, NO. 2, FEBRUARY 2018 In addition, the method in [ 1] uses a purely random sequence so that the number of samples is still large. To verify theimprovement of the proposed method, we mapped the circuits used in [ 1] to the same library and tested the yield improve- ment with respect to Œº T. The results are shown in Fig. 13(a), where we can see that the proposed method produces a better yield improvement than [ 1] with the same number of buffers. Furthermore, we show the execution time of these methods inFig. 13(b). It is clear that the extended method in this paper is more efÔ¨Åcient than [ 1]. VI. C ONCLUSION In this paper, we propose a sampling-based method to deter- mine locations and ranges of post-silicon tuning buffers ina circuit to improve the overall proÔ¨Åt with clock binning. By establishing the relation between buffer locations and the yield with an ILP model directly, the proposed method can learn the buffer locations for yield improvement effec- tively. With acceleration techniques such as a low discrepancysequence, the proposed method takes much less time than previous methods. Experimental results conÔ¨Årm that the proÔ¨Åt of the circuit after manufacturing can be imp"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_62", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 62, "text": "n techniques such as a low discrepancysequence, the proposed method takes much less time than previous methods. Experimental results conÔ¨Årm that the proÔ¨Åt of the circuit after manufacturing can be improved signiÔ¨Å-cantly with a small number of buffers. Future tasks of this paper include post-silicon testing and conÔ¨Åguration of delays buffers to achieve the given clock period or proÔ¨Åt. The majorchallenge is to make a good tradeoff between test cost and proÔ¨Åt improvement. R EFERENCES [1] G. L. Zhang, B. Li, and U. Schlichtmann, ‚ÄúSampling-based buffer insertion for post-silicon yield improvement under process variability,‚Äù inProc. Design Autom. Test Europe Conf. , Dresden, Germany, 2016, pp. 1457‚Äì1460. [2] D. Blaauw, K. Chopra, A. Srivastava, and L. Scheffer, ‚ÄúStatistical tim- ing analysis: From basic principles to state of the art,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 27, no. 4, pp. 589‚Äì607, Apr. 2008. [3] D. Ernst et al. , ‚ÄúRazor: A low-power pipeline based on circuit-level timing speculation,‚Äù in Proc. Int. Symp. Microarchitect. , San Diego, CA, USA, 2003, pp. 7‚Äì18. [4] S. Naffziger et al. , ‚ÄúThe implementation of a 2-core, multi-threaded Itanium family pr"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_63", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 63, "text": "circuit-level timing speculation,‚Äù in Proc. Int. Symp. Microarchitect. , San Diego, CA, USA, 2003, pp. 7‚Äì18. [4] S. Naffziger et al. , ‚ÄúThe implementation of a 2-core, multi-threaded Itanium family processor,‚Äù IEEE J. Solid-State Circuits , vol. 41, no. 1, pp. 197‚Äì209, Jan. 2006. [5] E. Takahashi, Y . Kasai, M. Murakawa, and T. Higuchi, ‚ÄúPost-fabrication clock-timing adjustment using genetic algorithms,‚Äù IEEE J. Solid-State Circuits , vol. 39, no. 4, pp. 643‚Äì650, Apr. 2004. [6] P. Mahoney, E. Fetzer, B. Doyle, and S. Naffziger, ‚ÄúClock distribution on a dual-core, multi-threaded ItaniumR/circlecopyrt-family processor,‚Äù in Proc. Int. Solid-State Circuits Conf. , 2005, pp. 292‚Äì293. [7] S. Tam et al. , ‚ÄúClock generation and distribution for the Ô¨Årst IA-64 microprocessor,‚Äù IEEE J. Solid-State Circuits , vol. 35, no. 11, pp. 1545‚Äì1552, Nov. 2000. [8] J.-L. Tsai, D. Baik, C. C.-P. Chen, and K. K. Saluja, ‚ÄúA yield improvement methodology using pre- and post-silicon statistical clock scheduling,‚Äù in Proc. Int. Conf. Comput.-Aided Design , San Jose, CA, USA, 2004, pp. 611‚Äì618. [9] J.-L. Tsai, L. Zhang, and C. C.-P. Chen, ‚ÄúStatistical timing analy- sis driven post-silicon-tunable clock-tree s"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_64", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 64, "text": ",‚Äù in Proc. Int. Conf. Comput.-Aided Design , San Jose, CA, USA, 2004, pp. 611‚Äì618. [9] J.-L. Tsai, L. Zhang, and C. C.-P. Chen, ‚ÄúStatistical timing analy- sis driven post-silicon-tunable clock-tree synthesis,‚Äù in Proc. Int. Conf. Comput.-Aided Design , San Jose, CA, USA, 2005, pp. 575‚Äì581. [10] V . Khandelwal and A. Srivastava, ‚ÄúVariability-driven formulation for simultaneous gate sizing and postsilicon tunability allocation,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 27, no. 4, pp. 610‚Äì620, Apr. 2008. [11] K. Nagaraj and S. Kundu, ‚ÄúA study on placement of post silicon clock tuning buffers for mitigating impact of process variation,‚Äù in Proc. Design Autom. Test Europe Conf. , 2009, pp. 292‚Äì295.[12] Z. Lak and N. Nicolici, ‚ÄúA novel algorithmic approach to aid post-silicon delay measurement and clock tuning,‚Äù IEEE Trans. Comput. , vol. 63, no. 5, pp. 1074‚Äì1084, May 2014. [13] B. Li and U. Schlichtmann, ‚ÄúStatistical timing analysis and critical- ity computation for circuits with post-silicon clock tuning elements,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 34, no. 11, pp. 1784‚Äì1797, Nov. 2015. [14] K. Nagaraj and S. Kundu, ‚ÄúAn automatic post "}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_65", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 65, "text": "ircuits with post-silicon clock tuning elements,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 34, no. 11, pp. 1784‚Äì1797, Nov. 2015. [14] K. Nagaraj and S. Kundu, ‚ÄúAn automatic post silicon clock tuning system for improving system performance based on tester measure- ments,‚Äù in Proc. Int. Test Conf. , 2008, pp. 1‚Äì8. [15] D. Tadesse, J. Grodstein, and R. I. Bahar, ‚ÄúAutoRex: An automated post- silicon clock tuning tool,‚Äù in Proc. Int. Test Conf. , Austin, TX, USA, 2009, pp. 1‚Äì10. [16] R. Ye, F. Yuan, and Q. Xu, ‚ÄúOnline clock skew tuning for timing specu- lation,‚Äù in Proc. Int. Conf. Comput.-Aided Design , San Jose, CA, USA, 2011, pp. 442‚Äì447. [17] Z. Lak and N. Nicolici, ‚ÄúOn using on-chip clock tuning ele- ments to address delay degradation due to circuit aging,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 31, no. 12, pp. 1845‚Äì1856, Dec. 2012. [18] A. Chakraborty et al. , ‚ÄúDynamic thermal clock skew compensation using tunable delay buffers,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 16, no. 6, pp. 639‚Äì649, Jun. 2008. [19] J. P. Fishburn, ‚ÄúClock skew optimization,‚Äù IEEE Trans. Comput. , vol. 39, no. 7, pp. 945‚Äì951, Jul. 1990. [20] K."}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_66", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 66, "text": "s. Very Large Scale Integr. (VLSI) Syst. , vol. 16, no. 6, pp. 639‚Äì649, Jun. 2008. [19] J. P. Fishburn, ‚ÄúClock skew optimization,‚Äù IEEE Trans. Comput. , vol. 39, no. 7, pp. 945‚Äì951, Jul. 1990. [20] K. S. Kim, S. Mitra, and P. G. Ryan, ‚ÄúDelay defect characteristics and testing strategies,‚Äù IEEE Design Test Comput. , vol. 20, no. 5, pp. 8‚Äì16, Sep./Oct. 2003. [21] G. L. Zhang, B. Li, and U. Schlichtmann, ‚ÄúEfÔ¨ÅTest: EfÔ¨Åcient delay test and statistical prediction for conÔ¨Åguring post-silicon tunable buffers,‚Äù in Proc. Design Autom. Conf. , Austin, TX, USA, 2016, pp. 1‚Äì6. [22] T. H. Cormen, C. E. Leiserson, and R. L. Rivest, Introduction to Algorithms . Cambridge, MA, USA: MIT Press, 1990. [23] C. Visweswariah, K. Ravindran, K. Kalafala, S. G. Walker, and S. Narayan, ‚ÄúFirst-order incremental block-based statistical timing anal- ysis,‚Äù in Proc. Design Autom. Conf. , 2004, pp. 331‚Äì336. [24] J. Xiong, Y . Shi, V . Zolotov, and C. Visweswariah, ‚ÄúStatistical multilayer process space coverage for at-speed test,‚Äù in Proc. Design Autom. Conf. , San Francisco, CA, USA, 2009, pp. 340‚Äì345. [25] T. Wang, C. Zhang, J. Xiong, and Y . Shi, ‚ÄúEagle-Eye: A near-optimal statistical framework for noise sensor"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_67", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 67, "text": "-speed test,‚Äù in Proc. Design Autom. Conf. , San Francisco, CA, USA, 2009, pp. 340‚Äì345. [25] T. Wang, C. Zhang, J. Xiong, and Y . Shi, ‚ÄúEagle-Eye: A near-optimal statistical framework for noise sensor placement,‚Äù in Proc. Int. Conf. Comput.-Aided Design , San Jose, CA, USA, 2013, pp. 437‚Äì443. [26] F. Gong, Y . Shi, H. Yu, and L. He, ‚ÄúVariability-aware parametric yield estimation for analog/mixed-signal circuits: Concepts, algorithms, andchallenges,‚Äù IEEE Design Test , vol. 31, no. 4, pp. 6‚Äì15, Aug. 2014. [27] A. Singhee and R. A. Rutenbar, ‚ÄúFrom Ô¨Ånance to Ô¨Çip Ô¨Çops: A study of fast quasi-Monte Carlo methods from computational Ô¨Ånance applied to statistical circuit analysis,‚Äù in Proc. Int. Symp. Qual. Electron. Design , San Jose, CA, USA, 2007, pp. 685‚Äì692. [28] V . Veetil, K. Chopra, D. Blaauw, and D. Sylvester, ‚ÄúFast statistical static timing analysis using smart Monte Carlo techniques,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 30, no. 6, pp. 852‚Äì865, Jun. 2011. [29] I. M. Sobol, ‚ÄúThe distribution of points in a cube and the approximate evaluation of integrals,‚Äù USSR Comput. Math. Math. Phys. , vol. 7, no. 4, pp. 86‚Äì112, 1967. [30] G. E. P. Box and M. E. Muller"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_68", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 68, "text": "9] I. M. Sobol, ‚ÄúThe distribution of points in a cube and the approximate evaluation of integrals,‚Äù USSR Comput. Math. Math. Phys. , vol. 7, no. 4, pp. 86‚Äì112, 1967. [30] G. E. P. Box and M. E. Muller, ‚ÄúA note on the generation of random normal deviates,‚Äù Ann. Math. Stat. , vol. 29, no. 2, pp. 610‚Äì611, 1958. [31] Gurobi Optimization, Inc. (2013). Gurobi Optimizer Reference Manual . [Online]. Available: http://www .gurobi .com [32] D. Chen, R. G. Batson, and Y . Dang, Applied Integer Programming: Modeling and Solution . Hoboken, NJ, USA: Wiley, 2011. Grace Li Zhang received the master‚Äôs degree from the School of Microelectronics, Xidian University, Xi‚Äôan, China, in 2014. She is currently pur- suing the Ph.D. degree with the Institute forElectronic Design Automation, Technical Universityof Munich, Munich, Germany. Her current research interests include high- performance and lower-power design, and emergingsystems. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 405 Bing Li received the bachel"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_69", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 69, "text": "ptember 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : DESIGN-PHASE BUFFER ALLOCATION FOR POST-SILICON CLOCK BINNING BY ITERATIVE LEARNING 405 Bing Li received the bachelor‚Äôs and master‚Äôs degrees in communication and information engi-neering from the Beijing University of Posts andTelecommunications, Beijing, China, in 2000 and 2003, respectively, and the Dr.-Ing. degree in elec- trical engineering from the Technical University ofMunich (TUM), Munich, Germany, in 2010. He is currently a Researcher with the Institute for Electronic Design Automation, TUM. His cur- rent research interests include high-performance andlower-power design, and emerging systems. Jinglan Liu received the B.E. degree in communica- tion engineering from the Beijing University of Posts and Telecommunications, Beijing, China, in 2014. She is currently pursuing the Ph.D. degree with theDepartment of Computer Science and Engineering,University of Notre Dame, Notre Dame, IN, USA. Her current research interests include low-power system design and machine learning applications oninterdisciplinary Ô¨Åelds. Yiyu Shi (M‚Äô09‚ÄìSM‚Äô14) received the B.S. (Hons.) degree in electronic engineering fr"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_70", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 70, "text": "rent research interests include low-power system design and machine learning applications oninterdisciplinary Ô¨Åelds. Yiyu Shi (M‚Äô09‚ÄìSM‚Äô14) received the B.S. (Hons.) degree in electronic engineering from TsinghuaUniversity, Beijing, China, in 2005, and the M.S.and Ph.D. degrees in electrical engineering from the University of California at Los Angeles, Los Angeles, CA, USA, in 2007 and 2009, respectively. He is currently an Associate Professor with the Departments of Computer Science and Engineering and Electrical Engineering, University of Notre Dame, Notre Dame, IN, USA. His current researchinterests include 3-D integrated circuits and machine learning on chips. Dr. Shi was a recipient of several best paper nominations in top confer- ences, the IBM Invention Achievement Award in 2009, the Japan Societyfor the Promotion of Science Faculty Invitation Fellowship, the Humboldt Research Fellowship for Experienced Researchers, the IEEE St. Louis Section Outstanding Educator Award, Academy of Science (St. Louis) InnovationAward, the Missouri S&T Faculty Excellence Award, the National ScienceFoundation CAREER Award, the IEEE Region 5 Outstanding Individual Achievement Award, and the Air F"}
{"id": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf::chunk_71", "source": "DesignPhase_Buffer_Allocation_for_Post-Silicon_Clock_Binning_by_Iterative_Learning.pdf", "chunk_index": 71, "text": "f Science (St. Louis) InnovationAward, the Missouri S&T Faculty Excellence Award, the National ScienceFoundation CAREER Award, the IEEE Region 5 Outstanding Individual Achievement Award, and the Air Force Summer Faculty Fellowship. Ulf Schlichtmann (S‚Äô88‚ÄìM‚Äô90) received the Dipl.-Ing. and Dr.-Ing. degrees in electrical engineer-ing and information technology from the Technical University of Munich (TUM), Munich, Germany, in 1990 and 1995, respectively. He was with Siemens AG, Munich, and InÔ¨Åneon Technologies AG, Munich, from 1994 to 2003, where he held various technical and managementpositions in design automation, design libraries, IPreuse, and product development. He has been a Professor and the Head of the Institute for Electronic Design Automation, TUM, since 2003, where he served as the Dean of theDepartment of Electrical and Computer Engineering, from 2008 to 2011. Hiscurrent research interests include computer-aided design of electronic circuits and systems, with an emphasis on designing reliable and robust systems. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:27:07 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_0", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 0, "text": "Advanced Engineering Informatics 60 (2024) 102540 Available online 12 April 2024 1474-0346/¬© 2024 Elsevier Ltd. All rights reserved.Full length article Development of a spatial dimension-based taxonomy for classifying the defect patterns in a wafer bin map Seung-Hyun Choia, Dong-Hee Leeb, Eun-Su Kimc, Young-Mok Baea,c, Young-Chan Ohc, Kwang-Jae Kima,* aDepartment of Industrial and Management Engineering, Pohang University of Science and Technology, 77, Cheongam-ro, Nam-gu, Pohang, Gyung-buk 37673, Republic of Korea bDepartment of Systems Management Engineering, Sung Kyun Kwan University, 2066, Seobu-ro, Jangan-gu, Suwon, Gyeong-gi 16419, Republic of Korea cSK Hynix Inc., 337, Jikji-daero, Heungdeok-gu, Cheongju, Chung-buk 28436, Republic of Korea ARTICLE INFO Keywords: Semiconductor manufacture Wafer bin map Defect pattern Classification Taxonomy ABSTRACT A wafer bin map (WBM) represents the locational information of defective chips on the wafer. The spatial correlation of defects on the wafer provides crucial information for the root cause diagnosis of defects in wafer fabrication. The spatial correlation is classified as a defect pattern for efficient diagnostics. A defect patter"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_1", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 1, "text": "he wafer provides crucial information for the root cause diagnosis of defects in wafer fabrication. The spatial correlation is classified as a defect pattern for efficient diagnostics. A defect pattern taxonomy should be defined in advance for coherent classification of defect patterns. Various taxonomies are used in previous studies, but they share common limitations in that the differentiation among defect patterns is unclear, the set of predefined defect patterns is insufficient, and they cannot accommodate newly-emerged defect patterns. A concept of spatial dimension-based defect pattern taxonomy and its development procedure are proposed. Defect patterns are defined by three spatial dimensions, namely, Shape , Size, and Location . The development procedure is applied to a major NAND flash memory semiconductor manufacturer for two years. Results show that spatial dimension-based taxonomy can improve the performance of the defect pattern clas- sification system by alleviating common existing limitations. Moreover, meaningful defect patterns for di- agnostics are retained through the engineers ‚Äô involvement in the development procedure. 1.Introduction The semiconductor manufactur"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_2", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 2, "text": " existing limitations. Moreover, meaningful defect patterns for di- agnostics are retained through the engineers ‚Äô involvement in the development procedure. 1.Introduction The semiconductor manufacturing process comprises several hun- dred steps to fabricate hundreds to thousands of chips on a wafer. After the wafer fabrication, electrical probe tests are conducted to determine whether a chip has the proper quality for a packaging process. Defective chips (referred to as defects) fail at least one of the probe tests. The test results are recorded by the binary bin code, which expresses whether a chip is functional or defective [1], or by the categorical bin code, which expresses the type of failed tests [2]. A wafer bin map (WBM) arranges the position of chips and their bin codes to represent the probe test re- sults of a wafer. A WBM may comprise random defects, non-random defects, or both. Determining whether a given defect (i.e., a specific defect) is a random or non-random defect is generally impossible due to the large number of chips on a wafer and the various factors influencing chip quality throughout the wafer fabrication process [3]. However, in the literature, if a group"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_3", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 3, "text": "s generally impossible due to the large number of chips on a wafer and the various factors influencing chip quality throughout the wafer fabrication process [3]. However, in the literature, if a group of defects exhibits a spatial correlation on the WBM, the de- fects are attributed to an assignable cause and categorized as non- random defects [4]. For instance, line-shaped and circle-shaped de- fects are attributed to the hardening of the pad and the non-uniformity problem during chemical ‚Äìmechanical planarization, respectively [5]. On the other hand, defects that are randomly distributed on a WBM without a spatial correlation are considered random defects. The types of spatial correlation among defects are referred to as defect patterns. They manifest themselves in various forms, such as a Line, Circle , and Ring [6]. The relationship between the wafer fabrication failure and defect patterns is identified through manual monitoring [7], statistical analysis [8], pattern mining [9], and rule-based inference [10]. The fundamental assumption of diagnostics is that defect patterns are coherently classified, but this assumption is invalid in practice. In manual classification, a single"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_4", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 4, "text": "d rule-based inference [10]. The fundamental assumption of diagnostics is that defect patterns are coherently classified, but this assumption is invalid in practice. In manual classification, a single engineer ‚Äôs long-term repeatability is less than 95 %, and the agreement between engineers is less than 45 % [11]. *Corresponding authors. E-mail addresses: seunghyun.choi@postech.ac.kr (S.-H. Choi), dhee@skku.edu (D.-H. Lee), eunsu381.kim@sk.com (E.-S. Kim), ymbae@postech.ac.kr (Y.-M. Bae), youngchan.oh@sk.com (Y.-C. Oh), kjk@postech.ac.kr (K.-J. Kim). Contents lists available at ScienceDirect Advanced Engineering Informatics u{ÔøΩ~zkw! s{yo|kr o>!√ê√ê√ê1owÔøΩo ÔøΩto~1m{y2w{m kÔøΩo2kot! https://doi.org/10.1016/j.aei.2024.102540 Received 28 February 2023; Received in revised form 13 March 2024; Accepted 9 April 2024 Advanced Engineering Informatics 60 (2024) 102540 2Automatic classification models have recently replaced manual classi - fication [1,5,9,12 ‚Äì16], but incoherently classified datasets degrade the performance of the classification models [17]. The performance of the models heavily depends on the quality of input data [18,19] ; thus, the acquisition of a coherently classified WBM datas"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_5", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 5, "text": "grade the performance of the classification models [17]. The performance of the models heavily depends on the quality of input data [18,19] ; thus, the acquisition of a coherently classified WBM dataset is important. A defect pattern taxonomy refers to a set of predefined defect pat- terns, and a WBM dataset is commonly classified using the taxonomy in practice. For instance, non-random defects in the WM811K dataset [20] are classified as one of the nine defect patterns of the WM811K taxon - omy, namely, Center, Donut, Location, Edge-Loc, Edge-Ring, Scratch, Random, None, and Near-Full . Fig. 1 depicts the WM811K taxonomy, where functional and defective chips are indicated in gray and white colors, respectively. As mentioned earlier, a WBM can be represented using either the binary bin code or the categorical bin code. However, in the literature, defect pattern taxonomies have been developed predominantly for the case of binary bin code. This is because a defect pattern taxonomy aims to classify defect patterns based solely on the spatial features of defects [21‚Äì23], where the binary bin code proves sufficient for representing these spatial features. Moreover, a WBM with the catego"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_6", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 6, "text": "o classify defect patterns based solely on the spatial features of defects [21‚Äì23], where the binary bin code proves sufficient for representing these spatial features. Moreover, a WBM with the categorical bin code can be easily transformed into one with the binary bin code [24]. Hence, without the loss of generality, this study assumes that the WBM com- prises the binary bin code. A poorly defined defect pattern taxonomy is one of the reasons for incoherent classification [1,25] . For coherent classification, the defect pattern taxonomy should possess three desirable properties of a general taxonomy, namely, robustness, comprehensiveness, and extendibility [26]. The robustness refers to a clear differentiation between the defect patterns. Accurately classifying spatial correlations requires differenti - ation criteria that facilitate clear differentiation between defect patterns. The comprehensiveness means that defect patterns are sufficiently defined to classify spatial correlations among defects in the WBM dataset. When defects show spatial correlations not defined in a defect pattern taxonomy, there is a risk of neglecting these spatial correlations during diagnostics or miscl"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_7", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 7, "text": " among defects in the WBM dataset. When defects show spatial correlations not defined in a defect pattern taxonomy, there is a risk of neglecting these spatial correlations during diagnostics or misclassifying them as a different defect pattern within the taxonomy. This may lead to inaccurate identification of the root cause [27]. The extendibility means the capability to add newly- emerged defect patterns in the future. A new defect pattern may indi- cate a previously unidentified root cause of wafer fabrication failure that requires investigation [9]. Consequently, the defect pattern taxonomy should be adaptable to include new patterns, facilitating ongoing root cause analysis in the wafer fabrication process. Data quality has grown to prominence in smart manufacturing sys- tems [28], and previous studies assume that the WBM dataset is coherently classified. However, previous taxonomies used in automatic defect pattern classification studies lack at least one of the three desir- able properties, which are critical for coherent defect pattern classifi - cation. The research gap between the acquisition of a coherently classified WBM dataset and defect pattern classification lies in"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_8", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 8, "text": " properties, which are critical for coherent defect pattern classifi - cation. The research gap between the acquisition of a coherently classified WBM dataset and defect pattern classification lies in the absence of a defect pattern taxonomy that possesses all three desirable properties. This paper presents the concept and a development procedure of a spatial-dimension-based WBM taxonomy that possesses the three desirable properties of a general taxonomy and integrates domain expertise. The proposed taxonomy comprises three spatial dimensions, namely, Shape , Size, and Location. The dimension levels represent the spatial features of the defects in each dimension. Defect patterns are defined by the combination of dimension levels of the three spatial di- mensions. The robustness, comprehensiveness, and extendibility are possessed through the methodical definition of defect patterns on the three-dimensional structure. We applied the proposed procedure to the development of a defect pattern taxonomy of NAND flash memory for two years and demonstrated the advantages of the developed taxonomy. This paper is organized as follows. A review of the existing taxon - omies for defect pattern "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_9", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 9, "text": "rn taxonomy of NAND flash memory for two years and demonstrated the advantages of the developed taxonomy. This paper is organized as follows. A review of the existing taxon - omies for defect pattern classification is provided in Section 2. The spatial dimension-based taxonomy and its development procedure are proposed in Section 3. The proposed taxonomy is validated through manual and automatic defect pattern classification in Section 4. Finally, concluding remarks and future research issues are discussed in Section 5. 2.Literature review The taxonomies developed in the early stages of defect pattern classification studies comprise only a few defect patterns. For instance, Cunningham and MacKinnon [4] defined only one defect pattern, Scratch . Chih-Hsuan Wang et al. [29] considered three defect patterns: Zone, Line, and Ring. Line corresponds to Scratch in Cunningham and MacKinnon [4] taxonomy. Similar taxonomies were proposed in other studies [9,30 ‚Äì36]. The taxonomies in the aforementioned category effectively classify a few defect patterns. However, the spatial correlation within defects becomes complicated because the wafer size is enlarged, and the chip size is decreased [25]"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_10", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 10, "text": "ntioned category effectively classify a few defect patterns. However, the spatial correlation within defects becomes complicated because the wafer size is enlarged, and the chip size is decreased [25]. Thus, the taxonomies in modern wafer fabrication processes are extended to accommodate more complicated defect pat- terns through two approaches. These two approaches will henceforth be referred to as ‚Äòpattern subdivision ‚Äô and ‚Äòpattern addition ‚Äô. One defect pattern may be related to several root causes [8,37] , and the pattern subdivision approach mitigated such relationships by sub- dividing the existing defect pattern into more detailed ones. For instance, Chen and Liu [38] subdivided ring-shaped and scratch-shaped defect patterns; ring-shaped defect patterns were subdivided in accor - dance with the distance from the wafer center and scratch-shaped defect patterns were subdivided by their location. Bae et al. [39] subdivided scattered-shaped defect patterns by their location, namely, random scattering , radial scattering , and scattering in one corner . Li and Huang [3] and Liukkonen and Hiltunen [40] used a similar approach. The pattern subdivision approach enhances the robustn"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_11", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 11, "text": ", random scattering , radial scattering , and scattering in one corner . Li and Huang [3] and Liukkonen and Hiltunen [40] used a similar approach. The pattern subdivision approach enhances the robustness by Fig. 1.WM811K taxonomy. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 3improving the differentiation between defect patterns. However, it has the disadvantage of limiting the taxonomy ‚Äôs comprehensiveness, as pattern subdivision can only extend the taxonomy based on existing defect patterns. For instance, the taxonomy introduced in Chen and Liu [38] cannot accommodate scattered-shaped defect patterns through subdivision because only ring- and scratch-shaped defect patterns exis- ted in the taxonomy from the beginning. The extendibility of the tax- onomy is limited in that this approach only allows the subdivision of existing defect patterns. In order to accommodate a newly-emerged defect pattern, the pattern addition approach added a newly-emerged defect pattern to an existing defect pattern taxonomy [41‚Äì49]. For instance, Hat pattern (Fig. 2-(a)) was added in Cheng et al. [50], Ooi et al. [49], and Ooi et al. [45], and Checker-board (Fig. 2-(b)) was added "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_12", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 12, "text": "n to an existing defect pattern taxonomy [41‚Äì49]. For instance, Hat pattern (Fig. 2-(a)) was added in Cheng et al. [50], Ooi et al. [49], and Ooi et al. [45], and Checker-board (Fig. 2-(b)) was added in Chien et al. [48] and S.-C. Hsu and Chien [43] to distinguish new defect patterns from existing defect patterns (i.e., Ring, Line, and Zone). The addition of a new defect pattern can accommodate newly-emerged defect patterns, wherein the comprehensiveness and extendibility are possessed. However, the pattern addition approach has the disadvantage of compromising the taxonomy ‚Äôs robustness. Adding a new defect pattern in an ad hoc manner may lead to inconsistent differentiation criteria between defect patterns, resulting in unclear differentiation between defect patterns. For example, in the WM811K taxonomy, Donut indicates a shape of defect pattern, while Center indicates a location of defect pattern. Thus, the donut-shaped defects in the center location can be classified as one of the two defect patterns depending on the engineer ‚Äôs subjective judgment. The research gap is evident in the existing pattern subdivision and pattern addition approaches, which do not possess all three de"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_13", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 13, "text": "two defect patterns depending on the engineer ‚Äôs subjective judgment. The research gap is evident in the existing pattern subdivision and pattern addition approaches, which do not possess all three desirable properties of taxonomy as summarized in Table 1. To address this research gap, this study proposes a spatial dimension-based taxonomy and its development procedure, aimed at embodying the three desirable properties as shown in the rightmost column of Table 1. Clear differ - entiation between dimension levels in each spatial dimension enhances the taxonomy ‚Äôs robustness, while the addition and modification of dimension levels in spatial dimensions contribute to the comprehen - siveness and extendibility. Moreover, domain expertise is integrated into the taxonomy through the involvement of engineers in the defect pattern development procedure. 3.Development of the spatial dimension-based taxonomy This section describes the concept of the spatial dimension-based taxonomy and its development procedure with an application to a NAND flash memory semiconductor manufacturer in Korea. The WBM dataset comprises 1793 WBMs, each consisting of approximately 500 chips, manufactured in 2020. "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_14", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 14, "text": "opment procedure with an application to a NAND flash memory semiconductor manufacturer in Korea. The WBM dataset comprises 1793 WBMs, each consisting of approximately 500 chips, manufactured in 2020. Each chip ‚Äôs binary bin codes and x- and y- positions on a WBM (integer, ¬â0C25¬ä2) are recorded in the dataset, along with the wafer ID. The WBM size is identical at 26 √ó26, in which a 26 √ó26 matrix is made for each wafer; the row and column of matrix correspond to the y-axis and x-axis of WBM, respectively. The matrices were converted into black-and-white images for manual inspection. Inspired by the general taxonomy development procedure proposed by Nickerson et al. [26], the two-stage procedure is proposed. In Stage 1, spatial dimensions and their dimension levels are defined. Spatial fea- tures of non-random defects are extracted from a thorough review of existing defect pattern taxonomies as well as a real WBM dataset. The features extracted are then organized into dimensions and levels within those dimensions. In Stage 2, defect patterns for the taxonomy are defined by combining the dimension levels. Some defect patterns are merged or removed so that only meaningful defect pattern"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_15", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 15, "text": "s within those dimensions. In Stage 2, defect patterns for the taxonomy are defined by combining the dimension levels. Some defect patterns are merged or removed so that only meaningful defect patterns for diag- nosing wafer fabrication failures are retained. Three practicing engineers, each with over five years of experience in wafer quality monitoring and control, were involved in the taxonomy development procedure. They played a crucial role in Stages 1 and 2. In Stage 1, the engineers assisted in deciding whether to merge or subdi - vide dimension levels. They also contributed to establishing differenti - ation criteria between these levels. In Stage 2, their involvement extended to screening dimension level combinations, identifying those sharing the same root cause and removing irrelevant combinations. The engineers ‚Äô involvement has been essential, integrating domain expertise to ensure the proposed taxonomy is both practically meaningful and effective. 3.1. Stage 1: Definition of dimensions and dimension levels The spatial dimension-based taxonomy comprises multiple di- mensions, each containing dimension levels that are mutually exclusive and collectively exhaustive. The m"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_16", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 16, "text": "of dimensions and dimension levels The spatial dimension-based taxonomy comprises multiple di- mensions, each containing dimension levels that are mutually exclusive and collectively exhaustive. The main spatial features of non-random defects should be considered in defining the dimensions. In manual vi- sual inspection of WBM, various spatial features such as shape, size, location, color, and orientation can be used to analyze non-random defects [4,31,32,38,42,51,52] . However, in the context of defect pattern taxonomy, color and orientation have been rarely considered. Color is not used because defect pattern taxonomies typically employ the binary bin code, as mentioned in Section 1. Orientation is disregarded because the same defect patterns with different orientations (i.e., rotation-variant defect patterns) are known to be associated with the identical wafer fabrication failure [33]. Therefore, the shape, size, and location are considered to be sufficient in defining the meaningful spatial dimensions of defect patterns. Thus, the proposed taxonomy is developed based on the dimensions of shape, size, and location. The Shape dimension manifests the form of a defect pattern, such"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_17", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 17, "text": "l spatial dimensions of defect patterns. Thus, the proposed taxonomy is developed based on the dimensions of shape, size, and location. The Shape dimension manifests the form of a defect pattern, such as a scratch or arc. The Size dimension is a scale indicator of the shape, so Size manifests itself in conjunction with Shape . For instance, length is a size measurement of a scratch shape. The Location dimension indicates the site of a defect pattern on a WBM. Dimension levels represent the spatial feature of the defect patterns in each dimension. Dimension levels were defined on the basis of spatial features from the collected WBM dataset for each dimension. The spatial features of each dimension are identified and subsequently organized into dimension levels. Identification and organization are iteratively performed until every dimension level is unique within its dimension, and all spatial features of non-random defects in the WBM dataset are Fig. 2.Reproduced example of Hat and Checker-board patterns. Table 1 Summary of existing WBM defect pattern taxonomies. Pattern subdivision Pattern addition Proposed taxonomy Robustness ‚úì ‚úì Comprehensiveness ‚úì ‚úì Extendibility ‚ñ≥ ‚úì ‚úì Related s"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_18", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 18, "text": "ker-board patterns. Table 1 Summary of existing WBM defect pattern taxonomies. Pattern subdivision Pattern addition Proposed taxonomy Robustness ‚úì ‚úì Comprehensiveness ‚úì ‚úì Extendibility ‚ñ≥ ‚úì ‚úì Related studies [3,38 ‚Äì40] [41‚Äì50] ‚Ä¢ ‚úì: possess, ‚ñ≥: restrictively possess S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 4represented by the dimension levels. Each dimension level is differen - tiated using an objective criterion, which formalizes engineers ‚Äô domain knowledge and subjective judgment into a definitive form [49]. In addition, the threshold level between dimension levels should be established to effectively aid in root cause diagnosis. The spatial features of the Size dimension were identified and orga- nized in conjunction with those of the Shape dimension. Meanwhile, the spatial features of the Location dimension were identified and organized independently. Additionally, the criteria for differentiating dimension levels were established based on the number of defects, considering that the WBM dataset comprises wafers with the same number of chips. These criteria can be defined either by a relative scale, such as the percentage of total chips on a wafer [43],"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_19", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 19, "text": "fects, considering that the WBM dataset comprises wafers with the same number of chips. These criteria can be defined either by a relative scale, such as the percentage of total chips on a wafer [43], or by a physical scale, such as the length measured in centimeters [38]. The levels of the Shape dimension are Scratch , Cluster , Ring, and Random . They represent the defect patterns ‚Äô forms, as indicated in those names. Scratch and Cluster were differentiated on the basis of the defect pattern ‚Äôs maximum width. The pattern is classified as Scratch when the maximum width is four chips. Otherwise, the pattern is classified as Cluster . The engineers determined the threshold level (i.e., four chips) because the scratch-shaped pattern was attributed to the physical damage during the wafer fabrication. Thus, its width is generally lower than the four chips. Similar to taxonomies found in [20,36,42,44] , the proposed taxonomy incorporates the ‚ÄúRandom ‚Äù level in the Shape dimension to characterize the defect pattern of a WBM without spatial correlation among defects. The levels of the Size dimension were defined in conjunction with the shape of the defect pattern. The levels of the Size d"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_20", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 20, "text": "erize the defect pattern of a WBM without spatial correlation among defects. The levels of the Size dimension were defined in conjunction with the shape of the defect pattern. The levels of the Size dimension for Cluster are Big and Small . The pattern is defined as Cluster-Big if the defect pattern comprises more than 40 chips and defined as Cluster-Small otherwise. The threshold level was determined at 40 chips, which is approximately 8 % of the total number of chips in a wafer, because the engineers believe that a cluster of more than 40 defective chips may degrade the wafer ‚Äôs overall quality. Similarly, the threshold for the Size dimension in the Random pattern was set at 150 chips, approximately 30 % of the total number of chips in a wafer. The threshold between Scratch-Long and Scratch-Short was determined at 10 chips, approxi - mately 75 % of the wafer ‚Äôs radius. This decision took into account the rotation of the wafer during fabrication, which contributes to the for- mation of line-shaped defect pattern. For the Ring pattern, the Size dimension levels were established to encompass representative angles of 90‚Ä¢, 180‚Ä¢, 270‚Ä¢, and 360‚Ä¢. Each of the representative angle is allo"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_21", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 21, "text": "f line-shaped defect pattern. For the Ring pattern, the Size dimension levels were established to encompass representative angles of 90‚Ä¢, 180‚Ä¢, 270‚Ä¢, and 360‚Ä¢. Each of the representative angle is allowed a leeway of ¬±45‚Ä¢except Ring-Whole , where the arc angle is defined to be between 315‚Ä¢and 360‚Ä¢. Table 2 presents the dimension level descrip - tion and representative images for the Shape and Size dimensions. Edge, Center , Others , and Scattered levels were defined by the relative location of the defect patterns on the WBM in the Location dimension. The Edge level indicates that the defect pattern contacts with the wafer edge. Without that contact with the wafer edge, the Center level mani - fests that the defect pattern ‚Äôs center point is on the wafer center. The Others level manifests if the center point is not at the center. Further detailed location levels (e.g., Upper-right , Lower-left ) exist at the early stage of dimension level organization, but they were merged into Others because the engineers claimed that the rotational-variant features were not critical for diagnostics. The Scattered level was defined to represent the Random level location. This dimension level indicat"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_22", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 22, "text": "cause the engineers claimed that the rotational-variant features were not critical for diagnostics. The Scattered level was defined to represent the Random level location. This dimension level indicates that the de- fects are scattered across the wafer. Descriptions and representative images of the Location dimension are provided in Table 3. 3.2. Stage 2: Definition of defect patterns Defect patterns were defined by the combination of the dimension levels in the three dimensions as Shape ‚ÄìSize‚ÄìLocation in the proposed taxonomy. For instance, Scratch ‚ÄìLong ‚ÄìCenter refers to a scratch-shaped defect pattern with a length exceeding 10 chips on the wafer center. Out of 40 possible combinations, 26 physically feasible combinations Table 2 Description of the Shape and Size dimensions. Dimension Shape Size Image Level Description Level Description Dimension Levels Scratch The defect pattern ‚Äôs shape is a thin line, and its maximum width is four chips. Long The length of the scratch exceeds 10 chips. Short The length of the scratch is 10 chips at most. Cluster The defect pattern ‚Äôs shape is a lump, and its maximum width exceeds four chips. Big The number of consisting chips exceeds 40. Smal"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_23", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 23, "text": "chips. Short The length of the scratch is 10 chips at most. Cluster The defect pattern ‚Äôs shape is a lump, and its maximum width exceeds four chips. Big The number of consisting chips exceeds 40. Small The number of consisting chips is 40 at most. Ring The defect pattern takes the form of an arc or a ring. One- quarter The arc angle is between 45‚Ä¢ and 135‚Ä¢. Half The arc angle is between 135‚Ä¢and 225‚Ä¢. Three- quarters The arc angle is between 225‚Ä¢and 315‚Ä¢. Whole The arc angle is between 315‚Ä¢and 360‚Ä¢. Random The defective chips do not show a spatial correlation. Frequent The number of consisting chips exceeds 150. Infrequent The number of consisting chips is 150 at most. Table 3 Description of the Location dimension. Level Description Image Edge The defect pattern contacts the wafer edge. Center The defect pattern ‚Äôs center point is on the center and does not contact the wafer edge. Others The defect pattern ‚Äôs center point is between the center and edge of the wafer and does not contact the edge. Scattered The defects are scattered across the wafer. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 5remained. For instance, the Ring level from the Shape dimension can"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_24", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 24, "text": "the edge. Scattered The defects are scattered across the wafer. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 5remained. For instance, the Ring level from the Shape dimension cannot be combined with the Scattered level in the Location dimension. The engineers reviewed the remaining combinations to reflect the domain knowledge on wafer fabrication failure, and Table 4 summarizes the results. Consequently, 10 out of the 26 defect patterns passed the practicality check. The engineers claimed that the root cause of the ring- shaped pattern is irrelevant to its size, wherein the related dimension levels in the Size dimension were merged into All. The Others and Center levels in the Location dimension were removed because the engineers knew from experience that the ring-shaped pattern occurred only at the edge of wafers. The engineers also argued that the root causes of cluster- shaped defects at the wafer center are similar. The Cluster ‚ÄìBig‚ÄìCenter and Cluster ‚ÄìSmall ‚ÄìCenter were merged into Cluster ‚ÄìAll‚ÄìCenter . The location of the scratch-shaped defect pattern was also considered insignificant. Thus, the related dimension levels in the Location dimen - sion were "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_25", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 25, "text": "Center were merged into Cluster ‚ÄìAll‚ÄìCenter . The location of the scratch-shaped defect pattern was also considered insignificant. Thus, the related dimension levels in the Location dimen - sion were merged into All. 4.Validation of the taxonomy In this section, the proposed taxonomy is validated through manual and automatic defect pattern classification. The WM811K taxonomy was selected for the benchmark taxonomy. The WM811K taxonomy is the most widely employed taxonomy for the validation of automatic defect pattern classification models [1,14 ‚Äì16,20,37,53 ‚Äì58]. Also, the WM811K taxonomy is the only taxonomy that is provided with a sub- stantial labeled WBM dataset [20], which can be served as a reference for manual classification. The WBM dataset used in this section consists of 3,209 WBMs of NAND flash memory product family. The data format and WBM size were identical to those used in the Section 3. 4.1. Assessment of the robustness and the comprehensiveness The robustness and comprehensiveness of the proposed taxonomy were assessed through manual classification in this section. Two raters independently classified the same WBM dataset using the proposed and WM811K taxonomies. Th"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_26", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 26, "text": "ehensiveness of the proposed taxonomy were assessed through manual classification in this section. Two raters independently classified the same WBM dataset using the proposed and WM811K taxonomies. The classification coherence between the raters was compared, and the incoherent classification results were reviewed to assess the robustness. Then, the number of WBMs classified as defect patterns without spatial correlation among defects (i.e., Random ‚ÄìInfrequent ‚ÄìScattered and None) in each taxonomy was compared to assess the comprehensiveness. A WBM is classified as them when the taxonomy cannot represent the spatial correlation among defects on a WBM. Thus, the number of WBMs classified as random defects is pre- sumed to be an indicator of the comprehensiveness. First, the inter-rater agreement was better in the proposed taxonomy. The inter ‚Äìrater agreement was assessed by proportion agreement and Cohen ‚Äôs Kappa [59]. A proportion agreement is a proportion of WBMs that two raters classified as the same defect pattern. Kappa is a chance- corrected index that ranges from \u00001 to ¬á1, where ¬á1 indicates perfect agreement and 0 indicates that the agreement is the same as chance agreement."}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_27", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 27, "text": "ified as the same defect pattern. Kappa is a chance- corrected index that ranges from \u00001 to ¬á1, where ¬á1 indicates perfect agreement and 0 indicates that the agreement is the same as chance agreement. The inter-rater agreement is considered better as the pro- portion agreement and the Kappa value approaches 100 % and ¬á1, respectively, in our context. Table 5 shows the inter-rater agreement results. Both indices were higher in the proposed taxonomy, which in- dicates that the two raters had more consistent differentiation results in the proposed taxonomy. Second, a review of the disagreement WBMs revealed that the dif- ferentiation criteria were clearer in the proposed taxonomy. Proportions of disagreements were 20.2 % and 34.7 % in the proposed and WBM taxonomies, respectively (Table 5), and the disagreement WBMs were reconciled to confirm the defect pattern. Fig. 3 shows five examples of ambiguous WBM images that were successfully differentiated in the proposed taxonomy, but not in the WM811K taxonomy. Fig. 3-(a) was clearly classified as a Cluster ‚ÄìBig‚ÄìEdge pattern in the proposed taxon - omy, but could be classified as Center , Edge-Loc , or Location depending on the rater ‚Äôs su"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_28", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 28, "text": "e WM811K taxonomy. Fig. 3-(a) was clearly classified as a Cluster ‚ÄìBig‚ÄìEdge pattern in the proposed taxon - omy, but could be classified as Center , Edge-Loc , or Location depending on the rater ‚Äôs subjective judgment using the WM811K taxonomy. The ambiguity arose due to the unclear differentiation criteria of the loca- tional information in the WM811K taxonomy. Fig. 3-(b) was clearly classified as Cluster ‚ÄìSmall ‚ÄìEdge in the proposed taxonomy because the differentiating criterion between Cluster and Scratch is objectively defined. However, the corresponding classification would be either Scratch or Edge-Loc in the WM811K taxonomy depending on the raters ‚Äô subjectiveness. Fig. 3-(c) and (d) were clearly classified as Cluster-All- Center in the proposed taxonomy, whereas they could be classified as Location or Donut in the WM811K taxonomy. Third, more spatial correlations among defects can be classified in the proposed taxonomy. The column of ‚ÄúOriginal ‚Äù in Table 6 shows the number of WBMs in the reconciled result. The number of WBMs with None pattern in the WM811K taxonomy was more than twice that of Random ‚ÄìInfrequent ‚ÄìScattered in the proposed taxonomy, indicating that more spati"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_29", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 29, "text": "BMs in the reconciled result. The number of WBMs with None pattern in the WM811K taxonomy was more than twice that of Random ‚ÄìInfrequent ‚ÄìScattered in the proposed taxonomy, indicating that more spatial correlations among defects can be represented in the pro- posed taxonomy. In the taxonomy development procedure, spatial features from the WBM dataset were identified and then organized into the three spatial dimensions. Thus, the proposed taxonomy did not omit the spatial fea- tures in the dataset. For instance, Fig. 4-(a) was clearly classified as Table 4 Defect patterns of the proposed taxonomy with representative images. Feasible combinations of dimension levels Review results Image Shape Size Location Scratch Long Edge Merged to Scratch ‚ÄìLong ‚ÄìAll Center Others Short Edge Merged to Scratch ‚ÄìShort ‚ÄìAll Center Others Cluster Big Edge Cluster ‚ÄìBig‚ÄìEdge Others Cluster ‚ÄìBig‚ÄìOthers Center Merged to Cluster ‚ÄìAll‚ÄìCenter Small Center Edge Cluster ‚ÄìSmall ‚ÄìEdge Others Cluster ‚ÄìSmall ‚ÄìOthers Ring One-quarter Half Three-quarters Whole Edge Merged to Ring ‚ÄìAll‚ÄìEdge Center Removed Others Removed Random Frequent Scattered Random ‚ÄìFrequent ‚ÄìScattered Infrequent Scattered Random ‚ÄìInfrequent ‚ÄìSca"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_30", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 30, "text": "ing One-quarter Half Three-quarters Whole Edge Merged to Ring ‚ÄìAll‚ÄìEdge Center Removed Others Removed Random Frequent Scattered Random ‚ÄìFrequent ‚ÄìScattered Infrequent Scattered Random ‚ÄìInfrequent ‚ÄìScattered Table 5 Inter ‚Äìrater agreement results. Taxonomy Proposed WM811K Proportion agreement 79.8 % 65.3 % Kappa 0.713 0.530 S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 6Ring ‚ÄìAll‚ÄìEdge in the proposed taxonomy. However, the Size dimension was not considered in the WM811K taxonomy; thus, the ring-shaped pattern with an angle less than 180‚Ä¢is undetermined in the WM811K taxonomy. Fig. 4-(b) was clearly classified as Scratch ‚ÄìShort ‚ÄìAll in the proposed taxonomy, whereas it was not clearly defined in the WM811K taxonomy because the Size dimension of the Line pattern is not consid - ered in the WM811K taxonomy. 4.2. Demonstration of the extendibility This section demonstrates the extendibility of the proposed taxon - omy. The taxonomy developed in Section 3 had been used in an auto- matic defect pattern classification system since 2020. A new technology for wafer fabrication was adopted in 2021, and new defect patterns emerged since then. The defect pattern classifica"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_31", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 31, "text": "in an auto- matic defect pattern classification system since 2020. A new technology for wafer fabrication was adopted in 2021, and new defect patterns emerged since then. The defect pattern classification system cannot classify the newly-emerged patterns. Thus, the proposed taxonomy was extended to accommodate them. Two types of new defect patterns were derived from the unclassified WBMs. Fig. 5 illustrates the Type 1 defect pattern. The spatial features of Type 1 were identified in accordance with the three dimensions and compared with the existing dimension levels. The spatial features of Type 1 were mapped to existing dimension levels: Ring for Shape , Three- quarters for Size, and Others for the Location dimension. The combination of the three levels had been removed in the second stage of the devel - opment procedure. However, the Ring ‚ÄìThree-quarters ‚ÄìOthers pattern was added, given that a new defect pattern occurred. Fig. 6 illustrates the Type 2 defect pattern. The spatial features of Type 2 were also identified and organized into three spatial dimensions. The dimension level of Location was defined as the existing level Center , and a new dimension level, namely, Double-cl"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_32", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 32, "text": "ures of Type 2 were also identified and organized into three spatial dimensions. The dimension level of Location was defined as the existing level Center , and a new dimension level, namely, Double-cluster , for the Shape dimension was defined. Given that the Size variation of Double-cluster was undetected in the dataset, a single level of All was defined in Size. Combining the dimension levels, the Double-cluster ‚ÄìAll‚ÄìCenter pattern was added. Double-cluster was consequently added in the Shape dimension, and two defect patterns were added to the existing taxonomy. Newly- observed spatial features were identified and added to the dimension levels; thus, the extendibility of the proposed taxonomy was realized. 4.3. Assessment of the classification coherence The coherence of manual classification was assessed using the clas- sification models in this section. The coherence in this section is focused on long-term repeatability. The performance of the classification model is better in the reliable training dataset [60], so the classification per- formance was presumed to indicate the coherence of the manually classified WBM dataset. The dataset obtained after reconciliation in Section "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_33", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 33, "text": "reliable training dataset [60], so the classification per- formance was presumed to indicate the coherence of the manually classified WBM dataset. The dataset obtained after reconciliation in Section 4.1 was used in this section. The WBM dataset was preprocessed using simple pre- processing. Several studies denoised a WBM dataset to remove defects Fig. 3.Examples of ambiguous WBM images. Table 6 Manual classification results for the WBM dataset. Proposed taxonomy WM811K taxonomy Defect pattern Original Remain Defect pattern Original Remain Cluster ‚ÄìSmall ‚ÄìEdge 1417 1417 None 1272 1264 Ring ‚ÄìAll‚ÄìEdge 579 578 Edge-Ring 701 690 Random ‚ÄìInfrequent ‚ÄìScattered 569 559 Edge-Loc 615 578 Scratch ‚ÄìShort ‚ÄìAll 266 266 Scratch 365 363 Cluster ‚ÄìSmall ‚ÄìOthers 118 118 Location 175 163 Scratch ‚ÄìLong ‚ÄìAll 103 102 Center 58 57 Cluster ‚ÄìAll‚ÄìCenter 77 75 Random 23 \u0000 Cluster ‚ÄìBig‚ÄìEdge 45 \u0000 Donut 0 \u0000 Random ‚ÄìFrequent ‚ÄìScattered 22 \u0000 Near-Full 0 \u0000 Cluster ‚ÄìBig‚ÄìOthers 13 \u0000 Total 3209 3115 3209 3115 Fig. 4.Examples of WBM images undefined in the WM811K taxonomy. Fig. 5.Newly-added defect pattern (Type 1). Fig. 6.Newly-added defect pattern (Type 2). S.-H. Choi et al. Advanced Engineering Informatics 60 (2024"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_34", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 34, "text": "ples of WBM images undefined in the WM811K taxonomy. Fig. 5.Newly-added defect pattern (Type 1). Fig. 6.Newly-added defect pattern (Type 2). S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 7lacking spatial correlations [12,33,56,61] . However, denoising was not used in this study, as the two taxonomies define defect patterns for WBMs lacking spatial correlation among defects. For each wafer matrix, each chip was assigned 0 for the non-wafer area, 0.5 for functional chips, and 1 for defective chips, and zero padding was not used. A convolutional neural network (CNN) [62] was utilized for the classification model in the experiments. The CNN model has an advan - tage over other alternative feature extraction-based methods in that it directly extracts the spatial features of defect patterns from WBM images [13]. Thus, the classification performance of different taxonomies can be clearly compared using the CNN model. However, the classification performance is affected by feature extraction methods as well as tax- onomy using the feature extraction-based models [50,54] . For instance, rotational invariant moment-based features are effective when defect patterns are de"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_35", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 35, "text": " feature extraction methods as well as tax- onomy using the feature extraction-based models [50,54] . For instance, rotational invariant moment-based features are effective when defect patterns are defined regardless of the rotational differences [45,50] . The CNN model is widely used in the defect pattern classification using the WM811K taxonomy, and many comparative studies revealed that the classification performance of the CNN model is superior to that of other models [2,14,55] . We referred to the traditional CNN architecture used in the WBM classification study because the input size of WBM was smaller than the commonly used image dataset [2,55] . However, a simpler architecture was used because the WBM size was smaller in our dataset. The CNN architecture used in this study is depicted in Fig. 7. Two convolutional layers and two fully-connected layers (‚ÄúConv ‚Äù and ‚ÄúFC‚Äù in Fig. 7, respectively) constituted the CNN architecture. Each convolutional layer used a 3 √ó3 convolution operation with a stride size of 1 √ó1, and four convolution filters were present. In the second convolutional layer, 2 √ó2 max-pooling with a stride size of 2 was conducted. The number of nodes in the firs"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_36", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 36, "text": "ration with a stride size of 1 √ó1, and four convolution filters were present. In the second convolutional layer, 2 √ó2 max-pooling with a stride size of 2 was conducted. The number of nodes in the first and second fully connected layers was 512. The number of output nodes was set to be the number of defect patterns in a taxonomy. Finally, each WBM was classified into the defect pattern with the highest node value. The rectified linear unit was used as an activation function from the first convolutional layer to the second fully connected layer, and the SoftMax function was used for output nodes. For training the model, categorical cross entropy was used for loss function, batch normalization was used with the batch size of 100, and an Adam [63] optimizer was used with a learning rate of 0.001. Defect patterns with less than 50 WBMs were removed from the dataset because the classification model hardly extracts spatial features from defect patterns with such small sample sizes. Three defect patterns from the proposed taxonomy and one defect pattern from the WM811K taxonomy were consequently removed from the dataset. The WBMs that were removed from one taxonomy were also removed from t"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_37", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 37, "text": "ct patterns from the proposed taxonomy and one defect pattern from the WM811K taxonomy were consequently removed from the dataset. The WBMs that were removed from one taxonomy were also removed from the other taxonomy. For instance, the number of WBMs in Location was also decreased by the removal of Cluster ‚ÄìBig‚ÄìOthers . As a result, 3115 WBMs from 3209 remained and were used for the experiment. The column of ‚ÄúRemain ‚Äù in Table 6 presents the numbers of WBMs after the removal of the defect patterns with small sample sizes. The remaining dataset was randomly divided into training and validation datasets in a ratio of 8:2. The CNN model weight with the best accuracy on the validation set was then stored until 50 epochs. The maximum epoch was set according to the overfitting problem in pre- liminary experiments. The validation loss increased rapidly after around 10 epochs in both taxonomies (Fig. 8). For the stored CNN model weights, the accuracy, precision, recall, and F-score of all defect patterns were examined. Macro-averaging of each metric was conducted in evaluating the performance of a classifi - cation model in consideration of the data imbalance. Macro-averaging calculates t"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_38", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 38, "text": "ect patterns were examined. Macro-averaging of each metric was conducted in evaluating the performance of a classifi - cation model in consideration of the data imbalance. Macro-averaging calculates the average of a metric of defect patterns in a taxonomy, and all defect patterns have identical weights, regardless of sample size [64]. Table 7 provides the formulas of the metrics, where l stands for the number of defect patterns in a taxonomy; i denotes the index of the defect pattern; tpi, tni, fpi, and fni are the true positive, true negative, false positive, and false negative counts for the defect pattern i, respectively. The M index represents the macro-averaging. The experiment was iterated 100 times, and the experimental results showed that the manual classification was more coherent in the pro- posed taxonomy than in the WM811K counterpart. Fig. 9 presents the box plots of the performance metrics. The box extended from Q1 to Q3 quartile values, and the whisker position was 1.5 interquartile range from the box edge. The median values of the average accuracy, macro- recall, and macro-F-score were higher in the proposed taxonomy. The median value of macro-precision was higher i"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_39", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 39, "text": "nterquartile range from the box edge. The median values of the average accuracy, macro- recall, and macro-F-score were higher in the proposed taxonomy. The median value of macro-precision was higher in the WM811K taxonomy, but more outliers exist than in the proposed taxonomy, which indicates that the classification performance was inconsistent during the iterated experiments. Table 8 presents the result of Welch ‚Äôs t-test for checking if the mean values of the metrics in 100 iterations from the two taxon - omies were similar. The average accuracy, macro-recall, and macro-F- score were significantly greater in the proposed taxonomy. The low recall of the WM811K taxonomy is attributed to low recalls of Location and Center patterns. Table 9 shows the average value of recall by each pattern for 100 iterated experiments, and Location and Center shows the extremely smaller recall than those of others. Table 10 pre- sents the classified result for 100 iterated experiments of WBMs with Location and Center patterns. WBMs with Location and Center patterns were frequently classified as Edge-Loc , which results in low recall of Location and Center patterns. This result indicates that the diff"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_40", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 40, "text": "on and Center patterns. WBMs with Location and Center patterns were frequently classified as Edge-Loc , which results in low recall of Location and Center patterns. This result indicates that the differentiation criteria between Center , Edge-Loc , and Location patterns were untrained in the classification model based on the WM811K taxonomy. The result is consistent with the qualitative assessment (Section 4.1) result, in which the inconsistent manual classification arose due to the unclear differentiation criteria of the locational information in the WM811K taxonomy. 4.4. Discussion on expected benefits This section discusses the expected benefits of the proposed ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ Fig. 7.CNN architecture. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 8taxonomy within practical applications based on the experimental findings presented in Sections 4.1 through Sections 4.3. Firstly, the ac- curacy of manual defect pattern classification can be improved by using the proposed taxonomy. As discussed in Section 4.1, employing the proposed taxonomy led to an improvement in inter-rater agreement during manual classification. Given that higher inter-rater agreement is indicative"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_41", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 41, "text": "axonomy. As discussed in Section 4.1, employing the proposed taxonomy led to an improvement in inter-rater agreement during manual classification. Given that higher inter-rater agreement is indicative of a more trustful ground truth [65], manual classification using the proposed taxonomy is considered more accurate than that using WM811K. Moreover, the proposed taxonomy facilitated the identification of more WBMs exhibiting spatial correlation among de- fects compared to WM811K. Accurate classification holds significant importance for root cause diagnosis in wafer fabrication [7‚Äì10] since the diagnostic performance relies on accurately classified WBM datasets. Secondly, the proposed taxonomy can enhance the accuracy of automatic defect pattern classification. Without the need for model enhancements or additional WBM data collection, the automatic clas- sification model demonstrated better accuracy when using the proposed taxonomy compared to WM811K (Section 4.3). This improvement can be attributed to the more cohesive classification of the WBM dataset used for model training with the proposed taxonomy. The increased accuracy in automatic defect pattern classification is advantageou"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_42", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 42, "text": "e attributed to the more cohesive classification of the WBM dataset used for model training with the proposed taxonomy. The increased accuracy in automatic defect pattern classification is advantageous as it aids practitioners in diagnosing the root causes of non-random defects. Lastly, the proposed taxonomy is extendable, allowing for the Fig. 8.Model loss function in the preliminary experiment. Table 7 Performance metrics for defect pattern classification models. Measure Formula Average accuracy ‚ãÉl i¬à1tpi¬átni tpi¬átni¬áfpi¬áfni l Precision M ‚ãÉl i¬à1tpi tpi¬áfpi l Recall M ‚ãÉl i¬à1tpi tpi¬áfni l Fscore M Precision MRecall M Precision M¬áRecall M Fig. 9.Box plot of the experimental results. Table 8 Summary of the experimental results. Metric Mean Welch ‚Äôs test p-value Proposed WM811K Average accuracy 0.894 0.865 D0.001 Macro-precision 0.551 0.557 0.556 Macro-recall 0.487 0.336 D0.001 Macro-F-score 0.516 0.417 D0.001 Table 9 Average recall of experiments. Proposed Average Recall WM811K Average Recall Cluster ‚ÄìSmall ‚ÄìEdge 0.785 None 0.901 Cluster ‚ÄìAll‚ÄìCenter 0.760 Edge-Ring 0.726 Ring ‚ÄìAll‚ÄìEdge 0.681 Edge-Loc 0.343 Random ‚ÄìInfrequent ‚ÄìScattered 0.562 Scratch 0.036 Scratch ‚ÄìLong ‚ÄìAll 0.344 Cen"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_43", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 43, "text": "ecall Cluster ‚ÄìSmall ‚ÄìEdge 0.785 None 0.901 Cluster ‚ÄìAll‚ÄìCenter 0.760 Edge-Ring 0.726 Ring ‚ÄìAll‚ÄìEdge 0.681 Edge-Loc 0.343 Random ‚ÄìInfrequent ‚ÄìScattered 0.562 Scratch 0.036 Scratch ‚ÄìLong ‚ÄìAll 0.344 Center 0.005 Cluster ‚ÄìSmall ‚ÄìOthers 0.173 Location 0.004 Scratch ‚ÄìShort ‚ÄìAll 0.105 Table 10 Cumulated classification result of Center and Location. Prediction Actual Center Location Center 6 0 Location 5 13 S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 9addition of new defect patterns to accommodate emerging patterns (Section 4.2). This extendibility is attributed to the flexibility provided by the spatial dimension-based structure of the proposed taxonomy. This characteristic enables practitioners to continually utilize the proposed taxonomy with some modifications in response to newly emerging patterns, such as those arising from technological advancements. 5.Conclusion The concept of spatial dimension-based defect pattern taxonomy and its development procedure are proposed. The concept was applied to a NAND flash memory semiconductor manufacturer for two years. Results indicate that the proposed taxonomy possesses the three desirable properties of a general taxono"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_44", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 44, "text": "posed. The concept was applied to a NAND flash memory semiconductor manufacturer for two years. Results indicate that the proposed taxonomy possesses the three desirable properties of a general taxonomy (i.e., robustness, comprehensiveness, and extendibility). Also, the domain expertise is integrated through the engineers‚Äô involvement in the proposed taxonomy development procedure. The main contribution of this study is the development of a taxon - omy possessing the three desirable properties through a spatial dimension-based structure. This structure effectively addresses limita - tions found in existing taxonomies, resulting in improved robustness, comprehensiveness, and extendibility. The managerial implications of this study are twofold. Firstly, the classification accuracy of the defect pattern classification system would be improved. The proposed taxonomy possesses robustness and comprehensiveness, allowing for the coherent classification of the WBM dataset. Consequently, this coherently classified dataset contributes to improved accuracy in the defect pattern classification system. Secondly, the proposed taxonomy is considered practical for wafer fabrication diagnostics bec"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_45", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 45, "text": "oherently classified dataset contributes to improved accuracy in the defect pattern classification system. Secondly, the proposed taxonomy is considered practical for wafer fabrication diagnostics because it has integrated domain expertise in its develop - ment procedure. It encompasses a concise set of defect patterns that are meaningful for diagnosing wafer fabrication failures, thus making the classified results more applicable for diagnostics. These managerial implications remain valid for newly-emerged defect patterns due to the extendibility of the proposed taxonomy. Three issues for future research are suggested. The first issue resides in the lack of case studies that validate the general applicability of the concept of spatial dimension-based taxonomy. The desirable properties were demonstrated for one wafer fabrication process in this study. Case studies on other manufacturing circumstances should be conducted in future research to validate the general applicability of the concept and development procedure. The second issue resides in the extension of dimensions. The mixed-type defect patterns occur when several defect patterns appear simultaneously in a wafer. Mixed-type"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_46", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 46, "text": "ncept and development procedure. The second issue resides in the extension of dimensions. The mixed-type defect patterns occur when several defect patterns appear simultaneously in a wafer. Mixed-type defect patterns frequently occur due to new technology adoption [5,15]. To classify mixed-type defect patterns, dimensions should be extended. The number [48], overlap [66], and homogeneity [67] of defect patterns may be added to the dimension. The third issue resides in improving the tax- onomy development procedure to be more intelligent. The active learning framework can be adopted to make the engineers‚Äô involvement efficient. For instance, inspection of clustered defects [68] can reduce the number of WBMs to be inspected in Stage 1 of the taxonomy development procedure. Manual identification of the newly-emerged defect patterns can be replaced by the classification uncertainty anal- ysis [53] for prompt extension of the existing taxonomy. CRediT authorship contribution statement Seung-Hyun Choi: Writing ‚Äì original draft, Validation, Methodol - ogy, Conceptualization. Dong-Hee Lee: Writing ‚Äì review & editing, Methodology. Eun-Su Kim: Methodology. Young-Mok Bae: Funding acquisition,"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_47", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 47, "text": "-Hyun Choi: Writing ‚Äì original draft, Validation, Methodol - ogy, Conceptualization. Dong-Hee Lee: Writing ‚Äì review & editing, Methodology. Eun-Su Kim: Methodology. Young-Mok Bae: Funding acquisition, Data curation. Young-Chan Oh: Funding acquisition, Data curation. Kwang-Jae Kim: Writing ‚Äì review & editing, Supervision. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability The data that has been used is confidential. Acknowledgment This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) [NRF- 2019R1A2C1007834] and by SK hynix Inc. References [1]S. Park, J. Jang, C.O. Kim, Discriminative feature learning and cluster-based defect label reconstruction for reducing uncertainty in wafer bin map labels, J. Intell. Manuf 32 (2021) 251‚Äì263, https://doi.org/10.1007/s10845-020-01571-4. [2]J.-H. Kim, H.-S. Kim, J.-S. Park, K.-H. Mo, P.-S. Kang, Bin2Vec: a better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer classification, "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_48", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 48, "text": "s10845-020-01571-4. [2]J.-H. Kim, H.-S. Kim, J.-S. Park, K.-H. Mo, P.-S. Kang, Bin2Vec: a better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer classification, Appl. Sci. (Switzerland) 9 (2019) 597, https://doi.org/10.3390/ app9030597. [3]T.-S. Li, C.-L. Huang, Defect spatial pattern recognition using a hybrid SOM‚ÄìSVM approach in semiconductor manufacturing, Expert. Syst. Appl 36 (2009) 374‚Äì385, https://doi.org/10.1016/j.eswa.2007.09.023. [4]S.P. Cunningham, S. MacKinnon, Statistical methods for visual defect metrology, IEEE. Trans. Semicond. Manuf. 11 (1998) 48‚Äì53, https://doi.org/10.1109/ 66.661284. [5]K. Kyeong, H. Kim, Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks, IEEE. Trans. Semicond. Manuf. 31 (2018) 395‚Äì402, https://doi.org/10.1109/TSM.2018.2841416. [6]W. Taam, M. Hamada, Detecting spatial effects from factorial experiments: an application from integrated-circuit manufacturing, Technometrics 35 (1993) 149‚Äì160, https://doi.org/10.1080/00401706.1993.10485037. [7]K. Radigan, B. Sheumaker, N. Heller, Using full wafer defect maps as process signatures to monitor and control yield, in: P"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_49", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 49, "text": "etrics 35 (1993) 149‚Äì160, https://doi.org/10.1080/00401706.1993.10485037. [7]K. Radigan, B. Sheumaker, N. Heller, Using full wafer defect maps as process signatures to monitor and control yield, in: Proceedings IEEE/SEMI international semiconductor Manufacturing science symposium, IEEE, 1991, pp. 129‚Äì135, https://doi.org/10.1109/ISMSS.1991.146281. [8]M.H. Hansen, V.N. Nair, D.J. Friedmand, D. Friedman, Process improvement through the analysis of spatially clustered defects on wafer maps, 1999. [9]K. Nakata, R. Orihara, Y. Mizuoka, K. Takagi, A comprehensive big-data-based monitoring system for yield enhancement in semiconductor manufacturing, IEEE. Trans. Semicond. Manuf. 30 (2017) 339‚Äì344, https://doi.org/10.1109/ TSM.2017.2753251. [10] K. Taha, CDID: a system for identifying the root cause of a defect in semiconductor wafer fabrication, IEEE. Trans. Semicond. Manuf. 31 (2018) 221‚Äì231, https://doi. org/10.1109/TSM.2018.2808703. [11] A. Drozda-Freeman, M. McIntyre, M. Retersdorf, C. Wooten, X. Song, A. Hesse, The Application and Use of an Automated Spatial Pattern Recognition (SPR) System in the Identification and Solving of Yield Issues in Semiconductor Manufacturing, in: Intergov"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_50", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 50, "text": "oten, X. Song, A. Hesse, The Application and Use of an Automated Spatial Pattern Recognition (SPR) System in the Identification and Solving of Yield Issues in Semiconductor Manufacturing, in: Intergovernmental Panel on Climate Change (Ed.), 2007 IEEE/SEMI Advanced Semiconductor Manufacturing Conference, IEEE, Cambridge, 2007: pp. 302‚Äì305, https://doi.org/10.1109/ASMC.2007.375121. [12] Y. Kong, D. Ni, Semi-supervised classification of wafer map based on ladder network, in: IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT), 2018, pp. 1‚Äì4, https://doi.org/10.1109/ ICSICT.2018.8564982. [13] T. Nakazawa, D.V. Kulkarni, Anomaly detection and segmentation for wafer defect patterns using deep convolutional encoder‚Äìdecoder neural network architectures in semiconductor Manufacturing, IEEE. Trans. Semicond. Manuf. 32 (2019) 250‚Äì256, https://doi.org/10.1109/TSM.2019.2897690. [14] C.Y. Hsu, J.C. Chien, Ensemble convolutional neural networks with weighted majority for wafer bin map pattern classification, J. Intell. Manuf 33 (2022) 831‚Äì844, https://doi.org/10.1007/s10845-020-01687-7. [15] T.S. Kim, J.W. Lee, W.K. Lee, S.Y. Sohn, Novel method for detection of"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_51", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 51, "text": "ty for wafer bin map pattern classification, J. Intell. Manuf 33 (2022) 831‚Äì844, https://doi.org/10.1007/s10845-020-01687-7. [15] T.S. Kim, J.W. Lee, W.K. Lee, S.Y. Sohn, Novel method for detection of mixed-type defect patterns in wafer maps based on a single shot detector algorithm, J. Intell. Manuf (2021), https://doi.org/10.1007/s10845-021-01755-6. [16] C.H. Jin, H.J. Kim, Y. Piao, M. Li, M. Piao, Wafer map defect pattern classification based on convolutional neural network features and error-correcting output codes, J. Intell. Manuf 31 (2020) 1861‚Äì1875, https://doi.org/10.1007/s10845-020- 01540-x. [17] D.F. Nettleton, A. Orriols-Puig, A. Fornells, A study of the effect of different types of noise on the precision of supervised learning techniques, Artif. Intell. Rev 33 (2010) 275‚Äì306, https://doi.org/10.1007/s10462-010-9156-z. [18] N. Omri, Z. Al Masry, N. Mairot, S. Giampiccolo, N. Zerhouni, Industrial data management strategy towards an SME-oriented PHM, J. Manuf. Syst 56 (2020) 23‚Äì36, https://doi.org/10.1016/j.jmsy.2020.04.002. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 10[19] P. Wang, M. Luo, A digital twin-based big data virtual and real fusion lea"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_52", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 52, "text": "23‚Äì36, https://doi.org/10.1016/j.jmsy.2020.04.002. S.-H. Choi et al. Advanced Engineering Informatics 60 (2024) 102540 10[19] P. Wang, M. Luo, A digital twin-based big data virtual and real fusion learning reference framework supported by industrial internet towards smart manufacturing, J. Manuf. Syst 58 (2021) 16‚Äì32, https://doi.org/10.1016/j. jmsy.2020.11.012 . [20] M.J. Wu, J.S. Jang, J.L. Chen, Wafer map failure pattern recognition and similarity ranking for large-scale data sets, IEEE. Trans. Semicond. Manuf. 28 (2015) 1‚Äì12, https://doi.org/10.1109/TSM.2014.2364237 . [21] Y. Wang, D. Ni, A deep learning analysis framework for complex wafer bin map classification, IEEE. Trans. Semicond. Manuf. 36 (2023) 367‚Äì377, https://doi.org/ 10.1109/TSM.2023.3269230 . [22] K.S.M. Li, N.C.Y. Tsai, K.C.C. Cheng, X.H. Jiang, P.Y.Y. Liao, S.J. Wang, A.Y. A. Huang, L. Chou, C.S. Lee, TestDNA: novel wafer defect signature for diagnosis and pattern recognition, IEEE. Trans. Semicond. Manuf. 33 (2020) 383‚Äì390, https://doi.org/10.1109/TSM.2020.2992927 . [23] Y. Wang, D. Ni, Multi-bin wafer maps defect patterns classification, Proceedings - 2019 IEEE International Conference on Smart Manufacturing, I"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_53", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 53, "text": "383‚Äì390, https://doi.org/10.1109/TSM.2020.2992927 . [23] Y. Wang, D. Ni, Multi-bin wafer maps defect patterns classification, Proceedings - 2019 IEEE International Conference on Smart Manufacturing, Industrial and Logistics Engineering, SMILE 2019 (2019) 48‚Äì52, https://doi.org/10.1109/SMIL E45626.2019.8965299 . [24] C.Y. Hsu, W.J. Chen, J.C. Chien, Similarity matching of wafer bin maps for manufacturing intelligence to empower industry 3.5 for semiconductor manufacturing, Comput. Ind. Eng 142 (2020) 106358, https://doi.org/10.1016/j. cie.2020.106358 . [25] C.-W.-W. Liu, C.-F.-F. Chien, An intelligent system for wafer bin map defect diagnosis: an empirical study for semiconductor manufacturing, Eng. Appl. Artif. Intell 26 (2013) 1479 ‚Äì1486, https://doi.org/10.1016/j.engappai.2012.11.009 . [26] R.C. Nickerson, U. Varshney, J. Muntermann, A method for taxonomy development and its application in information systems, Eur. J. Inf. Syst. 22 (2013) 336‚Äì359, https://doi.org/10.1057/ejis.2012.26 . [27] J. Jang, G.T. Lee, Decision fusion approach for detecting unknown wafer bin map patterns based on a deep multitask learning model, Expert. Syst. Appl 215 (2023) 119363, https://doi.org/10.1016"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_54", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 54, "text": " . [27] J. Jang, G.T. Lee, Decision fusion approach for detecting unknown wafer bin map patterns based on a deep multitask learning model, Expert. Syst. Appl 215 (2023) 119363, https://doi.org/10.1016/j.eswa.2022.119363 . [28] M.O. Gokalp, E. Gokalp, K. Kayabay, A. Ko√ßyi Àögit, P.E. Eren, Data-driven manufacturing: an assessment model for data science maturity, J. Manuf. Syst 60 (2021) 527‚Äì546, https://doi.org/10.1016/j.jmsy.2021.07.011 . [29] C.-H. Wang, W. Kuo, H. Bensmail, Detection and classification of defect patterns on semiconductor wafers, IIE. Trans. 38 (2006) 1059 ‚Äì1068, https://doi.org/10.1080/ 07408170600733236 . [30] H.-W. Hsieh, F.-L. Chen, Recognition of defect spatial patterns in semiconductor fabrication, Int. J. Prod. Res 42 (2004) 4153 ‚Äì4172, https://doi.org/10.1080/ 00207540410001716507 . [31] J.Y. Hwang, W. Kuo, Model-based clustering for integrated circuit yield enhancement, Eur. J. Oper. Res 178 (2007) 143‚Äì153, https://doi.org/10.1016/j. ejor.2005.11.032 . [32] T. Yuan, W. Kuo, A model-based clustering approach to the recognition of the spatial defect patterns produced during semiconductor fabrication, IIE. Trans. 40 (2007) 93‚Äì101, https://doi.org/10.1080/07"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_55", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 55, "text": "T. Yuan, W. Kuo, A model-based clustering approach to the recognition of the spatial defect patterns produced during semiconductor fabrication, IIE. Trans. 40 (2007) 93‚Äì101, https://doi.org/10.1080/07408170701592556 . [33] C.-H. Wang, Separation of composite defect patterns on wafer bin map using support vector clustering, Expert. Syst. Appl 36 (2009) 2554 ‚Äì2561, https://doi. org/10.1016/j.eswa.2008.01.057 . [34] Q. Zhou, L. Zeng, S. Zhou, Statistical detection of defect patterns using Hough transform, IEEE. Trans. Semicond. Manuf. 23 (2010) 370‚Äì380, https://doi.org/ 10.1109/TSM.2010.2048959 . [35] T. Yuan, W. Kuo, S.J. Bae, Detection of spatial defect patterns generated in semiconductor fabrication processes, IEEE. Trans. Semicond. Manuf. 24 (2011) 392‚Äì403, https://doi.org/10.1109/TSM.2011.2154870 . [36] G.-H. Choi, S.-H. Kim, C.-H. Ha, S.-J. Bae, Multi-step ART1 algorithm for recognition of defect patterns on semiconductor wafers, Int. J. Prod. Res 50 (2012) 3274 ‚Äì3287, https://doi.org/10.1080/00207543.2011.574502 . [37] K. Maksim, B. Kirill, Z. Eduard, G. Nikita, B. Aleksandr, L. Arina, S. Vladislav, M. Daniil, K. Nikolay, Classification of wafer maps defect based on deep learni"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_56", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 56, "text": "rg/10.1080/00207543.2011.574502 . [37] K. Maksim, B. Kirill, Z. Eduard, G. Nikita, B. Aleksandr, L. Arina, S. Vladislav, M. Daniil, K. Nikolay, Classification of wafer maps defect based on deep learning methods with small amount of data, in: 2019 International Conference on Engineering and Telecommunication (EnT)IEEE, 2019, pp. 1‚Äì5, https://doi.org/ 10.1109/EnT47717.2019.9030550 . [38] F.-L. Chen, S.-F. Liu, A neural-network approach to recognize defect spatial pattern in semiconductor fabrication, IEEE. Trans. Semicond. Manuf. 13 (2000) 366‚Äì373, https://doi.org/10.1109/66.857947 . [39] S.J. Bae, J.Y. Hwang, W. Kuo, Yield prediction via spatial modeling of clustered defect counts across a wafer map, IIE. Trans. 39 (2007) 1073 ‚Äì1083, https://doi. org/10.1080/07408170701275335 . [40] M. Liukkonen, Y. Hiltunen, Recognition of systematic spatial patterns in silicon wafers based on SOM and K-means, IFAC-PapersOnLine 51 (2018) 439‚Äì444, https://doi.org/10.1016/j.ifacol.2018.03.075 . [41] F. Di Palma, G. De Nicolao, G. Miraglia, E. Pasquinetti, F. Piccinini, Unsupervised spatial pattern classification of electrical-wafer-sorting maps in semiconductor manufacturing, Pattern. Recognit. Lett "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_57", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 57, "text": "i Palma, G. De Nicolao, G. Miraglia, E. Pasquinetti, F. Piccinini, Unsupervised spatial pattern classification of electrical-wafer-sorting maps in semiconductor manufacturing, Pattern. Recognit. Lett 26 (2005) 1857 ‚Äì1865, https://doi.org/ 10.1016/j.patrec.2005.03.007 . [42] C.-H. Wang, S.-J. Wang, W.-D. Lee, Automatic identification of spatial defect patterns for semiconductor manufacturing, Int. J. Prod. Res 44 (2006) 5169 ‚Äì5185, https://doi.org/10.1080/02772240600610822 . [43] S.-C. Hsu, C.-F. Chien, Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing, Int. J. Prod. Econ 107 (2007) 88‚Äì103, https://doi.org/10.1016/j.ijpe.2006.05.015 . [44] L.-C. Chao, L.-I. Tong, Wafer defect pattern recognition by multi-class support vector machines by using a novel defect cluster index, Expert. Syst. Appl 36 (2009) 10158 ‚Äì10167, https://doi.org/10.1016/j.eswa.2009.01.003 . [45] M.-P.-L. Ooi, H.-K. Sok, Y.-C. Kuang, S. Demidenko, C. Chan, Defect cluster recognition system for fabricated semiconductor wafers, Eng. Appl. Artif. Intell 26 (2013) 1029 ‚Äì1043, https://doi.org/10.1016/j.engappai.2012.03.016 . [46] C.-S. Liao, T.-J. Hsieh,"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_58", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 58, "text": "an, Defect cluster recognition system for fabricated semiconductor wafers, Eng. Appl. Artif. Intell 26 (2013) 1029 ‚Äì1043, https://doi.org/10.1016/j.engappai.2012.03.016 . [46] C.-S. Liao, T.-J. Hsieh, Y.-S. Huang, C.-F. Chien, Similarity searching for defective wafer bin maps in semiconductor manufacturing, IEEE. Trans. Autom. Sci. Eng. 11 (2014) 953‚Äì960, https://doi.org/10.1109/TASE.2013.2277603 . [47] G. Tello, O.Y. Al-Jarrah, P.D. Yoo, Y. Al-Hammadi, S. Muhaidat, U. Lee, Deep- structured machine learning model for the recognition of mixed-defect patterns in semiconductor fabrication processes, IEEE. Trans. Semicond. Manuf. 31 (2018) 315‚Äì322, https://doi.org/10.1109/TSM.2018.2825482 . [48] C.-F. Chien, S.-C. Hsu, Y.-J. Chen, A system for online detection and classification of wafer bin map defect patterns for manufacturing intelligence, Int. J. Prod. Res 51 (2013) 2324 ‚Äì2338, https://doi.org/10.1080/00207543.2012.737943 . [49] M.-P.-L. Ooi, E.K.J. Joo, Y.C. Kuang, S. Demidenko, L. Kleeman, C.W.K. Chan, Getting more from the semiconductor test: data mining with defect-cluster extraction, IEEE. Trans. Instrum. Meas 60 (2011) 3300 ‚Äì3317, https://doi.org/ 10.1109/TIM.2011.2122430 . ["}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_59", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 59, "text": "eeman, C.W.K. Chan, Getting more from the semiconductor test: data mining with defect-cluster extraction, IEEE. Trans. Instrum. Meas 60 (2011) 3300 ‚Äì3317, https://doi.org/ 10.1109/TIM.2011.2122430 . [50] J.W. Cheng, M.P.-L. Ooi, C. Chan, Y.C. Kuang, S. Demidenko, Evaluating the Performance of Different Classification Algorithms for Fabricated Semiconductor Wafers, in: 2010 Fifth IEEE International Symposium on Electronic Design, Test & ApplicationsIEEE, 2010, pp. 360‚Äì366, https://doi.org/10.1109/DELTA.2010.69 . [51] N.G. Shankar, Z.W. Zhong, Defect detection on semiconductor wafer surfaces, Microelectron. Eng 77 (2005) 337‚Äì346, https://doi.org/10.1016/j. mee.2004.12.003 . [52] A.I. Mirza, G. O‚ÄôDonoghue, A.W. Drake, S.C. Graves, Spatial yield modeling for semiconductor wafers, in: Proceedings of SEMI Advanced Semiconductor Manufacturing Conference and WorkshopIEEE, 1995, pp. 276‚Äì281, https://doi. org/10.1109/ASMC.1995.484386 . [53] J. Shim, S. Kang, S. Cho, Active learning of convolutional neural network for cost- effective wafer map pattern classification, IEEE. Trans. Semicond. Manuf. 33 (2020) 258‚Äì266, https://doi.org/10.1109/TSM.2020.2974867 . [54] M. Saqlain, B. Jargalsaikhan, "}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_60", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 60, "text": "nal neural network for cost- effective wafer map pattern classification, IEEE. Trans. Semicond. Manuf. 33 (2020) 258‚Äì266, https://doi.org/10.1109/TSM.2020.2974867 . [54] M. Saqlain, B. Jargalsaikhan, J.Y. Lee, A voting ensemble classifier for wafer map defect patterns identification in semiconductor manufacturing, IEEE. Trans. Semicond. Manuf. 32 (2019) 171‚Äì182, https://doi.org/10.1109/ TSM.2019.2904306 . [55] R. di Bella, D. Carrera, B. Rossi, P. Fragneto, G. Boracchi, Wafer defect map classification using Sparse convolutional networks, in: International Conference on Image Analysis and Processing, Springer International Publishing, 2019, pp. 125‚Äì136, https://doi.org/10.1007/978-3-030-30645-8_12 . [56] M. Piao, C.H. Jin, J.Y. Lee, J.-Y. Byun, Decision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features, IEEE. Trans. Semicond. Manuf. 31 (2018) 250‚Äì257, https://doi.org/10.1109/ TSM.2018.2806931 . [57] J. Yu, X. Zheng, J. Liu, Stacked convolutional sparse denoising auto-encoder for identification of defect patterns in semiconductor wafer map, Comput. Ind 109 (2019) 121‚Äì133, https://doi.org/10.1016/j.compind.2019.04.015 . [58] U. Batool, M"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_61", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 61, "text": "tional sparse denoising auto-encoder for identification of defect patterns in semiconductor wafer map, Comput. Ind 109 (2019) 121‚Äì133, https://doi.org/10.1016/j.compind.2019.04.015 . [58] U. Batool, M.I. Shapiai, H. Fauzi, J.X. Fong, Convolutional neural network for imbalanced data classification of silicon wafer defects, in: 2020 16th IEEE International Colloquium on Signal Processing & Its Applications (CSPA)IEEE, 2020, pp. 230‚Äì235, https://doi.org/10.1109/CSPA48992.2020.9068669 . [59] J. Cohen, A coefficient of agreement for nominal scales, Educ. Psychol. Meas 20 (1960) 37‚Äì46, https://doi.org/10.1177/001316446002000104 . [60] F. Cabitza, A. Campagner, D. Albano, A. Aliprandi, A. Bruno, V. Chianca, A. Corazza, F. Di Pietto, A. Gambino, S. Gitto, C. Messina, D. Orlandi, L. Pedone, M. Zappia, L.M. Sconfienza, The elephant in the machine: proposing a new metric of data reliability and its application to a medical case to assess classification reliability, Appl. Sci. 10 (2020) 4014, https://doi.org/10.3390/app10114014 . [61] T. Ishida, I. Nitta, D. Fukuda, Y. Kanazawa, Deep Learning-Based Wafer-Map Failure Pattern Recognition Framework, in: 20th International Symposium on Quality Ele"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_62", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 62, "text": "s://doi.org/10.3390/app10114014 . [61] T. Ishida, I. Nitta, D. Fukuda, Y. Kanazawa, Deep Learning-Based Wafer-Map Failure Pattern Recognition Framework, in: 20th International Symposium on Quality Electronic Design (ISQED)IEEE, 2019, pp. 291‚Äì297, https://doi.org/ 10.1109/ISQED.2019.8697407 . [62] A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet classification with deep convolutional neural networks, Commun. ACM 60 (2017) 84‚Äì90. [63] D.P. Kingma, J. Ba, Adam: A Method for Stochastic Optimization, (2014). https:// arxiv.org/abs/1412.6980 (accessed May 10, 2021). [64] M. Sokolova, G. Lapalme, A systematic analysis of performance measures for classification tasks, Inf. Process. Manag 45 (2009) 427‚Äì437, https://doi.org/ 10.1016/j.ipm.2009.03.002 . [65] A. Campagner, D. Ciucci, C.-M. Svensson, M.T. Figge, F. Cabitza, Ground truthing from multi-rater labeling with three-way decision and possibility theory, Inf. Sci. (n. y) 545 (2021) 771‚Äì790, https://doi.org/10.1016/j.ins.2020.09.049 . [66] Y. Kong, D. Ni, Recognition and Location of Mixed-type Patterns in Wafer Bin Maps, in: 2019 IEEE International Conference on Smart Manufacturing, Industrial & Logistics Engineering (SMILE)IEEE, 2019,"}
{"id": "Development of a spatial dimension-based taxonomy for classifying the.pdf::chunk_63", "source": "Development of a spatial dimension-based taxonomy for classifying the.pdf", "chunk_index": 63, "text": " Y. Kong, D. Ni, Recognition and Location of Mixed-type Patterns in Wafer Bin Maps, in: 2019 IEEE International Conference on Smart Manufacturing, Industrial & Logistics Engineering (SMILE)IEEE, 2019, pp. 4‚Äì8, https://doi.org/10.1109/ SMILE45626.2019.8965309 . [67] C.-H. Wang, Recognition of semiconductor defect patterns using spatial filtering and spectral clustering, Expert. Syst. Appl 34 (2008) 1914 ‚Äì1923, https://doi.org/ 10.1016/j.eswa.2007.02.014 . [68] J. Shim, S. Kang, S. Cho, Active cluster annotation for wafer map pattern classification in semiconductor manufacturing, Expert. Syst. Appl 183 (2021) 115429, https://doi.org/10.1016/j.eswa.2021.115429 . S.-H. Choi et al."}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_0", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 0, "text": "Citation: Kim, M.H.; Kim, T.S. Development of a Wafer Defect Pattern Classifier Using Polar Coordinate System Transformed Inputs and Convolutional Neural Networks. Electronics 2024 ,13, 1360. https://doi.org/10.3390/ electronics13071360 Academic Editors: Yi Gu, Fr√©d√©rique Ducroquet, Tao Wang, Jae-Hyung Jang and Hongtao Li Received: 12 March 2024 Revised: 1 April 2024 Accepted: 2 April 2024 Published: 4 April 2024 Copyright: ¬©2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/). electronics Article Development of a Wafer Defect Pattern Classifier Using Polar Coordinate System Transformed Inputs and Convolutional Neural Networks Moo Hyun Kim and Tae Seon Kim * School of Information, Communications and Electronics Engineering, The Catholic University of Korea, Bucheon 14662, Republic of Korea; chirss@catholic.ac.kr *Correspondence: tkim@catholic.ac.kr; Tel.: +82-2-2164-4367 Abstract: Defect pattern analysis of wafer bin maps (WBMs) is an important means of identifying process problems. Recently, automa"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_1", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 1, "text": "lic.ac.kr *Correspondence: tkim@catholic.ac.kr; Tel.: +82-2-2164-4367 Abstract: Defect pattern analysis of wafer bin maps (WBMs) is an important means of identifying process problems. Recently, automated analysis methods using machine learning or deep learning have been studied as alternatives to manual classification by engineers. In this paper, we propose a method to improve the feature extraction performance of defect patterns by transforming the polar coordinate system instead of the existing WBM image input. To reduce the variability of the location representation, defect patterns in the Cartesian coordinate system, where the location of the distributed defect die is not constant, were converted to a polar coordinate system. The CNN classifier, which uses polar coordinate transformed input, achieved a classification accuracy of 91.3%, which is 4.8% better than the existing WBM image-based CNN classifier. Additionally, a tree-structured classifier model that sequentially connects binary classifiers achieved a classification accuracy of 94%. The method proposed in this paper is also applicable to the defect pattern classification of WBMs consisting of different die sizes than th"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_2", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 2, "text": "inary classifiers achieved a classification accuracy of 94%. The method proposed in this paper is also applicable to the defect pattern classification of WBMs consisting of different die sizes than the training data. Finally, the paper proposes an automated pattern classification method that uses individual classifiers to learn defect types and then applies ensemble techniques for multiple defect pattern classification. This method is expected to reduce labor, time, and cost and enable objective labeling instead of relying on subjective judgments of engineers. Keywords: wafer bin map (WBM); defect pattern classification; polar coordinate system; convolutional neural network (CNN) 1. Introduction Integrated circuit (IC) chips are manufactured by hundreds of steps of continuous and complex chemical, optical, and mechanical processing on a semiconductor wafer. A single wafer may contain tens or hundreds of chips (or dies) that are manufactured to have uniform performance. Semiconductor companies are continuously developing miniatur- ization processes to produce more dies from a single wafer, reducing costs and enhancing integration. This complex semiconductor manufacturing process and"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_3", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 3, "text": "mpanies are continuously developing miniatur- ization processes to produce more dies from a single wafer, reducing costs and enhancing integration. This complex semiconductor manufacturing process and miniaturization pro- cess make the chips on the wafer susceptible to various types of defects. To detect the defects during the manufacturing process and analyze their causes, the wafer test steps are essential [ 1]. A typical wafer level test method is electrical die sorting (EDS), which is used to test the electrical characteristics of the chip. EDS tests focus on sorting chips or wafers through AC and DC parameter tests. Additionally, EDS can provide information on fabrication yield and chip functionality. Each die is assigned a bin code or bin code number based on the test results to identify the cause of the defect. Through this process, the defective dies on the wafer are visually represented according to the cause of the defect, forming a wafer image called a wafer bin map (WBM) as shown in Figure 1. Each die is normally represented by a binary logical value of ‚Äò0‚Äô or ‚Äò1‚Äô when a WBM determines only whether a die is failed or not. When the test results require a more detailed di"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_4", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 4, "text": " shown in Figure 1. Each die is normally represented by a binary logical value of ‚Äò0‚Äô or ‚Äò1‚Äô when a WBM determines only whether a die is failed or not. When the test results require a more detailed distinction Electronics 2024 ,13, 1360. https://doi.org/10.3390/electronics13071360 https://www.mdpi.com/journal/electronics Electronics 2024 ,13, 1360 2 of 32 between defect types, predetermined symbols or values are assigned to represent them. These values can be used to classify the type of wafer defect as a two-dimensional pattern, which can be categorized into typical pattern types such as ‚ÄòCenter‚Äô, ‚ÄòDonut‚Äô, ‚ÄòEdge-Loc‚Äô, ‚ÄòEdge-Ring‚Äô, ‚ÄòLoc‚Äô, ‚ÄòNear-Full‚Äô, ‚ÄòRandom‚Äô, ‚ÄòScratch‚Äô, or ‚Äònone‚Äô, depending on the spatial characteristics of the defect pattern [2‚Äì4]. Electronics 2024 , 13, 1360 2 of 32 determines only whether a die is failed or no t. When the test results require a more de- tailed distinction between defect types, predet ermined symbols or values are assigned to represent them. These values can be used to classify the type of wafer defect as a two- dimensional pa ttern, which can be categorized into typical pa ttern types such as ‚ÄòCenter‚Äô, ‚ÄòDonut‚Äô, ‚ÄòEdge-Loc‚Äô, ‚ÄòEdge-Ring ‚Äô, ‚ÄòLoc‚Äô,"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_5", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 5, "text": "values can be used to classify the type of wafer defect as a two- dimensional pa ttern, which can be categorized into typical pa ttern types such as ‚ÄòCenter‚Äô, ‚ÄòDonut‚Äô, ‚ÄòEdge-Loc‚Äô, ‚ÄòEdge-Ring ‚Äô, ‚ÄòLoc‚Äô, ‚ÄòNear-Full‚Äô, ‚ÄòRandom‚Äô, ‚ÄòScratch‚Äô, or ‚Äònone‚Äô, de- pending on the spatial characteristics of the defect pa ttern [2‚Äì4]. Figure 1. Example of WBM. The ultimate goal of this research is to develop a system that can automatically diag- nose process problems quickly and accurately using WBM data acquired in the semicon- ductor manufacturing process. For this, objectiv e of this paper is to develop a system that classi Ô¨Åes the type of WBM pa ttern based on data from eight types of defect pa tterns. Con- ventionally, experienced failure analysis engineers view WBM images and manually clas- sify failure pa tterns. However, manual classi Ô¨Åcation methods are ine Ô¨Écient in terms of time and cost and rely on subjective judgment of engineers, which li mits the repeatability of measurements. These issues signi Ô¨Åcantly reduce the accuracy and e Ô¨Éciency of WBM analysis and defect cause identi Ô¨Åcation. For this reason, many semiconductor companies are continuously researching to automate defect pa tter"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_6", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 6, "text": "s signi Ô¨Åcantly reduce the accuracy and e Ô¨Éciency of WBM analysis and defect cause identi Ô¨Åcation. For this reason, many semiconductor companies are continuously researching to automate defect pa ttern classi Ô¨Åcation using machine learning and deep learning techniqu es. Existing studies show that e Ô¨Äorts have been made to improve the classi Ô¨Åcation accuracy of defect pa tterns by using WBM images as training data for CNNs [5‚Äì7]. Upon analyzing each defect pa ttern on the WBM image used here, we can see that there are positional and geometric features in the distribution of defect dies for each defect pa ttern class. Figure 2a shows the defect pa ttern where the defect die group is distributed in the center of the WB M, which belongs to the ‚ÄòCenter‚Äô class. The ‚ÄòDonut‚Äô class is de Ô¨Åned by the defect pa ttern where the defect die is distributed in a donut shape. The ‚ÄòEdge-Ring‚Äô pa ttern is characterized by the distribution of defect dies along the edge of the WBM. For pa tterns such as ‚ÄòCenter‚Äô, ‚ÄòDonut‚Äô, and ‚ÄòEdge-Ring‚Äô, the images be- longing to these classes exhibit almost identi cal defect die distributions based on the in- plane position of each wafer. However, as depicted in Figu"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_7", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 7, "text": "enter‚Äô, ‚ÄòDonut‚Äô, and ‚ÄòEdge-Ring‚Äô, the images be- longing to these classes exhibit almost identi cal defect die distributions based on the in- plane position of each wafer. However, as depicted in Figure 2b, in the case of ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô pa tterns, the defect die clusters do not appear at a constant location. Rather, the spatial location of the defect die cl usters varies from image to image. Therefore, even if they belong to the same class, the lo cation information of the defect dies in the space represented by the Cartesian coordinate system makes the images look quite di Ô¨Äer- ent depending on their distribution. As a result, it is necessary to learn how to transform the WBM image data to be tter represent their positional features, rather than using the WBM image itself as the input of the classi Ô¨Åer as in existing methods. Figure 1. Example of WBM. The ultimate goal of this research is to develop a system that can automatically di- agnose process problems quickly and accurately using WBM data acquired in the semi- conductor manufacturing process. For this, objective of this paper is to develop a system that classifies the type of WBM pattern based on data from"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_8", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 8, "text": "and accurately using WBM data acquired in the semi- conductor manufacturing process. For this, objective of this paper is to develop a system that classifies the type of WBM pattern based on data from eight types of defect patterns. Conventionally, experienced failure analysis engineers view WBM images and manually classify failure patterns. However, manual classification methods are inefficient in terms of time and cost and rely on subjective judgment of engineers, which limits the repeatability of measurements. These issues significantly reduce the accuracy and efficiency of WBM analysis and defect cause identification. For this reason, many semiconductor companies are continuously researching to automate defect pattern classification using machine learn- ing and deep learning techniques. Existing studies show that efforts have been made to improve the classification accuracy of defect patterns by using WBM images as training data for CNNs [ 5‚Äì7]. Upon analyzing each defect pattern on the WBM image used here, we can see that there are positional and geometric features in the distribution of defect dies for each defect pattern class. Figure 2a shows the defect pattern where the de"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_9", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 9, "text": "n the WBM image used here, we can see that there are positional and geometric features in the distribution of defect dies for each defect pattern class. Figure 2a shows the defect pattern where the defect die group is distributed in the center of the WBM, which belongs to the ‚ÄòCenter‚Äô class. The ‚ÄòDonut‚Äô class is defined by the defect pattern where the defect die is distributed in a donut shape. The ‚ÄòEdge-Ring‚Äô pattern is characterized by the distribution of defect dies along the edge of the WBM. For patterns such as ‚ÄòCenter‚Äô, ‚ÄòDonut‚Äô, and ‚ÄòEdge-Ring‚Äô, the images belonging to these classes exhibit almost identical defect die distributions based on the in-plane position of each wafer. However, as depicted in Figure 2b, in the case of ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô patterns, the defect die clusters do not appear at a constant location. Rather, the spatial location of the defect die clusters varies from image to image. Therefore, even if they belong to the same class, the location information of the defect dies in the space represented by the Cartesian coordinate system makes the images look quite different depending on their distribution. As a result, it is necessary to learn how to"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_10", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 10, "text": "ation of the defect dies in the space represented by the Cartesian coordinate system makes the images look quite different depending on their distribution. As a result, it is necessary to learn how to transform the WBM image data to better represent their positional features, rather than using the WBM image itself as the input of the classifier as in existing methods. In this paper, we construct six models, including a comparison model, and evaluate their performance based on input data conversion, pre-processing method, and classifier structure. Section 4 describes the specific configuration of these models. We evaluated and compared the performance of the proposed method using the real-world WM-811K dataset through training and testing on 26 √ó26-sized WBMs. Experiments were conducted to classify the defect patterns of different-sized WBMs from the trained data to confirm the model‚Äôs general applicability. First, the defect die information on the WBM is converted to the polar coordinate system to enhance the characteristics of the distribution of defect Electronics 2024 ,13, 1360 3 of 32 dies by wafer defect class, rather than using the WBM image as input. To clarify, instead of u"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_11", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 11, "text": "te system to enhance the characteristics of the distribution of defect Electronics 2024 ,13, 1360 3 of 32 dies by wafer defect class, rather than using the WBM image as input. To clarify, instead of using Cartesian coordinates (x, y) to express position information, the distance information was expressed as r, and the rotation information was expressed as Œ∏, centered on the center of the circular wafer, so that the position characteristics of the defect pattern could be easily defined. If the transformed information from the polar coordinates is used, the amount of information from the points corresponding to the defective dies will be quite small compared to the entire space consisting of the radii and angles. To solve this problem, the space of the polar coordinate system is divided into a certain range, and the number of defective dies belonging to that area is measured and pre-processed to be used as input. In summary, the location information is resolved to the necessary level for defect pattern classification. The degree of defect at that location is expressed by the number of defect dies, allowing for robust classification of various types of WBM. Three different classificat"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_12", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 12, "text": " defect pattern classification. The degree of defect at that location is expressed by the number of defect dies, allowing for robust classification of various types of WBM. Three different classification models were used for classification and their performance was compared. A single CNN and a binary tree-structured classifier were used for single failure pattern classification, while a CNN-based ensemble classifier was used for mixed defect pattern classification. The binary classifier-based tree structure classification model trained on polar coordinate system data is a sequentially connected structure of binary classifiers to classify defect patterns with relatively clear distribution compared to other defect patterns first. In this way, we aimed to improve the classification accuracy compared to the existing model that classifies eight patterns at a time. Finally, we designed individual classifiers for each class to classify mixed defect patterns. These classifiers were trained on polar coordinate data, and an ensemble defect pattern classification model was presented. Based on the engineer‚Äôs judgment, we found that many WBMs contain multiple defect patterns rather than single "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_13", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 13, "text": "polar coordinate data, and an ensemble defect pattern classification model was presented. Based on the engineer‚Äôs judgment, we found that many WBMs contain multiple defect patterns rather than single defect patterns, although the dataset we used does not have accurate labeling information for multiple defect patterns. Electronics 2024 , 13, 1360 3 of 32 (a) ( b) Figure 2. WBM images with various positions of defect dies: ( a) Defect pa tterns with similar distri- bution of locations; ( b) Defect pa tterns with inconsistent di stribution of locations. In this paper, we construct six models, including a comparison model, and evaluate their performance based on input data conv ersion, pre-processing method, and classi Ô¨Åer structure. Section 4 describes the speci Ô¨Åc conÔ¨Åguration of these models. We evaluated and compared the performance of the proposed method using the real-world WM-811K da- taset through training and testing on 26 √ó 26-sized WBMs. Experi ments were conducted to classify the defect pa tterns of di Ô¨Äerent-sized WBMs from the trained data to con Ô¨Årm the model‚Äôs general applicability. First, the defect die information on the WBM is con- verted to the polar coordinate syst"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_14", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 14, "text": "he defect pa tterns of di Ô¨Äerent-sized WBMs from the trained data to con Ô¨Årm the model‚Äôs general applicability. First, the defect die information on the WBM is con- verted to the polar coordinate system to enhance the characteristics of the distribution of defect dies by wafer defect class, rather th an using the WBM image as input. To clarify, instead of using Cartesian coordinates (x, y) to express position information, the distance information was expressed as r, and the rotation information was expressed as Œ∏, centered on the center of the circular wafer, so that the position characteristics of the defect pa ttern could be easily de Ô¨Åned. If the transformed information from the polar coordinates is used, the amount of information from the points co rresponding to the defective dies will be quite small compared to the entire space consis ting of the radii and angles. To solve this problem, the space of the polar coordinate syst em is divided into a certain range, and the number of defective dies belonging to that area is measured and pre-processed to be used as input. In summary, the location information is resolved to the necessary level for defect pattern classi Ô¨Åcation. The d"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_15", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 15, "text": "efective dies belonging to that area is measured and pre-processed to be used as input. In summary, the location information is resolved to the necessary level for defect pattern classi Ô¨Åcation. The degree of defect at that location is expressed by the number of defect dies, allowing for robust classi Ô¨Åcation of various types of WBM. Three di Ô¨Äerent classi Ô¨Åcation models were used for classi Ô¨Åcation and their performance was compared. A single CNN and a binary tree-structured classi Ô¨Åer were used for single failure pa ttern classi Ô¨Åcation, while a CNN-based ensemble classi Ô¨Åer was used for mixed defect pa ttern classi Ô¨Åcation. The binary classi Ô¨Åer-based tree structure classi Ô¨Åcation model trained on po- lar coordinate system data is a sequenti ally connected structure of binary classi Ô¨Åers to classify defect pa tterns with relatively clear distribu tion compared to other defect pa tterns Ô¨Årst. In this way, we aimed to improve the classi Ô¨Åcation accuracy compared to the existing model that classi Ô¨Åes eight pa tterns at a time. Finally, we designed individual classi Ô¨Åers for each class to classify mixed defect pa tterns. These classi Ô¨Åers were trained on polar coordinate data, and a"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_16", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 16, "text": "that classi Ô¨Åes eight pa tterns at a time. Finally, we designed individual classi Ô¨Åers for each class to classify mixed defect pa tterns. These classi Ô¨Åers were trained on polar coordinate data, and an ensemble defect pa ttern classi Ô¨Åcation model was presented. Based on the engineer‚Äôs judgment, we found that many WBMs contain multiple defect pa tterns rather than single defect pa tterns, although the dataset we used does not have accurate labeling information for multiple defect pa tterns. The paper presents three novel contributions. Firstly, the use of a polar coordinate system transformation enhances the ability to classify pa tterns that are di Ô¨Écult to de Ô¨Åne as similar defect pa tterns in the conventional Cartesian coordinate system plane. Second, we showed that WBMs with di Ô¨Äerent die sizes or wafer dimensions can be classi Ô¨Åed by Figure 2. WBM images with various positions of defect dies: ( a) Defect patterns with similar distribution of locations; ( b) Defect patterns with inconsistent distribution of locations. The paper presents three novel contributions. Firstly, the use of a polar coordinate system transformation enhances the ability to classify patterns that are diff"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_17", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 17, "text": "consistent distribution of locations. The paper presents three novel contributions. Firstly, the use of a polar coordinate system transformation enhances the ability to classify patterns that are difficult to define as similar defect patterns in the conventional Cartesian coordinate system plane. Second, we showed that WBMs with different die sizes or wafer dimensions can be classified by the proposed system without additional training. Finally, we demonstrated the possibility of identifying WBMs with mixed defect patterns to comprehend the limitations of the original dataset, which was labeled with only a single failure pattern. The proposed method in this paper clarifies the location information of the defect pattern through the polar coordinate space representation, rather than relying on the location and shape information of the defect pattern represented in the WBM image or Cartesian coordinate system. Additionally, we were able to evaluate performance differences based on the pre-processing method and classifier model. Furthermore, we verified the labeling results of the WM-811K dataset Electronics 2024 ,13, 1360 4 of 32 using the mixed defect pattern classification model. Mo"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_18", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 18, "text": "-processing method and classifier model. Furthermore, we verified the labeling results of the WM-811K dataset Electronics 2024 ,13, 1360 4 of 32 using the mixed defect pattern classification model. Most previous papers using this dataset approached it as a pattern recognition problem to improve classification accuracy. However, in this paper, we were able to identify the limitations of the labeling defined in the dataset through mixed defect pattern classification to provide information necessary for actual semiconductor manufacturing. 2. Related Work 2.1. Single-Failure Pattern Classification With the growth of the semiconductor industry, many techniques have been studied to effectively classify defect patterns on wafers. Li and Huang proposed a method that combines self-organizing maps (SOMs) and support vector machines (SVMs) for binary bin map classification [ 5]. They emphasized that the combination of unsupervised SOM-based clustering and supervised SVM-based classification methods has computational advan- tages for solving large-scale problems, and the classification performance is better than the existing BP . However, it is to be considered that the optimal number of clust"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_19", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 19, "text": "ds has computational advan- tages for solving large-scale problems, and the classification performance is better than the existing BP . However, it is to be considered that the optimal number of clusters for classifying defect types or defect patterns varies depending on the type of data. Wu et al. extracted rotation- and scale-invariant wafer-specific features based on geometry from wafer map images and used them for failure pattern classification of wafers with different die sizes [ 8]. The authors applied the features to large-scale real-world wafer map data and demonstrated their efficient processing in wafer map failure pattern recognition (WMFPR) and wafer map similarity ranking (WMSR). Furthermore, Piao et al. [ 9] utilized the radon transform and interpolated projection to generate max, min, average, and standard de- viation values and classified failure patterns using a decision tree. While their proposed method demonstrated superior failure pattern recognition performance compared to many existing algorithms, it was found to be insufficient in describing the spatial information of defects on the wafer when multiple failure patterns exist, thus limiting its overall perfor-"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_20", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 20, "text": "pared to many existing algorithms, it was found to be insufficient in describing the spatial information of defects on the wafer when multiple failure patterns exist, thus limiting its overall perfor- mance. Several methods have been studied to classify single-defect patterns. Conventional classification methods, such as SVM, were applied in the beginning [ 10]. More recently, researchers have employed deep learning methods, mostly based on convolutional neural network (CNN) models [ 5‚Äì7]. CNNs possess translational invariance, which ensures that the absolute position of any image does not affect the classification performance of the model. Well-known models include ResNet and VGG16, and several studies have shown that these CNNs have strong image classification performance [ 11,12]. Nakazawa and Kulkarni [ 5] generated 28,600 synthetic wafer maps containing 22 different defect patterns and used them as training data for a CNN to perform defect pattern classification, resulting in a retrieval error rate of 3.7%. Wang and Tsai [13] also attempted classification using the MobileNet V2 algorithm to reduce the computational complexity compared to a typical CNN. Koo and Ko [ 14] used ve"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_21", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 21, "text": "trieval error rate of 3.7%. Wang and Tsai [13] also attempted classification using the MobileNet V2 algorithm to reduce the computational complexity compared to a typical CNN. Koo and Ko [ 14] used vectors encoding topological features as input to CNNs based on topological data analysis (TDA). Using TDA is a very different approach than traditional methods, and it allowed them to outperform traditional CNN-based models in experiments with small amounts of data and imbalanced data. Shin and Yoo [ 15] applied lightweight models such as EfficientNetV2, ShuffleNetV2, and MobileNetV3 to wafer map classification and compared them in terms of classification performance, hardware resource utilization, and execution time. They showed that fast inference is possible without high-performance hardware, making their proposed method applicable to real-world manufacturing. Wang et al. [ 16] proposed a two-stage classifier model with self-supervised pre-training using unlabeled WBMs followed by a few-shot fine tuning. They showed that it can classify effectively even with a small amount of labeled data. However, the proposed model is a single-defect classification model, but since real WBMs often "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_22", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 22, "text": "shot fine tuning. They showed that it can classify effectively even with a small amount of labeled data. However, the proposed model is a single-defect classification model, but since real WBMs often have multiple defects, further research is needed to develop a multi-defect classification model. While the selection of an appropriate pattern classifier is very important, for datasets with unbalanced data per class, such as semiconductor defect pattern classification, addi- tional operations such as data augmentation are often required in the data pre-processing stage to improve classification performance. Nakazawa et al. and Shim et al. balanced the Electronics 2024 ,13, 1360 5 of 32 data by using a small amount of real wafer data and additional synthesized data [ 5,17]. To address the imbalance in the dataset, Theodoros Tziolas et al. [ 18] independently processed each class in proportion to the number of samples. Abu Ebayyeh et al. [ 19] augmented the data in a balanced manner using a deep convolutional generative adversarial network (DCGAN) and then utilized a capsule network for classification. Park and You [ 20] also used a DCGAN-based data augmentation method to improve the p"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_23", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 23, "text": "a deep convolutional generative adversarial network (DCGAN) and then utilized a capsule network for classification. Park and You [ 20] also used a DCGAN-based data augmentation method to improve the performance of a defect pattern classifier with extremely imbalanced data. They also presented a metric called polymorphic generative index (PGI) to quantitatively evaluate the performance of the augmented model intuitively, although with some performance limitations. Given that semiconductor mass production systems require continuous process opti- mization and new process technologies are being introduced, analysis methods that only consider previously defined defect patterns may not be sufficient. Additionally, manually labeling defect patterns for products with varying die sizes is a laborious task. Considering this, research has been conducted using unsupervised learning methods, which are useful for handling large amounts of unlabeled data. Shon et al. presented a methodology to train a convolution-based variational autoencoder (CVAE) in an unsupervised manner [ 21], and Qiao Xu et al. used unlabeled data to learn common defect patterns using an unsuper- vised method [ 22]. However"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_24", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 24, "text": "a convolution-based variational autoencoder (CVAE) in an unsupervised manner [ 21], and Qiao Xu et al. used unlabeled data to learn common defect patterns using an unsuper- vised method [ 22]. However, only a few studies have used pure unsupervised learning. Recently, many studies have utilized the concept of semisupervised learning, which applies supervised learning to a small amount of labeled data and unsupervised learning to a large amount of unlabeled data. Niu et al. proposed a semisupervised fault detection method using GANs [ 23]. Li et al. also employed semisupervised learning by training a predictive model with labeled data and sending suspicious samples to an unsupervised learning algorithm [ 24]. These works have stimulated research on defect wafer image classification, leading to the problem of classifying mixed defect patterns, which will be discussed in the next section. 2.2. Mixed Failure Pattern Classification In semiconductor chip mass production, it is common for multiple defect patterns to appear on a wafer simultaneously. However, there is limited research on the classification of mixed defect patterns compared to single defect patterns. The most common methodo"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_25", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 25, "text": "tiple defect patterns to appear on a wafer simultaneously. However, there is limited research on the classification of mixed defect patterns compared to single defect patterns. The most common methodology for classifying mixed defect patterns is to separate them into multiple single patterns on a wafer map. Various methods can be used to combine multiple defect patterns into a single pattern, including hierarchical clustering, spectral clustering, support vector clustering, and density-based spatial clustering of applications with noise (DBSCAN). Among them, Wang et al. [ 25] showed that the single linkage method provides the best separation performance for unlinked mixed patterns. When dealing with mixed defect patterns, it is common for multiple patterns to be stuck together, making it difficult to separate them into a single pattern. Kim et al. [ 26] proposed a methodology that utilizes connectivity path filtering and an infinite warped mixture model (iWMM) to separate clusters of complex shapes. Remya et al. also attempted to classify mixed patterns by training several of them using ResNet50 [11]. In general, studies on defect pattern classification aim to separate outlier dete"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_26", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 26, "text": "omplex shapes. Remya et al. also attempted to classify mixed patterns by training several of them using ResNet50 [11]. In general, studies on defect pattern classification aim to separate outlier detection and defect pattern detection into independent steps. However, Jin et al. [ 27] presented a methodology that trains the DBSCAN algorithm using polar coordinate system data and performs both defect pattern and outlier removal simultaneously. After setting the appro- priate parameters using DBSCAN, a set of defective dies that are successfully clustered is considered as a defect pattern. Dies that do not belong to the cluster are considered as out- liers and removed. If multiple clusters of defect patterns are obtained from a single wafer map, they are classified as mixed patterns. The clusters extracted using this method can be referred to as mixed patterns. This approach proves useful when the algorithm parameters are adjusted based on the distribution of defect dies in each wafer map. However, this study only presents the classification results for Near-Full patterns. Therefore, it is unclear Electronics 2024 ,13, 1360 6 of 32 whether the same method is valid for the remaining pa"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_27", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 27, "text": ". However, this study only presents the classification results for Near-Full patterns. Therefore, it is unclear Electronics 2024 ,13, 1360 6 of 32 whether the same method is valid for the remaining pattern types, and further research is required. Kyeong and Kim [ 28] proposed a methodology to solve the mixed-type defect pattern classification problem and the data imbalance problem by creating separate classifiers for each class using the ensemble method. In this study, a multi-pattern classifier to distinguish the presence and absence of the corresponding patterns for the four classification models was implemented by creating classifiers for four pattern classes (Scratch, Ring, Circle, and Zone). Liu and Tang [ 29] addressed the mixed-type defect pattern classification problem by transforming it into a single defect classification problem using a triplet CNN model instead of a binary CNN. They utilized a weakly supervised learning approach to acquire highly imbalanced defect data without additional manual labeling, which is beneficial for practical applications. Wang and Chen [ 30] proposed a noise-robust composite defect pattern classification model by separating mixed-type defect"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_28", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 28, "text": "ut additional manual labeling, which is beneficial for practical applications. Wang and Chen [ 30] proposed a noise-robust composite defect pattern classification model by separating mixed-type defect patterns into clusters using a method called tensor voting. Tensor voting is a perceptual grouping method used to obtain continuous smooth curves, junctions, and regions in two- or three-dimensional (2D/3D) space. The extracted patterns were recognized as 16 types of failure patterns on the basis of a simple decision tree, and the performance was better than the results of the combination of the existing clustering method and a CNN. Furthermore, X-ray computed tomography has been recently utilized for defect anal- ysis in various engineering fields [ 31,32]. If high-resolution 3D images of semiconductor chips can be acquired through this method, physical defect analysis will be possible. As described above, the models for classifying defect patterns in WBM are mainly based on CNNs and focus on developing CNN architectures and algorithms to improve the classification accuracy of defect patterns. However, these studies are mainly aimed at improving the pattern recognition accuracy based"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_29", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 29, "text": "us on developing CNN architectures and algorithms to improve the classification accuracy of defect patterns. However, these studies are mainly aimed at improving the pattern recognition accuracy based on the dataset without considering the error of the original data‚Äôs label. Therefore, it is necessary to verify the dataset in addition to developing classification algorithms to accurately determine the type of defective pattern and diagnose process problems quickly. In this paper, the training data were filtered to exclude data with label values that do not clearly express the characteristics of WBM due to subjective judgments of engineers or the label method that can only express a single-defect pattern. To enhance pattern classification accuracy, the WBM information was represented as a polar coordinate system. Additionally, the number of defective dies per block was used as input to improve defect classification performance. Further details are explained in the next section. 3. Materials and Methods In this paper, we present a methodology for classifying wafer defect patterns using class-based defect distribution features. In this paper, instead of using image data as input for W"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_30", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 30, "text": "ials and Methods In this paper, we present a methodology for classifying wafer defect patterns using class-based defect distribution features. In this paper, instead of using image data as input for WBM defect pattern classification, we proposed a framework to enhance the spatial features of defect dies by converting the polar coordinate system to improve the classification accuracy and detect mixed defect patterns based on these data. Figure 3 illustrates the overall flowchart of the proposed process. In this paper, we use WM-811K, a real-world open dataset that is commonly used for WBM pattern classification, as the original data [ 8]. At first, we extract 26 √ó26 images from different sizes of WBM images and store only labeled data separately. In WM-811K, each wafer is labeled with 9 types of defect patterns, including ‚Äònone‚Äô (no defect pattern) and 8 defect patterns. We employed SVM to identify the presence or absence of defect patterns. For the remaining 8 classes of defect pattern images, any defect die that exists randomly, regardless of the typical pattern of a specific defect, is considered as noise and removed. Data augmentation is then performed to compensate for the imba"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_31", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 31, "text": " images, any defect die that exists randomly, regardless of the typical pattern of a specific defect, is considered as noise and removed. Data augmentation is then performed to compensate for the imbalance between the WBM data labeled by defect type. Electronics 2024 ,13, 1360 7 of 32 Electronics 2024 , 13, 1360 7 of 32 patterns, including ‚Äònone‚Äô (no defect pa ttern) and 8 defect pa tterns. We employed SVM to identify the presence or absence of defect pa tterns. For the remaining 8 classes of defect pattern images, any defect die that exists randomly, regardless of the typical pa ttern of a speciÔ¨Åc defect, is considered as noise and remov ed. Data augmentation is then performed to compensate for the imbalance between the WBM data labeled by defect type. Figure 3. Schematic of the proposed wafer defect pa ttern classi Ô¨Åcation method. The data generated by the WBM is divided into two types of inputs, and each type of input is fed into the classi Ô¨Åer for evaluation of its performance. The Ô¨Årst input has a structure in which the defective die and the normal die are divided into binary codes and the values are listed sequentially according to the (x, y) values in the Cartesian coordinat"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_32", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 32, "text": " Ô¨Årst input has a structure in which the defective die and the normal die are divided into binary codes and the values are listed sequentially according to the (x, y) values in the Cartesian coordinate system. In other words, the WBM image is re presented as a bitmap to provide WBM in- formation to the CNN. To evaluate the pre-processing performance for the method that used WBM images as training data, we compared the classi Ô¨Åcation performance of the model that trained the image data itself and th e model that used the number of defect dies in the speci Ô¨Åed area as training data. The second method involves classifying defect pat- terns using data generated by a polar coordinate system-based conversion. First, the WBM data are denoised and augmented and then co nverted to polar coordinate system data. Each defect die on the WBM is assigned a polar coordinate system value consisting of the distance from the origin and the angle (r, Œ∏) away from the baseline. At this point, the distance and angle are divided into speci Ô¨Åc ranges, and defect images within each range are extracted and used as training data for th e CNN (the detailed description is presented in Section 3.2). Subsequentl"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_33", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 33, "text": "and angle are divided into speci Ô¨Åc ranges, and defect images within each range are extracted and used as training data for th e CNN (the detailed description is presented in Section 3.2). Subsequently, we compared the classi Ô¨Åcation performance of the CNN classi Ô¨Åer trained using WBM image data with the CNN classi Ô¨Åer trained using polar co- ordinate system data. Next, we present a defect pa ttern classi Ô¨Åer that applies polar coordinate data and a tree structure. The defect pa ttern classi Ô¨Åer that applied the tree structure classi Ô¨Åed eight types of defect pa tterns through a binary classi Ô¨Åcation model using the CNN algorithm. To enhance the accuracy of defect pa ttern classi Ô¨Åcation, we Ô¨Årst classi Ô¨Åed patterns with consistent defect distribution features of WBMs belonging to the class, as shown in Figure 2a, by placing them close to the root node. Later, pa tterns with high randomness of defect distribution were classi Ô¨Åed, as shown in Figure 2b. We constructed a CNN-based ensemble model using polar coordinate system data to classify mixed defect pa tterns. A binary classi Ô¨Åcation model was trained for each of the eight defect pa tterns (Center, Donut, Edge-Loc, Edge -Ring, L"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_34", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 34, "text": "le model using polar coordinate system data to classify mixed defect pa tterns. A binary classi Ô¨Åcation model was trained for each of the eight defect pa tterns (Center, Donut, Edge-Loc, Edge -Ring, Loc, Near-Full, Random, and Scratch) by re-labeling the polar coordinate system data into the corresponding defect Figure 3. Schematic of the proposed wafer defect pattern classification method. The data generated by the WBM is divided into two types of inputs, and each type of input is fed into the classifier for evaluation of its performance. The first input has a structure in which the defective die and the normal die are divided into binary codes and the values are listed sequentially according to the (x, y) values in the Cartesian coordinate system. In other words, the WBM image is represented as a bitmap to provide WBM information to the CNN. To evaluate the pre-processing performance for the method that used WBM images as training data, we compared the classification performance of the model that trained the image data itself and the model that used the number of defect dies in the specified area as training data. The second method involves classifying defect patterns using data "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_35", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 35, "text": "he model that trained the image data itself and the model that used the number of defect dies in the specified area as training data. The second method involves classifying defect patterns using data generated by a polar coordinate system-based conversion. First, the WBM data are denoised and augmented and then converted to polar coordinate system data. Each defect die on the WBM is assigned a polar coordinate system value consisting of the distance from the origin and the angle (r, Œ∏) away from the baseline. At this point, the distance and angle are divided into specific ranges, and defect images within each range are extracted and used as training data for the CNN (the detailed description is presented in Section 3.2). Subsequently, we compared the classification performance of the CNN classifier trained using WBM image data with the CNN classifier trained using polar coordinate system data. Next, we present a defect pattern classifier that applies polar coordinate data and a tree structure. The defect pattern classifier that applied the tree structure classified eight types of defect patterns through a binary classification model using the CNN algorithm. To enhance the accuracy "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_36", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 36, "text": "ructure. The defect pattern classifier that applied the tree structure classified eight types of defect patterns through a binary classification model using the CNN algorithm. To enhance the accuracy of defect pattern classification, we first classified patterns with consistent defect distribution features of WBMs belonging to the class, as shown in Figure 2a, by placing them close to the root node. Later, patterns with high randomness of defect distribution were classified, as shown in Figure 2b. We constructed a CNN-based ensemble model using polar coordinate system data to classify mixed defect patterns. A binary classification model was trained for each of the eight defect patterns (Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, and Scratch) by re-labeling the polar coordinate system data into the corresponding defect pattern or other patterns. The models trained for each class were then ensembled to produce eight classification results. Additionally, a model capable of identifying two mixed defect patterns was presented. Electronics 2024 ,13, 1360 8 of 32 3.1. Dataset The dataset used in this paper, WM-811K, is open data consisting of WBMs of various die sizes col"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_37", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 37, "text": "f identifying two mixed defect patterns was presented. Electronics 2024 ,13, 1360 8 of 32 3.1. Dataset The dataset used in this paper, WM-811K, is open data consisting of WBMs of various die sizes collected from actual semiconductor manufacturing, with about 20% of the WBMs in the dataset labeled by domain experts [ 8]. Out of the 811,457 WBMs in WM-811K, 638,507 are unlabeled, and only 172,950 are labeled with ‚Äònone‚Äô and 8 types of defect patterns (Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, Scratch). However, out of the 172,950 labeled data, only 25,519 (3.1%) are labeled with a defect pattern, while the remaining 147,431 are labeled as ‚Äònone‚Äô. The WM-811K dataset includes 1266 wafers with varying die sizes, and the WBM contains 632 datasets with different die distributions on the wafer, depending on the wafer and die size. To develop a robust defect pattern classifier by machine learning or deep learning, the data must be accurately labeled and a sufficient number of data must be acquired to learn the features of each defect pattern. As previously stated, the WM-811K dataset contains a relatively small number of labeled data, and the number of dies on the wafer a"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_38", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 38, "text": " data must be acquired to learn the features of each defect pattern. As previously stated, the WM-811K dataset contains a relatively small number of labeled data, and the number of dies on the wafer and the area occupied by the die vary. Therefore, it is not appropriate to use the original data directly. To address this issue, a data selection process was applied in this paper, and we have taken 26√ó26WBMs among various sizes of WBMs. Table 1 lists the number of data by defect type for the 26 √ó26 WBMs. The data show a high number of ‚Äònone‚Äô pattern defects compared to other types, which is consistent with the overall imbalance in semiconductor production data. To solve this data imbalance problem, this paper uses a two-step classification method that first determines the presence or absence of defect patterns, and then classifies the defect types for WBMs containing defect patterns. Table 1. Number of labeled WBMs in 26 √ó26 size. Defect Type Number of Samples Center 90 Donut 1 Edge-Loc 296 Edge-Ring 31 Loc 290 Near-Full 16 Random 74 Scratch 72 None 13,489 Upon reviewing the 26 √ó26 WBM images, as shown in Figure 4, it is evident that the shape of the WBM is not always well matched to "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_39", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 39, "text": "96 Edge-Ring 31 Loc 290 Near-Full 16 Random 74 Scratch 72 None 13,489 Upon reviewing the 26 √ó26 WBM images, as shown in Figure 4, it is evident that the shape of the WBM is not always well matched to the defined label, or there are cases where two or more defect types are combined and only one label is labeled. Specifically, we observed numerous instances in the ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô categories where pattern classification is subject to the engineer‚Äôs subjective evaluation. If the labeled results are not objective or if it is difficult to determine that the labeled WBM is representative of the pattern, it can be difficult to extract the spatial features of each class and become a major factor in reducing the classification accuracy if the training data of the classifier contain data that are not representative of the pattern. Therefore, we considered these images as outliers and removed them from the training data. However, as shown in Table 1, there is only one ‚ÄòDonut‚Äô pattern among the 26 √ó26 size WBM data. Therefore, we artificially generated a pattern that can represent the ‚ÄòDonut‚Äô pattern and added it to the original data. We added 12 images to the existing data to "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_40", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 40, "text": "ern among the 26 √ó26 size WBM data. Therefore, we artificially generated a pattern that can represent the ‚ÄòDonut‚Äô pattern and added it to the original data. We added 12 images to the existing data to match the number of ‚ÄòNear-Full‚Äô patterns, which have the least amount of data except for the ‚ÄòDonut‚Äô pattern. Table 2 shows the amount of data for each class after removing outliers from the 26 √ó26 WBM and adding the randomly generated ‚ÄòDonut‚Äô pattern. Electronics 2024 ,13, 1360 9 of 32 Electronics 2024 , 13, 1360 9 of 32 the ‚ÄòDonut‚Äô pa ttern. Table 2 shows the amount of data for each class after removing outli- ers from the 26 √ó 26 WBM and adding the randomly generated ‚ÄòDonut‚Äô pa ttern. Table 2. Number of labeled WBMs in 26 √ó 26 size after removing outliers. Defect Type Number of Samples Center 46 Donut 13 Edge-Loc 160 Edge-Ring 31 Loc 108 Near-Full 13 Random 74 Scratch 35 Figure 4. Examples of WBM with ambigu ous labeling in a dataset. 3.2. Random Noise Filtering and Data Augmentation Figures 1, 2a,b and 4 show that there are randomly located defect dies on the WBM called random noise, in addition to the defect dies that match the typical trend of the de- fect pattern. In this paper,"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_41", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 41, "text": "gures 1, 2a,b and 4 show that there are randomly located defect dies on the WBM called random noise, in addition to the defect dies that match the typical trend of the de- fect pattern. In this paper, the term ‚Äôrandomly loca ted defect die‚Äô refers to defective dies that are located independently of the characteri stics of the typical defect types. These de- fect dies act as noisy data in the defect pa ttern classi Ô¨Åcation process. The pa tterned defect die populations are mainly in Ô¨Çuenced by controllable factors in the wafer production pro- cess, such as process parameters, equipment de fects, and improper operation. However, the presence of random noise in wafer production is often due to a lack of process environment management or factors that are difficult to cont rol directly. To reduce random noise, gradual improvement of the process environment or replacement of expensive equipment over a long period of time is necessary [33]. As a result, there are always defect dies corresponding to noise in the WBM. In this case, the number of noise defects degrades the geometric and spatial characteristics of the defect pattern. Therefore, it is necessary to remove random noise before us"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_42", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 42, "text": "ing to noise in the WBM. In this case, the number of noise defects degrades the geometric and spatial characteristics of the defect pattern. Therefore, it is necessary to remove random noise before using wafer defect pa tterns as training data. It is di Ô¨Écult to determine with certainty whether each die is a ‚Äòrandomly located defect die‚Äô or not. However, they are typically distributed uniformly across the wafer, similar to salt noise in an image. In this study, we denoise the center pixel of a 3 √ó 3 region by converting it to a normal die if there are less than N pixels in the 3 √ó 3 region that correspond to defective dies. In other words, if the number of defect dies in a 3 √ó 3 region as shown in Figure 5 is lower than a threshold value, we consider the defect die to be a ‚Äòrandomly located defect die‚Äô and de Ô¨Åne it as ‚Äòrandom noise‚Äô. Figure 5 displays the denoising outcomes based on the threshold N value. In Figure 5, the defect di es in the yellow box are an example of random noise. The image labeled ‚ÄòN = 3‚Äô shows an image where noise was removed by se tting the N value to 3. Similarly, the image labeled ‚ÄòN = 4‚Äô shows an image where noise was re- moved by se tting the N value to "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_43", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 43, "text": "The image labeled ‚ÄòN = 3‚Äô shows an image where noise was removed by se tting the N value to 3. Similarly, the image labeled ‚ÄòN = 4‚Äô shows an image where noise was re- moved by se tting the N value to 4. The distribution of th e ‚ÄòScratch‚Äô defect pa ttern which Figure 4. Examples of WBM with ambiguous labeling in a dataset. Table 2. Number of labeled WBMs in 26 √ó26 size after removing outliers. Defect Type Number of Samples Center 46 Donut 13 Edge-Loc 160 Edge-Ring 31 Loc 108 Near-Full 13 Random 74 Scratch 35 3.2. Random Noise Filtering and Data Augmentation Figures 1, 2a,b and 4 show that there are randomly located defect dies on the WBM called random noise, in addition to the defect dies that match the typical trend of the defect pattern. In this paper, the term ‚Äòrandomly located defect die‚Äô refers to defective dies that are located independently of the characteristics of the typical defect types. These defect dies act as noisy data in the defect pattern classification process. The patterned defect die populations are mainly influenced by controllable factors in the wafer production process, such as process parameters, equipment defects, and improper operation. However, the presenc"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_44", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 44, "text": "terned defect die populations are mainly influenced by controllable factors in the wafer production process, such as process parameters, equipment defects, and improper operation. However, the presence of random noise in wafer production is often due to a lack of process environment management or factors that are difficult to control directly. To reduce random noise, gradual improvement of the process environment or replacement of expensive equipment over a long period of time is necessary [ 33]. As a result, there are always defect dies corresponding to noise in the WBM. In this case, the number of noise defects degrades the geometric and spatial characteristics of the defect pattern. Therefore, it is necessary to remove random noise before using wafer defect patterns as training data. It is difficult to determine with certainty whether each die is a ‚Äòrandomly located defect die‚Äô or not. However, they are typically distributed uniformly across the wafer, similar to salt noise in an image. In this study, we denoise the center pixel of a 3 √ó3 region by converting it to a normal die if there are less than N pixels in the 3 √ó3 region that correspond to defective dies. In other words, "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_45", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 45, "text": "age. In this study, we denoise the center pixel of a 3 √ó3 region by converting it to a normal die if there are less than N pixels in the 3 √ó3 region that correspond to defective dies. In other words, if the number of defect dies in a 3 √ó3 region as shown in Figure 5 is lower than a threshold value, we consider the defect die to be a ‚Äòrandomly located defect die‚Äô and define it as ‚Äòrandom noise‚Äô. Figure 5 displays the denoising outcomes based on the threshold N value. In Figure 5, the defect dies in the yellow box are an example of random noise. The image labeled ‚ÄòN = 3‚Äô shows an image where noise was removed by setting the N value to 3. Similarly, the image labeled ‚ÄòN = 4‚Äô shows an image where noise was removed by setting the N value to 4. The distribution of the ‚ÄòScratch‚Äô defect pattern which has the thinnest defect pattern lost its shape due to excessive denoising when N = 4, as shown in the figure. Therefore, this paper selected N = 3 to eliminate random noise while preserving the defect pattern‚Äôs characteristics. Electronics 2024 ,13, 1360 10 of 32 Electronics 2024 , 13, 1360 10 of 32 has the thinnest defect pa ttern lost its shape due to excessive denoising when N = 4, as shown"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_46", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 46, "text": "fect pattern‚Äôs characteristics. Electronics 2024 ,13, 1360 10 of 32 Electronics 2024 , 13, 1360 10 of 32 has the thinnest defect pa ttern lost its shape due to excessive denoising when N = 4, as shown in the Ô¨Ågure. Therefore, this paper selected N = 3 to eliminate random noise while preserving the defect pa ttern‚Äôs characteristics. Figure 5. Example of noise removal results based on di Ô¨Äerent threshold values. Table 2 shows a signi Ô¨Åcant deviation in the number of data between the ‚Äònone‚Äô type of data and the remaining defect pa tterns, except for outliers. This data imbalance issue is prevalent in many Ô¨Åelds that require training data, no t just WBMs. Moreover, it is chal- lenging to rely on the performance of a classi Ô¨Åcation model trained with unbalanced data by class. In this study, we augmented the da ta using the method of rotating WBM images to balance the number of WBM data by defect ty pe to 250, as shown in Table 3. To achieve this, we sequentially rotated the original data from 15 degrees to 360 degrees, resulting in a total of 24 di Ô¨Äerent angles. The augmented data were then saved separately. If the num- ber of original data presented in Table 2 was insu Ô¨Écient to creat"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_47", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 47, "text": "om 15 degrees to 360 degrees, resulting in a total of 24 di Ô¨Äerent angles. The augmented data were then saved separately. If the num- ber of original data presented in Table 2 was insu Ô¨Écient to create 250 datasets, we ran- domly added augmented data from the separate ly stored augmented data to create 250 data for each class. Table 3 shows the number of labeled WBMs after outlier removal and augmentation. Table 3. Number of labeled WBMs in 26 √ó 26 size after data augmentation. Defect Type Number of Samples Center 250 Donut 250 Edge-Loc 250 Edge-Ring 250 Loc 250 Near-Full 250 Random 250 Scratch 250 3.3. Defect Pa ttern Classi Ô¨Åcation Using Polar Coordinate Data In general, WBM defect pa ttern classi Ô¨Åcation used two-dimensional image data rep- resented by the Cartesian coordinate system. In this case, the pixe l corresponding to the defect die has a spatial coordinate value on the x and y axis as shown in Figure 1. Figure 2a shows that for the ‚ÄòCenter‚Äô pa ttern, defects are concentrated in the center of the image. For the ‚ÄòDonut‚Äô pa ttern, defects are distributed in the sh ape of a donut with a hole in the center, and there are few defects in the positions corresponding to the cent"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_48", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 48, "text": "d in the center of the image. For the ‚ÄòDonut‚Äô pa ttern, defects are distributed in the sh ape of a donut with a hole in the center, and there are few defects in the positions corresponding to the center and edge. Even when the WBM image itself is used as training data for the classi Ô¨Åer, eÔ¨Écient defect pattern classi Ô¨Åcation is possible if the distribution of defect dies in WBM images belonging Figure 5. Example of noise removal results based on different threshold values. Table 2 shows a significant deviation in the number of data between the ‚Äònone‚Äô type of data and the remaining defect patterns, except for outliers. This data imbalance issue is prevalent in many fields that require training data, not just WBMs. Moreover, it is challenging to rely on the performance of a classification model trained with unbalanced data by class. In this study, we augmented the data using the method of rotating WBM images to balance the number of WBM data by defect type to 250, as shown in Table 3. To achieve this, we sequentially rotated the original data from 15 degrees to 360 degrees, resulting in a total of 24 different angles. The augmented data were then saved separately. If the number of or"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_49", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 49, "text": " achieve this, we sequentially rotated the original data from 15 degrees to 360 degrees, resulting in a total of 24 different angles. The augmented data were then saved separately. If the number of original data presented in Table 2 was insufficient to create 250 datasets, we randomly added augmented data from the separately stored augmented data to create 250 data for each class. Table 3 shows the number of labeled WBMs after outlier removal and augmentation. Table 3. Number of labeled WBMs in 26 √ó26 size after data augmentation. Defect Type Number of Samples Center 250 Donut 250 Edge-Loc 250 Edge-Ring 250 Loc 250 Near-Full 250 Random 250 Scratch 250 3.3. Defect Pattern Classification Using Polar Coordinate Data In general, WBM defect pattern classification used two-dimensional image data rep- resented by the Cartesian coordinate system. In this case, the pixel corresponding to the defect die has a spatial coordinate value on the x and y axis as shown in Figure 1. Figure 2a shows that for the ‚ÄòCenter‚Äô pattern, defects are concentrated in the center of the image. For the ‚ÄòDonut‚Äô pattern, defects are distributed in the shape of a donut with a hole in the center, and there are few de"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_50", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 50, "text": " for the ‚ÄòCenter‚Äô pattern, defects are concentrated in the center of the image. For the ‚ÄòDonut‚Äô pattern, defects are distributed in the shape of a donut with a hole in the center, and there are few defects in the positions corresponding to the center and edge. Even when the WBM image itself is used as training data for the classifier, efficient defect pattern classification is possible if the distribution of defect dies in WBM images belonging to a class is independent of the rotation of the pattern in the Cartesian coordinate system, as shown in Figure 2a. However, upon examining the ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô patterns in Figure 2b, it becomes apparent that they belong to the same class but are randomly located in the Cartesian coordinate system representation of (x, y). When the distribution Electronics 2024 ,13, 1360 11 of 32 of defect dies is highly randomized for each image, extracting the spatial characteristics of defect dies becomes challenging when training a classifier using WBM images as input. In this study, we applied the method of converting WBM spatial coordinate informa- tion into polar coordinate data to improve defect die distribution characteristics. To ach"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_51", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 51, "text": "using WBM images as input. In this study, we applied the method of converting WBM spatial coordinate informa- tion into polar coordinate data to improve defect die distribution characteristics. To achieve this, we obtained the distance from the origin of the WBM by recognizing the defect die as one spatial coordinate value. Then, we calculated the angle of each defect die in the counterclockwise direction with respect to the xaxis. The defect die‚Äôs distance from the origin is denoted by the variable r, while the angle away from the initial ray is denoted by the variable Œ∏, resulting in a polar coordinate pair of (r, Œ∏). Figure 6 shows the distribution of the defect dies on the coordinate system after con- verting the WBM data into a polar coordinate system, where the horizontal axis represents angle and the vertical axis represents distance from the center of wafer. The location in- formation of the defect dies was then used as input to the defect pattern classifier through the following process. The two-dimensional plane data were converted to the polar co- ordinate system and divided into 49 blocks based on r and Œ∏. Specifically, Œ∏was divided into seven sections from 0 to 360 deg"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_52", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 52, "text": "ng process. The two-dimensional plane data were converted to the polar co- ordinate system and divided into 49 blocks based on r and Œ∏. Specifically, Œ∏was divided into seven sections from 0 to 360 degrees in increments of 50 degrees, and the distance was divided into seven sections from 0 to 14 in increments of 2. The number of defective dies in each section was measured, and the data were reconstructed into a 7 √ó7 matrix- shaped two-dimensional array. The classifier was trained using the polar coordinate system data as input and its performance was compared to the existing classifier trained using WBM images. Electronics 2024 , 13, 1360 11 of 32 to a class is independent of the rotation of the pa ttern in the Cartesian coordinate system, as shown in Figure 2a. However, upon examining the ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô pat- terns in Figure 2b, it becomes apparent that they belong to the same class but are randomly located in the Cartesian coordinate system repr esentation of (x, y). When the distribution of defect dies is highly randomized for each image, extracting the spatial characteristics of defect dies becomes challenging when training a classi Ô¨Åer using WBM images as input"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_53", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 53, "text": "When the distribution of defect dies is highly randomized for each image, extracting the spatial characteristics of defect dies becomes challenging when training a classi Ô¨Åer using WBM images as input. In this study, we applied the method of converting WBM spatial coordinate infor- mation into polar coordinate data to improve defect die distribution characteristics. To achieve this, we obtained the distance from the origin of the WBM by recognizing the defect die as one spatial coordinate value. Then , we calculated the angle of each defect die in the counterclockwise direction with respect to the x axis. The defect die‚Äôs distance from the origin is denoted by the variable r, while the angle away from the initial ray is denoted by the variable Œ∏, resulting in a polar coordinate pair of (r, Œ∏). Figure 6 shows the distribution of the defect dies on the coordinate system after con- verting the WBM data into a polar coordinate system, where the horizontal axis represents angle and the vertical axis represents distance from the center of wafer. The location in- formation of the defect dies was then used as input to the defect pa ttern classi Ô¨Åer through the following process. The two-di"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_54", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 54, "text": "ical axis represents distance from the center of wafer. The location in- formation of the defect dies was then used as input to the defect pa ttern classi Ô¨Åer through the following process. The two-dimensional pl ane data were converted to the polar coor- dinate system and divided into 49 blocks based on r and Œ∏. Speci Ô¨Åcally, Œ∏ was divided into seven sections from 0 to 360 degrees in increments of 50 degrees, and the distance was divided into seven sections from 0 to 14 in increments of 2. The number of defective dies in each section was measured, and the da ta were reconstructed into a 7 √ó 7 matrix- shaped two-dimensional array. The classi Ô¨Åer was trained using the polar coordinate sys- tem data as input and its performance was compared to the existing classi Ô¨Åer trained us- ing WBM images. Figure 6. Examples of transformation in to polar coordinate system. Figure 6. Examples of transformation into polar coordinate system. This transformation aims to improve the characterization of defect patterns in ‚ÄòEdge- Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô, where the location of defect patterns is inconsistent in the Carte- sian coordinate system. Specifically, both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns, as sh"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_55", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 55, "text": "efect patterns in ‚ÄòEdge- Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô, where the location of defect patterns is inconsistent in the Carte- sian coordinate system. Specifically, both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns, as shown in Figure 6, share the common feature that defect dies are clustered in a certain space, but Electronics 2024 ,13, 1360 12 of 32 in both classes, the location of the defect pattern is not consistent, and it is difficult to distinguish them from the image alone. Therefore, to distinguish between these two classes, whether the defect pattern is located at the edge or inside the WBM plays an important role in classification performance. Therefore, it is predicted that the method using polar coordinate system data containing distance information from the origin will be better than the method using WBM images. Furthermore, upon examining the example WBM images in Figure 6, it becomes apparent that the defect patterns‚Äô locations in Cartesian coordinates differ significantly, despite both belonging to the same label as ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô, respectively. However, when the location information of defect dies is converted to a polar coordinate system, it becomes apparent that the distributi"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_56", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 56, "text": "onging to the same label as ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô, respectively. However, when the location information of defect dies is converted to a polar coordinate system, it becomes apparent that the distribution of defect differences is concentrated on the side farthest from the origin in the case of ‚ÄòEdge-Loc‚Äô, while in the case of ‚ÄòLoc‚Äô, the distribution of defect differences is concentrated in the area with a medium distance from the origin. Figure 7 and Table 4 shows the CNN architecture used in this study. The model comprises three convolutional layers with 32, 64, and 64 channels. The rectified linear unit (ReLU) function was used as the activation function for each layer. After completing all convolutional operations, the layers were reconnected through fully connected layers with 64 and 8 nodes. The output layer consists of neurons that correspond to each failure die pattern, and the softmax function is used as the activation function. The CNN structure was determined by tuning the hyperparameters manually. Adam was used as the optimizer, and the learning rate was set to 0.1, 0.01, and 0.001, which are commonly used values, to compare performance. The batch size was determined by gr"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_57", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 57, "text": "rparameters manually. Adam was used as the optimizer, and the learning rate was set to 0.1, 0.01, and 0.001, which are commonly used values, to compare performance. The batch size was determined by gradually increasing it from a small value to 64, 128, 256, and 512, while the epoch value was sequentially increased from 100 to 300, until the training loss no longer converged. Ultimately, a batch size of 256, a learning rate of 0.01, and 300 epochs were chosen. Electronics 2024 , 13, 1360 12 of 32 This transformation aims to improve the characterization of defect pa tterns in ‚ÄòEdge- Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô, wh ere the location of defect pa tterns is inconsistent in the Car- tesian coordinate system. Speci Ô¨Åcally, both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns, as shown in Figure 6, share the common feature that defect dies are clustered in a certain space, but in both classes, the location of the defect pa ttern is not consistent, and it is di Ô¨Écult to distin- guish them from the image alone. Therefore, to distinguish between these two classes, whether the defect pa ttern is located at the edge or inside the WBM plays an important role in classi Ô¨Åcation performance. Therefore, it is predicte"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_58", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 58, "text": "erefore, to distinguish between these two classes, whether the defect pa ttern is located at the edge or inside the WBM plays an important role in classi Ô¨Åcation performance. Therefore, it is predicted that the method using polar coordinate system data containing distance information from the origin will be be tter than the method using WBM images. Furthermore, upon examining the example WBM images in Figure 6, it becomes apparent that the defect pa tterns‚Äô locations in Cartesian coordinates diÔ¨Äer signi Ô¨Åcantly, despite both belonging to the same label as ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô, re- spectively. However, when the location information of defect dies is converted to a polar coordinate system, it becomes apparent that the distribution of defect di Ô¨Äerences is con- centrated on the side farthest from the origin in the case of ‚ÄòEdge-Loc‚Äô, while in the case of ‚ÄòLoc‚Äô, the distribution of defect di Ô¨Äerences is concentrated in the area with a medium distance from the origin. Figure 7 and Table 4 shows the CNN architecture used in this study. The model com- prises three convolutional layers with 32, 64, and 64 channels. The recti Ô¨Åed linear unit (ReLU) function was used as the activation fu nct"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_59", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 59, "text": "hows the CNN architecture used in this study. The model com- prises three convolutional layers with 32, 64, and 64 channels. The recti Ô¨Åed linear unit (ReLU) function was used as the activation fu nction for each layer. After completing all convolutional operations, the layers were reconnected through fully connected layers with 64 and 8 nodes. The output layer consists of neurons that correspond to each failure die pattern, and the softmax function is used as the activation function. The CNN structure was determined by tuning the hyperparamet ers manually. Adam was used as the opti- mizer, and the learning rate was set to 0.1, 0.01, and 0.001, which are commonly used values, to compare performance. The batch si ze was determined by gradually increasing it from a small value to 64, 128, 256, and 512, while the epoch value was sequentially in-creased from 100 to 300, until the training lo ss no longer converged. Ultimately, a batch size of 256, a learning rate of 0.01, and 300 epochs were chosen. Figure 7. Structure of CNN. Table 4. ConÔ¨Åguration of CNN. Layer Kernel Size, Stride No. of Parameters Output Shape Input - - (26, 26, 3) Convolutional 3 √ó 3 √ó 32, 1 320 (24, 24, 32) Max-Poo"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_60", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 60, "text": "re chosen. Figure 7. Structure of CNN. Table 4. ConÔ¨Åguration of CNN. Layer Kernel Size, Stride No. of Parameters Output Shape Input - - (26, 26, 3) Convolutional 3 √ó 3 √ó 32, 1 320 (24, 24, 32) Max-Pooling 2 √ó 2, 2 - (12, 12, 32) Convolutional 3 √ó 3 √ó 64, 1 18,496 (10, 10, 64) Max-Pooling 2 √ó 2, 2 - (5, 5, 64) Convolutional 3 √ó 3 √ó 64, 1 36,928 (3, 3, 64) Flatten - - (576) Fully Connected - 36,928 (64) Fully Connected - 520 (8) Figure 7. Structure of CNN. Table 4. Configuration of CNN. Layer Kernel Size, Stride No. of Parameters Output Shape Input - - (26, 26, 3) Convolutional 3 √ó3√ó32, 1 320 (24, 24, 32) Max-Pooling 2 √ó2, 2 - (12, 12, 32) Convolutional 3 √ó3√ó64, 1 18,496 (10, 10, 64) Max-Pooling 2 √ó2, 2 - (5, 5, 64) Convolutional 3 √ó3√ó64, 1 36,928 (3, 3, 64) Flatten - - (576) Fully Connected - 36,928 (64) Fully Connected - 520 (8) 3.4. Defect Pattern Classifier Using Polar Coordinate System Data and Tree Structure In the previous section, we presented a model for classifying eight defect patterns using WBM information expressed in a polar coordinate system as input to a single CNN. In this section, we present a model that can classify WBM defect patterns through binary pattern classi"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_61", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 61, "text": " patterns using WBM information expressed in a polar coordinate system as input to a single CNN. In this section, we present a model that can classify WBM defect patterns through binary pattern classifiers connected in series by applying a tree structure. To classify the eight Electronics 2024 ,13, 1360 13 of 32 defect patterns, we created eight binary classifiers that can classify each defect pattern and the remaining patterns. Unlike the conventional decision tree method, which is based on recursive partitioning and pruning and has an indeterminate structure of the whole tree, the proposed model simply connects as many binary classifiers in series as the number of defect patterns to be classified. The defect patterns in the WBM can be characterized by their location and shape on the plane. Some patterns are distinguishable solely by their location, while others are simply distinguishable by their shape rather than by their location. To simplify these problems, we used a structure with consecutive binary classifiers to classify defect patterns and compared their performance. The most important factors that determine the classification performance for classifiers with this structur"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_62", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 62, "text": "h consecutive binary classifiers to classify defect patterns and compared their performance. The most important factors that determine the classification performance for classifiers with this structure are the performance of individual classifiers and the order in which the classifiers are arranged. In this paper, SVM, one of the most popular binary classifiers, and CNN, a representative deep learning method, were used for each node of the tree structure. The order of the classifiers was determined based on their classification accuracy, with the highest accuracy classifiers placed at the top nodes. To reduce errors in classifying other classifiers, we first classify easily distinguishable patterns. To train the binary classifiers for learning individual patterns, we used the 2000 polar coordinate system data presented in Section 3.2 (Table 3). The data were split into a 7:3 ratio for training and test data, respectively. The training data were used with the two outputs relabeled as Applicable/Others for the corresponding patterns. Figure 8 illustrates the structure of the classifier proposed in this paper. The binary classifier‚Äôs classification performance for implementing the mod"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_63", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 63, "text": "plicable/Others for the corresponding patterns. Figure 8 illustrates the structure of the classifier proposed in this paper. The binary classifier‚Äôs classification performance for implementing the model is as follows: ‚ÄòCenter‚Äô: 98.9%, ‚ÄòDonut‚Äô: 100%, ‚ÄòEdge-Loc‚Äô: 94.8%, ‚ÄòEdge-Ring‚Äô: 98.1%, ‚ÄòLoc‚Äô: 93.5%, ‚ÄòNear-Full‚Äô: 99.3%, ‚ÄòRandom‚Äô: 98.1%, and ‚ÄòScratch‚Äô: 96%. We determined that the characteristics of the defect pattern become more distinct as the binary classifier‚Äôs performance improves. Therefore, we placed the patterns with better binary classification performance at the top node. We designed a tree structure for the eight classifiers by first classifying data with a clear defect pattern. Then, we placed the data predicted not to belong to that pattern at the higher classification node back into the lower classification node. The test results and performance comparison of this model are presented in Section 4. Electronics 2024 , 13, 1360 13 of 32 3.4. Defect Pa ttern Classi Ô¨Åer Using Polar Coordinate System Data and Tree Structure In the previous section, we presented a model for classifying eight defect pa tterns using WBM information expressed in a polar coordinate system as inpu"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_64", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 64, "text": "olar Coordinate System Data and Tree Structure In the previous section, we presented a model for classifying eight defect pa tterns using WBM information expressed in a polar coordinate system as input to a single CNN. In this section, we present a model that can classify WBM defect pa tterns through binary pattern classi Ô¨Åers connected in series by applying a tree structure. To classify the eight defect pa tterns, we created eight binary classi Ô¨Åers that can classify each defect pa ttern and the remaining pa tterns. Unlike the conventional decision tree method, which is based on recursive partitioning and pruning and has an indeterminate structure of the whole tree, the proposed model simply connects as many binary classi Ô¨Åers in series as the number of defect pa tterns to be classi Ô¨Åed. The defect pa tterns in the WBM can be characterized by their location and shape on the plane. Some pa tterns are distinguishable solely by their location, while others are simply distinguishable by their shape rather th an by their location. To simplify these prob- lems, we used a structure with consecutive binary classi Ô¨Åers to classify defect pa tterns and compared their performance. The most i"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_65", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 65, "text": "heir shape rather th an by their location. To simplify these prob- lems, we used a structure with consecutive binary classi Ô¨Åers to classify defect pa tterns and compared their performance. The most impo rtant factors that determine the classi Ô¨Åcation performance for classi Ô¨Åers with this structure are the performance of individual classi Ô¨Åers and the order in which the classi Ô¨Åers are arranged. In this pa per, SVM, one of the most popular binary classi Ô¨Åers, and CNN, a representative deep learning method, were used for each node of the tree structure. The order of the classi Ô¨Åers was determined based on their classi Ô¨Åcation accuracy, with th e highest accuracy classi Ô¨Åers placed at the top nodes. To reduce errors in classifying other classi Ô¨Åers, we Ô¨Årst classify easily distinguishable pat- terns. To train the binary classi Ô¨Åers for learning individual pa tterns, we used the 2000 polar coordinate system data presented in Sect ion 3.2 (Table 3). The data were split into a 7:3 ratio for training and test data, respective ly. The training data were used with the two outputs relabeled as Applicable /Others for the corresponding pa tterns. Figure 8 illustrates the structure of the clas"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_66", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 66, "text": " training and test data, respective ly. The training data were used with the two outputs relabeled as Applicable /Others for the corresponding pa tterns. Figure 8 illustrates the structure of the classi Ô¨Åer proposed in this paper. The binary classi Ô¨Åer‚Äôs classi Ô¨Åcation performance for implementing the model is as follows: ‚ÄòCenter‚Äô: 98.9%, ‚ÄòDonut‚Äô: 100%, ‚ÄòEdge-Loc‚Äô: 94.8%, ‚ÄòEdg e-Ring‚Äô: 98.1%, ‚ÄòLoc‚Äô: 93.5%, ‚ÄòNear-Full‚Äô: 99.3%, ‚ÄòRandom‚Äô: 98.1%, and ‚ÄòScratch‚Äô: 96%. We determined that the characteristics of the defect pa ttern become more distinct as the binary classi Ô¨Åer‚Äôs performance improves. Therefore, we placed the pa tterns with be tter binary classi Ô¨Åcation performance at the top node. We designed a tree structure for the eight classi Ô¨Åers by Ô¨Årst classifying data with a clear defect pa ttern. Then, we placed the data predicted not to belong to that pa ttern at the higher classi Ô¨Åcation node back into the lower classi Ô¨Åcation node. The test results and per- formance comparison of this model are presented in Section 4. Figure 8. Tree-structured classi Ô¨Åer using polar coordinate data. 3.5. Ensemble Structure for Classifying Mixed Failure Pa tterns In general, the method for separa"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_67", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 67, "text": "is model are presented in Section 4. Figure 8. Tree-structured classi Ô¨Åer using polar coordinate data. 3.5. Ensemble Structure for Classifying Mixed Failure Pa tterns In general, the method for separating mixed defect pa tterns in WBM is to segment multiple defect pa tterns on a WBM image by applying algorithms such as connectivity Figure 8. Tree-structured classifier using polar coordinate data. 3.5. Ensemble Structure for Classifying Mixed Failure Patterns In general, the method for separating mixed defect patterns in WBM is to segment multiple defect patterns on a WBM image by applying algorithms such as connectivity filtering or DBSCAN. However, these methods have a drawback in that the number of defect patterns to be segmented varies depending on the size or distribution of defect patterns on the WBM. Additionally, segmentation becomes difficult when other defect patterns are adjacent or overlapped on one defect pattern. In addition, defect dies corresponding to global defects that are not related to the defect pattern have a significant influence on Electronics 2024 ,13, 1360 14 of 32 the segmentation process, so it is essential to perform extra data pre-processing before cla"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_68", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 68, "text": "t are not related to the defect pattern have a significant influence on Electronics 2024 ,13, 1360 14 of 32 the segmentation process, so it is essential to perform extra data pre-processing before classifying mixed defect patterns. This paper proposes a method to classify mixed defect patterns by ensembling binary classification models for each class without segmenting the mixed defect patterns to solve these problems. The structure of the proposed classifier is shown in Figure 9. To implement this model, we first relabel the polar coordinate system data presented in Section 3.2 into two categories: the corresponding defect pattern and other patterns, and generate binary classification models for eight defect patterns (Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, and Scratch). Eight classification results are extracted for WBM images from the output layer by ensembling classifiers for each defect pattern. If two or more classifiers indicate that the defect pattern corresponds to the defect pattern, both classes are output to classify it as a mixed defect pattern. By synthesizing these results, we developed a classification model that can determine whether the defect "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_69", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 69, "text": "ponds to the defect pattern, both classes are output to classify it as a mixed defect pattern. By synthesizing these results, we developed a classification model that can determine whether the defect pattern on the WBM is a single defect pattern or a mixed defect pattern and identify which defect patterns are mixed. The ensemble technique used in this paper has a very simple structure, i.e., there are binary CNN classifiers that can distinguish each defect pattern, and their predictions are passed to the mixed defect pattern classification block shown in Figure 9 with same weight for each classifier. In other words, this step acts as a decision network layer in the ensemble network. In this step, the classification result is determined by the soft-voting ensemble method, i.e., the outputs of each binary classifier that exceed a certain threshold are selected to determine that the WBM belongs to the corresponding defect type. For this experiment, we set 0.7 as the threshold value. As a result, each WBM can be classified as either a WBM with only one defect type or a WBM with two or more defect types. Electronics 2024 , 13, 1360 14 of 32 Ô¨Åltering or DBSCAN. However, these methods hav"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_70", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 70, "text": "result, each WBM can be classified as either a WBM with only one defect type or a WBM with two or more defect types. Electronics 2024 , 13, 1360 14 of 32 Ô¨Åltering or DBSCAN. However, these methods have a drawback in that the number of defect pa tterns to be segmented varies depending on the size or distribution of defect pat- terns on the WBM. Additionally, segmentation becomes di Ô¨Écult when other defect pat- terns are adjacent or overlapped on one defect pa ttern. In addition, defect dies correspond- ing to global defects that are not related to the defect pa ttern have a signi Ô¨Åcant in Ô¨Çuence on the segmentation process, so it is essentia l to perform extra data pre-processing before classifying mixed defect pa tterns. This paper proposes a method to classify mixed defect pa tterns by ensembling binary classi Ô¨Åcation models for each class without segmenting the mixed defect pa tterns to solve these problems. The structure of the proposed classi Ô¨Åer is shown in Figure 9. To imple- ment this model, we Ô¨Årst relabel the polar coordinate system data presented in Section 3.2 into two categories: the corresponding defect pa ttern and other pa tterns, and generate bi- nary classi Ô¨Åcation"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_71", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 71, "text": "t this model, we Ô¨Årst relabel the polar coordinate system data presented in Section 3.2 into two categories: the corresponding defect pa ttern and other pa tterns, and generate bi- nary classi Ô¨Åcation models for eight defect pa tterns (Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, and Scratch). Eight classification results are extracted for WBM images from the output layer by ensembling cla ssifiers for each defect pattern. If two or more classifiers indicate that the defect patter n corresponds to the defect pattern, both clas- ses are output to classify it as a mixed defect pattern. By synthesizing these results, we de- veloped a classification model that can dete rmine whether the defect pattern on the WBM is a single defect pattern or a mixed defect pa ttern and identify which defect patterns are mixed. The ensemble technique us ed in this paper has a very simple structure, i.e., there are binary CNN classifiers that can distinguish ea ch defect pattern, and their predictions are passed to the mixed defect patter n classification block shown in Figure 9 with same weight for each classi Ô¨Åer. In other words, this step acts as a decision network layer in the ensem- b"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_72", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 72, "text": "dictions are passed to the mixed defect patter n classification block shown in Figure 9 with same weight for each classi Ô¨Åer. In other words, this step acts as a decision network layer in the ensem- ble network. In this step, the classi Ô¨Åcation result is determined by the soft-voting ensem- ble method, i.e., the outputs of each binary classi Ô¨Åer that exceed a certain threshold are selected to determine that the WBM belongs to the corresponding defect type. For this experiment, we set 0.7 as the threshold va lue. As a result, each WBM can be classi Ô¨Åed as either a WBM with only one defect type or a WBM with two or more defect types. Figure 9. Mixed defect pa ttern classi Ô¨Åer with ensemble structure. To evaluate this model, we used 877 labele d data points as shown in Table 1. The ‚Äònone‚Äô pa ttern was not used. The WM-811K dataset‚Äôs WBM is labeled as one of the eight bad patterns. If we consider the WBM classi Ô¨Åcation problem using these data as a general pattern recognition problem in machine learning or deep learning, the goal would be to Figure 9. Mixed defect pattern classifier with ensemble structure. To evaluate this model, we used 877 labeled data points as shown in Table 1. Th"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_73", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 73, "text": "chine learning or deep learning, the goal would be to Figure 9. Mixed defect pattern classifier with ensemble structure. To evaluate this model, we used 877 labeled data points as shown in Table 1. The ‚Äònone‚Äô pattern was not used. The WM-811K dataset‚Äôs WBM is labeled as one of the eight bad patterns. If we consider the WBM classification problem using these data as a general pattern recognition problem in machine learning or deep learning, the goal would be to construct a classifier with the highest accuracy based on the labeled values, regardless of the shape of the pattern. Actually, there are many results that approach the research goal to maximize accuracy based on the label of the dataset. However, the labeling of WBMs is subjective and relies on the judgment of semiconductor engineers. In practice, many WBMs are judged as a mixture of two or more defect patterns. Therefore, the original purpose of semiconductor testing is to improve yield by identifying WBM defect patterns. It is necessary to find a more appropriate defect type, even if the accuracy of the Electronics 2024 ,13, 1360 15 of 32 original dataset‚Äôs labeling cannot be judged by this dataset. In this study, we check"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_74", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 74, "text": " necessary to find a more appropriate defect type, even if the accuracy of the Electronics 2024 ,13, 1360 15 of 32 original dataset‚Äôs labeling cannot be judged by this dataset. In this study, we checked the performance of the ensemble model to classify mixed defect patterns based on the original data, which include all the outlier data shown in Figure 4 and have not been denoised. 4. Experiments and Results In this study, we conducted experiments and compared the performance of six scenar- ios, summarized in Table 5, according to the type of input data, the method of pre-processing the input data, and the configuration of the classifier. The scenarios were categorized into single-failure pattern classifiers (Models 1‚Äì5) and mixed-defect (failure) patterns classi- fiers (Model 6), based on the purpose of classifying failure patterns. The single-failure pattern classifiers were further divided into five models according to the type of input data, pre-processing, and classifier type. The performances of Model 1 and Model 2, which used WBM images as training data for the WBM failure pattern classification problem, and Model 3 and Model 4, which used information converted to the polar c"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_75", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 75, "text": "performances of Model 1 and Model 2, which used WBM images as training data for the WBM failure pattern classification problem, and Model 3 and Model 4, which used information converted to the polar coordinate system proposed in this paper as training data, were compared at first. To evaluate the performance of the pre-processing method, we have compared the performance of Model 2 and Model 4, which divide the WBM into defined blocks and use the number of defects per block, with that of Model 1 and Model 3, which have no pre-processing. Regarding the classifier, we compared a single CNN trained with the information converted to the polar coordinate system to distinguish between the eight failure patterns (Model 4) and a tree structure based on a binary classifier (Model 5). Finally, we evaluated the performance of the polar coordinate system transformed input-based ensemble of CNN structure (Model 6) for classifying mixed failure patterns. Table 5. Summary of the six models used to classify WBM defect patterns. Model Number Input Type Pre-Processing Model Type Objective 1 WBM image n/a Single CNNFor classification of single-failure pattern 2 WBM imageNumber of defect dies per block"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_76", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 76, "text": "ssify WBM defect patterns. Model Number Input Type Pre-Processing Model Type Objective 1 WBM image n/a Single CNNFor classification of single-failure pattern 2 WBM imageNumber of defect dies per blockSingle CNNFor classification of single-failure pattern 3Transformed data to polar coordinate representationn/a Single CNNFor classification of single-failure pattern 4Transformed data to polar coordinate representationNumber of defect dies per blockSingle CNNFor classification of single-failure pattern 5Transformed data to polar coordinate representationNumber of defect dies per blockCNN-based tree structureFor classification of single-failure pattern 6Transformed data to polar coordinate representationNumber of defect dies per blockEnsemble of CNNFor classification of mixed-failure patterns To compare the classification performance of the model, we used accuracy, precision, recall, and F1-Score as evaluation metrics based on the confusion matrix. In general, the accuracy of a classifier is a representative metric to evaluate the performance of a classifier, but when the data are highly imbalanced, such as the dataset used in this study, the F1-Score is used to evaluate the performance"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_77", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 77, "text": "s a representative metric to evaluate the performance of a classifier, but when the data are highly imbalanced, such as the dataset used in this study, the F1-Score is used to evaluate the performance. The calculation method for each metric can be found in Equations (1)‚Äì(4) and Table 6. Accuracy =TP+TN TP+FN+FP+TN(1) Precision =TP TP+FP(2) Recall =TP TP+FN(3) Electronics 2024 ,13, 1360 16 of 32 F1_Score =2‚àóPrecision ‚àóRecall Precision +Recall(4) Table 6. The confusion matrix. Predictive Table 4 Table 4 ActualPositive TP FN Negative FP TN The experiments were performed on an AMD Ryzen 7 3700X 8-core CPU and NVIDIA GeForce RTX 2070 SUPER GPU, using the Keras 2.15.0 open-source library based on TensorFlow 2.15.0. System specifications are summarized in Table 7. Table 7. System specification. Hardware Environment Software Environment CPU: AMD Ryzen 7 3700X 8-Core Processor, 3.59 GHz GPU: NVIDIA GeForce RTX 2070 SUPERWindow 10 TensorFlow 2.15.0 Keras 2.15.0 Python 3.10.9 4.1. Comparison of Classifier Performance Using WBM Image Information and Polar Coordinate Information 4.1.1. Comparison of Models Using WBM Image Data as Inputs For the method that used WBM images as training data, we c"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_78", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 78, "text": "lassifier Performance Using WBM Image Information and Polar Coordinate Information 4.1.1. Comparison of Models Using WBM Image Data as Inputs For the method that used WBM images as training data, we checked the classification performance of the model that trained the image of WBMs (Model 1) and the model that used the number of defect dies in the specified area as training data (Model 2). To evaluate the performance of the classifier constructed using the WBM image itself as training data, the 2000 pre-processed data shown in Table 3 were divided into 7:3 for training and testing and a 3-fold cross-validation method was implemented. Figure 10 shows a visualization of the classification results in the form of a confusion matrix of Model 1. The model shows a large number of misclassifications between the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns among the eight defect patterns. The reason for the large misclassification is that the labeling decision may vary depending on subjective judgment compared to other defect patterns. However, the model classified ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô for 19 WBMs. This is likely due to the model‚Äôs inability to learn the defect pattern features of the Scratch pattern. The CN"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_79", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 79, "text": " to other defect patterns. However, the model classified ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô for 19 WBMs. This is likely due to the model‚Äôs inability to learn the defect pattern features of the Scratch pattern. The CNN model using the WBM image of WBMsshowed a classification accuracy of 86.5%, precision of 0.86, recall of 0.85, and F1-Score of 0.85. Model 2 is a model that adds a pre-processing method to Model 1. That is, the WBM data was divided into 13 zones on the wafer plane as shown in Figure 11, and the number of defective dies corresponding to each zone was counted. This pre-processing method reflects the spatial characteristics of the defect variation in the Cartesian coordinate system, which is helpful when comparing performance with classifiers that use the input transformed to polar coordinate space. The data used in Model 2 are the same as in Model 1, consisting of 2000 pre- processed data points summarized in Table 3. The data were divided into 70% training and 30% test data, and the 3-fold cross-validation was used to implement the CNN model. The confusion matrix of the model is shown in Figure 12. Similar to Model 1, there were many cases where ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô were not properly "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_80", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 80, "text": "d cross-validation was used to implement the CNN model. The confusion matrix of the model is shown in Figure 12. Similar to Model 1, there were many cases where ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô were not properly identified. However, while Model 1 often misclassified ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô, Model 2 also misclassified ‚ÄòLoc‚Äô as ‚ÄòScratch‚Äô. Model 2 achieved a classification accuracy of 82%, precision of 0.86, recall of 0.85, and F1-Score of 0.85, which is similar to Model 1. However, its accuracy was 4.5% lower, indicating that the pre-processing may not be suitable for modeling methods that utilize WBMs as input. Electronics 2024 ,13, 1360 17 of 32 Electronics 2024 , 13, 1360 17 of 32 Figure 10. Confusion matrix of Model 1. Model 2 is a model that adds a pre-processing method to Model 1. That is, the WBM data was divided into 13 zones on the wafer plane as shown in Figure 11, and the number of defective dies corresponding to each zone was counted. This pre-processing method reÔ¨Çects the spatial characteristics of the defect variation in the Cartesian coordinate sys- tem, which is helpful when comparing performance with classi Ô¨Åers that use the input transformed to polar coordinate space. The data used "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_81", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 81, "text": "tics of the defect variation in the Cartesian coordinate sys- tem, which is helpful when comparing performance with classi Ô¨Åers that use the input transformed to polar coordinate space. The data used in Model 2 are the same as in Model 1, consisting of 2000 pre-processed data poin ts summarized in Table 3. The data were di- vided into 70% training and 30% test data, and the 3-fold cross-validation was used to implement the CNN model. The confusion matr ix of the model is shown in Figure 12. Similar to Model 1, there were many cases where ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô were not properly identi Ô¨Åed. However, while Model 1 often misclassi Ô¨Åed ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô, Model 2 also misclassi Ô¨Åed ‚ÄòLoc‚Äô as ‚ÄòScratch‚Äô. Model 2 achieved a classi Ô¨Åcation accuracy of 82%, preci- sion of 0.86, recall of 0.85, and F1-Score of 0.85, which is similar to Model 1. However, its accuracy was 4.5% lower, indicating that th e pre-processing may not be suitable for mod- eling methods that utilize WBMs as input. Figure 11. WBM divided into 13 zones. Figure 10. Confusion matrix of Model 1. Electronics 2024 , 13, 1360 17 of 32 Figure 10. Confusion matrix of Model 1. Model 2 is a model that adds a pre-processing method to "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_82", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 82, "text": "WBM divided into 13 zones. Figure 10. Confusion matrix of Model 1. Electronics 2024 , 13, 1360 17 of 32 Figure 10. Confusion matrix of Model 1. Model 2 is a model that adds a pre-processing method to Model 1. That is, the WBM data was divided into 13 zones on the wafer plane as shown in Figure 11, and the number of defective dies corresponding to each zone was counted. This pre-processing method reÔ¨Çects the spatial characteristics of the defect variation in the Cartesian coordinate sys- tem, which is helpful when comparing performance with classi Ô¨Åers that use the input transformed to polar coordinate space. The data used in Model 2 are the same as in Model 1, consisting of 2000 pre-processed data poin ts summarized in Table 3. The data were di- vided into 70% training and 30% test data, and the 3-fold cross-validation was used to implement the CNN model. The confusion matr ix of the model is shown in Figure 12. Similar to Model 1, there were many cases where ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô were not properly identi Ô¨Åed. However, while Model 1 often misclassi Ô¨Åed ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô, Model 2 also misclassi Ô¨Åed ‚ÄòLoc‚Äô as ‚ÄòScratch‚Äô. Model 2 achieved a classi Ô¨Åcation accuracy of 82%, preci- sion of"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_83", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 83, "text": "not properly identi Ô¨Åed. However, while Model 1 often misclassi Ô¨Åed ‚ÄòScratch‚Äô as ‚ÄòLoc‚Äô, Model 2 also misclassi Ô¨Åed ‚ÄòLoc‚Äô as ‚ÄòScratch‚Äô. Model 2 achieved a classi Ô¨Åcation accuracy of 82%, preci- sion of 0.86, recall of 0.85, and F1-Score of 0.85, which is similar to Model 1. However, its accuracy was 4.5% lower, indicating that th e pre-processing may not be suitable for mod- eling methods that utilize WBMs as input. Figure 11. WBM divided into 13 zones. Figure 11. WBM divided into 13 zones. Electronics 2024 , 13, 1360 18 of 32 Figure 12. Confusion matrix Model 2. 4.1.2. Comparison of Models Using Polar Coordinate System Data as Inputs In the case of using polar coordinate system data as training data, we evaluated the performance of each classi Ô¨Åer by implementing a model trained on the image data them- selves and a model trained on the number of defect dies in a given region. To represent the defect dies on the WBM in the polar coordi nate system space, we obtained the distance from the center point of the WBM and calculated the angle of each defect die in the coun- terclockwise direction. The Ô¨Årst variable, r, speci Ô¨Åes the distance between the defect die and the center point. The"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_84", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 84, "text": "e center point of the WBM and calculated the angle of each defect die in the coun- terclockwise direction. The Ô¨Årst variable, r, speci Ô¨Åes the distance between the defect die and the center point. The second variable, Œ∏, speci Ô¨Åes the angle value away from the initial ray, generating polar coordinate system data in the form of (r, Œ∏) polar coordinate pairs, and the data were used to train the model. The 2000 pre-processed data shown in Table 3 were divided 7:3 to be used as training and test data, and a 3-fold cross-validation method was applied. Model 3 exhibited a classi Ô¨Åcation accuracy of 79.5%, with a precision of 0.79, recall of 0.78, and F1-Score of 0.78. These results are slightly lower than the previous model that used WBM images as input. Figure 13 shows the confusion matrix for the classi Ô¨Åcation performance of Model 3. Overall, the failure to distinguish between the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns is similar to Models 1 and 2. Although the advantages of using polar coordinate transformations to represent spatial information in defect images were demonstrated in Section 3, the repre- sentation of coordinates corresponding to the defect die as points in polar coordinate sp"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_85", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 85, "text": "e transformations to represent spatial information in defect images were demonstrated in Section 3, the repre- sentation of coordinates corresponding to the defect die as points in polar coordinate space may be limited. In other words, the de fective die, previously represented with a resolution of 26 √ó 26 in the WBM, is now represented as a single point in the polar coordi-nate system, as shown in Figure 6. At this time, the polar coordinate system information (r, Œ∏) is converted so that the r value in the range of 0‚Äì14 and the Œ∏ value in the range of 0‚Äì360 degrees are expressed to the second deci mal place. In other words, the position of the defective die that was expressed with a resolution of 26 √ó 26 is expressed as a point on a plane with a resolution of 1400 √ó 36,000. Consequently, the proportion of the total area occupied by the defect dies in the WBM represented in the polarized plane is much smaller than the area of defect dies in the WBM before conversion, even when the same number of defective dies are represented on the plane. In other words, the amount of information on defect dies is relatively small compared to the total area of the WBM used as input. Figure 12. Con"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_86", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 86, "text": " number of defective dies are represented on the plane. In other words, the amount of information on defect dies is relatively small compared to the total area of the WBM used as input. Figure 12. Confusion matrix Model 2. Electronics 2024 ,13, 1360 18 of 32 4.1.2. Comparison of Models Using Polar Coordinate System Data as Inputs In the case of using polar coordinate system data as training data, we evaluated the performance of each classifier by implementing a model trained on the image data themselves and a model trained on the number of defect dies in a given region. To represent the defect dies on the WBM in the polar coordinate system space, we obtained the distance from the center point of the WBM and calculated the angle of each defect die in the counterclockwise direction. The first variable, r, specifies the distance between the defect die and the center point. The second variable, Œ∏, specifies the angle value away from the initial ray, generating polar coordinate system data in the form of (r, Œ∏) polar coordinate pairs, and the data were used to train the model. The 2000 pre-processed data shown in Table 3 were divided 7:3 to be used as training and test data, and a 3-fol"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_87", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 87, "text": "in the form of (r, Œ∏) polar coordinate pairs, and the data were used to train the model. The 2000 pre-processed data shown in Table 3 were divided 7:3 to be used as training and test data, and a 3-fold cross-validation method was applied. Model 3 exhibited a classification accuracy of 79.5%, with a precision of 0.79, recall of 0.78, and F1-Score of 0.78. These results are slightly lower than the previous model that used WBM images as input. Figure 13 shows the confusion matrix for the classification performance of Model 3. Overall, the failure to distinguish between the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns is similar to Models 1 and 2. Although the advantages of using polar coordinate transformations to represent spatial information in defect images were demonstrated in Section 3, the represen- tation of coordinates corresponding to the defect die as points in polar coordinate space may be limited. In other words, the defective die, previously represented with a resolution of 26√ó26in the WBM, is now represented as a single point in the polar coordinate system, as shown in Figure 6. At this time, the polar coordinate system information (r, Œ∏) is converted so that the r value in the range o"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_88", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 88, "text": " is now represented as a single point in the polar coordinate system, as shown in Figure 6. At this time, the polar coordinate system information (r, Œ∏) is converted so that the r value in the range of 0‚Äì14 and the Œ∏value in the range of 0‚Äì360 degrees are expressed to the second decimal place. In other words, the position of the defective die that was expressed with a resolution of 26 √ó26 is expressed as a point on a plane with a resolution of 1400 √ó36,000. Consequently, the proportion of the total area occupied by the defect dies in the WBM represented in the polarized plane is much smaller than the area of defect dies in the WBM before conversion, even when the same number of defective dies are represented on the plane. In other words, the amount of information on defect dies is relatively small compared to the total area of the WBM used as input. Electronics 2024 , 13, 1360 19 of 32 Figure 13. Confusion matrix Model 3. Therefore, the current representation provid es only a limited amount of information for learning compared to the amount required to learn the entire space of the polar coor-dinate system. As a result, prop er learning cannot be achieved. Therefore, it is estimate"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_89", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 89, "text": "mount of information for learning compared to the amount required to learn the entire space of the polar coor-dinate system. As a result, prop er learning cannot be achieved. Therefore, it is estimated that the classi Ô¨Åcation performance of Model 3 was in ferior, and to improve it, a pre-pro- cessing method is required. Model 4 includes a pre-processing step to solve the problem of Model 3. As described in Section 3.2, the angle Œ∏ is divided into seven levels of 50 degrees from 0 to 360 degrees and the distance is divided into seven levels of 2 from 0 to 14, a total of 49 sections, and then the number of defective dies belonging to each section is measured and reorganized into two-dimensional array data with a 7 √ó 7 matrix shape. This method reduces the reso- lution of the location of the defective die in polar coordinate space. However, it enables expression of the degree of existence of the defective die by the weight. As with other models, Model 4 was implemented using a 7:3 ratio of pre-processed data summarized in Table 3 for training and testing and a 3-fold cross-validation proce- dure for implementing the CNN model. Model 4 achieved a classi Ô¨Åcation accuracy of 91.3%, preci"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_90", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 90, "text": "f pre-processed data summarized in Table 3 for training and testing and a 3-fold cross-validation proce- dure for implementing the CNN model. Model 4 achieved a classi Ô¨Åcation accuracy of 91.3%, precision of 0.91, recall of 0.91, and F1 -Score of 0.91, which are significantly higher than those of Model 3 and superior to models that use existing WBM images as input in all evaluation metrics. The confusion matrix of th e model is shown in Figure 14. Although there is a slightly higher error rate in distinguis hing between the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns compared to other defect patterns, the overall error rate is still very low when compared to other classi Ô¨Åers. Additionally, there is no bias towards any particular failure pa ttern. Table 8 summarizes the classi Ô¨Åcation performance of the four models. Model 4, which uses polar coordinate system information as input for region segmentation pre-pro- cessing, shows the best performance in almost all evaluation metrics, as shown in the ta- ble. Especially fo r ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô pa tterns, which are considered to have high defect pa ttern randomness, the scores of all evaluation metrics are signi Ô¨Åcantly in- creased. For"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_91", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 91, "text": "- ble. Especially fo r ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô pa tterns, which are considered to have high defect pa ttern randomness, the scores of all evaluation metrics are signi Ô¨Åcantly in- creased. For ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns, the defect pa ttern can either exist at the edge or inside the WBM. However, there is a commo nality that the defect dies are clustered in a certain space. It is believed that classi Ô¨Åcation results using polar coordinate system data containing distance information from the origin are superior to image data. It was found that pre-processing with the number of defect ive dies using region segmentation was very useful for the classi Ô¨Åcation when using polar coordinate system data as input. However, this pre-processing method did not improv e performance when using Cartesian coordi- nate system data. This is a ttributed to the di Ô¨Éculty of clustering ‚ÄòLoc‚Äô and ‚ÄòEdge-Loc‚Äô, Figure 13. Confusion matrix Model 3. Therefore, the current representation provides only a limited amount of information for learning compared to the amount required to learn the entire space of the polar coordinate system. As a result, proper learning cannot be achieved. Therefore, it is"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_92", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 92, "text": "a limited amount of information for learning compared to the amount required to learn the entire space of the polar coordinate system. As a result, proper learning cannot be achieved. Therefore, it is estimated that Electronics 2024 ,13, 1360 19 of 32 the classification performance of Model 3 was inferior, and to improve it, a pre-processing method is required. Model 4 includes a pre-processing step to solve the problem of Model 3. As described in Section 3.2, the angle Œ∏is divided into seven levels of 50 degrees from 0 to 360 degrees and the distance is divided into seven levels of 2 from 0 to 14, a total of 49 sections, and then the number of defective dies belonging to each section is measured and reorganized into two-dimensional array data with a 7 √ó7 matrix shape. This method reduces the resolution of the location of the defective die in polar coordinate space. However, it enables expression of the degree of existence of the defective die by the weight. As with other models, Model 4 was implemented using a 7:3 ratio of pre-processed data summarized in Table 3 for training and testing and a 3-fold cross-validation procedure for implementing the CNN model. Model 4 achieved a cla"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_93", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 93, "text": " 4 was implemented using a 7:3 ratio of pre-processed data summarized in Table 3 for training and testing and a 3-fold cross-validation procedure for implementing the CNN model. Model 4 achieved a classification accuracy of 91.3%, precision of 0.91, recall of 0.91, and F1-Score of 0.91, which are significantly higher than those of Model 3 and superior to models that use existing WBM images as input in all evaluation metrics. The confusion matrix of the model is shown in Figure 14. Although there is a slightly higher error rate in distinguishing between the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns compared to other defect patterns, the overall error rate is still very low when compared to other classifiers. Additionally, there is no bias towards any particular failure pattern. Electronics 2024 , 13, 1360 20 of 32 which are represented by various (x, y) values in the Cartesian coordinate system, as de- scribed in Section 3.2, and the pre-proces sing would not be helpful in this case. Figure 14. Confusion matrix Model 4. Table 8. Classi Ô¨Åcation performance comparison table for the four models. Defect Type Model 1 Model 2 Model 3 Model 4 Precision Recall F1-Score Precision Recall F1-Score Precisi"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_94", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 94, "text": "fusion matrix Model 4. Table 8. Classi Ô¨Åcation performance comparison table for the four models. Defect Type Model 1 Model 2 Model 3 Model 4 Precision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score Center 0.91 0.97 0.94 0.91 0.95 0. 93 0.74 0.86 0.8 0.93 0.97 0.95 Donut 1 1 1 0.99 1 0.99 0.99 1 0.99 0.97 1 0.99 Edge-Loc 0.73 0.75 0.74 0.69 0.67 0. 68 0.8 0.51 0.62 0.84 0.78 0.81 Edge-Ring 0.92 0.92 0.92 0.75 0.86 0. 81 0.82 0.96 0.88 0.93 0.96 0.95 Loc 0.59 0.63 0.61 0.57 0.43 0.49 0.51 0.46 0.48 0.84 0.71 0.77 Near-Full 0.95 0.98 0.96 0.93 0.96 0. 96 0.99 0.94 0.96 0.98 0.98 0.98 Random 0.95 0.95 0.95 0.93 0.91 0. 91 0.89 0.92 0.91 0.97 0.95 0.96 Scratch 0.81 0.63 0.71 0.65 0.67 0. 66 0.55 0.61 0.58 0.81 0.91 0.86 Average 0.86 0.85 0.85 0.8 0.81 0. 8 0.78 0.78 0.78 0.91 0.91 0.91 4.1.3. Comparison of Classi Ô¨Åcation Performance of WBM with Di Ô¨Äerent Die Size from Training Data (Model 1 and Model 4) In this paper, we have con Ô¨Årmed that the method based on the number of defect dies per speci Ô¨Åed region in polar coordinate space as training data can improve the defect pat- tern classi Ô¨Åcation performance compared to the method based on c"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_95", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 95, "text": " method based on the number of defect dies per speci Ô¨Åed region in polar coordinate space as training data can improve the defect pat- tern classi Ô¨Åcation performance compared to the method based on conventional WBM im- age data. However, the test resu lts are limited to WBMs of 26 √ó 26 in ssize, so the perfor- mance cannot be con Ô¨Årmed when the die size or number of dies per wafer is di Ô¨Äerent. To test the scalability of the proposed method, we conducted defect pa ttern classi Ô¨Åcation on all labeled WM-811K WBMs, regardless of wafer dimension and die size. Table 9 summarizes the number of labeled WBMs in WM-811K by defect pa ttern type. All 25,519 of the 172,950 labeled data, except for the ‚Äònone‚Äô pa ttern, were resized to 26 √ó 26. This means that the pixel correspond ing to each die in the WBM image was resized to reduce or increase the number of dies. The next step is identical to the process described in Section 3.2: denoise the data, convert them to polar coordinates, and create a classi Ô¨Åer that measures the number of defective dies per speci Ô¨Åed region in polar coordinate space. Additionally, as a comparison group, a classi Ô¨Åcation model was created using the original WBM im"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_96", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 96, "text": " classi Ô¨Åer that measures the number of defective dies per speci Ô¨Åed region in polar coordinate space. Additionally, as a comparison group, a classi Ô¨Åcation model was created using the original WBM image without the polar coordinate system conversion. For both models, data were Figure 14. Confusion matrix Model 4. Table 8 summarizes the classification performance of the four models. Model 4, which uses polar coordinate system information as input for region segmentation pre- processing, shows the best performance in almost all evaluation metrics, as shown in the table. Especially for ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô patterns, which are considered to have high defect pattern randomness, the scores of all evaluation metrics are significantly increased. For ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns, the defect pattern can either exist at the edge or inside the WBM. However, there is a commonality that the defect dies are clustered in a certain space. It is believed that classification results using polar coordinate system data containing distance information from the origin are superior to image data. It was found that pre-processing with the number of defective dies using region segmentation was"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_97", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 97, "text": "olar coordinate system data containing distance information from the origin are superior to image data. It was found that pre-processing with the number of defective dies using region segmentation was very useful for the classification when using polar coordinate system data as input. However, this pre-processing method did not improve performance when using Cartesian coordinate system data. This is attributed to the difficulty of clustering ‚ÄòLoc‚Äô and ‚ÄòEdge-Loc‚Äô, which are represented by various (x, y) values in the Cartesian coordinate system, as described in Section 3.2, and the pre-processing would not be helpful in this case. Electronics 2024 ,13, 1360 20 of 32 Table 8. Classification performance comparison table for the four models. Defect TypeModel 1 Model 2 Model 3 Model 4 Precision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score Center 0.91 0.97 0.94 0.91 0.95 0.93 0.74 0.86 0.8 0.93 0.97 0.95 Donut 1 1 1 0.99 1 0.99 0.99 1 0.99 0.97 1 0.99 Edge-Loc 0.73 0.75 0.74 0.69 0.67 0.68 0.8 0.51 0.62 0.84 0.78 0.81 Edge-Ring 0.92 0.92 0.92 0.75 0.86 0.81 0.82 0.96 0.88 0.93 0.96 0.95 Loc 0.59 0.63 0.61 0.57 0.43 0.49 0.51 0.46 0.48 0.84"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_98", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 98, "text": "7 1 0.99 Edge-Loc 0.73 0.75 0.74 0.69 0.67 0.68 0.8 0.51 0.62 0.84 0.78 0.81 Edge-Ring 0.92 0.92 0.92 0.75 0.86 0.81 0.82 0.96 0.88 0.93 0.96 0.95 Loc 0.59 0.63 0.61 0.57 0.43 0.49 0.51 0.46 0.48 0.84 0.71 0.77 Near-Full 0.95 0.98 0.96 0.93 0.96 0.96 0.99 0.94 0.96 0.98 0.98 0.98 Random 0.95 0.95 0.95 0.93 0.91 0.91 0.89 0.92 0.91 0.97 0.95 0.96 Scratch 0.81 0.63 0.71 0.65 0.67 0.66 0.55 0.61 0.58 0.81 0.91 0.86 Average 0.86 0.85 0.85 0.8 0.81 0.8 0.78 0.78 0.78 0.91 0.91 0.91 4.1.3. Comparison of Classification Performance of WBM with Different Die Size from Training Data (Model 1 and Model 4) In this paper, we have confirmed that the method based on the number of defect dies per specified region in polar coordinate space as training data can improve the defect pattern classification performance compared to the method based on conventional WBM image data. However, the test results are limited to WBMs of 26 √ó26 in ssize, so the performance cannot be confirmed when the die size or number of dies per wafer is different. To test the scalability of the proposed method, we conducted defect pattern classification on all labeled WM-811K WBMs, regardless of wafer dimension and die size. Ta"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_99", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 99, "text": "r of dies per wafer is different. To test the scalability of the proposed method, we conducted defect pattern classification on all labeled WM-811K WBMs, regardless of wafer dimension and die size. Table 9 summarizes the number of labeled WBMs in WM-811K by defect pattern type. All 25,519 of the 172,950 labeled data, except for the ‚Äònone‚Äô pattern, were resized to 26√ó26. This means that the pixel corresponding to each die in the WBM image was resized to reduce or increase the number of dies. The next step is identical to the process described in Section 3.2: denoise the data, convert them to polar coordinates, and create a classifier that measures the number of defective dies per specified region in polar coordinate space. Additionally, as a comparison group, a classification model was created using the original WBM image without the polar coordinate system conversion. For both models, data were divided by 7:3 for training and testing and then 3-fold cross-validation was performed for modeling. Table 9. The number of labeled WBMs in the WM-811K dataset, excluding 26 √ó26 size WBM. Defect Type Number of Samples Center 4294 Donut 555 Edge-Loc 5189 Edge-Ring 9680 Loc 3593 Near-Full 149 "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_100", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 100, "text": "odeling. Table 9. The number of labeled WBMs in the WM-811K dataset, excluding 26 √ó26 size WBM. Defect Type Number of Samples Center 4294 Donut 555 Edge-Loc 5189 Edge-Ring 9680 Loc 3593 Near-Full 149 Random 866 Scratch 1193 Table 10 shows the classification results for 25,519 WBMs with different sizes than the WBMs used for training. The classifier that used WBM image data as input has an accuracy of 85.58%, while the classifier that used polar spatial information as input has an accuracy of 89.89%. Moreover, the model that used polar spatial information as input outperforms the model that used WBM image data in most other metrics. Both models performed about 2% less accurately than when tested on 26 √ó26 WBMs alone. This is due to the fact that cases with incorrect or ambiguous labels are removed when training and testing on 26√ó26WBMs only. For this test, we used all 25,519 WBMs for testing without removing outlier data, as it would have been inefficient from a time and labor perspective to manually check all 25,519 WBMs. The experiment confirmed that classifying defect patterns by converting WBM image data to polar coordinate data performs better than using WBM image data alone, e"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_101", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 101, "text": "ve to manually check all 25,519 WBMs. The experiment confirmed that classifying defect patterns by converting WBM image data to polar coordinate data performs better than using WBM image data alone, even when using all labeled data in WM-811K without removing outliers. Electronics 2024 ,13, 1360 21 of 32 Therefore, we expect that the proposed classifier can be used without additional training by resizing WBMs that are not the same size as the WBMs used for training. Table 10. Comparison of classification performance for WBM data with different sizes than the WBM for training. Defect TypeModel 1 Model 4 Accuracy Precision Recall F1-Score Accuracy Precision Recall F1-Score Center 0.93 0.93 0.93 0.93 0.95 0.94 0.99 0.96 Donut 0.78 0.78 0.83 0.83 0.91 0.97 0.94 0.95 Edge-Loc 0.8 0.81 0.79 0.79 0.79 0.82 0.84 0.83 Edge-Ring 0.97 0.97 0.96 0.96 0.97 0.94 0.97 0.95 Loc 0.72 0.72 0.71 0.71 0.74 0.86 0.79 0.82 Near-Full 0.87 0.87 0.87 0.87 0.92 0.9 0.95 0.92 Random 0.82 0.82 0.86 0.86 0.83 0.9 0.86 0.88 Scratch 0.36 0.36 0.41 0.41 0.54 0.79 0.58 0.67 Average 0.85 0.81 0.78 0.8 0.9 0.89 0.86 0.87 4.2. Defect Pattern Classifier Based on Polar Coordinate System Input Data and Tree Structure To"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_102", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 102, "text": "0.86 0.88 Scratch 0.36 0.36 0.41 0.41 0.54 0.79 0.58 0.67 Average 0.85 0.81 0.78 0.8 0.9 0.89 0.86 0.87 4.2. Defect Pattern Classifier Based on Polar Coordinate System Input Data and Tree Structure To implement the defect pattern classifier based on the polar coordinate system data and tree structure described in Section 3.3, we first created a binary classifier for each defect pattern. The training data were selected based on the experimental results presented in Section 4.1, using Model 4, which showed the best classification performance. In Section 4.2, we did not classify the defect patterns into eight classes. Instead, we created eight binary classifiers, each for a specific pattern. To achieve this, we implemented a model using support vector machine (SVM), which is a representative machine learning algorithm for binary classification. We then compared its performance with the binary classification model based on the CNN. The training data to test data ratio was set to 7:3 for both SVM and CNN models. The structure of the CNN model is shown in Figure 7 with two output layers. A batch size of 256, a learning rate of 0.01, and 300 epochs were used and three-fold cross-validatio"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_103", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 103, "text": "th SVM and CNN models. The structure of the CNN model is shown in Figure 7 with two output layers. A batch size of 256, a learning rate of 0.01, and 300 epochs were used and three-fold cross-validations were performed. Table 11 shows a comparison of the binary classification performance of the two models. As indicated in Table 11, the CNN model outperforms the SVM model on most performance metrics. Regarding the SVM model, similar to the classification results in Section 4.2, the performance is poor for ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, ‚ÄòRandom‚Äô, and ‚ÄòScratch‚Äô patterns, which are considered highly randomized defect patterns. This is due to SVM‚Äôs binary linear classification model, resulting in low performance for classes with high randomness between patterns. Therefore, we used CNN-based binary classifiers for each node of the tree-structured classifier. Table 11. Comparison of the binary classification performance for 25,519 WBM data. Defect TypeSVM CNN Accuracy Precision Recall F1-Score Accuracy Precision Recall F1-Score Center 0.971 0.928 0.951 0.939 0.988 0.967 0.982 0.974 Donut 1 1 1 1 1 1 1 1 Edge-Loc 0.891 0.753 0.661 0.692 0.948 0.88 0.876 0.878 Edge-Ring 0.976 0.955 0.934 0.944 0.98 0.95"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_104", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 104, "text": "ecision Recall F1-Score Center 0.971 0.928 0.951 0.939 0.988 0.967 0.982 0.974 Donut 1 1 1 1 1 1 1 1 Edge-Loc 0.891 0.753 0.661 0.692 0.948 0.88 0.876 0.878 Edge-Ring 0.976 0.955 0.934 0.944 0.98 0.953 0.953 0.953 Loc 0.855 0.635 0.648 0.641 0.926 0.829 0.756 0.786 Near-Full 0.996 0.988 0.998 0.992 0.99 0.978 0.978 0.978 Random 0.886 0.835 0.651 0.694 0.983 0.966 0.966 0.966 Scratch 0.905 0.78 0.659 0.697 0.961 0.897 0.913 0.905 Average 0.935 0.859 0.813 0.825 0.972 0.934 0.928 0.93 Electronics 2024 ,13, 1360 22 of 32 To implement a tree structure classifier, we first divided the 250 data for each class shown in Table 3 into a 7:3 ratio and stored them separately as training and test data. Then, we created binary classifiers for each of the eight classes by re-labeling the training data as Pattern/Others and training the CNN model. The binary classifiers in the tree struc- ture are ordered sequentially, starting from the pattern with the best binary classification performance in the above experiment, i.e., Donut, Near-Full, Center, Random, Edge-Ring, Scratch, Edge-Loc, and Loc, according to the experimental results. Figure 15 displays the confusion matrix of the binary classificati"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_105", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 105, "text": "ove experiment, i.e., Donut, Near-Full, Center, Random, Edge-Ring, Scratch, Edge-Loc, and Loc, according to the experimental results. Figure 15 displays the confusion matrix of the binary classification results for each level of the tree structure. The model‚Äôs overall classification accuracy was 94%, with successful class predictions for Donut (75), Near-Full (75), Center (72), Random (73), Edge-Ring (72), Scratch (71), Edge-Loc (69), and Loc (57), totaling 564. In total, 36 data points out of 600 WBMs failed to predict. Electronics 2024 , 13, 1360 23 of 32 Figure 15. Confusion matrix for each step of Model 5. Table 12. Classi Ô¨Åcation performance comparison of Model 4 and Model 5. Defect Type Model 4 Model 5 Accuracy Precision Recall F1-Score Accuracy Precision Recall F1-Score Center 0.97 0.93 0.97 0.95 0.98 0.99 0.98 0.99 Donut 1 0.97 1 0.99 1 1 1 1 Edge-Loc 0.78 0.84 0.78 0.81 0.95 0.96 0.93 0.95 Edge-Ring 0.96 0.93 0.96 0.95 0.99 0.99 0.99 0.99 Loc 0.7 0.84 0.71 0.77 0.89 0.58 0.7 0.64 Near-Full 0.97 0.98 0.98 0.98 0.99 1 0.99 0.99 Random 0.95 0.97 0.95 0.96 0.98 0.99 0.99 0.99 Scratch 0.91 0.81 0.91 0.86 0.94 0.97 0.93 0.95 Average 0.91 0.91 0.91 0.91 0.97 0.93 0.94 0.94 Howeve"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_106", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 106, "text": ".64 Near-Full 0.97 0.98 0.98 0.98 0.99 1 0.99 0.99 Random 0.95 0.97 0.95 0.96 0.98 0.99 0.99 0.99 Scratch 0.91 0.81 0.91 0.86 0.94 0.97 0.93 0.95 Average 0.91 0.91 0.91 0.91 0.97 0.93 0.94 0.94 However, this model has a limitation in that it cannot be used to classify mixed defect patterns with more than two defects. Additionally, the classi Ô¨Åcation result of the entire sample is obtained by sequentially connecting classi Ô¨Åers, resulting in varying amounts of data to be classi Ô¨Åed depending on the position of each binary classi Ô¨Åer. For instance, in this experiment, the number of data inputs to the classi Ô¨Åer at the Ô¨Årst node was 600, while the number of data inputs to the classi Ô¨Åer at the last node was only 72, which accounts for approximately 12% of the initial input data. Therefore, it is not reasonable to accept the evaluation metrics presented in Table 12 as a one-to-one comparison in such a situation with a signi Ô¨Åcant variation in the amount of input data. Further analysis is necessary to address this issue after securing more comprehensive data. Similar to the extensibility experiment of Model 4, we used Model 5 to classify 25,519 data labeled with defect pa ttern type amo"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_107", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 107, "text": "ecessary to address this issue after securing more comprehensive data. Similar to the extensibility experiment of Model 4, we used Model 5 to classify 25,519 data labeled with defect pa ttern type among WBMs other than 26 √ó 26 in size. The de- noising and pre-processing process, including how to convert the original data to 26 √ó 26, and the ratio of training and testing subjects were the same as in Model 4. In this Figure 15. Confusion matrix for each step of Model 5. Table 12 compares the classification results of Model 4 in Section 4.1 with those of Model 5 which used a tree structure. Both models use the number of defect dies per specified region in polar coordinate space as training data, so there is no difference in the type of data trained, only the structure of the classifier. Table 12 shows that Model 5 outperforms Model 4 on most metrics. The table displays the classification results for each defect type in Model 5. These results are based on the binary classification results of each node in the tree structure. The average value is the arithmetic mean of the results for each defect type. The overall classification accuracy is 94%, while the arithmetic mean of the accuracy "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_108", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 108, "text": "of each node in the tree structure. The average value is the arithmetic mean of the results for each defect type. The overall classification accuracy is 94%, while the arithmetic mean of the accuracy is 97%, which is expressed differently. Despite this, Model 5 still exhibits higher classification performance than Model 4. It has been confirmed that using a tree- structured method to classify defect patterns sequentially, based on classifiers with high binary classification performance, can improve the accuracy of defect pattern classification. Electronics 2024 ,13, 1360 23 of 32 Table 12. Classification performance comparison of Model 4 and Model 5. Defect TypeModel 4 Model 5 Accuracy Precision Recall F1-Score Accuracy Precision Recall F1-Score Center 0.97 0.93 0.97 0.95 0.98 0.99 0.98 0.99 Donut 1 0.97 1 0.99 1 1 1 1 Edge-Loc 0.78 0.84 0.78 0.81 0.95 0.96 0.93 0.95 Edge-Ring 0.96 0.93 0.96 0.95 0.99 0.99 0.99 0.99 Loc 0.7 0.84 0.71 0.77 0.89 0.58 0.7 0.64 Near-Full 0.97 0.98 0.98 0.98 0.99 1 0.99 0.99 Random 0.95 0.97 0.95 0.96 0.98 0.99 0.99 0.99 Scratch 0.91 0.81 0.91 0.86 0.94 0.97 0.93 0.95 Average 0.91 0.91 0.91 0.91 0.97 0.93 0.94 0.94 However, this model has a limitation i"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_109", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 109, "text": "8 0.99 1 0.99 0.99 Random 0.95 0.97 0.95 0.96 0.98 0.99 0.99 0.99 Scratch 0.91 0.81 0.91 0.86 0.94 0.97 0.93 0.95 Average 0.91 0.91 0.91 0.91 0.97 0.93 0.94 0.94 However, this model has a limitation in that it cannot be used to classify mixed defect patterns with more than two defects. Additionally, the classification result of the entire sample is obtained by sequentially connecting classifiers, resulting in varying amounts of data to be classified depending on the position of each binary classifier. For instance, in this experiment, the number of data inputs to the classifier at the first node was 600, while the number of data inputs to the classifier at the last node was only 72, which accounts for approximately 12% of the initial input data. Therefore, it is not reasonable to accept the evaluation metrics presented in Table 12 as a one-to-one comparison in such a situation with a significant variation in the amount of input data. Further analysis is necessary to address this issue after securing more comprehensive data. Similar to the extensibility experiment of Model 4, we used Model 5 to classify 25,519 data labeled with defect pattern type among WBMs other than 26 √ó26 in siz"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_110", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 110, "text": "after securing more comprehensive data. Similar to the extensibility experiment of Model 4, we used Model 5 to classify 25,519 data labeled with defect pattern type among WBMs other than 26 √ó26 in size. The denoising and pre-processing process, including how to convert the original data to 26√ó26, and the ratio of training and testing subjects were the same as in Model 4. In this experiment, the order of the binary classifiers in the tree structure was determined by placing the classifiers with the best binary classification performance at the top nodes sequentially. However, the order of the classifiers differed from that obtained using only the 26 √ó26 WBM. For this experiment, each binary classifier was placed in the following order: Near-Full, Donut, Random, Center, Scratch, Edge-Ring, Loc, and Edge-Loc. The confusion matrix of the binary classification results for each level of the tree structure is presented in Figure 16. Out of 7658 test data, 6225 were successfully predicted, while 1433 data failed to be predicted, resulting in an overall classification accuracy of 81.2%. The predicted data are shown as Near-Full: 35, Donut: 129, Random: 181, Center: 1194, Scratch: 135, Edge-"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_111", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 111, "text": "le 1433 data failed to be predicted, resulting in an overall classification accuracy of 81.2%. The predicted data are shown as Near-Full: 35, Donut: 129, Random: 181, Center: 1194, Scratch: 135, Edge-Ring: 2762, Loc: 671, Edge-Loc: 1118. The binary classifier exhibited the lowest performance, with the most misclassifications occurring in the ‚ÄòEdge-Loc‚Äô pattern classification. There was also a noticeable error in classifying ‚ÄòEdge-Loc‚Äô patterns as ‚ÄòOther‚Äô, but especially in misclassifying WBMs that were not labeled as ‚ÄòEdge-Loc‚Äô as ‚ÄòEdge-Loc‚Äô. Table 13 summarizes the evaluation metric values of the classifier for each type of defect. As mentioned in the previous experiment, the classification results for each defect type shown in this table are based on the binary classification results of each node in the tree structure. The average value is the arithmetic mean of the results for each defect type. The table displays an arithmetic mean accuracy of 93%, while the overall classification accuracy is 81.2%. The binary classifiers have an accuracy rate of at least 93% to 99%, with the exception of the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pattern classifiers. However, the ‚ÄòEdge-Loc‚Äô pattern classifier ha"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_112", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 112, "text": "ccuracy is 81.2%. The binary classifiers have an accuracy rate of at least 93% to 99%, with the exception of the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pattern classifiers. However, the ‚ÄòEdge-Loc‚Äô pattern classifier has an accuracy rate of only 77%. It is expected that there is a trade-off between the precision and recall values among the evaluation metrics, but the binary classifiers in Model 5 showed too much difference in these values for each classifier. For example, the classifier for the ‚ÄòScratch‚Äô pattern had a precision value of 0.92 and a recall value of 0.40, resulting in a large difference. In other Electronics 2024 ,13, 1360 24 of 32 words, the classifier‚Äôs performance was poor as it failed to classify more patterns as ‚ÄòScratch‚Äô than those that were not. The F1-Score value was only 0.56. Electronics 2024 , 13, 1360 24 of 32 experiment, the order of the binary classi Ô¨Åers in the tree structure was determined by placing the classi Ô¨Åers with the best binary classi Ô¨Åcation performance at the top nodes se- quentially. However, the order of the classi Ô¨Åers diÔ¨Äered from that obtained using only the 26 √ó 26 WBM. For this experiment, each binary classi Ô¨Åer was placed in the following order: Near-F"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_113", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 113, "text": "nodes se- quentially. However, the order of the classi Ô¨Åers diÔ¨Äered from that obtained using only the 26 √ó 26 WBM. For this experiment, each binary classi Ô¨Åer was placed in the following order: Near-Full, Donut, Random, Center, Sc ratch, Edge-Ring, Loc, and Edge-Loc. The confusion matrix of the bina ry classification results for each level of the tree struc- ture is presented in Figure 16. Out of 7658 test data, 6225 were successfully predicted, while 1433 data failed to be predicted, resulting in an overall classification accuracy of 81.2%. The predicted data are shown as Near-Full: 35, Donut: 129, Random: 181, Center: 1194, Scratch: 135, Edge-Ring: 2762, Loc: 671, Edge-Loc: 1118. The binary classifier exhibited the lowest performance, with the most misc lassifications occurring in the ‚ÄòEdge-Loc‚Äô pattern classifica- tion. There was also a noticeable error in cla ssifying ‚ÄòEdge-Loc‚Äô patterns as ‚ÄòOther‚Äô, but es- pecially in misclassifying WBMs that were not labeled as ‚ÄòEdge- Loc‚Äô as ‚ÄòEdge-Loc‚Äô. Figure 16. Confusion matrix for each step of Model 5 using 25,519 data. Table 13 summarizes the evaluation metric values of the classi Ô¨Åer for each type of defect. As mentioned in the previou"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_114", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 114, "text": "ge-Loc‚Äô. Figure 16. Confusion matrix for each step of Model 5 using 25,519 data. Table 13 summarizes the evaluation metric values of the classi Ô¨Åer for each type of defect. As mentioned in the previous experiment, the classi Ô¨Åcation results for each defect type shown in this table are based on the binary classi Ô¨Åcation results of each node in the tree structure. The average value is the arithmet ic mean of the results for each defect type. The table displays an arithmetic mean accuracy of 93%, while the overall classi Ô¨Åcation accuracy is 81.2%. The binary classi Ô¨Åers have an accuracy rate of at least 93% to 99%, with the exception of the ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa ttern classi Ô¨Åers. However, the ‚ÄòEdge-Loc‚Äô pat- tern classi Ô¨Åer has an accuracy rate of only 77%. It is expected that there is a trade-o Ô¨Ä between the precision and recall values among the evaluation metrics, but the binary classi Ô¨Åers in Model 5 showed too much di Ô¨Äerence in these values for each classi Ô¨Åer. For example, the classi Ô¨Åer for the ‚ÄòScratch‚Äô pa ttern had a precision value of 0.92 and a recall value of 0.40, resulting in a large di Ô¨Äerence. In other words, the classi Ô¨Åe r ‚Äô s p e r f o r m a n c e w a s p o o r a"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_115", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 115, "text": "assi Ô¨Åer for the ‚ÄòScratch‚Äô pa ttern had a precision value of 0.92 and a recall value of 0.40, resulting in a large di Ô¨Äerence. In other words, the classi Ô¨Åe r ‚Äô s p e r f o r m a n c e w a s p o o r a s i t f a i l e d t o c l a s s i f y m o r e p a tterns as ‚ÄòScratch‚Äô than those that were not. The F1-Score value was only 0.56. The tree-based Model 5 showed higher classi Ô¨Åcation performance than Model 4 in the defect pa ttern classi Ô¨Åcation problem of 26 √ó 26 WBMs, but in the classi Ô¨Åcation problem of WBMs of di Ô¨Äerent sizes, the accuracy was 8.69% lower than that of Model 4. The Figure 16. Confusion matrix for each step of Model 5 using 25,519 data. Table 13. Classification performance of Model 5 using 25,519 WBM data of different sizes. Defect TypeModel 5 (Using Different Sizes of WBM Data) Accuracy Precision Recall F1-Score Center 0.97 0.92 0.93 0.93 Donut 0.99 0.90 0.77 0.83 Edge-Loc 0.77 0.78 0.88 0.83 Edge-Ring 0.93 0.92 0.95 0.93 Loc 0.85 0.86 0.68 0.76 Near-Full 0.99 0.95 0.78 0.85 Random 0.99 0.90 0.70 0.79 Scratch 0.96 0.92 0.40 0.56 Average 0.93 0.89 0.76 0.81 The tree-based Model 5 showed higher classification performance than Model 4 in the defect pattern classificati"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_116", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 116, "text": " 0.85 Random 0.99 0.90 0.70 0.79 Scratch 0.96 0.92 0.40 0.56 Average 0.93 0.89 0.76 0.81 The tree-based Model 5 showed higher classification performance than Model 4 in the defect pattern classification problem of 26 √ó26 WBMs, but in the classification problem of WBMs of different sizes, the accuracy was 8.69% lower than that of Model 4. The classifiers exhibited a significant difference in recall values for each defect type, resulting in a lower overall F1-Score. Table 13 shows the variation in data quantity among each class in the training process of the binary classifier used in the corresponding tree structure and it is estimated to be a factor affecting the performance of the classifier. In summary, if the process of learning the features of the defect pattern class with a small amount of data is heavily influenced by the data trained as ‚ÄòOthers‚Äô with a relatively large amount of data, it is expected to be affected by the data imbalance problem. This can cause a stronger tendency to classify as ‚ÄòOthers‚Äô in the binary classification process. In general, if there is a data imbalance problem in the original data, it can be solved by using the data augmentation method. However, in"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_117", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 117, "text": "to classify as ‚ÄòOthers‚Äô in the binary classification process. In general, if there is a data imbalance problem in the original data, it can be solved by using the data augmentation method. However, in Model 5, the degree of data imbalance varies depending on the location of the binary classifier. Electronics 2024 ,13, 1360 25 of 32 As a result, it is considered that Model 4 is more appropriate than Model 5 in terms of the scalability of the classification task. 4.3. Ensemble Models for Mixed-Fault Pattern Classification To implement the mixed defect pattern classifier using polar coordinate system data and the ensemble structure presented in Section 3.4, we selected the training data of Model 4 since it demonstrated the best classification performance in the experimental results shown in Section 4.1. Then, for each class, we relabeled them into two classes: corresponding pattern and other patterns, and generated binary classification models for each of the eight defect patterns (Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, and Scratch). The CNN-model-based binary classifiers have the CNN structure depicted in Figure 7 with two output layers. The training data to test"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_118", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 118, "text": ", Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, and Scratch). The CNN-model-based binary classifiers have the CNN structure depicted in Figure 7 with two output layers. The training data to test data ratio was set to 7:3, with a batch size of 256, a learning rate of 0.01, and 300 epochs. And three-fold cross-validation was conducted. The binary classification models were connected in parallel, and the output from each model for each test WBM was aggregated for a total of eight outputs. In this step, the classification result is determined by the soft-voting ensemble method and we set 0.7 as the threshold value. From the original data of 26 √ó26 in size shown in Table 1, we excluded the ‚Äònone‚Äô pattern and used the remaining 877 WBMs as test data. Since these data are the original data before removing the outlier data, it is appropriate to use them as test data for the model because they contain images that are difficult to judge with a specific label or contain mixed defect patterns, as shown in Figure 4. As stated before, the dataset considered in this paper is labeled with only one defect pattern per WBM, so the classification accuracy of mixed defects cannot be evaluated usi"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_119", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 119, "text": "s, as shown in Figure 4. As stated before, the dataset considered in this paper is labeled with only one defect pattern per WBM, so the classification accuracy of mixed defects cannot be evaluated using this dataset. To evaluate the model, we temporarily generated WBMs with typical defect types, as shown in Figure 17, to test the classification of the mixed-pattern WBMs. As shown in the figure, the mixed patterns were output as [‚ÄòCenter‚Äô, ‚ÄòEdge-Ring‚Äô], [‚ÄòCenter‚Äô, ‚ÄòScratch‚Äô], respectively, to confirm that the model classified the mixed-defect patterns correctly. Electronics 2024 , 13, 1360 26 of 32 Table 14 shows the mixed-type pa ttern classi Ô¨Åcation results of the 877 WBMs. The ‚ÄòLabeled Defect Type‚Äô column indicates the type of defect pa ttern labeled in the dataset. The table presents the pa ttern classi Ô¨Åcation results for the 877 test data points and the corresponding defect types. In this model, 161 data points labeled as ‚ÄòCenter‚Äô, ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô out of the total 877 WBMs were classi Ô¨Åed as ‚Äònone‚Äô, which means that there is no defect. The data classi Ô¨Åed as having no defect pa ttern mostly consisted of im- ages like those shown in Figure 4, which are di Ô¨Écult"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_120", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 120, "text": " 877 WBMs were classi Ô¨Åed as ‚Äònone‚Äô, which means that there is no defect. The data classi Ô¨Åed as having no defect pa ttern mostly consisted of im- ages like those shown in Figure 4, which are di Ô¨Écult to identify as having any defect pat- tern. Therefore, it is assumed that all eight binary classi Ô¨Åers classi Ô¨Åed them as not belong- ing to any class. Table 14. Classi Ô¨Åcation results of mixed-type defect pa tterns. Labeled Defect Type No Defect Pa ttern Single Defect Pa ttern Two Types of Mixed-Defect Pa tterns Sum Center 22 68 0 90 Donut 0 1 0 1 Edge-Loc 59 230 7 296 Edge-Ring 0 31 0 31 Loc 66 214 17 297 Near-Full 0 16 0 16 Random 0 74 0 74 Scratch 14 52 6 72 Sum 161 686 30 877 Figure 17. Example of pa ttern classi Ô¨Åcation result of WBM with arti Ô¨Åcially generated mixed-defect pattern. Figure 18 shows the confusion matrix for 686 pa tterns that were classi Ô¨Åed as a single- defect pa ttern. The most frequent pa tterns were ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns, which the classi Ô¨Åer predicted as other pa tterns. The reason for this can be con Ô¨Årmed by checking the WBMs that were classi Ô¨Åed diÔ¨Äerently from the labeling values. Figure 19 presents some of the WBMs that the classi Ô¨Åer classi Ô¨Åe"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_121", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 121, "text": "s other pa tterns. The reason for this can be con Ô¨Årmed by checking the WBMs that were classi Ô¨Åed diÔ¨Äerently from the labeling values. Figure 19 presents some of the WBMs that the classi Ô¨Åer classi Ô¨Åed diÔ¨Äerently from the label. This Ô¨Ågure illustrates that there are instances where the label and pa ttern shape are inappropriate or uncertain. In other words, it seems that the error is caused by the error in labeling rather than the error in the classi Ô¨Åer. Figure 17. Example of pattern classification result of WBM with artificially generated mixed- defect pattern. Table 14 shows the mixed-type pattern classification results of the 877 WBMs. The ‚ÄòLabeled Defect Type‚Äô column indicates the type of defect pattern labeled in the dataset. The table presents the pattern classification results for the 877 test data points and the corresponding defect types. In this model, 161 data points labeled as ‚ÄòCenter‚Äô, ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô out of the total 877 WBMs were classified as ‚Äònone‚Äô, which means that there is no defect. The data classified as having no defect pattern mostly consisted of images Electronics 2024 ,13, 1360 26 of 32 like those shown in Figure 4, which are difficult to "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_122", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 122, "text": "hich means that there is no defect. The data classified as having no defect pattern mostly consisted of images Electronics 2024 ,13, 1360 26 of 32 like those shown in Figure 4, which are difficult to identify as having any defect pattern. Therefore, it is assumed that all eight binary classifiers classified them as not belonging to any class. Table 14. Classification results of mixed-type defect patterns. Labeled Defect TypeNo Defect Pattern Single Defect PatternTwo Types of Mixed-Defect PatternsSum Center 22 68 0 90 Donut 0 1 0 1 Edge-Loc 59 230 7 296 Edge-Ring 0 31 0 31 Loc 66 214 17 297 Near-Full 0 16 0 16 Random 0 74 0 74 Scratch 14 52 6 72 Sum 161 686 30 877 Figure 18 shows the confusion matrix for 686 patterns that were classified as a single- defect pattern. The most frequent patterns were ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns, which the classifier predicted as other patterns. The reason for this can be confirmed by checking the WBMs that were classified differently from the labeling values. Figure 19 presents some of the WBMs that the classifier classified differently from the label. This figure illustrates that there are instances where the label and pattern shape are inappropriat"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_123", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 123, "text": "lues. Figure 19 presents some of the WBMs that the classifier classified differently from the label. This figure illustrates that there are instances where the label and pattern shape are inappropriate or uncertain. In other words, it seems that the error is caused by the error in labeling rather than the error in the classifier. Electronics 2024 , 13, 1360 27 of 32 Figure 18. Confusion matrix of Model 6 for 686 patterns that were classified as a single-defect pattern. Figure 19. Prediction results of Model 6 that do not match the labels in the dataset. The classi Ô¨Åer predicted 30 WBMs out of a total of 877 WBMs as mixed-defect pa tterns. These pa tterns were originally labeled as ‚ÄòEdge-Loc‚Äô , ‚ÄòLoc‚Äô, and ‚ÄòScratch ‚Äô. Figure 20 shows an example of a WBM image that was predicted to be a mixed-defect pa ttern. As shown in the Ô¨Ågure, the proposed classi Ô¨Åer correctly classi Ô¨Åed the mixed-defect pa tterns in the WBM image without any additional clustering process. This demonstrates the feasibility of categorizing mixed-defect pa tterns using a model that combines binary classi Ô¨Åers built for each of the eight classes in a parallel stru cture. Figure 21 shows an example of a mixed- defect"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_124", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 124, "text": "bility of categorizing mixed-defect pa tterns using a model that combines binary classi Ô¨Åers built for each of the eight classes in a parallel stru cture. Figure 21 shows an example of a mixed- defect pa ttern that the proposed model judges as a mixed-defect pa ttern, but the result is ambiguous depending on the engineer‚Äôs judgment. Figure 18. Confusion matrix of Model 6 for 686 patterns that were classified as a single-defect pattern. The classifier predicted 30 WBMs out of a total of 877 WBMs as mixed-defect patterns. These patterns were originally labeled as ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô. Figure 20 shows an example of a WBM image that was predicted to be a mixed-defect pattern. As shown in the figure, the proposed classifier correctly classified the mixed-defect patterns in the WBM image without any additional clustering process. This demonstrates the feasibility of categorizing mixed-defect patterns using a model that combines binary classifiers built for each of the eight classes in a parallel structure. Figure 21 shows an example of a mixed- defect pattern that the proposed model judges as a mixed-defect pattern, but the result is ambiguous depending on the engineer‚Äôs judg"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_125", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 125, "text": "es in a parallel structure. Figure 21 shows an example of a mixed- defect pattern that the proposed model judges as a mixed-defect pattern, but the result is ambiguous depending on the engineer‚Äôs judgment. Electronics 2024 ,13, 1360 27 of 32 Electronics 2024 , 13, 1360 27 of 32 Figure 18. Confusion matrix of Model 6 for 686 patterns that were classified as a single-defect pattern. Figure 19. Prediction results of Model 6 that do not match the labels in the dataset. The classi Ô¨Åer predicted 30 WBMs out of a total of 877 WBMs as mixed-defect pa tterns. These pa tterns were originally labeled as ‚ÄòEdge-Loc‚Äô , ‚ÄòLoc‚Äô, and ‚ÄòScratch ‚Äô. Figure 20 shows an example of a WBM image that was predicted to be a mixed-defect pa ttern. As shown in the Ô¨Ågure, the proposed classi Ô¨Åer correctly classi Ô¨Åed the mixed-defect pa tterns in the WBM image without any additional clustering process. This demonstrates the feasibility of categorizing mixed-defect pa tterns using a model that combines binary classi Ô¨Åers built for each of the eight classes in a parallel stru cture. Figure 21 shows an example of a mixed- defect pa ttern that the proposed model judges as a mixed-defect pa ttern, but the result is amb"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_126", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 126, "text": "rs built for each of the eight classes in a parallel stru cture. Figure 21 shows an example of a mixed- defect pa ttern that the proposed model judges as a mixed-defect pa ttern, but the result is ambiguous depending on the engineer‚Äôs judgment. Figure 19. Prediction results of Model 6 that do not match the labels in the dataset. Electronics 2024 , 13, 1360 28 of 32 Figure 20. Examples of WBMs that are correctly predicted as having mixed-defect pa tterns. Figure 21. Examples of mis-predicted mixed-defect pa tterns. Both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns have the common feature that the defects are clus- tered in a speci Ô¨Åc area, but the defect pa ttern is located at the edge of the wafer in the case of ‚ÄòEdge-Loc‚Äô and inside the wafer in the case of ‚ÄòLoc‚Äô, so the pa tterns can be classi Ô¨Åed based on these features. However, if a defect pa ttern is located on the WBM at the bound- ary between the edge and the inside of the wafer, even if there is only one characteristic defect pa ttern, the mixed-defect pa ttern classi Ô¨Åer connected in parallel will determine that both the ‚ÄòEdge-Loc‚Äô pa ttern classi Ô¨Åer and the ‚ÄòLoc‚Äô pa ttern classi Ô¨Åer are defect pa tterns of the same class. In this sce"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_127", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 127, "text": "mixed-defect pa ttern classi Ô¨Åer connected in parallel will determine that both the ‚ÄòEdge-Loc‚Äô pa ttern classi Ô¨Åer and the ‚ÄòLoc‚Äô pa ttern classi Ô¨Åer are defect pa tterns of the same class. In this scenario, the classi Ô¨Åer‚Äôs output layer extrac ts two classes, and a WBM with a single characteristic defect pa ttern can be classi Ô¨Åed as a mixed-defect pa ttern. When dealing with a combination of ‚ÄòCenter‚Äô and ‚ÄòLoc‚Äô, a single-defect pa ttern‚Äôs classi Ô¨Å- cation as a mixed-defect pa ttern depends on its spatial location. This issue requires further veriÔ¨Åcation and research based on securing data accumulated through the process of la- beling mixed-type defect pa tterns according to the engineer‚Äôs judgment. 5. Discussion The experimental results of six models con Ô¨Årm that the proposed polar coordinate system conversion method and pre-processing method can improve the WBM defect pat- tern classi Ô¨Åcation performance. In examining the confusion matrix of Model 1, which was trained on the WBM image itself, it be comes apparent that the majority of Figure 20. Examples of WBMs that are correctly predicted as having mixed-defect patterns. Electronics 2024 , 13, 1360 28 of 32 Figure 20. Examples of"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_128", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 128, "text": " itself, it be comes apparent that the majority of Figure 20. Examples of WBMs that are correctly predicted as having mixed-defect patterns. Electronics 2024 , 13, 1360 28 of 32 Figure 20. Examples of WBMs that are correctly predicted as having mixed-defect pa tterns. Figure 21. Examples of mis-predicted mixed-defect pa tterns. Both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô pa tterns have the common feature that the defects are clus- tered in a speci Ô¨Åc area, but the defect pa ttern is located at the edge of the wafer in the case of ‚ÄòEdge-Loc‚Äô and inside the wafer in the case of ‚ÄòLoc‚Äô, so the pa tterns can be classi Ô¨Åed based on these features. However, if a defect pa ttern is located on the WBM at the bound- ary between the edge and the inside of the wafer, even if there is only one characteristic defect pa ttern, the mixed-defect pa ttern classi Ô¨Åer connected in parallel will determine that both the ‚ÄòEdge-Loc‚Äô pa ttern classi Ô¨Åer and the ‚ÄòLoc‚Äô pa ttern classi Ô¨Åer are defect pa tterns of the same class. In this scenario, the classi Ô¨Åer‚Äôs output layer extrac ts two classes, and a WBM with a single characteristic defect pa ttern can be classi Ô¨Åed as a mixed-defect pa ttern. When dealing with a combinati"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_129", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 129, "text": "n this scenario, the classi Ô¨Åer‚Äôs output layer extrac ts two classes, and a WBM with a single characteristic defect pa ttern can be classi Ô¨Åed as a mixed-defect pa ttern. When dealing with a combination of ‚ÄòCenter‚Äô and ‚ÄòLoc‚Äô, a single-defect pa ttern‚Äôs classi Ô¨Å- cation as a mixed-defect pa ttern depends on its spatial location. This issue requires further veriÔ¨Åcation and research based on securing data accumulated through the process of la- beling mixed-type defect pa tterns according to the engineer‚Äôs judgment. 5. Discussion The experimental results of six models con Ô¨Årm that the proposed polar coordinate system conversion method and pre-processing method can improve the WBM defect pat- tern classi Ô¨Åcation performance. In examining the confusion matrix of Model 1, which was trained on the WBM image itself, it be comes apparent that the majority of Figure 21. Examples of mis-predicted mixed-defect patterns. Both ‚ÄòEdge-Loc‚Äô and ‚ÄòLoc‚Äô patterns have the common feature that the defects are clustered in a specific area, but the defect pattern is located at the edge of the wafer in Electronics 2024 ,13, 1360 28 of 32 the case of ‚ÄòEdge-Loc‚Äô and inside the wafer in the case of ‚ÄòLoc‚Äô, so th"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_130", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 130, "text": " clustered in a specific area, but the defect pattern is located at the edge of the wafer in Electronics 2024 ,13, 1360 28 of 32 the case of ‚ÄòEdge-Loc‚Äô and inside the wafer in the case of ‚ÄòLoc‚Äô, so the patterns can be classified based on these features. However, if a defect pattern is located on the WBM at the boundary between the edge and the inside of the wafer, even if there is only one characteristic defect pattern, the mixed-defect pattern classifier connected in parallel will determine that both the ‚ÄòEdge-Loc‚Äô pattern classifier and the ‚ÄòLoc‚Äô pattern classifier are defect patterns of the same class. In this scenario, the classifier‚Äôs output layer extracts two classes, and a WBM with a single characteristic defect pattern can be classified as a mixed- defect pattern. When dealing with a combination of ‚ÄòCenter‚Äô and ‚ÄòLoc‚Äô, a single-defect pattern‚Äôs classification as a mixed-defect pattern depends on its spatial location. This issue requires further verification and research based on securing data accumulated through the process of labeling mixed-type defect patterns according to the engineer‚Äôs judgment. 5. Discussion The experimental results of six models confirm that the propos"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_131", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 131, "text": " securing data accumulated through the process of labeling mixed-type defect patterns according to the engineer‚Äôs judgment. 5. Discussion The experimental results of six models confirm that the proposed polar coordinate system conversion method and pre-processing method can improve the WBM defect pat- tern classification performance. In examining the confusion matrix of Model 1, which was trained on the WBM image itself, it becomes apparent that the majority of misclassifications were found in the classes associated with ‚ÄòEdge-Loc‚Äô, ‚ÄòLoc‚Äô, and ‚ÄòScratch‚Äô. These classes present limitations in terms of specifying the location where the defect patterns are dis- tributed. The defect die clusters‚Äô spatial randomness during the WBM image learning process, as described in Section 3.3, led to lower classification accuracy in these classes. Model 3 aimed to solve the problem by using polar coordinate transformed inputs but this approach actually resulted in a decrease in the classification accuracy. The reason for this is that the number of points corresponding to a single defective die is relatively small compared to the polar coordinate space. When the resolution of the location informatio"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_132", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 132, "text": "acy. The reason for this is that the number of points corresponding to a single defective die is relatively small compared to the polar coordinate space. When the resolution of the location information expressed in 26 √ó26 is converted to polar coordinate space, the features of the defective die are not properly learned. To address this limitation, Model 4 applies a pre-processing process that divides the polar coordinate space into regions of a certain size and measures the number of defective dies included per specified region. This model has the highest classification accuracy among the models compared in this paper. We confirmed that the model is applicable to the defect pattern classification test of WBMs with different die sizes than the WBM used for training. For the tree-structured model (Model 5), which connects binary classifiers sequentially instead of using a single CNN, the classification accuracy is 94%. This is an improvement over Model 4, which classifies eight defect patterns at once. However, in the defect pattern classification test of 25,519 WBMs with different die sizes than the ones used for training, the accuracy is lower than that of Model 4. This is likely d"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_133", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 133, "text": "tterns at once. However, in the defect pattern classification test of 25,519 WBMs with different die sizes than the ones used for training, the accuracy is lower than that of Model 4. This is likely due to the model structure‚Äôs inability to overcome the data imbalance problem of the binary classifier itself and the variation in the amount and characteristics of the test data depending on the node where the binary classifier is located. Therefore, for the single defect pattern classification problem of WBM, Model 4 is considered to be the most appropriate among the models tested in this paper. Table 15 shows the performance comparison of the model proposed in this paper with the results of several studies that classify WBM defect patterns using the WM-811K dataset. C.-Y. Wang et al. [ 13] classified defect patterns by implementing a general model using the MobileNet V2 algorithm and a lightweight model with 24.77% fewer parameters. T. Tziolas et al. [ 18] proposed a methodology for classifying WM-811K by using different data processing techniques for each class to address the issue of data imbalance. Ebayyeh et al. [ 19] proposed a data augmentation method for classifying WM-811K by"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_134", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 134, "text": "sifying WM-811K by using different data processing techniques for each class to address the issue of data imbalance. Ebayyeh et al. [ 19] proposed a data augmentation method for classifying WM-811K by using different data processing techniques for each class to address the issue of data imbalance. Q. Xu et al. [ 22] utilized a model based on ResNet18 with the CBAM algorithm and classified the defect patterns using the cosine normalization method to overcome the data imbalance problem. Although these studies used the same dataset, each model was trained and tested on different data. In some cases, all labeled data in the dataset were used for testing. However, if the number of test data is increased through data augmentation, it Electronics 2024 ,13, 1360 29 of 32 becomes difficult to verify the objectivity of the labels of the augmented data. However, if we disregard this point and compare the models‚Äô classification accuracy, the model proposed in this paper has an accuracy 2.56% lower than that of the best model in the existing results. Nevertheless, the F1-Score of the proposed model is higher than that of the comparison models, indicating that the polar coordinate system transfo"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_135", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 135, "text": " than that of the best model in the existing results. Nevertheless, the F1-Score of the proposed model is higher than that of the comparison models, indicating that the polar coordinate system transformation and the data pre-processing method presented in this paper have achieved significant results in defect pattern classification. Table 15. Comparison with models presented in other papers. Model Algorithm Data F1-Score Accuracy C.-Y. Wang, T.-H. Tsai [13] MobileNet V2Labeled WM-811K data (25,519) train: 70%, test: 30%- 96.56% C.-Y. Wang, T.-H. Tsai [13] (lightweight model)MobileNet V2 (simplified version)Labeled WM-811K data (25,519) train: 70%, test: 30%- 93.26% T. Tziolas et al. [18] Modified CNNRandomly select data after data augmentation using rotation train: 832 for 9 classes test: 45 for 9 classes0.93 95.3% Ebayyeh et al. [19] WaferCaps WM-811K train: 22,137, test: 2165 0.77 78.2% Ebayyeh et al. [19] WaferCapsData augmentation using DCGAN train: 63,200, test: 15,6000.91 91.4% Q. Xu, N. Yu, F. Essaf [22]Add CBAM based on ResNet-18, Cosine normalization algorithmLabeled WM-811K data (25,519) + 10,000 ‚Äònone‚Äô pattern data train: 75%, test: 25%- 95.5% Proposed Model 4 Modified C"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_136", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 136, "text": ". Xu, N. Yu, F. Essaf [22]Add CBAM based on ResNet-18, Cosine normalization algorithmLabeled WM-811K data (25,519) + 10,000 ‚Äònone‚Äô pattern data train: 75%, test: 25%- 95.5% Proposed Model 4 Modified CNN26√ó26 data (Table 3) train: 70%, test: 30%0.96 91.33% Proposed Model 4 Modified CNNLabeled WM-811K data (25,519) train: 70%, test: 30%0.87 89.89% Proposed Model 5 Modified CNN26√ó26 data (Table 3) train: 70%, test: 30%0.94 94% If the goal of this paper is simply to improve the accuracy of WBM defect pattern classification using pattern recognition techniques based on a dataset, the numbers of each performance metric can be said to represent the absolute performance. However, the ultimate aim of WBM defect pattern classification is to provide information that can quickly identify errors in the semiconductor process by identifying the type of defect pattern. Therefore, it is important to not only classify the single-defect patterns but also to identify WBMs labeled as having only one defect but whose defect pattern classification is ambiguous due to the overlap of multiple defects. To solve this problem, we implemented a model (Model 6) that can classify mixed-defect patterns by ensembl"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_137", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 137, "text": " but whose defect pattern classification is ambiguous due to the overlap of multiple defects. To solve this problem, we implemented a model (Model 6) that can classify mixed-defect patterns by ensembling binary classifiers in parallel to classify defect patterns without additional clustering of defect patterns. The model classified about 30 WBMs out of 877 WBMs as containing multiple defects. This number of instances is significant enough to impact classification accuracy by more than a few percentage points. However, since there are no WBMs labeled as having mixed-defect patterns in the dataset, an accurate evaluation is not possible. Therefore, we manually reviewed the WBMs classified as containing multiple-defect patterns. As a result, we found many appropriate classification results, but there were also cases where patterns judged to be single defects were classified as multiple defects. Therefore, additional verification and research are necessary based on the labeling data of mixed-defect patterns. Electronics 2024 ,13, 1360 30 of 32 6. Conclusions In this paper, we constructed six models, including a comparison model, and evalu- ated their performance based on input data tra"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_138", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 138, "text": "ed-defect patterns. Electronics 2024 ,13, 1360 30 of 32 6. Conclusions In this paper, we constructed six models, including a comparison model, and evalu- ated their performance based on input data transformation, pre-processing method, and classifier structure. For input data transformation, the defect die information on the WBM is converted to the polar coordinate system to enhance the characteristics of the distribution of defect dies by wafer defect class, rather than using the WBM image as input. The binary- classifier-based tree-structured classifier was used for single-failure pattern classification and the CNN-based ensemble classifier was used for mixed-defect pattern classification. The WM-811K dataset was used to classify failure patterns based on a 26√ó26-sized WBM. The model trained on a conventional WBM image achieved a classification accuracy of 86.5%. However, the model‚Äôs classification accuracy was 91.3% when the polar coordinate system space was divided into specific ranges based on the transformed polar coordinate system data and the number of defective dies belonging to the range was measured. This confirms that polar coordinate system transformed data can more ea"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_139", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 139, "text": "nges based on the transformed polar coordinate system data and the number of defective dies belonging to the range was measured. This confirms that polar coordinate system transformed data can more easily extract pattern- specific features of defective dies compared to WBM image information, which is generally used for defect pattern classification, thus contributing to improved defect pattern clas- sification performance. Additionally, a tree-structured model was implemented, which sequentially connects binary classifiers for each class trained on polar coordinate system data. This resulted in a classification accuracy of 94%, surpassing the 91.3% accuracy of the model that classifies eight defect classes in one step. However, we discovered that serializing the binary classifiers worsened the existing WM-811K data imbalance problem. Therefore, a single CNN using polar coordinate system transformed input achieved higher accuracy than a tree-structured classifier based on binary classifiers for defect pattern classification of WBMs of all sizes, except for the 26 √ó26 WBM used for training. Finally, to classify mixed-defect patterns, we designed individual classifiers for each failur"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_140", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 140, "text": "iers for defect pattern classification of WBMs of all sizes, except for the 26 √ó26 WBM used for training. Finally, to classify mixed-defect patterns, we designed individual classifiers for each failure pattern class by learning polar coordinate data. Then, we used the ensemble technique to classify the mixed defect patterns in WBM images without any additional clustering process. This study aims to identify the cause of defects in semiconductor mass production by analyzing WBMs that contain ambiguity or multiple defects in the labeling results. The focus is not solely on improving pattern recognition accuracy based on labeling but on providing useful information for defect identification. However, more data are needed to make an objective judgment. Therefore, further verification and research are required based on the data accumulated through engineers‚Äô mixed-defect pattern labeling processes. Furthermore, it is expected that the classification performance can be improved by developing an algorithm to select an adaptive threshold (N) value based on the distribution of defect dies in the WBM during random noise removal and studying the CNN architecture optimized for input data expre"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_141", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 141, "text": " an algorithm to select an adaptive threshold (N) value based on the distribution of defect dies in the WBM during random noise removal and studying the CNN architecture optimized for input data expressed in the polar coordinate system. Author Contributions: Conceptualization, T.S.K.; methodology, M.H.K. and T.S.K.; software, M.H.K.; validation, M.H.K. and T.S.K.; data curation, M.H.K.; writing‚Äîoriginal draft preparation, M.H.K. and T.S.K.; writing‚Äîreview and editing, M.H.K. and T.S.K.; supervision, T.S.K. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding. Data Availability Statement: The original data used in this paper is available as an open dataset in the http://mirlab.org/dataSet/public/ (accessed on 12 March 2024). Conflicts of Interest: The authors declare no conflicts of interest. References 1. Chen, W.C.; Tseng, S.S.; Wang, C.Y. A novel manufacturing defect detection method using association rule mining techniques. Expert Syst. Appl. 2005 ,29, 807‚Äì815. [CrossRef] 2. Hsu, S.-C.; Chien, C.-F. Hybrid Data Mining Approach for Pattern Extraction from Wafer Bin Map to Improve Yield in Semicon- ductor "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_142", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 142, "text": "ning techniques. Expert Syst. Appl. 2005 ,29, 807‚Äì815. [CrossRef] 2. Hsu, S.-C.; Chien, C.-F. Hybrid Data Mining Approach for Pattern Extraction from Wafer Bin Map to Improve Yield in Semicon- ductor Manufacturing. Int. J. Prod. Econ. 2007 ,107, 88‚Äì103. [CrossRef] 3. Chen, F.-L.; Liu, S.-F. A neural-network approach to recognize defect spatial pattern in semiconductor fabrication. IEEE Trans. Semicond. Manuf. 2000 ,13, 366‚Äì373. [CrossRef] Electronics 2024 ,13, 1360 31 of 32 4. Li, K.; Liao, P .; Cheng, K.; Chen, L.; Wang, S.; Huang, A.; Chou, L.; Han, G.; Chen, J.; Liang, H.; et al. Hidden wafer scratch defects projection for diagnosis and quality enhancement. IEEE Trans. Semicond. Manuf. 2021 ,34, 9‚Äì15. [CrossRef] 5. Nakazawa, T.; Kulkarni, D.V . Wafer Map Defect Pattern Classification and Image Retrieval using Convolutional Neural Network. IEEE Trans. Semicond. Manuf. 2019 ,31, 309‚Äì314. [CrossRef] 6. Lee, K.B.; Cheon, S.; Kim, C.O. A Convolutional Neural Network for Fault Classification and Diagnosis in Semiconductor Manufacturing Processes. IEEE Trans. Semicond. Manuf. 2017 ,30, 135‚Äì142. [CrossRef] 7. Park, J.S. Wafer map-based defect Detection Using Convolutional Neural Network"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_143", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 143, "text": "ion and Diagnosis in Semiconductor Manufacturing Processes. IEEE Trans. Semicond. Manuf. 2017 ,30, 135‚Äì142. [CrossRef] 7. Park, J.S. Wafer map-based defect Detection Using Convolutional Neural Networks. J. Korean Inst. Ind. Eng. 2018 ,44, 249‚Äì258. [CrossRef] 8. Wu, M.J.; Jang, J.S.R.; Chen, J.L. Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Trans. Semicond. Manuf. 2014 ,28, 1‚Äì12. [CrossRef] 9. Piao, M.; Jin, C.H.; Lee, J.Y.; Byun, J.Y. Decision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features. IEEE Trans. Semicond. Manuf. 2018 ,31, 250‚Äì257. [CrossRef] 10. Li, T.-S.; Huang, C.-L. Defect spatial pattern recognition using a hybrid SOM‚ÄìSVM approach in semiconductor manufacturing. Expert Syst. Appl. 2009 ,36, 374‚Äì385. [CrossRef] 11. Remya, K.; Sajith, V . Machine Learning Approach for Mixed type Wafer Defect Pattern Recognition by ResNet Architecture. In Proceedings of the 2023 International Conference on Control, Communication and Computing (ICCC), Thiruvananthapuram, India, 19‚Äì21 May 2023; pp. 1‚Äì6. [CrossRef] 12. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recogniti"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_144", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 144, "text": "erence on Control, Communication and Computing (ICCC), Thiruvananthapuram, India, 19‚Äì21 May 2023; pp. 1‚Äì6. [CrossRef] 12. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recognition. arXiv 2015 , arXiv:1512.03385. [CrossRef] 13. Wang, C.-Y.; Tsai, T.-H. Defect Detection on Wafer Map Using Efficient Convolutional Neural Network. In Proceedings of the IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW), Penghu, Taiwan, 15‚Äì17 September 2021; pp. 1‚Äì2. [CrossRef] 14. Ko, S.; Koo, D. A novel approach for wafer defect pattern classification based on topological data analysis. Expert Syst. Appl. 2023 , 30, 120765. [CrossRef] 15. Shin, E.; Yoo, C.D. Efficient Convolutional Neural Networks for Semiconductor Wafer Bin Map Classification. Sensors 2023 , 23, 1926. [CrossRef] [PubMed] 16. Wang, Y.; Ni, D.; Huang, Z. A Momentum Contrastive Learning Framework for Low-Data Wafer Defect Classification in Semiconductor Manufacturing. Appl. Sci. 2023 ,13, 5894. [CrossRef] 17. Shim, J.; Kang, S.; Cho, S. Active learning of convolutional neural network for cost-effective wafer map pattern classification. IEEE Trans. Semicond. Manuf. 2020 ,33, 258‚Äì266. [CrossRef] 1"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_145", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 145, "text": "ssRef] 17. Shim, J.; Kang, S.; Cho, S. Active learning of convolutional neural network for cost-effective wafer map pattern classification. IEEE Trans. Semicond. Manuf. 2020 ,33, 258‚Äì266. [CrossRef] 18. Tziolas, T.; Theodosiou, T.; Papageorgiou, K.; Rapti, A.; Dimitriou, N.; Tzovaras, D.; Papageorgiou, E. Wafer Map Defect Pattern Recognition using Imbalanced Datasets. In Proceedings of the 2022 13th International Conference on Information, Intelligence, Systems & Applications (IISA), Corfu, Greece, 18‚Äì20 July 2022; pp. 1‚Äì8. [CrossRef] 19. Ebayyeh, A.A.R.M.A.; Danishvar, S.; Mousavi, A. An Improved Capsule Network (WaferCaps) for Wafer Bin Map Classification Based on DCGAN Data Upsampling. IEEE Trans. Semicond. Manuf. 2021 ,35, 50‚Äì59. [CrossRef] 20. Park, S.; You, C. Deep Convolutional Generative Adversarial Networks-Based Data Augmentation Method for Classifying Class-Imbalanced Defect Patterns in Wafer Bin Map. Appl. Sci. 2023 ,13, 5507. [CrossRef] 21. Shon, H.S.; Batbaatar, E.; Cho, W.-S.; Choi, S.G. Unsupervised Pre-Training of Imbalanced Data for Identification of Wafer Map Defect Patterns. IEEE Access 2021 ,9, 52352‚Äì52363. [CrossRef] 22. Xu, Q.; Yu, N.; Essaf, F. Improved Wafe"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_146", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 146, "text": "W.-S.; Choi, S.G. Unsupervised Pre-Training of Imbalanced Data for Identification of Wafer Map Defect Patterns. IEEE Access 2021 ,9, 52352‚Äì52363. [CrossRef] 22. Xu, Q.; Yu, N.; Essaf, F. Improved Wafer Map Inspection Using Attention Mechanism and Cosine Normalization. Machines 2022 , 10, 146. [CrossRef] 23. Niu, S.; Lin, H.; Niu, T.; Li, B.; Wang, X. DefectGAN: Weakly-supervised defect detection using generative adversarial network. In Proceedings of the 2019 IEEE 15th International Conference on Automation Science and Engineering (CASE), Vancouver, BC, Canada, 22‚Äì26 August 2019; pp. 127‚Äì132. [CrossRef] 24. Li, K.S.M.; Jiang, X.H.; Chen, L.L.Y.; Wang, S.J.; Huang, A.Y.A.; Chen, J.E.; Liang, H.C.; Hsu, C.L. Wafer Defect Pattern Labeling and Recognition Using Semi-Supervised Learning. IEEE Trans. Semicond. Manuf. 2022 ,35, 291‚Äì299. [CrossRef] 25. Wang, C.H.; Kuo, W.; Bensmail, H. Detection and classification of defect patterns on semiconductor wafers. IIE Trans. 2006 ,38, 1059‚Äì1068. [CrossRef] 26. Kim, J.; Lee, Y.; Kim, H. Detection and clustering of mixed-type defect patterns in wafer bin maps. IISE Trans. 2018 ,50, 99‚Äì111. [CrossRef] 27. Jin, C.H.; Na, H.J.; Piao, M.; Pok, G.; Ryu,"}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_147", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 147, "text": "ssRef] 26. Kim, J.; Lee, Y.; Kim, H. Detection and clustering of mixed-type defect patterns in wafer bin maps. IISE Trans. 2018 ,50, 99‚Äì111. [CrossRef] 27. Jin, C.H.; Na, H.J.; Piao, M.; Pok, G.; Ryu, K.H. A novel DBSCAN-based defect pattern detection and classification framework for wafer bin map. IEEE Trans. Semicond. Manuf. 2019 ,32, 286‚Äì292. [CrossRef] 28. Kyeong, K.; Kim, H. Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks. IEEE Trans. Semicond. Manuf. 2018 ,31, 395‚Äì402. [CrossRef] 29. Liu, C.; Tang, Q. Triplet Convolutional Networks for Classifying Mixed-Type WBM Patterns with Noisy Labels. In Proceedings of the 2021 IEEE International Test Conference (ITC), Anaheim, CA, USA, 10‚Äì15 October 2021; pp. 395‚Äì402. [CrossRef] 30. Wang, R.; Chen, N. Detection and Recognition of Mixed Type Defect Patterns in Wafer Bin Maps via Tensor Voting. IEEE Trans. Semicond. Manuf. 2022 ,35, 485‚Äì494. [CrossRef] 31. Qiu, Q. Effect of internal defects on the thermal conductivity of fiber-reinforced polymer (FRP): A numerical study based on micro-CT based computational modeling. Mater. Today Commun. 2023 ,36, 106446. [CrossRef] Electronics 2024 ,13, "}
{"id": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf::chunk_148", "source": "Development of a Wafer Defect Pattern Classifier Using Polar.pdf", "chunk_index": 148, "text": "n the thermal conductivity of fiber-reinforced polymer (FRP): A numerical study based on micro-CT based computational modeling. Mater. Today Commun. 2023 ,36, 106446. [CrossRef] Electronics 2024 ,13, 1360 32 of 32 32. Zschech, E.; Niese, S.; L√∂ffler, M.; Wolf, M.J. Multi-scale X-ray tomography for process and quality control in 3D TSV packaging. Int. Symp. Microelectron. 2014 ,2014 , 184‚Äì187. [CrossRef] 33. Ma, J.; Zhang, T.; Yang, C.; Cao, Y.; Xie, L.; Tian, H.; Li, X. Review of Wafer Surface Defect Detection Methods. Electronics 2023 , 12, 1787. [CrossRef] Disclaimer/Publisher‚Äôs Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_0", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 0, "text": "Computers in Industry 152 (2023) 104005 Available online 7 August 2023 0166-3615/¬© 2023 Elsevier B.V. All rights reserved.Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods Dong-Hee Leea,*,1, Eun-Su Kimb, Seung-Hyun Choic, Young-Mok Baeb, Jong-Bum Parkb, Young-Chan Ohb, Kwang-Jae Kimc aDepartment of Industrial Engineering, Sungkyunkwan University, the Republic of Korea bDepartment of NAND SE, SK hynix, the Republic of Korea cDepartment of Industrial and Management Engineering, Pohang University of Science and Technology, the Republic of Korea ARTICLE INFO Keywords: Wafer bin map Word2Vec Bin2Vec Defect-pattern classification Convolutional neural networks ABSTRACT A wafer consists of several chips, and serial electrical tests are conducted for each chip to investigate whether the chip is defective. A bin indicates the test results for each chip with information on which tests the chip failed. A wafer bin map (WBM) shows the locations and bins of the defects on the wafer. WBMs showing spatial patterns of defects usually result from assignable causes in the wafer fabrication process; hence, they should be classified in advance"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_1", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 1, "text": "tions and bins of the defects on the wafer. WBMs showing spatial patterns of defects usually result from assignable causes in the wafer fabrication process; hence, they should be classified in advance. The existing defect-pattern taxonomies do not consider bins, although useful information can be ob- tained from them. We propose a taxonomy that consists of the shape, size, location, and bin dimensions. The bin dimension is developed using Bin2Vec method, which determines RGB (red-green-blue) code for each bin ac- cording to the spatial similarity between bins. Three levels of the bin dimension are defined by analyzing a large number of WBMs using Bin2Vec and clustering methods. Compared with the existing taxonomies, the proposed taxonomy has the advantage of identifying major bins of defect patterns, new defect patterns, and non-critical defect patterns. A high-quality training dataset was obtained using the proposed taxonomy; consequently, a defect pattern classification model with satisfactory classification performance could be obtained. 1.Introduction The semiconductor manufacturing process comprises several hun- dred process steps for the fabrication of wafers. After fabricati"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_2", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 2, "text": "tisfactory classification performance could be obtained. 1.Introduction The semiconductor manufacturing process comprises several hun- dred process steps for the fabrication of wafers. After fabrication, serial electrical probe tests are conducted for each semiconductor chip on a wafer to investigate whether the chip is defective. The chip is a physical object that exists on a wafer and bin is a variable indicating on which test the chip failed. Suppose that 10 serial electrical probe tests are con- ducted for each chip. The result of each electrical probe test is recorded as binary indicating that the chip is functional or defective. After the serial electrical probe tests, each chip has its own bin value according to its test results. Because there are 10 binary tests, a total of 1024 (¬à210) bins are possible. The probe test results are represented by a wafer bin map (WBM), which is an image showing the bins and locations of chips on a wafer. A chip is a physical object that exists on wafer and bin is a variable indicating on which test the chip failed. In other words, chip itself has no information. Instead, its bin value indicates on which test the chip failed. When the wafers "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_3", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 3, "text": "n wafer and bin is a variable indicating on which test the chip failed. In other words, chip itself has no information. Instead, its bin value indicates on which test the chip failed. When the wafers have same number of chips, the chip location on the wafers is also same. However, bin distributions on wafers can be different because chips of the wafers can have different bin values. Fig. 1(a) shows an example of a WBM marked with black for the background, gray for the normal chips, and white for the defective chips (referred to as defects hereinafter). Fig. 1(b) provides more information, as each chip is marked with color according to its bin. In Fig. 1(b), two spatial patterns of the defects (referred to as defect patterns hereinafter) in the WBM can be identified: 1) green defects are clustered on the upper-left part of the WBM, and 2) red defects are placed vertically, exhibiting a scratch pattern. Defect patterns are usually due to assignable causes in the fabrication process, such as machine abnormalities and operator errors. They can be prevented by identifying and eliminating the assignable causes. The first task for identifying the assignable causes is detecting wafers with"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_4", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 4, "text": " as machine abnormalities and operator errors. They can be prevented by identifying and eliminating the assignable causes. The first task for identifying the assignable causes is detecting wafers with defect patterns and classifying the patterns. Recently, automatic classification of defect patterns has been highlighted because of its advantages of low cost, full inspection, and good classification performance. Various *Corresponding author. E-mail address: dhee@skku.edu (D.-H. Lee). 1 ORCID: 0000-0001-8549-8992. Contents lists available at ScienceDirect Computers in Industry u{ÔøΩ~zkw! s{yo|kr o>!√ê√ê√ê1ÔøΩmt ozmont~omÔøΩ1m{ y2u{ÔøΩ~zk w2m{y|ÔøΩÔøΩo~ÔøΩ/t z/tznÔøΩÔøΩÔøΩ~√û! https://doi.org/10.1016/j.compind.2023.104005 Received 9 May 2023; Received in revised form 6 July 2023; Accepted 3 August 2023 Computers in Industry 152 (2023) 104005 2methodologies have been applied for automatic classification, such as convolutional neural networks (CNNs), decision trees, regression ana- lyses, and support vector machines (Yu and Lu, 2016; Piao et al., 2018; Adly et al., 2015; Fan et al., 2016; Nakazawa and Kulkarni, 2018; Kyeong and Kim, 2018; Saqlain et al., 2019; Shim et al., 2020 ). Because these are supervised"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_5", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 5, "text": "nes (Yu and Lu, 2016; Piao et al., 2018; Adly et al., 2015; Fan et al., 2016; Nakazawa and Kulkarni, 2018; Kyeong and Kim, 2018; Saqlain et al., 2019; Shim et al., 2020 ). Because these are supervised learning methods, training data should be prepared by labeling WBMs. For coherent labeling, defect patterns should be defined in advance. For example, the WM811K taxonomy is a repre - sentative method for defining defect patterns. Defect patterns observed in the WM811K dataset ‚Äîthe largest WBM dataset available to the public (Wu et al., 2015 )‚Äîare classified according to the WM811K tax- onomy, as shown in Fig. 2. Extensive studies have been conducted to define various defect patterns. However, the existing defect-pattern taxonomies, including the WM811K taxonomy, have common limitations in that they do not allow clear differentiation among defect patterns. To cope with this difficulty, Choi et al. (2021) proposed a spatial dimension-based taxonomy (SDT) with three spatial dimensions of a defect pattern: shape, size, and location. Levels are defined in each dimension with detailed criteria by reflecting the spatial features of the defect pattern; thus, the SDT can define the defect pat"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_6", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 6, "text": "defect pattern: shape, size, and location. Levels are defined in each dimension with detailed criteria by reflecting the spatial features of the defect pattern; thus, the SDT can define the defect patterns clearly and differentiate them accurately. In addition, a sufficient set of patterns can be defined by properly combining the levels of the three dimensions. Later, Kim et al. (2021) employed the SDT to develop a CNN model for the defect pattern. A high-quality training dataset was obtained by coherently labeling the detected patterns according to the SDT. Despite the advantages of the SDT, it may not be effective for iden- tifying significant defect patterns, because it does not consider the bins of chips on WBMs, although useful information can be obtained by considering it. First, it is possible to identify a major bin in a WBM. When the defects are marked only with white regardless of their bins, as shown in Fig. 1, wafers may have similar spatial defect patterns, but the major bins constituting the patterns may not be the same. Accordingly, the assignable causes resulting in the bins may not be the same. Second, it is possible to identify the spatial distribution of each bin"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_7", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 7, "text": "ins constituting the patterns may not be the same. Accordingly, the assignable causes resulting in the bins may not be the same. Second, it is possible to identify the spatial distribution of each bin in the WBM; thus, new defect patterns can be defined. By tracking wafers with new defect patterns, new assignable causes can be identified. One simple approach for considering the bin in the WBM is to apply a random coloring approach, as shown in Fig. 1(b). In this approach, the color for each bin is randomly determined, and each chip is marked with a random color according to its bin. In such a case, the relationships among the bins cannot be preserved. Recently, Kim et al. (2019) pro- posed Bin2Vec ‚Äîa neural network-based bin coloring method. Bin2Vec uses Word2Vec to transform the bins into three-dimensional vectors so that the spatial similarity between bins can be measured. By regarding the three-dimensional vectors as RGB codes, chips can be marked with colors according to the RGB codes. This allows similar bins to be rep- resented by similar colors. In the probe test, if two chips are physically close to each other, their test results are likely to be similar. This is because wa"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_8", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 8, "text": "des. This allows similar bins to be rep- resented by similar colors. In the probe test, if two chips are physically close to each other, their test results are likely to be similar. This is because wafer fabrication is a batch process, and nearby chips are likely to be processed under the same manufacturing conditions. The Bin2Vec-based coloring method reflects the nature of the probe test by representing similar bins with similar colors. It makes major bins, whose degree of similarity to the bin of the normal chip is low, more noticeable because most of the chips are normal. This is useful for identifying sig- nificant defect patterns. Because of this advantage, we used Bin2Vec to develop a taxonomy that considers the bins of the defect patterns. The proposed taxonomy was developed by adding a bin dimension to the SDT; i.e., the proposed taxonomy consists of the shape, size, location, and bin dimension. Three levels of the bin dimension were defined by analyzing a large amount of WBM data using Bin2Vec and clustering methods. A total of 24 defect patterns were defined in the proposed taxonomy, and a CNN model for defect classification was developed to validate the proposed taxonom"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_9", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 9, "text": "data using Bin2Vec and clustering methods. A total of 24 defect patterns were defined in the proposed taxonomy, and a CNN model for defect classification was developed to validate the proposed taxonomy. A high-quality training dataset was obtained using the proposed tax- onomy; thus, the CNN model exhibited satisfactory classification per- formance. A semiconductor manufacturing company located in Korea provided the probe-test data and confirmed the effectiveness of the proposed taxonomy. The remainder of this paper is organized as follows. Section 2 re- views the existing taxonomies for defect-pattern classification, including the SDT and Bin2Vec, which are related to the proposed taxonomy. Sections 3 and 4 explain the development and verification processes of the proposed taxonomy, respectively. Finally, the concluding remarks are presented in Section 5. 2.Literature review 2.1. Existing taxonomies for defect-pattern classification Several taxonomies have been proposed for defect-pattern classifi - cation (Cunningham and MacKinnon, 1998 ). defined a single defect pattern: Scratch (Wang et al., 2006 ). considered three defect patterns: Zone, Line, and Ring. Here, Line corresponds "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_10", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 10, "text": "tern classifi - cation (Cunningham and MacKinnon, 1998 ). defined a single defect pattern: Scratch (Wang et al., 2006 ). considered three defect patterns: Zone, Line, and Ring. Here, Line corresponds to Scratch in the work of (Cunningham and MacKinnon, 1998 ). Other researchers proposed similar taxonomies (Hsieh and Chen, 2004; Hwang and Kuo, 2007; Yuan and Kuo, 2007; Wang, 2009; Zhou et al., 2010; Yuan et al., 2011; Choi et al., 2012; Nakata et al., 2017; Yu et al., 2021; Liu and Chien, 2013 ). Fig. 1.Example of WBMs. Fig. 2.WM811K taxonomy. D.-H. Lee et al. Computers in Industry 152 (2023) 104005 3Later, more diverse defect patterns were defined (Li and Huang, 2009; Chien et al., 2013; Liukkonen and Hiltunen, 2018; Chen and Liu, 2000 ). Although such taxonomies have been widely used, their usefulness is limited by the unclear criteria for differentiation between defect pat- terns. The set of defect patterns is provided without a precise definition of each defect pattern. For example, in the WM811K taxonomy, the center refers to a defect pattern clustered in the center region, regardless of its shape. Hence, classifying a given WBM as one of the defect patterns frequently involves"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_11", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 11, "text": " in the WM811K taxonomy, the center refers to a defect pattern clustered in the center region, regardless of its shape. Hence, classifying a given WBM as one of the defect patterns frequently involves a high degree of subjective judgment, which hinders coherent classification. Recently, Choi et al. (2021) proposed an SDT in which defect pat- terns were defined according to the shape , size, and location dimensions. According to the three spatial dimensions, the SDT provided a clear definition of the defect patterns. Ten defect patterns were derived using the SDT, as shown in Table 1. Nine patterns were defined (with the exception of noise ‚Äìinfrequent ‚Äìscattered , which was defined for normal wafers). WBMs were labeled coherently according to the 10 detected patterns, resulting in good classification performance for the 10 defect patterns. The 10 defect patterns were validated through an investigation of the assignable causes by collaborating with the semiconductor manufacturing company. Despite the advantage of the SDT, it has the disadvantage that the bin information is not considered. As mentioned previously, identifying major bins is important for identifying assignable causes. "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_12", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 12, "text": ". Despite the advantage of the SDT, it has the disadvantage that the bin information is not considered. As mentioned previously, identifying major bins is important for identifying assignable causes. In addition, new defect patterns can be defined by considering the spatial distribu - tion of bins in the WBM, which is useful for identifying the assignable causes. In this regard, we propose a new four-dimensional taxonomy that extends the SDT by adding the bin dimension. In the proposed taxonomy, Bin2Vec and clustering methods are used to develop the bin dimension. Bin2Vec is reviewed in Section 2.2. 2.2. Bin2Vec The random RGB coloring method is a simple approach for pre- senting bin information in the WBM. WBMs are colorized by assigning randomly selected RGB codes to each bin so that different bin values can be distinguished in the WBM. The main drawback of this method is that the relationships between the bins are not preserved. In practice, some bins are closely related, whereas others are completely unrelated (Choi et al., 2021 ). Bin2Vec is a neural network-based bin coloring method that assigns an RGB code to each bin so that similar bins have similar RGB codes. This idea wa"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_13", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 13, "text": "hers are completely unrelated (Choi et al., 2021 ). Bin2Vec is a neural network-based bin coloring method that assigns an RGB code to each bin so that similar bins have similar RGB codes. This idea was inspired by the domain knowledge of semiconductor practitioners that nearby chips often fail the same test. Bin2Vec trans - forms a one-dimensional scalar bin into a three-dimensional embedding vector by employing the learning mechanism of the Word2Vec embed - ding model. Word2Vec is a widely used neural network-based distrib - uted representation method that represents a word in a fixed dimension (Mikolov et al., 2013a, 2013b ). Compared with traditional one-hot encoding methods, Word2Vec can preserve the semantic relationship between words. When considering words as bins, Bin2Vec can preserve the spatial relationship between the bins. Once the bin is converted into a three-dimensional vector, it can be used not only to assign an RGB code, which can also be considered a three-dimensional vector, but also to compute the similarity between any two bins (Kim et al., 2019 ). There are two Word2Vec structures: continuous bag-of-words (CBOW) and Skip-Gram, which have exactly reversed stru"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_14", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 14, "text": "l vector, but also to compute the similarity between any two bins (Kim et al., 2019 ). There are two Word2Vec structures: continuous bag-of-words (CBOW) and Skip-Gram, which have exactly reversed structures. CBOW takes the neighborhood words as the input and is trained to correctly predict the targeted word, whereas Skip-Gram takes the tar- geted word as the input of the network and is trained to correctly predict the neighborhood words. Bin2Vec employs the Skip-Gram structure because it is more effective than CBOW for learning infrequent words. Table 1 Defect patterns of SDT (reprinted from Choi et al. (2021) ). Defect pa ttern (Shape‚ÄìSize‚ÄìLocation) Sample WBM Defect pattern (Shape‚ÄìSize‚ÄìLocation) Sample WBM Cluster‚ÄìAll‚ÄìCenter Noise‚ÄìFrequent‚ÄìScattered Cluster‚ÄìBig‚ÄìEdge Noise‚ÄìInfrequent‚ÄìScattered Cluster‚ÄìSmall‚ÄìEdg e Ring‚ÄìAl l‚ÄìEdg e Cluster‚ÄìBig‚ÄìOthers Scratch‚ÄìLong‚ÄìAll Cluster‚ÄìSmall‚ÄìOthers Scratch‚ÄìShort‚ÄìAll Fig. 3.Example of a target chip (brown color) and surrounding chips (reprinted from Kim et al. (2019) ) D.-H. Lee et al. Computers in Industry 152 (2023) 104005 4To employ Skip-Gram, Bin2Vec defines a target chip and its sur- rounding chips. Fig. 3 shows an example of a target chip "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_15", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 15, "text": " Kim et al. (2019) ) D.-H. Lee et al. Computers in Industry 152 (2023) 104005 4To employ Skip-Gram, Bin2Vec defines a target chip and its sur- rounding chips. Fig. 3 shows an example of a target chip and its 24 surrounding chips. The numbers in Fig. 3 indicate the bins of the chips. The number of surrounding chips for each target chip is assumed to be 2C. For example, C is set as C¬à12 in Fig. 3. Bin2Vec designates every chip in the WBM as the target chip and its surrounding chips to train the Skip-Gram model. Fig. 4 shows the Skip-Gram structure employed in Bin2Vec (Mikolov et al., 2013a ). It consists of input, projection, and output layers. The input layer takes the one-hot encoding vector of the bin of the target chip, whereas the output layer takes the one-hot encoding vectors of the bins of the surrounding chips. Suppose that we have T chips to train the Skip-Gram model, and V bins are observed in the T chips. Then, each target chip defines a single V-dimensional one-hot encoding vector as the input and 2C V-dimensional one-hot encoding vectors as the output according to the bins of the target and surrounding chips. Once the V-dimensional one-hot encoding vectors are prepared,"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_16", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 16, "text": "vector as the input and 2C V-dimensional one-hot encoding vectors as the output according to the bins of the target and surrounding chips. Once the V-dimensional one-hot encoding vectors are prepared, the projection layer is trained. The projection layer consists of three hidden nodes; thus, the hidden weight matrix W between the input and pro- jection layers has dimensions of V√ó3, and the hidden weight matrix W‚Ä≤ between the projection and output layers has dimensions of 3√óV. W and W‚Ä≤ are trained to maximize the probability of generating the actual bins of the surrounding chips for a given bin of the target chip. Specif - ically, given a sequence of training chip bins (B1CB2C‚Ä¶CBT), the objective function of the Skip-Gram model maximizes the average log probability, as shown in Eq. (1): maximize WCW‚Ä≤1 TÃÇT t¬à1ÃÇ \u0000C‚âºj‚âºCCj‚Ñë¬à0logp\u0000 Bt¬áj‚Ä†Bt) B (1) The probability of generating the bins of the surrounding chips (denoted as s) given the bin of the target chip (denoted as t) is computed using a softmax function, as follows: logp s‚Ä†t¬Ü¬àexp uT svt¬Ü ‚ãÉV w¬à1exp uT wvt¬ÜC (2) where u is the column vector of the hidden weight matrix W‚Ä≤, and v is the column vector of the hidden weight matrix W. After "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_17", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 17, "text": "softmax function, as follows: logp s‚Ä†t¬Ü¬àexp uT svt¬Ü ‚ãÉV w¬à1exp uT wvt¬ÜC (2) where u is the column vector of the hidden weight matrix W‚Ä≤, and v is the column vector of the hidden weight matrix W. After the training process is complete, either the row vector of W or the column vector of W‚Ä≤ can be used as a bin vector that serves as RGB codes. 3.Development of proposed taxonomy The proposed taxonomy is developed through five steps: 1) data collection, 2) data preprocessing, 3) deriving RGB codes for bins using Bin2Vec, 4) clustering bins according to the RGB codes, and 5) extending the SDT by adding the bin dimension. The five steps are explained in detail in this section. 3.1. Step 1: data collection A semiconductor manufacturing company located in Korea provided probe-test data of 10174 wafers grouped into 500 lots. The dataset is different from that of Choi et al. (2021) . The dataset of Choi et al. (2021) has WBM data where only binary information for each chip, i.e., whether each chip is defective or not, exists. No bin information exists in the dataset of Choi et al. (2021) . In contrast, the newly provided dataset included probe-test results for every chip on the wafers. The loc"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_18", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 18, "text": " is defective or not, exists. No bin information exists in the dataset of Choi et al. (2021) . In contrast, the newly provided dataset included probe-test results for every chip on the wafers. The location of each chip on a wafer was denoted by x and y coordinates, and the bin for the chip was included. The wafer size was 27√ó22, and each chip on the wafer had a bin value ranging from 1 to 57. The chips with a bin value of 54 were normal chips, whereas those with other bin values were defects. Fig. 5 shows the bin distribution of the defects. Each defect corre - sponded to one bin value ranging from 1 to 57 (with the exception of 54). The top six bins having large proportions in Fig. 5 (bins 24, 20, 14, 28, 2, and 32) were the major bins, and 64.1 % of the defects corre - sponded to one of these six bins. Fig. 4.Skip-Gram model architecture employed in Bin2Vec (N¬à3). Fig. 5.Bin distribution of defects. Fig. 6.Distribution of bins in the RGB space without wafer screening. D.-H. Lee et al. Computers in Industry 152 (2023) 104005 53.2. Step 2: data preprocessing Three types of preprocessing were conducted for the probe-test dataset. First, the wafers were screened to balance the number"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_19", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 19, "text": ". Computers in Industry 152 (2023) 104005 53.2. Step 2: data preprocessing Three types of preprocessing were conducted for the probe-test dataset. First, the wafers were screened to balance the number of wa- fers. Because most of the chips were normal, the training data were imbalanced. When such data are used for training the Bin2Vec model, the relationship between bins can be misleading. To investigate this issue, we trained the Bin2Vec model without wafer screening. Fig. 6 shows the RGB codes of the 57 bins obtained from the Bin2Vec model. Bin 54 exhibited an isolated RGB code, and the other bins were relatively closely clustered. When most of the chips were normal, the chips sur- rounding the normal chips were also likely to be normal. Because defective chips rarely exist, the defective chips can be considered as outliers in terms of the normal chip. In contrast, although majority is a normal chip, the chips surrounding the defective chip can be another defective chip. This is because the defective chips often locate nearby as shown in Table 1. This makes the RGB code of the normal chip (i.e., Bin 54) is quite different from those of defective chips. Also, this makes defective "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_20", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 20, "text": "use the defective chips often locate nearby as shown in Table 1. This makes the RGB code of the normal chip (i.e., Bin 54) is quite different from those of defective chips. Also, this makes defective chips have similar RGB codes regardless of their bin. Conse - quently, it is difficult to identify the major bins. To resolve this issue, we classified each wafer into one of the 10 defect patterns of the SDT, as shown in Table 1, and selected the wafers based on the classification result so that training data were balanced. A total of 10,174 wafers were manually classified, and 4672 wafers were found to have defect patterns. Among them, we selected 3630 wafers with six large or long defect patterns. Specifically, the six large or long defect patterns were cluster-big-center , cluster-big-edge , cluster-big-others , noise-frequent-scattered , ring-all-edge , and scratch-long-all . We selected wafers with these defect patterns because they were considered to be more critical than the other patterns. For normal wafers (i.e., wafers with a Noise ‚ÄìInfrequent ‚ÄìScattered pattern in Table 1), we selected 500 wafers from 500 lots (a single wafer from each lot) to accurately represent the chara"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_21", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 21, "text": "patterns. For normal wafers (i.e., wafers with a Noise ‚ÄìInfrequent ‚ÄìScattered pattern in Table 1), we selected 500 wafers from 500 lots (a single wafer from each lot) to accurately represent the characteristics of the entire lot, because the wafers in the same lot are likely to be homogeneous in a batch process such as the wafer fabrication process. As a result, we selected 3630 wafers from the six large or long defect patterns and 500 wafers from the normal pattern. Each pattern commonly includes approximately 500‚Äì700 wafers; thus, the training data were balanced. Second, pairs of bin vectors were prepared to train the Bin2Vec model. Fig. 3 shows an example of the target chip and its surrounding chips. According to the Skip-Gram structure, the bin of the target chip and the bins of the surrounding chips served as the input and output vectors, respectively. Like the example in Fig. 3, it should be decided which chips to include as the surrounding chips. The surrounding chips can be selected by setting C value. When C changes, the training dataset changes accordingly. This results in changes in RGB of each bin; thus, the C value should be carefully selected. Basic rule for setting t"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_22", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 22, "text": "ected by setting C value. When C changes, the training dataset changes accordingly. This results in changes in RGB of each bin; thus, the C value should be carefully selected. Basic rule for setting the value of C is considering the degree of similarity in electrical characteristics between the two chips (i.e., target and surrounding chips). The closer the chip is, the more similar the electrical characteristics to the target chip, so it should be selected as the surrounding chip. Also, larger C value generates more pairs of surrounding and target chips. This re- quires more computational burden for training Bin2Vec model. We interviewed the probe test engineer about the similarity in the electrical characteristics of the two chips to determine the C value. As a result, we found that chips within a 5√ó5 grid might have high simi- larity in the electrical characteristics. For this reason, we set C¬à12. In addition, we conducted a sensitivity analysis with respect to C to support the engineer ‚Äôs decision. We applied C¬à4, 12, 24. As shown in Fig. 3, C equals to 12 when the grid is 5√ó5. Similarly, C equals to 4 and 24 when the grid is 3√ó3 and 7√ó7, respectively. Fig. 7 shows examples of W"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_23", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 23, "text": "eer ‚Äôs decision. We applied C¬à4, 12, 24. As shown in Fig. 3, C equals to 12 when the grid is 5√ó5. Similarly, C equals to 4 and 24 when the grid is 3√ó3 and 7√ó7, respectively. Fig. 7 shows examples of WBM colored by Bin2Vec for the three C values. As we expected, RGBs were different according to the C values. Among them, differences in colors of bins were biggest when C¬à12. This big difference in colors is helpful in defining the bin dimension. Based on the process engineer ‚Äôs decision and the result of the sensitivity analysis, we set C¬à12. Third, the pairs of bin vectors were deleted. When a chip and its surrounding chips had the same bin value, the pairs of bin vectors generated from these chips had the same input and output vectors. These pairs of bin vectors were deleted because they provided no information regarding the spatial similarity between bins. Additionally, when the surrounding area of a normal chip only consisted of other normal chips or non-wafer parts, the generated vectors were deleted, for the same reason. After these bin vectors were deleted, approximately 85,000,000 pairs of bin vectors remained. 3.3. Step 3: deriving RGB codes for bins using Bin2Vec The 85,000,"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_24", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 24, "text": "tors were deleted, for the same reason. After these bin vectors were deleted, approximately 85,000,000 pairs of bin vectors remained. 3.3. Step 3: deriving RGB codes for bins using Bin2Vec The 85,000,000 pairs of bin vectors prepared in Step 2 were trans - formed into 57-dimensional one-hot encoding vectors to reflect all bin values. Each pair of bin vectors consisted of two 57-dimensional vectors: one for the input vector and the other for the output vector. The Bin2Vec model was trained using 85,000,000 pairs of one-hot encoding bin vectors. We set the number of epochs as 100, which is a common value. After the training was complete, a three-dimensional vector represent - ing the RGB code was obtained for each bin. Additionally, we conducted Fig. 7.Examples of WBM from three C values (left: C¬à4; center: C¬à12; right: C¬à24). D.-H. Lee et al. Computers in Industry 152 (2023) 104005 6min-max normalization for the three-dimensional vectors to make the vectors have values between 0 and 1 and then transformed these values again by multiplying by 255 to represent RGB codes, as suggested by Kim et al. (2019) . Fig. 8 shows the RGB colors for the 57 bins. 3.4. Step 4: clustering bins accor"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_25", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 25, "text": "nd then transformed these values again by multiplying by 255 to represent RGB codes, as suggested by Kim et al. (2019) . Fig. 8 shows the RGB colors for the 57 bins. 3.4. Step 4: clustering bins according to RGB codes In Step 3, 57 RGB codes were derived, as shown in Fig. 8. These RGB codes are used to define a new dimension ‚Äîthe bin dimension ‚Äîand its levels for extending the SDT. There are issues to be considered when Fig. 8.RGB colors derived using Bin2Vec. Fig. 9.Results of the bin clustering. D.-H. Lee et al. Computers in Industry 152 (2023) 104005 7defining these levels. First, the number of levels should be small. Increasing the number of levels increases the complexity of the taxon - omy. From the perspective of inspectors who label WBMs according to the proposed taxonomy, a simple taxonomy is easy to use with reason - able cognitive effort. Second, different frequencies among bins should be considered. As shown in Fig. 5, the frequencies of the bins were different. Frequent bins should be emphasized when defining the levels. We clustered bins to consider these two issues. We selected the top six bins shown in Fig. 5 (bins 24, 20, 14, 28, 2, and 32) as the initial centroids"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_26", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 26, "text": "ns should be emphasized when defining the levels. We clustered bins to consider these two issues. We selected the top six bins shown in Fig. 5 (bins 24, 20, 14, 28, 2, and 32) as the initial centroids. However, we found that the colors of bins 2 and 14 were similar; hence, we combined them as a single centroid. We then assigned each of the other bins to the closest centroid among the five centroids. Thus, five clusters were obtained, as shown in Fig. 9. For each cluster, we calculated the average RGB code and represented it as a color, as shown in the right part of Fig. 9. The three numbers in each square in the right part of Fig. 9 are the average RGB codes. The average RGBs of the second and third clusters were similar; hence, we combined them as a single Fig. 10.Example of the ‚Äú8‚Äù defect pattern. Table 2 The 24 defect patterns defined in the proposed taxonomy. Defect pattern (Shape ‚ÄìSize ‚Äì Location-Bin)Sample WBMDefect pattern (Shape ‚ÄìSize ‚Äì Location-Bin)Sample WBMDefect pattern (Shape ‚ÄìSize ‚Äì Location-Bin)Sample WBM 1. Cluster‚Äì Big‚ÄìCenter- Yellow9. Cluster‚ÄìBig‚Äì others- Purple17. Noise‚Äì Frequent‚Äì Scattered- Green 2. Cluster‚Äì Big‚ÄìCenter- Green10. Ring-All- Edge -Yellow18. Noise‚Äì "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_27", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 27, "text": "ape ‚ÄìSize ‚Äì Location-Bin)Sample WBM 1. Cluster‚Äì Big‚ÄìCenter- Yellow9. Cluster‚ÄìBig‚Äì others- Purple17. Noise‚Äì Frequent‚Äì Scattered- Green 2. Cluster‚Äì Big‚ÄìCenter- Green10. Ring-All- Edge -Yellow18. Noise‚Äì Frequent‚Äì Scattered- Purple 3. Cluster‚Äì Big‚ÄìCenter- Purple11. Ring-All- Edge -Green19. 8-All- Center-Yellow 4. Cluster‚Äì Big‚ÄìEdge - Yellow12. Ring-All- Edge -Purple20. 8-All- Center-Green 5. Cluster‚Äì Big‚ÄìEdge - Green13. Scratch ‚Äì Long‚ÄìAll- Yellow21. 8-All- Center-Purple 6. Cluster‚Äì Big‚ÄìEdge - Purple14. Scratch ‚Äì Long‚ÄìAll- Green22. Flipp edC- All- Center-Yellow 7. Cluster‚Äì Big‚Äìothers- Yellow15. Scratch ‚Äì Long‚ÄìAll- purple23. Flipp edC- All- Center-Green 8. Cluster‚Äì Big‚Äìothers- Green16. Noise‚Äì Frequent‚Äì Scattered- Yellow24. Flipp edC- All- Center-PurpleD.-H. Lee et al. Computers in Industry 152 (2023) 104005 8cluster. Thus, we obtained four clusters, as shown in the right part of Fig. 9. The color of the last cluster was similar to that of bin 54 (i.e., bin of the normal chip). The four bins included in the last cluster (bins 6, 28, 37, and 48) had high spatial similarity to the bin of a normal chip, indicating that these failures were not critical. Thus, we excluded the last cluster and f"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_28", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 28, "text": "ncluded in the last cluster (bins 6, 28, 37, and 48) had high spatial similarity to the bin of a normal chip, indicating that these failures were not critical. Thus, we excluded the last cluster and finally determined three levels of the bin dimension from the three clusters. They are denoted as yellow , green , and purple levels. 3.5. Step 5: extending SDT by adding bin dimension We converted the probe-test data of the 4130 wafers to WBMs to visually identify the defect patterns. The 4130 wafers were selected in Step 2 to train the Bin2Vec model. Each chip was marked with a color according to its bin, as shown in Fig. 9. For example, a chip with bin 24 was marked yellow. Thus, we obtained 4130 WBMs marked with four colors. Through manual inspection of the 4130 WBMs, we identified two new defect patterns that were not defined in the SDT. Fig. 10(a) shows the WBM marked with white for defects, regardless of their bins. A large cluster of defects is located in the center of the WBM. In fact, this is not a simple cluster but a complex pattern composed of two bin clusters whose shape is similar to that of the number 8. However, it is impossible to identify the ‚Äú8‚Äù defect pattern in Fig"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_29", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 29, "text": "act, this is not a simple cluster but a complex pattern composed of two bin clusters whose shape is similar to that of the number 8. However, it is impossible to identify the ‚Äú8‚Äù defect pattern in Fig. 10(a). Fig. 10(b) provides more information, as the chips are marked with four colors according to their bins. Here, we observe that two clusters marked purple are located in the upper and lower areas within the large cluster marked in yellow. The shape of this new defect pattern is similar to that of an ‚Äú8‚Äù or a ‚Äúsnowman. ‚Äù Several WBMs exhibited this ‚Äú8‚Äù pattern. Surprisingly, this pattern has not been previously observed, according to interviews of practitioners from the semiconductor manufacturing company. New assignable causes were identified by investigating the fabrication pro- cess, which is expected to affect the purple-colored bins. We found that both the ‚Äú8‚Äù pattern and associated assignable causes resulted from new process development. Similarly, we identified another new defect pattern ‚Äîa ‚Äúflipped C‚Äù pattern ‚Äîand associated assignable causes. These findings indicate that the proposed taxonomy can identify valid patterns. Before extending the SDT, we modified it by adding"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_30", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 30, "text": "ect pattern ‚Äîa ‚Äúflipped C‚Äù pattern ‚Äîand associated assignable causes. These findings indicate that the proposed taxonomy can identify valid patterns. Before extending the SDT, we modified it by adding two new patterns and excluding insignificant patterns. The sizes of the two new defect patterns were either small or large; thus, we defined them as 8-All-Center and FlippedC-All-Center . The existing SDT consists of 10 defect patterns, as shown in Table 1. To exclude non-critical defect patterns, we comprehensively evaluated each defect pattern by interviewing the practitioners of the semiconductor company that provided the probe- test data. We concluded that four defect patterns with small sizes (i.e., cluster ‚Äìsmall ‚Äìedge, cluster ‚Äìsmall ‚Äìothers , noise ‚Äìinfrequent ‚Äìscattered , and scratch ‚Äìshort ‚Äìall) were not critical; thus, we excluded them. This exclusion is consistent with that of Step 2. Thus, eight defect patterns were defined. Next, we extended each of the defect patterns using the three colors defined in Step 4. Thus, 24 (¬à8√ó3) defect patterns were defined, as shown in Table 2. The first 18 defect patterns in Table 2 were defined by extending the existing defect patterns o"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_31", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 31, "text": " the three colors defined in Step 4. Thus, 24 (¬à8√ó3) defect patterns were defined, as shown in Table 2. The first 18 defect patterns in Table 2 were defined by extending the existing defect patterns of the SDT, and the following six defect patterns were defined by extending the new pat- terns: 8-All-Center and FlipC-All-Center. The proposed taxonomy has three advantages over existing taxon - omies, including the SDT, which do not consider the bins of chips in the WBM. First, a group of major bins of the defect pattern can be identified according to the bin dimension. For example, the first three defect patterns in Table 2 are considered identical in terms of the SDT; how- ever, they are considered different in terms of the proposed taxonomy. The three patterns are likely to result from different assignable causes; thus, new assignable causes can be identified by investigating the wafers having the patterns. Second, new defect patterns can be identified. As mentioned previously, the 8-All-Center and FlippedC-All-Center are new defect patterns defined in the proposed taxonomy. These patterns are likely to result from new assignable causes. Third, non-critical bins can be identified. "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_32", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 32, "text": "ll-Center and FlippedC-All-Center are new defect patterns defined in the proposed taxonomy. These patterns are likely to result from new assignable causes. Third, non-critical bins can be identified. In Step 4, we excluded the four bins included in the last cluster according to the spatial similarity to the bin of a normal chip. Because of these advantages, the proposed taxonomy can serve as a basis for various engineering activities, such as detecting and eliminating new assignable causes or analyzing the relationships between bins. In addition, the proposed taxonomy is easy to use in practice. Typi- cally, hundreds of bins exist in probe-test data. The bin dimension of the proposed taxonomy was developed by clustering bins according to spatial similarity, and bins in the same cluster are represented with a single color. This simplifies the taxonomy; thus, inspectors can easily use it with reasonable cognitive effort. Table 3 Number of WBMs before and after augmentations. Defect pattern (Shape ‚ÄìSize‚ÄìLocation-Bin ) Original After 1st augmentation After 2nd augmentation Train Validation Test Train Validation Test 1. Cluster ‚ÄìBig‚ÄìCenter-Yellow 432 302 65 65 604 130 130 2. Cluster ‚ÄìBi"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_33", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 33, "text": "rn (Shape ‚ÄìSize‚ÄìLocation-Bin ) Original After 1st augmentation After 2nd augmentation Train Validation Test Train Validation Test 1. Cluster ‚ÄìBig‚ÄìCenter-Yellow 432 302 65 65 604 130 130 2. Cluster ‚ÄìBig‚ÄìCenter-Green 101 70 15 16 621 144 144 3. Cluster ‚ÄìBig‚ÄìCenter-Purple 456 319 68 69 636 138 138 4. Cluster ‚ÄìBig‚ÄìEdge-Yellow 5 23 5 5 621 135 135 5. Cluster ‚ÄìBig‚ÄìEdge-Green 20 23 5 5 621 135 135 6. Cluster ‚ÄìBig‚ÄìEdge-Purple 8 23 5 5 621 135 135 7. Cluster ‚ÄìBig‚Äìothers-Yellow 128 89 19 20 616 140 140 8. Cluster ‚ÄìBig‚Äìothers-Green 22 105 22 23 624 138 138 9. Cluster ‚ÄìBig‚Äìothers-Purple 28 109 23 24 648 144 144 10. Ring-All-Edge-Yellow 19 56 12 12 616 132 132 11. Ring-All-Edge-Green 18 56 12 12 616 132 132 12. Ring-All-Edge-Purple 43 56 12 12 616 132 132 13. Scratch ‚ÄìLong ‚ÄìAll-Yellow 0 63 13 14 620 140 140 14. Scratch ‚ÄìLong ‚ÄìAll-Green 35 63 13 14 620 140 140 15. Scratch ‚ÄìLong ‚Äì All-purple 55 63 13 14 620 140 140 16. Noise ‚ÄìFrequent ‚ÄìScattered-Purple 0 9 2 2 621 138 138 17. Noise ‚ÄìFrequent ‚ÄìScattered-Green 6 9 2 2 621 138 138 18. Noise ‚ÄìFrequent ‚ÄìScattered-Purple 2 9 2 2 621 138 138 19. 8-All-Center-Yellow 379 265 57 57 530 114 114 20. 8-All‚ÄìCenter-Green 3 267 57 58 532 116 116 21. 8-All‚ÄìCenter"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_34", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 34, "text": "ed-Green 6 9 2 2 621 138 138 18. Noise ‚ÄìFrequent ‚ÄìScattered-Purple 2 9 2 2 621 138 138 19. 8-All-Center-Yellow 379 265 57 57 530 114 114 20. 8-All‚ÄìCenter-Green 3 267 57 58 532 116 116 21. 8-All‚ÄìCenter-Purple 25 282 61 61 564 122 122 22. FlippedC-All-Center-Yellow 46 35 7 8 612 144 144 23. FlippedC-All-Center-Green 2 35 7 8 612 144 144 24. FlippedC-All-Center-Purple 2 35 7 8 612 144 144 Total 1835 2366 504 516 14,645 3253 3253 D.-H. Lee et al. Computers in Industry 152 (2023) 104005 94.Verification and validation of proposed taxonomy To evaluate the classification performance of the proposed method, we developed a CNN classification model using the proposed taxonomy. The first task was to prepare WBMs for training the CNN model. The WBMs of 11266 wafers were collected and manually classified according to the proposed taxonomy. Each WBM was labeled as one of the defect patterns in Table 2. However, some WBMs exhibited multiple defect patterns or did not exhibit clear defect patterns that could be classified as one of the patterns in Table 1. According to (Krawczyk, 2016 ), wafer maps showing unclear defect patterns can negatively affect learning. Therefore, we selected 1835 WBMs with"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_35", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 35, "text": " could be classified as one of the patterns in Table 1. According to (Krawczyk, 2016 ), wafer maps showing unclear defect patterns can negatively affect learning. Therefore, we selected 1835 WBMs with a single and clear defect pattern. The second column of Table 3 presents the number of WBMs for each defect pattern. We found that the number of WBMs was imbalanced among the defect patterns and that some of the defect patterns had small numbers of WBMs. Such problems of small and imbalanced data are common in defect-pattern classification and should be solved to ensure high classification performance of the CNN model (Kim et al., 2021 ). We conducted two types of data augmentation. First, we augmented WBMs by replacing colors without modifying their shape, size, or location. The purpose of this augmentation was to resolve the imbalance of colors. For example, the 22nd pattern in Table 3 (i.e., FlippedC-All-Center-Yellow ) had 46 WBMs, whereas the 23rd pattern (i.e., FlippedC-All-Center-Green ) had only two WBMs. To generate the WBMs of the 23rd pattern, we replaced the yellow color of the 46 WBMs of the 22nd pattern with green. Similarly, we replaced the purple color of the two WBMs "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_36", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 36, "text": "reen ) had only two WBMs. To generate the WBMs of the 23rd pattern, we replaced the yellow color of the 46 WBMs of the 22nd pattern with green. Similarly, we replaced the purple color of the two WBMs of the 24th pattern with green. The number of WBMs of the 23rd defect pattern was increased from 2 to 50 by generating 48 WBMs (¬à46¬á2) via simple color replacement. Then, we divided the 50 WBMs as follows: 35 WBMs for training, 7 WBMs for validation, and 8 WBMs for testing, as shown in Table 3 (ratios of approximately 70%, 15%, and 15%, respectively, which are commonly used). Thus, we augmented the WBMs of all the defect patterns and divided them into three datasets. The ‚Äúafter 1st augmentation ‚Äù column of Table 3 presents the number of WBMs for the three datasets. Although the 1st augmentation solved the problem of data imbalance between colors, the number of WBMs was still imbalanced among the shape, size, and location dimensions. To solve this problem, we con- ducted simple transformations, such as rotation, horizontal flipping, and vertical flipping, to generate augmented WBMs. We used the Image - DataGenerator library of Keras for augmentation. When conducting the transformation, "}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_37", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 37, "text": "ons, such as rotation, horizontal flipping, and vertical flipping, to generate augmented WBMs. We used the Image - DataGenerator library of Keras for augmentation. When conducting the transformation, we were careful not to disturb the defect patterns. For example, we did not apply horizontal flipping to ‚ÄúFlippedC ‚Äù patterns, because this would result in ‚ÄúC,‚Äù as shown in Fig. 11. ‚ÄúC‚Äù patterns were not defined in the proposed taxonomy. Similarly, we did not apply rotation to ‚Äú8‚Äù patterns, because the rotated ‚Äú8‚Äù patterns were not defined in the proposed taxonomy. The ‚Äúafter 2nd augmentation ‚Äù col- umn of Table 3 presents the number of WBMs for the three datasets. We trained the defect-pattern classification model using a CNN based on the original and augmented WBMs. Among the various CNN models, we used DenseNet201, which is the most widely used CNN structure for image classification. In addition, we used Adam as an optimizer and categorical cross-entropy as a loss function in training. We trained the CNN model with 100 epochs, and the accuracy for the validation dataset exceeded 0.95, as shown in Fig. 12. We evaluated the classification performance of the CNN model using a test data"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_38", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 38, "text": "We trained the CNN model with 100 epochs, and the accuracy for the validation dataset exceeded 0.95, as shown in Fig. 12. We evaluated the classification performance of the CNN model using a test dataset consisting of 3253 WBMs. The accuracy of the CMM model was 95% for this dataset. Additionally, we evaluated the classification performance with regard to four indices: accuracy, precision, recall, and F1-score. The results indicated that the classification performance was satisfactory, as shown in Table 4. Thus, a CNN model with high per- formance for defect-pattern classification can be developed using the proposed taxonomy. In addition, we compared classification performances between the proposed taxonomy and the existing SDT to validate the proposed Fig. 11.Examples of augmented WBMs not defined in the proposed taxonomy. Fig. 12.Accuracy for the training and validation datasets. Table 4 Evaluation results for the classification performance. Defect pattern (Shape ‚ÄìSize‚ÄìLocation- Bin) Precision Recall F1- score Support 1. Cluster ‚ÄìBig‚ÄìCenter-Yellow 0.96 0.99 0.97 130 2. Cluster ‚ÄìBig‚ÄìCenter-Green 0.84 0.92 0.88 144 3. Cluster ‚ÄìBig‚ÄìCenter-Purple 0.86 0.93 0.90 138 4. Cluster ‚ÄìBig‚ÄìEd"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_39", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 39, "text": " Precision Recall F1- score Support 1. Cluster ‚ÄìBig‚ÄìCenter-Yellow 0.96 0.99 0.97 130 2. Cluster ‚ÄìBig‚ÄìCenter-Green 0.84 0.92 0.88 144 3. Cluster ‚ÄìBig‚ÄìCenter-Purple 0.86 0.93 0.90 138 4. Cluster ‚ÄìBig‚ÄìEdge-Yellow 0.98 0.85 0.91 135 5. Cluster ‚ÄìBig‚ÄìEdge-Green 0.95 0.72 0.82 135 6. Cluster ‚ÄìBig‚ÄìEdge-Purple 1.00 0.85 0.92 135 7. Cluster ‚ÄìBig‚Äìothers-Yellow 0.96 1.00 0.98 140 8. Cluster ‚ÄìBig‚Äìothers-Green 0.67 0.96 0.96 138 9. Cluster ‚ÄìBig‚Äìothers-Purple 0.90 0.97 0.94 144 10. Ring-All-Edge-Yellow 1.00 0.98 0.99 132 11. Ring-All-Edge-Green 1.00 1.00 1.00 132 12. Ring-All-Edge-Purple 1.00 0.99 1.00 132 13. Scratch ‚ÄìLong ‚ÄìAll-Yellow 0.80 1.00 0.89 140 14. Scratch ‚ÄìLong ‚ÄìAll-Green 0.98 1.00 0.99 140 15. Scratch ‚ÄìLong ‚Äì All-purple 0.98 0.95 0.96 140 16. Noise ‚ÄìFrequent ‚ÄìScattered-Purple 1.00 1.00 1.00 138 17. Noise ‚ÄìFrequent ‚ÄìScattered-Green 0.92 1.00 0.96 138 18. Noise ‚ÄìFrequent ‚ÄìScattered-Purple 0.99 1.00 1.00 138 19. 8-All-Center-Yellow 0.98 0.93 0.95 114 20. 8-All‚ÄìCenter-Green 0.97 1.00 0.99 116 21. 8-All‚ÄìCenter-Purple 0.96 0.98 0.97 122 22. FlippedC-All-Center-Yellow 1.00 0.88 0.93 144 23. FlippedC-All-Center-Green 1.00 1.00 1.00 144 24. FlippedC-All-Center-Purple 0.99 1.00 1.00 144 Total 0"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_40", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 40, "text": " 21. 8-All‚ÄìCenter-Purple 0.96 0.98 0.97 122 22. FlippedC-All-Center-Yellow 1.00 0.88 0.93 144 23. FlippedC-All-Center-Green 1.00 1.00 1.00 144 24. FlippedC-All-Center-Purple 0.99 1.00 1.00 144 Total 0.96 0.96 0.96 D.-H. Lee et al. Computers in Industry 152 (2023) 104005 10taxonomy. Recently, Kim et al. (2021) developed the CNN model based on the SDT. The number of WBMs in the case example of Kim et al. (2021) was imbalanced like the case study in this section; thus, they conducted data augmentation before fitting the CNN model. Also, the CNN models of the proposed and Kim et al. (2021) ‚Äôs method are same. Thus, we believed that the comparison is fair to investigate the effect of adding color dimension to SDT. The main difference between the pro- posed taxonomy and SDT is that the proposed method considers the color dimension whereas SDT does not. To resolve this issue, we merged three defect patters having same shape-size-location into a single defect pattern. As a result, the 24 defect patterns are merged into 8 defect patterns as shown in Table 5. Average of three classification perfor - mance values are calculated accordingly. The left part of Table 5 reports the averages of the"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_41", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 41, "text": "t patterns are merged into 8 defect patterns as shown in Table 5. Average of three classification perfor - mance values are calculated accordingly. The left part of Table 5 reports the averages of the classification performance values. Originally, the SDT defined 10 defect patterns; however, six of them are common with the 8 defect patterns of the proposed taxonomy. Thus, classification performance indices for the common 6 defect patterns of the SDT are reported in the right part of Table 5. It should be noted that the CNN model developed from the proposed taxonomy shows better classifica - tion performance compared to the CNN model from the SDT. This result indicates that considering bin information in developing taxonomy and classification model is helpful for achieving high classification performance. 5.Concluding remarks We proposed a taxonomy composed of the shape, size, location, and bin dimension for classifying defect patterns. It extends the existing SDT by adding the bin dimension. The bin dimension was developed by employing the Bin2Vec method, which determines the RGB code for each bin according to the spatial similarity between bins. Three levels of the bin dimension w"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_42", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 42, "text": "nsion. The bin dimension was developed by employing the Bin2Vec method, which determines the RGB code for each bin according to the spatial similarity between bins. Three levels of the bin dimension were defined by analyzing a large number of WBMs using Bin2Vec and clustering methods. Compared with the existing taxonomies, the proposed taxonomy has the advantage of identifying major bins in WBMs, new defect patterns, and non-critical defect pat- terns. A total of 24 defect patterns were defined in the proposed tax- onomy, and a CNN model for classifying the 24 patterns was developed to validate the taxonomy. A high-quality training dataset was obtained using the proposed taxonomy; thus, the CNN model exhibited satisfac - tory classification performance. In this paper, the proposed method was solely applied to extend the specific taxonomy, SDT proposed by Choi et al. (2021) . However, the proposed method is not tied to this specific taxonomy but is a universal approach that can be applied to any defect-pattern taxonomy. Any defect-pattern taxonomies be extended by adding the bin dimension through the proposed 5-step procedure. The first four steps determine RGB for each bin and form"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_43", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 43, "text": "ed to any defect-pattern taxonomy. Any defect-pattern taxonomies be extended by adding the bin dimension through the proposed 5-step procedure. The first four steps determine RGB for each bin and form clusters based on their RGBs. Actually, the first four steps are conducted without SDT. In Step 5, SDT is extended by adding the bin dimension. In this step, SDT can be simply replaced with other taxonomy. Recently, using CNN has been a common practice when classifying the defect patterns. One of important issues of using CNN is preparing a high-quality training dataset to learn CNN classifier. The high-quality training dataset can be obtained when each defect pattern is labeled coherently through well-defined taxonomy. The proposed method could obtain the well-defined taxonomy by adding useful bin information. Major bins of defect patters, new defect patterns, and non-critical defect patterns could be identified thorough the proposed method. These cannot be obtained by solely using the existing methods such as the existing taxonomies, Bin2Vec, Clustering, CNN and so on. As a direction for future research, more systematic preprocessing and clustering are needed. In Step 2, the probe-t"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_44", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 44, "text": "xisting methods such as the existing taxonomies, Bin2Vec, Clustering, CNN and so on. As a direction for future research, more systematic preprocessing and clustering are needed. In Step 2, the probe-test dataset was preprocessed through wafer screening and the preparation of bin vectors for training the Bin2Vec model. In Step 2, we selected WBMs with large or long defect patterns. For normal wafers, we selected a single wafer for each lot to represent the characteristics of the entire wafer fairly. In addition, we set C¬à12 to generate pairs of bin vectors. In Step 4, we selected the top five bins and used them as centroids for clustering bins. We collaborated with practitioners of a semiconductor company; thus, all these decisions were based on the empirical knowledge of semi- conductor process engineers. We believe that these decisions were suitable for our probe-test data; however, they may not be suitable for other probe-test data. In this regard, the development of a more sys- tematic approach or guidelines for making optimal decisions for pre- processing and clustering is imperative. On the other hand, the proposed method uses a neural net only to train Bin2Vec model to assign"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_45", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 45, "text": "tic approach or guidelines for making optimal decisions for pre- processing and clustering is imperative. On the other hand, the proposed method uses a neural net only to train Bin2Vec model to assign RGB code for each Bin. Once every Bin has its own RGB code, bins having similar RGB codes are clustered. This clustering is conducted on empirical judgment, but it also can be con- ducted with a neural net model. In order to train the neural net model for clustering, evaluation metrics such as Silhouette coefficient can be employed. Then, optimal clusters can be formed by maximizing the evaluation metric. This might reduce the amount of empirical judgment in the clustering analysis. CRediT authorship contribution statement Dong-Hee Lee: Methodology, Writing ‚Äì original draft, Conceptual - ization, Formal analysis, Project administration, Writing ‚Äì review & editing. Eun-Su Kim: Methodology, Validation, Visualization. Seung- Hyun Choi: Validation. Young-Mok Bae: Funding acquisition, Data curation. Jong-Bum Park: Funding acquisition, Data curation. Young- Chan Oh: Funding acquisition, Data curation. Kwang-Jae Kim: Supervision. Declaration of Competing Interest The authors declare that the"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_46", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 46, "text": "ation. Jong-Bum Park: Funding acquisition, Data curation. Young- Chan Oh: Funding acquisition, Data curation. Kwang-Jae Kim: Supervision. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data Availability The data that has been used is confidential. Table 5 Comparison of classification performance of CNN models developed by two taxonomies. Defect pattern Proposed taxonomy SDT (Kim et al., 2021 ) Precision Recall F1-score Precision Recall F1-score Cluster ‚ÄìBig‚ÄìCenter 0.89 0.95 0.92 0.94 1 0.97 Cluster ‚ÄìBig‚ÄìEdge 0.98 0.81 0.88 0.91 0.75 0.82 Cluster ‚ÄìBig‚Äìothers 0.84 0.98 0.96 1 0.99 1 Ring-All-Edge 1.00 0.99 1.00 1 0.9 0.95 Scratch ‚ÄìLong ‚ÄìAll 0.92 0.98 0.95 0.93 0.95 0.94 Noise ‚ÄìFrequent ‚ÄìScattered 0.97 1.00 0.99 0.8 1 0.89 8-All-Center 0.97 0.97 0.97 N/A N/A N/A FlippedC-All-Center 1.00 0.96 0.98 N/A N/A N/A Average 0.96 0.96 0.96 0.93 0.93 0.93 D.-H. Lee et al. Computers in Industry 152 (2023) 104005 11Acknowledgement This work was supported by a research fund from SK hynix in Korea. It was also supported by the National Researc"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_47", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 47, "text": "93 0.93 0.93 D.-H. Lee et al. Computers in Industry 152 (2023) 104005 11Acknowledgement This work was supported by a research fund from SK hynix in Korea. It was also supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. NRF- 2022R1C1C1011743). Disclosure statement No potential conflict of interest was reported by the author(s). References Adly, F., Alhussein, O., Yoo, P.D., Al-Hammadi, Y., Taha, K., Muhaidat, S., Jeong, Y.-S., Lee, U., Ismail, M., 2015. Simplified subspaced regression network for identification of defect patterns in semiconductor wafer maps. IEEE Trans. Ind. Inf. 11, 1267‚Äì1276. Chen, F.-L., Liu, S.-F., 2000. A neural-network approach to recognize defect spatial pattern in semiconductor fabrication. IEEE Trans. Semicond. Manuf. 13, 366‚Äì373. https://doi.org/10.1109/66.857947. Chien, C.-F., Hsu, S.-C., Chen, Y.-J., 2013. A system for online detection and classification of wafer bin map defect patterns for manufacturing intelligence. Int. J. Prod. Res. 51, 2324‚Äì2338. https://doi.org/10.1080/00207543.2012.737943. Choi, G.-H., Kim, S.-H., Ha, C.-H., Bae, S.-J., 2012. Multi-step ART1 algorithm for recognition of def"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_48", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 48, "text": "ing intelligence. Int. J. Prod. Res. 51, 2324‚Äì2338. https://doi.org/10.1080/00207543.2012.737943. Choi, G.-H., Kim, S.-H., Ha, C.-H., Bae, S.-J., 2012. Multi-step ART1 algorithm for recognition of defect patterns on semiconductor wafers. Int. J. Prod. Res. 50, 3274‚Äì3287. https://doi.org/10.1080/00207543.2011.574502. Choi, S.-H., Kim, E.-S., Lee, D.-H., Bae, Y.-M., Oh, Y.-C., Kim, K.-J., 2021. Development of a Spatial Dimension-based Taxonomy for Classifying the Defect Patterns of a Wafer Bin Map. Cunningham, S.P., MacKinnon, S., 1998. Statistical methods for visual defect metrology. IEEE Trans. Semicond. Manuf. 11, 48‚Äì53. https://doi.org/10.1109/66.661284. Fan, S.K.S., Lin, S.C., Tsai, P.F., 2016. Wafer fault detection and key step identification for semiconductor manufacturing using principal component analysis, AdaBoost and decision tree. J. Ind. Prod. Eng. 33, 151‚Äì168. https://doi.org/10.1080/ 21681015.2015.1126654. Hsieh, H.-W., Chen, F.-L., 2004. Recognition of defect spatial patterns in semiconductor fabrication. Int. J. Prod. Res. 42, 4153‚Äì4172. https://doi.org/10.1080/ 00207540410001716507. Hwang, J.Y., Kuo, W., 2007. Model-based clustering for integrated circuit yield enha"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_49", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 49, "text": "erns in semiconductor fabrication. Int. J. Prod. Res. 42, 4153‚Äì4172. https://doi.org/10.1080/ 00207540410001716507. Hwang, J.Y., Kuo, W., 2007. Model-based clustering for integrated circuit yield enhancement. Eur. J. Oper. Res. 178, 143‚Äì153. https://doi.org/10.1016/j. ejor.2005.11.032. Kim, E.-S., Choi, S., Lee, D., Kim, K., Bae, Y., Oh, Y.-C., 2021. An oversampling method for wafer map defect pattern classification considering small and imbalanced data. Comput. Ind. Eng. 162, 107767 https://doi.org/10.1016/j.cie.2021.107767. Kim, J.-H., Kim, H.-S., Park, J.-S., Mo, K.-H., Kang, P.-S., 2019. Bin2Vec: a better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer classification. Appl. Sci. 9, 597. https://doi.org/10.3390/app9030597. Krawczyk, B., 2016. Learning from imbalanced data: open challenges and future directions. Prog. Artif. Intell. 5, 221‚Äì232. https://doi.org/10.1007/s13748-016- 0094-0. Kyeong, K., Kim, H., 2018. Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks. IEEE Trans. Semicond. Manuf. 31, 395‚Äì402. https://doi.org/10.1109/TSM.2018.2841416. Li, T.-S., Huang, C.-L., 2009. Defect spatial p"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_50", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 50, "text": "fect patterns in wafer bin maps using convolutional neural networks. IEEE Trans. Semicond. Manuf. 31, 395‚Äì402. https://doi.org/10.1109/TSM.2018.2841416. Li, T.-S., Huang, C.-L., 2009. Defect spatial pattern recognition using a hybrid SOM‚ÄìSVM approach in semiconductor manufacturing. Expert Syst. Appl. 36, 374‚Äì385. https:// doi.org/10.1016/j.eswa.2007.09.023. Liu, C.W., Chien, C.F., 2013. An intelligent system for wafer bin map defect diagnosis: an empirical study for semiconductor manufacturing. Eng. Appl. Artif. Intell. 26, 1479‚Äì1486. https://doi.org/10.1016/J.ENGAPPAI.2012.11.009. Liukkonen, M., Hiltunen, Y., 2018. Recognition of systematic spatial patterns in silicon wafers based on SOM and K-means. IFAC-PapersOnLine 51, 439‚Äì444. https://doi. org/10.1016/j.ifacol.2018.03.075. Mikolov, T., Chen, K., Corrado, G., Dean, J., 2013a. Efficient estimation of word representations in vector space. In: 1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings, pp. 1‚Äì12. Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., 2013b. Distributed representations of words and phrases and their compositionality. Adv. Neural Inf. Process Syst. 3111‚Äì311"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_51", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 51, "text": "ings, pp. 1‚Äì12. Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., 2013b. Distributed representations of words and phrases and their compositionality. Adv. Neural Inf. Process Syst. 3111‚Äì3119. Nakata, K., Orihara, R., Mizuoka, Y., Takagi, K., 2017. A comprehensive big-data-based monitoring system for yield enhancement in semiconductor manufacturing. IEEE Trans. Semicond. Manuf. 30, 339‚Äì344. https://doi.org/10.1109/ TSM.2017.2753251. Nakazawa, T., Kulkarni, D.V., 2018. Wafer map defect pattern classification and image retrieval using convolutional neural network. IEEE Trans. Semicond. Manuf. 31, 309‚Äì314. https://doi.org/10.1109/TSM.2018.2795466. Piao, M., Jin, C.H., Lee, J.Y., Byun, J.-Y., 2018. Decision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features. IEEE Trans. Semicond. Manuf. 31, 250‚Äì257. https://doi.org/10.1109/TSM.2018.2806931. Saqlain, M., Jargalsaikhan, B., Lee, J.Y., 2019. A voting ensemble classifier for wafer map defect patterns identification in semiconductor manufacturing. IEEE Trans. Semicond. Manuf. 32, 171‚Äì182. https://doi.org/10.1109/TSM.2019.2904306. Shim, J., Kang, S., Cho, S., 2020. Active learning of c"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_52", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 52, "text": "fect patterns identification in semiconductor manufacturing. IEEE Trans. Semicond. Manuf. 32, 171‚Äì182. https://doi.org/10.1109/TSM.2019.2904306. Shim, J., Kang, S., Cho, S., 2020. Active learning of convolutional neural network for cost-effective wafer map pattern classification. IEEE Trans. Semicond. Manuf. 33, 258‚Äì266. https://doi.org/10.1109/TSM.2020.2974867. Wang, C.-H., 2009. Separation of composite defect patterns on wafer bin map using support vector clustering. Expert Syst. Appl. 36, 2554‚Äì2561. https://doi.org/ 10.1016/j.eswa.2008.01.057. Wang, C.-H., Kuo, W., Bensmail, H., 2006. Detection and classification of defect patterns on semiconductor wafers. IIE Trans. 38, 1059‚Äì1068. https://doi.org/10.1080/ 07408170600733236. Wu, M.-J., Jang, J.-S.R., Jui-Long, Chen, 2015. Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Trans. Semicond. Manuf. 28, 1‚Äì12. https://doi.org/10.1109/TSM.2014.2364237. Yu, J., Lu, X., 2016. Wafer map defect detection and recognition using joint local and nonlocal linear discriminant analysis. IEEE Trans. Semicond. Manuf. 29, 33‚Äì43. https://doi.org/10.1109/TSM.2015.2497264. Yu, J., Shen, Z., Wang, S., 2021. Waf"}
{"id": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf::chunk_53", "source": "Development of taxonomy for classifying defect patterns on wafer bin map using Bin2Vec and clustering methods.pdf", "chunk_index": 53, "text": "ion and recognition using joint local and nonlocal linear discriminant analysis. IEEE Trans. Semicond. Manuf. 29, 33‚Äì43. https://doi.org/10.1109/TSM.2015.2497264. Yu, J., Shen, Z., Wang, S., 2021. Wafer map defect recognition based on deep transfer learning-based densely connected convolutional network and deep forest. Eng. Appl. Artif. Intell. 105, 104387 https://doi.org/10.1016/J.ENGAPPAI.2021.104387. Yuan, T., Kuo, W., 2007. A model-based clustering approach to the recognition of the spatial defect patterns produced during semiconductor fabrication. IIE Trans. 40, 93‚Äì101. https://doi.org/10.1080/07408170701592556. Yuan, T., Kuo, W., Bae, S.J., 2011. Detection of spatial defect patterns generated in semiconductor fabrication processes. IEEE Trans. Semicond. Manuf. 24, 392‚Äì403. https://doi.org/10.1109/TSM.2011.2154870. Zhou, Q., Zeng, L., Zhou, S., 2010. Statistical detection of defect patterns using hough transform. IEEE Trans. Semicond. Manuf. 23, 370‚Äì380. https://doi.org/10.1109/ TSM.2010.2048959. D.-H. Lee et al."}
{"id": "Efficient Production Binning.pdf::chunk_0", "source": "Efficient Production Binning.pdf", "chunk_index": 0, "text": "UPCommons Portal del coneixement obert de la UPC http://upcommons.upc.edu/e -prints Aquesta √©s una c√≤pia de la versi√≥ author‚Äôs final draft d'un article publicat a la revista IEEE Transactions on Computer -Aided Design of Integrated Circuits and Systems . URL d'aquest document a UPCommons E-prints: http://hdl.handle.net/2117/83209 Paper publicar / Published paper : Gomez -Pau, A.; Balado, L.; Figueras, J. (2015) Efficient p roduction binning using octree tessellation in the alternate measurements space . IEEE Transactions on Computer -Aided Design of I ntegrated Circuits and Systems. D oi: 10.1109/TCAD.2015.2501309 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 1 EfÔ¨Åcient Production Binning Using Octree Tessellation in the Alternate Meas"}
{"id": "Efficient Production Binning.pdf::chunk_1", "source": "Efficient Production Binning.pdf", "chunk_index": 1, "text": " information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 1 EfÔ¨Åcient Production Binning Using Octree Tessellation in the Alternate Measurements Space ¬¥Alvaro G ¬¥omez-Pau, Student Member, IEEE , Luz Balado, Joan Figueras, Member, IEEE Abstract ‚ÄîBinning after volume production is a widely ac- cepted technique to classify fabricated ICs into different clusters depending on different degrees of speciÔ¨Åcation compliance. This allows the manufacturer to sell non optimal devices at lower rates, so adapting to customer‚Äôs quality-price requirements. The binning procedure can be carried out by measuring every single circuit performances, but this approach is costly and time consuming. On the contrary, if alternate measurements are used to characterize the bins, the procedure is considerably enhanced. In such a case, the speciÔ¨Åcation bin boundaries become arbitrary shape regions due to the highly non linear mappings between the speciÔ¨Åcations space and the alternate measurements space. The binning strategy proposed in this work functions with the same efÔ¨Åciency regardless of these shapes. The digital encoding of the bins in the al"}
{"id": "Efficient Production Binning.pdf::chunk_2", "source": "Efficient Production Binning.pdf", "chunk_index": 2, "text": "Ô¨Åcations space and the alternate measurements space. The binning strategy proposed in this work functions with the same efÔ¨Åciency regardless of these shapes. The digital encoding of the bins in the alternate measurements space using octrees is the key idea of the proposal. The strategy has two phases, the training phase and the binning phase. In the training phase, the speciÔ¨Åcation bins are encoded using octrees. This Ô¨Årst phase requires sufÔ¨Åcient samples of each class to generate the octree under realistic variations, but it only needs to be performed once. The binning phase corresponds to the actual production binning of the fabricated ICs. This is achieved by evaluating the alternate measurements in the previously generated octree. The binning phase is fast due to the inherent sparsity of the octree data structure. In order to illustrate the proposal, the method has been applied to a band-pass Butterworth Ô¨Ålter considering three speciÔ¨Åcation bins as a proof of concept. Successful simu- lation results are reported showing considerable advantages as compared to a SVM based classiÔ¨Åer. Similar bin misclassiÔ¨Åcations are obtained with both methods, 1.68% using octrees and 1.83% using "}
{"id": "Efficient Production Binning.pdf::chunk_3", "source": "Efficient Production Binning.pdf", "chunk_index": 3, "text": "mu- lation results are reported showing considerable advantages as compared to a SVM based classiÔ¨Åer. Similar bin misclassiÔ¨Åcations are obtained with both methods, 1.68% using octrees and 1.83% using SVM, while binning time is 5X times faster using octrees than using the SVM based classiÔ¨Åer. Index Terms‚ÄîProduction Binning, SpeciÔ¨Åcation Binning, Quality Binning, Alternate Test, Analog and Mixed-Signal Test, Quadtrees, Octrees, ClassiÔ¨Åers, Feature Selection, Signature Se- lection, Quality Metrics, Analog Filter, Butterworth Filter. I. I NTRODUCTION FABRICATED ICs may present different degrees of spec- iÔ¨Åcation compliance due to manufacturing process vari- ations. Some devices exhibit excellent performance, therefore they are closer to nominal speciÔ¨Åcations, while others present worse performance, indicating they are far away from nominal specs. SpeciÔ¨Åcation based binning has been used as an efÔ¨Åcient The authors are with the Department of Electronics Engineering at Univer- sitat Polit `ecnica de Catalunya (UPC-BarcelonaTech). Av. Diagonal, 647, 9th Ô¨Çoor, 08028, Barcelona, Spain. Contact email: alvaro.gomez-pau@upc.edu. This work has been partially supported by the Spanish Ministry of "}
{"id": "Efficient Production Binning.pdf::chunk_4", "source": "Efficient Production Binning.pdf", "chunk_index": 4, "text": "nica de Catalunya (UPC-BarcelonaTech). Av. Diagonal, 647, 9th Ô¨Çoor, 08028, Barcelona, Spain. Contact email: alvaro.gomez-pau@upc.edu. This work has been partially supported by the Spanish Ministry of Economics and Competitiveness, projects references TEC2010-18384 and TEC2013-41209-P, and European Union FEDER funds. The authors would like to thank the Reviewers for their helpful improve- ment comments.way of increasing production proÔ¨Åt for digital circuits [1]‚Äì [5]. To this purpose, several binning goals are considered, traditionally, power consumption and speed [6], [7]. Similar concept has been applied for binning analog and mixed-signal circuits [6], [8]. Production testing of analog and mixed-signal circuits is an increasingly challenging task due to the presence of statisti- cal variations related with the manufacturing process which directly affect circuit speciÔ¨Åcations [9], [10]. High amount of resources are solely dedicated to test and diagnose such devices to ensure that only speciÔ¨Åcation compliant circuits are shipped to customers [10], [11]. One possible option to reduce these costs is to perform a speciÔ¨Åcation based binning [6]. This allows the manufacturer to classify "}
{"id": "Efficient Production Binning.pdf::chunk_5", "source": "Efficient Production Binning.pdf", "chunk_index": 5, "text": "speciÔ¨Åcation compliant circuits are shipped to customers [10], [11]. One possible option to reduce these costs is to perform a speciÔ¨Åcation based binning [6]. This allows the manufacturer to classify devices according to a quality criterion depending on how close the circuit is to nominal speciÔ¨Åcations [6]. Binning of mixed-signal circuits can be achieved by sim- ply measuring the speciÔ¨Åcations as in classic speciÔ¨Åcation based testing or by performing alternate measurements that correlate to actual speciÔ¨Åcations [12], [13]. Alternate testing techniques require a mapping between the speciÔ¨Åcation space and the measurements space in order to allow the test decision to be performed. ArtiÔ¨Åcial intelligence [14] and regression techniques [13], [15], [16] have been used with successful results to this purpose, as well as using octrees to represent the pass/fail regions [17], [18]. In this paper, octree data structures are used to encode the speciÔ¨Åcation bins in the alternate measurements space. The rest of paper is organized as follows. Section II presents the procedure for binning mixed-signal circuits using octrees in the alternate measurements space. Also, and due to the novelty of the"}
{"id": "Efficient Production Binning.pdf::chunk_6", "source": "Efficient Production Binning.pdf", "chunk_index": 6, "text": "e. The rest of paper is organized as follows. Section II presents the procedure for binning mixed-signal circuits using octrees in the alternate measurements space. Also, and due to the novelty of the application of octrees in this Ô¨Åeld, a brief introduction to the generation of octrees and their application to encode the bins in the measurements space is given. Section III deÔ¨Ånes some efÔ¨Åciency metrics to evaluate the resulting octree in terms of binning time estimation, incurred global bin escapes and noise impact. Section IV focuses on the application of the previously presented methodology to bin a 4th order Butterworth Ô¨Ålter using alternate measurements [17], [19]. A criterion to select an adequate set of alternate measurements to avoid redundancy is presented. Section V reports the simulation results and presents the efÔ¨Åciency of the binning procedure using the previously deÔ¨Åned quality metrics. The octree binning technique is compared to a state of the art classiÔ¨Åer based on support vector machines. Finally, section VI summarizes the work and concludes the paper. 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Se"}
{"id": "Efficient Production Binning.pdf::chunk_7", "source": "Efficient Production Binning.pdf", "chunk_index": 7, "text": "port vector machines. Finally, section VI summarizes the work and concludes the paper. 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 2 II. S PECIFICATION BASED BINNING OF MIXED -SIGNAL CIRCUITS The procedure of binning analog and mixed-signal circuits after volume production can be formalized as the classiÔ¨Åcation of any candidate circuit into a cluster, according to certain cir- cuit performances, among several possible disjoint bins. Such clustering is performed according to parameters of different nature. The most common space for binning mixed-signal circuits is the speciÔ¨Åcations space in which circuit performances are directly measured and binned accordingly. Process variations may cause some circuits to violate or not fulÔ¨Åll the s"}
{"id": "Efficient Production Binning.pdf::chunk_8", "source": "Efficient Production Binning.pdf", "chunk_index": 8, "text": "g mixed-signal circuits is the speciÔ¨Åcations space in which circuit performances are directly measured and binned accordingly. Process variations may cause some circuits to violate or not fulÔ¨Åll the set of functional speciÔ¨Åcations related to certain bins. The effect of the uncertainties in the manufacturing process are modeled in this work by the statistical distributions offered by tech- nology‚Äôs process design kit in the components space. Direct measurement of circuit speciÔ¨Åcations is difÔ¨Åcult and time consuming [10]. To overcome these drawbacks, the use of alternate measurements is widely adopted as an indirect and effective solution to test analog and mixed-signal ICs [13]. In this work, the term measurements space will be used to designate the alternate measurements which will facilitate the binning process. Fig. 1 sketches these three spaces and the bin boundaries deÔ¨Åned according to certain speciÔ¨Åcation levels. M2M3 M1 SpaceSpecifications SpaceComponents Alternate Measurements Spacespec2 spec1spec3 C1‚àÜ ‚àÜ ‚àÜNOMINAL C2C3 Bin 1Bin 2Bin 3 Bin 1Bin 2Bin 3 Fig. 1. Sketch of the three spaces considered in this work. Components space variability induce deviations in the speciÔ¨Åcations"}
{"id": "Efficient Production Binning.pdf::chunk_9", "source": "Efficient Production Binning.pdf", "chunk_index": 9, "text": "pacespec2 spec1spec3 C1‚àÜ ‚àÜ ‚àÜNOMINAL C2C3 Bin 1Bin 2Bin 3 Bin 1Bin 2Bin 3 Fig. 1. Sketch of the three spaces considered in this work. Components space variability induce deviations in the speciÔ¨Åcations space as well as in the alternate measurements space in which the binning process takes place. The proposed production binning methodology is performed in two phases, namely, training and binning phases. First, the training phase encodes the speciÔ¨Åcation bins in the measure- ments space using octrees relying on circuit samples obtained by simulation, model evaluation or actual production data. After the training phase, the production binning is achieved by evaluating the alternate measurements of a candidate circuit in the previously trained octree data structure. A. Training Phase In order to encode the bins in the measurements space, a considerable amount of representative data need to be generated. This can be done entirely relying on simulations, circuit models or by using available data on the production run with already binned ICs. Of course, accelerating techniques for obtaining representative bin border circuits can also be used, such us statistical blockade [20], stratiÔ¨Åed sa"}
{"id": "Efficient Production Binning.pdf::chunk_10", "source": "Efficient Production Binning.pdf", "chunk_index": 10, "text": "ata on the production run with already binned ICs. Of course, accelerating techniques for obtaining representative bin border circuits can also be used, such us statistical blockade [20], stratiÔ¨Åed sampling [21], cop- ula theory [22] or estimating the probability density function using kernels [23]. The deÔ¨Åned bins in the speciÔ¨Åcation spacewill map to arbitrary regions in the measurements space which will be used for binning the forthcoming circuits. As an example of circuit data generation in the measure- ments space, 104Monte Carlo circuit samples of a 4th order band-pass Butterworth Ô¨Ålter have been generated relying on HSPICE simulations. Fig. 2 shows these circuits in the mea- surements space where green points encode circuits fulÔ¨Ålling the speciÔ¨Åcations (bin 1), yellow points indicate circuits pre- senting marginal speciÔ¨Åcations (bin 2) and red points indicate circuits not satisfying all the speciÔ¨Åcations (bin 3). Further explanations on circuit speciÔ¨Åcations and bin deÔ¨Ånitions will be given in section IV. ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits Fig. 2. Monte Carlo samples of a 4th order b"}
{"id": "Efficient Production Binning.pdf::chunk_11", "source": "Efficient Production Binning.pdf", "chunk_index": 11, "text": "ll be given in section IV. ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits Fig. 2. Monte Carlo samples of a 4th order band-pass Butterworth Ô¨Ålter in the measurements space. The circuit has been designed and simulated using an industrial 65 nm CMOS technology. Once circuit data are generated, they need to be digitally encoded using an octree data structure. This data structure presents the advantage of being able to represent arbitrary n-dimensional regions and the capability of controlling its resolution by just limiting the maximum depth level. Such tree structures can be digitally represented and are easily evaluated using recursion. Next section describes how octrees can be created using circuit data samples. B. Octree Encoding Octrees have been extensively used in the Ô¨Åeld of computer graphics since they were proposed in [24]. Their main ap- plications include texture rendering, image color quantization, object identiÔ¨Åcation, and data clustering. In this work, octrees will be used to encode the speciÔ¨Åcation bins in the alternate measurements space. An octree data structure of dimension nis a tree i"}
{"id": "Efficient Production Binning.pdf::chunk_12", "source": "Efficient Production Binning.pdf", "chunk_index": 12, "text": "n, object identiÔ¨Åcation, and data clustering. In this work, octrees will be used to encode the speciÔ¨Åcation bins in the alternate measurements space. An octree data structure of dimension nis a tree in which each node has exactly 2nchildren or none. Octrees are a particular case of k-ary trees, where k= 2n. Octrees usually represent a geometric partition of a three dimensional space, 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 3 hence each node has exactly 8 children, what gives its name. For the case of two dimensional applications, they also receive the name of quadtrees since each node has exactly 4 children. The concept can be easily generalized to n-dimensional spaces where sometimes are referred as 2n-ary trees, or simply n- di"}
{"id": "Efficient Production Binning.pdf::chunk_13", "source": "Efficient Production Binning.pdf", "chunk_index": 13, "text": "y also receive the name of quadtrees since each node has exactly 4 children. The concept can be easily generalized to n-dimensional spaces where sometimes are referred as 2n-ary trees, or simply n- dimensional octrees, which is the term used in this work. 1 2 27 48 73 3 12 21 22 28 29 30 47 49 50 55 64 74 83 84 93 4 5 6 7 13 14 15 20 23 24 25 26 8 9 10 11 16 17 18 1931 36 41 42 32 33 34 35 37 38 39 40 43 44 45 4651 52 53 54 56 57 62 63 65 70 71 72 58 59 60 61 66 67 68 6975 76 77 82 85 90 91 92 78 79 80 81 86 87 88 89 Fig. 3. Graph representation of the quadtree depicted in Fig. 4. For illustration purposes, only two bins have been considered, i.e. green and red. The resulting tree is 4 levels deep and has 93 nodes. As an example of data encoding using octrees, consider the set of two dimensional alternate measurements shown in Fig. 4. The color of each pair of measurements indicate they belong to bin 1 (green) or bin 2 (red). Initially, and also during the whole process, the theoretical boundary separating both bins is unknown, so the presented algorithm is solely based on the alternate measurements. The encoding algorithm starts with the deÔ¨Ånition of a square cell (root node) incl"}
{"id": "Efficient Production Binning.pdf::chunk_14", "source": "Efficient Production Binning.pdf", "chunk_index": 14, "text": "l boundary separating both bins is unknown, so the presented algorithm is solely based on the alternate measurements. The encoding algorithm starts with the deÔ¨Ånition of a square cell (root node) including all the data to be considered in the training phase. Then, the square is tessellated in 4 equal regions by halving each dimension. Each of these 4 generated regions is further examined. If it exclu- sively contains single bin measurements, the square is tagged accordingly to that class and no further partitioning is needed. Otherwise, the square is marked as decision pending (white parent nodes in Fig. 3) and the tessellation/labeling procedure continues until all the generated squares only contain equal class measurements. ‚àí1 ‚àí0.5 0 0.5 1‚àí1‚àí0.8‚àí0.6‚àí0.4‚àí0.200.20.40.60.81 Measure 1 (arb. units)Measure 2 (arb. units) Bin 1 circuits Bin 2 circuits Actual boundary Fig. 4. Example of a quadtree generated using 100 bivariate Gaussian samples and two bins. The actual boundary separating both bins is represented by the thick orange line. The resulting quadtree is 4 levels deep and has the graph representation depicted in Fig. 3. Depending on the underlying statistical distributions of th"}
{"id": "Efficient Production Binning.pdf::chunk_15", "source": "Efficient Production Binning.pdf", "chunk_index": 15, "text": "h bins is represented by the thick orange line. The resulting quadtree is 4 levels deep and has the graph representation depicted in Fig. 3. Depending on the underlying statistical distributions of the available alternate measurements, octree cells containing nodata may occur in deep levels. In this case, unknown octree cells are labeled accordingly to the bin assigned to the majority of their neighboring cells. C. Binning Phase As mentioned earlier, the binning phase corresponds to the actual production binning of the fabricated ICs using the octree data structure encoded in the former training phase. The binning procedure is time efÔ¨Åcient due to the sparsity of the octree as will be shown later. Consider a pair of alternate circuit measurements, (M1;M2), corresponding to a fabricated circuit aiming to be binned using, for instance, the octree depicted in Fig. 4. The binning procedure is performed using the graph of Fig. 3. Assuming the pair of alternate measurements are within the initial square box (root node), the binning algorithm computes to which of the four quadrants the measurements belong to by performing one comparison per coordinate. This decision brings the candidate c"}
{"id": "Efficient Production Binning.pdf::chunk_16", "source": "Efficient Production Binning.pdf", "chunk_index": 16, "text": "itial square box (root node), the binning algorithm computes to which of the four quadrants the measurements belong to by performing one comparison per coordinate. This decision brings the candidate circuit to a new bound hence a new and deeper octree level is achieved. If the current node is labeled, the circuit is mapped to that bin and the evaluation Ô¨Ånishes. If not, the evaluation algorithm repeats the comparison operation through the graph until a labeled node is found (tree leafs) and the circuit is binned. The pseudocode of the binning algorithm using octrees is listed in Fig. 5. 1:function EVALMEASUREMENTS (N;M ) 2: Precond:Nis an octree node data structure 3: Precond:Mis a vector of alternate measurements 4: ifN:label6=NULL then 5: returnN:label 6: else 7:idchild compare(M;N:center ) 8:N N:child [idchild ] 9: return EVALMEASUREMENTS (N;M ) 10: end if 11:end function Fig. 5. Pseudocode of a recursive implementation of the binning process using octrees in the alternate measurements space. Octree evaluation is efÔ¨Åcient since only one comparison per coordinate and level is required. III. E FFICIENCY METRICS A. Binning Complexity Estimation The process of binning analog and mix"}
{"id": "Efficient Production Binning.pdf::chunk_17", "source": "Efficient Production Binning.pdf", "chunk_index": 17, "text": "nts space. Octree evaluation is efÔ¨Åcient since only one comparison per coordinate and level is required. III. E FFICIENCY METRICS A. Binning Complexity Estimation The process of binning analog and mixed-signal circuits using octrees can be formalized as an application between then-dimensional alternate measurements space and natural numbers. That is, for any vector of alternate measurements, M2Rn, the octree maps it to a bin b=O(M)2N, O:Rn!N M7!b(1) 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 4 Similarly, let h(M)be the application mapping any vector of alternate measurements, M2Rn, to the maximum octree depth (or height) at that exact location. Under such deÔ¨Ånitions and according to the concepts and algorithm exposed in previous sec"}
{"id": "Efficient Production Binning.pdf::chunk_18", "source": "Efficient Production Binning.pdf", "chunk_index": 18, "text": "ng any vector of alternate measurements, M2Rn, to the maximum octree depth (or height) at that exact location. Under such deÔ¨Ånitions and according to the concepts and algorithm exposed in previous section, the number of comparisons, Nc, to bin a circuit using a vector of alternate measurements, M, turns to beNc=nh(M ), i.e. one comparison per coordinate and level traversed. Moreover, if P(M)denotes the joint probability density distribution in the alternate measurements sample space \u001aRn, the average number of comparisons to bin a circuit using the octree data structure is, fNc=nZ h(M)P(M)dM nhmax (2) Despite of the fact that the number of nodes of a sparse 2n-tree grows exponentially with the dimensionality of the measurements space, is because of such inherent sparsity [17] that the average number of required comparisons is far below the theoretical upper bound nhmax. This fact makes octree evaluation time efÔ¨Åcient and easy to be digitally implemented as the algorithm listed in Fig. 5 clearly states. B. Bin Escapes As pointed before, the binning phase consists on the eval- uation of a candidate circuit in the octree generated in the training phase, b=O(M), according to previously "}
{"id": "Efficient Production Binning.pdf::chunk_19", "source": "Efficient Production Binning.pdf", "chunk_index": 19, "text": " clearly states. B. Bin Escapes As pointed before, the binning phase consists on the eval- uation of a candidate circuit in the octree generated in the training phase, b=O(M), according to previously introduced notations. Certain circuits may be incorrectly binned due to insufÔ¨Åcient octree resolution or noise in the measurements. Similarly to test escapes and test yield loss, a new metric to measure the quality of the binning procedure needs to be deÔ¨Åned. Here forth, these circuits will be referred as bin escapes. In order to quantify this metric, let pdenote the number of bins and let us deÔ¨Åne a p\u0002pmatrixE= (eij) referred from now on as the bin escapes matrix. Element eij inbin escapes matrix indicates how many circuits certainly belonging to bin ihave been clustered into bin j. Then, the global bin escapes metric can be naturally deÔ¨Åned as the sum of all the misclassiÔ¨Åed circuits as follows, GBE =pX i;j=1 i6=jeij (3) Then, it is clear that the circuits accounted in the diagonal of the bin escapes matrix correspond to correctly binned circuits. On the contrary, circuits accounted above or below the diagonal of the bin escapes matrix are circuits that have been misclassiÔ¨Åed. Circui"}
{"id": "Efficient Production Binning.pdf::chunk_20", "source": "Efficient Production Binning.pdf", "chunk_index": 20, "text": "e bin escapes matrix correspond to correctly binned circuits. On the contrary, circuits accounted above or below the diagonal of the bin escapes matrix are circuits that have been misclassiÔ¨Åed. Circuits above the diagonal are circuits classiÔ¨Åed in a worse performance bin than the actual circuits. On the contrary, elements located below the diagonal correspond to circuits classiÔ¨Åed in a bin being representative of better circuit performances than the actual circuit. Bin escapes matrix is being used in section V to evaluate the efÔ¨Åciency of the proposed binning procedure.C. Noise Impact Under realistic conditions, any circuit measurements is subjected to certain level of uncertainty, mainly due to the noise present in the measurements. Assume a voltage range Vrange and a maximum uncertainty level in the measure of Vnoise, what gives the dynamic range of the measurement, DNR =Vrange=Vnoise. Since each octree level halves the range, it is clear that the resolution is Vrange=2hmax, beinghmaxthe maximum octree height. Given the previous deÔ¨Ånitions, it is clear that the maximum required octree depth under the mentioned noise conditions is hmax=dlog2DNRe. If octree computation is stopped a"}
{"id": "Efficient Production Binning.pdf::chunk_21", "source": "Efficient Production Binning.pdf", "chunk_index": 21, "text": "xthe maximum octree height. Given the previous deÔ¨Ånitions, it is clear that the maximum required octree depth under the mentioned noise conditions is hmax=dlog2DNRe. If octree computation is stopped at level hmax, even when circuit data is available to continue tessellating the space beyond level hmax, the impact of noise can be quantiÔ¨Åed as the ratio of the decision pending cells hypervolume and the root node hypervolume. Of course, bin escapes will also reÔ¨Çect the noise impact since the values located above and below the diagonal of bin escapes matrix will increase. In the subsequently presented case study the impact of noise in the binning efÔ¨Åciency is also explored. IV. C ASE STUDY : 4THORDER BAND -PASSBUTTERWORTH FILTER A. SpeciÔ¨Åcations Space and Alternate Measurements Space In order to show the viability of the proposed binning methodology using octrees, it has been applied to bin a 4th order band-pass Butterworth Ô¨Ålter in the alternate mea- surements space. The Butterworth Ô¨Ålter has been designed and simulated in an industrial 65 nm N-well bulk CMOS technology from ST-Microelectronics [25] as illustrated in the schematic shown in Fig. 6. The used topology corresponds to a mu"}
{"id": "Efficient Production Binning.pdf::chunk_22", "source": "Efficient Production Binning.pdf", "chunk_index": 22, "text": " has been designed and simulated in an industrial 65 nm N-well bulk CMOS technology from ST-Microelectronics [25] as illustrated in the schematic shown in Fig. 6. The used topology corresponds to a multiple feedforward implementation [26] according to the design speciÔ¨Åcations shown in Table I. The designed Butterworth Ô¨Ålter has been tuned at 1 MHz with a 500 kHz bandwidth. Circuit components have been chosen to meet the aforementioned speciÔ¨Åcations and im- plemented using technology speciÔ¨Åc passive components as illustrated in Fig. 6. Resistors have been implemented using Ô¨Åxed width high resistance polysilicon resistors and capacitors using metal-insulator-metal capacitors. The sheet resistance of the used polysilicon resistors is approximately, Rs= 6k /\u0003, while the capacitance of the used metal-insulator-metal capac- itors is about 5fF/\u0016m2. TABLE I BUTTERWORTH FILTER DESIGN SPECIFICATIONS Design SpeciÔ¨Åcation Symbol Value Units Filter order n 4 Center frequency f0 1 MHz Bandwidth (\u00003 dB) BW 500 kHz Band-pass gain G \u00003 dB Even though the presented methodology can be naturally extended to an arbitrary number of bins, in this work only 0278-0070 (c) 2015 IEEE. Personal use is permitte"}
{"id": "Efficient Production Binning.pdf::chunk_23", "source": "Efficient Production Binning.pdf", "chunk_index": 23, "text": "B) BW 500 kHz Band-pass gain G \u00003 dB Even though the presented methodology can be naturally extended to an arbitrary number of bins, in this work only 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 5 ‚àí +‚àí +‚àí +‚àí +‚àí +Vbias Vbias Vbias Vbias VbiasC C C C R R R RR RRi Rf1Rf2 Rf2OA1 OA2 OA3 OA4 OA5Vin Vout Fig. 6. Schematic of the 4th order band-pass Butterworth Ô¨Ålter used as case study. The chosen topology corresponds to a multiple feedforward implementation [26]. The Ô¨Ålter has been designed and simulated using a low-power standard-Vt 65 nm CMOS technology from ST-Microelectronics. Passive elements correspond to Ô¨Åxed width high resistance polysilicon resistors (rhiporpo) and metal-insulator-metal capacitors (mim). Components values are R= 1"}
{"id": "Efficient Production Binning.pdf::chunk_24", "source": "Efficient Production Binning.pdf", "chunk_index": 24, "text": "S technology from ST-Microelectronics. Passive elements correspond to Ô¨Åxed width high resistance polysilicon resistors (rhiporpo) and metal-insulator-metal capacitors (mim). Components values are R= 10 k , Ri= 4R,Rf1= 0:444R ,Rf2= 1:414R andC= 15:9 pF. Power supply for this technology is 1.2 V . three bins have been considered as a proof of concept. Table II deÔ¨Ånes bin boundaries based on frequency/gain performances of every sample circuit. For instance, a circuit will be classiÔ¨Åed in bin 1 if and only if all the following conditions are satisÔ¨Åed: (1) the Ô¨Ålter presents a gain less than \u00001:8 dB within the 262.8 kHz band-pass bandwidth, (2) it attenuates no more than \u00004:2 dB within the 262.8 kHz band-pass bandwidth and (3) it attenuates more than \u000049:0 dB at the stop-band corner fre- quencies (9.9 MHz bandwidth). Analogous reasoning applies for bins 2 and 3 according to the information shown in Table II. TABLE II BUTTERWORTH FILTER BINLIMITS SpeciÔ¨Åcation Bins 1‚Äì2 Bins 2‚Äì3 Units Pass-band bandwidth 262.8 530.8 kHz Stop-band bandwidth 9.9 14.9 MHz Max pass-band gain \u00001:8 \u00001:4 dB Min pass-band gain \u00004:2 \u000010:8 dB Min stop-band gain \u000049:0 \u000056:0 dB Circuit excitation is achieved by applyi"}
{"id": "Efficient Production Binning.pdf::chunk_25", "source": "Efficient Production Binning.pdf", "chunk_index": 25, "text": "d bandwidth 262.8 530.8 kHz Stop-band bandwidth 9.9 14.9 MHz Max pass-band gain \u00001:8 \u00001:4 dB Min pass-band gain \u00004:2 \u000010:8 dB Min stop-band gain \u000049:0 \u000056:0 dB Circuit excitation is achieved by applying a single 3 tone input stimulus. The chosen tones correspond to Ô¨Ålter‚Äôs center frequency, an octave lower and an octave higher. The input- output composition can be considered as an analog signature characterizing the Ô¨Ålter and its level of speciÔ¨Åcation com- pliance [27]‚Äì[29]. Fig. 7 shows the input-output Lissajous composition for a nominal Ô¨Ålter when it is excited using the aforementioned 3 tone stimulus as well as the Lissajous trace when the stimulus is applied to a Ô¨Ålter affected by process variability. As demonstrated in previous works [27], Lissajous compositions serve as an indicator of circuit parametric devi- ations in linear analog Ô¨Ålters. Continuous trace information is compacted to a set of 10 evenly spaced (in time) voltage samples of Ô¨Ålter response to the mentioned multitone stimulus as Fig. 7 illustrates. The selection of such points allows an easy and systematic ap- proach facilitating further data processing while keeping most of the Lissajous trace information avai"}
{"id": "Efficient Production Binning.pdf::chunk_26", "source": "Efficient Production Binning.pdf", "chunk_index": 26, "text": "ne stimulus as Fig. 7 illustrates. The selection of such points allows an easy and systematic ap- proach facilitating further data processing while keeping most of the Lissajous trace information available to the forthcoming measurements selection criterion [30]. The actual alternate measurements correspond to the difference of the samples of the deviated response with respect to the nominal response. 0 0.2 0.4 0.6 0.8 10.30.40.50.60.70.80.9 Nominal Filter Deviated Filter Candidate alternate measurements Selected alternate measurementsFig. 7. Input-output composition when a 3 tone signal is applied to the band-pass Butterworth Ô¨Ålter. Evenly spaced (in time) voltage samples form the candidate set of alternate measurements to be used in the binning process. B. Alternate Measurements Selection Criterion Last section deÔ¨Åned the set of possible alternate measure- ments to be used during the binning procedure. As Fig. 7 illus- trates, there are a total of 10 candidate alternate measurements to be considered. It is quite clear that a set of alternate measurements to be used for binning purposes has to satisfy two main properties: (1) the measurements need to reÔ¨Çect circuit‚Äôs performances "}
{"id": "Efficient Production Binning.pdf::chunk_27", "source": "Efficient Production Binning.pdf", "chunk_index": 27, "text": "to be considered. It is quite clear that a set of alternate measurements to be used for binning purposes has to satisfy two main properties: (1) the measurements need to reÔ¨Çect circuit‚Äôs performances variability in order to allow the binning to be performed efÔ¨Åciently and (2) an adequate set of measurements should not be redundant to avoid incurring in extra binning costs [31]‚Äì [33]. The Ô¨Årst condition is achieved by means of a sensitivity analysis of candidate alternate measurements. Regarding the second condition, Kendall‚Äôs Tau rank correlation coefÔ¨Åcient [34] is used to rate the most adequate pair of measurements with the aim of reducing redundant information [35]. Kendall‚Äôs 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 6 Tau rank c"}
{"id": "Efficient Production Binning.pdf::chunk_28", "source": "Efficient Production Binning.pdf", "chunk_index": 28, "text": "y edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 6 Tau rank correlation coefÔ¨Åcient computed between all the possible alternate measurements pairs of the Butterworth Ô¨Ålter under study is shown in Fig. 8. The minimum absolute value of Kendall‚Äôs Tau is 0.1126, highlighted in a white border and corresponds to measurements ids 9 and 7. Here forth, these measurements will deÔ¨Åne the alternate measurements space for the case study. 1 2 3 4 5 6 7 8 9 101 2 3 4 5 6 7 8 9 10 Measurement idMeasurement id 0.20.30.40.50.60.70.80.91 Fig. 8. Kendall‚Äôs Tau rank correlation coefÔ¨Åcients between all the possible pairs of candidate alternate measurements. The minimum absolute value is highlighted in white. Warm colors indicate high correlation while cold colors indicate low correlation. The previous procedure has selected a pair of alternate measurements since two measurements are enough for char- acterizing the variability in this work. Despite of that, the method can be naturally generalized if more than two alternate measurements are needed. The proposed heuristi"}
{"id": "Efficient Production Binning.pdf::chunk_29", "source": "Efficient Production Binning.pdf", "chunk_index": 29, "text": "rements are enough for char- acterizing the variability in this work. Despite of that, the method can be naturally generalized if more than two alternate measurements are needed. The proposed heuristic maintains the same criterion of minimizing the overall correlation within the target alternate measurements set. This can be achieved by minimizing the sum of the absolute values of Kendall‚Äôs Tau of the chosen pairs. LetNbe the total number of candidate alternate mea- surements and k\u00152the number of alternate measurements to be selected for binning/testing purposes. Let Trepresent the absolute value of Kendall‚Äôs Tau rank correlation matrix between all the possible pairs among the Ncandidate alternate measurements, i.e. N(N\u00001)=2 different elements. Then, apply the following greedy algorithm, 1) Choose the Ô¨Årst pair of measurements in matrix T among theN(N\u00001)=2 different pairs presenting the minimum Kendall‚Äôs Tau value. 2) Choose the next pair among the remaining pairs present- ing the next minimum Kendall‚Äôs Tau value, taking into account it will add one extra measurement if the chosen pair lies in the rows/columns of previously selected pairs and will add two extra measurements otherwi"}
{"id": "Efficient Production Binning.pdf::chunk_30", "source": "Efficient Production Binning.pdf", "chunk_index": 30, "text": " minimum Kendall‚Äôs Tau value, taking into account it will add one extra measurement if the chosen pair lies in the rows/columns of previously selected pairs and will add two extra measurements otherwise. 3) Continue applying the same procedure until the required alternate measurements are obtained to form the target set consisting of, at least, kmeasurements.C. Training Phase The proposed binning strategy using octrees has been ap- plied to bin a 4th order band-pass Butterworth Ô¨Ålter under the presence of process variations. As mentioned earlier, the circuit has been designed using and industrial 65 nm CMOS technology and simulated using HSPICE simulator. Monte Carlo simulations have been conducted relying on technology‚Äôs process design kit (statcrolles corner) [25]. The set of obtained circuits clearly present different degrees of speciÔ¨Åcation compliance. Fig. 9 shows in detail the obtained magnitude Bode plots together with the bin boundaries deÔ¨Åned in Table II. 105106107‚àí90‚àí80‚àí70‚àí60‚àí50‚àí40‚àí30‚àí20‚àí100 Frequency (Hz)Magnitude (dB) Nominal Bin 1 circuits Bin 2 circuits Bin 3 circuits Bin 1‚àí2 spec Bin 2‚àí3 spec Fig. 9. Detail of the magnitude Bode plots generated using HSPICE Monte Car"}
{"id": "Efficient Production Binning.pdf::chunk_31", "source": "Efficient Production Binning.pdf", "chunk_index": 31, "text": "‚àí50‚àí40‚àí30‚àí20‚àí100 Frequency (Hz)Magnitude (dB) Nominal Bin 1 circuits Bin 2 circuits Bin 3 circuits Bin 1‚àí2 spec Bin 2‚àí3 spec Fig. 9. Detail of the magnitude Bode plots generated using HSPICE Monte Carlo simulations of the Butterworth Ô¨Ålter used as case study. The speciÔ¨Åcations boundaries deÔ¨Åning each of the bins are also shown using discontinuous traces. The training phase uses the measurements selected in pre- vious section to encode the bins in the alternate measurements space using octrees. Fig. 10 shows the resulting encoding of the circuits shown in Fig. 2. Green, yellow and red octree cells correspond to bin 1, bin 2 and bin 3, respectively. The resulting octree has 14 levels in depth, i.e. hmax= 14. The resulting levels distribution for the encoded octree representing the alternate measurements space of the Butter- worth Ô¨Ålter is shown in Fig. 11. As can be appreciated, the vast majority of nodes correspond to levels 6, 7, 8, and 9 despite the maximum node level is 14. Further details will be given in the forthcoming sections, but this fact implies a considerable advantage in terms of binning time since a considerable amount of circuit samples will be binned without achievin"}
{"id": "Efficient Production Binning.pdf::chunk_32", "source": "Efficient Production Binning.pdf", "chunk_index": 32, "text": "etails will be given in the forthcoming sections, but this fact implies a considerable advantage in terms of binning time since a considerable amount of circuit samples will be binned without achieving a deep recursion level. V. S IMULATION RESULTS A. SpeciÔ¨Åcation Based Binning Using Octrees In order to evaluate the binning procedure using octrees, a new set of 50\u0002103Butterworth Ô¨Ålters has been generated using Monte Carlo simulations and evaluated in the octree 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 7 ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits Fig. 10. Resulting octree after the application of the training phase to the set of104Butterworth Ô¨Ålte"}
{"id": "Efficient Production Binning.pdf::chunk_33", "source": "Efficient Production Binning.pdf", "chunk_index": 33, "text": "0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits Fig. 10. Resulting octree after the application of the training phase to the set of104Butterworth Ô¨Ålter samples shown in Fig. 2. As can be appreciated, high octree levels concentrate in bin boundaries, where a reÔ¨Ånement is needed. 0 1 2 3 4 5 6 7 8 910 11 12 13 140100200300400500600 Octree levelOccurrencies Fig. 11. Levels distribution for the octree shown in Fig. 10. Despite the maximum octree level is 14, the vast majority of octree cells correspond to levels 6, 7, 8, and 9, what greatly facilitates its evaluation in terms of binning efÔ¨Åciency. generated in the training phase. The results of the evaluation can be observed in Fig. 12. Correctly binned circuits are drawn using green, yellow and red colors, which respectively correspond to bins 1, 2, and 3. Circuits that have not been correctly binned are circled using different colors according to the legend shown in Fig. 12. Table III reports the data characterizing the bin escapes matrix for the case study. As expected, the vast majority of bin escapes takes place between contiguous bins. Global bin escapes for this case study is 1.6"}
{"id": "Efficient Production Binning.pdf::chunk_34", "source": "Efficient Production Binning.pdf", "chunk_index": 34, "text": "orts the data characterizing the bin escapes matrix for the case study. As expected, the vast majority of bin escapes takes place between contiguous bins. Global bin escapes for this case study is 1.676% out of the 50\u0002103that form the binning set. The worst adjacent bin misclassiÔ¨Åcation is 0.494%. In order to study the time efÔ¨Åciency of evaluating the octree presented in section IV, all the required comparisons have been stored for the generated set of 50\u0002103circuits. Fig. 13 shows the cumulative percentage of binned circuits as a function of the required number of comparisons at a certain level. As ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits Bin 1 ‚àí> Bin 2 Bin 2 ‚àí> Bin 1 Bin 2 ‚àí> Bin 3 Bin 3 ‚àí> Bin 2Fig. 12. Binning results using the testing set of 50\u0002103Monte Carlo circuit samples by means of the octree illustrated in Fig. 10 and generated in the former training phase. MisclassiÔ¨Åed circuits concentrate in bin boundaries. TABLE III BINESCAPES MATRIX FOR OCTREES BASED BINNING (%) Without noise Gaussian noise \u001b= 3 mV Bin 1 Bin 2 Bin 3 Bin 1 Bin 2 Bin 3 Bin 1 56.580 0.494 0.000 53.970 3.084 0.020 Bin"}
{"id": "Efficient Production Binning.pdf::chunk_35", "source": "Efficient Production Binning.pdf", "chunk_index": 35, "text": "te in bin boundaries. TABLE III BINESCAPES MATRIX FOR OCTREES BASED BINNING (%) Without noise Gaussian noise \u001b= 3 mV Bin 1 Bin 2 Bin 3 Bin 1 Bin 2 Bin 3 Bin 1 56.580 0.494 0.000 53.970 3.084 0.020 Bin 2 0.328 26.750 0.436 2.288 23.902 1.324 Bin 3 0.000 0.418 14.994 0.004 1.006 14.402 GBE 1.676% 7.726% can be observed, about 95% of the circuits are clustered by just performing 7 two-dimensional comparisons despite the octree is 14 levels deep. As suggested earlier, this implies a considerable beneÔ¨Åt in terms of binning time since the octree data structure adapts its shape to the irregular bin boundaries generated in the alternate measurements space, only where a reÔ¨Ånement is needed. 0 1 2 3 4 5 6 7 8 9 10 11 12 13 140102030405060708090100 Octree levelCumulative binned (%) Fig. 13. Cumulative percentage of binned circuits as a function of the achieved octree level for the binning phase using 50\u0002103Butterworth Ô¨Ålters. As can be observed, about 95% of the circuits are binned by just performing 7 comparisons. 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/in"}
{"id": "Efficient Production Binning.pdf::chunk_36", "source": "Efficient Production Binning.pdf", "chunk_index": 36, "text": "ming 7 comparisons. 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 8 It has been mentioned that there are two main sources of bin escapes, namely, Ô¨Ånite octree resolution and noise. The former issue has already been studied and simulation results have been reported. It basically depends on the required resolution which is also related with the number of samples used in the training phase. The latter issue, noise, is also of crucial importance thus resolution strictly depends on the DNR in a real world application. When noise is added, similar results to those presented in Fig. 12 are obtained, but numbers get degraded. Table III also reports information on a noisy binning scenario, where Gaussian noise has been added to the alternate me"}
{"id": "Efficient Production Binning.pdf::chunk_37", "source": "Efficient Production Binning.pdf", "chunk_index": 37, "text": "ar results to those presented in Fig. 12 are obtained, but numbers get degraded. Table III also reports information on a noisy binning scenario, where Gaussian noise has been added to the alternate measurements. In this case, the global bin escapes rises up to 7.726% being the worst adjacent bin misclassiÔ¨Åcation 3.084% out of the total set of considered circuits. Binning results for different noise levels added to the alternate measurements and different sizes of the training set are reported in Fig. 14. Global bin escapes is considerably affected when noise levels are increased, clearly showing a direct relationship between noise and GBE. Training set size also plays a noticeable role with respect to bin escapes. For the presented case study, if the training set consists of 103circuits, the resulting octree represents the alternate measurements space poorly what translates in high GBE. On the contrary, if sample size is in the order of 104or larger, the octree is sufÔ¨Åcient to encode the bins in the measurements space. 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 502468101214 Standard deviation of noise (mV)Global bin escapes (%) 1k circuits 2k circuits 5k circuits 10k circuits 20k circuits 50k c"}
{"id": "Efficient Production Binning.pdf::chunk_38", "source": "Efficient Production Binning.pdf", "chunk_index": 38, "text": "he bins in the measurements space. 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 502468101214 Standard deviation of noise (mV)Global bin escapes (%) 1k circuits 2k circuits 5k circuits 10k circuits 20k circuits 50k circuits Fig. 14. Global bin escapes as a function of the number of circuit samples used in the training phase and the noise present in the alternate measurements. As expected, global bin escapes metric increases as noise level increases. B. Comparison with Support Vector Machines ClassiÔ¨Åers In order to compare the proposed method for binning mixed- signal ICs with state of the art tools and techniques, a support vector machine (SVM) classiÔ¨Åer has been trained using exactly the same set of circuits used for octrees which is depicted in Fig. 2. The training procedure has been carried out using MATLAB and the sequential minimal optimization training method. The kernel used in the procedure is a radial basis function (RBF), which is a standard choice in the Ô¨Åeld [36]‚Äì [38]. The SVM training has been carried out using a 5-foldscross validation together with a grid search to determine the optimum kernel spread, \u001b, as well as the optimum soft margin parameter,C. A single SVM classiÔ¨Åer is capa"}
{"id": "Efficient Production Binning.pdf::chunk_39", "source": "Efficient Production Binning.pdf", "chunk_index": 39, "text": "s been carried out using a 5-foldscross validation together with a grid search to determine the optimum kernel spread, \u001b, as well as the optimum soft margin parameter,C. A single SVM classiÔ¨Åer is capable of dealing with two classes only, so for binning circuits in pbins,p\u00001 support vector machines need to be trained. In this work, two SVM classiÔ¨Åers have been trained, one for separating bins 1-2 and one for separating bins 2-3. The results for the grid search can be seen in Fig. 15. ‚àí1.5‚àí1‚àí0.5012301020304050 log10(œÉ)log10(C)Average misclassifications ‚àí1‚àí0.50 11.522.5010203040 log10(œÉ)log10(C)Average misclassifications Fig. 15. Results of the grid search in the (\u001b;C )space using 5-fold cross validation technique with the training set presented in Fig. 2. The plot on the left corresponds to the SVM between bins 1-2 while the plot on the right corresponds to the SVM between bins 2-3. The cross validation procedure together with the grid search method to determine the best \u001bandCparameters yields to the optimum support vector machines to be used. Table IV reports the training results for the two SVM classiÔ¨Åers trained using the same training set as used with octrees (104samples). The wh"}
{"id": "Efficient Production Binning.pdf::chunk_40", "source": "Efficient Production Binning.pdf", "chunk_index": 40, "text": "yields to the optimum support vector machines to be used. Table IV reports the training results for the two SVM classiÔ¨Åers trained using the same training set as used with octrees (104samples). The whole SVM training process takes 1.5 h. The resulting optimum SVM classiÔ¨Åers boundaries are shown in Fig. 16. TABLE IV SVM C LASSIFIERS TRAINING INFORMATION Aspect SVM 1-2 SVM 2-3 Units Training set size 10k 10k ckts Number of grid search points 110 100 Cross validation folds 5 5 Optimum\u001bparameter 0.2512 0.1848 OptimumCparameter 398.1 158.5 Average misclassiÔ¨Åcation 12.6 25.0 ckts Number of support vectors 180 623 Single SVM training time 6.64 6.44 s Total training time 53.7 38.7 min Table V summarizes the results of the comparison between the production binning using octrees and using support vector machines. Regarding the training phase, the training using SVM is considerably longer, specially if the cross validation and grid search needs to be performed. The global bin escapes for octrees and SVM are similar, accounting for 1.676% if octrees are used and 1.828% if SVM classiÔ¨Åers are used. The time needed to achieve the binning for the 50\u0002103circuits was around 5 times faster using octr"}
{"id": "Efficient Production Binning.pdf::chunk_41", "source": "Efficient Production Binning.pdf", "chunk_index": 41, "text": "and SVM are similar, accounting for 1.676% if octrees are used and 1.828% if SVM classiÔ¨Åers are used. The time needed to achieve the binning for the 50\u0002103circuits was around 5 times faster using octrees than support vector machines classiÔ¨Åers. This strictly depends on the number of support vectors resulting after the training phase for the case of SVM classiÔ¨Åers while it only depends on the average octree level for the case of octree classiÔ¨Åers. Table VI reports the bin escapes matrix for the binning procedure using the trained SVMs. The left hand side table 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 9 ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits SV"}
{"id": "Efficient Production Binning.pdf::chunk_42", "source": "Efficient Production Binning.pdf", "chunk_index": 42, "text": "ctions on Computer-Aided Design of Integrated Circuits and Systems 9 ‚àí0.05 0 0.05 0.1 0.15 0.2 0.25‚àí0.15‚àí0.1‚àí0.0500.050.10.15 Measure 1 (V)Measure 2 (V) Bin 1 circuits Bin 2 circuits Bin 3 circuits SVM 1‚àí2 SVM 2‚àí3 Fig. 16. Best SVM classiÔ¨Åers using the training set of 104circuits shown in Fig. 2. The SVM has been trained using sequential minimal optimization method and radial basis functions (RBF) kernels. TABLE V COMPARISON BETWEEN OCTREES AND SUPPORT VECTOR MACHINES Aspect Octree SVM Grid search and cross validation time not needed 1.5 h Single classiÔ¨Åer training time 1.3 s 13 s Production binning time 19.2 s 99.8 s Global bin escapes 1.676 % 1.828 % corresponds to the ideal classiÔ¨Åcation with no noise while the right hand side table reports the bin escapes matrix when Gaussian noise is added. Under the presence of noise, octree global bin escapes represent the 7.726% out of the total circuits while SVM wrongly bins the 7.660%, showing almost equivalent performances. It is important to note that non linear support vector machines rely on a minimization algorithm which may not converge immediately. Furthermore, SVM classiÔ¨Åers depend on several tuning parameters which require speci"}
{"id": "Efficient Production Binning.pdf::chunk_43", "source": "Efficient Production Binning.pdf", "chunk_index": 43, "text": "to note that non linear support vector machines rely on a minimization algorithm which may not converge immediately. Furthermore, SVM classiÔ¨Åers depend on several tuning parameters which require speciÔ¨Åc parameter selection and may result in non optimal classiÔ¨Åers. On the contrary, the octree encoding algorithm is straightforward to implement and solely relies on the available data. TABLE VI BINESCAPES MATRIX FOR SVM C LASSIFIER (%) Without noise Gaussian noise \u001b= 3 mV Bin 1 Bin 2 Bin 3 Bin 1 Bin 2 Bin 3 Bin 1 56.688 0.3860 0.000 54.078 2.980 0.016 Bin 2 0.204 26.234 1.076 2.244 23.464 1.806 Bin 3 0.000 0.162 15.250 0.004 0.610 14.798 GBE 1.828% 7.660% VI. C ONCLUSIONS A speciÔ¨Åcation based binning strategy for mixed-signal circuits using octrees in the measurements space has been proposed. The method comprises two phases, training andbinning. The training phase digitally encodes the speciÔ¨Åcation bins in the measurements space using octrees. It is based on a set of circuits obtained from Monte Carlo simulations, model evaluation or available data on the production run. The genera- tion of the octree in the training phase may be computationally intensive but it only needs to be perfor"}
{"id": "Efficient Production Binning.pdf::chunk_44", "source": "Efficient Production Binning.pdf", "chunk_index": 44, "text": " Monte Carlo simulations, model evaluation or available data on the production run. The genera- tion of the octree in the training phase may be computationally intensive but it only needs to be performed once. Its size, i.e. the number of tree nodes, grows exponentially with the number of alternate measurements used (n). Our experiments show acceptable tree sizes for low dimensionalities (n = 2;3). The binning phase performs circuit binning according to the octree generated in the previous phase taking advantage of the inherently sparse octree data structures. In order to show the viability of the proposal, a But- terworth Ô¨Ålter has been designed in an industrial 65 nm CMOS technology and binned using octrees. Monte Carlo simulations have been conducted to evaluate the bin escapes as a function of several parameters such as the training set size and noise levels. Simulation results reveal that worst adjacent bin misclassiÔ¨Åcation is 0.494% out of the total set of circuits when no noise is considered. The octree binning procedure has been compared against state of the art support vector machines classiÔ¨Åers revealing considerable advantages in terms of evaluation complexity showing a "}
{"id": "Efficient Production Binning.pdf::chunk_45", "source": "Efficient Production Binning.pdf", "chunk_index": 45, "text": "is considered. The octree binning procedure has been compared against state of the art support vector machines classiÔ¨Åers revealing considerable advantages in terms of evaluation complexity showing a speedup of 5X and slightly better misclassiÔ¨Åcation results for the considered two-dimensional case study, therefore assessing the viability of the proposal for circuit binning based on a small number of alternate measurements. REFERENCES [1] M. Gong, H. Zhou, L. Li, J. Tao, and X. Zeng, ‚ÄúBinning optimization for transparently-latched circuits,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 30, no. 2, pp. 270‚Äì283, February 2011. [2] Z. Pan and M. Breuer, ‚ÄúEstimating error rate in defective logic using signature analysis,‚Äù Computers, IEEE Transactions on, vol. 56, no. 5, pp. 650‚Äì661, May 2007. [3] A. Davoodi and A. Srivastava, ‚ÄúVariability driven gate sizing for binning yield optimization,‚Äù Very Large Scale Integration (VLSI) Systems, IEEE Transactions on, vol. 16, no. 6, pp. 683‚Äì692, June 2008. [4] S. Lichtensteiger and J. Bickford, ‚ÄúUsing selective voltage binning to maximize yield,‚Äù Semiconductor Manufacturing, IEEE Transactions on, vol. 26, no. "}
{"id": "Efficient Production Binning.pdf::chunk_46", "source": "Efficient Production Binning.pdf", "chunk_index": 46, "text": "on, vol. 16, no. 6, pp. 683‚Äì692, June 2008. [4] S. Lichtensteiger and J. Bickford, ‚ÄúUsing selective voltage binning to maximize yield,‚Äù Semiconductor Manufacturing, IEEE Transactions on, vol. 26, no. 4, pp. 436‚Äì441, November 2013. [5] G. Gielen and R. Rutenbar, ‚ÄúComputer-aided design of analog and mixed-signal integrated circuits,‚Äù Proceedings of the IEEE, vol. 88, no. 12, pp. 1825‚Äì1854, December 2000. [6] E. Yilmaz, S. Ozev, and K. Butler, ‚ÄúAdaptive quality binning for analog circuits,‚Äù in Test Symposium (ETS), 2013 18th IEEE European, May 2013, pp. 1‚Äì6. [7] R. Shen, S.-D. Tan, and X.-X. Liu, ‚ÄúA new voltage binning technique for yield improvement based on graph theory,‚Äù in Quality Electronic Design (ISQED), 2012 13th International Symposium on, March 2012, pp. 243‚Äì248. [8] E. Yilmaz and S. Ozev, ‚ÄúTest application for analog/rf circuits with low computational burden,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 31, no. 6, pp. 968‚Äì979, June 2012. [9] S. Callegari, F. Pareschi, G. Setti, and M. Soma, ‚ÄúComplex oscillation- based test and its application to analog Ô¨Ålters,‚Äù Circuits and Systems I: Regular Papers, IEEE Transactions on, vol. 57, no"}
{"id": "Efficient Production Binning.pdf::chunk_47", "source": "Efficient Production Binning.pdf", "chunk_index": 47, "text": " [9] S. Callegari, F. Pareschi, G. Setti, and M. Soma, ‚ÄúComplex oscillation- based test and its application to analog Ô¨Ålters,‚Äù Circuits and Systems I: Regular Papers, IEEE Transactions on, vol. 57, no. 5, pp. 956‚Äì969, May 2010. [10] L. Milor, ‚ÄúA tutorial introduction to research on analog and mixed- signal circuit testing,‚Äù Circuits and Systems II: Analog and Digital Signal Processing, IEEE Transactions on, vol. 45, no. 10, pp. 1389‚Äì 1407, October 1998. 0278-0070 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2501309, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 10 [11] F. Liu, E. Acar, and S. Ozev, ‚ÄúTest yield estimation for analog/rf circuits over multiple correlated measurements,‚Äù in Test Conference, 2007. ITC 2007. IEEE International, October 2007, pp. 1‚Äì10. [12] R. V oorakaranam, S. Akbay, S. B"}
{"id": "Efficient Production Binning.pdf::chunk_48", "source": "Efficient Production Binning.pdf", "chunk_index": 48, "text": "st yield estimation for analog/rf circuits over multiple correlated measurements,‚Äù in Test Conference, 2007. ITC 2007. IEEE International, October 2007, pp. 1‚Äì10. [12] R. V oorakaranam, S. Akbay, S. Bhattacharya, S. Cherubal, and A. Chat- terjee, ‚ÄúSignature testing of analog and rf circuits: Algorithms and methodology,‚Äù Circuits and Systems I: Regular Papers, IEEE Trans- actions on, vol. 54, no. 5, pp. 1018‚Äì1031, May 2007. [13] S. Devarakond, S. Sen, S. Bhattacharya, and A. Chatterjee, ‚ÄúConcurrent device/speciÔ¨Åcation cause-effect monitoring for yield diagnosis using al- ternate diagnostic signatures,‚Äù Design Test of Computers, IEEE, vol. 29, no. 1, pp. 48‚Äì58, February 2012. [14] H.-G. Stratigopoulos and Y . Makris, ‚ÄúError moderation in low-cost machine-learning-based analog/rf testing,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 27, no. 2, pp. 339‚Äì351, February 2008. [15] H. Stratigopoulos and S. Mir, ‚ÄúAdaptive alternate analog test,‚Äù Design Test of Computers, IEEE, vol. 29, no. 4, pp. 71‚Äì79, August 2012. [16] H. Ayari, F. Azais, S. Bernard, M. Comte, V . Kerzerho, O. Potin, and M. Renovell, ‚ÄúMaking predictive analog/rf alternate test strat"}
{"id": "Efficient Production Binning.pdf::chunk_49", "source": "Efficient Production Binning.pdf", "chunk_index": 49, "text": "st of Computers, IEEE, vol. 29, no. 4, pp. 71‚Äì79, August 2012. [16] H. Ayari, F. Azais, S. Bernard, M. Comte, V . Kerzerho, O. Potin, and M. Renovell, ‚ÄúMaking predictive analog/rf alternate test strategy independent of training set size,‚Äù in Test Conference (ITC), 2012 IEEE International, November 2012, pp. 1‚Äì9. [17] A. Gomez-Pau, L. Balado, and J. Figueras, ‚ÄúM-s test based on speci- Ô¨Åcation validation using octrees in the measure space,‚Äù in Proceedings of IEEE European Test Symposium (ETS), Avignon, France, May 2013, pp. 70‚Äì75. [18] K. Huang, N. Kupp, C. Xanthopoulos, J. Carulli, and Y . Makris, ‚ÄúLow- cost analog/rf ic testing through combined intra- and inter-die correlation models,‚Äù Design Test, IEEE, vol. 32, no. 1, pp. 53‚Äì60, February 2015. [19] A. Gomez-Pau, L. Balado, and J. Figueras, ‚ÄúM-s speciÔ¨Åcation binning based on digitally coded indirect measurements,‚Äù in Proceedings of IEEE European Test Symposium (ETS), Paderborn, Germany, May 2014, pp. 105‚Äì110. [20] A. Singhee and R. Rutenbar, ‚ÄúStatistical blockade: Very fast statistical simulation and modeling of rare circuit events and its application to memory design,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEE"}
{"id": "Efficient Production Binning.pdf::chunk_50", "source": "Efficient Production Binning.pdf", "chunk_index": 50, "text": "tenbar, ‚ÄúStatistical blockade: Very fast statistical simulation and modeling of rare circuit events and its application to memory design,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 28, no. 8, pp. 1176‚Äì1189, August 2009. [21] D. Hocevar, M. Lightner, and T. N. Trick, ‚ÄúA study of variance reduction techniques for estimating circuit yields,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 2, no. 3, pp. 180‚Äì192, July 1983. [22] A. Bounceur, S. Mir, and H. Stratigopoulos, ‚ÄúEstimation of analog para- metric test metrics using copulas,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 30, no. 9, pp. 1400‚Äì 1410, September 2011. [23] H. Stratigopoulos, S. Mir, and A. Bounceur, ‚ÄúEvaluation of analog/rf test measurements at the design stage,‚Äù Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 28, no. 4, pp. 582‚Äì590, April 2009. [24] D. Meagher, ‚ÄúOctree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer,‚Äù Rens- selaer Polytechnic Institute, New York, techreport, 1980. [25] ST-Microelect"}
{"id": "Efficient Production Binning.pdf::chunk_51", "source": "Efficient Production Binning.pdf", "chunk_index": 51, "text": "ree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer,‚Äù Rens- selaer Polytechnic Institute, New York, techreport, 1980. [25] ST-Microelectronics, ‚ÄúCmos065 design rule manual. 65 nm bulk cmos process,‚Äù 2013, version 5.3.6. [26] P. Mohan, VLSI Analog Filters: Active RC, OTA-C, and SC, ser. Model- ing and Simulation in Science, Engineering and Technology. Springer, 2012. [27] L. Balado, E. Lupon, J. Figueras, M. Roca, E. Isern, and R. Picos, ‚ÄúVeri- fying functional speciÔ¨Åcations by regression techniques on lissajous test signatures,‚Äù Circuits and Systems I: Regular Papers, IEEE Transactions on, vol. 56, no. 4, pp. 754‚Äì762, April 2009. [28] A. Gomez, R. Sanahuja, L. Balado, and J. Figueras, ‚ÄúAnalog circuit test based on a digital signature,‚Äù in Proceedings of IEEE Design Automation and Test in Europe Conference (DATE), Dresden, Germany, March 2010, pp. 1641‚Äì1644. [29] N. Nagi, A. Chatterjee, H. Yoon, and J. Abraham, ‚ÄúSignature analysis for analog and mixed-signal circuit test response compaction,‚Äù Computer- Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 17, no. 6, pp. 540‚Äì546, June 1998. [30] A. "}
{"id": "Efficient Production Binning.pdf::chunk_52", "source": "Efficient Production Binning.pdf", "chunk_index": 52, "text": "nalysis for analog and mixed-signal circuit test response compaction,‚Äù Computer- Aided Design of Integrated Circuits and Systems, IEEE Transactions on, vol. 17, no. 6, pp. 540‚Äì546, June 1998. [30] A. Gomez-Pau, L. Balado, and J. Figueras, ‚ÄúDiagnosis of parametric de- fects in dual axis ic accelerometers,‚Äù Microsystem Technologies Journal, vol. 21, no. 9, pp. 1855‚Äì1866, July 2015. [31] M. Barragan and G. Leger, ‚ÄúA procedure for alternate test feature design and selection,‚Äù Design Test, IEEE, vol. 32, no. 1, pp. 18‚Äì25, February 2015. [32] ‚Äî‚Äî, ‚ÄúEfÔ¨Åcient selection of signatures for analog/rf alternate test,‚Äù in Test Symposium (ETS), 2013 18th IEEE European, May 2013, pp. 1‚Äì6.[33] H. Ayari, F. Azais, S. Bernard, M. Comte, M. Renovell, V . Kerzerho, O. Potin, and C. Kelma, ‚ÄúSmart selection of indirect parameters for dc- based alternate rf ic testing,‚Äù in VLSI Test Symposium (VTS), 2012 IEEE 30th, April 2012, pp. 19‚Äì24. [34] M. G. Kendall, ‚ÄúA new measure of rank correlation,‚Äù Biometrika, vol. 30, no. 1/2, pp. 81‚Äì93, June 1938. [35] A. Gomez-Pau, L. Balado, and J. Figueras, ‚ÄúQuality metrics for mixed- signal indirect testing,‚Äù in Proceedings of Design of Circuits and Integrated Systems Con"}
{"id": "Efficient Production Binning.pdf::chunk_53", "source": "Efficient Production Binning.pdf", "chunk_index": 53, "text": " 30, no. 1/2, pp. 81‚Äì93, June 1938. [35] A. Gomez-Pau, L. Balado, and J. Figueras, ‚ÄúQuality metrics for mixed- signal indirect testing,‚Äù in Proceedings of Design of Circuits and Integrated Systems Conference (DCIS), Madrid, Spain, November 2014, pp. 1‚Äì6. [36] K. Huang, J. Carulli, and Y . Makris, ‚ÄúCounterfeit electronics: A rising threat in the semiconductor manufacturing industry,‚Äù in Test Conference (ITC), 2013 IEEE International, September 2013, pp. 1‚Äì4. [37] C. Cortes and V . Vapnik, ‚ÄúSupport-vector networks,‚Äù Machine Learning, vol. 20, no. 3, pp. 273‚Äì297, September 1995. [38] K. Beznia, A. Bounceur, R. Euler, and S. Mir, ‚ÄúA tool for analog/rf bist evaluation using statistical models of circuit parameters,‚Äù ACM Trans. Des. Autom. Electron. Syst., vol. 20, no. 2, pp. 31:1‚Äì31:22, March 2015. ¬¥Alvaro G ¬¥omez-Pau received the M.Sc. degree in Engineering from Universitat Polit `ecnica de Catalunya (UPC-BarcelonaTech), Barcelona, Spain, in 2010. He is a Ph.D. candidate at the Department of Electronics Engineering at the same university. His research interests include design and test of analog and mixed-signals circuits. Luz Balado received the M.Sc. and Ph.D. de- grees in engineering"}
{"id": "Efficient Production Binning.pdf::chunk_54", "source": "Efficient Production Binning.pdf", "chunk_index": 54, "text": "of Electronics Engineering at the same university. His research interests include design and test of analog and mixed-signals circuits. Luz Balado received the M.Sc. and Ph.D. de- grees in engineering from Universitat Polit `ecnica de Catalunya (UPC), Barcelona, Spain, in 1980 and 1986, respectively. She is currently an Associate Professor with the Department of Electronics En- gineering, UPC, where she teaches electronics and electronic instrumentation. She is involved in Mi- croelectronics and Test Research Group. Her main research interests include design and test of digital and mixed-signal circuits, defect modeling, and low- power design. Joan Figueras received his Industrial Engineering degree from Universitat Polit `ecnica de Catalunya (UPC), Barcelona, Spain, and the M.Sc. and Ph.D. degrees from the University of Michigan, Ann Ar- bor. He is currently Emeritus Professor at the De- partment of Electronics of the UPC, where he has research responsibilities in the areas of electronics and digital and mixed-signal design and test. His research interests are centered in emerging topics in low-power design and advanced test of electronic circuits and systems. He has an extensive "}
{"id": "Efficient Production Binning.pdf::chunk_55", "source": "Efficient Production Binning.pdf", "chunk_index": 55, "text": "nics and digital and mixed-signal design and test. His research interests are centered in emerging topics in low-power design and advanced test of electronic circuits and systems. He has an extensive publication record and has presented seminars and tutorials in professional meetings, NATO seminars on topics related to ‚ÄúLow Power Design‚Äù and ‚ÄúQuality in Electronics‚Äù. Dr. Figueras is currently an Editor of JETTA, was an Associated Editor of THE IEEE T RANSACTIONS ONCOMPUTER -AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS , and is a member of the steering and program committee of several Test and Low Power Design conferences."}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_0", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 0, "text": "Enhanced detection ofunknown defectpatternsonwaferbinmapsbased onanopen-setrecognition approach Jin-SuShina,b,Min-JooKima,b,Beom-Seok Kimc,Dong-Hee Leec,*,1 aDepartment ofSemiconductor andDisplayEngineering, Sungkyunkwan University, 2066,Seobu-ro, Suwon-si, Gyunggi-do 16419,RepublicofKorea bMemoryDivision,SamsungElectronics Co,Ltd.,1-1Samsungjeonja-ro, Hwaseong-si, Gyeonggi-do18448, RepublicofKorea cDepartment ofIndustrial Engineering, Sungkyunkwan University, 2066,Seobu-ro, Suwon-si, Gyunggi-do 16419,RepublicofKorea ARTICLE INFO Keywords: Wafer-bin mapclassification Realfielddata Unknown defectpatterns One-class SVM Open-set recognitionABSTRACT Itiscrucialtodetectandclassifydefectpatternsonwafersinsemiconductor-manufacturing processes forwafer- qualitymanagement andpromptanalysisofdefectcauses.Inrecentyears,continuous technological innovation andadvancements insemiconductor-industry processes haveledtoanincreaseinunknown defectpatterns, whichmustbedetectedandclassified. However, detection ofunknown defectpatternsisdifficultduetocomplex reasons,suchastrainingonnon-existent defectclasses,closeddatasetsowingtoindustrial security,andlabeling largevolumesofmanufacturing data.Owingtothe"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_1", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 1, "text": "tion ofunknown defectpatternsisdifficultduetocomplex reasons,suchastrainingonnon-existent defectclasses,closeddatasetsowingtoindustrial security,andlabeling largevolumesofmanufacturing data.Owingtothesechallenges, methodsfordetecting unknown defectpatterns inanactualsemiconductor-manufacturing environment primarily relyonqualitative indicators, suchasintuition andexperience ofengineers. Toovercome theseproblems, thisstudyproposesamethodology basedonopen-set recognition toaccurately detectunknown defectpatterns. Thismethodology beginswithtwopreprocessing steps:constrained meanfiltering(C-meanfiltering); andRadontransform todiminish noiseandefficiently extractfeaturesfromwafer-bin maps.Thisstudythendevelopsanentropy-estimation one-class supportvector machine(EEOC-SVM), whichaccountsfortheuncertainty intheone-class SVMclassification results.EEOC-SVM computes entropy-uncertainty scoresbasedonthedistancebetweendecisionboundaries andsamplesandthen reclassifies uncertain samplesusingaweighted sumofuncertainties foreachclass.Thismethodcaneffectively detectunknown defectpatterns.Theproposed methodachievesadetection performance ofover98%forvarious defectclassesbasedonexperiments conducted wi"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_2", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 2, "text": " sumofuncertainties foreachclass.Thismethodcaneffectively detectunknown defectpatterns.Theproposed methodachievesadetection performance ofover98%forvarious defectclassesbasedonexperiments conducted withnewdefectpatternsoccurring inactualsemiconductor- manufacturing environments. Theseresultsconfirmthattheproposed methodisaneffectivetoolfordetecting andaddressing unknown defectpatterns. 1.Introduction Thesemiconductor-manufacturing industryisthecornerstone of moderntechnology. Avarietyofprocesses areusedtoimprintnumerous elementsontoasinglechiptomanufacture integrated circuitscapableof processing andstoringcomplexfunctions. Inthisprocess,waferbin maps(WBM),whichvisualize theresultsofelectrical dietests,are widelyusedforanalyzing andmeasuring waferdefects(Kyeongand Kim,2018).DefectpatternsdetectedintheWBMcontaininformation foranalyzing variouscausesofwaferdefects,suchasprocessfailures, production-equipment abnormalities, anddesignflaws.Therefore, ac- curateclassification andanalysisofthedefectpatternsintheWBMcan playacrucialroleinidentifying thespecificprocesses ormachines thatcausedefects. Recenttrendsinsemiconductor researchhaveaimedtoenhancechip processing powerandfunctionality by"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_3", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 3, "text": "defectpatternsintheWBMcan playacrucialroleinidentifying thespecificprocesses ormachines thatcausedefects. Recenttrendsinsemiconductor researchhaveaimedtoenhancechip processing powerandfunctionality byintegrating anincreasing number ofdevicesintoasinglechip.Consequently, withtheintroduction ofthe latestprocesstechnologies andavarietyofnewequipment, semi- conductor manufacturing processes havebecomemorerefinedand advanced, andunknown defectpatternsthatdifferfromtraditional defecttypesareconstantly emerging. However, identification of emerging defectpatternsandlabelingofdatastillrelyheavilyon qualitative metrics,suchasengineerintuitionandjudgment(C. Y.Hsu etal.,2020).Ifengineers failtoidentifydefectsbasedonintuitionand experience, theriskofreliability andqualityissuesinsemiconductor production increasesignificantly, whichhasaconsiderable impacton *Corresponding author. E-mailaddress:dhee@skku.edu (D.-H.Lee). 1ORCID:0000 ‚Äì0001-8549 ‚Äì8992 Contentslistsavailable atScienceDirect Computers inIndustry u{ÔøΩ~zkw s{yo|kr o>√ê√ê√ê1ÔøΩmt ozmont~omÔøΩ1m{ y2u{ÔøΩ~zk w2m{y|ÔøΩÔøΩo~ÔøΩ/t z/tznÔøΩÔøΩÔøΩ~√û https://doi.org/10.1016/j.compind.2024.104208 Received 6June2024;Received inrevisedform2October2024;Accepted 3November"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_4", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 4, "text": "ndustry u{ÔøΩ~zkw s{yo|kr o>√ê√ê√ê1ÔøΩmt ozmont~omÔøΩ1m{ y2u{ÔøΩ~zk w2m{y|ÔøΩÔøΩo~ÔøΩ/t z/tznÔøΩÔøΩÔøΩ~√û https://doi.org/10.1016/j.compind.2024.104208 Received 6June2024;Received inrevisedform2October2024;Accepted 3November 2024Computers in Industry 164 (2025) 104208 Available online 14 November 2024 0166-3615/¬© 2024 Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies. wafer-manufacturing costs(J.Zhuetal.,2022).Therefore, theaccurate classification ofunknown WBMdefectpatternsiscritical(F.-L.Chenand Liu,2000;S.C.HsuandChien,2007). Itissignificantly difficultfornewlydiscovered unknown defect patternstopredicttheirshapeortiminginadvance.Moreover, research onthedetection ofunknown defectpatternsintheWBMiscompounded bycloseddatasetsowingtoindustrial security, highcostsandtime requiredtolabelvastamountsofmanufacturing data,andthedifficulty inacquiring unknown defectdata.Consequently, traditional classifica- tionalgorithms orclassifiers thatconsideronlytheknowndefectpat- ternsincludedinthetrainingdatahavelimitations indetecting these unknown defectpatterns(T.KimandBehdinan, 2023).Despitethis background, mostWBMdefect-analysis studiesprimarily fo"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_5", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 5, "text": "onlytheknowndefectpat- ternsincludedinthetrainingdatahavelimitations indetecting these unknown defectpatterns(T.KimandBehdinan, 2023).Despitethis background, mostWBMdefect-analysis studiesprimarily focusonthe classification accuracy andspeedofknowndefecttypesandfailto providesolutions fordetecting unknown defectpatterns(Chaand Jeong,2022;Chenetal.,2022;E.S.Kimetal.,2021;M.Kimetal.,2023; Nagetal.,2022;Nakazawa andKulkarni, 2018;Shindeetal.,2022;Xu etal.,2022;N.Yuetal.,2019).Recentstudiesintroduce modelsto improvethedetection performance ofmixeddefectsbasedonknown defectpatterns(Houetal.,2024;Zhangetal.,2024),orpropose augmentation methods utilizing visiontransformer models, a cutting-edge deeplearningmodel,toaddresstheproblemofimbalance betweenknowndefectclasses(FanandChiu,2024).However, research ondetecting unknown defectpatternsinWBMisrelatively scarce.Some studieshighlighted thepotentialoccurrence ofunknown defectpatterns intheWBMandtheirassociated risks,underscoring theimportance of researchinthisarea.However, thesestudiesonlyofferlimitedsolutions fordetecting unknown defectpatterns, suchaspresuming acertain shapeofpotentially unknown defect-pattern classes(LeeandKim, 2020),sett"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_6", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 6, "text": " researchinthisarea.However, thesestudiesonlyofferlimitedsolutions fordetecting unknown defectpatterns, suchaspresuming acertain shapeofpotentially unknown defect-pattern classes(LeeandKim, 2020),settingaclassifier‚Äôs threshold torejectsampleswithhighun- certainty (M.B.Alawieh,2020),ortrainingonbothout-of-distribution (OOD)andin-distribution (IND)defectspresentinthetrainingdatato detectalimitednumberofOODdefects(Y.Kim,2020).Thisimpliesthat acomprehensive solutioncapableofeffectively detecting entirelynew typesofdefectswithoutanypriorinformation onunknown defectpat- ternshasnotyetbeenpresented. Therefore, thisstudyaimstoaccurately detectunknown defect patternsusinganopen-setrecognition (OSR)methodology basedonan entropy-estimation one-class supportvectormachine(EEOC-SVM) to overcome thelimitations ofexistingresearch. Thismethodology effec- tivelyremovesnoisefromWBMwithoutcompromising thekeydefect areasbyincorporating preprocessing stepssuchasconstrained mean filtering(C-meanfiltering)andRadontransform, andefficiently extracts thecorefeaturesofWBMdefects.Additionally, byutilizingtheradial basisfunction(RBF)kernelembedding ofanOC-SVMtrainedonlyon knowndefectpatterns, previously undefin"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_7", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 7, "text": "Radontransform, andefficiently extracts thecorefeaturesofWBMdefects.Additionally, byutilizingtheradial basisfunction(RBF)kernelembedding ofanOC-SVMtrainedonlyon knowndefectpatterns, previously undefined defectpatternscanbe successfully detected. Additionally, inordertominimize errorsarising frombinaryclassification basedonthelearnedboundary oftheOC- SVM,thedistancebetweenthesampleandboundary wascalculated toestimatetheprobability ofeachsamplebelonging toeachregion,and theentropywascalculated. Adjustment oftheclassification resultsto maximize theweighted sumofuncertainties forhighlyuncertain sam- plesenablesthesuccessful detection ofpreviously undefined defect patternswhilealsoenablingmoreaccuratediscrimination ofsamples pronetomisclassification. Thisremainder ofthispaperisstructured asfollows.InSection2,we reviewrecenttrendsinassumed unknown defectpatternsinWBM classification researchandvariousfeature-extraction methods. InSec- tion3,weexplaintheEEOC-SVM-based OSRmethodology. InSection4, weintroduce theWM-811K datasetusedinthestudyandverifythe effectiveness ofthemethodology throughexperimental resultsand analysisusingtheWM-811K data.Section5demonstrates thepractical applicability o"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_8", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 8, "text": "4, weintroduce theWM-811K datasetusedinthestudyandverifythe effectiveness ofthemethodology throughexperimental resultsand analysisusingtheWM-811K data.Section5demonstrates thepractical applicability oftheproposed methodbyusingrealindustrial datacon- tainingunknown defectpatterns.Finally,Section6concludes thepaper andbrieflyoutlinesfutureresearchdirections. Theexperimental results showthattheproposed methodology effectively detectspreviouslyundefined defectpatternswithhighaccuracy compared withexisting classification techniques. Inparticular, theEEOC-SVM hasshownsig- nificantperformance, eveninenvironments wheremultipleunknown defectpatternsoccursimultaneously andhasbeenproventobeeffective inclassifying varioustypesofdefects.ThisimpliesthattheEEOC-SVM maybeausefultoolfordetecting unpredictable defecttypesin semiconductor-manufacturing processes. 2.Relatedworks 2.1.Open-setrecognition OSRaimstoidentifyorrejectunknown classesbasedonexisting classes.Toachievethis,OSRutilizesvariousmethodsofdimensionality reduction andembedding oftheoriginaldatatoanalyzethedifferences fromknownclasses.Thisenablestheeffectiverejectionoridentification ofunknown classes. EarlyworkonOSRinvolvedthresholding "}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_9", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 9, "text": "fdimensionality reduction andembedding oftheoriginaldatatoanalyzethedifferences fromknownclasses.Thisenablestheeffectiverejectionoridentification ofunknown classes. EarlyworkonOSRinvolvedthresholding thepost-SoftMax outputof adeep-learning modeltoclassifysamplesbelowacertainprobability as unknown classes(Nguyen etal.,2015).However, thisapproach is limitedbecausethethreshold maynotbeappropriately applied. Therefore, thepre-SoftMax technique, whichusesanadjustable threshold forthelogitvaluebeforetheSoftMaxlayer,andOpen-Max (Bendale andBoult,2016)method, whichutilizesextremeprobability valuesofsamplesbasedontheWeibulldistribution ofeachclass,have beenproposed. Theseapproaches canbeeffectively appliedtoanalyzethevarious defectpatternsthatmayarisewiththeadvancement ofsemiconductor processes (J√∫nioretal.,2016;MahdaviandCarvalho, 2021).However, inwafer-defect analysisstudies,thelackofdiversedefectdataowingto securityreasonsandthedifficulty indistinguishing between defect patternsposechallenges. Despitetheimportance ofexploring unknown defectpatterns, successful application ofOSRinthisfieldhasbeen limited,withonlyafewstudiespartiallyapplyingOSRtechniques. Forexample, (M.B.Alawieh, 2020)att"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_10", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 10, "text": "s. Despitetheimportance ofexploring unknown defectpatterns, successful application ofOSRinthisfieldhasbeen limited,withonlyafewstudiespartiallyapplyingOSRtechniques. Forexample, (M.B.Alawieh, 2020)attempted tomaintain theper- formance ofclassifiers byaddingarejectionoptionforsampleswithlow confidence. However, theirfocuswasonpredefined defectpatterns, leadingtodecreased recallperformance andissueswithrejectingsam- plesfromknowndefectpatternclasses.(Frittolietal.,2022)proposed a methodusingawaferdefectmap(WDM)withaVGG-based submanifold sparseconvolutional network (SSCN)fordimensionality reduction, followedbytheuseofapretrained Gaussian mixturemodel(GMM)to determine unknown classesbasedondensity-based likelihood scores. However, thisapproach haslimitations, suchaslengthyweight-learning processes, significant impactofthreshold settings,increased costfor effective VGGtraining-data augmentation, andrestricted performance-evaluation metricsfordefectrecall. Therefore, ourstudyaimstopresentamethodology fordefect detection inWBMusingOSRtechniques, focusing oneffectively detecting previously unseendefectpatternsbyleveraging onlyknown defectclassesandpatternsinlimitedscenarios. 2.2.Unknown de"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_11", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 11, "text": "thodology fordefect detection inWBMusingOSRtechniques, focusing oneffectively detecting previously unseendefectpatternsbyleveraging onlyknown defectclassesandpatternsinlimitedscenarios. 2.2.Unknown defectpatternsonwaferbinmaps Mostresearchondetecting andclassifying defectsinWBMsfocuses onusingpre-prepared trainingdataandlabelsforsupervised learning (ChaandJeong,2022;Chenetal.,2022;E.S.Kimetal.,2021;M.Kim etal.,2023;Nagetal.,2022;Nakazawa andKulkarni, 2018;Shinde etal.,2022;Xuetal.,2022;N.Yuetal.,2019),unsupervised learning thatdoesnotrequirelabelsforalltrainingdata(Wuetal.,2015;Lee etal.,2021),andsemi-supervised learningthatoptimizes theefficiency andcostoflabelingthetrainingdata(LeeandKim,2020;Shimetal., 2020;YuandLiu,2021).Theseapproaches concentrate primarily on buildingclassifiers basedonpreviously acquiredtrainingdatatodetect knowndefectpatterns. Giventheincreasing importance ofdetecting unknown defectpatternsinWBManalysisduetotheminiaturization ofJ.-S.Shinetal. Computers in Industry 164 (2025) 104208 2 semiconductor manufacturing processes, severalstudieshaveacknowl- edgedthechallenge ofidentifying newtypesofdefectsthatarenot predefined intraditional supervised-learning model"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_12", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 12, "text": "try 164 (2025) 104208 2 semiconductor manufacturing processes, severalstudieshaveacknowl- edgedthechallenge ofidentifying newtypesofdefectsthatarenot predefined intraditional supervised-learning models(Batooletal., 2021).Thislackofresearchcanleadtodifficulties inresponding when unknown defectpatternsemerge.Therefore, thissectionaimstoun- derstand thenecessity ofthisstudybyidentifying theresearch mentioned inWBMstudiesonthedetection issuesofunknown defect patterns,theirsolutions, andthelimitations ofthesestudies. Thestudiesthatmentioned problems withunknown defectpatterns aresummarized inTable1.Forexample,(Y.Kim,2020)highlighted that theclassifiers usedinprevious supervised researchcouldnotdetect unknown defecttypes,leadingtomisclassification andperformance degradation. Toaddressthis,amethodwasproposed todifferentiate betweenOODandINDdefectsbydividingtheentiretrainingdataset andtrainingdifferentlossesforeachdataset.However, thisapproach requirespredefined OODandINDdefectpatterns, whichnecessitates datacollection andtraining. Furthermore, (H.LeeandKim,2020) proposed amulti-label classification solutionbasedon16complex defectpatternsassumedfromfoursingledefecttypes(‚ÄòCircle ‚Äô,‚ÄòScratch "}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_13", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 13, "text": "ecessitates datacollection andtraining. Furthermore, (H.LeeandKim,2020) proposed amulti-label classification solutionbasedon16complex defectpatternsassumedfromfoursingledefecttypes(‚ÄòCircle ‚Äô,‚ÄòScratch ‚Äô, ‚ÄòPartialRing ‚Äô,‚ÄòLocalZone ‚Äô),aimingtoclassifyunlearned complexdefect types.However, thismethodhaslimitations indetecting new single-defect patternsorunlabeled defecttypes.(M.B.Alawieh, 2020) introduced aselective-learning technique topreventtheperformance degradation ofsupervised learning-based convolutional neuralnetwork (CNN)classifiers owingtotheemergence ofunknown defectpatterns, wheretheclassifierdoesnotjudgesamplesthatdonotmeetthedecision threshold. However, thisapproach reliesonauser-defined hyper- parameter forthethreshold, whichsignificantly reducestherecallper- formance oftheclassifierforknowndefectpatterns.Finally,(Nakazawa andKulkarni, 2019)suggested arule-based feature-extraction methodto isolateareasofinterestinWBMdefectregionsandeliminate noise,and theyproposed thattheycouldextractthecorepatternsofunlearned defectpatterns.However, thisresearch, whichusedarule-based meth- odology, islimitedinitsapplication to‚Äòrandom ‚Äôdefectpatternsand requires furtherclassification and"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_14", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 14, "text": "uldextractthecorepatternsofunlearned defectpatterns.However, thisresearch, whichusedarule-based meth- odology, islimitedinitsapplication to‚Äòrandom ‚Äôdefectpatternsand requires furtherclassification andvalidation aftersimplefeature extraction. Consequently, althoughsomestudieshaveproposed solutionsforthe problemofunknown defectpatternsinWBMs,atrulyeffectivemethod fordetecting newtypesofdefectswithoutanypriorinformation about theseunknown defectpatternshasnotyetbeenintroduced. Therefore, inthisstudy,weproposeamethodology thatintroduces anOSRsolution foreffectively detecting unknown defectpatternsinWBMs.2.3.Feature-extraction methodforwaferbinmaps InOSRmethodologies, variousdiscrimination strategies arepri- marilybasedtothedistancebetweentheinputimages.Tosuccessfully applythisapproach, theinputimagesmustbeappropriately mappedto apre-trained latentspace,enablingeffectivecalculation ofthedistances betweeneachimage(MahdaviandCarvalho, 2021).Duringthisprocess, thechoiceofdimensionality-reduction technique isofutmostimpor- tance.Featureswithanexcessively highdimension mayexperience reduced accuracy indistance-based classification andincreased computational costs.Conversely, excessively redu"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_15", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 15, "text": "on technique isofutmostimpor- tance.Featureswithanexcessively highdimension mayexperience reduced accuracy indistance-based classification andincreased computational costs.Conversely, excessively reducing dimensionality canrisklosingessentialinformation fromtheoriginaldata.Therefore, featuresmustbeextracted withappropriate dimensions thatpreserve thecriticalcharacteristics oftheoriginaldatawhileensuringcompu- tationalefficiency. Variousdimensionality-reduction techniques usedin WBMresearchhavebeeninvestigated, rangingfromrule-based manual feature-extraction methods todimension-extraction methods using end-to-end structured CNNs. Table2illustrates differentfeature-extraction techniques. Theseare broadlyclassified intotwocategories: manualfeature-extraction methods andautomated end-to-end feature-extraction approaches (KangandKang,2021).Manualmethods includegeometric feature extraction, density-based featureextraction, andfeatureextraction usingtheRadontransform. Geometric feature(Wuetal.,2015) extraction utilizesparameters suchasthelongaxis,shortaxis,area, curvature, andradiustoanalyzetheshapesofdefects.Density-based featureextraction (Saqlainetal.,2019)dividesthewaferintomulti- ple"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_16", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 16, "text": ".,2015) extraction utilizesparameters suchasthelongaxis,shortaxis,area, curvature, andradiustoanalyzetheshapesofdefects.Density-based featureextraction (Saqlainetal.,2019)dividesthewaferintomulti- pleregionsandtransforms thedefectcountwithineachregionintoa histogram formodeltraining. Inaddition, Radontransform-based featureextraction (Wuetal.,2015)isanimportant methodthatuses thesinogram obtained fromtheRadontransform ofWBMimagesto identifythecoreareasoftheWBM.Otherstudieshavealsoanalyzedthe Table1 Studieswithassumptions aboutunknown defectpatternsinWBMs. Reference Objective Algorithm Model (Y.Kim, 2020)OODdetection OODdetection (Supervised learning)CNN (H.Leeand Kim,2020)Classification ofmixed patternsMulti-label classification (Supervised learning)Semi-supervised convolutional deep generative model withmultiple discriminative networks (M.B. Alawieh, 2020)Prevent misclassification of unknown defect patternDeepselective learning (Supervised learning)CNN&Auto encoder (Nakazawa and Kulkarni, 2019)Featureextraction of defectpatternsFeatureextraction (Segmentation)Seg-net &U-net& Fullyconvolutional network Proposed Detecting and preventing misclassification of unknown defect patternsOS"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_17", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 17, "text": "rni, 2019)Featureextraction of defectpatternsFeatureextraction (Segmentation)Seg-net &U-net& Fullyconvolutional network Proposed Detecting and preventing misclassification of unknown defect patternsOSR (Unsupervised learning)EEOC-SVMTable2 Feature-extraction techniques usedinWBMresearch. Reference Feature Extract MethodFeature SizeClassifier Algorithm (Wuetal., 2015)Geometry, Radon Transform116(40 Radon,18 Geometry) √ó2(Median Filter)SVM Classification (Supervised Learning) (J.Yuand Lu,2016)Geometry, Radon Transform, Gray, Texture53(24 Radon,18 Geometry, 6 Gray,5 Texture)Jointlocaland nonlocallinear discriminant analysis-based Fisher discriminant (J.Zhu etal., 2022)Geometry, Density17(13 Density,4 Geometry)SVM (Piao etal., 2018)Radon Transform30(30 Radon)Ensemble (4 Decisiontree Models) (Saqlain etal., 2019)Geometry, Density, Radon Transform66(40 Radon,20 Density,6 Geometry)Ensemble (Linear regression, Randomforest, Gradient boosting machine, Feedforward neuralnetwork) (Kangand Kang, 2021)Geometry, Density, Radon Transform & CNN59(40 Radon,13 Density,6 Geometry) &(64,64)Ensemble (Feedforward neural networks, CNN) Proposed Radon Transform20(20 Radon)EEOC-SVM OSR (Unsupervised)J.-S.Sh"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_18", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 18, "text": "21)Geometry, Density, Radon Transform & CNN59(40 Radon,13 Density,6 Geometry) &(64,64)Ensemble (Feedforward neural networks, CNN) Proposed Radon Transform20(20 Radon)EEOC-SVM OSR (Unsupervised)J.-S.Shinetal. Computers in Industry 164 (2025) 104208 3 grayscale valuesortexturecharacteristics ofimages(J.YuandLu, 2016). Automated end-to-end feature-extraction methods thatutilize weightvaluesfromdeep-learning models,suchasCNNsandautoen- coders,havealsobeenwidelyused(KangandKang,2021).These feature-extraction methodsprimarily aimtoefficiently useknownpat- ternsforaccurate classification andaregenerally focused on supervised-learning research. However, theeffectiveness ofthese feature-extraction methodshasnotbeenfullyverifiedinstudiesaimed atdetecting unknown patterns. Therefore, thisstudyaimstotrainthe proposed EEOC-SVM classifier usingfeaturesobtained throughthe Radontransform, whilealsoevaluating theperformance ofvarious feature-extraction methodsusedinWBMresearch. 3.Proposed method Fig.1illustrates thecomprehensive framework ofthemethodology proposed inthisstudy.Thetrainingdatasetconsistsofsampleswith knowndefectpatterns, whereasthetestdatasetisassumedtoinclude bothpotentially unknown"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_19", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 19, "text": "llustrates thecomprehensive framework ofthemethodology proposed inthisstudy.Thetrainingdatasetconsistsofsampleswith knowndefectpatterns, whereasthetestdatasetisassumedtoinclude bothpotentially unknown andknowntypesofdefectpatterns. The objectiveofthisstudyistoaccurately classifywhetherthesamplesinthe testdatasetareknowndefectivepatternsornot.Duringthelearningand testingphases,eachdatasetunderwent common preprocessing. The preprocessed trainingdatasetwasusedtotraintheOC-SVM, andthis trainedOC-SVMisthenappliedtoperformOSRonthepreprocessed test dataset.Subsequently, thepredicted sample-classification labelswere re-assigned throughanentropy-estimation processusingtheEEOC-SVM module,leadingtothederivation ofthefinalclassification resultsofthe samples. Proposed MethodOverview Thetrainingphaseofthemethodology proposed inthisstudyisas follows:(1)DataPreprocessing :First,allsamplesinthetrainingdatawere subjected tonoisereduction usingaC-meanfilter.Subsequently, important featuresareextracted throughtheRadontransform. Thispreprocessing stagehelpsextractmeaningful information fromthedataandreduceunnecessary variability. (2)TrainingOC-SVM:TheOC-SVMwastrainedusingonlyknown typesofdefect-pattern"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_20", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 20, "text": "roughtheRadontransform. Thispreprocessing stagehelpsextractmeaningful information fromthedataandreduceunnecessary variability. (2)TrainingOC-SVM:TheOC-SVMwastrainedusingonlyknown typesofdefect-pattern data.TheOC-SVMemploysaRBFkernel tomapthedataintoahigher-dimensional spaceandforma boundary thatdistinguishes databelonging tothenormalcate- goryfromanomalies basedonthedistribution ofthedata. Thetestingstageofthemethodology proposed inthisstudyiscon- ductedthroughdatapreprocessing (1)andEEOC-SVM (2)‚Äì(3).The specificprocedures areasfollows: (1)DataPreprocessing :Thesamplesinthetestdatasetunderwent thesamepreprocessing stepsasthoseinthetrainingphase. (2)OSRwithOC-SVM:Thedecisionboundary oftheOC-SVM trainedfromthetrainingdatawasusedasareference to performbinaryclassification oneachsampleofthetestdata.The distances betweeneachsampleandthedecisionboundary were thencalculated. Thisdistanceinformation isusedtoquantifythe uncertainty intheclassification resultsforeachsampleusing information entropy. (3)LabelReplacement :Thequantified classification-uncertainty scoreforeachsampleisusedtocalculate aweighted sumby class,whichisthenusedtodetermine thefinalclassification label forthesample.Thispro"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_21", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 21, "text": "py. (3)LabelReplacement :Thequantified classification-uncertainty scoreforeachsampleisusedtocalculate aweighted sumby class,whichisthenusedtodetermine thefinalclassification label forthesample.Thisprocessallowsforamoreaccuratedetection ofknownandunknown defect-pattern samples. Fig.2showstheclassification flowoftestdataafterassuming the ‚ÄòScratch ‚ÄôdefectpatternintheWM-811K datasetasanunknown defect pattern. Fig.1.Overallframework oftheproposed method. Fig.2.Flowdiagramoftheproposed methodinthetestphase.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 4 3.1.Datapreprocessing: C-meanFiltering Inthisstudy,aC-meanfilterwasutilizedtofilteroutnoiseinthe WBMimages.Noisefiltering iscommonly employed inimage- classification researchtoeliminate unnecessary regionsandfocuson essentialcorepatterns,therebysignificantly reducingthecomputational complexity (HyunandKim,2020).IntheWBManalysis,somechips withdefectsmayinfluence theextraction ofdefective patterncharac- teristics;hence,suchchipsareconsidered noiseandareremovedbefore extracting thefeaturesofdefective patterns. WhiletheMedianfilter technique, themostcommon andstraightforward method,hasbeen predominantly usedinmostWBMstudies(S.Cheneta"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_22", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 22, "text": "idered noiseandareremovedbefore extracting thefeaturesofdefective patterns. WhiletheMedianfilter technique, themostcommon andstraightforward method,hasbeen predominantly usedinmostWBMstudies(S.Chenetal.,2022;Liao etal.,2014;Piaoetal.,2018;Wuetal.,2015;J.YuandLu,2016),ithas thedrawback ofremoving chipsthatformdefectpatterns, suchas Edge-Ring andScratch,owingtoexcessive noiseremoval.Thisisshown inFig.3(b). Incontrast, theC-meanfilterusedinthisstudytargetsonlythe surrounding areasofeachdefectpatterntoidentifyedgesandremove noise,effectively preserving linearpatterns. Thiscanbeobserved in Fig.3(c).Theworkingprinciple oftheC-meanfilterispresented inAl- gorithm1.Ifthethreshold ofthecondition isnotmet,thebindataofthe chipchangethepixelvalueto1(‚ÄòNone ‚Äôpattern),considering itasnoise, asshowninEq.(1).Thisapproach contributes totheefficientremovalof unnecessary information fromtheWBMimageanalysisandmore accurately extractsthecharacteristics ofessentialdefectpatterns.Bin Pi¬Ü¬à| ‚®Ü‚®Ü‚®Ü„Äà ‚®Ü‚®Ü‚®Ü‚éú2if1 ‚Ä†ni‚Ä†ÃÇ j‚àÉniBin\u0000 Pj) ‚âΩtc 1Otherwisefori‚àÉPdef (1) ALGORITHM 1.:C-MeanFilterforDefectPatternDetection 3.2.Datapreprocessing: radontransform TheRadontransform isausefultoolforanalyzing andunderstanding complex2D"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_23", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 23, "text": "j‚àÉniBin\u0000 Pj) ‚âΩtc 1Otherwisefori‚àÉPdef (1) ALGORITHM 1.:C-MeanFilterforDefectPatternDetection 3.2.Datapreprocessing: radontransform TheRadontransform isausefultoolforanalyzing andunderstanding complex2Ddata.IthasbeenwidelyusedinWBMresearchtohandle2D images,particularly asamethodforfeatureextraction, considering the characteristics oftheoriginalimages(Table2).TheRadontransform effectively represents thecharacteristics ofdefectpatternsbyutilizing thedistancefromtheoriginandangleinformation withrespecttothex- axisonthewafermap,makingitsuitableforextracting andlearning defects.Inthisstudy,thefeature-extraction methodusingtheRadon transform isasfollows.First,theequationofalinewithanangle Œ∏from thex-axisandadistance œÅfromtheorigincanbeexpressed asEq.(2) xcosŒ∏¬áysinŒ∏¬àœÅ# (2) Foraspecific(œÅ,Œ∏),ifwedenotetheresultafterapplyingtheRadon transform asg œÅCŒ∏¬Ü,andtheelementinthex-throwandy-thcolumnof theWBMasM xCy¬Ü,theng œÅCŒ∏¬Ücanbeexpressed asEq.(3) J.-S.Shinetal. Computers in Industry 164 (2025) 104208 5 g œÅCŒ∏¬Ü¬àÃÇm x¬à1ÃÇn y¬à1M xCy¬ÜŒ¥ xcosŒ∏¬áysinŒ∏\u0000œÅ¬Ü# (3) Informula(4)Œ¥ k¬Üisanimpulsefunctionthathasavalueof1only when(k¬à0).IntheWBManalysis,itplaysanimportant roleinselecting thedatapointsofeachdefective dietha"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_24", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 24, "text": "g œÅCŒ∏¬Ü¬àÃÇm x¬à1ÃÇn y¬à1M xCy¬ÜŒ¥ xcosŒ∏¬áysinŒ∏\u0000œÅ¬Ü# (3) Informula(4)Œ¥ k¬Üisanimpulsefunctionthathasavalueof1only when(k¬à0).IntheWBManalysis,itplaysanimportant roleinselecting thedatapointsofeachdefective diethatcorrespond toastraightlineat acertainangle.Utilizingthisfunction, thelocationanddistribution of defective diescanbeaccurately determined undercertainconditions, whichisusefulforfailureanalysisanddefectpatternrecognition. Œ¥ k¬Ü¬à\\ 1Cifk¬à0 0Cotherwise# (4) Thevaluesobtained byvarying œÅCŒ∏canberepresented inmatrix formG,andtheresultsoftransforming WBMinto œÅCŒ∏axesareshownin Fig.4(a).Fig.4(b)showstheresultaftertheRadontransformation ofthe WBMfollowing C-meanfiltering, wherethecharacteristics ofeach defectpatternareemphasized, andnoisethatmayhinderlearningis removed. G¬à‚é¢ ‚®Ä‚®Ä‚®Ä‚®Ä‚®Ä‚àÆg 1C1¬Üg 1C2¬Ü ‚ãØg 1CŒ∏180¬Ü g 2C1¬Üg 2C2¬Ü ‚ãØg 2CŒ∏180¬Ü ‚ãÆ ‚ãÆ ‚ã± ‚ãÆ g œÅmaxC1¬Ü œÅmaxCŒ∏180¬Ü‚ãØg œÅmaxCŒ∏180¬Ü‚é• ‚®Å‚®Å‚®Å‚®Å‚®Å‚®ÄCGŒº¬à‚é¢ ‚®Ä‚®Ä‚®Ä‚®Ä‚®Ä‚àÆgŒº 1¬Ü gŒº 2¬Ü ‚ãÆ gŒº œÅmax¬Ü‚é• ‚®Å‚®Å‚®Å‚®Å‚®Å‚®Ä# (5) Finally,usingformula(5),anewcolumnvector GŒºwasobtained, consisting oftheaveragesofeachrowofthematrixGderivedfromthe Radontransform. Toextractthenecessary featuresfortrainingfromthe columnvector GŒº,20Radon-based featureswereextracted usingcubic interpolation. Theextracted 20-dime"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_25", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 25, "text": "sofeachrowofthematrixGderivedfromthe Radontransform. Toextractthenecessary featuresfortrainingfromthe columnvector GŒº,20Radon-based featureswereextracted usingcubic interpolation. Theextracted 20-dimensional featurevectorwasthen usedtotrainthedecisionboundary oftheOC-SVMandclassifythe samples. 3.3.TrainingOC-SVM SVM,whichisamongthemostpopularmethodologies intraditional machine-learning-based OSRapproaches( Gengetal.,2021;MahdaviandCarvalho, 2021),wasutilizedtoapplytheOSRtechnique for detecting unknown defectpatterns. Inparticular, theOC-SVM isan optimized modelforbinaryclassification basedonwhetherthetestdata matchaknowndefectpattern.OC-SVMutilizeskernelfunctions for mapping datatoahigher-dimensional spaceandformsadecision boundary thatencompasses asmuchnormaldataaspossiblewhilebeing asfarawayfromtheoriginaspossible.Theformulaoftheobjective functionisshowninEq.(6),andthevariables usedintheOC-SVM formulaarelistedinTable3. min wCŒæiCœÅ1 2‚Ä°w‚Ä°2¬á1 ŒΩlÃÇl i¬à1Œæi\u0000œÅ# (6) subjectto w‚â°Œ¶ xi¬Ü¬Ü‚âΩœÅ\u0000ŒæiCŒæi‚âΩ0foralli¬à1C2C‚ãØCl Thisprocessinvolves defining aLagrangian function usingthe methodofLagrange multipliers (Eq.(7))andapplying theKar- ush‚ÄìKuhn ‚ÄìTuckerconditions bydifferentiating withrespecttovariables"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_26", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 26, "text": "0foralli¬à1C2C‚ãØCl Thisprocessinvolves defining aLagrangian function usingthe methodofLagrange multipliers (Eq.(7))andapplying theKar- ush‚ÄìKuhn ‚ÄìTuckerconditions bydifferentiating withrespecttovariables w,Œæ,andœÅ(Eqs.(8)‚Äì(10)): Lp¬à1 2‚Ä°w‚Ä°2¬á1 ŒΩlÃÇl i¬à1Œæi\u0000œÅ\u0000ÃÇl i¬à1Œ±i w‚â°Œ¶ xi¬Ü\u0000œÅ¬áŒæi¬Ü\u0000ÃÇl i¬à1Œ≤iŒæi# (7) ‚àÇLp ‚àÇw¬àw\u0000ÃÇl i¬à1Œ±iŒ¶ xi¬Ü¬à0‚à¥w¬àÃÇl i¬à1Œ±iŒ¶ xi¬Ü# (8) ‚àÇLp ‚àÇŒæi¬à1 vl\u0000Œ±i\u0000Œ≤i¬à0‚à¥Œ±i¬à1 vl\u0000Œ≤i# (9) ‚àÇLp ‚àÇœÅ¬à\u00001¬áÃÇl i¬à1Œ±i¬à0‚à¥ÃÇl i¬à1Œ±i¬à1# (10) Subsequently, theLagrange multipliers arecalculated andtrans- formedintoadualproblem, asshowninEq.(11),fromwhichthefinal objective functionthatformsthedecisionboundary oftheOC-SVMis derived: min1 2ÃÇl i¬à1ÃÇl j¬à1Œ±iŒ±jŒ¶ xi¬ÜŒ¶\u0000 xj) # (11) Inthisstudy,weonlyuseddatafromknowndefectpatternsinthe Fig.3.WM-811K defectpatternimages:(a)originalimages(b)median-filtering applied(c)c-meanfilteringapplied.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 6 trainingphasetoformadecisionboundary usingtheRBFkernelto determine whetherasamplebelongstoanunknown orknownclass.In reality,knownclassesdonotconsistofasingleclassbutofseveral predefined defectpatternclasses.Theseknowndefectpatternclasses weremergedintoasingledataset,whichwassubsequently usedtotrain themodelandgenerate adecisionboundary thr"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_27", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 27, "text": "consistofasingleclassbutofseveral predefined defectpatternclasses.Theseknowndefectpatternclasses weremergedintoasingledataset,whichwassubsequently usedtotrain themodelandgenerate adecisionboundary throughunsupervised learning, asshowninFig.5. 3.4.Labelreplacement withentropyestimation TheEEOC-SVM methodproposed inthisstudyrepresents anewattempttoenhancetheperformance ofthetraditional OC-SVM. Tradi- tionally,theOC-SVMreliesonahyperplane derivedfromtrainingdata todetermine whethernewdatabelongtoaspecificclass.However, this approach dependsonthehyperplane andcannotsolvethemisclassifi- cationissuearisingfromthelimitations ofthetrainingdata(F.Zhuetal., 2016).Toaddressthisissue,weintroduced anentropy-estimation methodtoquantify theuncertainty ofeachsampleandconducted additional analysesonsampleswithhighuncertainty. ThepurposeofEEOC-SVM istoutilizethedecisionboundary ofOC- SVMtoestimatetheuncertainty oftheprobability thateachsample Fig.4.Defectpattern-image sinogram (a)beforefiltering(b)afterfiltering. Table3 Variables usedforformulating OC-SVM. Symbol Description Value x Inputdata x‚àÉZp w Vectorrepresenting thedirection ofthehyperplane w‚àÉZq Œ¶ Mappingfunction(Datatofeaturespace) Zp‚ÜíZq l Nu"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_28", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 28, "text": "filtering. Table3 Variables usedforformulating OC-SVM. Symbol Description Value x Inputdata x‚àÉZp w Vectorrepresenting thedirection ofthehyperplane w‚àÉZq Œ¶ Mappingfunction(Datatofeaturespace) Zp‚ÜíZq l Numberofsamples(Knowndefectpatterns) l‚àÉ‚äî1C‚Ä¶Cl‚äì ŒΩ Ratioofsupportvectorsusedformodeltraining (Hyperparameter)0DŒΩD1 Œæ Distancefromhyperplane tooutliersamples Œæ‚àÉZ œÅ Distancefromorigintohyperplane œÅ‚àÉZ Œ±i Lagrange multiplier foreachsamplespoint0‚âºŒ±i‚âº1 ŒΩl Œ≤i Kernelfunctionparameters Œ≤iF0 Fig.5.Decisionboundary ofOC-SVMtrainedbyknowndefectpatterns.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 7 belongstoeitheraknownclassoranunknown class,andtoappropri- atelyreplacethelabelsofsampleswithhighclassification uncertainty. Inthisstudy,wecalculated theprobability valuestomeasureuncer- taintyusingthedistance Dbetween datapointsandthedecision boundary. Thedistance Dbetween datapointsandthedecision boundary wasobtained usingthedecisionfunctionvalueoftheOC- SVM.Thedecisionfunctioniscalculated asshowninEq.(12),where Œ±iarethelearnedLagrange multipliers, KistheRBFkernelfunction representing thesimilarity betweenthetrainingdatapointxiandthe testdatapointx.Finally,themodel ‚Äôsbias œÅindicates thedistanceb"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_29", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 29, "text": "Eq.(12),where Œ±iarethelearnedLagrange multipliers, KistheRBFkernelfunction representing thesimilarity betweenthetrainingdatapointxiandthe testdatapointx.Finally,themodel ‚Äôsbias œÅindicates thedistancebe- tweentheoriginandthedecisionboundary. Therefore, asshownin Fig.6,thismethodrepresents thedistance(D)betweeneachsampleand thetrainedboundary oftheOC-SVM. Consequently, testdatapoints withhighsimilarity tothetrainingdata,whichbelongtotheknown class,willhavepositivedistancevalues,whiletestdatapointswithlow similarity willhavenegativedistancevalues. Eq.13showstheprocessofcalculating theprobability thatadata pointbelongstoeitheraknownorunknown classusingthedistanceD between thedecisionboundary andthedatapoint.Bysettingthe probability ofdatapointsonthedecisionboundary to0.5,Minmax scalingisappliedsuchthatpositivedistancevaluesarescaledtoprob- abilitiesbetween0.5and1,andnegativedistancevaluesarescaledto probabilities between0and0.5.Theresultingvaluecanbeinterpreted astheprobability thatthedatapointbelongstotheknownclass,defined asP1 D¬Ü.Conversely, 1-P1 D¬Üistheprobability thatthedatapointbe- longstotheunknown class,definedasP2 D¬Ü. D¬àÃÇl i¬à1Œ±iK xiCx¬Ü\u0000œÅ# (12)P1 D¬Ü¬à| ‚®Ü‚®Ü„Äà ‚®Ü‚®Ü‚éúMinMax 0B5C1¬Ü DF0¬Ü 0"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_30", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 30, "text": "pointbelongstotheknownclass,defined asP1 D¬Ü.Conversely, 1-P1 D¬Üistheprobability thatthedatapointbe- longstotheunknown class,definedasP2 D¬Ü. D¬àÃÇl i¬à1Œ±iK xiCx¬Ü\u0000œÅ# (12)P1 D¬Ü¬à| ‚®Ü‚®Ü„Äà ‚®Ü‚®Ü‚éúMinMax 0B5C1¬Ü DF0¬Ü 0B5 D¬à0¬Ü MinMax 0C0B5¬Ü DD0¬Ü# #(13) P1 D¬Ü¬àP Samplebelonging toaknown class¬Ü P2 D¬Ü¬à1\u0000P1 D¬Ü¬àP Samplebelonging toaunknown class¬Ü InEq.(14),theentropyH(D)measures theuncertainty oftheclas- sification resultforeachsample.TheentropyH(D)utilizesP1 D¬Üand P2 D¬ÜasdefinedinEq.(13).Consequently, theinformation entropyin Eq.(14)quantifies theuncertainty oftheclassification resultbycalcu- latingtheprobability P1 D¬Üofasamplebelonging totheKnownclass andtheprobability P2 D¬Üofbelonging totheUnknown class,usingthe distanceDfromthedecisionboundary ofthetrainedOC-SVM. InEEOC- SVM,uncertainty iscalculated foralltestdatasamples,andthetop5% ofsampleswiththehighestuncertainty areselectedforfurtheranalysis. H D¬Ü¬à\u0000‚äîP1 D¬Ülog2P1 D¬Ü¬áP2 D¬Ülog2P2 D¬Ü‚äì# (14) Fortheseselectedsamples,ak-nearest neighbor (KNN)algorithm basedoncosinesimilarity isapplied.Subsequently, theclassweightsof thenearestneighbors obtainedasaresultareaggregated, andtheclass withthegreatestsumofweightsisreassigned tothesample.Inthis process,toassignlo"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_31", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 31, "text": "cosinesimilarity isapplied.Subsequently, theclassweightsof thenearestneighbors obtainedasaresultareaggregated, andtheclass withthegreatestsumofweightsisreassigned tothesample.Inthis process,toassignlowerweightstosampleswithhigheruncertainty, the entropyvaluesaremultiplied by\u00001.Throughthisprocedure, ourstudy aimstoenhance theperformance oftheOC-SVM, particularly by improving theclassification accuracy ofdatawithhighuncertainty. Algorithm 2describes theprocessofapplyingtheKNNalgorithm todata withhighentropyvaluestoaggregate theclassweightsofthenearest neighbors andreassignthelabelsofthedata. Fig.6.Estimation ofprobability ofsampleusingdistancefromtraineddeci- sionboundary. Fig.7.Methodforreassigning labelsofmisclassified samplesinEEOC-SVM.Table4 Distribution ofeachdefectpatterntypeinWM-811K. DefectPattern NumberofSamples Center 4294 Donut 555 Edge-Loc 5189 Edge-Ring 9680 Loc 3593 Random 866 Scratch 1193 Near-full 149 None 145,861 Total 171,380J.-S.Shinetal. Computers in Industry 164 (2025) 104208 8 ALGORITHM 2.:EEOC-SVM LabelReplacement withWeighted Sum ofInformation Entropy Thismethodcanimprovetheperformance oftheOC-SVM and enhancetheclassification accuracyfordatawithhighuncertainty"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_32", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 32, "text": "5) 104208 8 ALGORITHM 2.:EEOC-SVM LabelReplacement withWeighted Sum ofInformation Entropy Thismethodcanimprovetheperformance oftheOC-SVM and enhancetheclassification accuracyfordatawithhighuncertainty. Such anapproach isespecially meaningful forimbalanced datasetsandcon- tributestoreducingtheperformance degradation duetomisclassifica- tion.Fig.7showstheprocessofreplacing theclassesofmisclassified samplesusingtheproposed EEOC-SVM, basedonthedecisionboundary ofOC-SVM. CaseStudy1:usingWM-811K dataset3.5.Experimental design TheWM-811K datasetisextensively usedinWBMdefectanalyses. Thisdatasetcomprises eightdefectpatterns(Center,Donut,Edge-Loc, Edge-Ring, Loc,Random, Scratch,andNear-Full) andonenormal pattern(None).Thenumberofsamplesforeachdefectpatternandthe imagesforeachdefectpatternareshowninTable4andFig.8, respectively. Theprimaryaimofthisstudyistoaccurately identify unknown defectpatternsinthetestdatathatarenotpresentinthe trainingdata.Therefore, tosimulatetheemergence ofunknown defect patternsthatarenotincludedinthetrainingdata,wemaskedeachof theeightdefectpatternsintheWM-811K datasetusinga‚Äòleave-one-out‚Äô approach, asshowninFig.8.Wethendividedtheremaining defect patternsintotrainin"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_33", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 33, "text": "patternsthatarenotincludedinthetrainingdata,wemaskedeachof theeightdefectpatternsintheWM-811K datasetusinga‚Äòleave-one-out‚Äô approach, asshowninFig.8.Wethendividedtheremaining defect patternsintotrainingandtestdatasets.Finally,weaddedthepreviously J.-S.Shinetal. Computers in Industry 164 (2025) 104208 9 maskedandexcluded defectpatterndataintothetestdatasetonly. Usingthesedatasets,wedesigned experiments toevaluatetheperfor- manceoftheproposed modeltoaccurately distinguish betweenknown andunknown defectpatternsintestdata. 3.6.Experimental resultsofproposedmethod Inthisstudy,weproposeamethodology andEEOC-SVM toaccu- ratelydistinguish betweenknownandunknown defectpatterns. To validatetheeffectiveness ofthisresearch,asshowninFig.8,eachdefect patternintheWM-811K datasetwasassumedasanunknown pattern, andtheclassification performance oftheevaluation datasetwas measured usingmodelstrainedoneachscenario. Themetricsusedfor performance evaluation weretheoveralldataclassification accuracy andtherecallmetricforunknown defectpatterns(Eq.15andFig.9). Predictions forunknown patternsareconsidered asbeingpositive,while predictions forknownpatternsareconsidered asbeingnegative. The actualanswerlabelsare"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_34", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 34, "text": "lmetricforunknown defectpatterns(Eq.15andFig.9). Predictions forunknown patternsareconsidered asbeingpositive,while predictions forknownpatternsareconsidered asbeingnegative. The actualanswerlabelsarealsomappedsuchthatdataforknownpatternsisassigned asanegative label,whiledataforunknown patternsis assigned asapositivelabel,evenifmultiplenewclassesarise.For example, inthe\"Center\"scenario, ifthemodelpredictsa\"Center\" patternsampleasanunknown pattern,itisclassified asaTruePositive. Conversely, ifthemodelpredictsitasaknownpattern,itiscountedasa FalseNegative. Inthisscenario, forotherpatternsassumedasknown patterns(e.g.,\"Donut,\"\"Loc,\"\"Scratch,\" etc.),ifthemodelpredictsthem asknownpatterns,theyareclassified asTrueNegative, whilepredicting themasunknown patternsinaFalsePositive. Generally, whenevaluating theperformance ofmodelsforclassesdo notpresentintrainingdata,suchasingeneralized zero-shot learning, Fig.8.Dataset-construction processusedinthestudy. Fig.9.Confusion matrixofstudy. Table5 Performance oftheproposed model:Accuracy &Recall. SenarioName Accuracy Recall Center 0.94 0.90 Donut 0.94 1.00 Edge-Loc 0.88 0.48 Edge-Ring 0.94 0.95 Loc 0.90 0.54 Random 0.94 1.00 Scratch 0.91 0.21 Near"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_35", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 35, "text": "formance oftheproposed model:Accuracy &Recall. SenarioName Accuracy Recall Center 0.94 0.90 Donut 0.94 1.00 Edge-Loc 0.88 0.48 Edge-Ring 0.94 0.95 Loc 0.90 0.54 Random 0.94 1.00 Scratch 0.91 0.21 Near-full 0.94 1.00 Average(Macro) 0.92 0.76 Fig.10.Datasetconstruction processforcross-validation.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 10 thecommonly usedmetricsaretheaccuracy ofseenclassesandthe accuracy ofunseenclasses(Pourpanah etal.,2020).Similarly, inOSR studies,whichaimtoaccurately detectuntrained classes,thedetection accuracyofunseenclassesisfrequently usedtomeasuremodelperfor- mance(Yueetal.,2021).AscanbeseeninEq.15,theaccuracyofthe unknown classissynonymous withtherecalloftheunknown class. Therefore, inthisstudy,wemeasured performance usingtherecall metricoftheunknown class,atermmorecommonly usedingeneral classification performance. Anotherreasonwhytherecallmetricoftheunknown classis important isthatthedetection accuracy oftheunknown classis particularly crucialinsemiconductor manufacturing processes. Since theunknown classdoesnotexistinthetrainingdata,itisverydifficult todetectnewlyoccurring unknown defectpatternsinthetestdata throughclassifiers trainedwiththee"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_36", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 36, "text": "miconductor manufacturing processes. Since theunknown classdoesnotexistinthetrainingdata,itisverydifficult todetectnewlyoccurring unknown defectpatternsinthetestdata throughclassifiers trainedwiththeexistingtrainingdata.Insemi- conductor manufacturing processes, vastamountsofdataaregenerated daily,andproduction proceeds throughrandomsampling. Failureto detectsuchunknown defectpatternscanposesignificant riskstoqual- ity.Forthesereasons,weusedtherecallmetric(unknown classdetect accuracy) oftheunknown classastheperformance evaluation metricin thisstudy. However, ifhyperparameters areadjusted solelytoincreasethe recallmetric,thereisariskofexcessively detecting manynormal samplesduetodataimbalance andknowndefectpatterns, thereby significantly increasing inspection costs.Therefore, theoverallclassifi- cationaccuracyofthedatawasalsopresented. Thisaccuracyissimilar totheconceptofOpenSetOverallAccuracy proposed inthestudybyPal etal.(2022),considering boththeaccuracy ofknownclassesandthe accuracyofunknown classestorepresent theoverallperformance ofthe model. Table5presentstheperformance oftheproposed EEOC-SVM model asdemonstrated inthestudy.Thisperformance wasachieved using datasetsconstruct"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_37", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 37, "text": "yofunknown classestorepresent theoverallperformance ofthe model. Table5presentstheperformance oftheproposed EEOC-SVM model asdemonstrated inthestudy.Thisperformance wasachieved using datasetsconstructed basedonthedefectpatternscenarios depictedin Fig.8.AsshowninTable5,theEEOC-SVM achievedanaverageoverall classification accuracy of0.92andarecall(classification accuracy forunknown defecttypes)of0.76acrossallunknown defectpatternsce- narios.Notably, inscenarios wheredefectpatternssuchas\"Donut\", \"Random\", and\"Near-full\" wereassumedtobeunknown defectpatterns, themodelsuccessfully detectedunknown defecttypescontained within thetestdatawithanaccuracyof0.94andarecallof1.00.Additionally, inscenarios wheredefectpatternssuchas\"Center\"and\"Edge-Ring\" were assumed tobeunknown defects,themodeldemonstrated excellent performance withrecallmetricsandclassification accuracy exceeding 0.90. Inthisstudy,weutilizeda5-foldcross-validation technique to ensurethereliability oftheperformance evaluation resultsforthe proposed model.Thisallowedustoverifytheperformance variationdue torandomness. Theexperimental designforthe5-foldcross-validation canbeseeninFig.10.AsseeninFig.10showsthatwefirstdivide theknownde"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_38", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 38, "text": "orthe proposed model.Thisallowedustoverifytheperformance variationdue torandomness. Theexperimental designforthe5-foldcross-validation canbeseeninFig.10.AsseeninFig.10showsthatwefirstdivide theknowndefectpatterndatafromonescenariodatasetinFig.8intoa totalof5folds.Then,wesequentially changeeachfoldusinga‚Äôleave- one-out ‚Äômethodtoalterthetestdata.Atthispoint,thedataassumedto beunknown defectpatternsarenotsplitintotrainingandtestsets,but 100%ofalldataisalwaysincludedonlyinthetestdata.Asaresult,we conductatotalof5repeatedexperiments foreachscenariodatasetin Fig.8,measuring themodel ‚Äôsperformance variation duetochangesin trainingdatausingthecross-validation technique. Theoverallmodel performance measured throughcross-validation canbeseeninTable6. Lookingatthe5-foldcross-validation resultsoftheproposed model,we canseethattheperformance foreachiterationismaintained without significant deviation inbothaccuracy andrecall.Furthermore, comparing theclassification performance proposed inTable5withthe performance confirmed throughcross-validation inTable6,wecansee thatthereislittleperformance variation betweeniterations forthedata scenarios, andtheaverageperformance isalsoidenticalatabout0.92 an"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_39", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 39, "text": "he performance confirmed throughcross-validation inTable6,wecansee thatthereislittleperformance variation betweeniterations forthedata scenarios, andtheaverageperformance isalsoidenticalatabout0.92 and0.76.Theseresultsareduetothefactthatintheprocessofcreating thetestdataset,theunknown defecttypesarealways100%includedin thetestdata,minimizing theintervention ofrandomness bynotusing randomsplitting. Additionally, theknownpatternsamplesusedfor modeltrainingaremappedtothe\"knownpattern\"classwithout considering subclasses, formingasinglelargedecisionboundary forthe knownpatternclass.Therefore, ifthenumberofsamplesinthetrainingTable6 Performance Recalloftheproposed modelmeasured usingcrossvalidation. Performance ofProposed Method ScenarioName Iteration1 Iteration2 Iteration3 Iteration4 Iteration5 Average Acc Recall Acc Recall Acc Recall Acc Recall Acc Recall Acc Recall Center 0.939 0.898 0.937 0.895 0.936 0.895 0.936 0.896 0.936 0.897 0.937 0.896 Donut 0.937 0.998 0.937 1.000 0.939 0.998 0.938 0.998 0.936 1.000 0.934 0.999 Edge-Loc 0.874 0.471 0.875 0.481 0.873 0.470 0.873 0.470 0.875 0.473 0.874 0.473 Edge-Ring 0.938 0.964 0.936 0.947 0.935 0.946 0.935 0.946 0.935 0.946 0.936 0.946 Loc 0"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_40", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 40, "text": "8 0.998 0.936 1.000 0.934 0.999 Edge-Loc 0.874 0.471 0.875 0.481 0.873 0.470 0.873 0.470 0.875 0.473 0.874 0.473 Edge-Ring 0.938 0.964 0.936 0.947 0.935 0.946 0.935 0.946 0.935 0.946 0.936 0.946 Loc 0.902 0.540 0.903 0.542 0.900 0.542 0.900 0.540 0.901 0.537 0.901 0.540 Random 0.939 1.000 0.938 1.000 0.938 1.000 0.942 1.000 0.936 1.000 0.939 1.000 Scratch 0.910 0.210 0.908 0.205 0.909 0.207 0.907 0.203 0.906 0.209 0.908 0.207 Near-full 0.936 1.000 0.934 1.000 0.937 1.000 0.934 1.000 0.935 1.000 0.935 1.000 Average(Macro) 0.92 0.76 Accuracy¬àTP¬áTN TotalnumberofsamplesCRecall¬àTP Numberofunknownclasssamples# (15)J.-S.Shinetal. Computers in Industry 164 (2025) 104208 11 dataandthedistribution betweenknownpatternclassesaremaintained, wecanseethatperformance variation duetorandomness isminimized, ensuringconsistent reliability intheperformance evaluation processof thisstudy. 3.7.Performance Comparison byFeature-Extract Method Inthissection,wecompared theperformance oftheproposed EEOC- SVMmethodology withvariousWBMfeatureextraction methodsfrom Table2andCNN-based auto-encoders usingoutlierdetection tech- niques.Thecomparison wasmadeusingtheaccuracyandrecallmetrics presented inEq.15.Detailed"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_41", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 41, "text": "odology withvariousWBMfeatureextraction methodsfrom Table2andCNN-based auto-encoders usingoutlierdetection tech- niques.Thecomparison wasmadeusingtheaccuracyandrecallmetrics presented inEq.15.Detaileddescriptions ofeachcompared modelareasfollows: A.Autoencoder (64):ACNN-basedapproach toprocessing WBMwith input-data dimensions scaledto80‚Äù80pixels.Thismodelusesan end-to-end automated feature-extraction technology builtonan encoder ‚Äìdecoderarchitecture toextract64-dimensional features fromtheinputimageusingaCNNkernelwithlearnedweights.Using anencodertrainedonknowndefect-pattern data,unknown defect patternswithinthetestdataweredetectedusinganomalydetection. B.BeforeFeatureExtract(6400):TheWBMimagethathasundergone onlyC-meanfilteringissmoothed toonedimension andusedtotrainTable7 Performance comparison byfeature-extraction method:Accuracy (Recall). SenarioName Performance Comparison byFeature-Extract Method:Accuracy (Recall) A B C D E F(Proposed) Center 0.71(0.30) 0.83(0.63) 0.90(0.85) 0.81(0.45) 0.85(0.87) 0.94(0.90) Donut 0.81(0.25) 0.86(0.63) 0.90(0.99) 0.85(0.86) 0.86(1.00) 0.94(1.00) Edge-Loc 0.68(0.28) 0.77(0.27) 0.83(0.38) 0.79(0.42) 0.79(0.44) 0.88(0.48) Edge-Ring 0.67(0.30) 0.70"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_42", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 42, "text": "0.45) 0.85(0.87) 0.94(0.90) Donut 0.81(0.25) 0.86(0.63) 0.90(0.99) 0.85(0.86) 0.86(1.00) 0.94(1.00) Edge-Loc 0.68(0.28) 0.77(0.27) 0.83(0.38) 0.79(0.42) 0.79(0.44) 0.88(0.48) Edge-Ring 0.67(0.30) 0.70(0.28) 0.75(0.26) 0.84(0.80) 0.74(0.38) 0.94(0.95) Loc 0.67(0.10) 0.79(0.19) 0.87(0.58) 0.79(0.26) 0.83(0.64) 0.90(0.54) Random 0.66(0.59) 0.86(0.99) 0.90(1.00) 0.85(0.88) 0.86(1.00) 0.94(1.00) Scratch 0.74(0.33) 0.82(0.05) 0.88(0.25) 0.83(0.23) 0.84(0.34) 0.91(0.21) Near-full 0.74(0.71) 0.86(1.00) 0.90(1.00) 0.85(1.00) 0.85(1.00) 0.94(1.00) Average(Macro) 0.71(0.40) 0.81(0.51) 0.87(0.66) 0.83(0.61) 0.83(0.71) 0.92(0.76) Fig.11.(a)Accuracy performance (%)foreachpattern,(b)macro-average performance (%)ofaccuracy andrecallforallpatterns.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 12 OC-SVM.ThesizeoftheWBMbeforeflattening is80√ó80,andafter theflattening process,itbecomesa6400-dimensional vector. C.Radon/Geometry/Density (59):Afterprocessing theWBMimages withaC-meanfilter,featureswereextracted usingacombination of theRadontransform, geometric analysis,anddensitymeasurements (total59-dimensional vector).Subsequently, thesefeatureswere usedtotrainOC-SVM. D.Geometry (6):TheWBMdefect"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_43", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 43, "text": "eextracted usingacombination of theRadontransform, geometric analysis,anddensitymeasurements (total59-dimensional vector).Subsequently, thesefeatureswere usedtotrainOC-SVM. D.Geometry (6):TheWBMdefect-pattern imagewasanalyzed asa sparsematrix,andthegeometric featuresofthelargestconnected component intheWBMwereusedasthefeatures(radius,area,and lengthofmajoraxisofconnected component (6-dimensional vec- tor)).Asix-dimensional vectorconsisting oftheminor-axis length, eccentricity, andsoliditywasusedastheinputfortheOC-SVM. E.Density(13):Afterprocessing theWBMimageusingtheC-means filter,theWBMwasdividedinto13zones(13-dimensional vector), andfeatureswereextracted bymeasuring thedensityofthezones. ThesefeatureswerethenusedtotraintheOC-SVM. F.Proposed Method(20):Afterprocessing theWBMimageswithaC- meanfilter,20features(20-dimensional vectors)wereextracted by interpolating theaveragevaluesofeachrowfromthematricesbased ontheRadontransform. Thesefeatureswereusedtotrainthepro- posedmodel(EEOC-SVM ). Inthissection,toensureconsistent performance evaluation across models,differenttrainingdatasetswereusedforeachscenariowhile keepingthemodel ‚Äôsbasicstructure, operational method,andhyper- parameters "}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_44", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 44, "text": ". Inthissection,toensureconsistent performance evaluation across models,differenttrainingdatasetswereusedforeachscenariowhile keepingthemodel ‚Äôsbasicstructure, operational method,andhyper- parameters (e.g.,optimizer andlearningrateoftheAutoencoder, nuof SVM,etc.)unchanged. Thus,theexperiments inthissectionevaluate howwelltheproposed EEOC-SVM methodology, thefeatureextraction methods ofWBMmodels,andoutlierdetection-based autoencoder modelscanclassifyvariousshapesofunknown defectpatternsusing onlyknownpatterndata.Regarding this,therowlabeled\"Center\"in Table7represents theclassification performance ofeachcomparative modelevaluated usingthedatasetfromthe\"Center\"scenarioinFig.8.In thisscenario, the\"Center\"defectpatternisassumed asanunknown pattern,thusexcludedfromthetrainingdatawhileallotherpatternsin WM-811K areincludedasknowndefectpatterns. Table7andFig.11showthattheproposed EEOC-SVM methodology (F)hassuperioroverallclassification accuracyandrecallcompared with theothermodels.ThisindicatesthatEEOC-SVM canexhibitexceptional performance indetecting unknown defectpatterns, evenwhenonly knowndefectpatternsareusedastrainingdata.Theseresultsrepresent asignificant advancement inovercoming ex"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_45", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 45, "text": "sthatEEOC-SVM canexhibitexceptional performance indetecting unknown defectpatterns, evenwhenonly knowndefectpatternsareusedastrainingdata.Theseresultsrepresent asignificant advancement inovercoming existinglimitations inthe WBMresearchfield.Eachdefectpatternisassumedtobeunknown for eachmodel;theperformance perdefectpattern(Fig.11(a))andaverage performance graphforalldefects(Fig.11(b))areasshowninFig.11.In particular, thesignificant performance difference inspecificdefect patterns,suchas‚ÄòEdge-Ring ‚Äôand‚ÄòRandom ‚Äôsuggeststhattheproposed methodisbetteratunderstanding andclassifying specificdefectpat- terns.However, fordefectpatternssuchas‚ÄòLoc‚Äôand‚ÄòScratch ‚Äô,arela- tivelylowerperformance isobservedcompared toothermodels.Ifthesedefectpatternsarenottrained,theyarefrequently confused with similarlyshapedclassesoftraineddefectpatterns,suchas‚ÄòEdge-Loc ‚Äôor ‚ÄòLoc‚Äô,andtheperformance metricsareobserved todegradeacrossall models. Compared withothermodels,thelowperformance oftraditional weight-based model-training techniques andanomaly-detection ap- proaches indetecting unknown patternshighlights thelimitations of thesemodels(ModelA).Although thebasicperformance oftheOC-SVM (ModelB)withoutfeatureextr"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_46", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 46, "text": "l-training techniques andanomaly-detection ap- proaches indetecting unknown patternshighlights thelimitations of thesemodels(ModelA).Although thebasicperformance oftheOC-SVM (ModelB)withoutfeatureextraction wasrelatively high,itstillfellshort oftheproposed EEOC-SVM methodology. Additionally, theperformance degradation experienced byModelC,whichusedvariousfeature- extraction methods, andModelD,whichexcessively reducedthe dimensionality oftheoriginaldata,suggeststhathavingtoomanyortoo fewfeaturescanbedisadvantageous forclassifying wafer-defect pat- terns.Conversely, ModelE,whichutilizedadensity-estimation method forfeatureextraction, showedhigherrecallvaluesthantheothermodels butstillperformed lowerinbothaccuracy andrecallcompared tothe proposed EEOC-SVM methodology. Thisindicates thattheproposed EEOC-SVM methodology isamoresuitableapproach fordetecting un- knowndefectpatterns. 3.8.Performance comparison byOSRmodel Toevaluatetheperformance oftheproposed modelmorespecif- ically,weconstructed classifiers forunknown defectpatternsinthe WBMusingvariousOSRtechniques andcompared theirperformance withtheproposed methodology. Theperformance metricscompared werethesameasinEq.(15).Whenevaluati"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_47", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 47, "text": "ted classifiers forunknown defectpatternsinthe WBMusingvariousOSRtechniques andcompared theirperformance withtheproposed methodology. Theperformance metricscompared werethesameasinEq.(15).Whenevaluating theaccuracyandrecall metricsforeachmodel,weassessedthemusingabinaryclassification approach forknownandunknown classes.Detaileddescriptions ofthe configurations ofeachmodelareasfollows: Soft-Max (80√ó80):Todetectunknown patterns, weusedthe ResNet50 modelfortraining. Throughout thetrainingprocess,the optimalthreshold foreachclasswasdetermined. Themodelwas structured toclassifysamplesasunknown defectpatternsiftheyfailed tomeettheoptimalthreshold foranyclass,basedontheprobability outputforeachclassthroughSoftMaxacrossallclasses. Pre-SoftMax (80√ó80):Byutilizingknowndefectpatterns, we employed logitvaluesimmediately beforetheSoftMaxlayerofapre- trainedResNet50 model.Wemeasured theaverageactivation distance betweeneachlogitvalue.Weestablished athreshold basedonthedis- tancebetweentheaveragelogitsforeachclassofsamples.Thisenabled ustoconstruct amodelcapableofdetecting unknown defectpatterns. Open-Max (80√ó80):TheOpenMax modelalsoutilizesapre- trainedResNet50, leveraging knowndefectpatterns. I"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_48", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 48, "text": "tsforeachclassofsamples.Thisenabled ustoconstruct amodelcapableofdetecting unknown defectpatterns. Open-Max (80√ó80):TheOpenMax modelalsoutilizesapre- trainedResNet50, leveraging knowndefectpatterns. Itcalculates the averageactivation distanceforeachlogitandthen,foreachclass,uses thesamplesthatarefurthestawaytodetermine theextremevalues. TheseextremevaluesarethenfittedtoaWeibulldistribution foreach class.Thesamplesthatdonotmeetthethreshold determined bythe Weibulldistribution areclassified ashavingunknown defectpatterns. VGG16 &GMM(40):(Frittolietal.,2022)usedapre-trained SSCN Table8 Performance comparison byOSRmodel:Accuracy (Recall). SenarioName Performance comparison byOSRmodel:Accuracy (Recall) Soft-Max (Nguyenetal.,2015)Pre-SoftMax OpenMax (BendaleandBoult,2016)VGG16ÔøΩGMM (Frittolietal.,2022)Proposed Method Center 0.81(0.40) 0.82(0.43) 0.72(0.61) 0.85(0.69) 0.94(0.90) Donut 0.85(0.42) 0.89(0.37) 0.89(0.35) 0.61(0.86) 0.94(1.00) Edge-Loc 0.81(0.44) 0.86(0.43) 0.72(0.47) 0.75(0.39) 0.88(0.48) Edge-Ring 0.82(0.13) 0.59(0.30) 0.71(0.42) 0.57(0.33) 0.94(0.95) Loc 0.82(0.50) 0.86(0.43) 0.75(0.57) 0.69(0.43) 0.90(0.54) Random 0.83(0.53) 0.78(0.52) 0.85(0.45) 0.74(0.39) 0.94(1.00) Scrat"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_49", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 49, "text": "88(0.48) Edge-Ring 0.82(0.13) 0.59(0.30) 0.71(0.42) 0.57(0.33) 0.94(0.95) Loc 0.82(0.50) 0.86(0.43) 0.75(0.57) 0.69(0.43) 0.90(0.54) Random 0.83(0.53) 0.78(0.52) 0.85(0.45) 0.74(0.39) 0.94(1.00) Scratch 0.80(0.37) 0.87(0.36) 0.81(0.50) 0.58(0.21) 0.91(0.21) Near-full 0.85(0.14) 0.87(0.11) 0.87(0.14) 0.90(0.82) 0.94(1.00) Average(Macro) 0.82(0.37) 0.82(0.37) 0.79(0.44) 0.71(0.52) 0.92(0.76)J.-S.Shinetal. Computers in Industry 164 (2025) 104208 13 modelbasedona224√ó224VGG16ona20,000√ó20,000WDM, leveraging knowndefectpatternclasses.Thismodelreducedthefea- turesto128dimensions, andthesereducedfeatureswerethenusedas inputstoaGMM,whichisalsotrainedonknowndefect-pattern classes. Thedensity-based likelihood ratiofromtheGMMwasusedtodetect unknown classes.Inourstudy,weusedWBMinsteadofWDMand therefore employed theVGG16modelfordimension reduction instead oftheSSCNmodule.Inaddition, wereducedthenumberoffeaturesto 40dimensions insteadof128,whichwerethenusedasinputsforthe GMM. Proposed Method(20):Afterprocessing theWBMimageswithaC- meanfilter,20features(20-dimensional vectors)wereextracted by interpolating theaveragevaluesofeachrowfromthematricesbasedon theRadontransform. Thesefeatureswereusedtotra"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_50", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 50, "text": "processing theWBMimageswithaC- meanfilter,20features(20-dimensional vectors)wereextracted by interpolating theaveragevaluesofeachrowfromthematricesbasedon theRadontransform. Thesefeatureswereusedtotraintheproposedmodel(EEOC-SVM ). Table8presentsacomparison oftheclassification performance of theproposed modelandmodelsdeveloped usingdifferentOSRtech- niques.Themethodology leveraging EEOC-SVM proposed inthisstudy demonstrates superiorclassification accuracy andrecallmetricsacross mostunknown defect-pattern datasets, exceptfortherecallofthe ‚ÄòScratch ‚Äôand‚ÄòLocal ‚Äôclasses.Fordefectpatternssuchas‚ÄòScratch ‚Äô,‚ÄòLoc‚Äô, and‚ÄòEdge-Loc ‚Äô,thisstudyassumedunknown defectpatternsusingthe WM-811K datasetinleave-one-out method.However, becausethese defectsarehighlysimilar,evenwithouttrainingwithoneclassassumed tobeunknown, themodelstendtorecognize themashavingsimilar defectpatterns,resultinginagenerally lowrecallperformance acrossall models.ModelsbasedonSoft-Max, Pre-SoftMax, andOpen-Max, which usepre-trained deep-learning classifier thresholds foreachdefect pattern,showmarginally higherrecallmetricsfordistinguishing similar patterns. Incontrast,forsingledefectpatternsthatdiffersignificantly from existing"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_51", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 51, "text": " deep-learning classifier thresholds foreachdefect pattern,showmarginally higherrecallmetricsfordistinguishing similar patterns. Incontrast,forsingledefectpatternsthatdiffersignificantly from existing defectpatterns, suchas‚ÄòCenter ‚Äô,‚ÄòDonut ‚Äô,‚ÄòEdge-Ring ‚Äô, ‚ÄòRandom ‚Äô,and‚ÄòNear-full ‚Äô,anoticeable difference existsintheaccuracy andrecallmetricsbetweenotherOSRtechniques andtheproposed methodology. Inparticular, fordefectpatternssuchas‚ÄòEdge-Ring ‚Äô,the proposed modelexhibitsarecallrateover50%higherthanthatofthe next-best-performing model,Open-Max, indicating asignificant improvement. Thetestperformance ofeachmodelalsoshowsthatthe ResNet-based Open-Max, SoftMax, andPre-SoftMax modelsexhibit similarperformance. Fig.12presentsagraphoftheclassification ac- curacyandmacro-averaged recallmetricsforalldatasetsforeachmodel usingtheOSRtechnique. TheOSRmethodusingVgg16andGMMshows slightlybetterrecallmetricscompared toothermodels.However, the proposed methodoutperforms thismodelbyapproximately 25%in recallandabout21%inaccuracy. Additionally, compared toallmodels, theproposed methodachievesatleast10%higheraccuracyandatleast 24%higherrecall.Theseresultsdemonstrate theeffectiveness andsu- periorperforma"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_52", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 52, "text": "llandabout21%inaccuracy. Additionally, compared toallmodels, theproposed methodachievesatleast10%higheraccuracyandatleast 24%higherrecall.Theseresultsdemonstrate theeffectiveness andsu- periorperformance oftheproposed approach fordetecting unknown defectpatternswithintheWBMdomain. CaseStudy2:usingreal-field data Thissectionfurtherverifiestheapplicability ofthemethodologies foreffectively detecting variousunknown defectpatternsthatcanoccur duringthesemiconductor-manufacturing process,basedonrealfield dataobtained fromrealsemiconductor-production sites.Thedefect patternimagesobtainedfromrealfielddataandtheircountsarelisted inTable9. The‚ÄòEye‚Äôdefectpatternisconsidered asanewsingle-defect pattern, havingashapesimilartoamixofthe‚ÄòCenter ‚Äôand‚ÄòEdge-Ring ‚Äôdefect Fig.12.Macroaverageperformance (%)ofeachOSRmodel. Table9 Realfielddataimagesandnumberofsamples. DefectPatternName WaferMapImage NumberofSamples Eye 715 Windmill 221 Total 936 Fig.13.Sinogram imageofrealfielddata.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 14 Fig.14.Datasetconstruction processwithrealfielddata. Table10 Performance comparison byOSRmethod:accuracyandrecall. ModelName Dataset1Eye Dataset2Windmill Dataset3Eye&W"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_53", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 53, "text": "in Industry 164 (2025) 104208 14 Fig.14.Datasetconstruction processwithrealfielddata. Table10 Performance comparison byOSRmethod:accuracyandrecall. ModelName Dataset1Eye Dataset2Windmill Dataset3Eye&Windmill Average(Macro) Accuracy Recall Accuracy Recall Accuracy Recall Accuracy Recall Soft-Max (Nguyenetal.,2015)0.80 0.62 0.85 0.67 0.78 0.59 0.81 0.63 Pre-SoftMax 0.72 0.56 0.86 0.71 0.70 0.69 0.71 0.65 OpenMax (BendaleandBoult,2016)0.75 0.50 0.80 0.44 0.72 0.42 0.76 0.45 VGG16ÔøΩGMM (Frittolietal.,2022)0.80 0.61 0.81 0.71 0.79 0.71 0.80 0.68 Proposed Method 0.98 1.00 0.98 1.00 0.98 1.00 0.98 1.00 Fig.15.Macroaverageperformance (%)ofeachmodel.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 15 patternsfoundinWM-811K. The‚ÄòWindmill ‚Äôdefectimageissimilarto the‚ÄòLoc‚Äôdefectpatternbutischaracterized bythecontinuous occur- renceoffour‚ÄòLoc‚Äôdefectpatternsataspecificlocation.Thesinogram imagesaftertheRadontransform ofeachindustrial datasetcanbe observed inFig.13,showingdifferentpatternsofdefectcharacteristics fromthoseofWM-811K. AsseeninFig.14,themodelwastrainedusingonlytheWM-811K dataset,andexperiments weredesigned toevaluatethemodel ‚Äôsper- formance byaddingthreedifferentcombinations ofda"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_54", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 54, "text": "tcharacteristics fromthoseofWM-811K. AsseeninFig.14,themodelwastrainedusingonlytheWM-811K dataset,andexperiments weredesigned toevaluatethemodel ‚Äôsper- formance byaddingthreedifferentcombinations ofdatasetstothetest data.Dataset1includestheadditionofthe\"Eye\"patterntothetestdata, andDataset2includestheadditionofthe\"Windmill\" pattern.Each datasetisconstructed byaddingindustrial defectpatternstothetest dataalongside thedefectpatternsfromtheWM-811K dataset.Addi- tionally,Dataset3includesboththe\"Eye\"and\"Windmill\" patternsinthe testdata,allowing fortheevaluation ofthemodel ‚Äôsperformance in scenarios wheremultiple unknown defectpatterns occur simultaneously. Table10andFig.15presenttheclassification performance of variousOSRtechniques appliedunderthesameconditions asinSection 4,utilizingareal-field dataset.Acloserexamination oftheresults revealed similarities tothoseevaluated usingtheWM-811K datain Section4.Themodelsemploying OSRtechniques onthesameResNet50 model,namelySoftMax, OpenMax, andPre-SoftMax, exhibited anaverageaccuracy difference oflessthan5%,indicating nosignificant difference inclassification performance. However, theSoftMaxmodel, whichlearnedtheoptimalthreshold foreachclassfr"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_55", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 55, "text": "-SoftMax, exhibited anaverageaccuracy difference oflessthan5%,indicating nosignificant difference inclassification performance. However, theSoftMaxmodel, whichlearnedtheoptimalthreshold foreachclassfromthetraining data,demonstrated amarginally betterperformance intermsofaccu- racyandrecallthantheothermodels.Similarly, themodelsutilizing VGG16andGMMwithOSRtechniques, asinSection4,showthehighest recallmetrics.However, nosignificant difference wasobserved inthe accuracywhencompared withtheothermodels. Moreover, inevaluation dataset3(EyeandWindmill), whichas- sumestheoccurrence ofmultipleunknown defect-pattern classes,all modelsexceptfortheproposed methodology showedadecrease in classification accuracycompared todatasets1and2.Thissuggeststhat theperformance ofthemodelmaydeclinewhenthenumberofun- knowndefectpatternsincreases orwhenvariousdefectpatternsoccur simultaneously. However, theproposed EEOC-SVM modeldemon- stratedsuperiorperformance intermsofbothaccuracy andrecall, provingitsefficientdefect-pattern detection andclassification capabil- itiesonactualfielddata.Notably,theabilityofthismodeltodetect 100%oftheunknown defectpatternsandachieveanoverallaccuracy ofover98%inalldatasetsindi"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_56", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 56, "text": "ntdefect-pattern detection andclassification capabil- itiesonactualfielddata.Notably,theabilityofthismodeltodetect 100%oftheunknown defectpatternsandachieveanoverallaccuracy ofover98%inalldatasetsindicatesthatitcaneffectively identifyand classifyvariousdefectpatternsinreal-field environments, aswellas manage theemergence ofmultiple unknown defectpatterns simultaneously. Theresultsofthevisualanalysisofthetestdatausingtheadditional clustering methodsarepresented inFig.16.Fig.16(a)showstheresults ofclassifying thetestdatausingOC-SVMwithoutgoingthroughthe feature-extraction phaseonindustrial dataset3 (whichcontainstwo unknown defectpatterns), andthenvisualizing thesamplespredicted as unknown defectpatternsusingUMAPwiththeactualanswerlabelsof eachsample.Here,the ‚Äú1‚Äùand ‚Äú-1‚Äùlabelsrepresent unknown and knowndefectpatterns,respectively. Fig.16(b)showstheresultsusing theanswerlabelsoftheunknown defectpatternsfinallypredicted bythe EEOC-SVM usingtheproposed methodology, and(c)showstheresults ofeachclusterformedusingDB-SCAN ontheunknown defectpatterns predicted bytheEEOC-SVM inthesamemanner.Thus,wecanconfirm thattheproposed methodcaneffectively detectbothknownandun- knownpatterns, andclearclu"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_57", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 57, "text": "achclusterformedusingDB-SCAN ontheunknown defectpatterns predicted bytheEEOC-SVM inthesamemanner.Thus,wecanconfirm thattheproposed methodcaneffectively detectbothknownandun- knownpatterns, andclearclusterseparation amongunknown defect patternsisalsoobserved. Additionally, byexamining theWBMimagesofthesamplesineach clusterbasedontheclustered resultsinFig.16(c),asshowninFig.17, wecanconfirmthatdifferenttypesofdefectpatternsareappropriately formedforeachcluster:cluster0(knowntypeofdefectpattern),clusters 1and2(‚ÄúEye‚Äùdefectpattern),andcluster3(‚ÄúWindmill ‚Äùdefectpattern). Theseresultsindicatethatevenwiththeoccurrence ofmultiple Fig.16.(a)Truelabelsafterclassification byOC-SVM, (b)truelabelsafterclassification byEEOC-SVM, (c)DB-SCAN clustering resultsafterclassification by EEOC-SVM. Fig.17.WBMimageforeachclusterusingtheresultsfromDB-SCAN.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 16 unknown defectpatterns, byseparating unknown datausingthepro- posedmethodology andEEOC-SVM andproceeding withclustering basedontheresults,engineers canbeassistedwithearlyrecognition of theemergence ofnewtypesofdefects.Furthermore, theresults demonstrate thepotential ofthemodeltoefficiently handletas"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_58", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 58, "text": "ding withclustering basedontheresults,engineers canbeassistedwithearlyrecognition of theemergence ofnewtypesofdefects.Furthermore, theresults demonstrate thepotential ofthemodeltoefficiently handletasks,such asaddingclassesofunknown defectpatternstoexistingclassifiers or labelingnewdefects. 4.Conclusions Thisstudyproposes amethodology foraccurately andefficiently detecting unknown defectpatternsthathavebeenoverlooked inpre- viousWBMdefect-pattern analysisstudies.Mostprevious studies focusedontheuseoftrainingdatasetstomakeclassifiers moreaccurate andefficient.However, thesestudiesdidnotconsiderthepossibility and importance ofdetecting unknown defectpatternsthatdonotexistinthe trainingdataandhaverecentlyemerged. Consequently, itisamajor challenge todetect,collect,andlabeltheseunknown defectpatternsat semiconductor manufacturing sites. Therefore, thisstudyproposesanEEOC-SVM modelandmethodol- ogythatutilizesOSRtechniques toaccurately classifyknowndefect patternswithoutanyinformation orassumptions regarding unknown defectpatterns. Thismethodology includesdesigning amodelthat combines C-meanfilteringfornoiseremovalintheWBM,feature extraction basedontheRadontransform, andtheEEOC-SVM model"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_59", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 59, "text": "mptions regarding unknown defectpatterns. Thismethodology includesdesigning amodelthat combines C-meanfilteringfornoiseremovalintheWBM,feature extraction basedontheRadontransform, andtheEEOC-SVM modelto improvethedecisionuncertainty ofthetraditional OC-SVM. Toevaluate theperformance oftheproposed model,weassumedeachdefectpattern intheWM-811K datasettobeanunknown patternandcompared its performance withthatofexistingWBMfeature-extraction methodsand anomaly-detection techniques usingaweighted learning-based CNN model.Theresultsshowedthattheproposed EEOC-SVM model exhibited thehighestperformance intermsofbothaccuracyandrecall rates,andsuccessfully detectedunknown defectpatterns.Additionally, byconstructing modelsapplying variousOSRtechniques andcon- ductingdetection evaluations forunknown defectpatternsinWBM underthesameconditions, theproposed modeldemonstrated superior classification performance acrossallmetrics.Furthermore, thisstudy provedthattheproposed modelcouldefficiently detectandclassify variousdefectpatternsinrealenvironments, surpassing anoverallac- curacyof98%andachieving 100%detection ofunknown defectpat- ternsinalldatasetsbasedonactualsemiconductor-manufacturing field dat"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_60", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 60, "text": "lassify variousdefectpatternsinrealenvironments, surpassing anoverallac- curacyof98%andachieving 100%detection ofunknown defectpat- ternsinalldatasetsbasedonactualsemiconductor-manufacturing field data(‚ÄòEye‚Äô,‚ÄòWindmill‚Äô). Thisconfirms thatthemodelcannotonly efficiently detectandclassifyvariousdefectpatternsthatmayoccurin realenvironments butisalsoapplicable tosituations wheremultiple unknown defectsemergesimultaneously. Inaddition, wevisually analyzed thetestdatausingadditional clustering methods, confirming thattheproposed methodcaneffectively detectknownandunknown data,andobserved aclearclustering separation betweentheunknown data.Consequently, theproposed methodology isexpected tosignifi- cantlyaffectthequalitycontrolandmaintenance offuture semiconductor-manufacturing processes, whichwillbecomemore complex.Thismethodology canbeusedasapowerfultoolforeffectively detecting andresponding tounexpected defectpatterns. Thisstudyaimstoclearlydetectunknown defectdata,whichare newdefecttypesthathavenotbeenpre-learned. Accordingly, thetest dataweredividedintoknowndefectpatterndataandunknown defect patterndata,butthedetailedclassesoftheknowndefectpatternsample werenotclassified. Therefore, f"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_61", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 61, "text": "athavenotbeenpre-learned. Accordingly, thetest dataweredividedintoknowndefectpatterndataandunknown defect patterndata,butthedetailedclassesoftheknowndefectpatternsample werenotclassified. Therefore, futureresearch, basedontheresultsof thisstudy,isfocusingonupdating thepre-trained classifier usinga stream-based onlineactivelearningmethod.Thiswillensurethatthe pre-trained classifier maintains highperformance onknowndefect patterndatawhilecontinuously detecting newlyoccurring unknown defectpatterndatainthetestdata.Additionally, inordertobetterun- derstandmoredetaileddefectinformation, weareconducting multi-task learningresearchthatcombines defectpatternclassifiers andlanguage modelsusingtextdatacontaining information aboutsuspiciousprocesses andequipment, aswellasWBMimages.Thesestudieswill contribute significantly tosemiconductor manufacturing processes by notonlydetecting unknown defectsproposed inthisstudybutalso providing aclearerandmoredetailedanalysisofthecausesofexisting defects. CRediTauthorship contribution statement Beom-Seok Kim:Visualization, Validation, Software, Formalanal- ysis.Min-JooKim:Projectadministration, Datacuration.Jin-SuShin: Writing ‚Äìoriginaldraft,Validation, "}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_62", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 62, "text": "ediTauthorship contribution statement Beom-Seok Kim:Visualization, Validation, Software, Formalanal- ysis.Min-JooKim:Projectadministration, Datacuration.Jin-SuShin: Writing ‚Äìoriginaldraft,Validation, Methodology, Conceptualization. DongheeLee:Supervision, Projectadministration, Conceptualization. Declaration ofCompeting Interest Theauthorsdeclarethattheyhavenoknowncompeting financial interestsorpersonalrelationships thatcouldhaveappeared toinfluence theworkreportedinthispaper. Acknowledgement Thisworkwassupported bytheNationalResearch Foundation of Korea(NRF)grantfundedbytheKoreagovernment (MSIT)(No.NRF- 2022R1C1C1011743). Dataavailability Datawillbemadeavailable onrequest. References Batool,U.,Shapiai,M.I.,Tahir,M.,Ismail,Z.H.,Zakaria,N.J.,Elfakharany, A.,2021. ASystematic reviewofdeeplearningforsiliconwaferdefectrecognition. IEEE Access9,116572‚Äì116593. https://doi.org/10.1109/ACCESS.2021.3106171. Bendale,A.,Boult,T.E.,2016.Towardsopensetdeepnetworks. Proc.IEEEConf. Comput.Vis.PatternRecognit. 1563‚Äì1572. Cha,J.,Jeong,J.,2022.Improved U-netwithresidualattention blockformixed-defect wafermaps.Appl.Sci.(Switz.)12(4).https://doi.org/10.3390/app12042209. Chen,F.-L.,Liu,S.-F.,2000.Aneur"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_63", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 63, "text": "Recognit. 1563‚Äì1572. Cha,J.,Jeong,J.,2022.Improved U-netwithresidualattention blockformixed-defect wafermaps.Appl.Sci.(Switz.)12(4).https://doi.org/10.3390/app12042209. Chen,F.-L.,Liu,S.-F.,2000.Aneural-network approach torecognize defectspatial patterninsemiconductor fabrication. IEEETrans.SEMICONDUCTOR Manuf.13(3). Chen,S.,Zhang,Y.,Hou,X.,Shang,Y.,Yang,P.,2022.Wafermapfailurepattern recognition basedondeepconvolutional neuralnetwork. ExpertSyst.Appl.209. https://doi.org/10.1016/j.eswa.2022.118254. Fan,S.K.S.,Chiu,S.H.,2024.AnewViT-Based augmentation framework forwafermap defectclassification toenhancetheresilience ofsemiconductor supplychains.Int.J. Prod.Econ.273.https://doi.org/10.1016/j.ijpe.2024.109275. Frittoli,L.,Carrera,D.,Rossi,B.,Fragneto, P.,Boracchi, G.,2022.Deepopen-set recognition forsiliconwaferproduction monitoring. PatternRecognit. 124.https:// doi.org/10.1016/j.patcog.2021.108488. Geng,C.,Huang,S.J.,Chen,S.,2021.RecentAdvances inOpenSetRecognition: A Survey.In:InIEEETransactions onPatternAnalysisandMachineIntelligence, 43.IEEE Computer Society,pp.3614‚Äì3631. https://doi.org/10.1109/TPAMI.2020.2981604. Hou,X.,Yi,M.,Chen,S.,Liu,M.,Zhu,Z.,2024.Recognition andclassific"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_64", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 64, "text": "ransactions onPatternAnalysisandMachineIntelligence, 43.IEEE Computer Society,pp.3614‚Äì3631. https://doi.org/10.1109/TPAMI.2020.2981604. Hou,X.,Yi,M.,Chen,S.,Liu,M.,Zhu,Z.,2024.Recognition andclassification ofmixed defectpatternwafermapbasedonmulti-path DCNN.IEEETrans.Semicond. Manuf. 37(3),316‚Äì328. https://doi.org/10.1109/TSM.2024.3418520. Hsu,C.Y.,Chen,W.J.,Chien,J.C.,2020.Similarity matching ofwaferbinmapsfor manufacturing intelligence toempower Industry3.5forsemiconductor manufacturing. Comput.Ind.Eng.142.https://doi.org/10.1016/j.cie.2020.106358. Hsu,S.C.,Chien,C.F.,2007.Hybriddataminingapproach forpatternextraction from waferbinmaptoimproveyieldinsemiconductor manufacturing. Int.J.Prod.Econ. 107(1),88‚Äì103.https://doi.org/10.1016/j.ijpe.2006.05.015. Hyun,Y.,Kim,H.,2020.Memory-augmented convolutional neuralnetworks withtriplet lossforimbalanced waferdefectpatternclassification. IEEETrans.Semicond. Manuf.33(4),622‚Äì634. https://doi.org/10.1109/TSM.2020.3010984. J√∫nior,P.R.M.,Boult,T.E.,Wainer,J.,&Rocha,A.(2016).Open-Set SupportVector Machines. https://doi.org/10.1109/TSMC.2021.3074496. Kang,H.,Kang,S.,2021.Astackingensemble classifierwithhandcrafted and convolutional featuresforwa"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_65", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 65, "text": ".,Wainer,J.,&Rocha,A.(2016).Open-Set SupportVector Machines. https://doi.org/10.1109/TSMC.2021.3074496. Kang,H.,Kang,S.,2021.Astackingensemble classifierwithhandcrafted and convolutional featuresforwafermappatternclassification. Comput.Ind.129. https://doi.org/10.1016/j.compind.2021.103450. Kim,E.S.,Choi,S.H.,Lee,D.H.,Kim,K.J.,Bae,Y.M.,Oh,Y.C.,2021.Anoversampling methodforwafermapdefectpatternclassification considering smalland imbalanced data.Comput.Ind.Eng.162.https://doi.org/10.1016/j. cie.2021.107767. Kim,M.,Tak,J.,Shin,J.,2023.Adeeplearningmodelforwaferdefectmap classification: perspective onclassification performance andcomputational volume. Phys.StatusSolidi(B)BasicRes.https://doi.org/10.1002/pssb.202300113.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 17 Kim,T.,Behdinan, K.,2023.Advances inmachinelearninganddeeplearning applications towardswafermapdefectrecognition andclassification: areview.In:In JournalofIntelligent Manufacturing, 34.Springer, pp.3215‚Äì3247. https://doi.org/ 10.1007/s10845-022-01994-1. Kyeong,K.,Kim,H.,2018.Classification ofmixed-type defectpatternsinwaferbinmaps usingconvolutional neuralnetworks. IEEETrans.Semicond. Manuf.31(3), 395‚Äì402. https://"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_66", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 66, "text": "oi.org/ 10.1007/s10845-022-01994-1. Kyeong,K.,Kim,H.,2018.Classification ofmixed-type defectpatternsinwaferbinmaps usingconvolutional neuralnetworks. IEEETrans.Semicond. Manuf.31(3), 395‚Äì402. https://doi.org/10.1109/TSM.2018.2841416. Lee,H.,Kim,H.,2020.Semi-supervised multi-label learningforclassification ofwafer binmapswithmixed-type defectpatterns.IEEETrans.Semicond. Manuf.33(4), 653‚Äì662. https://doi.org/10.1109/TSM.2020.3027431. Lee,J.H.,Moon,I.C.,Oh,R.,2021.Similarity searchonwaferbinmapthrough nonparametric andhierarchical clustering. IEEETrans.Semicond. Manuf.https:// doi.org/10.1109/TSM.2021.3102679. Liao,C.S.,Hsieh,T.J.,Huang,Y.S.,Chien,C.F.,2014.Similarity searching fordefective waferbinmapsinsemiconductor manufacturing. IEEETrans.Autom.Sci.Eng.11 (3),953‚Äì960. https://doi.org/10.1109/TASE.2013.2277603. Mahdavi, A.,&Carvalho, M.(2021).ASurveyonOpenSetRecognition. Proceedings - 2021IEEE4thInternational Conference onArtificial Intelligence andKnowledge Engineering, AIKE2021,37‚Äì44.https://doi.org/10.1109/AIKE52691.2021.00013. Nag,S.,Makwana, D.,R,S.C.T.,Mittal,S.,Mohan,C.K.,2022.WaferSegClassNet -A light-weight networkforclassification andsegmentation ofsemiconductor wafer def"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_67", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 67, "text": ".https://doi.org/10.1109/AIKE52691.2021.00013. Nag,S.,Makwana, D.,R,S.C.T.,Mittal,S.,Mohan,C.K.,2022.WaferSegClassNet -A light-weight networkforclassification andsegmentation ofsemiconductor wafer defects.Comput.Ind.142.https://doi.org/10.1016/j.compind.2022.103720. Nakazawa, T.,Kulkarni, D.V.,2018.Wafermapdefectpatternclassification andimage retrievalusingconvolutional neuralnetwork. IEEETrans.Semicond. Manuf.31(2), 309‚Äì314. https://doi.org/10.1109/TSM.2018.2795466. Nakazawa, T.,Kulkarni, D.V.,2019.Anomaly detection andsegmentation forwafer defectpatternsusingdeepconvolutional encoder-decoder neuralnetwork architectures insemiconductor manufacturing. IEEETrans.Semicond. Manuf.32 (2),250‚Äì256. https://doi.org/10.1109/TSM.2019.2897690. Nguyen,A.,Yosinski, J.,&Clune,J.(2015).DeepNeuralNetworks areEasilyFooled: HighConfidence Predictions forUnrecognizable Images.https://doi.org/https:// doi.org/10.48550/arXiv.1412.1897. Piao,M.,Jin,C.H.,Lee,J.Y.,Byun,J.Y.,2018.Decisiontreeensemble-based wafermap failurepatternrecognition basedonradontransform-based features.IEEETrans. Semicond. Manuf.31(2),250‚Äì257. https://doi.org/10.1109/TSM.2018.2806931. Pourpanah, F.,Abdar,M.,Luo,Y.,Zhou,X.,Wang,R.,"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_68", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 68, "text": "fermap failurepatternrecognition basedonradontransform-based features.IEEETrans. Semicond. Manuf.31(2),250‚Äì257. https://doi.org/10.1109/TSM.2018.2806931. Pourpanah, F.,Abdar,M.,Luo,Y.,Zhou,X.,Wang,R.,Lim,C.P.,Wang,X.-Z.,&Wu,Q. M.J.(2020).AReviewofGeneralized Zero-Shot LearningMethods. https://doi.org/ 10.1109/TPAMI.2022.3191696.Saqlain,M.,Jargalsaikhan, B.,Lee,J.Y.,2019.Avotingensemble classifierforwafermap defectpatternsidentification insemiconductor manufacturing. IEEETrans. Semicond. Manuf.32(2),171‚Äì182. https://doi.org/10.1109/TSM.2019.2904306. Shim,J.,Kang,S.,Cho,S.,2020.Activelearningofconvolutional neuralnetworkfor cost-effective wafermappatternclassification. IEEETrans.Semicond. Manuf.33(2), 258‚Äì266. https://doi.org/10.1109/TSM.2020.2974867. Shinde,P.P.,Pai,P.P.,Adiga,S.P.,2022.Waferdefectlocalization andclassification usingdeeplearningtechniques. IEEEAccess10,39969‚Äì39974. https://doi.org/ 10.1109/ACCESS.2022.3166512. Wu,M.J.,Jang,J.S.R.,Chen,J.L.,2015.Wafermapfailurepatternrecognition and similarity rankingforlarge-scale datasets.IEEETrans.Semicond. Manuf.28(1), 1‚Äì12.https://doi.org/10.1109/TSM.2014.2364237. Xu,Q.,Yu,N.,Essaf,F.,2022.Improved wafermapinspection usingattent"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_69", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 69, "text": "ognition and similarity rankingforlarge-scale datasets.IEEETrans.Semicond. Manuf.28(1), 1‚Äì12.https://doi.org/10.1109/TSM.2014.2364237. Xu,Q.,Yu,N.,Essaf,F.,2022.Improved wafermapinspection usingattention mechanism andcosinenormalization. Machines 10(2).https://doi.org/10.3390/ machines10020146. Yu,J.,Liu,J.,2021.Two-dimensional principalcomponent analysis-based convolutional autoencoder forwafermapdefectdetection. IEEETrans.Ind.Electron. 68(9), 8789‚Äì8797. https://doi.org/10.1109/TIE.2020.3013492. Yu,J.,Lu,X.,2016.WaferMapDefectDetection andRecognition UsingJointLocaland NonlocalLinearDiscriminant Analysis.IEEETrans.Semicond. Manuf.29(1),33‚Äì43. https://doi.org/10.1109/TSM.2015.2497264. Yu,N.,Xu,Q.,Wang,H.,2019.Waferdefectpatternrecognition andanalysisbasedon convolutional neuralnetwork. IEEETrans.Semicond. Manuf.32(4),566‚Äì573. https://doi.org/10.1109/TSM.2019.2937793. Yue,Z.,Wang,T.,Sun,Q.,Hua,X.S.,Zhang,H.,2021.Counterfactual zero-shot and open-setvisualrecognition. Proc.IEEE/CVF Conf.Comput.Vis.PatternRecognit. 15404‚Äì15414. Zhang,X.,Jiang,Z.,Yang,H.,Mo,Y.,Zhou,L.,Zhang,Y.,Li,J.,Wei,S.,2024. DMWMNet: Anoveldual-branch multi-level convolutional networkforhigh- performance mixed-type"}
{"id": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf::chunk_70", "source": "Enhanced detection of unknown defect patterns on wafer bin maps.pdf", "chunk_index": 70, "text": "Comput.Vis.PatternRecognit. 15404‚Äì15414. Zhang,X.,Jiang,Z.,Yang,H.,Mo,Y.,Zhou,L.,Zhang,Y.,Li,J.,Wei,S.,2024. DMWMNet: Anoveldual-branch multi-level convolutional networkforhigh- performance mixed-type wafermapdefectdetection insemiconductor manufacturing. Comput.Ind.161.https://doi.org/10.1016/j. compind.2024.104136. Zhu,F.,Yang,J.,Gao,C.,Xu,S.,Ye,N.,Yin,T.,2016.Aweighted one-class support vectormachine. Neurocomputing 189,1‚Äì10.https://doi.org/10.1016/j. neucom.2015.10.097. Zhu,J.,Liu,J.,Xu,T.,Yuan,S.,Zhang,Z.,Jiang,H.,Gu,H.,Zhou,R.,Liu,S.,2022. Opticalwaferdefectinspection atthe10nmtechnology nodeandbeyond.In:In International JournalofExtremeManufacturing, 4.InstituteofPhysics.https://doi. org/10.1088/2631-7990/ac64d7.J.-S.Shinetal. Computers in Industry 164 (2025) 104208 18"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_0", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 0, "text": "Int. J. Production Economics 107 (2007) 88‚Äì103 Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing Shao-Chung Hsu, Chen-Fu Chien/C3 Department of Industrial Engineering & Engineering Management, National Tsing Hua University, Hsinchu 30043, Taiwan, ROC Received 16 September 2005; accepted 25 May 2006 Available online 4 December 2006 Abstract Semiconductor manufacturing involves lengthy and complex processes, and hence is capital intensive. Companies compete with each other by continuously employing new technologies, increasing yield, and reducing costs. Yield improvement is increasingly important as advanced fabrication technologies are complicated and interrelated. In particular, wafer bin maps (WBM) that present speciÔ¨Åc failure patterns provide crucial information to track the processproblems in semiconductor manufacturing, yet most fabrication facility (fabs) rely on experienced engineers‚Äô judgments ofthe map patterns through eye-ball analysis. Thus, existing studies are subjective, time consuming, and are also restricted by the capability of human recognition. This study proposes a hybrid data mining approach tha"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_1", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 1, "text": " through eye-ball analysis. Thus, existing studies are subjective, time consuming, and are also restricted by the capability of human recognition. This study proposes a hybrid data mining approach that integrates spatial statistics and adaptive resonance theory neural networks to quickly extract patterns from WBM and associate with manufacturingdefects. An empirical study of WBM clustering was conducted in a fab for validation. The results showed practical viability of the proposed approach and now an expert system embedded with the developed algorithm has been implemented in a fab in Taiwan. This study concludes with a discussion on further research.r2006 Elsevier B.V. All rights reserved. Keywords: Data mining; Yield improvement; Wafer bin map; Spatial randomness test; ART1; Neural networks; Semiconductor manufacturing; Quality engineering 1. Introduction The semiconductor manufacturing processes are lengthy and complex. Thus, the capital investments in the semiconductor industry are huge. Themanufacturing usually contains 100‚Äì200 processsteps, in which the wafers move from step to step ingroups of 25 or 24 identical wafers in a fabricationfacility (fab). After wafer fabrication,"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_2", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 2, "text": " huge. Themanufacturing usually contains 100‚Äì200 processsteps, in which the wafers move from step to step ingroups of 25 or 24 identical wafers in a fabricationfacility (fab). After wafer fabrication, circuit probe(CP) testing is performed on each die on the wafer. Then, the wafers are died up, and the good dies arepackaged into chips and shipped to the customer after Ô¨Ånal testing (FT). The critical factors maintaining competitive advantages for semiconductor wafer fabs includelowering die costs via lean production and increas-ing yield via quick response to yield excursions(Leachman and Hodges, 1996 ;Peng and Chien, 2003). In particular, the defect problems should be detected in time and the assignable causes should then be resolved to reduce the loss of hundreds of thousands of dollars of scraped wafers as soon asARTICLE IN PRESS www.elsevier.com/locate/ijpe 0925-5273/$ - see front matter r2006 Elsevier B.V. All rights reserved. doi:10.1016/j.ijpe.2006.05.015/C3Corresponding author. Tel.: +886 3 5742648; fax: +886 3 5722685. E-mail address: cfchien@mx.nthu.edu.tw (C.-F. Chien). possible. Four yield deÔ¨Ånitions are used in semi- conductor manufacturing: CP test yield (CP yield, YCP"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_3", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 3, "text": "Tel.: +886 3 5742648; fax: +886 3 5722685. E-mail address: cfchien@mx.nthu.edu.tw (C.-F. Chien). possible. Four yield deÔ¨Ånitions are used in semi- conductor manufacturing: CP test yield (CP yield, YCP), fabrication line yield ( YL), assembly yield (YAS) and Ô¨Ånal test yield ( YFT). Among them, the CP yield is the most critical ( Cunningham et al., 1995). CP yield improvement is divided into two major categories: (1) based line yield improvement,and (2) low yield trouble shooting. The based lineyield improvement is based on tuning the processrecipes to improve device performance and reduce defects, while low yield trouble shooting involves monitoring and diagnosing the failures caused byabnormal events such as mis-operation, trouble tooland contamination. Wafer bin map (WBM) is theresult of CP inspection of dies on the wafer at theend of fabrication. WBM patterns can provideinformation to monitor the process and product. This study aims to develop a hybrid data mining approach that integrates spatial statistics and adap- tive resonance theory (ART) neural networks torapidly extract patterns from WBM and associatethem with manufacturing defects. An empirical studyof WBM clustering was"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_4", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 4, "text": "rates spatial statistics and adap- tive resonance theory (ART) neural networks torapidly extract patterns from WBM and associatethem with manufacturing defects. An empirical studyof WBM clustering was conducted in a fab forvalidation. Mining large amounts of data can helpthe engineers make the right decision of classifyingpatterns. During the manufacturing process, data are collected for various purposes. In particular, Wafer In Process (WIP) data refers to the data collectedwhile processing wafers; metrology data refers to thedata collected from in-line inspections; electrical test(E-test) data refers to data collected to measuredevice performance in chips, and the CP test datarecords each chip‚Äô functional test result after waferfabrication. Since modern fabs are equipped with the computer integrated manufacturing (CIM) system, data collection is no longer a major issue. Further-more, an engineering data analysis (EDA) systemthat is an off-line analysis-oriented system with data warehouse is generally developed to support data analysis activities ( Peng and Chien, 2003 ;Chien et al., 2007 ). A remaining issue is to sieve out relevant data from a massive pool to derived useful info"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_5", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 5, "text": "ouse is generally developed to support data analysis activities ( Peng and Chien, 2003 ;Chien et al., 2007 ). A remaining issue is to sieve out relevant data from a massive pool to derived useful informa-tion that can assist engineers in timely troubleshooting and yield enhancement. WBMs are multi-dimensional and have complex structures, can provide essential information forengineers to identify problems in the manufacturing process. Fig. 1 shows a typical WBM where the different symbols denote chips failing in differentfunctional tests. To assist visualization and analysis,WBM is usually transformed into a binary map thatrepresents it using binary code or two differentcolors. This study uses yellow squares or ‚Äò‚Äò1‚Äô‚Äô todenote defective chips, and red squares or ‚Äò‚Äò0‚Äô‚Äô todenote functional chips. The failure patterns of WBM can be classiÔ¨Åed into three major categories ( Taam and Hamada, 1993;Stapper, 2000 ): (1) Random defect: No spatial clustering or pattern exists, and the defective chips are randomlydistributed in the two-dimensional map. Ran-dom defects are usually caused by the manu-facturing environmental factors. Even in a in anear-sterile environment, particles cannot beremoved"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_6", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 6, "text": "s are randomlydistributed in the two-dimensional map. Ran-dom defects are usually caused by the manu-facturing environmental factors. Even in a in anear-sterile environment, particles cannot beremoved completely. However, reducing the level of random defects can improve the overall productivity of wafer fabrication. (2) Systematic defect: The positions of defective chips in the wafer show the spatial correlation,for example, ring, edge-fail, checkerboard.Fig. 2 shows 10 systematic patterns that are frequently seen in fab, as deÔ¨Åned by domainexperts.ARTICLE IN PRESS ab Fig. 1. Example of WBM: (a) WBM with each failure bin denoted by a different symbol; (b) WBM with speciÔ¨Åc bin denoted by the symbol ‚Äò‚Äò%‚Äô‚Äô.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 89 (3) Mixed defect: Consisting of a random defect and a systematic defect in one map. Most wafermaps are of this type, as shown in Fig. 3 . Engineer needs to separate random and sys-tematic defects in the WBM, since the systematicdefect‚Äôs signature can reveal the process problem (Friedman et al., 1997 ). The rest of this study is organized as follows: Section 2 formulates the WBM clustering problemsin yield imp"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_7", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 7, "text": "e the systematicdefect‚Äôs signature can reveal the process problem (Friedman et al., 1997 ). The rest of this study is organized as follows: Section 2 formulates the WBM clustering problemsin yield improvement and reviews related studies.Section 3 outlines the proposed approaches. Section4 details a research framework for pattern extrac- tion from WBM. Section 5 describes an empirical study for validation. Finally, Section 6 concludesthis study with discussing the results and the direction of future research. 2. Problem formulation This study addresses the problem of Ô¨Ånding patterns from WBMs to monitor semiconductor manufacturing process and provide pattern infor- mation for trouble shooting. Engineers have tointegrate and analyze large amounts of data duringanalysis. Data mining can efÔ¨Åciently Ô¨Ånd hidden yetpotentially valuable information in terms of speciÔ¨Åcpatterns from massive data ( Keki et al., 1993 ; Kusiak, 2000 ;Peng et al., 2004 ). Several studies have applied data mining techniques to solve manufacturing and yield problems. For example, the decision tree method can be used to identify thefaulty equipment and the corresponding dates offailure ( Bergeret and Gall, 2003 ;Br"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_8", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 8, "text": "hniques to solve manufacturing and yield problems. For example, the decision tree method can be used to identify thefaulty equipment and the corresponding dates offailure ( Bergeret and Gall, 2003 ;Braha and Shmilovici, 2002, 2003 ;Chien et al., 2007 ). Self- Organization Map (SOM) clustering has beenapplied to cluster E-test, CP fail bins and metro-logy data to detect the failure patterns ( Chien et al., 2003 ). In addition, Braha and Shmilovici (2003) apply three classiÔ¨Åcation-based data miningARTICLE IN PRESS Systematic Random Mixed Type Fig. 3. Mixed defect map.ab c d ef ijgh Fig. 2. Systematic defect patterns in semiconductor manufacturing.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 90 methods (decision tree induction, neural networks, and composite classiÔ¨Åers) to reÔ¨Åne dry-cleaning technology for process improvement. However, few studies have been conducted to develop WBM clustering methods, though WBMspatial patterns contain useful information aboutpotential manufacturing problems. For example,mask misalignment in the lithographic processgenerates a checkerboard pattern; the abnormaltemperature control in the rapid thermal annealing process (RTP) "}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_9", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 9, "text": "tential manufacturing problems. For example,mask misalignment in the lithographic processgenerates a checkerboard pattern; the abnormaltemperature control in the rapid thermal annealing process (RTP) can generate a ring of failing chips around the edge of the wafer. By reviewing WBMpatterns, experienced engineers can quickly clarifythe root causes and identify the assignable causes.Most existing studies focus on diagnosing systema-tic defects or patterns in wafer maps ( Mallory et al., 1983;Hansen and Nair, 1995 ;Kaempf, 1995 ; Friedman et al., 1997 ), but give no information about pattern types. The lack of adequate tools has also led engineers to only use data relating to simple measures such asoverall yield to track process problems. Experiencedengineers review the WBM to possibly identifyspatial patterns with only visual analysis based onprinted maps. Furthermore, most effort in existinganalysis is devoted to data integration from testers and manufacturing process. The existing practice based on human judgments causes low analysisefÔ¨Åciency and the results varied among the expertssince they had different mental models. 3. Fundamental 3.1. Spatial randomness test The spatial corr"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_10", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 10, "text": "ctice based on human judgments causes low analysisefÔ¨Åciency and the results varied among the expertssince they had different mental models. 3. Fundamental 3.1. Spatial randomness test The spatial correlation of two groups of data can be tested by the odd ratio hypothesis test ( Agresti, 1990;Taam and Hamada, 1993 ). The revised estimator is as Eq. (1). ^y¬º √∞NGG√æ0:5√û√∞NBB√æ0:5√û √∞NGB√æ0:5√û√∞NBG√æ0:5√û. (1) In Eq. (1), NGG,NBB,NBGand NGBare deÔ¨Åned as the counts of relations of adjacent chips in thetwo-way contingency table, as described in Table 1 . The relation is deÔ¨Åned by the King‚ÄìMove neigh-borhood in two-dimensional space as describedinFig. 4 . LetY irepresents the CP test result of chip in the position iof map. If Yi¬º1, then the chip in position ifails in the CP test; conversely, Yi¬º0 means the chip passes the CP test. Then, NGG,NBB,NBGandNGBcan be calculated as follows: NGG¬ºXX iojdij√∞1/C0Yi√û√∞1/C0Yj√û; (2) NGB¬ºXX iojdij√∞1/C0Yi√ûYj, (3) NBG¬ºXX iojdijYi√∞1/C0Yj√û, (4) NBB¬ºXX iojdijYiYj, (5) where dij1i f YiandYjare in King /C0Move neightbor ; 0 otherwise ;( The steps of spatial randomness testing are described as follows: Step 1: Establish hypotheses: Two alternative hypotheses are built fo"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_11", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 11, "text": "re dij1i f YiandYjare in King /C0Move neightbor ; 0 otherwise ;( The steps of spatial randomness testing are described as follows: Step 1: Establish hypotheses: Two alternative hypotheses are built for the spatial randomness test. /C15H0: The distribution of failure chips or goodchips in the wafer is spatially random.ARTICLE IN PRESS Table 1 Two-way contingency table of adjacent chips Position i Position j Good Bad Good NGG NGB Bad NBG NBB Fig. 4. King‚ÄìMove neighborhood.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 91 /C15H1: The distribution is not spatially random and the map exhibits special clusters of fail chips or repeat patterns. Step 2: Select the test statistics: When the sample size is large, the distribution of estimator, log ^yis asymptotic to normal distribution with the parameters ( m,s),where m¬º0, and s¬º 1 NGG√æ0:5√æ1 NBB√æ0:5√æ1 NGB√æ0:5√æ1 NBG√æ0:5/C16/C171=2 Step 3: Test WBM with following rules: /C15Rule 1: If log ^y/C250, then the map is spatially random. /C15Rule 2: If log ^yb0, then the map shows special clusters. /C15Rule 3: If log ^y50, then the map shows a repeating pattern. 3.2. ART for map clustering The ART ( Carpenter and Grossberg, 1"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_12", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 12, "text": " random. /C15Rule 2: If log ^yb0, then the map shows special clusters. /C15Rule 3: If log ^y50, then the map shows a repeating pattern. 3.2. ART for map clustering The ART ( Carpenter and Grossberg, 1988 ; Freeman and Skapura, 1991 ) has been applied in many areas including pattern recognition andspatial analysis. ART derives fundamentally fromthe adaptive resonant feedback between two layersof neurons. To manage the variety input, ART hasthe following characteristics: (1) balance on stabilityand plasticity, (2) match and reset, and (3) balance on search and direct access. ART solves the stability‚Äìplasticity dilemma, which is caused bylearning new data leading to unstable conditionsand loss of data. Several algorithms are derivedfrom the original ART, including ART1 ( Carpenter and Grossberg, 1988 ), ART2 ( Carpenter and Grossberg, 1987 ), ART3 ( Carpenter and Grossberg, 1990), ARTMAP ( Carpenter et al., 1991 ), and Fuzzy ART ( Carpenter et al., 1991 ). This study employs the ART1 algorithm for WBM clustering, since the input data form a binary map. 3.3. Decision tree Decision tree can be used to extract models to describe important data classes or to predict futuredata trends. A d"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_13", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 13, "text": "rithm for WBM clustering, since the input data form a binary map. 3.3. Decision tree Decision tree can be used to extract models to describe important data classes or to predict futuredata trends. A decision tree is a Ô¨Çow-chart-like treestructure where the root at the top and the leaves atthe bottom. Through serial tests on the attributes of the root node containing the entire dataset, the branches representing the outcomes of the tests andthe leaves indicating the classes are thus con- structed. Each path from the root node to a leaf can be interpreted as a rule. Decision tree construction can be separated to three basic elements: Ô¨Årst, growing the tree; second,pruning the tree; third, extracting rules from thetree. Several algorithms have been developed toconstruct decision tree model. Chi-squared auto-matic interaction detection (CHAID) is a non-binary decision tree that determines the best multi- way partitions of the data on the basis of signiÔ¨Åcance tests ( Kass, 1980 ). CHAID is designed speciÔ¨Åcally to deal with categorical variables.classiÔ¨Åcation and regression tree (CART) is a binarydecision tree with the Gini-index of diversity as thesplitting criterion, and pruning by min"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_14", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 14, "text": "designed speciÔ¨Åcally to deal with categorical variables.classiÔ¨Åcation and regression tree (CART) is a binarydecision tree with the Gini-index of diversity as thesplitting criterion, and pruning by minimizing thetrue misclassiÔ¨Åcation error estimate ( Breiman et al., 1984). CART can deal with categorical and continuous variable. C4.5 is a variant and extension of a well-known decision tree algorithm, ID3(Quinlan, 1993 ). The splitting criterion of C4.5 algorithm is gain ratio that expresses the proportionon information generated by a split. The error-based pruning is used to C4.5 for pruning. Lim et al. (2000) compared the prediction accuracy, complex- ity and training time of 33 classiÔ¨Åcation algorithms, and indicated that decision tree provides good accuracy and data interpretation. 4. The research framework This study proposes a framework integrated with spatial statistics and ART1 network with domainknowledge to improve the efÔ¨Åciency of WBM clustering. Then, the extracted spatial patterns will be correlated with process data by applying decisiontree to identify the root causes. Fig. 5 illustrates the research framework. 4.1. Data pre-processing Before clustering, the WBM data are"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_15", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 15, "text": "terns will be correlated with process data by applying decisiontree to identify the root causes. Fig. 5 illustrates the research framework. 4.1. Data pre-processing Before clustering, the WBM data are pre-pro- cessed in three stages: data integration, data cleaning and data transformation. (1) Data integration: Engineers usually use a speciÔ¨Åc bin or combined multi-bins to query WBM data.Two options are available for integrating theWBM data: Analysis by wafer where each maprepresents a wafer, the other is analysis by lot where the map is generated from all wafers within the lot. Each map represents the integratedARTICLE IN PRESS S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 92 spatial result of a lot. In practice, engineers will try to correlate the spatial patterns with processdata, like tools, date and operator, yet withoutsystematic methodologies to support effective analyses. The data resolution of process data is usually with lot-based in 200 mm wafer fabs.Thus, the WBM data has to integrate fromwafers into lot-based map for data preparation tosupport analysis with the lot-based process data.In this study, we applied a threshold value totranslate the a"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_16", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 16, "text": ".Thus, the WBM data has to integrate fromwafers into lot-based map for data preparation tosupport analysis with the lot-based process data.In this study, we applied a threshold value totranslate the accumulated percentage by wafersinto binary data to represent the lot-based WBM. (2) Data cleaning: Missing data often arise in the WBM because the probe might not workcorrectly in some chips during the CP test. This study deletes missing data. Therefore, if aposition of has no test data in one map, thenthe data in this position in other maps are not included in the calculation. (3) Data transformation: The data are transformed into several formats for different purposes. Theproposed framework deÔ¨Ånes two formats to betransformed: (a) Binary map: Based on the selected bin, BIN i, the ‚Äò‚Äòbinary‚Äô‚Äô map is created using 1 to denotethe defective chips, and 0 to denote passing chips. The binary map is used for to visualize the chip, and to test for spatial randomness.ARTICLE IN PRESS Fig. 5. Research framework for WBM clustering.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 93 (b) Binary vector: Each WBM is converted from the two-dimensional map into an one- dimensiona"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_17", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 17, "text": "ch framework for WBM clustering.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 93 (b) Binary vector: Each WBM is converted from the two-dimensional map into an one- dimensional vector using the index map. The index map is deÔ¨Åned by coding theposition of each chip in the map with asequence sorted from left to right and top tobottom. Then, each map can be convertedinto a vector in terms of this sequence. Fig. 6 illustrates this transformation process. Thebinary vector is applied to generate the ART1 network. 4.2. Spatial randomness testing Each map is tested for spatial randomness testing and classiÔ¨Åed into three types: ‚Äò‚ÄòCheckerboardDefect‚Äô‚Äô, ‚Äò‚ÄòClustered Defect‚Äô‚Äô and ‚Äò‚ÄòRandom De-fect‚Äô‚Äô. The ‚Äò‚ÄòCheckerboard Defect‚Äô‚Äô (or ‚Äò‚ÄòRepeatingDefect‚Äô‚Äô) group can be further analyzed by beingdirectly correlated with the lithographic processdata. The ‚Äò‚ÄòClustered Defect‚Äô‚Äô maps are clustered using ART1. The ‚Äò‚ÄòRandom Defect‚Äô‚Äô maps are further classiÔ¨Åed by the WBM fail rate thatrepresents the degree of trouble in manufacturing.‚Äò‚ÄòRandom Defect‚Äô‚Äô maps are classiÔ¨Åed into threesub-groups: ‚Äò‚ÄòMinor Fail‚Äô‚Äô, ‚Äò‚ÄòModerate Fail‚Äô‚Äô and‚Äò‚ÄòSerious Fail‚Äô‚Äô. The maps in the ‚Äò‚ÄòModerateFail‚Äô‚Äô group a"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_18", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 18, "text": "esents the degree of trouble in manufacturing.‚Äò‚ÄòRandom Defect‚Äô‚Äô maps are classiÔ¨Åed into threesub-groups: ‚Äò‚ÄòMinor Fail‚Äô‚Äô, ‚Äò‚ÄòModerate Fail‚Äô‚Äô and‚Äò‚ÄòSerious Fail‚Äô‚Äô. The maps in the ‚Äò‚ÄòModerateFail‚Äô‚Äô group are also clustered by ART1 to ensurethat no information has been lost in pattern extraction, since the spatial randomness testing only tests the spatial independence between ‚Äò‚ÄòGood‚Äô‚Äôand ‚Äò‚ÄòBad‚Äô‚Äô chips, not the pattern itself. Addition-ally, the deÔ¨Ånition of ‚Äòneighborhood‚Äô affects the testresults.4.3. Enhance the signal and remove the noise To obtain good clustering results, we developed a data preparation procedure to enhance the signaland remove the noise (ESRN) as follows: First, the King‚ÄìMove neighborhood is applied to deÔ¨Åne the weighs of the adjacent chips. Thepositions on the four nearest neighbors (left, right,top and down) are weighted 1. The corner positionsare weighted 0.5. Second, two rules are applied to each chip in the map. For spatial randomness testing, Y iis deÔ¨Åned as the CP test result of the chip in the position iof the map. If Yi¬º1, then the chip in position ifails the CP test; while Yi¬º0 indicates that the chip passes the CP test. For a given position i, let Ni√æ¬ºXn j¬º"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_19", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 19, "text": "test result of the chip in the position iof the map. If Yi¬º1, then the chip in position ifails the CP test; while Yi¬º0 indicates that the chip passes the CP test. For a given position i, let Ni√æ¬ºXn j¬º1dij√∞1/C0Yi√ûYj, (6) Ni/C0¬ºXn j¬º1dijYi√∞1/C0Yj√û, (7) where dij¬º1i f YiandYjare in King /C0Move neightbor ; 0 otherwise :/C26 Rule 1: If Yi¬º0 and Ni√æ4r1;then Yi¬º1 (en- hance signal). Rule 2: If Yi¬º1 and Ni/C04r2;then Yi¬º0 (re- move noise),where r 1andr2represent the threshold value of enhancing signal and removing noise.ARTICLE IN PRESS 123 45678 91 01 11 21 31 41 5 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64010 10110 1100010 010111100 111 1 1 0 0 1101 1 100000 10000011 101100 01010 101 Binary Map IndexMap (By Product) Codi n g Progra m [0,1,0,1,0,1,1,0,1,1,0,0,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,0‚Ä¶]123 45678 91 01 11 21 31 41 5 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64010 10110 1100010 010111100 11 111001 1 01 1100000 10000011 101100 01010 101 Coding Program Fig. 6. Tra"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_20", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 20, "text": "2 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64010 10110 1100010 010111100 11 111001 1 01 1100000 10000011 101100 01010 101 Coding Program Fig. 6. Transfer map data (2D) format into vector (1D).S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 94 Fig. 7 illustrates two rules applied to chips in a King‚ÄìMove neighborhood. An experiment withdifferent r 1andr2setting was performed to identify which types of signals are enhanced and which aredegraded. We select three frequent-seen patternsand one composite pattern for ESRN test. Thesetting of r 1changes from 4 to 5, while r2changesfrom 5 to 6. Fig. 8 displays the experiment result of ESRN. As shown in the results, some random defective chips have been removed from original maps of the ‚Äò‚ÄòRight-Down Edge‚Äô‚Äô pattern and‚Äò‚ÄòComposite‚Äô‚Äô pattern and the rule 2 has enhancedthe pattern in the maps of these patterns. However,the pattern with ‚Äò‚ÄòCheckerboard‚Äô‚Äô defect that iscaused by mask defects is totally destroyed and the‚Äò‚ÄòRing‚Äô‚Äô defect is affected by the setting of thresholdvalue. These results are due to the King‚ÄìCross neighbor can handle the blocked pattern more effectively"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_21", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 21, "text": " mask defects is totally destroyed and the‚Äò‚ÄòRing‚Äô‚Äô defect is affected by the setting of thresholdvalue. These results are due to the King‚ÄìCross neighbor can handle the blocked pattern more effectively. To solve this issue, we apply the spatialrandomness testing before ESRN to separate the‚Äò‚ÄòCheckerboard‚Äô‚Äô defect from others in our proposedframework. For the ‚Äò‚ÄòRing‚Äô‚Äô defect, we set theARTICLE IN PRESS b a Fig. 7. ESRN graph of a chip: (a) Enhance signals; (b) Remove the noise. Pattern Checkerboard Ring Right-Down Edge Composite PatternOriginal MapESRN (œÅ1=4, œÅ2=6)ESRN (œÅ1=4, œÅ2=5)ESRN (œÅ1=5, œÅ2=6)ESRN (œÅ1=5, œÅ2=5) Fig. 8. Comparison of maps before and after ESRN with different threshold settings.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 95 threshold value of r1andr2to 4 and 6, respectively, in our algorithm, which are better setting in the experiment. 4.4. Map clustering The objective of map clustering is to maximize the spatial similarity within clusters and minimize thenumber of clusters. This study applies the ART1method to cluster the similar maps. The other objective is to extract the common pattern from each cluster. The common pattern is deÔ¨Åned as"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_22", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 22, "text": "d minimize thenumber of clusters. This study applies the ART1method to cluster the similar maps. The other objective is to extract the common pattern from each cluster. The common pattern is deÔ¨Åned as theintersection of maps within a cluster. With thisinformation, engineers do not need to examine thepatterns map by map, and can correlate the patternswith the speciÔ¨Åc process problem mentioned inSection 2. Two groups of maps are clustered byART1 after spatial randomness testing: the ‚Äò‚ÄòClus- tered Defect‚Äô‚Äô group and the ‚Äò‚ÄòModerate Fail‚Äô‚Äô sub- group of ‚Äò‚ÄòRandom Fail‚Äô‚Äô. 4.5. Merger pattern The patterns that are generated from the ‚Äò‚ÄòClus- tered Defect‚Äô‚Äô group and the ‚Äò‚ÄòModerate Fail‚Äô‚Äô groupare collected and clustered using ART1 to merge the patterns. This step serves two purposes: (1) to minimize the number of clusters as few as possiblesince many clusters make patterns hard to interpret,and (2) to integrate the patterns, since some maps inthe ‚Äò‚ÄòRandom Fail‚Äô‚Äô group may still have patterns ofspatial cluster, which may be similar to the‚Äò‚ÄòClustered Defect‚Äô‚Äô patterns. 4.6. Interpret results Engineers can select patterns to analyze further. For example, they can conduct correlation analysisto"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_23", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 23, "text": "spatial cluster, which may be similar to the‚Äò‚ÄòClustered Defect‚Äô‚Äô patterns. 4.6. Interpret results Engineers can select patterns to analyze further. For example, they can conduct correlation analysisto correlate the special patterns with the processinformation. If the result is unacceptable, engineerscan return to the steps of Map Clustering or MergePattern to adjust the parameters in the framework to generate a new result. 4.7. Root cause identiÔ¨Åcation The step of root cause identiÔ¨Åcation is employed to identify the suspected process tools or periodsthat cause the fault or abnormal pattern of selectedcomponent. ClassiÔ¨Åcation techniques, i.e., decision tree, are applied to clarify the relations of the selected component to clarify the relations andrelated process information systematically. The Ô¨Årst step is to integrate these data together and transfer into a new variable with two categories, ‚Äò‚ÄòWith Pattern‚Äô‚Äô and ‚Äò‚ÄòWithout Pattern‚Äô‚Äô. This new variableis the target variable of decision tree. Then, therelated process data including tools, date, andoperator are used as the input for decision treeanalysis to identify the suspected process steps forfurther investigations. Finally, engine"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_24", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 24, "text": "ree. Then, therelated process data including tools, date, andoperator are used as the input for decision treeanalysis to identify the suspected process steps forfurther investigations. Finally, engineer can makejudgments on the suspected causes of extracted clustered WBMs. 4.8. A numerical example To demonstrate the effectiveness of the proposed framework, a case of 25 maps was generated fromseven groups with special patterns plus randomdefects (see Fig. 9 for some of the patterns). Each map contained 63 chips and the fail rate varied from 0% to 100%. (1) Spatial Randomness Testing: Table 2 sum- marizes the spatial randomness results. Threemaps were placed in the ‚Äò‚ÄòClustered Defect‚Äô‚Äôgroup with the criterion of p-valueo0.00005 (maps 8, 13 and 16). Three maps with negative log odd ratio and p-valueo0.05 were classiÔ¨Åed as the ‚Äò‚ÄòCheckerboard Defect‚Äô‚Äô (maps 2, 7 and18). Others were classiÔ¨Åed as ‚Äò‚ÄòRandom Defect‚Äô‚Äô,and were further classiÔ¨Åed into three sub-groupsby the fail rate. The ‚Äò‚ÄòMinor Fail‚Äô‚Äô sub-groupcomprised the maps with fail rate %5% (maps 4, 12 and 22), while the ‚Äò‚ÄòSerious Fail‚Äô‚Äô sub-grouphad fail rate ^95% (map 6, 17 and 21). The remaining maps (total 13 maps) were placed into"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_25", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 25, "text": "ail‚Äô‚Äô sub-groupcomprised the maps with fail rate %5% (maps 4, 12 and 22), while the ‚Äò‚ÄòSerious Fail‚Äô‚Äô sub-grouphad fail rate ^95% (map 6, 17 and 21). The remaining maps (total 13 maps) were placed into the ‚Äò‚ÄòModerate Fail‚Äô‚Äô group. Further examina-tion of the maps in the ‚Äò‚ÄòModerate Fail‚Äô‚Äô groupindicated 11 maps with two special patterns,‚Äò‚ÄòRing‚Äô‚Äô (maps 3, 5,10,11 and 14) and ‚Äò‚ÄòCompo-site‚Äô‚Äô(maps 9,15, 20, 24 and 25). The ART1clustering was applied to the ‚Äò‚ÄòModerate Fail‚Äô‚Äôgroup later. (2) Map Clustering: With the vigilance threshold, one cluster was extracted from the ‚Äò‚ÄòClusteredDefect‚Äô‚Äô group, and two were extracted from the‚Äò‚ÄòModerate Fail‚Äô‚Äô group. After merging thepatterns, the three groups had not changed.Fig. 10 summarizes the Ô¨Ånal results. Compar- ingFigs. 9 and 10 , shows that the maps with the special patterns deÔ¨Åned in Fig. 10 are in the same group after clustering. For example, the maps with ‚Äò‚ÄòRight-Down Edge‚Äô‚Äô pattern areARTICLE IN PRESS S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 96 clustered in the C1 group before and after clustering. The only mis-classiÔ¨Åed map is the18th map, which belongs to the ‚Äò‚ÄòComposite‚Äô‚Äôgroup but is classiÔ¨Åed into the ‚Äò‚ÄòCh"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_26", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 26, "text": " Economics 107 (2007) 88‚Äì103 96 clustered in the C1 group before and after clustering. The only mis-classiÔ¨Åed map is the18th map, which belongs to the ‚Äò‚ÄòComposite‚Äô‚Äôgroup but is classiÔ¨Åed into the ‚Äò‚ÄòCheckerboard‚Äô‚Äôcluster due to this map‚Äôs overall mis-classiÔ¨Åca-tion rate is 4% (1/25). Therefore, the clusteringresults using the proposed framework are fairlyconsistent with the true groups. 5. Empirical study For validation, an empirical study was conducted to verify the effectiveness of the proposed frame-work over conventional methods in a wafer fab. Thestudy used a product with high yield variation in CP testing over a period of 2 months. A total of 138 lots completed the CP test during this period.5.1. Data pre-processing The raw data were selected from database and transformed into 138 maps, each of which repre-sented an integrated result of lot accumulated bywafers within the lot. The original map consisted of301 chips, but 33 chips had at least one map withmissing data. Excluding these chips, the location of 268 chips was used for clustering and spatial randomness testing. 5.2. Spatial randomness testing After testing, 59 maps were found to have spatial correlation under signiÔ¨Åca"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_27", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 27, "text": "se chips, the location of 268 chips was used for clustering and spatial randomness testing. 5.2. Spatial randomness testing After testing, 59 maps were found to have spatial correlation under signiÔ¨Åcant level a¬º0.00005, and were placed in the ‚Äò‚ÄòClustered Defect‚Äô‚Äô group, while the other 79 maps were placed in the ‚Äò‚ÄòRandomARTICLE IN PRESS Group 2 (Right-Down Edge) Group 3 (Composite) Group 4 (Checkerboard) Group 5 (Minor Random) Group 6 (Serious Random)8 91 51 82 02 4 2 513 16 27 14 1 2 61 7 2 119 22 23 Fig. 9. Groups and patterns used to generate maps.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 97 Defect‚Äô‚Äô group. The ‚Äò‚ÄòRandom Defect‚Äô‚Äô group was divided into three sub-groups using the deÔ¨Ånition inSection 6. The ‚Äò‚ÄòMinor Defect‚Äô‚Äô group containedthree maps with fail rate %5%, while the ‚Äò‚ÄòSerious Defect‚Äô‚Äô contained eight maps with fail rate ^95%. The other maps (68 in total) were placed in the ‚Äò‚ÄòModerate Defect‚Äô‚Äô group. 5.3. Map clustering A total of 29 patterns were generated from the ‚Äò‚ÄòClustered Defect‚Äô‚Äô group with vigilance threshold.The same algorithm of ART1 clustering was alsoapplied to the ‚Äò‚ÄòModerate Defect‚Äô‚Äô group. A total of6 patterns (20 maps) were e"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_28", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 28, "text": "ere generated from the ‚Äò‚ÄòClustered Defect‚Äô‚Äô group with vigilance threshold.The same algorithm of ART1 clustering was alsoapplied to the ‚Äò‚ÄòModerate Defect‚Äô‚Äô group. A total of6 patterns (20 maps) were extracted from the‚Äò‚ÄòModerate Defect‚Äô‚Äô group. After merging thepatterns, 21 patterns were Ô¨Ånally obtained from 79 maps. After excluding the patterns with single map, there are 14 patterns with more than one mapwithin cluster. Fig. 11 presents the patterns with more than one map within cluster. 5.4. Result and discussion In summary, the WBM patterns from 138 maps were extracted and organized in several groups byusing the proposed framework. Fig. 12 summarizes the Ô¨Ånal results of this study. The results revealsome speciÔ¨Åc patterns deÔ¨Åned in Fig. 2 , such as the half-moon (P2), center (P8) and ring patterns (P11). However, some maps had apparent clusteringpatterns and were thus placed in the ‚Äò‚ÄòRandomDefect‚Äô‚Äô group with no special patterns, which wasdue to the vigilance threshold setting in the ART1network. The lower the vigilance threshold value,the more patterns are extracted from the maps.However, a low vigilance threshold value may also cause dissimilar maps to group in the same cluster."}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_29", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 29, "text": "ART1network. The lower the vigilance threshold value,the more patterns are extracted from the maps.However, a low vigilance threshold value may also cause dissimilar maps to group in the same cluster. To estimate the effectiveness of the proposed framework, nine senior integration engineers whoare domain experts for WBM analysis in thisempirical study were asked to cluster the 138WBMs by themselves. The results were recordedand the time to complete the clustering wasmeasured. Table 3 shows the summary of the WBM clustering result by testers. The results showed that most of the experts clustered the mapsinto 12‚Äì28 patterns and the identiÔ¨Åed maps withspatial patterns varied from 72 to 103. These resultsrevealed that the sensitivity of identifying patternsby experienced engineers is higher than our algo-rithm with the current setting of parameters. Inaddition, the cluster dissimilarity that measures the variability of tester‚Äôs clustering result to the result of our model is deÔ¨Åned as follows: For speciÔ¨Åc patterns such as ring, half-moon, and center defect, the engineers can easily cluster the maps together. That is, the maps with blockeddefective pattern can be easily grouped by bothh"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_30", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 30, "text": "ows: For speciÔ¨Åc patterns such as ring, half-moon, and center defect, the engineers can easily cluster the maps together. That is, the maps with blockeddefective pattern can be easily grouped by bothhuman and computer algorithm, while the un-blocked patterns were recognized from person toperson with high variation. As for the efÔ¨Åciency, the fastest engineer took 15.5 min to complete the clustering (9 patterns of 72 maps) and the time taken varied from 15 to 28 min, while the developed WBM clustering andARTICLE IN PRESS Table 2 Summary of spatial randomness testing of 25 maps IdNBBNGB NBG NGGLog OR Std. p-value Fail_rate (%) 1 0 20 18 175 /C01.464 1.452 0.15673 11 2 7 56 57 93 /C01.533 0.423 0.00015 19 3 18 48 44 103 /C00.120 0.327 0.35707 27 4 213 0 0 0 6.057 2.450 0.00672 0 5 21 42 45 105 0.160 0.319 0.30826 28 6 0 0 0 213 6.057 2.450 0.00672 1007 1 30 33 149 /C01.517 0.858 0.03856 17 8 33 40 19 121 1.640 0.338 0.00000 31 95 2 5 6 5 6 4 9 /C00.206 0.273 0.22577 50 10 13 35 34 131 0.371 0.373 0.15957 1811 23 44 47 99 0.101 0.310 0.37238 28 12 1 15 15 182 0.131 0.895 0.44203 6 13 51 38 16 108 2.174 0.339 0.00000 3714 19 41 41 112 0.242 0.329 0.23114 2515 46 57 54 56 /C00.176 0.274 0"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_31", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 31, "text": "1 0.373 0.15957 1811 23 44 47 99 0.101 0.310 0.37238 28 12 1 15 15 182 0.131 0.895 0.44203 6 13 51 38 16 108 2.174 0.339 0.00000 3714 19 41 41 112 0.242 0.329 0.23114 2515 46 57 54 56 /C00.176 0.274 0.25980 47 16 37 32 11 133 2.595 0.390 0.00000 30 17 189 12 12 0 /C00.500 1.471 0.36695 95 18 38 61 59 55 /C00.538 0.278 0.02631 45 19 1 11 10 191 0.867 0.924 0.17419 8 20 52 56 56 49 /C00.206 0.273 0.22577 50 21 190 11 12 0 /C00.412 1.474 0.39003 95 22 0 8 8 197 0.312 1.497 0.41732 3 23 2 20 18 173 0.134 0.713 0.42533 9 24 45 52 52 64 0.063 0.275 0.40972 4525 40 59 58 56 /C00.419 0.276 0.06443 45 Dissimilarity ¬º1/C0Max√∞#of matched map between tester0s cluster and selected cluster √û #of map of selected cluster. (8)S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 98 classiÔ¨Åcation system embedded with the developed hybrid algorithm only took 3 min to generate theresult (21 patterns of 79 maps). The algorithm wasexecuted on a PC with a Pentium 4 processor, with a2.4 GHz clock speed and 512 MB RAM. Further- more, the computational requirements of our proposed algorithm depend on the training para-meters. However, the computational complexity ofthe algorithm is essenti"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_32", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 32, "text": "clock speed and 512 MB RAM. Further- more, the computational requirements of our proposed algorithm depend on the training para-meters. However, the computational complexity ofthe algorithm is essentially O( gm), where gis the gross die number and mis the number of map. 5.5. Root cause analyses and identiÔ¨Åcation This study employed decision tree to identify root cause of speciÔ¨Åc patterns ( Chien et al., 2007 ). Inparticular, Patterns P1 and P2 were selected as the target variables, in which Pattern P1 contains 12maps and Pattern P2 contains 5 maps. Forcommonality analysis, we selected 10 lots from‚Äò‚ÄòMinor Defect‚Äô‚Äô group and ‚Äò‚ÄòModerate Defect‚Äô‚Äô group as the ‚Äò‚ÄòWithout Pattern‚Äô‚Äô category of target variable, where three lots from ‚Äò‚ÄòMinor Defect‚Äô‚Äôgroup and seven lots from ‚Äò‚ÄòModerate Defect‚Äô‚Äôgroup with top seven highest CP yield. A total of226 process steps with tool data of these lots areselected as the explained variables. For Pattern P1,the decision tree shows the ‚Äò‚ÄòADO_Photo‚Äô‚Äô step hasthe highest impact factor at the Ô¨Årst branch of derived decision tree by excluding the metrology and clean process steps, as shown in Fig. 13 . TheARTICLE IN PRESS C1 (Ring) C2 (Right-Down Edge) C3 (Comp"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_33", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 33, "text": " highest impact factor at the Ô¨Årst branch of derived decision tree by excluding the metrology and clean process steps, as shown in Fig. 13 . TheARTICLE IN PRESS C1 (Ring) C2 (Right-Down Edge) C3 (Composite) Checkerboard Minor Random Serious Random35 1 0 81 3 1 611 14 9 1 52 02 42 5 27 1 8 14 1 2 61 72 119 22 23 Fig. 10. Patterns extracted from 25 maps.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 99 branch of this tree reveals the higher percentage of lots that were processed by PHO_13 toolhad signiÔ¨Åcant P1 pattern than those processedby the other tools. This implies that the lotswith P1 pattern may be damaged by ‚Äò‚ÄòADO Photo‚Äô‚Äôstep and the suspected abnormal tool is ‚Äò‚ÄòPHO_13‚Äô‚Äô. The derived result was then presented to domain experts for interpretation. The process engineersfound that the PHO_13 tool did have abnormal events. Similarly, decision tree analysis was em-ployed for Pattern P2 and the result showedthe MTE_13 tool in ML1_Etch process caused thelots to have P2 failure pattern than those by theother tools, as shown in Fig. 14 . The domain experts who are process engineers have conÔ¨Årmed the results.ARTICLE IN PRESS Fig. 11. Partial pattern list after "}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_34", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 34, "text": "have P2 failure pattern than those by theother tools, as shown in Fig. 14 . The domain experts who are process engineers have conÔ¨Årmed the results.ARTICLE IN PRESS Fig. 11. Partial pattern list after merging patterns.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 100 5.6. Implement The results of the above empirical study show practical viability of the developed algorithm.Indeed, a WBM clustering and classiÔ¨Åcation(WBMCC) expert system embedded with the devel-oped algorithm has now been implemented in a fabin Taiwan. Through the developed WBMCC,engineers can directly query data, view maps,perform WBM clustering and view the results. Alternatively, engineers can also classify an un- known WBM into speciÔ¨Åc pattern group viaWBMCC. Furthermore, engineers can dynamically adjust the ART1 parameters to see the change in result. The system also permits merging patterns by ART1 clustering or by manually selecting severalpatterns. The clustering results can also link todecision tree analysis to correlate with process toolsautomatically. 6. Conclusions This study presented a hybrid algorithm that integrates spatial statistics and ART1 neuralARTICLE IN PRESS Table 3 WB"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_35", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 35, "text": "ecision tree analysis to correlate with process toolsautomatically. 6. Conclusions This study presented a hybrid algorithm that integrates spatial statistics and ART1 neuralARTICLE IN PRESS Table 3 WBM clustering result by nine domain experts Pattern dissimilarity Domain experts Statistics ]1 ]2 ]3 ]4 ]5 ]6 ]7 ]8 ]9 Mean SD P1 0.58 0.58 0.08 0.17 0.42 0.67 0.58 0.25 0.67 0.44 0.22 P2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 P3 0.00 0.00 0.00 1.00 0.00 0.50 0.00 0.00 0.00 0.17 0.35P4 0.25 0.00 0.00 0.25 0.50 1.00 0.25 0.00 0.00 0.25 0.33P5 0.00 0.00 0.00 0.25 0.00 1.00 0.25 0.00 0.00 0.17 0.33 P6 0.25 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.25 0.44 0.11 P7 0.00 0.00 0.00 0.00 0.33 1.00 1.00 0.00 0.00 0.26 0.43P8 0.00 0.00 0.00 0.00 0.67 0.67 0.00 0.00 0.00 0.15 0.30P9 0.00 0.00 1.00 0.00 1.00 1.00 0.00 0.00 0.00 0.33 0.50 P10 0.00 1.00 0.00 1.00 1.00 1.00 0.00 0.00 0.00 0.44 0.53 P11 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00P12 0.00 0.00 0.00 0.50 0.50 0.00 0.00 0.00 0.00 0.11 0.22P13 0.00 0.00 0.00 1.00 0.00 1.00 1.00 1.00 0.00 0.44 0.53 P14 1.00 0.00 0.00 1.00 1.00 1.00 1.00 1.00 0.00 0.67 0.50 ]of Patterns 11 11 17 24 16 18 21 9 13 15.6 5.00 ]of maps with "}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_36", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 36, "text": "0.00 0.00 0.11 0.22P13 0.00 0.00 0.00 1.00 0.00 1.00 1.00 1.00 0.00 0.44 0.53 P14 1.00 0.00 0.00 1.00 1.00 1.00 1.00 1.00 0.00 0.67 0.50 ]of Patterns 11 11 17 24 16 18 21 9 13 15.6 5.00 ]of maps with Patterns 91 79 75 79 103 91 99 72 86 86.1 10.74 Time (min) 20.0 22.8 22.5 20.5 23.0 23.8 26.5 15.5 28.5 22.6 22.85Moderate 4879 68 3Minor Defect8Defect Serious DefectDefectART1 ClusteringSpatial Randomness TestingSpecial Patterns 79 (21 patterns)Clustered Defect 7959 68 38ModerateART1 Clustering 20(6 patterns)59 (23 patterns) 138 maps Random DefectART1 ClusteringClustered Defect ART1 Special Patterns Fig. 12. Summary of clustering results of empirical data.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 101 networks to automatically extract patterns from WBM. The framework can identify the maps withspatial correlation using the spatial randomnesstesting. Furthermore, the patterns can be speciÔ¨Åedby the ART1 clustering method and extended to link with trouble shooting procedure to provide useful information to support yield improvementdecisions and activities in modern fabs. An empiri-cal study showed that the proposed framework caneffectively improve the efÔ¨Åcienc"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_37", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 37, "text": " procedure to provide useful information to support yield improvementdecisions and activities in modern fabs. An empiri-cal study showed that the proposed framework caneffectively improve the efÔ¨Åciency of WBM cluster-ing, save WBM clustering time consistently andprovide the essential information for root causesanalysis. However, the proposed framework that employed ART1 as the clustering method can handle onlybinary map. Other clustering methods such as ART2 can be applied in the framework forclustering the data with continuous type in thefuture study. We found that the parameter settingsin ESRN and ART1 are sensitive to our framework. For example, the number of clusters extracted in the input maps by ART1 is sensitive to the vigilanceparameter. Thus, further studies are needed to Ô¨Åne-tune the parameters in various contexts to increasethe effectiveness of WBM clustering. In addition,some systematic patterns such as ring pattern aredifÔ¨Åcult to detect them by neither spatial random-ness testing nor ART. Further research is needed to develop different methodologies to effectively iden- tify speciÔ¨Åc WBM patterns.ARTICLE IN PRESS All Data 9 - 9-50.050.056.660.060.071.484.6 45.7 ZER WET "}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_38", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 38, "text": "testing nor ART. Further research is needed to develop different methodologies to effectively iden- tify speciÔ¨Åc WBM patterns.ARTICLE IN PRESS All Data 9 - 9-50.050.056.660.060.071.484.6 45.7 ZER WET STRIPAll Data 12 12 24 50% 50% 100% PHO_05 PHO_11 3 12 15 20% 80% 100%PHO_13 100% 100%AOD PHOTOName Global Impact PL2 WETSTRIP SPR CLN STI CMP CLN AOD PHOTO CO1 DRY STRIP STI DRY STRIP SPR ASHING ONO DRY ETCH CO1 SPR ETCH ILD BPSG FLOW PL4 BARC ETCH PL2 PHOTO 41.241.241.241.7 WL SPR ETCH 41.244.4 Fig. 13. Commonality analysis result of P1 pattern. -- --PL1 LIN-OX CLN 59.559.559.559.559.559.5All Data 5 12 17 29% 71% 100% MT E11 12 12100% 100%MTE13 5 5100% 100%ML1 ETCH Name Global Impact PL4 BARC ETCH WL SPR ETCH ML1 ETCH 100100100100 STI SW-OX 76.4 STI DRY STRIP PL2 WETSTRIP SPR ASHING PS1 ETCH 73.873.873.873.8 STI ETCH RDF WET STRIP PW1 WETSTRIP NW1 DESCUM PL3 WETSTRIP SOFT ETCH Fig. 14. Commonality analysis result of P2 pattern.S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 102 Acknowledgements This study is partially supported by National Science Council, Taiwan (NSC94-2213-E-007-050)and Macronix International Co., Ltd. Specialthanks go to Smith Peng, Top Lin"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_39", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 39, "text": "07) 88‚Äì103 102 Acknowledgements This study is partially supported by National Science Council, Taiwan (NSC94-2213-E-007-050)and Macronix International Co., Ltd. Specialthanks go to Smith Peng, Top Lin, Qiao-Wen Liu,and Rachel Huang for their assistance. References Agresti, A., 1990. Categorical Data Analysis. Wiley, New York. Bergeret, F., Gall, C.L., 2003. Yield improvement using statistical analysis of process dates. IEEE Transactions on Semicon- ductor Manufacturing 16 (3), 535‚Äì542. Braha, D., Shmilovici, A., 2002. Data mining for improving a cleaning process in the semiconductor industry. IEEETransactions on Semiconductor Manufacturing 15 (1), 91‚Äì101. Braha, D., Shmilovici, A., 2003. On the use of decision tree induction for discovery of interactions in a photolithographic process. IEEE Transactions on Semiconductor Manufactur- ing 16 (4), 644‚Äì652. Breiman, L., Friedman, J.H., Olshen, R.J., Stone, C.J., 1984. ClassiÔ¨Åcation and Regression Trees. Wadsworth, Belmont, CA. Carpenter, G.A., Grossberg, S., 1988. The ART of adaptive pattern recognition by a self-organization neural network.Computer 21 (3), 77‚Äì88. Carpenter, G.A., Grossberg, S., 1987. ART 2: Stable self- organization of"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_40", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 40, "text": "A., Grossberg, S., 1988. The ART of adaptive pattern recognition by a self-organization neural network.Computer 21 (3), 77‚Äì88. Carpenter, G.A., Grossberg, S., 1987. ART 2: Stable self- organization of pattern recognition codes for analog inputpatterns. Applied Optics 26, 4919‚Äì4930. Carpenter, G.A., Grossberg, S., 1990. ART 3: Hierarchical search using chemical transmitters in self-organizing patternrecognition architectures. Neural Networks 3, 129‚Äì152. Carpenter, G.A., Grossberg, S., Reynolds, J.H., 1991. ART- MAP: Supervised real-time learning and classiÔ¨Åcation of non- stationary data by a self-organizing neural network. NeuralNetworks 4, 565‚Äì588. Carpenter, G.A., Grossberg, S., Rosen, D.B., 1991. Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system. Neural Networks 4, 759‚Äì771. Chien, C., Lee, P., Peng, C., 2003. Semiconductor manufacturing data mining for clustering and feature extraction. Journal of Information Management 10 (1), 63‚Äì84. Chien, C., Wang, W., Cheng, J., 2007. Data mining for yield enhancement in semiconductor manufacturing and an em- pirical study. Expert Systems with Applications 33 (1), 1‚Äì7.Cunningham, S.P., Spano"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_41", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 41, "text": "4. Chien, C., Wang, W., Cheng, J., 2007. Data mining for yield enhancement in semiconductor manufacturing and an em- pirical study. Expert Systems with Applications 33 (1), 1‚Äì7.Cunningham, S.P., Spanos, C.J., Voros, K., 1995. Semiconductor yield improvement: Results and best practices. IEEE Trans- actions on Semiconductor Manufacturing 8 (2), 103‚Äì109. Freeman, J.A., Skapura, D.M., 1991. Neural Networks: Algo- rithm and Programming Techniques. Addison-Wesley, Read- ing, MA. Friedman, D.J., Hansen, M.H., Nair, V.N., James, D.A., 1997. Model-free estimation of defect clustering in integrated circuitfabrication. IEEE Transactions on Semiconductor Manufac- turing 10 (3), 344‚Äì359. Hansen, M.H., Nair, V.N., 1995. Monitoring wafer map from integrated circuit fabrication processes for spatially clustered defects. Technometrics 39 (3), 241‚Äì253. Kaempf, U., 1995. The binomial test: A simple tool to identify process problems. IEEE Transactions on SemiconductorManufacturing 8 (2), 160‚Äì166. Kass, G.V., 1980. An exploratory technique for investigating large quantities of categorical data. Applied Statistics 292 (2),119‚Äì127. Keki, B., Cheng, J., Fayyad, U., Qian, Z., 1993. Applying machine learnin"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_42", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 42, "text": "V., 1980. An exploratory technique for investigating large quantities of categorical data. Applied Statistics 292 (2),119‚Äì127. Keki, B., Cheng, J., Fayyad, U., Qian, Z., 1993. Applying machine learning to semiconductor manufacturing. IEEE Expert, 41‚Äì47. Kusiak, A., 2000. Decomposition in data mining: An industrial case study. IEEE Transactions on Electronic Packaging Manufacturing 23 (4), 345‚Äì352. Leachman, R.C., Hodges, D.A., 1996. Benchmarking semicon- ductor manufacturing. IEEE Transactions on Semiconductor Manufacturing 9 (2), 158‚Äì169. Lim, T.S., Loh, W.Y., Shih, Y.S., 2000. A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classiÔ¨Åcation algorithms. Machine Learn- ing 40, 203‚Äì229. Mallory, C.L., Perloff, D.S., Hasan, T.F., Stanley, R.M., 1983. Spatial yield analysis in integrated circuit manufacturing. Solid State Technology November, 121‚Äì127. Peng, C., Chien, C., 2003. Data value development to enhance yield and maintain competitive advantage for semiconductormanufacturing. International Journal of Service Technology and Management 4 (6), 365‚Äì383. Peng, J., Chien, C., Tseng, B., 2004. Rough set theory for data mining for fault diagn"}
{"id": "Hybrid data mining approach for pattern extraction from wafer.pdf::chunk_43", "source": "Hybrid data mining approach for pattern extraction from wafer.pdf", "chunk_index": 43, "text": "antage for semiconductormanufacturing. International Journal of Service Technology and Management 4 (6), 365‚Äì383. Peng, J., Chien, C., Tseng, B., 2004. Rough set theory for data mining for fault diagnosis on distribution feeder. In: IEEProceedings-Generation, Transmission, and Distributions 151 (6), 689‚Äì697. Quinlan, J.R., 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Francisco, CA. Stapper, C.H., 2000. LSI yield modeling and process monitoring. IBM Journal of Research and Development 44 (2), 112‚Äì118. Taam, W., Hamada, M., 1993. Detecting spatial effects from factorial experiments: an application from integrated-circuit manufacturing. Technometrics 35 (2), 149‚Äì160.ARTICLE IN PRESS S.-C. Hsu, C.-F. Chien / Int. J. Production Economics 107 (2007) 88‚Äì103 103"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_0", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 0, "text": "IC Performance Prediction for Test Cost Reduction Jungran Lee Dept. of C:oniputcr Science College Station, TX USA D. M. 11. Walker Dept. of Computer 7 ~ience ,' Texas A&M University 'Texas A&M University Sunnyvale, CA, llSA College Station, 'I'X LISA Linda Milor, Ycng Peng, Gene Hill Advanced Micro Devices Ahstruct . ~ TIiB pup er^ (lesrrihes (I nlafho~/o/o~Ji,for blri/diilg models predicting manufirctnrerl integruted circuit performances (IS N function of inlirre nnd w(IJLr r?lectricnl te,st measuremen1.s. We show how these predictioiis CNI~ he used to predict the pei:firmnnce of nn industrial niicrq~roce,s,ror, and redirce the averrrgc irurnher uf speed bi11s that misf be te.sled by 45%. IN'I'RODUC'I'ION As manufacturing geometries continuc to shrink and circuit performances increase, statistical process variation is OS increasing concern. They must be controllcd to rcdncc parametric yield loss, aiid tlic resulting circuits tested in ordcr to guarantee that thcy meet their specifications. However it is often impossible to directly mcasure process variation. The goal of this work is to build modcls predicting manufactured integrated circuit (IC) periormances as a fnnction of inlin"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_1", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 1, "text": "ions. However it is often impossible to directly mcasure process variation. The goal of this work is to build modcls predicting manufactured integrated circuit (IC) periormances as a fnnction of inlinc and wafer electrical test measnremcnts, as sliown iii Figure 1. Such models can be used for a variety of applications. In process diagnosis, they can bc used in reverse to deterniinc [lie soiircc of process variability, aiid identify tcst structures ancl measuremcnts to help control that variability. In proccss optimization, they can be used to select process settings lo optimize the tr;idcoff hctwcen parametric yield loss and circuit performance, In sclicduling applications, performance prediction caii lx: used to reorder tlic processing of wafers in assembly and rid test in ordcr tri ineel product demands with ininimuni cycle time. 111 test cost reduction, prediction models caii be uscd to predict iiiic IC pcrforinancc given thc iiieasnrcmciit of anullrcr. OIIC cu.amplc is to test tlic circuit iit uiie tcmpcraturc and ~ircdict the pcrfonnance at another tcmpcraturc. Figure 1. IC pcrformance prcdiction modeling Given Ilie increasing difficulty or testing high-speed microprocessors, "}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_2", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 2, "text": " circuit iit uiie tcmpcraturc and ~ircdict the pcrfonnance at another tcmpcraturc. Figure 1. IC pcrformance prcdiction modeling Given Ilie increasing difficulty or testing high-speed microprocessors, the rapidly rising costs of testers, and increasing cost pressure in the microprocessor market, 0-7803-5403-6/99/$10.00 0 1999 IEEE. 111 prcdic~ion modcls providr iin attractive mcaiis 01 rcdiiciiig test costs. lu this work, we build a inodcl predicting microprocessor clock speed as a fmiction of wafer electrical tests, and use it to signiricantly reduce the number uf speed bins that must be testcd to bin the product. In the sections that follow we discnss our niorlcl-building methodology. the results of building a pcrformancc prediction niodcl for an industrial nricroproccssor. and cxpcriniental results on the test cost reduction application M~I'I-101~)01.OC;Y Tlie model-building mctliodology consists 111' tlic IOlliiwiiig steps: 1. Identification of Inw-cost mea~nrcnicnt~ that correlate well with the circuit pcrfornianccs of intcrcst. 2. Construction of responsc surface models using measurcrncnls and pcrforn~ancer. Many diffcrcnl lypes of iiicasurenrcirts arc corrclatcd to IC @\"nnaii"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_3", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 3, "text": "well with the circuit pcrfornianccs of intcrcst. 2. Construction of responsc surface models using measurcrncnls and pcrforn~ancer. Many diffcrcnl lypes of iiicasurenrcirts arc corrclatcd to IC @\"nnaiices. 'Thcsc include inlinc iiicasiircniciits I I1[2 1. sucl1 as a poly Cl); water CIeCtrlcill lest StlllCIUrc niCasiircmciits. such as ring oscillator licr!iicncy; iiiicl product mcasiirenicnts. sncli as tlic dclay 011 a long circiiif path. 'lcst structtircs ea11 even hc sp illy clcsigocil to have higli corrclation to pcrformance. Selcctioii 01' tlic most appropriate niciisiircnieiits to use dcpcnils on tlic puticiiliir application. 'l'lic decis~ii~i will typically bc hahcd cii, tlic vcrsiis the value of tlic pIc1lictio11. 111 gciicrtil. wc waiit tlie lowest pnssihlc rircasurcmciit costs and tlic l~~glicst ~iiissihl~ predictinn accuracy. Correlation of iiieasiircniciits ti1 peribrmaliccs ciiii hi. dotic empirically [SI or by siiiiiilatioti 141, Siiiiii,ltilioii c~ii I~L. dolie with little produclion data, but it rcqit~rcs iiiiic!i dcsigii data and well-calihratcd models. In our experiments we had production daka, hut only mcagcr design det;i, so we nnly dcscribe the empirical approach "}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_4", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 4, "text": "produclion data, but it rcqit~rcs iiiiic!i dcsigii data and well-calihratcd models. In our experiments we had production daka, hut only mcagcr design det;i, so we nnly dcscribe the empirical approach in this paper. A full discussion oS a simulation-based model-hnilding approach can be found in lilis]. Aftcr selectiirg a !set of nica~urenrent~ scnsitwc tc circuit pcrfiirmaiiccs. low-order polynoniial iespiiiisc su~f~icc models arc built, using tlic smiul;~tcd or mcas~~rcd data. M'c use stcpwisc regression to linild sucli modcls Whcii several mcasurcmcnts arc iiglily ci~rrcIstcd ii it11 miL' COSt llf LllC llleasllrclllcllt (Illcludlng tiny 111c iirca c051) Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:06:55 UTC from IEEE Xplore. Restrictions apply. another (e.g. several different types of riiig oscillators), we discard those with lesser correlation before building the model. For accurate performance prediction, me must take into account spatial variation in process parameters, particularly variation in LCri and iutc:.connect parasitics 171. If we makc measurcmcnts on every die, we can estimate the local variation by looking at ncighho"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_5", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 5, "text": "patial variation in process parameters, particularly variation in LCri and iutc:.connect parasitics 171. If we makc measurcmcnts on every die, we can estimate the local variation by looking at ncighhoring mcasuremen~s. One estimate is tlie average of the neighboring nicasiirements. Auothcr cstiniatc is the gradient from the plane cqiiation Ax-I~.!3j'-+C = 0 lit to the ncighhoring uicasiireiiients. In addition to a local gradient, random and systcniutic local variation in process paramcters is also present within a die. This may he averaged out over long circuit paths, but can reduce tlic correlation between a small clectrical test structure and a long path [ 8 I MICROPROCESSOR MODELING We apply our methodology to predicting the critical path delay of an industrial niicroproccssor design as a function of wafer electrical test striicturc nieasnreme~its. 'l'liis design has a set of 10 transistor aud 7 ring oscillator test struclnres in a corner of the chip. Itis,, measurements are taken from devices of various sizes, oricntations, and densities. The ring oscillators have a variety of Crontend and backend loading, including NAND gates, and metal plate capacitance. The perforniance of i"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_6", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 6, "text": "rom devices of various sizes, oricntations, and densities. The ring oscillators have a variety of Crontend and backend loading, including NAND gates, and metal plate capacitance. The perforniance of interest isfiiinx, the worst delay amoug several hundred critical paths. This test is difficult and iioisy at the wafer level. It also contains outliers due to spot defects. For the model-building procedure we uscd a production sample of 2,780 chips over 11 lots. Ontlicrs were discarded, hut it is likely that chips with smaller delays due to spot defects remained. Half of tlie data was used for model huilding and the other half for testing. lhe results of evaluating a number of different models are sununarized io Table I. Measurements were either from test Struchlres on the chip (local), the local plus the average of the neighbors, or the local iiieasurcmeuts aud the gr a d' lent fit through the neighboring measurements. Not all chips had 4 neighboring measurcmcnts, so the w~dicut was fit using the ineasuremcnts available. All 2\"' order models uscd quadratic (quad.) terms, while all Is' order modcls uscd linear (linear) teriiis. The notatious C-iv, f-iv, C--ro, arid f-ro mean that the a"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_7", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 7, "text": "sing the ineasuremcnts available. All 2\"' order models uscd quadratic (quad.) terms, while all Is' order modcls uscd linear (linear) teriiis. The notatious C-iv, f-iv, C--ro, arid f-ro mean that the averaged (C) and gradient-fit (0 neighboring transistor (iv) and ring oscillator (10) measurements were used in the model, in addition to the local measurements. The best results came for a 2\"' order modcl using local and gradient data, with ail R2 of 0.8. To avoid ovcrfittiug, variables with low fmax correlation wcrc discarded. One major limiter on the correlation is the poor visibility of the test structures into variations in interconnect parasitics. The interconnect-loaded ring oscillators used only lower metal layers, and did not have sufficicnt loadiug to achieve Iiigii sensitivity. lo addition, test structures sciiiitivc 10 intra-dic variation would also he icqiiiicd to iicIuc\\~c hgliei correlation [SI. As can he sccii iii Figurc 3, tlic ~ircdiction errnr is witliiii ~I~S'Y'. The modcl slightly underpredicts performance clue to a difference hctwccii tlic Ilaining and tcsting data ~nca~is. 'I'tthlc I. Summary u1~~rcd1ctio11 iiiodc ICSLII~S Measurementr -~ I.ocal test StrlLcIllIc i"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_8", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 8, "text": "cl slightly underpredicts performance clue to a difference hctwccii tlic Ilaining and tcsting data ~nca~is. 'I'tthlc I. Summary u1~~rcd1ctio11 iiiodc ICSLII~S Measurementr -~ I.ocal test StrlLcIllIc inCasiircmeiits 120cal k Averaged test slrllclnrc mcasurcincnts - Local & imlicnt of LCSI structure Il~L'ilslIl~cIneIlts AI'I'LICAIION We dcmonstrate our iiiodel 011 thc problcni of reducing the cost of speed binning thc micruprocessor. 'Ihe bins arc bin A, bin LJ, and hili C, wlicrc the speed 01 A IS less than 13. winch is less than (~. 'Ihc incan fiequency OS tlic populatioii IS approximatcly(B ~+ 2(')/3 Ml~lz as shown 111 1;igiirc 2. A LI ( Mlli hlH, MtI, Mll, Figure 2. Microprocessoi hiiiiiiiig cuaiiiplc Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:06:55 UTC from IEEE Xplore. Restrictions apply. 15 10 5 L E BQ s -5 -10 -15 1 51 104 151 201 251 301 die number Figure 3. Delay prcdictiun error in final model. We analyzed three simple test stratcgies in Table 2. l'hc first is to test from slowcst (A) to fastest bin (C), stopping when a bin fails. 'The second is to test from Castest (C) to slowest (A) bin, stopping once a bin passes. 'l'"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_9", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 9, "text": "stratcgies in Table 2. l'hc first is to test from slowcst (A) to fastest bin (C), stopping when a bin fails. 'The second is to test from Castest (C) to slowest (A) bin, stopping once a bin passes. 'l'lic third is to test bin B first. If D passcs, tcst bin C, otherwise test bill A. For this last casc, two bins are always tested, while for thc other two strategies, the iinrnbcr of hitis tesled depcntls on the frequency distribution of the microprocessor spccd. Prom the table it can be seen that testing fastest to slowcst results in the fcwest hins tcsted due to the high average speed of this microprocessor. These results depend 011 tlie yield of the micropro tlie start of production when parametric yield inay he low, testing the slowest bin first would bc a better strategy. Testinghc fastest bin first also reduces tcst time more than indicated by the number of bins. A chip tested beyond its speed capability will fail sooner, and the test time of the faster bins is less than that of the slower bins. Table 2. Number of bins tested for siniple test strategies, 2.00 => if fail, A In Table 3 we used the mean of thc performancc prediction to select the starting test bin. This is almost alw"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_10", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 10, "text": "lower bins. Table 2. Number of bins tested for siniple test strategies, 2.00 => if fail, A In Table 3 we used the mean of thc performancc prediction to select the starting test bin. This is almost always hili D in our data set. We use two strategies. 'l'he first strategy is to test in the starting bin, and then go to the ncxt higher bin if the first passes. In tlie second strategy, we do not test at the higher speed bin. In this casc there is a risk oidowiibinniiig the product if the prediction is inaccurate. In our data 16.43% are downbinned, while the tcst time is cnt nearly in half. This is not a reasonable economic trade-off for a microprocessor. In 'Sable 4, wc applied the same stratcgy as 111 'hiblc 2, hiit iiscd the 95% conlidcncc intcrwil ((:I) riitlic~ thin JILSI t11r incan. When the interval crosses a bin houndary. we iclcci citlier the slowcr or fiistcr bin Sirst. as sliowii. I i' wc !,CICCI the slowcr bin and tht: chip pa , we do llilt test tile IICXl faster bin. In this case tlicrc is a cllance that the chip will hc downbiinied. 'l'lic results sliow that the :ivclagc iiiiiiibcr iil' bins tested does not change signiSicantly by iisiiig the ('I, but the amonnt uf downbin"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_11", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 11, "text": "se tlicrc is a cllance that the chip will hc downbiinied. 'l'lic results sliow that the :ivclagc iiiiiiibcr iil' bins tested does not change signiSicantly by iisiiig the ('I, but the amonnt uf downbinning IS greatly rcduccd. Nvtc tliat using the CI actually i-cduces the avcragc iiuinbcr (11 bins for thc sccond strategy, at thc same time it rcduccs downbinning. Using ii 09'!4 conCidencc interval woiild result in B negligiblc iimoiint U(' douwbiiiiiiiig at only ii slight incrcasc iii Ihc avcragc iiuinbcr of biix tcstcd. li. discussed abovc, tcsting thc Sastcr bin lirst will icd iii IIIL test time being somewliat Icss tliilii indicaicd by tlic IIVCII!!~ numbcr ofbins. Table 4. Averagc nmnbcr of lest bins based mi 9% Cl (11' prcdicted delay fnt different test strategies. 113 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:06:55 UTC from IEEE Xplore. Restrictions apply. CONC1,IJSIONS We have shown that an accurate performancc prcdiction model can he built using low-cost wafer tests. l'licsc tests are done on indi\\dual transistor and ring oscillator test structurcs commonly found 011 largc integrated circuits. We have developcd a performanc"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_12", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 12, "text": "can he built using low-cost wafer tests. l'licsc tests are done on indi\\dual transistor and ring oscillator test structurcs commonly found 011 largc integrated circuits. We have developcd a performance prediction niodel for an industrial microprocessor and applied it tn tlic problem 11V speed hinning. Coiiiparcd to tlic best siiiiplc hili tcsl stralegy, our prcdiction-hascd apprvacli rcducci LIic iiiiiiilicr nf tested bins by 45% at tlic cost of a slight ainouiit of downbinning. By using ii largei conlidence interval. downbinning caii be niatle negligible. Our work also sliows that the local gradicnt in proccss parameters has a significant impact on circuit performance. Includitig tlic gradicnt io the performance prcdiction iiicrcascd thc correlation from 0.73 to 0.80. We believe that by usnig test structures with bcttcr visibility ol iiiterconncct variation, it is possible to achieve higher corrclations. ACKNOWI~.I'.D(;I~MLlNTS i liis rcscarcli was finidcd in part by tlic National Scicncc Fouridation under grant MIE-9406946 and by the 'lcxas Advanced 'I'cchriology I'rograni under grant 999903- 100. _1 I(1iFERENChS [I] (1. R. Shyamsundar, 1'. I<. Mozumder, and A. J. Strojwas, \"Stat"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_13", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 13, "text": "cncc Fouridation under grant MIE-9406946 and by the 'lcxas Advanced 'I'cchriology I'rograni under grant 999903- 100. _1 I(1iFERENChS [I] (1. R. Shyamsundar, 1'. I<. Mozumder, and A. J. Strojwas, \"Statistical Control of VISI Fabrication Proccsscs: A Software System,\" IEEE Trans. Semiconductor Manufacturing, vol. 1, no. 2, May 1988, pp. 72-82. [2] 1'. K. Mozumdcr, C. I<. Sliyanisund;ii. and .A 1 Slrojwas, \"Statistical Ciiii~rol US VI.SI Ibabi~cai~i~~i I'rnccsscs: A Fmmework.\" IEEE Trans. Scn,icundiicto~ Manufacturing, viil. 1, no. 2, May 1988. pp 62-71 131 I). A. I~laiison, R. J. (i. Goossens, ivl. Ilcdforil. S McCilnty, J. I<. Klbarlali. and I<, W Michiicli. \"Analysis til MixctlLSignal Maii~il'~~ctur~ih~lity ii1111 Statisticti1 'lcclniology CAI) ('KAI))\". ll;lil: I I~IIIS Szmiconductor R.l;~niii;~c~u~~~ng. vol. 9. 110 :I ipp -178 488, Nnv. 1990. 141 (~'. S. Murtliy and M. (>all, \"I'roccss Viiinatioii llll~cts on Circuit I'erfhrmancc: 'I'C'AD Siiiiiilaiiuii 01' 2i& .Mhit 'I'echnology,\" IliEli 'l'rans. ('AD. vol. IO. iio I I pii. 1383-1380, Nov. 1997. [SI 1. 11. Lcc, \"IC I'erformance Prcdictioii for 'Test Cost Reduction\", 1'li.D. Dissertation, Dcpt. of Computer Science, 'l'cxas A&M Un"}
{"id": "IC_performance_prediction_for_test_cost_reduction.pdf::chunk_14", "source": "IC_performance_prediction_for_test_cost_reduction.pdf", "chunk_index": 14, "text": "liEli 'l'rans. ('AD. vol. IO. iio I I pii. 1383-1380, Nov. 1997. [SI 1. 11. Lcc, \"IC I'erformance Prcdictioii for 'Test Cost Reduction\", 1'li.D. Dissertation, Dcpt. of Computer Science, 'l'cxas A&M University, .Ianuary 1999. [6j V. Ilaniakrishnan and I). M. 11. Walkcr, \"I(' I'crinrnxincc Prediction System,'' IEEE International Test Conrcrcncc, Waslnogton DC'. Oct. 109S, pp. 336- 334. 171 %. Lin, C. J. Spanos, L. S. Milor. and Y. 'I. 1.m Ykcuit Scnsiiivily to Interconnect Variation,\" ILLE 'Trans. Semiconductor ManuSacturmg, vol. I I, nu. 4, Nov. 1998, lip. 557-568. IS] 1.. M. Iiuisman, Torrclations I3ctwcen I'atli Delays and tiic Accuracy of l'crfnrmancc l'rcdictinii\". 11:1~1~ International Test C:onferencc. Wasliiiigton. I)(', OCI 1998, pp. XOl-808. I14 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:06:55 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_0", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 0, "text": "Fulllengtharticle Input-guidance diffusionmodelforunknowndefectpatternsdetectionin waferbinmap SeokhoMoon,SeoungBumKim* SchoolofIndustrial andManagement Engineering, KoreaUniversity, PostalCode02841,Seoul,RepublicofKorea ARTICLE INFO Keywords: Semiconductor manufacturing Waferbinmap Unknown defectpatterndetection DiffusionmodelsABSTRACT Thedetectionofunknowndefectpatternsinwaferbinmap(WBM)iscrucialformaintaining highproduction yieldsinsemiconductor manufacturing. Existingmethodsoftenfailtohandletheseunknown defectpatterns becauseoftheirrelianceonhigh-quality labeleddata.Inthisstudy,weproposeaWBMinput-guidance diffusion model(WigDM) fordetecting unknown defectpatternsusingunlabeled data.WigDMleverages thespecific guidanceofinputsamplestoenhancereconstruction quality,allowingeffectivedifferentiation betweenknown andunknownpatterns.Furthermore, existingunknowndetectionscoresaredesignedfornaturalimagedataand thusfailtoaccurately reflectthecharacteristics ofWBM.Therefore, theproposedmethodintroduces anewdata- drivenunknowndetectionscoreforWBMdataset.Experimental resultsonWM-811K andMixedWM38 datasets demonstrate thesuperiority oftheproposedWigDM,outperforming existingmethodsin32outof36u"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_1", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 1, "text": "ntroduces anewdata- drivenunknowndetectionscoreforWBMdataset.Experimental resultsonWM-811K andMixedWM38 datasets demonstrate thesuperiority oftheproposedWigDM,outperforming existingmethodsin32outof36unknown defectpatternscenarios. Theproposedmethodreducestherelianceonlabeleddata,offeringanewsolutionfor defectpatterndetectioninsemiconductor manufacturing. 1.Introduction Thesemiconductor industryisafundamental component ofmodern technology, playingacrucialroleintheproduction ofawiderangeof electronic devices.Thesedevicesincludeeverydayconsumer electronics suchassmartphones andlaptops,aswellasadvanced systemsusedin computing, telecommunications, andindustrial applications [1,2]. Manycountries considerthesemiconductor industryasessential becauseofitsimpactontechnological innovation andeconomicgrowth. Withtherapidincreaseindemandforsemiconductors hasincreased rapidly,theindustrymustcontinuously enhancemanufacturing pro- cessestoboostproductivity andmeetthisgrowingdemand[3]. Toachievethis,thesemiconductor industrymustfocusonimproving precision andefficiency ateveryproduction stage.Thisincludes adoptingadvanced technologies andrigorousinspection methodsto ensurethehighestquality[4‚Äì7].Amon"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_2", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 2, "text": "esemiconductor industrymustfocusonimproving precision andefficiency ateveryproduction stage.Thisincludes adoptingadvanced technologies andrigorousinspection methodsto ensurethehighestquality[4‚Äì7].Amongthese,theinspection stepis crucialformaintaining highyieldratesinincreasingly complexpro- ductionenvironments. Inparticular, theelectrical diesorting(EDS) process,whichuseselectronic signalstoverifythefunctionality ofthe chipsonawafer,iswidelyusedintheinspection process[8].Theresults oftheEDSprocessareusuallyrepresented inwaferbinmaps(WBMs), whichvisuallydisplaythestatusofeachchipaseitherdefectiveorfunctional. TheEDSprocesscanidentifytherootcausesofdefectsbyrevealing patternsthatindicatespecificfailuresduringfabrication [9].For example,systematic defectpatternsinWBMscanhighlightrecurring issuesincertainmanufacturing steps,helpingengineers traceandfix theseproblems. Earlydetectionandclassification ofdefectsarecrucial formaintaining highproduction yieldsandensuringproductquality, thusavoidingcostlydownstream issues. Traditionally, engineers manually checkedtheWBMsgenerated fromtheEDSprocess.However, withtheincreasing complexity of production processesandthegrowingnumberofwafers,thistask"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_3", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 3, "text": "ngcostlydownstream issues. Traditionally, engineers manually checkedtheWBMsgenerated fromtheEDSprocess.However, withtheincreasing complexity of production processesandthegrowingnumberofwafers,thistaskhas becomeincreasingly difficult[10].Moreover, asmanufacturing pro- cessesbecomemorecomplicated, thevarietyofdefectpatternsinWBMs alsoincreases. Thisleadstoashortageofskilledengineers capableof accurately identifying thesepatterns.Toaddressthesechallenges, researchhasfocusedonclassifying defectpatternsinWBMsusingdeep learningmethods[11‚Äì18].Thesestudiesaimtoautomatetheinspection processandimproveaccuracy. Nonetheless, thesemethodshaveasig- nificantlimitation: theyoftenfailtohandleunknown defectpatterns effectively. Unknown defectpatternsrefertodatathatthedeeplearningmodels havenotencountered duringtrainingstep.Thesemodelstypically *Corresponding author. E-mailaddresses: danny232@korea.ac.kr (S.Moon),sbkim1@korea.ac.kr (S.B.Kim). ContentslistsavailableatScienceDirect Advanced Engineering Informatics u{ÔøΩ~zkw s{yo|kr o>√ê√ê√ê1owÔøΩo ÔøΩto~1m{y2w{m kÔøΩo2kot https://doi.org/10.1016/j.aei.2024.103078 Received8August2024;Receivedinrevisedform17November 2024;Accepted20December 2024Advanced Engineering "}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_4", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 4, "text": "ormatics u{ÔøΩ~zkw s{yo|kr o>√ê√ê√ê1owÔøΩo ÔøΩto~1m{y2w{m kÔøΩo2kot https://doi.org/10.1016/j.aei.2024.103078 Received8August2024;Receivedinrevisedform17November 2024;Accepted20December 2024Advanced Engineering Informatics 64 (2025) 103078 Available online 24 December 2024 1474-0346/¬© 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies. struggletodetectsuchunknown defectpatterns,whichiscritical becausetheseunknowndefectpatternscanindicatenewissuesinthe manufacturing process.Inlarge-scale semiconductor manufacturing, quicklyidentifying andaddressing thecausesoftheseunknowndefect patternsiscrucial.Therefore, thereisaneedformethodsthatcan accurately detectunknowndefectpatterns.Someresearchhasfocused ondetectingunknowndefectpatternsinWBMclassification [19‚Äì22]. However,mostofthesestudiesassumethathigh-quality labeleddata isreadilyavailabletobuildeffectivedefectpatternclassifiers. Inreality, obtaining high-quality labeleddatainWBMsischallenging andtime- consuming, oftenrequiringsignificant resources. Thus,itisnecessary todevelopmethodsthatcandetectunknowndefectpatternsusingonly unlabeled data.Out-of-distribution (OOD)detectioni"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_5", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 5, "text": "ischallenging andtime- consuming, oftenrequiringsignificant resources. Thus,itisnecessary todevelopmethodsthatcandetectunknowndefectpatternsusingonly unlabeled data.Out-of-distribution (OOD)detectionisamethodology usedtoidentifydistributions thatwerenotpresentinthetrainingset andhasbeenextensively studiedinthefieldofcomputer vision[23]. Furthermore, OODdetection canbeperformed evenwithoutlabels throughlikelihood-based orreconstruction-based methods. Among these,OODdetectionmethodsbasedondiffusionmodels,whichhave recentlyshownoutstanding performance inmanyfields,havebeen proposed[24,25].However, tothebestofourknowledge, noresearch hasappliedOODdetectionalgorithms usingdiffusionmodelstoWBM data. Inthisstudy,weproposeaWBMinput-guidance diffusionmodel (WigDM) fordetecting unknown defectpatterns. Unlikeprevious methodsthatusedanunconditional diffusionmodel,theproposed approachleveragesthespecificguidanceofinputsamples,addressing thesubtledifferences betweenknownandunknowndefectpatternsin WBMs.Additionally, becausethemethodisreconstruction-based, itis crucialtoaccurately measurethedifference betweentheinputimage andthereconstructed image.Tothisend,weuseafeaturemapdistance tailoredforWBMa"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_6", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 6, "text": "Ms.Additionally, becausethemethodisreconstruction-based, itis crucialtoaccurately measurethedifference betweentheinputimage andthereconstructed image.Tothisend,weuseafeaturemapdistance tailoredforWBMandproposeadata-driven unknowndetectionscore basedontheWBM-aware distance.Wedemonstrate thesuperiority of theproposed methodthroughvariousunknown defectpatternssce- nariosusingrealWBMdatasets,WM-811K [26]andMixedWM38 [27]. Themotivation behindWigDMliesinitsabilitytoovercome the limitations ofexistingWBMclassification methodsthatstrugglewith unknown defectpatterns.Throughtheapplication ofWBM-specific inputguidance, ourmethodaddresses theuniquechallenges posedby thevarietyandcomplexity ofunknown defectpatternsinthesemi- conductor manufacturing process.Additionally, weaimtoprovidea moreaccessible solutionbyremoving therelianceonlabeleddata, whichisoftendifficulttoobtaininthisdomain.Thisapproachhasthe potentialtosignificantly enhancetheinspection accuracyandefficiency withinthesemiconductor industry,ensuringrobustdefectdetection withoutextensive datalabeling.Themaincontributions ofthisstudy canbesummarized asfollows: ‚â°WeproposeWigDM,amethodspecifically designedtodetectun- knowndefectpattern"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_7", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 7, "text": "ustry,ensuringrobustdefectdetection withoutextensive datalabeling.Themaincontributions ofthisstudy canbesummarized asfollows: ‚â°WeproposeWigDM,amethodspecifically designedtodetectun- knowndefectpatternsinWBMwithoutrelyingonlabeleddata.By incorporating WBM-specific inputguidance withinadenoising diffusionmodel,ourapproach improves theperformance ofun- knowndefectpatterndetectionandaddresses thechallenges posed bythevarietyandcomplexity ofdefectsinsemiconductor manufacturing. ‚â°Weintroduce anautomated, data-driven unknown detectionscore thatreflectstheuniquecharacteristics ofWBM,distinguishing them fromconventional naturalimages.Thisscorecanautomatically determine whethertofocusonpixel-level changesorpattern-level changes,enablingmoreeffectivedetectionofunknown defectsby adaptingtothespecificfeaturespresentinWBM. ‚â°Wevalidatetheeffectiveness ofWigDMthroughextensive experi- mentsontwopubliclyavailablereal-world WBMdatasets,WM-811K andMixedWM38, demonstrating higherperformance acrossvarious scenarios. Byusingpubliclyopendatasets,ourproposedmethodcan bereadilyreproduced, promoting transparency andfacilitating furtherresearchinthisarea.Thestructureofthispaperisorganized asfollows.Section2pr"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_8", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 8, "text": "cenarios. Byusingpubliclyopendatasets,ourproposedmethodcan bereadilyreproduced, promoting transparency andfacilitating furtherresearchinthisarea.Thestructureofthispaperisorganized asfollows.Section2provides areviewoftheexistingliteratureondeeplearningapplications ofWBM andOODdetectionmethods.Section3presentsthedetailsofourpro- posedmethod.InSection4,wedescribetheexperimental setupand presentourresults.Finally,Section5concludes thepaperandoffers suggestions forfutureresearch. 2.Relatedworks 2.1.Deeplearningapplications forwaferbinmaps TheEDSprocessgenerates WBMdatathatcanberepresented as grayscaleimages.Aspreviously mentioned, defectpatternscanbeused toidentifywhichmanufacturing processeshaveissues.Expertengineers canassociatespecificdefectpatternswithcertainprocessproblems. Consequently, mostexistingresearchonWBMhasfocusedondefect patternclassification tasks,aimingtoimproveperformance usingdeep learningtechniques. Amethodusingconvolutional neuralnetwork (CNN)forWBMdefectpatternrecognition andanalysiswasproposed, achieving highaccuracyinidentifying andclassifying variousdefect patterns[11].Astackingensemble classifiercombining handcrafted featureswithCNN-extracted featureswasintrodu"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_9", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 9, "text": "ion andanalysiswasproposed, achieving highaccuracyinidentifying andclassifying variousdefect patterns[11].Astackingensemble classifiercombining handcrafted featureswithCNN-extracted featureswasintroduced toenhanceWBM defectpatternclassification [12].Amixup-based approach forclassi- fyingmixed-type defectpatternsinWBMimproved performance by generating mixed-type defectpatternsduringtraining[13].Amethod calledSWaCowasproposedforWBMclassification usingself-supervised contrastive learningtohandleunlabeled OODdata,achieving better classification accuracy[14].AdeepCNNmodeldesignedforWBM defectidentification onimbalanced datasetsdemonstrated robustper- formance evenwithskewedclassdistributions [15].Furthermore, generative adversarial network(GAN)hasbeenappliedtoaugmentdata forminorityclassesinWBMdataset,whichhasenhanced theperfor- manceofCNN-based defectclassification [17].Similarly, theauxiliary classifierdenoising diffusionprobabilistic model(ACDDPM) hasbeen proposedtoaddressclassimbalance inwafermapdefectdatasetsby generating diversesyntheticsamplesandcombining themwithaCNN classifier,significantly improving defectclassification accuracy[18]. However, asignificant limitation ofthesetra"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_10", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 10, "text": "inwafermapdefectdatasetsby generating diversesyntheticsamplesandcombining themwithaCNN classifier,significantly improving defectclassification accuracy[18]. However, asignificant limitation ofthesetraditional studiesistheir inabilitytoeffectively handleunknowndefectpatterns.Theoccurrence ofunknowndefectpatternsincreasesuncertainty inthemanufacturing process,posingasignificant risk.Therefore, itiscrucialtodetectthese defectsquicklyinlarge-scale semiconductor manufacturing processes. Toaddressthisissue,severalstudieshavebeenconducted. Forexample, asupport-weighted ensemblemodelthatcombines multipleclassifiers toimprovetheopen-setrecognition (OSR)ofWBMdefectswasproposed [19].Anoptimalbinembedding technique wasdeveloped torecognize unknownWBMdefectpatternsbytransforming morphological features of3DWBMandusingsimultaneous optimization forbetterfeature vectorclustering [20].Additionally, adecisionfusionapproach that integrates multipledecisionstrategies todetectunknownWBMdefect patternswasintroduced [21].Finally,acontrastive deepclustering methodwaspresented fordetectingnewdefectpatternsinWBM,using contrastive learningtoimprovetheclustering andidentification ofnovel defectpatterns[22]. De"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_11", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 11, "text": "roduced [21].Finally,acontrastive deepclustering methodwaspresented fordetectingnewdefectpatternsinWBM,using contrastive learningtoimprovetheclustering andidentification ofnovel defectpatterns[22]. Despitetheseadvancements, suchmethodsstillrelyonhigh-quality labeleddatatotrainclassifiers. Insemiconductor manufacturing, la- belingWBMsisatime-consuming processbecauseofthelimitedavail- abilityofexpertengineers. Therefore, itisnecessary todevelopmethod thatcanquicklydetectunknown defectpatternsusingthecurrently availableunlabeled data.Ourproposedmethodaddresses thisissueby trainingadiffusionmodelonunlabeled dataandusingthereconstruc- tionprocesstodetectunknowndefectpatterns. 2.2.Unsupervised out-of-distribution detection OODdetection referstomethodsthatdistinguish betweenauser-S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 2 definedin-distribution (ID)datasetandallotherdatasets,termedOOD. Withinthisframework, unsupervised OODdetectionalgorithms, which donotrequirelabeleddata,canbeprimarily categorized intotwo approaches. Thefirstapproachislikelihood-based. Typically, agenerative model, oncetrained,cancomputethelikelihood ofanygiveninput.Thecentral premiseofusinglike"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_12", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 12, "text": "ddata,canbeprimarily categorized intotwo approaches. Thefirstapproachislikelihood-based. Typically, agenerative model, oncetrained,cancomputethelikelihood ofanygiveninput.Thecentral premiseofusinglikelihood forOODdetectionisthatsamplesfromthe IDdatasetwillhavehigherlikelihoods, whilesamplesfromOODdata- setswillexhibitlowerlikelihoods [28].Thus,sampleswithlowlikeli- hoodsareidentified asOOD.However, thisapproachhasdemonstrated limitations incertainbenchmark datasets,whereOODsamplesare sometimes assignedhighlikelihoods [29].Tomitigatethisissue,afew studieshavebeenconducted toimprovethereliability oflikelihood- basedmethods[30,31].Despitetheseefforts,thechallenges associ- atedwithrelyingonlyonlikelihood havelimitedthewidespread adoptionofthisapproach. Thesecondapproachisreconstruction-based. Thebasicassumption isthatamodeltrainedonIDsampleswillreconstruct thesesamples well,whereasitwillstrugglewithOODsamples.Bymeasuring the distanceorerrorbetweentheinputimageandthereconstructed image, OODdetection canbeperformed. Research hasusedautoencoder modelsforthispurpose,demonstrating thatIDsampleshavelower reconstruction errorscompared toOODsamples[32].Recently,several studieshaveuseddiffusion"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_13", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 13, "text": "detection canbeperformed. Research hasusedautoencoder modelsforthispurpose,demonstrating thatIDsampleshavelower reconstruction errorscompared toOODsamples[32].Recently,several studieshaveuseddiffusion modelsforreconstruction-based OOD detectionbecauseoftheireffectiveness inimagegeneration. Onepro- posedmethodinvolvestrainingadiffusionmodelonIDsamplesand generating multiplereconstructed imagesfromtheinputimagewith variousnoisesteps.Bycalculating theerrorbetweentheinputandthe reconstructed images,OODsamplescanbedetected[24].Another methodusesadiffusionmodeltrainedonIDdatatoperforminpainting onmaskedinputimages,calculating theerrorbetweentheinputandreconstructed imagesforOODdetection [25].Additionally, arecent studyaddresses theissueofdecreased OODdetectionperformance due tobackground similarity betweenIDandOODsamplesbyremoving background information beforereconstruction [33].However, inWBM datasets,thedifference betweenIDandOOD(inthiscontext,unknown defectpatterns)islessclearcompared tocomputer visionbenchmark datasetssuchasMNIST,CIFAR10, andImageNet. Furthermore, measuring reconstruction errorforWBMrequiresaspecialized approachdifferentfromthatusedfornaturalimages.Toaddressthese cha"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_14", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 14, "text": "omputer visionbenchmark datasetssuchasMNIST,CIFAR10, andImageNet. Furthermore, measuring reconstruction errorforWBMrequiresaspecialized approachdifferentfromthatusedfornaturalimages.Toaddressthese challenges, ourstudyproposesanunknowndefectionpatterndetection framework calledWigDM. 3.Proposed method Webaseourapproach ondenoising diffusionmodelsforout-of- distribution detection (DDPM-OOD) [24],ahigh-performing method forOODdetectionusingdiffusionmodels.Thetraditional DDPM-OOD trainsadiffusionmodelusingaknowndatasetasthetrainingdataset. Duringtheinferencestep,variousscalesofGaussiannoiseareinjected intothetestimage,andeachnoisedimageisdenoisedusingthetrained diffusionmodeltoobtaincleanimages.Finally,unknowndetectionis performed bycalculating thesimilarity betweenthetestimageandthe reconstructed cleanimages.However, whenappliedtoWBMdata,as showninFig.6forDDPM-OOD, thereconstructed imageofaknown datasampledivergesfromtheinputimageastheGaussiannoisestep increases. Thisapproach, whichjudgessamplesasunknownwhentheir similarity islow,negatively impactsunknown detection performance becausethesimilarity forknownsamplesalsodecreases. Thisissue ariseseasilyinWBMdatasetsinwhichknownandunknown d"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_15", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 15, "text": "amplesasunknownwhentheir similarity islow,negatively impactsunknown detection performance becausethesimilarity forknownsamplesalsodecreases. Thisissue ariseseasilyinWBMdatasetsinwhichknownandunknown datasets havesimilarforms,makingthemdifficulttodistinguish. Toaddressthisproblem,weproposeWigDM(WBMinput-guidance Fig.1.TrainingstepofWigDM.TheU-Netmodel ‚àäŒ∏andfeatureextractorResNet-18 œÑŒ∏aretrainedusingaknownWBMdataset.WhenGaussiannoise ‚àäisaddedto therawimage x0,theresultingnoisedimageisdenotedasxt.Thegoalofthetrainingistoreducethedifference betweentheaddedGaussiannoise ‚àäandtheU-Net ‚Äôs predictednoise ‚àäŒ∏ xtCtCc¬Ü,definedastheLsimple Œ∏¬Ü.Additionally, thearchitecture isdesignedasaconditional diffusionmodeltoeffectively conveyinformation from therawimagetotheU-Net.S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 3 diffusionmodel)toensurethatthereconstructed imageretainsthein- formation oftheinputimageevenwhentheGaussiannoisestepin- creases.Theproposed modelusesaconditional diffusion model structuretoincorporate theinputimageinformation intotherecon- structionprocess.Conditional diffusionmodelshaverecentlygained significant attentioninthefieldofgenerative models.Initially,th"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_16", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 16, "text": "usion model structuretoincorporate theinputimageinformation intotherecon- structionprocess.Conditional diffusionmodelshaverecentlygained significant attentioninthefieldofgenerative models.Initially,they wereresearched forgenerating imagesthatmatchuser-desired content throughtextconditioning [34,35].Recently,methodsforincorporating varioustypesofconditioning, includingimages,havealsobeenstudied[36].WigDMisthefirsttouseanimageconditioning diffusionmodel structurethatusesinputimageinformation asguidance forrecon- struction, modifiedforthepurposeofunknowndetection. Theproposedmethodisdividedintotwomainsteps:thetraining stepandtheinferencestep.First,asshowninFig.1,thetrainingofthe conditional diffusionmodelinvolvesaddingGaussiannoisetotheWBM imagex0ateachtimestept.TheamountofGaussiannoiseaddedfollows auser-defined schedule Œ≤t,resultinginthenoisedimagextattimestept. Thisprocessisknownastheforwardprocessornoisingprocessandcan Fig.2.InferencestepofWigDM.Atestimageisperturbed bydifferentlevelsofnoiseatvarioustimesteps t,resultinginthegeneration ofmultiplenoisedimages. Theseimagesareprocessed bythetrainedU-Netmodeland,aftertiterations, aretransformed intothereconstructed images.Thereconstruc"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_17", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 17, "text": "fnoiseatvarioustimesteps t,resultinginthegeneration ofmultiplenoisedimages. Theseimagesareprocessed bythetrainedU-Netmodeland,aftertiterations, aretransformed intothereconstructed images.Thereconstruction errorbetweenthe inputimageandthereconstructed imagesiscalculated andusedfortheunknowndetectionscore. Fig.3.Thedenoising processcompares theDDPMsamplerandthePLMSsamplermethods.WhileDDPMsamplerpassesthroughalltsteps,PLMSsamplerallows skippingaspecifiednumberofsteps.S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 4 bedefinedasfollows: q xt‚Ä†x0¬Ü¬àN xt‚Ä†‚é™‚é™‚é™‚é™ Œ±t‚áì x0C 1\u0000Œ±t¬ÜI¬ÜC‚Äô (1) Similartoexistingstudies,0‚âºt‚âºTand Œ±tB¬à1\u0000Œ≤tCwith Œ±tB¬à‚ãÇt s\u00001Œ±s.ItisassumedthatxTisacompleted Gaussiannoiseimage, followingthedistribution XTN 0CI¬Ü.Thenoiseschedule Œ≤tcanbesetby theuser,generally startingsmallandincreasing towardstheend.By timestept,thefullynoisedxtisconsidered tohavethecharacteristics of xTN 0CI¬Ü. Assuggested inpreviousresearch[37],weuselossfunction Lsimple Œ∏¬Ü,whichcanberepresented bythedifference betweenthenoise valuegiventotheinputimageandthenoisevaluepredicted bythe model,asfollows: Lsimple Œ∏¬Ü¬àKtCx0C‚àä‚àö ‚Ä°‚àä\u0000‚àäŒ∏ xtCtCc¬Ü‚Ä°2‚áë C‚Äô (2) wherecdenotesthefeaturevectorfromfeatureextractorRe"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_18", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 18, "text": "ythedifference betweenthenoise valuegiventotheinputimageandthenoisevaluepredicted bythe model,asfollows: Lsimple Œ∏¬Ü¬àKtCx0C‚àä‚àö ‚Ä°‚àä\u0000‚àäŒ∏ xtCtCc¬Ü‚Ä°2‚áë C‚Äô (2) wherecdenotesthefeaturevectorfromfeatureextractorResNet-18 œÑŒ∏. xtCtCc¬Ürepresents theinputstotheU-Net ‚àäŒ∏.And‚àäŒ∏ xtCtCc¬Ürepresents a predicted Gaussiannoiseimage.Aftertrainingthemodelwithknown WBMdataset,wecandefinethereverseprocess(ordenoising process), whichaimstoestimateprobability ofxt\u00001givenxt.Togenerateclean images,weusetheGaussiantransition representing therelationship betweentimestept\u00001andtduringthedenoising process.Animageat timestept\u00001canbegenerated fromanimageattimesteptasfollows: xt\u00001¬à1‚é™‚é™‚é™‚é™Œ±t‚ô†[ xt\u00001\u0000Œ±t‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™1\u0000Œ±t‚ô† ‚àäŒ∏ xtCtCc¬Ü] ¬áœÉtzC‚Äô (3) wherexT‚äÉN 0CI¬Üandz‚äÉN 0CI¬ÜiftF1Celsez¬à0.Thisprocessis repeateduntilthefullycleanimagex0isobtained. Additionally, the denoising processcanbeinitiatedfromanyxt(fortDT).Inother words,thediffusionmodelcanperformdenoising onxtinjectedwith noiseatanyscale,leveraging thispropertytoreconstruct imagesduring theinferencestep. AsshowninFig.2,theinferencestepusesthetrainedmodel,sub- jectingthetestimagetonoisedstepsatt¬à10,60,‚Ä¶,910,960,creating atotalof20noisedimages.Thetrainedmodelthendenoisesthese20 n"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_19", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 19, "text": "uring theinferencestep. AsshowninFig.2,theinferencestepusesthetrainedmodel,sub- jectingthetestimagetonoisedstepsatt¬à10,60,‚Ä¶,910,960,creating atotalof20noisedimages.Thetrainedmodelthendenoisesthese20 noisedimages.Introducing varyinglevelsofnoiseintotheinputdata andperforming denoising isessentialbecauseitisuncertain atwhich noiseleveltheinformation withintheinputdatabecomesfully degraded. Byinjectingnoiseofvariousscalesandaveraging the reconstructed images,themodelcapturesthedistinctive contributions ofdifferentscaleswithoutbiasingtowardanyspecificscale.Thisaver- agingapproachenhancestherobustness ofthemodelindetectingun- knowndefectpatternsbyleveraging thevaryingdegreesofinformation preservation acrossdifferentnoiselevels.Thedenoising processusing thediffusionmodel,alsoreferredtoassampling, involvesremovingthe predicted noisefromthenoisedimagestepbysteptoobtainthefinal cleanimage,asillustrated inFig.3.Inthisstudy,weusethepseudo- likelihood maximization sampler(PLMS)sampler,whichisfasterthan theDDPMsampler.Naturally, thelargerthenoisestep,thelongerthe denoising process.Thisprocessisrepeateduntilacleanreconstruction imageisobtained. Thisresultsinatotalof20reconstructed images,whichar"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_20", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 20, "text": "rthan theDDPMsampler.Naturally, thelargerthenoisestep,thelongerthe denoising process.Thisprocessisrepeateduntilacleanreconstruction imageisobtained. Thisresultsinatotalof20reconstructed images,whicharethen usedtocalculatethereconstruction errorwiththetestimage,forming thefinalunknowndetectionscore.However, existingapproaches that uselearnedperceptual imagepatchsimilarity (LPIPS)[38]tomeasure thereconstruction errorbetweentheinputimageandtheunknown imagedonoteffectively capturethecharacteristics ofWBM.Thisis becauseWBMimages,consisting ofblackpatternsonagrayback- ground,aresignificantly differentfromreal-world data.Toaddress theseissues,theproposed WigDMdefinesadata-driven unknown detection score.Thedetailedmethodforcalculating theunknown detectionscoreisdescribed inSection4.2.Insummary, bycalculating theunknown detection scorethroughthetrainingstepandinferencesteps,wecandetectunknownWBMdefectpatterns. 4.Experiment 4.1.Data Inthisstudy,weusedtwoWBMdatasetscollectedfromactual manufacturing processes: WM-811K andMixedWM38. TheWM-811K datasetcomprises atotalof811,457samples,outofwhich172,950 samplesarelabeledbyexpertsintonineclasses.Toconstructscenarios withvariousclassesofunknown defe"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_21", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 21, "text": "ng processes: WM-811K andMixedWM38. TheWM-811K datasetcomprises atotalof811,457samples,outofwhich172,950 samplesarelabeledbyexpertsintonineclasses.Toconstructscenarios withvariousclassesofunknown defectpatterns,weusedonlythe labeleddataasshowninTable1.Additionally, the‚Äúnone ‚Äùclasswas excluded becauseitdoesnotrepresent adefectpattern,andthe ‚Äúrandom ‚Äùclasswasexcludedbecauseofitssimilarity tothe‚Äúnear-full ‚Äù class.Consequently, thesevenclassesusedinthisexperiment are ‚Äúcenter ‚Äù,‚Äúdonut, ‚Äù,‚Äúedge-loc ‚Äù,‚Äúedge-ring ‚Äù,‚Äúloc‚Äù,‚Äúscratch ‚Äù,and ‚Äúnear- full‚Äù.TheMixedWM38 datasetconsistsof38,015instances, labeledinto 38singleandmixeddefectpatternclasses.Weusedatotalof29classes ofmixeddefectpatternstoconstruct variousscenarios ofunknown defectpatterns.Thesepatternsaregroupedbasedonthenumberof combined defectsasfollows: ‚â°2mixed-type defectPatterns(13classes): ‚ÄúC¬áEL(center¬áedge- loc)‚Äù,‚ÄúC¬áER(center¬áedge-ring) ‚Äù,‚ÄúC¬áL(center¬áloc)‚Äù,‚ÄùC¬áS (center¬áscratch) ‚Äú,‚ÄùD¬áEL(donut¬áedge-loc) ‚Äú,‚ÄùD¬áER(donut¬á edge-ring) ‚Äú,‚ÄùD¬áL(donut¬áloc)‚Äú,‚ÄùD¬áS(donut¬áscratch) ‚Äú,‚ÄùEL¬á L(edge-loc¬áloc)‚Äú,‚ÄùEL¬áS(edge-loc¬áscratch) ‚Äú,‚ÄùER¬áL(edge- ring¬áloc)‚Äú,‚ÄùER¬áS(edge-ring¬áscratch) ‚Äú,‚ÄùL¬áS(loc¬áscratch) ‚Äú ‚â°3mixed-type defectpatterns(12classes): ‚ÄúC¬áEL¬áL(c"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_22", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 22, "text": "onut¬áloc)‚Äú,‚ÄùD¬áS(donut¬áscratch) ‚Äú,‚ÄùEL¬á L(edge-loc¬áloc)‚Äú,‚ÄùEL¬áS(edge-loc¬áscratch) ‚Äú,‚ÄùER¬áL(edge- ring¬áloc)‚Äú,‚ÄùER¬áS(edge-ring¬áscratch) ‚Äú,‚ÄùL¬áS(loc¬áscratch) ‚Äú ‚â°3mixed-type defectpatterns(12classes): ‚ÄúC¬áEL¬áL(center¬á edge-loc¬áloc)‚Äù,‚ÄúC¬áEL¬áS(center¬áedge-loc¬áscratch) ‚Äù,‚ÄúC¬áERTable1 Thenumberofdatapointsduringtraining,validation, andinferencesteps. Defectpattern All Train Valid inference(wheneachpattern istreatedasunknown) Center(C) 4,294 3,865 429 1,000 Donut(D) 555 500 55 555 Edge-loc(EL) 5,189 4,671 518 1,000 Edge-ring (ER) 9,680 8,712 968 1,000 Loc(L) 3,593 3,234 359 1,000 Scratch(S) 1,193 1,074 119 1,000 Near-full(NF) 149 135 14 149 C¬áEL 1,000 0 0 1,000 C¬áER 1,000 0 0 1,000 C¬áL 1,000 0 0 1,000 C¬áS 1,000 0 0 1,000 D¬áEL 1,000 0 0 1,000 D¬áER 1,000 0 0 1,000 D¬áL 1,000 0 0 1,000 D¬áS 1,000 0 0 1,000 EL¬áL 1,000 0 0 1,000 EL¬áS 1,000 0 0 1,000 ER¬áL 1,000 0 0 1,000 ER¬áS 1,000 0 0 1,000 L¬áS 1,000 0 0 1,000 C¬áEL¬áL 1,000 0 0 1,000 C¬áEL¬áS 2,000 0 0 1,000 C¬áER¬áL 1,000 0 0 1,000 C¬áER¬áS 1,000 0 0 1,000 C¬áL¬áS 1,000 0 0 1,000 D¬áEL¬áL 1,000 0 0 1,000 D¬áEL¬áS 1,000 0 0 1,000 D¬áER¬áL 1,000 0 0 1,000 D¬áER¬áS 1,000 0 0 1,000 D¬áL¬áS 1,000 0 0 1,000 EL¬áL¬áS 1,000 0 0 1,000 ER¬áL¬áS 1,000 0 0 1,000 C¬áEL¬áL¬áS1,000 0 0 1,000 C¬áE"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_23", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 23, "text": "00 0 0 1,000 D¬áEL¬áL 1,000 0 0 1,000 D¬áEL¬áS 1,000 0 0 1,000 D¬áER¬áL 1,000 0 0 1,000 D¬áER¬áS 1,000 0 0 1,000 D¬áL¬áS 1,000 0 0 1,000 EL¬áL¬áS 1,000 0 0 1,000 ER¬áL¬áS 1,000 0 0 1,000 C¬áEL¬áL¬áS1,000 0 0 1,000 C¬áER¬áL¬áS1,000 0 0 1,000 D¬áEL¬áL¬áS1,000 0 0 1,000 D¬áER¬áL¬áS1,000 0 0 1,000S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 5 ¬áL(center¬áedge-ring¬áloc)‚Äù,‚ÄúC¬áER¬áS(center¬áedge-ring¬á scratch) ‚Äù,‚ÄúC¬áL¬áS(center¬áloc¬áscratch) ‚Äù,‚ÄúD¬áEL¬áL(donut¬á edge-loc¬áloc)‚Äù,‚ÄúD¬áEL¬áS(donut¬áedge-loc¬áscratch) ‚Äù,‚ÄúD¬áER ¬áL(donut¬áedge-ring¬áloc)‚Äù,‚ÄúD¬áER¬áS(donut¬áedge-ring¬á scratch) ‚Äù,‚ÄúD¬áL¬áS(donut¬áloc¬áscratch) ‚Äù,‚ÄúEL¬áL¬áS(edge-loc ¬áloc¬áscratch) ‚Äù,‚ÄúER¬áL¬áS(edge-ring¬áloc¬áscratch) ‚Äù ‚â°4mixed-type defectpatterns(4classes): ‚ÄúC¬áEL¬áL¬áS(center¬á edge-loc¬áloc¬áscratch) ‚Äù,‚ÄúC¬áER¬áL¬áS(center¬áedge-ring¬áloc ¬áscratch) ‚Äù,‚ÄúD¬áEL¬áL¬áS(donut¬áedge-loc¬áloc¬áscratch) ‚Äù,‚ÄúD ¬áER¬áL¬áS(donut¬áedge-ring¬áloc¬áscratch) ‚ÄùFig.4showstheimagesofthedefectpatternsusedfrombothdata- sets.WBMsarecollectedinvarioussizes,butfortheconvenience of modeltraining,theywereresizedto64x64andconverted to1-channel grayscaleimages. Whenconstructing trainingdatasetsforeachscenario,asshownin Table1,90%ofthedatafromeachdefectpatternclasswasusedfor training,andtheremaining 10%wasu"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_24", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 24, "text": "izedto64x64andconverted to1-channel grayscaleimages. Whenconstructing trainingdatasetsforeachscenario,asshownin Table1,90%ofthedatafromeachdefectpatternclasswasusedfor training,andtheremaining 10%wasusedforvalidation. Forinstance, inScenario1,‚Äúdonut, ‚Äù‚Äúedge-loc, ‚Äù,‚Äúedge-ring ‚Äù,‚Äúloc‚Äù,‚Äúscratch ‚Äùand ‚Äúnear-full ‚ÄùweretakenfromtheWM-811Kdataset,with90%usedfor training.Themodelwasthenevaluated onitsabilitytodetectthe ‚Äúcenter ‚Äùunknown defectpattern.Thenumberofinstances foreach Fig.4.Visualization ofalldefectpatternimagesusedforexperiments fromtheWM-811KandMixedWM38 datasets.S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 6 datasetwaslistedinTable1.Fortheunknowndefectpatterndata,1,000 sampleswereselectedfromeachdefectpatternclass.Ifaclasscontained morethan1,000samples,1,000wererandomly selected,andifitcon- tainedfewerthan1,000samples,allavailablesampleswereused. 4.2.Experimental setting Todemonstrate theeffectiveness oftheproposed method,we compared withthefollowing sixexistingunsupervised OODdetection methods: 1.Likelihood: unknown detection basedonp xCŒ∏¬Üobtainedfroma generative model.Thegenerative modelusedhereisadiffusion model[28].2.Anomalydetectionwithgenerative adve"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_25", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 25, "text": "ngunsupervised OODdetection methods: 1.Likelihood: unknown detection basedonp xCŒ∏¬Üobtainedfroma generative model.Thegenerative modelusedhereisadiffusion model[28].2.Anomalydetectionwithgenerative adversarial networks(AnoGAN): Agenerative adversarial networkcomposed ofagenerator anda discriminator istrained.unknowndetectionisperformed basedon theweighted sumofresiduallossanddiscrimination loss: Œª‚â°‚ãÉ‚É¶‚É¶x\u0000G\u0000 zŒ≥)‚É¶‚É¶¬á 1\u0000Œª¬Ü‚â°‚ãÉ‚É¶‚É¶f x¬Ü\u0000f\u0000 G\u0000 zŒ≥))‚É¶‚É¶wheref ‚â°¬Üisthe discriminator ‚Äôsfeatureextractor, G ‚â°¬Üisthegenerator, zŒ≥israndom noise,and Œªissetto0.9[39]. 3.Autoencoder: Athree-layer autoencoder istrained.Duringinference, themeansquarederror(MSE)‚Ä°x\u0000}x‚Ä°2ismeasured betweenthe inputimageandthereconstructed image.MSEisusedforunknown detection. 4.Memory-augmented deepautoencoder (MemAE): Anautoencoder withamemorybankdesignedtoretainmoreinformation fromthe Fig.5.(a)AnenlargedviewofWBMillustrating calculation ofdefectivechipratio Œ±throughanexample.(b)Resultsofcalculating defectivechipratio Œ±forseven examplesofWBM. Fig.6.Comparison ofreconstructed imageresultsbetweenDDPM-OOD andWigDM.DDPM-OOD, withoutinputguidance, producesreconstructed imagesthatare notsimilartotheinputimagewhen tishighfornoisedimages.Inc"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_26", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 26, "text": "fWBM. Fig.6.Comparison ofreconstructed imageresultsbetweenDDPM-OOD andWigDM.DDPM-OOD, withoutinputguidance, producesreconstructed imagesthatare notsimilartotheinputimagewhen tishighfornoisedimages.Incontrast,theproposedWigDM,throughinputguidance, ensuressimilaritytotheinputimageeven athightfornoisedimages.S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 7 trainingdataset,enhancing detectionperformance. MSEisusedas thecriterion[32]. 5.Lift,map,detect(LMD):Leveraging thecapability ofatrained diffusionmodeltoperforminpainting onmaskedimages,recon- structionofthemaskedinputimageisperformed duringinference. unknown detectionisbasedontheLPIPSvaluebetweentheinput imageandthereconstructed image[25]. 6.DDPM-OOD: Usingtheabilityofdiffusion modelstodenoise Gaussiannoiseatvarioussteps.Ininferencestep,Gaussiannoiseis addedtotheinputimageatmultiplelevels,anddenoising iscon- ducted.TheMSEandLPIPSvaluesbetweentheinputandrecon- structedimagesarenormalized usingZ-scoresandsummedfor unknowndetection[24]. Theproposedmethodadoptedastandardarchitecture commonly usedindiffusionmodelresearch[40].Thisarchitecture consistedofa three-layer U-Netwithchanneldimensions of[256,512,784].To integ"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_27", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 27, "text": "nowndetection[24]. Theproposedmethodadoptedastandardarchitecture commonly usedindiffusionmodelresearch[40].Thisarchitecture consistedofa three-layer U-Netwithchanneldimensions of[256,512,784].To integratetheconditionintotheU-Net,weusedaResNet-18 structureas thefeatureextractor fortheinputimage[41].Thiscondition was incorporated intoeveryblockoftheU-Netthroughattentionoperations. Additionally, thetimestepvalueoftheGaussiannoisewasembedded intoa1024-dimensional vectorusingamulti-layer perceptron. The optimizer usedfortrainingwasadaptivemomentestimation (Adam) [42]withalearningrateof0.00001.Alldatasetsweretrainedfor500 epochs,withanoisescheduling ofbetavaluesbetween0.0015and 0.0195,similartotypicaldiffusionmodels[24,43].Thebatchsizewassetto512,andtrainingwasconducted onasingleNVIDIAA100GPU with80GBmemory.Duringinference, asdescribed inSection3,the PLMSsamplerwasusedtoreducethe1000-step generation processof theDDPMsamplerto25stepsforreconstruction. Aspreviously mentioned, traditional unknowndetectionscoreswere notsuitableforWBM.MetricslikeLPIPS,trainedonnaturalimages,or simplepixel-wise differences likeMSE,didnoteffectively capturethe differences betweentheinputandreconstructed WBMdata"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_28", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 28, "text": "wndetectionscoreswere notsuitableforWBM.MetricslikeLPIPS,trainedonnaturalimages,or simplepixel-wise differences likeMSE,didnoteffectively capturethe differences betweentheinputandreconstructed WBMdata.Therefore, weproposed anunknown detection scoredthatsimultaneously capturedpixel-level changesandWBM-specific patternchanges,defined asfollows: d¬àÃÇ20 n¬à1Œ±‚â°Reconpixel\u0000 x0C}x0Cn) ¬á 1\u0000Œ±¬Ü‚â°ReconWBM\u0000patterns\u0000 x0C}x0Cn) C‚Äô (4) where Œ±isthedefectivechipratioofasinglewafer,asshowninFig.5.x0 represents theinputimage,while}x0Cndenoteseachimageofrecon- structedimagesgenerated according tothenoisescale,asillustrated in Fig.2.Theerrorsbetweentheinputimageandthereconstructed image, ReconpixelandReconWBM\u0000patterns,aredefinedasfollows. Reconpixel xC}x¬Ü¬à‚Ä°x\u0000}x‚Ä°2C‚Äô (5) ReconWBM\u0000patterns xC}x¬Ü¬àÃÇ l1 HlWlÃÇ hCw‚Ä°wl¬©\u0000 ml hw\u0000}ml hw) ‚Ä°2 2C‚Äô(6) wheremdenotesthefeaturemapsofimagexintheResNet-18 archi-Table2 AUROCperformance forunknowndefectpatterndetectionacross36scenarioscomparing theproposedWigDMwithsixothermethods.Scenarios1to7focusonthe detectionofsingle-type defectpatterns;Scenarios8to20focusonthedetectionof2mixed-type defectpatterns;Scenarios21to32addressthedetectionof3mixed- typedefectpatterns;andScenarios33"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_29", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 29, "text": "cenarios1to7focusonthe detectionofsingle-type defectpatterns;Scenarios8to20focusonthedetectionof2mixed-type defectpatterns;Scenarios21to32addressthedetectionof3mixed- typedefectpatterns;andScenarios33to36focusonthedetectionof4mixed-type defectpatterns.Thebestperformance ishighlighted inbold,andthesecond-best performance isunderlined. No. Training datasetUnknown defectpattern Likelihood Ano GANAutoencoder MemAE LMD DDPM-OOD WigDM (Proposed) 1 D,EL,ER,L,S,NF Center(C) 0.493 0.631 0.625 0.630 0.539 0.665 0.619 2 C,EL,ER,L,S,NF Donut(D) 0.716 0.704 0.730 0.759 0.674 0.865 0.908 3 C,D,ER,L,S,NF Edge-loc(EL) 0.520 0.593 0.550 0.633 0.680 0.623 0.793 4 C,D,EL,L,S,NF Edge-ring (ER) 0.801 0.749 0.788 0.778 0.538 0.806 0.900 5 C,D,EL,ER,S,NF Loc(L) 0.452 0.465 0.424 0.558 0.755 0.625 0.857 6 C,D,EL,ER,L,NF Scratch(S) 0.409 0.350 0.560 0.506 0.742 0.447 0.846 7 C,D,EL,ER,L,S Near-full(NF) 0.920 0.939 0.647 0.640 0.768 0.986 0.992 8 D,ER,L,S,NF C¬áEL 0.996 0.934 0.896 0.880 0.841 0.992 0.997 9 D,ER,L,S,NF C¬áER 0.994 0.980 0.901 0.916 0.830 0.996 0.998 10 D,EL,ER,S,NF C¬áL 0.995 0.940 0.898 0.947 0.968 0.998 0.998 11 D,EL,ER,L,NF C¬áS 0.967 0.942 0.937 0.860 0.951 0.995 0.997 12 C,ER,L,S,NF D¬áEL 0"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_30", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 30, "text": ",L,S,NF C¬áER 0.994 0.980 0.901 0.916 0.830 0.996 0.998 10 D,EL,ER,S,NF C¬áL 0.995 0.940 0.898 0.947 0.968 0.998 0.998 11 D,EL,ER,L,NF C¬áS 0.967 0.942 0.937 0.860 0.951 0.995 0.997 12 C,ER,L,S,NF D¬áEL 0.997 0.917 0.864 0.856 0.912 0.999 0.999 13 C,EL,L,S,NF D¬áER 0.992 0.955 0.903 0.899 0.925 0.999 0.999 14 C,EL,ER,S,NF D¬áL 0.990 0.949 0.879 0.901 0.930 1.000 1.000 15 C,EL,ER,L,NF D¬áS 0.991 0.960 0.882 0.933 0.929 1.000 1.000 16 C,D,ER,S,NF EL¬áL 0.983 0.918 0.907 0.909 0.907 0.995 0.998 17 C,D,ER,L,NF EL¬áS 0.984 0.963 0.922 0.917 0.867 0.998 0.996 18 C,D,EL,S,NF ER¬áL 0.991 0.976 0.891 0.883 0.881 0.995 0.998 19 C,D,EL,L,NF ER¬áS 0.985 0.929 0.920 0.921 0.879 0.998 0.996 20 C,D,EL,ER,NF L¬áS 0.995 0.941 0.876 0.903 0.866 0.999 1.000 21 D,ER,S,NF C¬áEL¬áL 0.961 0.923 0.850 0.879 0.918 0.972 0.982 22 D,ER,L,NF C¬áEL¬áS 0.940 0.919 0.901 0.922 0.910 0.959 0.988 23 D,EL,S,NF C¬áER¬áL 0.933 0.938 0.899 0.920 0.922 0.956 0.989 24 D,EL,L,NF C¬áER¬áS 0.958 0.936 0.870 0.887 0.943 0.962 0.991 25 D,EL,ER,NF C¬áL¬áS 0.994 0.956 0.967 0.985 0.980 1.000 1.000 26 C,ER,S,NF D¬áEL¬áL 0.937 0.949 0.873 0.889 0.956 0.962 0.994 27 C,ER,L,NF D¬áEL¬áS 0.921 0.902 0.897 0.908 0.944 0.977 0.995 28 C,EL,S,NF D¬áER¬áL 0.918 0.9"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_31", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 31, "text": "¬áL¬áS 0.994 0.956 0.967 0.985 0.980 1.000 1.000 26 C,ER,S,NF D¬áEL¬áL 0.937 0.949 0.873 0.889 0.956 0.962 0.994 27 C,ER,L,NF D¬áEL¬áS 0.921 0.902 0.897 0.908 0.944 0.977 0.995 28 C,EL,S,NF D¬áER¬áL 0.918 0.900 0.915 0.877 0.938 0.962 0.996 29 C,EL,L,NF D¬áER¬áS 0.970 0.943 0.895 0.926 0.940 0.966 0.988 30 C,EL,ER,NF D¬áL¬áS 0.948 0.912 0.924 0.930 0.927 0.968 0.998 31 C,D,ER,NF EL¬áL¬áS 0.956 0.902 0.937 0.923 0.885 0.981 0.989 32 C,D,EL,NF ER¬áL¬áS 0.949 0.933 0.860 0.874 0.931 0.955 0.991 33 D,ER,NF C¬áEL¬áL¬áS 0.908 0.869 0.881 0.878 0.904 0.927 0.945 34 D,EL,NF C¬áER¬áL¬áS 0.907 0.885 0.905 0.911 0.899 0.921 0.915 35 C,ER,NF D¬áEL¬áL¬áS 0.928 0.903 0.912 0.918 0.937 0.955 0.961 36 C,EL,NF D¬áER¬áL¬áS 0.916 0.894 0.923 0.910 0.958 0.950 0.964 AverageAUROC 0.895 0.872 0.845 0.855 0.869 0.926 0.960S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 8 tecture,obtainedthroughaself-supervised learningapproach [44]. Here,handwdenotetheheightandwidthofthefeaturemap,respec- tively,andlrepresents eachlayeroftheResNet-18 inwhichwlcorre- spondstotheweightsofeachlayer.Inthisexperiment, wetreatedallwl asone. Theuseofadata-driven Œ±wasmotivated bytheneedforascorethat reflectedthecharacteristics oftheinput"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_32", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 32, "text": "yeroftheResNet-18 inwhichwlcorre- spondstotheweightsofeachlayer.Inthisexperiment, wetreatedallwl asone. Theuseofadata-driven Œ±wasmotivated bytheneedforascorethat reflectedthecharacteristics oftheinputWBM.Forinstance,detecting patternslike ‚Äúnear-full ‚ÄùrequiredahigherweightforReconpixelbecause ofthesignificance ofpixel-level changes.Conversely, fordefectpatterns like ‚Äúscratch ‚Äùor‚Äúedge-loc, ‚Äùthedetection reliedmoreonthepattern changesbetweentheinputandreconstructed images,necessitating a higherweightforReconWBM\u0000patterns.Toavoidtheneedformanualweight selectionbytheuser,weusedthedefectivechipratio Œ±oftheinput image,asshowninFig.5,todetermine theweightsautomatically. To explainindetail,Fig.5(a)showsanenlargedviewofWBM,whichin- dicatesthattheWBMconsistsofmultipledefectivechipscombined with normalchips. Additionally, byleveraging thebinarydatacharacteristics ofthe WBM,theratioofdefectivechipsinasinglewafercanbecalculated. Thiscanbeperformed bydividingthenumberofdefectivechipsbythe totalnumberofchips.Fig.5(b)presentsthedefectchipratios Œ± calculated forsevendifferent WBMdefectpatternsamples. As mentioned before,inthecaseof‚Äúscratch ‚Äùor‚Äúedge-loc ‚Äùdefectpatterns, Œ±valuesaresmall,whichautomatica"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_33", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 33, "text": "fchips.Fig.5(b)presentsthedefectchipratios Œ± calculated forsevendifferent WBMdefectpatternsamples. As mentioned before,inthecaseof‚Äúscratch ‚Äùor‚Äúedge-loc ‚Äùdefectpatterns, Œ±valuesaresmall,whichautomatically givesahigherweightto ReconWBM\u0000patternsaccording toequation(4). 4.3.Results AsshowninTable2,weevaluated unknowndefectpatterndetection across36scenariosusingtheareaunderthereceiveroperating char- acteristic(AUROC), astandardmetricinout-of-distribution andanom- alydetection taskswherevaluesclosertooneindicatebetter performance. Theproposed method,WigDM,achievedsuperiorper- formancein32outof36scenarios, withanaverageAUROCof0.960, significantly higherthanthenext-bestmethod,DDPM-OOD, whichhad anaverageAUROCof0.926.Particularly inchallenging scenarios involving difficult-to-detect defectpatternssuchas‚Äúedge-loc, ‚Äù‚Äúloc,‚Äù and ‚Äúscratch, ‚ÄùWigDMoutperformed existingmethods,highlighting its practicalrelevance inreal-world applications. InScenarios1to7,whichinvolvesingledefectpatternsasun- knowns,WigDMshowedremarkable performance, particularly insce- narioswhereothermethodsstruggled. Forinstance, inScenario3 (‚Äúedge-loc ‚Äù),WigDMachievedanAUROCof0.793,whileothermethods likeLikelihood andAutoencoder"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_34", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 34, "text": "DMshowedremarkable performance, particularly insce- narioswhereothermethodsstruggled. Forinstance, inScenario3 (‚Äúedge-loc ‚Äù),WigDMachievedanAUROCof0.793,whileothermethods likeLikelihood andAutoencoder scored0.520and0.550,respectively. Thisindicatesasubstantial improvement indetecting the‚Äúedge-loc ‚Äù defect,whichisoftenchallenging becauseofitssubtlefeaturesand similarity tootherpatterns.Similarly, inScenario5(‚Äúloc‚Äù),WigDM achievedanAUROCof0.857,significantly outperforming theother methods,withthehighestAUROCamongthembeing0.755byLMD. InScenario6(‚Äúscratch ‚Äù),WigDMachievedanAUROCof0.846,while theothermethodshadconsiderably lowerscores,withLikelihood at 0.409andDDPM-OOD at0.447.Theseresultshighlight WigDM ‚Äôs effectiveness indetecting difficultdefectpatterns,demonstrating its practicalrelevance inreal-world applications wheresuchdefectsmay havesignificant implications forproductquality. InScenarios8to20,whichfocuson2mixed-type defectpatterns common inpractical settingsbecause ofthecomplexity of manufacturing processes, WigDMconsistently yieldedsuperiorperfor- mance.Forexample,inScenarios14and15,WigDMachievedperfect AUROCscoresof1.000indetecting ‚ÄúD¬áL‚Äùand‚ÄúD¬áS‚Äùdefectpatterns. InScenarios8to2"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_35", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 35, "text": "of manufacturing processes, WigDMconsistently yieldedsuperiorperfor- mance.Forexample,inScenarios14and15,WigDMachievedperfect AUROCscoresof1.000indetecting ‚ÄúD¬áL‚Äùand‚ÄúD¬áS‚Äùdefectpatterns. InScenarios8to20,WigDM ‚ÄôsAUROCscoresrangedfrom0.996to 1.000,consistently outperforming othermethodsthatshowedmore variability intheirperformance. Thisconsistent highperformance sug- geststhatWigDMisrobustinhandlingtheincreasedcomplexity intro- ducedbymixeddefectpatterns,effectively capturing thenuancesthatarisewhenmultipledefectsoccursimultaneously. Moreover, inScenarios21to32,involving3mixed-type defectpat- terns,andScenarios33to36,involving 4mixed-type defectpatterns, WigDMcontinued tooutperform othermethods. InScenarios25, WigDMachievedperfectAUROCscoresof1.000,demonstrating its abilitytodetectevenhighlycomplexdefectcombinations. Inthemost complexscenariosinvolving mixeddefectpatterns,suchasScenarios 33,35,and36,WigDMconsistently achievedthehighestAUROCscores, rangingfrom0.945to0.964.Forexample,inScenario33,WigDM scored0.945,outperforming DDPM-OOD, whichscored0.927.Simi- larly,inScenario36,WigDMachieved0.964compared toDDPM-OOD ‚Äôs 0.950.However, inScenario34,WigDM ‚ÄôsAUROCof0.915wasslightly belowDDP"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_36", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 36, "text": "ario33,WigDM scored0.945,outperforming DDPM-OOD, whichscored0.927.Simi- larly,inScenario36,WigDMachieved0.964compared toDDPM-OOD ‚Äôs 0.950.However, inScenario34,WigDM ‚ÄôsAUROCof0.915wasslightly belowDDPM-OOD ‚Äôsscoreof0.921.TheseresultshighlightWigDM ‚Äôs abilitytomaintainhighdetection performance eveninchallenging scenarioswithmultiplemixed-type patterns.Thisstrengthdemonstrates WigDM ‚Äôseffectiveness inhandlingcomplexdefectdistributions, making itareliablechoiceforreal-world applications. AsshowninTable3,wedemonstrated thesuperiority ofourpro- posedunknowndetectionscoredcompared totraditional metricslike MSEandLPIPS.WhileMSEorLPIPSperformed betterdepending onthe defectpattern,ourproposed dcalculated thescoreinadata-driven mannerbasedontheinputimage.Additionally, byusingafeature mapdistancespecifically modifiedforWBM,ourmethodachievedsu- periorperformance acrossvariousdefectpatterns.Additionally, as mentioned inEquation(6),weusedafeaturemapdistancespecifically modifiedforWBM.Here,mdenotesthefeaturemapsfromaResNet-18 architecture thatwasseparately trainedusingaself-supervised learning method[44]ontheWM-811K dataset,allowingourmethodtoachieve superiorperformance acrossvariousdefectpattern"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_37", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 37, "text": "efeaturemapsfromaResNet-18 architecture thatwasseparately trainedusingaself-supervised learning method[44]ontheWM-811K dataset,allowingourmethodtoachieve superiorperformance acrossvariousdefectpatterns. Thereasonsforthesuperiorperformance oftheproposedmethodare illustrated inFig.6.Inthisexample,thedatasetsettingofScenario6was used,withdetailedinformation presented ontheleftsideofFig.6. Specifically, bothDDPM-OOD andWigDMweretrainedusingthe trainingdatasetfromScenario6.Theredlinerepresents thedenoising processoftheconventional DDPM-OOD, whilethebluelinedepictsthe denoising processofWigDM.Typically, asthenoisestepincreasesandt growslarger,theinformation fromtheinputimagetendstobelost, leadingtoahigherprobability ofrandomly reconstructing oneofthe imagesfromthetrainingdataset.Therefore, theDDPM-OOD oftenre- constructs patternsthatdifferfromtheinputimagebutmatchonefrom thetrainingset.Toaddressthisissue,WigDM,whichusesaninput- guidance diffusionmodel,maintains animagesimilartotheinput imageevenatnoisestepsashighas990.Inaddition,becausetheun- knowndetection scoreisbasedonthepixelandpatternchangesbe- tweentheinputimageandthereconstructed image,thescoreremains low,allowingthedatatobeclassi"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_38", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 38, "text": "evenatnoisestepsashighas990.Inaddition,becausetheun- knowndetection scoreisbasedonthepixelandpatternchangesbe- tweentheinputimageandthereconstructed image,thescoreremains low,allowingthedatatobeclassifiedasaknowndefectpattern.ThisTable3 AUROCperformance ofWigDMonnon-mixed unknowndefectpatternscenarios usingMSE,LPIPS,andproposedunknown detectionscore d.Thebestperfor- manceishighlighted inbold. No.Training datasetUnknown defect patternMSELPIPS d(unknown detectionscore) 1D,EL,ER,L, S,NFCenter(C) 0.5570.6230.619 2C,EL,ER,L, S,NFDonut(D) 0.7250.740 0.908 3C,D,ER,L,S, NFEdge-loc(EL) 0.4600.656 0.793 4C,D,EL,L,S, NFEdge-ring (ER) 0.5410.688 0.900 5C,D,EL,ER, S,NFLoc(L) 0.3590.747 0.857 6C,D,EL,ER, L,NFScratch(S) 0.2360.820 0.846 7C,D,EL,ER, L,SNear-full(NF) 0.9550.853 0.992S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 9 robustperformance isattributed toWigDM‚Äôsabilitytoeffectively pre- servetheinputimagecharacteristics throughout thedenoising process, whichisparticularly crucialforaccurateunknown defectpattern detectionincomplexandmixeddefectpatternscenarios. AsshowninTable4,theinferencetimesforlikelihood, LMD,DDPM- OOD,andWigDM,whicharebasedondiffusionmodels,werelonge"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_39", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 39, "text": "rucialforaccurateunknown defectpattern detectionincomplexandmixeddefectpatternscenarios. AsshowninTable4,theinferencetimesforlikelihood, LMD,DDPM- OOD,andWigDM,whicharebasedondiffusionmodels,werelonger thanthoseforAnoGAN, autoencoder, andMemAE.However, consid- eringthatthemaximum numberofwafersproducible inasemi- conductor manufacturing lineis1000perday,thetotalinferencetime perdayforWigDMwas3.97h,assuming1000waferswereproduced eachday.Therefore, althoughtheinferencetimewaslongercompared toothermodels,itwasfeasibletoinspecttheentiredailyproduction of wafersinapracticalsetting.Hence,applyingthehighest-performing WigDMcouldeffectively replacethemanuallaborofengineers. 5.Conclusion Inthisstudy,wepresentWigDM,aconditional diffusionmodelfor detectingunknowndefectpatternsinWBMwithouttheneedforlabeled data.Ourapproach integrates WBM-specific inputguidanceintothe denoising process,allowingthemodeltopreservethecharacteristics of theinputimagewhileeffectively differentiating betweenknownand unknownpatterns.Experimental resultsonWM-811KandMixedWM38 datasetsconfirmtherobustness andsuperiority ofWigDMacrossmul- tiplescenarios. Byreducingthedependence onlabeleddata,WigDM addresses asignificant c"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_40", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 40, "text": "ownpatterns.Experimental resultsonWM-811KandMixedWM38 datasetsconfirmtherobustness andsuperiority ofWigDMacrossmul- tiplescenarios. Byreducingthedependence onlabeleddata,WigDM addresses asignificant challenge inthefield. Despiteitssuperiorperformance, WigDMhasseverallimitations. Onedrawback isthehightrainingcostassociated withdiffusionmodels compared tootherCNN-based models,necessitating carefulcalculation ofeconomic benefitsandcostsforpracticalapplications. Additionally, becauseofthenatureofdiffusionmodels,theinferenceprocessinvolves time-consuming denoising throughpredictednoise.Althoughthisstudy usesthePLMSsamplertoreduceinferencetime,itremainsachallenging issue.Nevertheless, asmentioned inSection4.3,itisfeasibletoinspect allwafersproduced inactualsemiconductor manufacturing processes withinareasonable amountoftime.Recently, aone-stepgeneration diffusionmodelknownastheconsistency model[45]hasbeenstudied. Futureresearchshouldfocusonapplyingthismethodtofurtherreduce inferencetime.Inaddition,futureresearchwillexplorethepotentialof integrating semi-supervised learningtechniques, suchasactivelearning intoourframework. Whileourcurrentmethodoperatesinafullyun- supervised setting,theinc"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_41", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 41, "text": "dition,futureresearchwillexplorethepotentialof integrating semi-supervised learningtechniques, suchasactivelearning intoourframework. Whileourcurrentmethodoperatesinafullyun- supervised setting,theinclusion ofasmallamountoflabeleddata throughactivelearningcouldimprovedetection performance and facilitatemoreefficientlabeling,particularly forchallenging defect patterns.Moreover, weplantoimprovethemodelbyincludingvisually indistinguishable samples,suchastherandomclass,toevaluateits performance inmorecomplexandrealisticscenarios. Thisexpansion aimstofurtherenhancetheapplicability andeffectiveness ofWigDMin diversereal-world conditions. CRediTauthorship contribution statement SeokhoMoon:Writing ‚Äìoriginaldraft,Visualization, Software, Methodology, Investigation, Formalanalysis,Datacuration,Conceptu- alization. SeoungBumKim:Writing ‚Äìreview &editing,Validation,Supervision, Resources, Projectadministration, Fundingacquisition. Funding Thisresearchwassupported byBrainKorea21FOUR,theMinistryof ScienceandICT(MSIT)inKoreaundertheITRCsupportprogramsu- pervisedbytheInstituteforInformation Communication Technology PlanningandEvaluation (IITP-2020-0-01749), theNationalResearch Foundation ofKoreagra"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_42", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 42, "text": "ienceandICT(MSIT)inKoreaundertheITRCsupportprogramsu- pervisedbytheInstituteforInformation Communication Technology PlanningandEvaluation (IITP-2020-0-01749), theNationalResearch Foundation ofKoreagrantfundedbytheKoreagovernment (RS-2022- 00144190), Culture,SportsandTourismR&DProgramthroughthe KoreaCreativeContentAgencygrantfundedbytheMinistryofCulture, SportsandTourismin2024(Project Name:Development ofAI-based large-scale automatic gameverification technology toimprovegame production verification efficiency forsmallandmedium-sized game companies, ProjectNumber:RS-2024-00393500, Contribution Rate: 100%),andKoreaPlanning &Evaluation InstituteofIndustrial Tech- nology(RS-2024-00426183). Declaration ofcompeting interest Theauthorsdeclarethattheyhavenoknowncompeting financial interestsorpersonalrelationships thatcouldhaveappearedtoinfluence theworkreportedinthispaper. Acknowledgments Theauthorswouldliketoexpresstheirsinceregratitudetotheeditor andanonymous reviewers fortheirvaluablefeedbackandconstructive suggestions, whichhavesignificantly contributed toimproving the qualityandclarityofthismanuscript. Theirthoughtful comments and recommendations wereinstrumental inrefiningouranalysisa"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_43", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 43, "text": "kandconstructive suggestions, whichhavesignificantly contributed toimproving the qualityandclarityofthismanuscript. Theirthoughtful comments and recommendations wereinstrumental inrefiningouranalysisand presentation. Dataavailability Allresearchdataarepubliclyavailable at:https://www.kaggle. com/datasets/qingyi/wm811k-wafer-map, https://www.kaggle.com/ datasets/co1d7era/mixedtype-wafer-defect-datasets. References [1]H.Casper,A.Rexford,D.Riegel,A.Robinson, E.Martin,M.Awwad,Theimpactof thecomputerchipsupplyshortage,in:Proceedings oftheinternational conference onindustrial engineering andoperations management, Bangalore, India,2021,pp. 236‚Äì245. [2]R.Nikandish, E.Blokhina, D.Leipold,R.B.Staszewski, Semiconductor quantum computing: towardaCMOSquantumcomputeronchip,IEEENanatechnol. Mag.15 (6)(2021)8‚Äì20. [3]J.Shim,S.Cho,E.Kum,S.Jeong,Adaptivefaultdetectionframework forrecipe transition insemiconductor manufacturing, Comput.Ind.Eng.161(Nov.2021), https://doi.org/10.1016/j.cie.2021.107632. [4]H.Chun,J.Wang,J.Kim,C.Lee,Waferparticleinspection technique using computer visionbasedonacolorspacetransform model,Int.J.Adv.Manuf. Technol.127(11‚Äì12)(2023)5063‚Äì5071. [5]J.Yu,S.Han,C.-O.Lee,Defectinspe"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_44", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 44, "text": ".Chun,J.Wang,J.Kim,C.Lee,Waferparticleinspection technique using computer visionbasedonacolorspacetransform model,Int.J.Adv.Manuf. Technol.127(11‚Äì12)(2023)5063‚Äì5071. [5]J.Yu,S.Han,C.-O.Lee,Defectinspection insemiconductor imagesusingFAST- MCDmethodandneuralnetwork, Int.J.Adv.Manuf.Technol.129(3)(2023) 1547‚Äì1565. [6]S.-K.-S.Fan,C.-Y.Hsu,C.-H.Jen,K.-L.Chen,L.-T.Juan,Defectivewaferdetection usingadenoising autoencoder forsemiconductor manufacturing processes, Adv. Eng.Inf.46(2020),101166.Table4 Inferencetimeperwafer,maximum numberofmanufactured wafersperday,andtotalinferencetimeperdayacrosssevenmethods. Likelihood Ano GANAutoencoder MemAE LMD DDPM-OOD WigDM (Proposed) Inferencetime/wafer (seconds)11.7 3.5 1.0 1.3 13.9 13.1 14.3 Maximum numberofmanufactured wafers/day 1000 1000 1000 1000 1000 1000 1000 Totalinferencetime/day (hours)3.25 0.97 0.28 0.36 3.86 3.64 3.97S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 10 [7]H.-W.Xu,W.Qin,J.-H.Hu,Y.-N.Sun,Y.-L.Lv,J.Zhang,ACopulanetwork deconvolution-based directcorrelation disentangling framework forexplainable faultdetectioninsemiconductor waferfabrication, Adv.Eng.Inf.59(2024), 102272. [8]J.Kim,H.Kim,J.Park,K.Mo,P.Kang,Bi"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_45", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 45, "text": "anetwork deconvolution-based directcorrelation disentangling framework forexplainable faultdetectioninsemiconductor waferfabrication, Adv.Eng.Inf.59(2024), 102272. [8]J.Kim,H.Kim,J.Park,K.Mo,P.Kang,Bin2Vec:Abetterwaferbinmapcoloring schemeforcomprehensible visualization andeffectivebadwaferclassification, Appl.Sci.9(3)(2019)597. [9]M.H.Hansen,V.N.Nair,D.J.Friedman, Monitoring wafermapdatafrom integrated circuitfabrication processesforspatiallyclustereddefects, Technometrics 39(3)(1997)241‚Äì253. [10]D.-H.Lee,J.-K.Yang,C.-H.Lee,K.-J.Kim,Adata-driven approachtoselectionof criticalprocessstepsinthesemiconductor manufacturing processconsidering missingandimbalanced data,J.Manuf.Syst.52(2019)146‚Äì156. [11]N.Yu,Q.Xu,H.Wang,Waferdefectpatternrecognition andanalysisbasedon convolutional neuralnetwork, IEEETrans.Semicond. Manuf.32(4)(2019) 566‚Äì573. [12]H.Kang,S.Kang,Astackingensembleclassifierwithhandcrafted and convolutional featuresforwafermappatternclassification, Comput.Ind.129 (2021),103450. [13]W.Shin,H.Kahng,S.B.Kim,Mixup-based classification ofmixed-type defect patternsinwaferbinmaps,Comput.Ind.Eng.167(2022),107996. [14]M.G.Kwak,Y.J.Lee,S.B.Kim,SWaCo:safewaferbinmapclassification withs"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_46", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 46, "text": "[13]W.Shin,H.Kahng,S.B.Kim,Mixup-based classification ofmixed-type defect patternsinwaferbinmaps,Comput.Ind.Eng.167(2022),107996. [14]M.G.Kwak,Y.J.Lee,S.B.Kim,SWaCo:safewaferbinmapclassification withself- supervised contrastive learning, IEEETrans.Semicond. Manuf.36(3)(Aug.2023) 416‚Äì424,https://doi.org/10.1109/TSM.2023.3280891 . [15]M.Saqlain,Q.Abbas,J.Y.Lee,Adeepconvolutional neuralnetworkforwafer defectidentification onanimbalanced datasetinsemiconductor manufacturing processes, IEEETrans.Semicond. Manuf.33(3)(Aug.2020)436‚Äì444,https://doi. org/10.1109/TSM.2020.2994357 . [16]X.Zheng,S.Zheng,Y.Kong,J.Chen,Recentadvancesinsurfacedefectinspection ofindustrial productsusingdeeplearningtechniques, Int.J.Adv.Manuf.Technol. 113(2021)35‚Äì58. [17]Y.Ji,J.-H.Lee,UsingGANtoimproveCNNperformance ofwafermapdefecttype classification: yieldenhancement, in:202031stannualSEMIadvanced semiconductor manufacturing conference (ASMC),IEEE,2020,pp.1‚Äì6. [18]J.Li,R.Tao,R.Chen,Y.Chen,C.Zhao,X.Huang,Sample-imbalanced wafermap defectsclassification basedonauxiliaryclassifierdenoising diffusionprobability model,Comput.Ind.Eng.192(2024),110209. [19]J.Jang,M.Seo,C.O.Kim,Supportweightedensemblemodelforopenset reco"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_47", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 47, "text": "nced wafermap defectsclassification basedonauxiliaryclassifierdenoising diffusionprobability model,Comput.Ind.Eng.192(2024),110209. [19]J.Jang,M.Seo,C.O.Kim,Supportweightedensemblemodelforopenset recognition ofwafermapdefects,IEEETrans.Semicond. Manuf.33(4)(2020) 635‚Äì643. [20]M.Chu,S.Park,J.Jeong,K.Joo,Y.Lee,J.Kang,Recognition ofunknownwafer defectviaoptimalbinembedding technique, Int.J.Adv.Manuf.Technol.121(5) (2022)3439 ‚Äì3451. [21]J.Jang,G.T.Lee,Decisionfusionapproachfordetectingunknownwaferbinmap patternsbasedonadeepmultitasklearningmodel,ExpertSyst.Appl.215(2023), 119363. [22]I.Baek,S.B.Kim,Contrastive deepclustering fordetectingnewdefectpatternsin waferbinmaps,Int.J.Adv.Manuf.Technol.(2024)1‚Äì11. [23]J.Yang,K.Zhou,Y.Li,andZ.Liu, ‚ÄúGeneralized out-of-distribution detection: a survey, ‚ÄùarXivpreprintarXiv:2110.11334 ,2021. [24]M.S.Graham,W.H.L.Pinaya,P.-D.Tudosiu,P.Nachev,S.Ourselin,J.Cardoso, Denoising diffusionmodelsforout-of-distribution detection, in:Proceedings ofthe IEEE/CVF Conference onComputer VisionandPatternRecognition, 2023,pp. 2947 ‚Äì2956.[25]Z.Liu,J.P.Zhou,Y.Wang,andK.Q.Weinberger, Unsupervised out-of-distribution detectionwithdiffusioninpainting, in:International Conf"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_48", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 48, "text": "erence onComputer VisionandPatternRecognition, 2023,pp. 2947 ‚Äì2956.[25]Z.Liu,J.P.Zhou,Y.Wang,andK.Q.Weinberger, Unsupervised out-of-distribution detectionwithdiffusioninpainting, in:International Conference onMachine Learning, PMLR,2023,pp.22528 ‚Äì22538. [26]M.-J.Wu,J.-S.-R.Jang,J.-L.Chen,Wafermapfailurepatternrecognition and similarity rankingforlarge-scale datasets,IEEETrans.Semicond. Manuf.28(1) (2014)1‚Äì12. [27]J.Wang,C.Xu,Z.Yang,J.Zhang,X.Li,Deformable convolutional networksfor efficientmixed-type waferdefectpatternrecognition, IEEETrans.Semicond. Manuf. 33(4)(2020)587‚Äì596. [28]C.M.Bishop,Noveltydetectionandneuralnetworkvalidation, IEEProceedings- Vision,ImageandSignalProcessing 141(4)(1994)217‚Äì222. [29]H.Choi,E.Jang,A.A.Alemi, ‚ÄúWaic,butwhy?generative ensembles forrobust anomalydetection, ‚ÄùarXivpreprintarXiv:1810.01392, 2018. [30]J.Ren,etal.,Likelihood ratiosforout-of-distribution detection, Adv.NeuralInf. ProcessSyst.32(2019). [31]P.Kirichenko, P.Izmailov,A.G.Wilson,Whynormalizing flowsfailtodetectout- of-distribution data,Adv.NeuralInf.ProcessSyst.33(2020)20578 ‚Äì20589. [32]D.Gongetal.,Memorizing normality todetectanomaly:memory-augmented deep autoencoder forunsupervised anomal"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_49", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 49, "text": "flowsfailtodetectout- of-distribution data,Adv.NeuralInf.ProcessSyst.33(2020)20578 ‚Äì20589. [32]D.Gongetal.,Memorizing normality todetectanomaly:memory-augmented deep autoencoder forunsupervised anomalydetection, in:Proceedings oftheIEEE/CVF international conference oncomputer vision,2019,pp.1705 ‚Äì1714. [33]S.Choi,H.Lee,H.Lee,M.Lee,Projection regret:reducingbackground biasfor noveltydetectionviadiffusionmodels,AdvNeuralInfProcessSyst36(2024). [34]A.Radfordetal.,Learningtransferable visualmodelsfromnaturallanguage supervision, in:International conference onmachinelearning,PMLR,2021,pp. 8748 ‚Äì8763. [35]A.Rameshetal.,Zero-shot text-to-image generation, in:International conference onmachinelearning,Pmlr,2021,pp.8821 ‚Äì8831. [36]C.Sahariaetal.,Palette:Image-to-image diffusionmodels,in:ACMSIGGRAPH 2022conference proceedings, 2022,pp.1‚Äì10. [37]J.Ho,A.Jain,P.Abbeel,Denoising diffusionprobabilistic models,Adv.NeuralInf. ProcessSyst.33(2020)6840 ‚Äì6851. [38]R.Zhang,P.Isola,A.A.Efros,E.Shechtman, O.Wang,Theunreasonable effectiveness ofdeepfeaturesasaperceptual metric,in:Proceedings oftheIEEE conference oncomputer visionandpatternrecognition, 2018,pp.586‚Äì595. [39]T.Schlegl,P.Seeb ock,S.M.Waldste"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_50", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 50, "text": "Wang,Theunreasonable effectiveness ofdeepfeaturesasaperceptual metric,in:Proceedings oftheIEEE conference oncomputer visionandpatternrecognition, 2018,pp.586‚Äì595. [39]T.Schlegl,P.Seeb ock,S.M.Waldstein, U.Schmidt-Erfurth, andG.Langs, Unsupervised anomalydetectionwithgenerative adversarial networkstoguide markerdiscovery, in:International conference oninformation processing in medicalimaging,Springer,2017,pp.146‚Äì157. [40]R.Rombach, A.Blattmann, D.Lorenz,P.Esser,B.Ommer,High-resolution image synthesiswithlatentdiffusionmodels,in:Proceedings oftheIEEE/CVF conference oncomputer visionandpatternrecognition, 2022,pp.10684 ‚Äì10695. [41]K.He,X.Zhang,S.Ren,J.Sun,Deepresiduallearningforimagerecognition, in: Proceedings oftheIEEEconference oncomputer visionandpatternrecognition, 2016,pp.770‚Äì778. [42]D.P.Kingmam J.Ba,‚ÄúAdam:Amethodforstochastic optimization, 2014,arXiv preprintarXiv:1412.6980. [43]M.S.Grahametal.,Unsupervised 3dout-of-distribution detectionwithlatent diffusionmodels,in:International Conference onMedicalImageComputing and Computer-Assisted Intervention, Springer,2023,pp.446‚Äì456. [44]H.Kahng,S.B.Kim,Self-supervised representation learningforwaferbinmap defectpatternclassification"}
{"id": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf::chunk_51", "source": "Input-guidance diffusion model for unknown defect patterns detection in wafer bin map.pdf", "chunk_index": 51, "text": "l Conference onMedicalImageComputing and Computer-Assisted Intervention, Springer,2023,pp.446‚Äì456. [44]H.Kahng,S.B.Kim,Self-supervised representation learningforwaferbinmap defectpatternclassification, IEEETrans.Semicond. Manuf.34(1)(Feb.2021) 74‚Äì86,https://doi.org/10.1109/TSM.2020.3038165 . [45]Y.Song,P.Dhariwal, M.Chen,I.Sutskever, Consistency models,in:Proceedings of the40thInternational Conference onMachineLearning,2023,pp.32211 ‚Äì32252.S.MoonandS.B.Kim Advanced Engineering Informatics 64 (2025) 103078 11"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_0", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 0, "text": "ResearchArticle Clustering Ensemble for Identifying Defective Wafer Bin Map in Semiconductor Manufacturing Chia-Yu Hsu DepartmentofInformationManagementandInnovationCenterforBigData&DigitalConvergence,YuanZeUniversity, Chungli,Taoyuan32003,Taiwan CorrespondenceshouldbeaddressedtoChia-YuHsu;cyhsu@saturn.yzu.edu.tw Received30October2014;Revised27January2015;Accepted28January2015 AcademicEditor:ChiwoonCho Copyright ¬© 2015 Chia-YuHsu.ThisisanopenaccessarticledistributedundertheCreativeCommonsAttributionLicense,which permitsunrestricteduse,distribution,andreproductioni nanymedium,providedtheoriginalworkisproperlycited. Wafer bin map (WBM) represents specific defect pattern that provides information for diagnosing root causes of low yield in semiconductormanufacturing.Inpractice,mostsemiconductorengineersusesubjectiveandtime-consumingeyeballanalysisto assess WBM patterns. Given shrinking feature sizes and increasing wafer sizes, various types of WBMs occur; thus, relying onhuman vision to judge defect patterns is complex, inconsistent, and unreliable. In this study, a clustering ensemble approach is proposed to bridge the gap, facilitating WBM pattern extraction and assisting engineer to"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_1", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 1, "text": "dge defect patterns is complex, inconsistent, and unreliable. In this study, a clustering ensemble approach is proposed to bridge the gap, facilitating WBM pattern extraction and assisting engineer to recognize systematic defect patterns efficiently. The clustering ensemble approach not only generates diverse clusters in data space, but also integrates them in labelspace.First,themountainfunctionisusedtotransformdatabyusingpatterndensity.Subsequently, k-means and particle swarm optimization (PSO) clustering algorithms are used to generate diversity partitions and various label results. Finally, the adaptive response theory (ART) neural network is used to attain consensus partitions and integration. An experiment was conducted toevaluate the effectiveness of proposed WBMs clustering ensemble approach. Several criterions in terms of sum of squared error, precision, recall, and F-measure were used for evaluating clustering results. The numerical results showed that the proposed approachoutperformstheotherindividualclusteringalgorithm. 1. Introduction To maintain their profitability and growth despite con- tinual technology migration, semiconductor manufacturing companiesprovidewaferma"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_2", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 2, "text": "tperformstheotherindividualclusteringalgorithm. 1. Introduction To maintain their profitability and growth despite con- tinual technology migration, semiconductor manufacturing companiesprovidewafermanufacturingservicesgenerating value for their customers through yield enhancement, costreduction, on-time delivery, and cycle time reduction [ 1,2]. Theconsumermarketrequiresthatsemiconductorproductsexhibiting increasing complexity be rapidly developed anddelivered to market. Technology continues to advance andrequired functionalities are increasing; thus, engineers have a drastically decreased amount of time to ensure yield enhancementanddiagnosedefects[ 3]. The lengthy process of semiconductor manufacturing involves hundreds of steps, in which big data includingthe wafer lot history, recipe, inline metrology measurement,equipmentsensorvalue,defectinspection,andelectricaltestdata are automatically generated and recorded. Semicon-ductorcompaniesexperiencechallengesintegratingbigdatafrom various sources into a platform or data warehouse and lackintelligentanalyticssolutionstoextractusefulmanufac-turing intelligence and support decision making regardingproduction planning, process contro"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_3", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 3, "text": "rious sources into a platform or data warehouse and lackintelligentanalyticssolutionstoextractusefulmanufac-turing intelligence and support decision making regardingproduction planning, process control, equipment monitor-ing, and yield enhancement. Scant intelligent solutions havebeen developed based on data mining, soft computing, andevolutionaryalgorithmstoenhancetheoperationaleffective-nessofsemiconductormanufacturing[ 4‚Äì7]. Circuit probe (CP) testing is used to evaluate each die on the wafer after the wafer fabrication processes. Wafer bin maps (WBMs) represent the results of a CP test and providecrucialinformationregardingprocessabnormalities,facilitating the diagnosis of low-yield problems in semicon-ductor manufacturing. In WBM failure patterns the spatialdependences across wafers express systematic and randomeffects. Various failure patterns are required; these patterntypesfacilitaterapidlyidentifyingtheassociaterootcausesoflow yield [ 8]. Based on the defect size, shape, and location onthewafer,theWBMcanbeexpressedasspecificpatterns Hindawi Publishing Corporation Mathematical Problems in Engineering Volume 2015, Article ID 707358, 11 pages http://dx.doi.org/10.1155/2015/70"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_4", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 4, "text": "ocation onthewafer,theWBMcanbeexpressedasspecificpatterns Hindawi Publishing Corporation Mathematical Problems in Engineering Volume 2015, Article ID 707358, 11 pages http://dx.doi.org/10.1155/2015/707358 2 MathematicalProblemsinEngineering suchasrings,circles,edges,andcurves.Defectivediescaused by random particles are difficult to completely remove andtypically exhibit nonspecific patterns. Most WBM patternsconsistedofasystematicpatternandarandomdefect[ 8‚Äì10]. Inpractice,thousandsofWBMsaregeneratedforinspec- tion and engineers must spend substantial time on pattern judgment rather than determining the assignable causes of low yield. Grouping similar WBMs into the same clustercan enable engineers to effectively diagnose defects. Thecomplicated processes and diverse products fabricated insemiconductormanufacturingcanyieldvariousWBMtypes,makingitdifficulttodetectsystematicpatternsbyusingonlyeyeballanalysis. Clustering analysis is used to partition data into several groups in which the observations are homogeneous withina group and heterogeneous between groups. Clusteringanalysis has been widely applied in applications such asgrouping [ 11] and pattern extraction [ 12]. However, most "}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_5", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 5, "text": "servations are homogeneous withina group and heterogeneous between groups. Clusteringanalysis has been widely applied in applications such asgrouping [ 11] and pattern extraction [ 12]. However, most conventionalclusteringalgorithmsinfluencetheresultbasedon the data type, algorithm parameter settings, and priorinformation. For example, the ùëò-means algorithm is used to analyze substantial amount of data that exhibit time com-plexity [13]. However, the results of the ùëò-means algorithm depend on the initially selected centroid and predefinednumber of clusters. To address the disadvantages of the ùëò- meansalgorithmevolutionarymethodshavebeendevelopedto conduct data clustering such as the genetic algorithm(GA) and particle swarm optimization (PSO) [ 14]. PSO is particularly advantageous because it requires less parameteradjustmentcomparedwiththeGA[ 15]. Combining results by applying distinct algorithms to the same data set or algorithm by using various parametersettings yields high-quality clusters. Based on the criteria ofthe clustering objectives, no individual clustering algorithmis suitable for whole problem and data type. Compared withindividual clustering algorithms, clustering ens"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_6", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 6, "text": "lusters. Based on the criteria ofthe clustering objectives, no individual clustering algorithmis suitable for whole problem and data type. Compared withindividual clustering algorithms, clustering ensembles thatcombine multiple clustering results yield superior clusteringeffectiveness regarding robustness and stability, incorpo-rating conflicting results across partitions [ 16]. Instead of searching for an optimal partition, clustering ensemblescaptureaconsensuspartitionbyintegratingdiversepartitionsfrom various clustering algorithms. Clustering ensembleshave been developed to improve the accuracy, robustness,and stability of clustering; such ensembles typically involvetwo steps. The first step involves generating a basic set ofpartitions that can be similar to or distinct from those ofvarious parameters and cluster algorithms [ 17]. The second step involves combining the basic set of partitions by usinga consensus function [ 18]. However, with the shrinking integratedcircuitfeaturesizeandcomplicatedmanufacturingprocess, the WBM patterns become more complex becauseof various defect density, die size, and wafer rotation. It isdifficult to extract defect pattern by single specific cl"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_7", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 7, "text": "eandcomplicatedmanufacturingprocess, the WBM patterns become more complex becauseof various defect density, die size, and wafer rotation. It isdifficult to extract defect pattern by single specific cluster-ing approach and needs to incorporate different clustering aspectsforvariouscomplicatedWBMpatterns. To bridge the need in real setting, this study proposes a WBMclusteringensembleapproachtofacilitateWBMdefectpattern extraction. First, the target bin value is categorizedinto binary value and the wafer maps are transformed fromtwo-dimensionaltoone-dimensionaldata.Second, ùëò-means and PSO clustering algorithms are used to generate variousdiversity partitions. Subsequently, the clustering results areregarded as label representations to facilitate aggregatingthe diversity partition by using an adaptive response theory(ART) neural network. To evaluate the validity of the pro- posedmethod,anexperimentalanalysiswasconductedusing six typical patterns found in the fabrication of semiconduc-tor wafers. Using various parameter settings, the proposedcluster ensembles that combine diverse partitions instead ofusing the original features outperform individual clusteringmethodssuchas ùëò-meansandPS"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_8", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 8, "text": "wafers. Using various parameter settings, the proposedcluster ensembles that combine diverse partitions instead ofusing the original features outperform individual clusteringmethodssuchas ùëò-meansandPSO. The remainder of this study is organized as follows. Section2 introducesafundamentalWBM. Section3 presents the proposed approach to the WBM clustering problem.Section4 provides experimental comparisons, applying the proposedapproachtoanalyzetheWBMclusteringproblem.Section5 offers a conclusion and the findings and future researchdirectionsarediscussed. 2. Related Work A WBM is a two-dimensional failure pattern. Based onvarious defects types, random, systematic, and mixed fail-ure patterns are primary types of WBMs generated duringsemiconductor fabrication [ 19,20]. Random failure patterns are typically caused by random particles or noises in themanufacturing environment. In practice, completely elimi-nating these random defects is difficult. Systematic failurepatterns show the spatial correlation across wafers such asrings,crescentmoon,edge,andcircles. Figure1showstypical WBMpatternswhicharetransformedintobinaryvaluesforvisualization and analysis. The dies that pass the functionaltes"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_9", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 9, "text": "rrelation across wafers such asrings,crescentmoon,edge,andcircles. Figure1showstypical WBMpatternswhicharetransformedintobinaryvaluesforvisualization and analysis. The dies that pass the functionaltest are denoted as 0 and the defective dies are denoted as1 .B a s e do nt h es y s t e m a t i cp a t t e r n s ,d o m a i ne n g i n e e r sc a nrapidlydeterminetheassignablecausesofdefects[ 8].Mixed failurepatternscomprisetherandomandsystematicdefectsonawafer.Themixedpatterncanbeidentifiedifthedegreeoftherandomdefectisslight. Defect diagnosis of facilitating yield enhancement is critical in the rapid development of semiconductor manu-facturing technology. An effective method of ensuring thatthe causes of process variation are assignable is analyz-ing the spatial defect patterns on wafers. WBMs providecrucial guidance, enabling engineers to rapidly determinethe potential root causes of defects by identifying patterns. Most studies have used neural network and model-based approaches to extract common WBM patterns. Hsu andChien [8] integrated spatial statistical analysis and an ART neural network to conduct WBM clustering and associatedthe patterns with manufacturing defects to facilitat"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_10", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 10, "text": "act common WBM patterns. Hsu andChien [8] integrated spatial statistical analysis and an ART neural network to conduct WBM clustering and associatedthe patterns with manufacturing defects to facilitate defectdiagnosis. In addition to ART neural network, Liu andChien [10] applied moment invariant for shape clustering of WBMs. Model-based clustering algorithms are used toconstruct a model for each cluster and compare the like-lihood values between clusters to identify defect patterns.Wang et al. [ 21] used model-based clustering, applying a Gaussian expectation maximization algorithm to estimatedefectpatterns.HwangandKuo[ 22]modeledglobaldefects 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MathematicalProblemsinEngineering 3 (a) (b) (c) (d) (e) (f) Figure1:TypicalWBMpatterns. and local defects in clusters exhibiting ellipsoidal patterns and local defects in clusters exhibiting linear or curvilinearpatterns. Yuan a"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_11", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 11, "text": "ering 3 (a) (b) (c) (d) (e) (f) Figure1:TypicalWBMpatterns. and local defects in clusters exhibiting ellipsoidal patterns and local defects in clusters exhibiting linear or curvilinearpatterns. Yuan and Kuo [ 23] used Bayesian inference to identify the patterns of spatial defects in WBMs. Drivenby continuous migration of semiconductor manufacturingtechnology, the more complicated types of WBM patternshave been occurred due to the increase of wafer size andshrinkageofcriticaldimensionsonspecificaspectofcomplex WBM pattern and little research has evaluated using the clustering ensemble approach to analyze WBMs and extractfailurepatterns. 3. Proposed Approach The terminologies and notations used in this study are asfollows: ùëÅ ùëî:numberofgrossdies; ùëÅùë§:numberofwafers; ùëÅùëù:numberofparticles; ùëÅùëê:numberofclusters; ùëÅùëè:numberofbaddies; ùëñ:waferindex, ùëñ=1,2,...,ùëÅùë§; ùëó:dimensionindex, ùëó=1,2,...,ùëÅùëî; ùëò:clusterindex, ùëò=1,2,...,ùëÅùëê; ùëô:particleindex, ùëô=1,2,...,ùëÅùëù; ùëû:clusteringresultindex, ùëû=1,2,...,ùëÄ ; ùëü:baddieindex, ùëü=1,2,...,ùëÅùëè; ùë†:c l u s t e r i n gs u b o b j e c t i v ei nP S Oc l u s t e r i n g , ùë†= 1,2,3; ùëà:uniformrandomnumberintheinterval [0,1]; ùúîV:inertiaweightofvelocityupdate; ùúîùë†:weightofclus"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_12", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 12, "text": "ddieindex, ùëü=1,2,...,ùëÅùëè; ùë†:c l u s t e r i n gs u b o b j e c t i v ei nP S Oc l u s t e r i n g , ùë†= 1,2,3; ùëà:uniformrandomnumberintheinterval [0,1]; ùúîV:inertiaweightofvelocityupdate; ùúîùë†:weightofclusteringsubobjective; ùëêùëù:personalbestpositionaccelerationconstants;ùëêùëî:globalbestpositionaccelerationconstants; ùõΩ:anormalizationfactor; ùëö:aconstantforapproximatedensityshapeinmoun- tainfunction; ùë¶ùëü:theùëüthbaddieonawafer; ùëõùëò:thenumberofWBMsinthe ùëòthcluster; ùëõùëôùëò: the number of WBMs in the ùëòth cluster of ùëôth particle; ùê∂ùëò:subsetofWBMsinthe ùëòthcluster; ùë•max:maximumvalueintheWBMdata; mùëò:vectorofthe ùëòthclustercentroid, mùëò=[ ùëöùëò1,ùëöùëò2, ...,ùëöùëòùëÅùëî]; mùëôùëò:vectorcentroidofthe ùëòthclusterof ùëôthparticle; pùëô: vector centroids of the ùëôthparticle, pùëô=[ ùëöùëô1,ùëöùëô2, ...,ùëöùëôùëò]; ùúÉùëôùëó:positionofthe ùëôthparticleatthe ùëóthdimension; ùëâùëôùëó:velocityofthe ùëôthparticleatthe ùëóthdimension; ùúìùëôùëó:personalbestposition( ùëùbest)ofthe ùëôthparticleat ùëóthdimension; ùúìùëîùëó:globalbestposition( ùëîbest)atthe ùëóthdimension; xùëñ:vectorofthe ùëñthWBM, xùëñ=[ ùë•ùëñ1,ùë•ùëñ2,...,ùë•ùëñùëÅùëî]; Œòùëô:v e c t o rp o s i t i o no ft h e ùëôth particle,Œòùëô=[ ùúÉùëô1,ùúÉùëô2, ...,ùúÉùëôùëÅùëî]; Vùëô:v e c t o rv e l o c i t yo ft h e ùëôth particle, Vùëô=[ ùëâùëô1,ùëâùëô2, ...,ùëâùëôùëÅùëî]; ùúìùëô: vector personal best of the ùëôt"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_13", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 13, "text": "2,...,ùë•ùëñùëÅùëî]; Œòùëô:v e c t o rp o s i t i o no ft h e ùëôth particle,Œòùëô=[ ùúÉùëô1,ùúÉùëô2, ...,ùúÉùëôùëÅùëî]; Vùëô:v e c t o rv e l o c i t yo ft h e ùëôth particle, Vùëô=[ ùëâùëô1,ùëâùëô2, ...,ùëâùëôùëÅùëî]; ùúìùëô: vector personal best of the ùëôthparticle,ùúìùëô=[ ùúìùëô1, ùúìùëô2,...,ùúìùëôùëÅùëî]; ùúìùëî:v e c t o rg l o b a lb e s tp o s i t i o n ,ùúìùëî=[ ùúìùëî1,ùúìùëî2,..., ùúìùëîùëÅùëî]. 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 4 MathematicalProblemsinEngineering Consensus partitionFinal clustering resultsWBMs #1clustering #qclustering#2clustering First stage: data space Second stage: label spaceLabels ùúã1Labels ùúã2 Labelsùúãq...... Figure2:AframeworkforWBMsclusteringensemble. 3.1. Problem Definition of WBM Clustering Ensemble. Clus- tering ensembles can be regarded as two-stage partitions, inwhich various clustering algorithms are used to assess thedataspaceatthefirststageandconsensusfunctionisusedtoassess the label space at the second stage. Figure2shows the two-stageclusteringperspective.C"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_14", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 14, "text": "ch various clustering algorithms are used to assess thedataspaceatthefirststageandconsensusfunctionisusedtoassess the label space at the second stage. Figure2shows the two-stageclusteringperspective.Consensusfunctionisusedtodevelopaclusteringcombinationbasedonthediversityoftheclusterlabelsderivedatthefirststage. LetX={x 1,x2,...,xùëÅùë§}denote a set of ùëÅùë§WBMs andŒ†={ ùúã1,ùúã2,...,ùúãùëÄ}denote a set of partitions based onùëÄclustering results. The various partitions of ùúãùëû(ùë•ùëñ) represent a label assigned to ùë•ùëñby theùëûth algorithm. Each label vector ùúãùëûis used to construct a representation Œ†, in which the partitions of Xcomprise a set of labels for each wafer xùëñ,ùëñ = 1,...,ùëÅùë§. Therefore, the difficulty of constructingaclusteringensembleislocatinganewpartitionŒ†that provides a consensus partition satisfying the label informationderivedfromeachindividualclusteringresultofthe original WBM. For each label ùúã ùëû,ab i n a r ym e m b e r s h i p indicatormatrix ùêª(ùëû)isconstructed,containingacolumnfor eachcluster.Allvaluesofarowinthe ùêª(ùëû)aredenotedas1if the row correspondsto an object. Furthermore,the space of a consensus partition changes from the original ùëÅùëîfeatures intoùëÅùë§features. For example, Table 1shows eig"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_15", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 15, "text": "valuesofarowinthe ùêª(ùëû)aredenotedas1if the row correspondsto an object. Furthermore,the space of a consensus partition changes from the original ùëÅùëîfeatures intoùëÅùë§features. For example, Table 1shows eight WBMs grouped using three clustering algorithms ( ùúã1,ùúã2,ùúã3); the threeclusteringresultsaretransformedintoclusteringlabelsthat are transformed into binary representations ( Table 2). Regardingconsensuspartitions,thebinarymembershipindi- cator matrix ùêª (ùëû)is used to determine a final clustering result, using a consensus model based on the eight features(V 1,V2,..., V8). 3.2.DataTransformation. Thebinaryrepresentationofgood and bad dies is shown in Figure3(a) .A l t h o u g ht h i sb i n a r y representation is useful for visualisation, displaying the spa-tialrelationofeachbaddieacrossawaferisdifficult. Toquantifythespatialrelationsandincreasethedensity of a specific feature, the mountain function is used to trans-formthebinaryvalueintoacontinuousvalue.Themountainmethod is used to determine the approximate cluster centerby estimating the probability density function of a feature[24] .I n s t e a do fu s i n gag r i dn o d e ,am o d i fi e dm o u n t a i nTable 1: Original label vectors."}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_16", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 16, "text": " the approximate cluster centerby estimating the probability density function of a feature[24] .I n s t e a do fu s i n gag r i dn o d e ,am o d i fi e dm o u n t a i nTable 1: Original label vectors. ùúã1 ùúã2 ùúã3 x1 111 x2 111 x3 111 x4 221 x5 222 x6 312 x7 312 x8 312 Table2:Binaryrepresentationofclusteringensembles. Clusteringresults V1 V2 V3 V4 V5 V6 V7 V8 ùêª(1)‚Ñé11 11100000 ‚Ñé12 00011000 ‚Ñé13 00000111 ùêª(2) ‚Ñé21 11100111 ‚Ñé22 00011000 ùêª(3) ‚Ñé31 1111 0000 ‚Ñé32 00001111 function can employ data points by using a correlation self- comparison[ 25].Themodifiedmountainfunctionforabad dieùëüonawafer ùëÄ(ùë¶ùëü)isdefinedasfollows: ùëÄ(ùë¶ùëü)=ùëÅùëè ‚àë ùëü=1ùëí‚àíùëöùõΩùëë(ùë¶ùëü,ùë¶ùë†), ùëü=1,2,3,...,ùëÅùëè,(1) where ùõΩ=(ùëë(ùë¶ùëü‚àíùë¶wc) ùëÅùëè)‚àí1 (2) andùëë(ùë¶ùëü,ùë¶ùë†)isthedistancebetweendices ùëüandùë†.Parameter ùõΩis the normalization factor for the distance between bad dieùëüand the wafer centroid ùë¶wc. Parameter ùëöis a constant. Parameter ùëöùõΩdetermines the approximate density shape of thewafer. Figure3(b) showsanexampleofWBMtransforma- tion.Twotypesofdataareusedtogenerateabasicsetofpar-titions. Moreover, each WBM must sequentially transform 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. "}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_17", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 17, "text": "ateabasicsetofpar-titions. Moreover, each WBM must sequentially transform 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MathematicalProblemsinEngineering 5 (1)Randomlyselect ùëòdataasthecentroidofcluster (2)Repeat Foreachdatavector,assigneachdataintothegroupwithrespecttotheclosestcentroidby minimumEuclideandistance. recalculatethenewcentroidbasedonalldatawithinthegroup. endfor (3)Steps1and2areiterateduntilthereisnodatachange. Procedure1: ùëò-meansalgorithm. (a) Binaryvalue 5 10 15 20 25 30 (b) Continuousvalue Figure3:Representationofwaferbinmapbybinaryvalueandcontinuousvalue. from a two-dimensional map into a one-dimensional data vector[8].Suchvectorsareusedtoconductfurtherclustering analysis. 3.3.DiversePartitionsGenerationby ùëò-MeansandPSOClus- tering.Bothùëò-meansandPSOclusteringalgorithmsareused to generate basic partitions.To consider the spatial relationsacrossawafer,boththebinaryandcontinuousvaluesareusedtodeterm"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_18", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 18, "text": "tionby ùëò-MeansandPSOClus- tering.Bothùëò-meansandPSOclusteringalgorithmsareused to generate basic partitions.To consider the spatial relationsacrossawafer,boththebinaryandcontinuousvaluesareusedtodeterminedistinctclusteringresultsbyusing ùëò-meansand PSOclustering.Subsequently,variousnumbersofclustersareusedforcomparison. ùêæ-meansisanunsupervisedmethodofclusteringanaly- sis [13] used to group data into several predefined numbers of clusters by employing a similarity measure such as theEuclidean distance. The objective function of the ùëò-means algorithmistominimizethewithin-clusterdifference,thatis,thesumofthesquareerror(SSE)whichisdeterminedusing(3).Theùëò-meansalgorithmconsistsofthefollowingstepsas showninProcedure 1: SSE= ùëÅùëê ‚àë ùëò=1‚àë xùëñ‚ààùê∂ùëò(xùëñ‚àímùëò)2. (3) Data clustering is regarded as an optimisation problem. PSOisanevolutionaryalgorithm[ 14]whichisusedtosearch for optimal solutions based on the interactions amongstparticles; it requires adjusting fewer parameters comparedwithusingotherevolutionaryalgorithms.vanderMerweandEngelbrecht [ 26] proposed a hybrid algorithm for clustering data, in which the initial swarm is determined using theùëò-meansresultandPSOisusedtorefinetheclusterresults.As i"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_19", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 19, "text": "aryalgorithms.vanderMerweandEngelbrecht [ 26] proposed a hybrid algorithm for clustering data, in which the initial swarm is determined using theùëò-meansresultandPSOisusedtorefinetheclusterresults.As i n g l ep a r t i c l e p ùëôrepresents the ùëòcluster centroid vectors:pùëô=[ ùëöùëô1,ùëöùëô2,...,ùëöùëôùëò]. A swarm defines a number of candidate clusters. To consider the maximal homogeneitywithinaclusterandheterogeneitybetweenclusters,afitnessfunctionisusedtomaximizetheinterclusterseparationandminimizetheintraclusterdistanceandquantisationerror ùëì(p ùëñ,Zùëô)=ùúî1√óùêΩùëí+ùúî2√óùëëmax(pùëô,Zùëô)+ùúî3 √ó( ùëãmax‚àíùëëmin(pùëô)),(4) whereZùëôis a matrix representing the assignment of the WBMs to the clusters of the ùëôth particle. The following quantization error equation is used to evaluate the level ofclusteringperformance: ùêΩ ùëí=‚àëùëÅùëê ùëò=1‚åä‚àë‚àÄxùëñ‚ààùê∂ùëòùëë(xùëñ,ùëöùëò)/ùëõùëò‚åã ùêæ.(5) Inaddition, ùëëmax(pùëñ,Zùëô)=max ùëò=1,2,...,ùëÅùëê[[ [‚àë ‚àÄxùëñ‚ààùê∂ùëôùëòùëë(xùëñ,mùëôùëò) ùëõùëôùëò]] ](6) isthemaximumaverageEuclideandistanceofparticletothe assignedclustersand ùëëmin(pùëô)=min ‚àÄùë¢,V,ùë¢Ã∏=V[ùëë(mùëôùë¢,mùëôV)] (7) is the minimum Euclidean distance between any pair of clusters. Procedure 2shows the steps involved in the PSO clusteringalgorithm. 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/d"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_20", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 20, "text": "(7) is the minimum Euclidean distance between any pair of clusters. Procedure 2shows the steps involved in the PSO clusteringalgorithm. 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 6 MathematicalProblemsinEngineering (1) Initializeeachparticlewith ùëòclustercentroids. (2) Foriteration ùë°=1toùë°=maxdo Foreachparticle ùëôdo Foreachdatapattern xùëñ calculatetheEuclideandistancetoallclustercentroidsandassignpattern xùëñtocluster ùëêùëò whichhastheminimumdistance endfor calculatethefitnessfunction ùëì(pùëñ,Zùëô) endfor findthepersonalbestandglobalbestpositionsofeachparticle.updatetheclustercentroidsbytheupdatevelocityequation(i)andupdatecoordinateequation(ii). V ùëñ(ùë° + 1) = ùúîVVùëñ(ùë°) + ùëêùëùùë¢(ùúìùëô(ùë°) ‚àíŒòùëô(ùë°)) + ùëêùëîùë¢(ùúìùëî(ùë°) ‚àíŒòùëô(ùë°)) (i) Œòùëô(ùë° + 1) =Œòùëô(ùë°) +Vùëô(ùë° + 1) (ii) endfor (3)Step2isiterateduntiltheseisnodatachange Procedure2:PSOclusteringalgorithm. 3.4. Consensus Partition by Adaptive Response Theory. ART hasbeenusedinnumerousareassuchaspatternre"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_21", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 21, "text": "+Vùëô(ùë° + 1) (ii) endfor (3)Step2isiterateduntiltheseisnodatachange Procedure2:PSOclusteringalgorithm. 3.4. Consensus Partition by Adaptive Response Theory. ART hasbeenusedinnumerousareassuchaspatternrecognitionand spatial analysis [ 27]. Regarding the unstable learning conditions caused by new data, ART can be used to addressstability and plasticity because it addresses the balancebetween stability and plasticity, match and reset, and searchand direct access [ 8]. Because the input labels are binary, the ART1 neural network [ 27] algorithm is used to attain a consensuspartitionofWBMs. Theconsensuspartitionapproachisasfollows. Step 1.Applyùëò-means and PSO clustering algorithms and usevariousparameters(e.g.,variousnumbersofclustersandtypesofinputdata)togeneratediverseclusters. Step 2.Transform the original clustering label into binary representationmatrix ùêªasaninputforART1neuralnetwork. Step 3.Apply ART1 neural network to aggregate the diverse partitions. 4. Numerical Experiments In this section, this study conducts a numerical study todemonstrate the effectiveness of the proposed clusteringensemble approach. Six typical WBM patterns from semi- conductor fabrication were used such as m"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_22", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 22, "text": "ection, this study conducts a numerical study todemonstrate the effectiveness of the proposed clusteringensemble approach. Six typical WBM patterns from semi- conductor fabrication were used such as moon, edge, and sector. In the experiments, the percentage of defective diesinsixpatternsisdesignedbasedonrealcases.Withoutlosinggenerality of WBM patterns, the data have been systemati-cally transformed for proprietary information protection ofthe case company. Total 650 chips were exposed on a wafer.Basedonvariousdegreesofnoise,eachpatterntypewasusedtogenerate10WBMsforestimatingthevalidityofproposedclustering ensemble approach. The noise in WBM could becausedfromrandomparticlesacrossawaferandtestbiasinCP test, which result in generating bad die randomly on awafer and generating good die within a group of bad dies. Itm e a n st h a ts o m eb a dd i c e sa r es h o w na sg o o dd i c ea n dt h e1012151823 1522 1370 11841098 945 02004006008001000120014001600 0510152025 0.3 0.4 0.5 0.6 0.7 SSECluster number ART1 vigilance threshold Clustering number SSE Figure4:ComparisonofvariousART1vigilancethreshold. density ofbad die couldbe sparse. Forexample, thevalueof degreeofnoiseis0.02whichrepre"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_23", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 23, "text": "ECluster number ART1 vigilance threshold Clustering number SSE Figure4:ComparisonofvariousART1vigilancethreshold. density ofbad die couldbe sparse. Forexample, thevalueof degreeofnoiseis0.02whichrepresentstotal2%gooddieandbaddiesareinverse. The proposed WBM clustering ensemble approach was compared with ùëò-means, PSO clustering method, and the algorithm proposed by Hsu and Chien [ 8]. Six numbers of clusters were used for single ùëò-means methods and single PSO clustering algorithms. Table 3showed the parameter settingsforPSOclustering.Thenumberofclustersextracted byART1neuralnetworkissensitivetothevigilancethreshold value. The high vigilance threshold is used to produce moreclustersandthesimilaritywithinaclusterishigh.Incontrast,the low vigilance threshold results in fewer numbers ofclusters. However, the similarity within a cluster could below. To compare the parameter setting of ART1 vigilancet h r e s h o l d ,v a r i o u sv a l u e sw e r eu s e da ss h o w ni n Figure4. Each clustering performance was evaluated in terms of theSSE and number of clusters. The SSE is used to compare thecohesionamongstvariousclusteringresults,andasmallSSEindicatesthattheWBMwithinaclusterishighlysimi"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_24", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 24, "text": "ing performance was evaluated in terms of theSSE and number of clusters. The SSE is used to compare thecohesionamongstvariousclusteringresults,andasmallSSEindicatesthattheWBMwithinaclusterishighlysimilar.Thenumber of clusters represents the effectiveness of the WBMgrouping.Accordingtotheobjectiveofclusteringistogroup 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MathematicalProblemsinEngineering 7 Table3:ParametersettingsforPSOclustering. Parameter Value Parameter Value ùëö 20 ùúî 1 ùëãmax1 ùëé1 0.4 ùëêùëù 2 ùëé2 0.3 ùëêùëî 2 ùëé3 0.3 Iteration 500 Table 4: Results of clustering methods by SSE. Methods Noise degree 0.02 0.04 0.06 0.08 0.10 HsuandChien[ 8]1 1 8 4 1 1 9 2 1 2 0 3 1 2 4 8 1 3 2 2 Individual clusteringKB 2889 3092 3003 4083 3570 KC 3331 2490 2603 3169 2603 PB 5893 3601 6566 5839 6308 PC 4627 4873 3330 3787 6112 Clustering ensembleKBandPB 1827 1280 1324 1801 2142 KC and PC 2272 2363 2400 1509 1718 KBandPC 1368 1459 2400 "}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_25", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 25, "text": " 3570 KC 3331 2490 2603 3169 2603 PB 5893 3601 6566 5839 6308 PC 4627 4873 3330 3787 6112 Clustering ensembleKBandPB 1827 1280 1324 1801 2142 KC and PC 2272 2363 2400 1509 1718 KBandPC 1368 1459 2400 1509 2597 KC and PB 2100 2048 1421 1928 2043 KBandPBand KC and PC1586 1550 1541 1571 1860 the WBM into few clusters in which the similarities among the WBMs within a cluster are high as possible. Therefore,t h es e t t i n go fA R T 1v i g i l a n c et h r e s h o l dv a l u ei su s e da s0 . 5 0inthenumericalexperiments. WBM clustering is to identify the similar type of WBM intothesamecluster.ToconsideronlysixtypesofWBMsthatwere used in the experiments, the actual number of clustersshouldbesix.BasedonthevariousdegreeofnoiseinWBMgeneration as shown in Table 4,severalindividualclustering methods including ART1 [ 8],ùëò-means clustering, and PSO clustering were used for evaluating clustering performance.Table 4shows that the ART1 neural network yielded a lower SSE compared with the other methods. However, the ART1neuralnetworkseparatestheWBMinto15clustersasshowninFigure5. The ART1 neural network yields unnecessary partitions for the similar type of WBM pattern. In order togeneratediversecl"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_26", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 26, "text": "ds. However, the ART1neuralnetworkseparatestheWBMinto15clustersasshowninFigure5. The ART1 neural network yields unnecessary partitions for the similar type of WBM pattern. In order togeneratediverseclusteringpartitionsforclusteringensemblemethod, four combinations with various data scale and clustering algorithms including ùëò-means by binary value (KB),ùëò-means by continuous value (KC), PSO by binary value (PB), and PSO by continuous value (PC) are used.Regardless of the individual clustering results based on sixnumbers of clusters, using ùêæ-means clustering and PSO clustering individually yielded larger SSE values than usingART1only. Table 4also shows the clustering ensembles that use various types of input data. For example, the clusteringensemblemethodKB&PBintegratesthesixresultsincludingtheùëò-means algorithm by three kinds of clusters (i.e., ùëò= 5,6,7) and PSO clustering by three kinds of clusters (i.e., ùëò=5 , 6 , 7 ), respectively, to form the WBM clustering viaGroup 1 Group 2 Group 3 Group 4 Group 5 Group 6 Group 7 Group 8 Group 9 Group 10 Group 11 Group 12 Group 13 Group 14 Group 15 Figure5:ClusteringresultbyART1(15clusters). labelspace.Ingeneral,theclusteringensemblesdemonstrate"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_27", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 27, "text": "Group 4 Group 5 Group 6 Group 7 Group 8 Group 9 Group 10 Group 11 Group 12 Group 13 Group 14 Group 15 Figure5:ClusteringresultbyART1(15clusters). labelspace.Ingeneral,theclusteringensemblesdemonstrate smaller SSE values than do individual clustering algorithmssuchasthe ùëò-meansorPSOclusteringalgorithms. In addition to compare the similarity within the cluster, anindexcalledspecificitywasusedtoevaluatetheefficiency oftheevolvedclusteroverrepresentingthetrueclusters[ 28]. Thespecificityisdefinedasfollows: specificity =ùë° ùëê ùëáùëí, (8) whereùë°ùëêisthenumberoftrueWBMpatternscoveredbythe numberofevolvedWBMpatternsand ùëáùëíisthetotalnumber of evolved WBM patterns. As shown in the ART1 neuralnetworkclusteringresults,thetotalnumberofevolvedWBMclusters is 15 and number of true WBM clusters is 6. Then,the specificity is 0.4. Table 5shows the results of specificity 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 8 MathematicalProblemsinE"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_28", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 28, "text": "onditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 8 MathematicalProblemsinEngineering (a) (b) (c) (d) (e) (f) Figure6:SixtypesofWBMpatterns. Table5:Resultsofclusteringmethodsbyspecificity. Methods Noise degree 0.02 0.04 0.06 0.08 0.10 HsuandChien[ 8] 0.4 0.4 0.4 0.4 0.4 Individual clusteringKB 1.0 1.0 1.0 1.0 1.0 KC 1.0 1.0 1.0 1.0 1.0 PB 1.0 1.0 1.0 1.0 1.0 PC 1.0 1.0 1.0 1.0 1.0 Clustering ensembleKBandPB 0.7 0.5 0.5 0.5 0.8 KC and PC 0.5 0.8 0.9 0.8 0.6 KBandPC 0.5 0.7 0.9 0.8 0.7 KC and PB 0.9 0.5 0.5 0.6 0.7 KBandPBand KC and PC1.0 0.9 0.9 0.9 1.0 amongclusteringmethods.TheART1neuralnetworkhasthe lowest specificity due to the large number of clusters. Thespecificityofindividualclusteringis1becausethenumberofevolvedWBMpatternsisfixedas6.Furthermore,comparedwith individual clustering algorithms, combining variousclustering ensembles yields not only smaller SSE values, butalso smaller numbers of clusters. Thus, the homogeneitywithin a cluster can be improved using proposed approach.The threshold of ART1 neural network yields maximal clus-ter numbers. Theref"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_29", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 29, "text": " values, butalso smaller numbers of clusters. Thus, the homogeneitywithin a cluster can be improved using proposed approach.The threshold of ART1 neural network yields maximal clus-ter numbers. Therefore, the proposed clustering ensembleapproach considering diversity partitions has better resultsregarding the SSE and number of clusters than individualclusteringmethods. To evaluate the results among various clustering ensem- bles and to assess cluster validity, WBM class labels areemployed based on six pattern types as shown in Figure6.Thus,theindicesincludingprecisionandrecallaretwoclassi- fication-orientedmeasures[ 29]definedasfollows: precision =TP TP+FP, recall=TP TP+FN,(9) where TP (true positive) is the number of WBMs correctly classifiedintoWBMpatterns,FP(falsepositive)isthenum-ber of WBMs incorrectly classified, and FN (false negative)isthen umberofWBMstha tneedtobeclassified,butnottobe determined incorrectly. The precision measure is used toassess how many WBMs classified as Pattern (a) are actuallyPattern (a). The recall measure is used to assess how manysamplesofPattern(a)arecorrectlyclassified. However, a trade-off exists between precision and recall; therefore, when one"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_30", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 30, "text": "ttern (a) are actuallyPattern (a). The recall measure is used to assess how manysamplesofPattern(a)arecorrectlyclassified. However, a trade-off exists between precision and recall; therefore, when one of these measures increases, the otherdecreases.The ùêπ-measureisaharmonicmeanoftheprecision andrecallwhichisdefinedasfollows: ùêπ=2√óprecision √órecall precision +recall=2TP FP+FN+2TP.(10) Specifically, the ùêπ-measure represents the interaction between the actual and classification results (i.e., TP). If theclassificationresultisclosetotheactualvalue,the ùêπ-measure ishigh. Tables6,7,a n d8show a summary of various metrics amongsixtypesofWBMinprecision,recall,and ùêπ-measure, respectively. As shown in Figure6, Patterns (b) and (c) are similar in the wafer edge, demonstrating smaller averageprecisionandrecallvaluescomparedwiththeotherpatterns.Theclusteringensembles which generatepartitionsby usingùëò-means make it difficult to identify in both Patterns (b) and (c). Using a mountain function transformation enables 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_31", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 31, "text": "tion enables 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MathematicalProblemsinEngineering 9 Table6:Clusteringresultontheindexofprecision. HsuandChien[ 8]Clusteringensemble KBandPB KCandPC KBandPC KCandPB KBandPBandKCandPC PrecisionA 0.70 0.84 0.92 0.92 0.92 0.98 B 0.50 0.66 0.96 0.92 0.62 0.96 C 0.60 0.64 1.00 1.00 0.60 1.00 D 0.70 0.98 0.92 0.92 0.98 1.00 E 0.60 0.94 0.82 0.82 0.98 0.98 F 0.80 0.98 0.76 0.76 0.98 0.98 Avg. 0.65 0.84 0.90 0.89 0.85 0.98 Table7:Clusteringresultontheindexofrecall. HsuandChien[ 8]Clusteringensemble KBandPB KCandPC KBandPC KCandPB KBandPBandKCandPC RecallA 1.00 1.00 1.00 0.93 1.00 1.00 B 1.00 0.97 0.7 0.78 0.83 1.00 C 1.00 0.94 0.67 0.84 0.67 0.97 D 1.00 0.81 1.00 1.00 1.00 1.00 E 1.00 0.79 1.00 1.00 1.00 1.00 F 1.00 1.00 1.00 1.00 1.00 1.00 Avg. 1.00 0.92 0.90 0.93 0.92 1.00 Table8:Clusteringresultontheindexof ùêπ-measure. HsuandChien[ 8]Clusteringensemble KBandPB KCandPC KBandPC K"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_32", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 32, "text": "0 0.79 1.00 1.00 1.00 1.00 F 1.00 1.00 1.00 1.00 1.00 1.00 Avg. 1.00 0.92 0.90 0.93 0.92 1.00 Table8:Clusteringresultontheindexof ùêπ-measure. HsuandChien[ 8]Clusteringensemble KBandPB KCandPC KBandPC KCandPB KBandPBandKCandPC ùêπ-measureA 0.82 0.91 0.96 0.92 0.96 0.99 B 0.67 0.79 0.81 0.84 0.71 0.98 C 0.75 0.76 0.8 0.91 0.63 0.98 D 0.82 0.89 0.96 0.96 0.99 1.00 E 0.75 0.86 0.90 0.90 0.99 0.99 F 0.89 0.99 0.86 0.86 0.99 0.99 Avg. 0.78 0.87 0.88 0.90 0.88 0.99 consideringthedefectdensityofthespatialrelationsbetween thegoodandbaddiesacrossawafer.Basedonthe ùêπ-measure, the clustering ensembles obtained using all generated parti- tions exhibit larger precision and recall values and superior levelsofperformanceregardingeachpatterncomparedwith the other methods. Thus, the partitions generated by usingùëò-means and PSO clustering in various data types must be considered. Th ep r a c t i c a lv i a b i l i t yo ft h ep r o p o s e da p p r o a c hw a s examined. The results show that the ART1 neural network performingintodataspacedirectlyleadstoworseclustering performanceintermsofprecision.However,thetruetypesofW B Mc a nb ei d e n t i fi e dt h r o u g ht r a n s f o r m i n go r i g i n a ld a "}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_33", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 33, "text": "network performingintodataspacedirectlyleadstoworseclustering performanceintermsofprecision.However,thetruetypesofW B Mc a nb ei d e n t i fi e dt h r o u g ht r a n s f o r m i n go r i g i n a ld a t a space into label space and performing consensus partition by ART1 neural network. The proposed cluster ensembleapproach can get better performance with fewer numbers of clusters than other conventional clustering approaches including ùëò-means, PSO clustering, and ART1 neural net- work.5. Conclusion WBMs provide important information for engineers torapidly find the potential root cause by identifying patternscorrectly. As the driven force for semiconductor manufac-turingtechnology,WBMidentificationtothecorrectpatternbecomes more difficult because the same type of patterns isinfluencedbyvariousfactorssuchasdiesize,patterndensity, and noise degree. Relying on only engineers‚Äô experiences of visual inspections and personal judgments in the mappatternsisnotonlysubjective,andinconsistent,butalsoverytime-consuming and inefficient. Therefore, grouping similarWBM quickly helps engineer to use more time to diagnosetherootcauseoflowyield. Considering the requirements of clustering WBMs in prac"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_34", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 34, "text": "lsoverytime-consuming and inefficient. Therefore, grouping similarWBM quickly helps engineer to use more time to diagnosetherootcauseoflowyield. Considering the requirements of clustering WBMs in practice, a cluster ensemble approach was proposed tofacilitate extracting the common defect pattern of WBMs,enhancing failure diagnosis and yield enhancement. Theadvantage of the proposed method is to yield high-qualityclusters by applying distinct algorithms to the same data 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 10 MathematicalProblemsinEngineering set and by using various parameter settings. The robustness of clustering ensemble is higher than individual clusteringmethodbecausetheclusteringfromvariousaspectsincludingalgorithmsandparametersettingisintegratedintoaconsen-susresult. The proposed clustering ensemble has two stages. At the first stage, diversity partitions are generated using two types ofinputdata:v"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_35", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 35, "text": "ingalgorithmsandparametersettingisintegratedintoaconsen-susresult. The proposed clustering ensemble has two stages. At the first stage, diversity partitions are generated using two types ofinputdata:variousclusternumbersanddistinctclusteringalgorithms. At the second stage, a consensus partition isattained using these diverse partitions. The numerical anal-ysis demonstrated that the clustering ensemble is superiorto using individual ùëò-means or PSO clustering algorithms. The results demonstrate that the proposed approach caneffectively group the WBMs into several clusters based ontheirsimilarityinlabelspace.Thus,engineerscanhavemoret i m et of o c u st h ea s s i g n a b l ec a u s eo fl o wy i e l di n s t e a do fextractingdefectpatterns. Clustering is an exploratory approach. In this study, we assume that the number of clusters is known. Evaluatingtheclustering ensemble approach, prior information is requiredregarding the cluster numbers. Further research can be con-ductedregardingself-tuningtheclusternumberinclusteringensembles. Conflict of Interests The author declares that there is no conflict of interestsregardingthepublicationofthispaper. Acknowledgment Th i sr e s e a r c hi"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_36", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 36, "text": "f-tuningtheclusternumberinclusteringensembles. Conflict of Interests The author declares that there is no conflict of interestsregardingthepublicationofthispaper. Acknowledgment Th i sr e s e a r c hi ss u p p o r t e db yN a t i o n a lS c i e n c eC o u n c i l ,Taiwan (NSC 102-2221-E-155-093; MOST 103-2221-E-155- 029-MY2).TheauthorwouldliketothankMr.Tsu-AnChao for his kind assistance. The author also wishes to thankthe editors and two anonymous referees for their insightfulcommentsandsuggestions. References [1] R.C.Leachman,S.Ding,andC.-F.Chien,‚ÄúEconomicefficiency analysisofwaferfabrication,‚Äù IEEETransactionsonAutomation ScienceandEngineering ,vol.4,no .4,pp .501 ‚Äì512,2007 . [2] C.-F. Chien and C.-H. Chen, ‚ÄúA novel timetabling algorithm for a furnace process for semiconductor fabrication with con-strained waiting and frequency-based setups,‚Äù OR Spectrum , vol.29,no.3,pp.391‚Äì419,2007. [3] C.-F. Chien, W.-C. Wang, and J.-C. Cheng, ‚ÄúData mining for yield enhancement in semiconductor manufacturing and anempirical study,‚Äù Expert Systems with Applications ,v o l .3 3 ,n o . 1,pp.192‚Äì198,2007. [4] C.-F. Chien, Y.-J. Chen, and J.-T. Peng, ‚ÄúManufacturing intelli- genceforsemiconductordem"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_37", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 37, "text": "nufacturing and anempirical study,‚Äù Expert Systems with Applications ,v o l .3 3 ,n o . 1,pp.192‚Äì198,2007. [4] C.-F. Chien, Y.-J. Chen, and J.-T. Peng, ‚ÄúManufacturing intelli- genceforsemiconductordemandforecastbasedontechnology diffusion and product life cycle,‚Äù International Journal of Pro- ductionEconomics ,vol.128,no .2,pp .496‚Äì509 ,2010. [5] C.-J. Kuo, C.-F. Chien, and J.-D. Chen, ‚ÄúManufacturing intel- ligence to exploit the value of production and tool data to reduce cycle time,‚Äù IEEE Transactions on Automation Science andEngineering ,vol.8,no.1,pp.103‚Äì111,2011.[6] C.-F.Chien,C.-Y.Hsu,andC.-W.Hsiao,‚ÄúManufacturingintelli- gencetoforecastandreducesemiconductorcycletime,‚Äù Journal ofIntelligentManufacturing ,vol.23,no .6,pp .2281 ‚Äì2294,2012. [7] C.-F. Chien, C.-Y. Hsu, and P.-N. Chen, ‚ÄúSemiconductor fault detection and classification for yield enhancement and man- ufacturing intelligence,‚Äù Flexible Services and Manufacturing Journal,vol.25,no .3,pp .367 ‚Äì388,2013. [8] S.-C. Hsu and C.-F. Chien, ‚ÄúHybrid data mining approach for patternextractionfromwaferbinmaptoimproveyieldinsemi- conductor manufacturing,‚Äù International Journal of Production Economics ,vol.107,no.1,pp.88‚Äì103,2007."}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_38", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 38, "text": ".-F. Chien, ‚ÄúHybrid data mining approach for patternextractionfromwaferbinmaptoimproveyieldinsemi- conductor manufacturing,‚Äù International Journal of Production Economics ,vol.107,no.1,pp.88‚Äì103,2007. [9] C.-F. Chien, S.-C. Hsu, and Y.-J. Chen, ‚ÄúA system for online detectionandclassificationofwaferbinmapdefectpatternsformanufacturingintelligence,‚Äù InternationalJournalofProduction Research,vol.51,no .8,pp .2324‚Äì2338,2013. [10] C.-W.LiuandC.-F.Chien,‚ÄúAnintelligentsystemforwaferbin map defect diagnosis: an empirical study for semiconductormanufacturing,‚Äù Engineering Applications of Artificial Intelli- gence,vol.26,no .5-6,pp .1479‚Äì1486,2013. [11] C.-F. Chien and C.-Y. Hsu, ‚ÄúA novel method for determining machine subgroups and backups with an empirical study for semiconductormanufacturing,‚Äù Journal of Intelligent Manufac- turing,vol.17 ,no .4,pp .429‚Äì439 ,2006. [12] K.-S. Lin and C.-F. Chien, ‚ÄúCluster analysis of genome-wide expression data for feature extraction,‚Äù Expert Systems with Applications ,vol.36,no.2,pp.3327‚Äì3335,2009. [13] J. A. Hartigan and M. A. Wong, ‚ÄúA K-means clustering algo- rithm,‚ÄùAppliedStatistics ,vol.28,no .1,pp .100‚Äì108,1979 . [14] J. Kennedy and R. C. Eberhart, ‚Äú"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_39", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 39, "text": "ications ,vol.36,no.2,pp.3327‚Äì3335,2009. [13] J. A. Hartigan and M. A. Wong, ‚ÄúA K-means clustering algo- rithm,‚ÄùAppliedStatistics ,vol.28,no .1,pp .100‚Äì108,1979 . [14] J. Kennedy and R. C. Eberhart, ‚ÄúParticle swarm optimization,‚Äù inProceedings of the IEEE International Conference on Neural Networks,pp.1942‚Äì1948,December1995. [15] D. W. Boeringer and D. H. Werner, ‚ÄúParticle swarm optimiza- tionversusgeneticalgorithmsforphasedarraysynthesis,‚Äù IEEE Transactions on Antennas and Propagation ,v o l .5 2 ,n o .3 ,p p . 771‚Äì779,2004. [16] A.StrehlandJ.Ghosh,‚ÄúClusterensembles‚Äîaknowledgereuse framework for combining multiple partitions,‚Äù The Journal of MachineLearningResearch ,vol.3,no .3,pp .583‚Äì617 ,2002. [17] A. L. V. Coelho, E. Fernandes, and K. Faceli, ‚ÄúMulti-objective design of hierarchical consensus functions for clustering ensemblesviageneticprogramming,‚Äù DecisionSupportSystems , vol.51,no .4,pp .794‚Äì809 ,2011. [18] A. Topchy, A. K. Jain, and W. Punch, ‚ÄúClustering ensembles: models of consensus and weak partitions,‚Äù IEEE Transactions onPatternAnalysisandMachineIntelligence ,vol.27 ,no .12,pp . 1866‚Äì1881,2005. [19] C. H. Stapper, ‚ÄúLSI yield modeling and process monitoring,‚Äù IBM Journa"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_40", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 40, "text": "nsensus and weak partitions,‚Äù IEEE Transactions onPatternAnalysisandMachineIntelligence ,vol.27 ,no .12,pp . 1866‚Äì1881,2005. [19] C. H. Stapper, ‚ÄúLSI yield modeling and process monitoring,‚Äù IBM Journal of Research and Development ,v o l .2 0 ,n o .3 ,p p . 228‚Äì234,1976. [20] W. Taam and M. Hamada, ‚ÄúDetecting spatial effects from factorial experiments: an application from integrated-circuit manufacturing,‚Äù Technometrics ,vol.35,no.2,pp.149‚Äì160,1993. [21] C.-H. Wang, W. Kuo, and H. Bensmail, ‚ÄúDetection and clas- sification of defect patterns on semiconductor wafers,‚Äù IIE Transactions ,vol.38,no.12,pp.1059‚Äì1068,2006. [22] J.Y.HwangandW.Kuo,‚ÄúModel-basedclusteringforintegrated circuit yield enhancement,‚Äù European Journal of Operational Research,vol.178,no .1,pp .143‚Äì153,2007 . [23] T.YuanandW.Kuo,‚ÄúSpatialdefectpatternrecognitiononsemi- conductor wafers using model-based clustering and Bayesian inference,‚Äù European Journal of Operational Research ,v o l .1 9 0 , no.1,pp.228‚Äì240,2008. 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-condition"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_41", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 41, "text": "015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License MathematicalProblemsinEngineering 11 [24] R. R. Yager and D. P. Filev, ‚ÄúApproximate clustering via the mountain method,‚Äù IEEE Transactions on Systems, Man and Cybernetics ,vol.24,no .8,pp .1279‚Äì1284,1994. [25] M.-S. Yang and K.-L. Wu, ‚ÄúA modified mountain clustering algorithm,‚Äù PatternAnalysisandApplications ,vol.8,no.1 -2,pp. 125‚Äì138,2005. [26] D. W. van der Merwe and A. P. Engelbrecht, ‚ÄúData cluster- ing using particle swarm optimization,‚Äù in Proceedings of the Congress on Evolutionary Computation (CEC ‚Äô03) , pp. 215‚Äì220, December2003. [27] G.A.CarpenterandS.Grossberg,‚ÄúTheARTofadaptivepattern recognition by a self-organization neural network,‚Äù Computer , vol.21,no.3,pp.77‚Äì88,1988. [28] C. Wei and Y. Dong, ‚ÄúA mining-based category evolution approach to managing online document categories,‚Äù in Pro- ceedingsofthe34thAnnualHawaiiInternationalConferenceon System Sciences ,J anu"}
{"id": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf::chunk_42", "source": "Mathematical Problems in Engineering - 2015 - Hsu - Clustering Ensemble for Identifying Defective Wafer Bin Map in.pdf", "chunk_index": 42, "text": "988. [28] C. Wei and Y. Dong, ‚ÄúA mining-based category evolution approach to managing online document categories,‚Äù in Pro- ceedingsofthe34thAnnualHawaiiInternationalConferenceon System Sciences ,J anuary2001. [29] L. Rokach and O. Maimon, ‚ÄúData mining for improving the quality of manufacturing: a feature set decomposition approach,‚Äù JournalofIntelligentManufacturing ,vol.17 ,no.3,pp. 285‚Äì299,2006. 2629, 2015, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2015/707358, Wiley Online Library on [12/09/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_0", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 0, "text": "On Performance Binning of Multi-core Processors John Sartori‚Ä†, Ashish Pant‚Ä°, Rakesh Kumar‚Ä†, Puneet Gupta‚Ä° ‚Ä†Coordinated Science Laboratory‚Ä°Electrical Engineering Department 1308 West Main St University of California, Los Angeles Urbana, IL 61801 Los Angeles, CA 90095-1594 Abstract‚ÄîNumber of cores per multi-core processor die, as well as variation between the maximum operating frequency of ind ividual cores, is rapidly increasing. This makes performance binni ng of multi- core processors a non-trivial task. In this paper, we study m ulti-core binning metrics and strategies to evaluate them efÔ¨Åciently . We also show that variation model aware binning can signiÔ¨Åcantly reduce the binning overhead with a negligible loss in binning quality. I. INTRODUCTION Performance (or speed) binning refers to test procedures to Ô¨Ånd out the maximum operating frequency of a processor. It is com mon practice to speed bin processors for graded pricing. In the c ase of uniprocessors, performance of a processor strongly correl ated with its frequency of operation. For multi-core processors, how ever, the appropriate binning metrics are much less clear. ‚Ä¢Because of large number of cores per die and increasin"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_1", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 1, "text": " strongly correl ated with its frequency of operation. For multi-core processors, how ever, the appropriate binning metrics are much less clear. ‚Ä¢Because of large number of cores per die and increasing proce ss variations [5][1], it is unlikely that the maximum operatin g frequencies of all cores would be similar. Therefore, if bin ning is done according to lowest common operating frequency of all cores (one obvious extension to the uniprocessor binnin g metric), it would be highly pessimistic. ‚Ä¢Time overhead for binning is an important metric and a choice needs to be made between the correlation to performance and binning overhead for multi-core processors. In this paper, we discuss two binning metrics and quantify th eir correlation with absolute performance and time overhead. W e also show that the process variation model itself can be used to co me up with binning strategies that take much less time for binning without signiÔ¨Åcantly sacriÔ¨Åcing correlation to performance. II. MODELING VARIATION An accurate physically justiÔ¨Åable model of spatial variabi lity is very important to reliably predict and leverage core-to-co re variation in the binning process. We use a polynomial varia"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_2", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 2, "text": "G VARIATION An accurate physically justiÔ¨Åable model of spatial variabi lity is very important to reliably predict and leverage core-to-co re variation in the binning process. We use a polynomial variation model s imilar to ones proposed in [2], [3], [4] having three components: (1 ) systematic (bowl-shaped) across wafer variation1; (2) random core- to-core variation (arising from random within-die variati on); and (3) random die-to-die variation (e.g., from wafer-to-wafer or lot-to-lot variation). Vd(x,y) =A(Xc+x)2+B(Yc+y)2+C(Xc+x) (1) +D(Yc+y)+E(Xc+x)(Yc+y)+F+R+M whereVd(x,y)is the variation of parameter dat die location x,y; Xc,Ycare the wafer coordinates of the center of the die ( (0,0) is center of wafer); x,yare die coordinates of a point within the die;Mis the die-to-die variation and Ris the random core-to-core variation. A,B,C,D,E,Fare Ô¨Åtted coefÔ¨Åcients for systematic across- wafer variation. We use a Ô¨Åtted model as above based on real 1An example physical source of across-wafer bowl-shaped var iation can be plasma etch.silicon data from a 45nm industrial process .2The goal of the binning process is to bin a chip into one of nbins (where nis decided based on business reason"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_3", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 3, "text": "r bowl-shaped var iation can be plasma etch.silicon data from a 45nm industrial process .2The goal of the binning process is to bin a chip into one of nbins (where nis decided based on business reasons) in light of the above vari ation model. III. BINNINGMETRICS In this section, we discuss two simple binning metrics that recognize the frequency effects of process variation. A. Min-Max and Œ£f Min-max stands for the minimum of the maximum frequencies for various cores of a chip multiprocessor. The min-max metr ic is computed with equation 2, where nrepresents the number of frequency bins, mrepresents the number of processor cores, and fijis a successful test frequency or 0 if core j fails the ithtest. minmax =min[max[fij|n i=1|m j=1 (2) The second binning metric that we look at is Œ£fwhich ranks processors based on maximum attainable throughput [6] (eve ry core operating at its maximum frequency). Œ£f=m ‚àë j=1max[fij|n i=1 (3) In terms of correlation of the metric with the throughput of the chip, min-max is a conservative metric and, therefore, s hould demonstrate good correlation only for workloads with regul ar par- titioning in which the load is distributed evenly between al l cores."}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_4", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 4, "text": " chip, min-max is a conservative metric and, therefore, s hould demonstrate good correlation only for workloads with regul ar par- titioning in which the load is distributed evenly between al l cores. For other workloads that have inherent heterogeneity or tha t are multiprogrammed, Œ£fshould demonstrate good correlation. To compare the two metrics, consider the asymptotic case of v ery largenandmand completely random core-to-core variation (i.e., A, B, C, D,E, F, M all zero in equation 1). In this simpliÔ¨Åed cas e, Œ£fconverges to m√ómeanfrequency whileminmaxconverges to (E(Mini=1...‚àûfi) =0, i.e., we expect the minmax to be a progres- sively worse metric as number of cores in a die increases or th e variation increases. B. Binning Overhead To calculate binning overhead for min-max for nfrequency bins andmcores, we use binary search3to Ô¨Ånd out fmaxfor every core. However, the search range will reduce progressively. The worst case arises when fmaxfor every core is 1 binsize less than the previously found fmaxfor the last core. In this case, the worst-case tests that need to be performed can be computed as (log(n!)+m‚àín) (assuming m‚â•n). The best case binning overhead for min-max would be "}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_5", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 5, "text": "eviously found fmaxfor the last core. In this case, the worst-case tests that need to be performed can be computed as (log(n!)+m‚àín) (assuming m‚â•n). The best case binning overhead for min-max would be m. Calculating the average-case binning overhead for min- max for our binning strategy is fairly involved since test ti me of 2For this model mean = 4GHz, œÉbowl=0.128GHz, œÉR=0.121GHz, œÉM= 0.09GHz. 3In this work, we assume that if a core works at a certain freque ncy, it is guaranteed to work at frequencies below it. This stems from t he speciÔ¨Åc case of using binary search in conjunction with minmax metric. Th e constraint can be easily avoided by adding one more test per core(i.e., t esting it at the minmax frequency coreidepends on minmax frequency seen for the Ô¨Årst i‚àí1 cores. Assuming nto be large enough for us to approximate (testable) frequency distribution as continuous, the average test tim e can be derived as T=E(Œ£i=1...mlog(min(x1...xi)) =E(Œ£i=1...mlog(i√óf(x)√ó(1‚àíF(x))i‚àí1) wheref(x)andF(x)are PDF and CDF of the core frequency distribution respectively. To best of our knowledge no clos ed form expressions are known for the above. We therefore show the av erage case testing time b"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_6", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 6, "text": "andF(x)are PDF and CDF of the core frequency distribution respectively. To best of our knowledge no clos ed form expressions are known for the above. We therefore show the av erage case testing time by our experiments rather than analytical expres- sions. Tofullyevaluate the Œ£fmetric,the maximum operating frequency of each core must be learned. Using a binary search, this proc ess performs, on the worst, m√ólogntests. The best case is still mtests. The average case binning overhead is m√ó(logn‚àí1).4 IV. USINGVARIATION MODEL TO REDUCEBINNINGOVERHEAD In this section, we argue that the overhead of binning can be considerably reduced by making the binning strategies vari ation model-aware. fmaxof acorecanbestronglypredicted(i.e.meanwith standard deviation around it) based on the process variatio n model. Therefore, process variation model can give a smaller frequ ency range within which the search should be done. A. Curve Fitting The curve-Ô¨Åtting strategy involves approximating the expe cted frequency (in GHz) as well as the standard deviation ( =/radicalbig (œÉ2 M+ œÉ2 R)) of a core given its location within a die and die location wit hin the wafer using the variation model (equation 1). T"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_7", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 7, "text": "frequency (in GHz) as well as the standard deviation ( =/radicalbig (œÉ2 M+ œÉ2 R)) of a core given its location within a die and die location wit hin the wafer using the variation model (equation 1). Therefore , we can identify center (= mean) as well as corners (= +/- kœÉ) of the search range. If the core falls out of this range (decided by k), we assume lowest frequency bin for the core. This reduces both the aver age and worst-case test time for the core. B. Clustering Another strategy for reducing the binning overhead can be cl uster- ingthe cores ina chipmultiprocessor andthen usingmin-max within the cluster (low binning overhead advantage) while using Œ£famong the clusters (high correlation to maximum throughput advan tage). To further reduce the overhead of binning, a process like curve Ô¨Åtting can be applied where the process variation model is used to id entify the search range for fmaxof a core. In order to improve the performance correlation within the c luster (especially when across-wafer variations are high), clust ers can also be chosen intelligently to minimize frequency variation (a nd hence loss of correlation) within a cluster. To this end, the clust er size can be s"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_8", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 8, "text": "across-wafer variations are high), clust ers can also be chosen intelligently to minimize frequency variation (a nd hence loss of correlation) within a cluster. To this end, the clust er size can be set to be inversely proportional to the spread of frequenc y mean (calculated from the bowl-shape in equation 1) within the cl uster. In general, the dies close to the center of the bowl (typically c lose to the center of wafer) will see clusters of large sizes, while c lusters are smaller for the dies closer to the edge of the wafer. We do not evaluate variable clustering in this paper due to the rel atively low across-wafer variations that our current process varia tion models suggest. 4Note that this expression and the expressions for minmax ign ore the bias introduced in binary search by the probability distributio n of the frequencies themselves.TABLE I Benchmarks used Program Description ammp Computational Chemistry (SPEC) crafty Game Playing:Chess (SPEC) eon Computer Visualization (SPEC) mcf Combinatorial Optimization (SPEC) twolf Place and Route Simulator (SPEC) mgrid Multi-grid Solver: 3D Potential Field (SPEC) mesa 3-D Graphics Library (SPEC) groff Typesetting package (IBS) de"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_9", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 9, "text": "PEC) mcf Combinatorial Optimization (SPEC) twolf Place and Route Simulator (SPEC) mgrid Multi-grid Solver: 3D Potential Field (SPEC) mesa 3-D Graphics Library (SPEC) groff Typesetting package (IBS) deltablue Constraint Hierarchy Solver (OOCSB) adpcmc Adaptive Differential PCM (MediaBench) V. METHODOLOGY We model chip multiprocessors with various number of cores o n the die for different technologies. Each core is a dual issue Alpha 21064-like inorder core with 16KB, 2-way set-associative I cache and DCache. Each core (1 mm2at 45nm) on a multiprocessor has a private 1MB L2 cache (0 .33MB/mm2at 45nm). We assumed a gshare branch-predictor with 8k entries for all the cores. T he various miss penalties and L2 cache access latencies for the simulat ed cores were determined using CACTI [7]. We model the area consumpti on of the processors for different technologies using the meth odology in [8]. We considered two types of workloads - multiprogrammed work - loads and parallel workloads. Table I lists the ten benchmar ks used for constructing multiprogrammed workloads. The benchmar ks are chosen from different suites (SPEC,IBS, OOCSB, and Mediabe nch) for diversity. Three parallel applicati"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_10", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 10, "text": "I lists the ten benchmar ks used for constructing multiprogrammed workloads. The benchmar ks are chosen from different suites (SPEC,IBS, OOCSB, and Mediabe nch) for diversity. Three parallel applications (CG, FT, MG) are chosen from the NAS benchmark suite and run to completion. The class B implementations are run. Multiprogrammed workloads are created using the sliding wi n- dow methodology in [10]. For multiprogrammed workloads, th e performance of a multiprocessor is assumed to be the sum of th e performance of each core of the multiprocessor derated by a c onstant factor. The methodology is accurate for our case where each c ore is assumed to have a private L2 cache and a memory controller [8] . The methodology was shown to be reasonable for our benchmark s even for processors with shared L2 [8] due to the derating fac tor. Parallel applications as mentioned before are run to comple tion. Simulations are done for 250 million cycles for cores runnin g at different frequencies given by the variation model, afte r fast- forwarding an appropriate number of instructions [9]. Simu lations use a modiÔ¨Åed version of SMTSIM [10]. VI. ANALYSIS OF RESULTS We run Monte-Carlo simulations usi"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_11", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 11, "text": "by the variation model, afte r fast- forwarding an appropriate number of instructions [9]. Simu lations use a modiÔ¨Åed version of SMTSIM [10]. VI. ANALYSIS OF RESULTS We run Monte-Carlo simulations using 100,000 dies, each die being a 64 core processor (256 mm2) in a 45nm technology 300mm wafer, binned using 8 frequency bins. Figure 1 shows the binning overhead and throughput correlat ion for different number of frequency bins for multiprogrammed work- loads. Correlation is calculated using 100,000 data points (processor dies) between the average of the maximum throughput of the va rious multiprogrammed workloads on a processor (where cores run a t different frequencies dictated by the variation model) and the value of the metric when following a given binning strategy. Note t hat performance of a thread often does not vary linearly with fre quency due to pipeline hazards, memory accesses, etc., so correlat ion will unlikely be 1 for any binning metric. There are several things to note in the graph. First, Œ£fhas a signiÔ¨Åcantly better correlation to throughput than minmaxfor multiprogrammed workloads. This is not surprising conside ring that throughput of a thread often depends on th"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_12", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 12, "text": "in the graph. First, Œ£fhas a signiÔ¨Åcantly better correlation to throughput than minmaxfor multiprogrammed workloads. This is not surprising conside ring that throughput of a thread often depends on the frequency of a cor e it 2 Fig. 1. Effect of maximum number of frequency values a core is tested at, on binning. Fig. 2. Effect of varying number of cores per die on binning. is running on. minmaxfails to account for the variation in frequency (and, therefore, average throughout) of individual cores. Correlation is especially low for small number of frequency bins. This is because binning process picks an overly conservative frequ ency asfmaxfor a core in that case. Even the relative performance of minmax(as compared to Œ£f) worsens as the number of frequency bins is decreased. We also evaluated throughput correlatio n of the two metrics for our parallel workloads. Correlation to thro ughput improved for minmaxfor such workloads. In fact, it was higher thanŒ£ffor large number of frequency bins (16 or higher). This was expected as the throughput of our parallel benchmarks wa s determined by the slowest thread. In terms of binning overhead, minmaxis signiÔ¨Åcantly faster than Œ£f, especially"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_13", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 13, "text": "ins (16 or higher). This was expected as the throughput of our parallel benchmarks wa s determined by the slowest thread. In terms of binning overhead, minmaxis signiÔ¨Åcantly faster than Œ£f, especiallyfor large number of bins (70% faster for 32bins) . This is because while Œ£finvolves doing binary search over full range (over all frequency bins) for everycore,minmaxhas progressively reducing search ranges. minmaxandŒ£fhave comparable overheads for small number of bins as the search range is reduced. The graph also shows that curvefit(refers to the approach of usingvariationmodelawarecurve Ô¨Åttingstrategytoapprox imateŒ£f) has performance correlation to throughput that is equivale nt to that forŒ£f.Thisisbecause arange of six-sigma(+/-3-sigma) issearch ed forcurvefitwhich is often big enough to allow the discovery of truefmaxof a core. In terms of binning overhead, curvefitis signiÔ¨Åcantly faster than Œ£f(36% for our baseline architecture). This is because the range of frequencies that are searched for curvefit is directed by the variation model and, therefore, small. Ov erhead is bigger than that for minmaxbecause of the need to estimate the Fig. 3. Effect of binary search range on binning"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_14", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 14, "text": "ched for curvefit is directed by the variation model and, therefore, small. Ov erhead is bigger than that for minmaxbecause of the need to estimate the Fig. 3. Effect of binary search range on binning strategies. Search range is varied from ¬±1œÉto¬±4œÉ(baseline). Here œÉrefers to total standard deviation of die-to-die and core-to-core variation. Fig. 4. Effect of varying cluster sizes on binning strategie s. fmaxfor every core. Clustering-based strategies (refers to the approach of usi ng clus- tering strategy to approximate Œ£f) (results are shown for a cluster size of 16) result in a smaller binning overhead than curvefit(26% for baseline). Clustering that relies on the variation mode l to reduce the range of search for fmaxfor the cores ( smart clust ) is faster than than the one that performs search over the full range for all cores (naive clust ) (6% improvement in test time for baseline case). In terms of correlation to throughput, clustering based str ategies lie between Œ£fandminmax. This is not surprising considering that clustering represents a hybrid between the two schemes. The trends as well analysis were same for our parallel workloads. Figure 2 shows how the binning overhe"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_15", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 15, "text": " This is not surprising considering that clustering represents a hybrid between the two schemes. The trends as well analysis were same for our parallel workloads. Figure 2 shows how the binning overhead changes with the number of cores on the processor chips. The numbers are shown for 16 frequency bins. As we can see, the binning overhead increa ses with increasing number of cores. More interestingly, the co rrelation to throughput increases for both clustering-based strateg ies with the number of cores. Better correlation is a result of having a la rger number of clusters per chip (note that the more the clusters, the more the number of fmaxvalues being summed). To conÔ¨Årm this, we also performed experiments to see how the correlation and binning overhead change when the number of cores per cluster (and, therefore, the number of clusters) is changed for a Ô¨Åxed size d chip (with 64 cores). Figure 4 shows the results. We indeed observ e that the binning overhead of clustering decreases with increasi ng number of cores per cluster. Similarly, the correlation to through put increases with increasing number of clusters. We also quantiÔ¨Åed the effect of changing the range of search. 3 Fig"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_16", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 16, "text": "ith increasi ng number of cores per cluster. Similarly, the correlation to through put increases with increasing number of clusters. We also quantiÔ¨Åed the effect of changing the range of search. 3 Fig. 5. Effect of nature of variation on binning. Figure3showshow correlationtoperformance andbinningov erhead change withthe searchrange. Aswecansee,boththetechniqu es that relyon the variation model tocome up withaggressive search ranges (curvefitand (smart clust ) have better correlation as the range of search is increased. This is not surprising because the bigg er is the range, the higher the probability that a true fmaxis found. Finally, we show the effect of nature of variations on binnin g metrics and their evaluation in Figure 5. The four cases: baseline (used in rest of the experiments), only inter-core random ,only inter- die random andonly across-wafer systematic (i.e., the bowl-shaped variation) all have the same variance. As within-die (i.e. c ore-to- core) variation increases, correlation of minmaxto true throughput decreases as it grossly underestimates throughput (since i t is taking minimum of fmaxof all cores). The extremes are only inter-core variation where the correl"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_17", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 17, "text": "correlation of minmaxto true throughput decreases as it grossly underestimates throughput (since i t is taking minimum of fmaxof all cores). The extremes are only inter-core variation where the correlation to throughput is barely 0.18 and only inter-die variation where the correlation is same as that of Œ£f. VII. C ONCLUSIONS In this paper, we have studied for the Ô¨Årsttime, speed binning for multi-core processors. We have compared two intuitive m etrics minmaxandŒ£fin terms of their correlation to actual throughput as well as testing overhead. Further, we have proposed binni ng strategies which leverage extent of variation (clustering ) as well as partially systematic nature of it (curve Ô¨Åtting). Curve Ô¨Ått ing achieves same correlation with true throughput as Œ£fwith signiÔ¨Åcantly less testing overhead (36% for our baseline architecture). Clus tering reduces the test time even further (26% for baseline) with li ttle loss in correlation (except for cases when core-to-core random v ariation is dominant form of variation). We also conclude that the tes t time beneÔ¨Åt of smart clustering is small (6% improvement in test t ime for baseline case). Our overall conclusion is that uniprocessor b"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_18", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 18, "text": "is dominant form of variation). We also conclude that the tes t time beneÔ¨Åt of smart clustering is small (6% improvement in test t ime for baseline case). Our overall conclusion is that uniprocessor binning method s do not scale well for multi-core processors in presence of vari ations. Multi-core binning metrics and testing strategies should b e carefully chosen to strike a good balance between goodness of the metri c and time required to evaluate it. Clustering may be constrained by design decisions (e.g., multiple cores sharing the same clocking) as well as by tester power (in this work we have assumed that only one cor e can be tested at a time): topics we intend to further pursue. REFERENCES [1] S. Borkar, ‚ÄúDesign Challenges of Technology Scaling‚Äù, IEEE Micro , 1999. [2] K. Qian and C.J. Spanos, ‚ÄúA Comprehensive Model of Proces s Variability for Statistical Timing Optimization‚Äù, Proc. SPIE Design for Manufacturability through Design-Process Integration , 2008. [3] P. Friedberg, W. Cheung and C.J. Spanos, ‚ÄúSpatial Modeli ng of Micron-Scale Gate Length Variation‚Äù, Proc. SPIE Data Analysis and Modeling for Process Control, 2006.[4] B.E. Stine, D.S. Boning and J.E. Chung, ‚ÄúAnalysi"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_19", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 19, "text": " Cheung and C.J. Spanos, ‚ÄúSpatial Modeli ng of Micron-Scale Gate Length Variation‚Äù, Proc. SPIE Data Analysis and Modeling for Process Control, 2006.[4] B.E. Stine, D.S. Boning and J.E. Chung, ‚ÄúAnalysis and Dec omposition of Spatial Variation in Integrated Circuit Processes and Devi ces‚Äù,IEEE Trans. Semiconductor Manufacturing , 10(1), 1997. [5] ITRS, 2007, http://public.itrs.net . [6] Asanovic, Krste and Bodik, Ras and Catanzaro, Bryan Chri stopher and Gebis, Joseph James and Husbands, Parry and Keutzer, Kurt and Patte rson, David A. and Plishker, William Lester and Shalf, John and Williams, S amuel Webb and Yelick, Katherine A., ‚ÄúThe Landscape of Parallel Computing Research: A View from Berkeley‚Äù, EECS Department, University of California , Berkeley, 2006. [7] S. J. E. Wilton and N. P. Jouppi, ‚ÄúCACTI: an enhanced cache access and cycle time model,‚Äù IEEE Journal of Solid-State Circuits , 1996. [8] Rakesh Kumar and Dean M. Tullsen, ‚ÄúCore architecture opt imization for hetero- geneouschipmultiprocessors‚Äù, International ConferenceonParallelArchitectures and Compilation Techniques, PACT , 2006. [9] Timothy Sherwood and Erez Perelman and Greg Hamerly and B rad Calder, ‚ÄúAutomatically Cha"}
{"id": "On Performance Binning of Multi-core Processors.pdf::chunk_20", "source": "On Performance Binning of Multi-core Processors.pdf", "chunk_index": 20, "text": "pmultiprocessors‚Äù, International ConferenceonParallelArchitectures and Compilation Techniques, PACT , 2006. [9] Timothy Sherwood and Erez Perelman and Greg Hamerly and B rad Calder, ‚ÄúAutomatically Characterizing Large Scale Program Behavi or‚Äù, ASPLOS, 2002. [10] D.M. Tullsen, ‚ÄúSimulation and Modeling of a Simultaneo us Multithreading Processor‚Äù, 1996, 22nd Annual Computer Measurement Group Conference . 4"}
{"id": "Optimizating semiconductor binning by feed-forward process adjustment.pdf::chunk_0", "source": "Optimizating semiconductor binning by feed-forward process adjustment.pdf", "chunk_index": 0, "text": ""}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_0", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 0, "text": "Proceedings of the 2009 Winter Simulation Conference M. D. Rossetti, R. R. Hill, B. Johansson, A. Dunkin and R. G. Ingalls, eds. OPTIMIZING DEMAND FU LFILLMENT FROM TEST BINS Brittany M. Bogle Scott J. Mason Department of Industrial Engineering 4207 Bell Engineering Center University of Arkansas Fayetteville, AR 72701, USA ABSTRACT A primary component of the wafer assembly and final testing phases of the semiconductor manufacturing process is the process of binning wherein integrated circuits are tested for speed, voltage, and other functionali ty requirements. Customer demand for products is satisfied using binned components. While higher functionality components can be used to satisfy lower -level demand at a profit loss, the reverse case is not an option. We investigate the important questio n of satisfy customer demand from available binned devices with maximum profit in terms of maximizing revenue and minimizing inventory holding costs using a mathematical programming -based solution approach . Initial results suggest our model is able to accurately produce cost -effective demand fulfilment strategies for semiconductor manufacturers in practice. 1 INTRODUCTION Integrated circu"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_1", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 1, "text": "ion approach . Initial results suggest our model is able to accurately produce cost -effective demand fulfilment strategies for semiconductor manufacturers in practice. 1 INTRODUCTION Integrated circuits (ICs) are the heart of most electronic devices, toys, and appliances today. ICs are fabricated first as indi- vidual di e on silicon wafers in wafer fabrication facilities. Next, once the die are electrically tested for functionality, the sil i- con wafers are sawed into individual circuits for subsequent assembly or packaging and final testing. A primary component of the wa fer assembly and final testing phases is the idea of binning . During final test, completed ICs may be evaluated in terms of assessing their processing speed (i.e., 3.0 GHz) and/or voltage requirements (i.e., 1.45 volts). After each IC‚Äôs fu nc- tionality is assessed and recorded, it is placed ( sorted) by the manufacturer (i.e., the supply side) based on capability testing results in a ‚Äúbin‚Äù corresponding to different product qualities (Uzsoy et al. , 1992) . Consider the following binning scenario: b in 1 coul d be reserved for the ‚Äúhighest functionality‚Äù components; bin 2 could contain components with ‚Äúmedium"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_2", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 2, "text": "ent product qualities (Uzsoy et al. , 1992) . Consider the following binning scenario: b in 1 coul d be reserved for the ‚Äúhighest functionality‚Äù components; bin 2 could contain components with ‚Äúmedium functionality ;‚Äù bin 3, in turn, could hold the ‚Äú low functionality‚Äù components. In practice, devices are place d into bins when they fall into a certain functionality range . For example, one bin may contain d e- vices that ha ve a power rating of 89 Watts, a speed of 3.1 GHz, and a voltage level between 1.425 volts and 1.45 volts . Further, it is important to note that product binning is not deterministic, as wafer fab production variability (which is inevitable) leads to variable end product capabilities/functionality. External customers (i.e., the demand side) may place orders with a semiconductor manufacturer for various quantities of products having a wid e range of capabilities ‚Äîthese product capabilities typically map to specific bin designations (i.e., su p- plier bin designations often relate to customer ordering patterns/demands) . If necessary, h igher product functionality can be substituted for lower lev el product demand , but not vice versa. For example, if there is cu"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_3", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 3, "text": "s often relate to customer ordering patterns/demands) . If necessary, h igher product functionality can be substituted for lower lev el product demand , but not vice versa. For example, if there is customer demand for Bin 3 products in excess of the available inventory , bin 1 and/or bin 2 products could be used by the supplier to meet th e demand. However, this substitution often comes w ith a significant price in terms of lost potential profits due to the related selling prices of high vs. low functionality components. As customer demands occur on a weekly basis , frequent high functionality product substitution for lower functionality product demand can result in significant lost profits. However, generating excess inventories of all product functionality types can lead to unnecessarily high inventory holding costs . As excess inventory creation is not desirable, this paper investigates the important question of satisfy customer demand from available binned devices with maximum profit in terms of maximizing revenue and minimizing inventory holding costs. Towards this goal, we present an mathematical programming model designed to achieve our research goals . 1730 978-1-4244-5771-"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_4", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 4, "text": "it in terms of maximizing revenue and minimizing inventory holding costs. Towards this goal, we present an mathematical programming model designed to achieve our research goals . 1730 978-1-4244-5771-7/09/$26.00 ¬©2009 IEEE Bogle and Mason 2 LITERATURE REVIEW The tradeoff between maintaining appropriate inventory levels to satisfy customer demand while seeking to maximize profits has been addressed previously in the literature, especially as global planning has become more necessary in practice due to increasing product demands. Hsu and Bassok (1999) present a downgrading substitution model with random demand and random yield that is quite similar to our motivating case of using devices placed in higher functionality bins for lower functionality demand satisfaction. Bitran and Gilbert (1994) study the idea of co -producing different products in batches within the semiconductor manufacturing industry. They note that random produc tion yield of wa fer die can help to enable manufacturer s to supply a range of product functionalitie s to a number of customers from one production batch. IMPReSS, an optimization production planning and scheduling tool developed at the University of Calif"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_5", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 5, "text": " to supply a range of product functionalitie s to a number of customers from one production batch. IMPReSS, an optimization production planning and scheduling tool developed at the University of Calif ornia -Berkel ey, was created in order to provide inventory planning assistance for Harris Corporation through more effective scheduling efforts (Leachman et al., 1996). Hung and Wang (1997) examine th e problem of meeting customer demand requirements through effective inventory planning. Finally, a theoretical approach presented by Gallego et al. (2006) is the most close ly-related prior effort to our re- search study. Gallego et al. (2006) explore the minimization of inventory through part downgrading for customers that desire low functionality products . In contrast, o ur approach is more applied in nature than Gallego et al. (2006) as (1) we develop a number of our model‚Äôs constraints based on prior discussions with semiconductor industry personnel and (2) we focus on m i- nimizing total inventory cost s over a multi -time period planning horizon . Towards this end, we now present an initial, work- ing deterministic optimization model for the demand fulfillment problem of interest"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_6", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 6, "text": "tal inventory cost s over a multi -time period planning horizon . Towards this end, we now present an initial, work- ing deterministic optimization model for the demand fulfillment problem of interest that later can be enhanced with a dditio n- al, realistic probabilistic customer demand requirements and stochastic device binning d istributions /results . 3 MODEL DEVELOPMENT 3.1 Definitions Throughout the remainder of this paper, we will use key terms such as devices, bins, and OPNs, as they relate to a semiconductor manufacturer with whom we have consulted on the problem area of interest. For reader clarification, the se key terms are defined as follows: ‚Ä¢ Devices ‚Ä¢ : The products that are electrically tested to ascertain different levels of functionality during the final test stage of the semiconductor manufacturing process. Based on the results of these tests, devices are assigned to a si n- gle bin related to their functionality/capability. Bin: ‚Ä¢ A repositor y or inventory location containing tested devices of some specified functionality or capability. I n- dividual bins are used to satisfy customer demand requirements for one or more specific OPNs . OPN: 3.2 Model Order Part"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_7", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 7, "text": "n containing tested devices of some specified functionality or capability. I n- dividual bins are used to satisfy customer demand requirements for one or more specific OPNs . OPN: 3.2 Model Order Part Number . Customers place their demand orders for OPNs in varying quantities during each time period . This demand subsequently is satisfied by the supplier with tested devices from bins corresponding to r e- quired production functionality/capability specifications. We now present a mixed -integer programming model for optimizing cu stomer demand fulfillment from bins such that company profits are maximized. First, we define relevant model notation in terms of the model‚Äôs sets, parameters, and variables: B Set of b ins, indexed by b Sets: D Set of d evices , indexed by d O Set of OPNs , indexed by o T Set of t ime periods, indexed by t 1731 Bogle and Mason ùëéùëéùëèùëèùëèùëè percent of device d assigned/distributed to bin b during electrical testing; these values were obtained from hi s- torical data supplied by our partnering semiconductor manufacturer; ‚â•0 , ‚â§1 Parameters: ùëöùëöùëèùëèùëèùëè =1 if demand for OPN o can be satisfied by devices in bin b; otherwise, =0 ùë£ùë£ùëèùëè initial inventory for device d; ‚â•0 ùëùùëù"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_8", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 8, "text": " supplied by our partnering semiconductor manufacturer; ‚â•0 , ‚â§1 Parameters: ùëöùëöùëèùëèùëèùëè =1 if demand for OPN o can be satisfied by devices in bin b; otherwise, =0 ùë£ùë£ùëèùëè initial inventory for device d; ‚â•0 ùëùùëùùëèùëè cost to produce device d; ‚â•0 ‚Ñéùëèùëè holding cost per unit in bin b per time period; ‚â•0 ùëõùëõùëèùëèùëúùëú customer d emand for OPN o during time period t; ‚â•0 ùë•ùë•ùëèùëèùëèùëèùëúùëú integer variable representing t he number of components selected from bin b to satisfy customer demand for OPN o in time period t; ‚â•0 Variables: ùë¶ùë¶ùëèùëèùëúùëú integer variable representing the component inventory level in bin b during time period t; ‚â•0 ùëßùëßùëèùëèùëúùëú integer variable representing the quantity of device d components produce d in time period t; ‚â•0 The o bjective function of our model minimize s the sum of inventory holding costs and production cost s: minimize ‚àë‚àë‚àë ((‚Ñéùëèùëèùë¶ùë¶ùëèùëèùëúùëú ùëèùëè‚ààùê∑ùê∑ ùëúùëú‚ààùëáùëá ùëèùëè‚ààùêµùêµ )+(ùëùùëùùëèùëèùëßùëßùëèùëèùëúùëú)) (1) A number of constraints are necessary in our model. First, constraint sets (2) and (3) maintain inventory balance across all time periods by reconciling inventory levels with production quantities and customer demand levels: ùë¶ùë¶ùëèùëè1=‚àë (( ùë£ùë£ùëèùëè+ùëßùëßùëèùëè1 ùëèùëè‚ààùê∑ùê∑ ùëéùëéùëèùëèùëèùëè)‚àí‚àëùë•ùë•ùëèùëèùëèùëè1 ‚àÄùëèùëè‚ààùêµùêµ ùëèùëè‚ààùëÇùëÇ (2) ùë¶ùë¶ùëèùëèùëúùëú=ùë¶ùë¶ùëèùëè(ùëúùëú‚àí1)+‚àë (( ùë£ùë£ùëèùëè+ùëßùëßùëèùëèùëúùëú ùëèùëè‚ààùê∑"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_9", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 9, "text": "ime periods by reconciling inventory levels with production quantities and customer demand levels: ùë¶ùë¶ùëèùëè1=‚àë (( ùë£ùë£ùëèùëè+ùëßùëßùëèùëè1 ùëèùëè‚ààùê∑ùê∑ ùëéùëéùëèùëèùëèùëè)‚àí‚àëùë•ùë•ùëèùëèùëèùëè1 ‚àÄùëèùëè‚ààùêµùêµ ùëèùëè‚ààùëÇùëÇ (2) ùë¶ùë¶ùëèùëèùëúùëú=ùë¶ùë¶ùëèùëè(ùëúùëú‚àí1)+‚àë (( ùë£ùë£ùëèùëè+ùëßùëßùëèùëèùëúùëú ùëèùëè‚ààùê∑ùê∑ ùëéùëéùëèùëèùëèùëè)‚àí‚àëùë•ùë•ùëèùëèùëèùëèùëúùëú ‚àÄùëèùëè‚ààùêµùêµ,ùëúùëú‚ààùëáùëá,ùëúùëú>1 ùëèùëè‚ààùëÇùëÇ (3) Next, constraint set (4) ensures that demand for each OPN is only met by comp onents contained in valid (i.e., functionally compatible) bins in each time period: ‚àëùë•ùë•ùëèùëèùëèùëèùëúùëú‚â•ùëõùëõùëèùëèùëúùëú ùëèùëè‚ààùêµùêµ ‚àÄùëèùëè‚ààùëÇùëÇ,ùëúùëú‚ààùëáùëá (4) Finally, constraint set (5) requires that only available binned components can be used to satisfy customer demand in each time period: ‚àë‚àëùë•ùë•ùëèùëèùëèùëèùëúùëú‚â§‚àë‚àë (ùëßùëßùëèùëèùëúùëúùëéùëéùëèùëèùëèùëè+ ùëèùëè‚ààùê∑ùê∑ ùëèùëè‚ààùêµùêµ ùëèùëè‚ààùëÇùëÇ ùëèùëè‚ààùêµùêµ ùë¶ùë¶ùëèùëèùëúùëú) ‚àÄùëúùëú‚ààùëáùëá (5) Variable type constraints are not included here, as they are defined above in the model notation portion of the paper. 3.3 Model Validation In order to assess the validity of our formulation, we now present an example toy data set to demonstrate the model‚Äôs fun c- tionality. First, let the set of devices D = {A, B, C, D, E, F, G, H}. Assume that customers can place orders for OPNs in the set O = {I, II, III, IV, V, VI, VII, VIII}. Further, we defined the set B to contain bins 1 through 9 and initially examine a two - period time horizon "}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_10", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 10, "text": "that customers can place orders for OPNs in the set O = {I, II, III, IV, V, VI, VII, VIII}. Further, we defined the set B to contain bins 1 through 9 and initially examine a two - period time horizon (i.e, T = {1, 2}). Table 1 contains an example matrix for parameter ùëéùëéùëèùëèùëèùëè describing the distribution for each device d into bin b resulting from th e final test stage of semiconductor manufacturing. The values were obtained from our partnering semiconductor manufacturer. This distribution is expressed as the fraction of devices tested that are mapped/placed into each bin. Note that the column assoc iated with each device sums to 1, as each device must be entirely mapped to the available bins. 1732 Bogle and Mason Table 1: Example Data for Device -to-Bin Mapping Parameter ùíÇùíÇùíÉùíÉùíÉùíÉ Device Bin A B C D E F G H 1 0 0 0 0 0 0 .03 0 2 0 0 0 0 0 0 .02 0 3 0 0 0 0 0 0 .08 0 4 .84 .06 .99 0 .94 .95 .33 0 5 .16 .94 .01 0 .06 .05 .32 0 6 0 0 0 0 0 0 .13 .01 7 0 0 0 0 0 0 .09 .79 8 0 0 0 .84 0 0 0 .20 9 0 0 0 .16 0 0 0 0 The distribution or mapping of devices into bins as given in Table 1 determines how much each bin will/can be utilized when fulfilling customer demand orders . For example, conside"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_11", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 11, "text": "9 0 0 0 .16 0 0 0 0 The distribution or mapping of devices into bins as given in Table 1 determines how much each bin will/can be utilized when fulfilling customer demand orders . For example, consider the bin mappings for devices D and G in Table 1. Between these two device types, all bins can be covered . However, the cost of making each de vice type comes into play when a sem i- conductor manufacturer is deciding on which device to produce in order to meet customer demand. For example, if it is more expensive to produce device type G, a semiconductor manufacturer may elect to produce device H products in order to satisfy inventory requirements for bin 7. Next, Table 2 displays example production cost data for each device type. Even though device types D and G can be used solely to produce inventories for all bin types (see Table 1), they are also the most costly to produce, according to Table 2. This tradeoff is especially evident when one considers the inventory holding costs incurred when extra devices are not sold to customers in response to OPN orders. For example, observe bin 5 and the low yield of device C into this bin (1%) and it‚Äôs cost in Table 2 (1 unit). These values "}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_12", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 12, "text": "red when extra devices are not sold to customers in response to OPN orders. For example, observe bin 5 and the low yield of device C into this bin (1%) and it‚Äôs cost in Table 2 (1 unit). These values are in stark contrast to the same bin 5 values for device B (94% and a cost of 5 units). It is possible that the 500% cost increase may be warranted if significant a mounts of demand exist for bin 5 comp o- nents, given the difference between the two device‚Äôs mapping percentage into bin 5. Table 2: Example Device Production Cost Data Device A B C D E F G H ùëùùëùùëèùëè 10 5 1 20 4 8 20 16 Table 3 displays example inventory holding cost data for the components in each bin . Each bin has a different carrying cost per piece held , as the value of the components contained in each bin vary according to the specifications of each bin. As a remind er, cost is the main objective of our proposed optimization model. Next, Table 4 displays the initial inventory (in number of items) of each device available for binning. From these initial inventories, subsequent binning and production d e- cisions follow. Table 3: Example Bin Holding Cost Data Bin 1 2 3 4 5 6 7 8 9 ‚Ñéùëèùëè .01 .02 .01 .02 .05 .07 1 .05 .04 Ta"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_13", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 13, "text": "or binning. From these initial inventories, subsequent binning and production d e- cisions follow. Table 3: Example Bin Holding Cost Data Bin 1 2 3 4 5 6 7 8 9 ‚Ñéùëèùëè .01 .02 .01 .02 .05 .07 1 .05 .04 Table 4: Example Initial Device Inventory Levels Device A B C D E F G H ùë£ùë£ùëèùëè 10439 2052 636 64560 12648 5700 373142 81659 In Table 5, an example bin -to-OPN map ping is shown. This is the map of bins from which components can be used to fulfill customer OPN demands. For example, the only way that a ny customer ‚Äôs demand for OPN I can be satisfied is by ha v- ing an appropriate amount of inventory in bin 1. This mapping data, viewed in concert with Table 1‚Äôs specification that only one device (G) bins out to b in 1, suggest that sufficient inventories and/or production levels of device G are critical. Lastly, Table 6 shows an example set of customer OPN demand quantities for use in our model verification efforts. 1733 Bogle and Mason Table 5: Example Bin -to-OPN Mapping Data (ùíéùíéùíÉùíÉùíÉùíÉ) OPN Bin I II III IV V VI VII VIII 1 1 0 0 0 0 0 0 0 2 0 1 1 0 0 0 0 0 3 0 0 1 1 0 0 0 0 4 0 0 0 0 1 0 0 0 5 0 0 0 0 1 1 0 0 6 0 0 0 0 1 1 1 0 7 0 0 0 0 0 1 0 0 8 0 0 0 0 0 0 1 0 9 0 0 0 0 0 0 1 1 Table 6: Exa"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_14", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 14, "text": "I II III IV V VI VII VIII 1 1 0 0 0 0 0 0 0 2 0 1 1 0 0 0 0 0 3 0 0 1 1 0 0 0 0 4 0 0 0 0 1 0 0 0 5 0 0 0 0 1 1 0 0 6 0 0 0 0 1 1 1 0 7 0 0 0 0 0 1 0 0 8 0 0 0 0 0 0 1 0 9 0 0 0 0 0 0 1 1 Table 6: Example Customer Demand Orders by OPN in Each Time Period OPN Time I II III IV V VI VII VIII 1 19806 320 946 71831 115822 6839 155606 13208 2 18636 33323 7317 23533 148777 30000 270479 7317 The model is implemented in AMPL v10.1 for solution and analysis using CPLEX v10.1 on a standard desktop PC. As it is in the class of optimization problems known as assignment problems, solution time is negligible. After analyzing this example problem, we achieve a n objective function value of $343,843,106.90 for total production and inventory holding costs. The model outputs for primary decision v ariable ùë•ùë•ùëèùëèùëèùëèùëúùëú resulting from this solution are presented in Tables 7 and 8 for time periods 1 and 2, respectively. Table 7: Number of Units Taken from Each Bin to Fulfill Demand in Time Period 1 OPN Bin I II III IV V VI VII VIII 1 27294 0 0 0 0 0 0 0 2 0 320 0 0 0 0 0 0 3 0 0 953 71831 0 0 0 0 4 0 0 0 0 300234 0 0 0 5 0 0 0 0 291136 0 0 0 6 0 0 0 0 0 0 118274 0 7 0 0 0 0 0 81882 0 0 8 0 0 0 0 0 0 37348 0"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_15", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 15, "text": " III IV V VI VII VIII 1 27294 0 0 0 0 0 0 0 2 0 320 0 0 0 0 0 0 3 0 0 953 71831 0 0 0 0 4 0 0 0 0 300234 0 0 0 5 0 0 0 0 291136 0 0 0 6 0 0 0 0 0 0 118274 0 7 0 0 0 0 0 81882 0 0 8 0 0 0 0 0 0 37348 0 9 0 0 0 0 0 0 0 13211 Table 8: Number of Units Taken from Each Bin to Fulfill Demand in Time Period 2 OPN Bin I II III IV V VI VII VIII 1 23172 0 0 0 0 0 0 0 2 0 33324 0 0 0 0 0 0 3 0 0 32715 23533 0 0 0 0 4 0 0 0 0 254892 0 0 0 5 0 0 0 0 247168 0 0 0 6 0 0 0 0 0 0 100412 0 7 0 0 0 0 0 69516 0 0 8 0 0 0 0 0 0 154130 0 9 0 0 0 0 0 0 15943 7317 1734 Bogle and Mason Table 9 displays the model‚Äôs output for the amount of device production required each time period to satisfy customer demand. Careful observation confirms that this indeed is the least costly option, based on the multiple competing factors ‚Äî production costs are balanced with inventory holding costs in order to produce the most cost -effective solution . The primary decision is to only produce devices D and G, and then allow the bin mapping percentages result in appropriate amounts of all customer -demanded OPNs. In fact, the majority of all demanded OPNs are satisfied from device G production. Table 9: Model Outputs for Week"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_16", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 16, "text": "bin mapping percentages result in appropriate amounts of all customer -demanded OPNs. In fact, the majority of all demanded OPNs are satisfied from device G production. Table 9: Model Outputs for Weekly Device Production Device Week 1 Week 2 A 0 0 B 0 0 C 0 0 D 82575 145375 E 0 0 F 0 0 G 909800 772400 H 0 0 Building on the production results in Table 9, Table 10 displays the inventory levels in each bin during each time period. As production efforts build device inventory levels, final testing distributes these devices to their appropriate bins. Then , customer demand for OPNs consumes binned ICs in the most cost -effective manner, resulting in the bin inventory levels d e- scribed in Table 10. Table 10: Bin Inventory Levels Per Week Bin Week 1 Week 2 1 0 0 2 17876 0 3 0 5544 4 0 0 5 0 0 6 0 0 7 0 0 8 32015 0 9 1 1 3.4 Model Sensitivity Analysis In order to test the model‚Äôs sensitivity to various input parameter values , the OPN -to-Bin map parameter ùëöùëöùëèùëèùëèùëè was varied to assess the model‚Äôs ability to select different bins for customer OPN demand. However, it is clear from Table 1 that device G (as described by our partnering semiconductor manufacturer) often i s the sole source for"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_17", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 17, "text": "el‚Äôs ability to select different bins for customer OPN demand. However, it is clear from Table 1 that device G (as described by our partnering semiconductor manufacturer) often i s the sole source for several bins ‚Äô inventories . Therefore, regardless of a variety of sensitivity analysis changes, device G must always be chosen for production in order to satisfy cu s- tomer demand, regardless of device G‚Äôs associated costs. It is important to realize that care must be taken to insure proper coverage of all bins is possible. Preliminary exper i- ments reveal that w hen device G‚Äôs mapping parameters were changed to not produce any bin 1 components ( ùëéùëé1ùê∫ùê∫=0), de- mand for OPN I could not be satisfied at all , as bin 1 is the only bin allowed to fulfill OPN I demand. This highlight the i m- portance of proper bin coverage and confirms t he model‚Äôs ability to seek lowest cost, feasible solutions for customer OPN demand fulfillment. 4 CURRENT RESEARCH ‚ÄîSCALING UP TO REALIT Y Now that our initial model is verified and its functionality has been validated, we are working with our partnering semico n- ductor manufacturer to generate a larger, more realistic data set. For this effort, the mo"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_18", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 18, "text": "tial model is verified and its functionality has been validated, we are working with our partnering semico n- ductor manufacturer to generate a larger, more realistic data set. For this effort, the model scale of interest contains 300 OPN s available for customer demand and a product mix of 350 different device types . Some initial lessons learned from this 1735 Bogle and Mason effort confirmed the importance of ensuring appropriate bin coverage for all bins are available for device -to-OPN translation mapping. Upon generating our first realistically -sized dataset, t he optimization model described above was run again in CPLEX . Unfortunately, our initial solution was determined to be infeasible, which at first we thought was the result of infeas i- ble/uncovered bin mappings. However, subsequent investigations revealed that the integer restrictions on our model‚Äôs prim a- ry decision v ariables were the reason for this infeasibility. While customer demand requirements are for integer quantities of OPNs, the device -to-bin mapping parameters cause a fractional number of items to be present in bin inventories. We continue to investigate t he appropriate method for relaxing the integ"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_19", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 19, "text": "quantities of OPNs, the device -to-bin mapping parameters cause a fractional number of items to be present in bin inventories. We continue to investigate t he appropriate method for relaxing the integrality restrictions in practice. We have verified that individually relaxing the integ rality restriction on each of the model‚Äôs three primary decision variables, ùë•ùë•ùëèùëèùëèùëèùëúùëú, ùë¶ùë¶ùëèùëèùëúùëú, and ùëßùëßùëèùëèùëúùëú, separately results in optimal solution s that are within .000001% of each other, regardless of which variable was chosen for integrality relaxation. Therefore, our future efforts will focus on this area of model modification to produce cost -effective deman d fulfillment solutions for our partnering semiconductor manufacturer. ACKNOWLEDGMENTS This research was partially supported by an Arkansas State Undergraduate Research Fellowship (SURF) grant. REFERENCES Bitran, G., and Gilbert, S. 1994. Co -Production Pro cesses with Random Yields in the Semiconductor Industry. Operations Research , 42 (3) : 476‚Äì491. Gallego, G., Katirci oglu, K., and Ramachandran, B. 2006. Semiconductor Inventory Management with Multiple Grade Parts and Downgrading. Production Planning and Co ntrol , 17 (7) : 689‚Äì700. Hsu, "}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_20", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 20, "text": "‚Äì491. Gallego, G., Katirci oglu, K., and Ramachandran, B. 2006. Semiconductor Inventory Management with Multiple Grade Parts and Downgrading. Production Planning and Co ntrol , 17 (7) : 689‚Äì700. Hsu, A., and Bassok, Y. 1999. Random Yield and Random Demand in a Production System with Downward Substitution. Operations Research , 47 (2) : 277‚Äì290. Hung, Y., and Wang, Q. 1997. A New Formu lation Technique for Alternative Material Planning. Computers and Enginee r- ing, 32 (2): 281‚Äì297. Leachman, R., Benson, R., Liu, C., and Raar, D. 1996. IMPReSS: An Automated Production -Planning and Delivery - Quotation System at Harris Corporation -Semiconductor Sector. Interfaces , 26 (1) : 6‚Äì37. Uzsoy, R., Lee, C. -Y., and Martin -Vega, L. A. 1992. A Review of the Production Planning and Scheduling Models in the Semiconductor Industry Part I: System Characteristics, Performance Evaluation and Production Planning. IIE Transa c- tions, 24 (4) : 47‚Äì60. AUTHOR BI OGRAPHIES BRITTANY M. BOGLE is a senior industrial engineering undergraduate research assistant in the Honors College at the University of Arkansas. She has won a number of scholarships and undergraduate research grants during her academic ca"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_21", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 21, "text": "dustrial engineering undergraduate research assistant in the Honors College at the University of Arkansas. She has won a number of scholarships and undergraduate research grants during her academic career and has studied abroad in China and Singapore. In addition, Brittany has completed two National Science Foundation R e- search Experiences for Undergraduates (REUs). Her future plans are to pursue industrial engineering graduate studies in o r- der to become a faculty member. Brittany can be reached via e -mail at <bmbogle@uark.edu> . SCOTT J. MASON is an Associate Professor and the Associate Department Head of Industrial Engineering at the Univers i- ty of Arkansas (UA). He received his BS in mechanical engineering and MS in engineering (emphasis in operations r e- search) from The University of Texas at Austin and his PhD in industrial engineering from Arizona State University. Scott has published journal articles, book chapters, and conference papers in the fields of production planning and scheduling in semiconductor manufacturing facilities; supply chain optimization and analysis; and transportation logistics. Currently, he is an Associate Editor for IEEE Transactions on Elec"}
{"id": "Optimizing Demand Fulfillment from Test Bins.pdf::chunk_22", "source": "Optimizing Demand Fulfillment from Test Bins.pdf", "chunk_index": 22, "text": "nning and scheduling in semiconductor manufacturing facilities; supply chain optimization and analysis; and transportation logistics. Currently, he is an Associate Editor for IEEE Transactions on Electronic s Packaging Manufacturing. Scott is a member of INFORMS, a s e- nior member of the Institute for Industrial Engineers (IIE), and can be reached via e -mail at <mason@uark.edu> . 1736"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_0", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 0, "text": "Technische Universit√§t M√ºnchen TUM School of Computation, Information and Technology Performance Prediction of Microcontrollers based upon integrated Technology Monitors Tobias Kilian Vollst√§ndiger Abdruck der von der TUM School of Computation, Information and Technology der Technischen Universit√§t M√ºnchen zur Erlangung eines Doktors der Ingenieurwissenschaften (Dr.-Ing.) genehmigten Dissertation. Vorsitz: Prof. Dr.-Ing. Georg Sigl Pr√ºfende der Dissertation: 1. Prof. Dr.-Ing. Ulf Schlichtmann 2. Prof. Matteo Sonza Reorda, Ph.D. Die Dissertation wurde am 10.04.2024 bei der Technischen Universit√§t M√ºnchen eingereicht und durch die TUM School of Computation, Information and Technology am 24.01.2025 angenommen. Abstract Microcontrollers (MCUs) are used for a broad range of applications. The testing of such MCUs is an essential topic for MCU manufacturers, particularly in safety-critical MCUs. Such MCUs are used in the automotive industry to operate braking, steering, and airbag systems. A critical test of the MCU testing process is the performance screening in which the maximum clock frequency of the MCU is determined under worst-case conditions. Indirect monitors, like Ring Oscillator"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_1", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 1, "text": "critical test of the MCU testing process is the performance screening in which the maximum clock frequency of the MCU is determined under worst-case conditions. Indirect monitors, like Ring Oscillators (ROs), are used for this performance screening. This work presents the functional path ROs as an indirect monitoring structure used for performance screening. A holistic overview of the functional path ROs from the pre-silicon to the post-silicon is presented. The implementation of such ROs and the associated advantages in terms of area consump- tion, leakage, and routing are presented. In addition, advanced implementation methodolo- gies are proposed to save further routing resources. A considerable framework is suggested to select promising functional paths based on sensitivity analysis, and the entire implementation selection Ô¨Çow is validated. In the post-silicon phase, a statistically signiÔ¨Åcant amount of MCUs that contain the functional path ROs are manufactured and tested. The measured func- tional path RO frequencies are correlated with the MCU performance using machine learning approaches and compared with traditional RO structures. The performance screening uses the implemen"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_2", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 2, "text": "ured func- tional path RO frequencies are correlated with the MCU performance using machine learning approaches and compared with traditional RO structures. The performance screening uses the implemented RO types, and the results yield is evaluated. i Acknowledgments This thesis results from my work as a doctoral candidate at InÔ¨Åneon Technologies AG, Neubiberg, Germany. First of all, I thank Prof. Dr.-Ing. Ulf Schlichtmann for offering me the generous opportunity for this research work. He guided me through the work with his passion, constructive advice, and valuable discussions. I truthfully appreciate his genius academic support and feedback on publishing my papers. I also would like to thank the co-examiner, Prof. Matteo Sonza Reorda, Ph.D., for his interest in my thesis and his time. Also, I would like to thank my colleagues at InÔ¨Åneon Technologies AG. Thank you to my managers, Carsten Doerrhoefer and Dr. rer. nat. Jochen Roeder, for admitting me to the opportunity in your team. A special thanks to my supervisors, Dr.-Ing. Martin Huch and Dr.-Ing. Daniel Tille. Martin, thank you for the inspiring discussions and technical guidance through this work. Daniel, thank you for the ac"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_3", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 3, "text": "special thanks to my supervisors, Dr.-Ing. Martin Huch and Dr.-Ing. Daniel Tille. Martin, thank you for the inspiring discussions and technical guidance through this work. Daniel, thank you for the academic guidance in the test community, the constructive discussions, and the distinguished feedback. In addition, thank you to the teams that supported and helped me make this research work successful from the concept to the Ô¨Årst silicon and beyond, especially the DFX, chip integration, test, and product engineering teams. With your support, this work is in the state as it is now. I want to thank Dr.-Ing. Juergen Alt for the review of this thesis and the discussions. I would also like to thank the students who contributed to this work, especially Markus Hanel. Also, I am deeply thankful for the great collaboration and research conducted with the Politecnico di Torino (Turin, Italy), thanks to Nicol√≤ Bellarmino, Prof. Riccardo Cantoro, and Prof. Giovanni Squillero. Finally, I would like to thank my family and friends for their support and understanding of my lack of time and presence over the recent years. Mainly, I sincerely thank my wife, Kerstin, for her continuous support and motiva"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_4", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 4, "text": "thank my family and friends for their support and understanding of my lack of time and presence over the recent years. Mainly, I sincerely thank my wife, Kerstin, for her continuous support and motivation. Contents Abstract i Acknowledgments ii 1. Introduction 1 1.1. Motivation and Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2. Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3. Contribution of this Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4. Outline of this Dissertation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2. Background 8 2.1. Digital MCU Development Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.2. Timing and Performance of digital Circuits . . . . . . . . . . . . . . . . . . . . . 10 2.3. PVT Variations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.4. Testing of MCUs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.5. Performance testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.6. Machine Learning in IC Testing . . . . . . . . . . . . . . . . "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_5", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 5, "text": " . . . . . . . . . . . . . . . 19 2.5. Performance testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.6. Machine Learning in IC Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.7. Automotive Quality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 I. PRE-Silicon 31 3. Functional Path Ring Oscillators 32 3.1. Basic Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.2. Advanced Implementation Concepts . . . . . . . . . . . . . . . . . . . . . . . . . 35 3.3. Self Enabling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 3.4. Control Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3.5. Implementation Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 3.6. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4. Path Selection Methodology 61 4.1. Selection Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 iii Contents 4.2. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_6", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 6, "text": " Selection Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 iii Contents 4.2. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 5. PRE-Silicon VeriÔ¨Åcation and Validation 68 5.1. PRE-Silicon VeriÔ¨Åcation of the Functional Path ROs . . . . . . . . . . . . . . . . 68 5.2. SI Bring-up Preparation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5.3. PRE- Silicon Validation and Improvement . . . . . . . . . . . . . . . . . . . . . . 75 6. PRE-SI Summary 83 II. POST-Silicon 85 7. Measurement and Validation of the Functional Path RO 87 7.1. Functional Path RO Measurement Results . . . . . . . . . . . . . . . . . . . . . . 87 8. Performance Screening Using Functional Path RO 91 8.1. Method and Data Set for the Performance Screening . . . . . . . . . . . . . . . 91 8.2. Preprocessing of the Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 8.3. Performance Screening Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 8.4. Deploy the Performance Screening . . . . . . . . . . . . . . . . . . . . . . . . . . 104 8.5. Results of the Performance Screening . . . . . ."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_7", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 7, "text": ". . . . . . . . . . . . . . . . . . . . . . . . . 97 8.4. Deploy the Performance Screening . . . . . . . . . . . . . . . . . . . . . . . . . . 104 8.5. Results of the Performance Screening . . . . . . . . . . . . . . . . . . . . . . . . 104 9. POST-SI Summary 115 10. Conclusion 116 10.1. Summary of Key Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 10.2. Obstacles in an Industrial Context . . . . . . . . . . . . . . . . . . . . . . . . . . 117 10.3. Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 List of Figures 119 List of Tables 122 Acronyms 123 Bibliography 126 iv 1. Introduction Semiconductor electronics are an essential element in today‚Äôs digitized world. This has become common knowledge in 2022 since the U.S. and European governments have released billions of dollars in subsidies to strengthen and foster the semiconductor ecosystem in the U.S. [1] and European [2] chips acts. Essential semiconductor devices are integrated circuits (ICs). ICs are small semiconductor devices that are fundamental components in nearly everything in life and the economy. A subgroup of ICs are microcontrollers (MCUs). An MCU i"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_8", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 8, "text": "are integrated circuits (ICs). ICs are small semiconductor devices that are fundamental components in nearly everything in life and the economy. A subgroup of ICs are microcontrollers (MCUs). An MCU is an IC that combines different systems on one chip; also, the term system-on-chip (SoC) is used. An MCU combines the processor, memory, input/output (I/O) peripherals, and communication interfaces on a single chip. The Ô¨Åeld of applications is enormous. It ranges from tiny household and commercial applications to high-reliable technologies, like space applications and automotive technology. Depending on the application, MCUs must meet different quality, power consumption, performance, and cost requirements. MCUs used in the automotive industry have special needs regarding quality [3] and reliability [4]. This work focuses on MCUs for automotive applications; however, the method can be used for every MCU. 1.1. Motivation and Problem Statement More than 100 of these MCUs are incorporated in modern vehicles [4] and are used in safety-critical steering and braking systems as well as in advanced driver assistance systems (ADAS). The MCUs must work under extreme temperature conditions from \u0000"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_9", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 9, "text": "modern vehicles [4] and are used in safety-critical steering and braking systems as well as in advanced driver assistance systems (ADAS). The MCUs must work under extreme temperature conditions from \u000040\u000eCup to 150\u000eC. They are exposed to vibrations and harsh conditions. Moreover, the automotive MCU must ensure to work for up to 15years [5]. A not correctly working MCU can cause tremendous damage and risk human lives. Therefore, much effort is invested in testing and validating automotive MCUs to satisfy quality requirements. The MCU test is essential for Ô¨Ånding defects provoked by the manufacturing process, ensuring proper functionality, and meeting the required speciÔ¨Åcations. The major challenge in testing automotive MCUs is to achieve zero-defect quality [6]. This means only MCUs, which are error-free, will be delivered to the customer. However, zero- defect quality is not easy to achieve for large and complex automotive MCUs. Therefore, 1 1. Introduction automotive MCU manufacturers invest much effort in testing all devices to deliver zero-defect quality. There are many test stages along the manufacturing process, and modern MCUs have an extensive DFT infrastructure on board to s"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_10", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 10, "text": "invest much effort in testing all devices to deliver zero-defect quality. There are many test stages along the manufacturing process, and modern MCUs have an extensive DFT infrastructure on board to support and enable the various tests. An essential test of the MCUs test procedure is performance screening. The performance of an MCU is the maximum achievable clock frequency at which the device can execute all use cases under worst-case conditions, denoted as FMAX . Performance screening describes the test in which FMAX is determined. Therefore, each device shipped to the customer must pass the performance screening by achieving the performance speciÔ¨Åed in the data sheet. The timing of the design in the MCU determines the FMAX . Since the technology node in MCU is shrinking, the timing variability becomes more sensitive to manufacturing, environment, and aging. This timing variability is called PVTA (process, voltage, temperature, aging) variation. The aging component is neglected in this work since it is an elaborate topic that is out of scope. Thus, Process-Voltage-Temperature (PVT) variability is addressed in this work. The timing of the MCU and FMAX should be satisÔ¨Åed regardless "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_11", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 11, "text": "s work since it is an elaborate topic that is out of scope. Thus, Process-Voltage-Temperature (PVT) variability is addressed in this work. The timing of the MCU and FMAX should be satisÔ¨Åed regardless of the PVT variability. This makes the performance screening even more challenging since the FMAX should be guaranteed under worst-case conditions. Figure 1.1 provides a simpliÔ¨Åed illustration of the performance in MCU manufacturing. The performance of manufactured MCUs can be approximated as Gaussian distribution colored in blue [7]. Thus, many of the devices are well centered around the mean. However, there are also devices with lower FMAX , the so-called slow tail on the left side of the distribution, and devices with higher FMAX on the right side, called the fast tail of the distribution. The reason for this distribution lies in the semiconductor manufacturing process itself. The aim is for many components within this Gaussian distribution to fulÔ¨Åll the requirement FMAX , which in turn depends on the design border. This design border is the value that is required as a design speciÔ¨Åcation. The exact position of the design border depends on many technical as well as Ô¨Ånancial factors."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_12", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 12, "text": " depends on the design border. This design border is the value that is required as a design speciÔ¨Åcation. The exact position of the design border depends on many technical as well as Ô¨Ånancial factors. The brute force approach would shift the design border (red) far to the left sides of the distribution - which means all MCUs are indeed fast. Unfortunately, that does not work since this would result in an MCU design that is not competitive due to area, design effort, and economic reasons. The design border in realistic scenarios is much closer to the distribution and can even cut into this distribution. The performance screening targets testing the performance near the design border. However, the performance cannot be measured directly, and the entire multidimensional PVT space must be considered. In recent years, various methods for determining performance have been proposed. The methods range from structural tests to system-level-tests and indirect monitoring structures [8, 9, 10, 11, 12, 13, 14, 15, 16]. Due to the fact that a hundred 2 1. Introduction Design Border Performance ( FMAX)Number of Devices Guardband Figure 1.1.: Process window after tightening the limits. percent acc"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_13", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 13, "text": " 12, 13, 14, 15, 16]. Due to the fact that a hundred 2 1. Introduction Design Border Performance ( FMAX)Number of Devices Guardband Figure 1.1.: Process window after tightening the limits. percent accurate determination of the performance is not possible, it is an attempt to predict the performance as accurately as possible. What remains is an inaccuracy that must be priced into the performance screening. In order to safeguard the inaccuracy of the screening, a so-called Guardband (colored orange in Figure 1.1) is used. This margin is added to the performance screening to meet the high-quality requirements - better performance screening methods result in higher screening accuracy, and thus less Guardband is required. In order to determine the performance for the performance screening, indirect monitors are often used. Such indirect monitor structures are ring oscillators (ROs). The oscillation frequency of such ROs is measured, and this measured frequency correlates with FMAX . However, the RO structures usually have a signiÔ¨Åcant area overhead, but in turn, have a high resolution and are easy and fast to measure [17]. Furthermore, the quality and accuracy of performance screening d"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_14", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 14, "text": ", the RO structures usually have a signiÔ¨Åcant area overhead, but in turn, have a high resolution and are easy and fast to measure [17]. Furthermore, the quality and accuracy of performance screening depend signiÔ¨Åcantly on the design of such RO structures [18, 19, 20]. The functional path ROs [21] are a subtype of ROs that promise advantages in terms of area and accuracy since they use functional paths which are already on the design. However, the functional path ROs need further research on how to implement and control, which paths to select, and how to establish the functional path RO for performance screening on silicon in a large automotive MCU. This work is an important contribution to these endeavors. 1.2. Related Work Determining the performance of modern SoCs is challenging due to their complexity - especially for large MCUs. Three signiÔ¨Åcant approaches in FMAX testing are widely used and visualized in Figure 1.2. One way to test performance is to use structural at-speed test patterns, such as Transition Delay Fault [22] patterns or Path Delay Fault [23] patterns [8, 9]. However, such at-speed 3 1. Introduction Structural TestsFunctional Tests Indirect MonitorsFMAX Figure 1."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_15", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 15, "text": "tterns, such as Transition Delay Fault [22] patterns or Path Delay Fault [23] patterns [8, 9]. However, such at-speed 3 1. Introduction Structural TestsFunctional Tests Indirect MonitorsFMAX Figure 1.2.: Test approaches for FMAX testing. patterns can only provide a pass or fail categorization of the chip. Performance testing requires an accurate determination of the numerical performance value. A straightforward approach is determining the MCU‚Äôs performance with a Functional Test on the automatic test equipment (ATE) [10]. Small critical code blocks as part of the ATE test program are executed, and the clock frequency is increased until the point of failure [11]. However, ATE systems usually have limited power integrity, making the exact performance prediction inaccurate [24]. As a result, System-Level Test (SLT) is gaining increasing attention [12, 13]. In contrast to the functional test on the ATE, the SLT is performed on an application- like board with software close to the device‚Äôs Ô¨Ånal application. However, several thousand applications are conceivable. Therefore, all possible applications must be tested under different voltage and temperature conditions to determine the maxim"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_16", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 16, "text": " Ô¨Ånal application. However, several thousand applications are conceivable. Therefore, all possible applications must be tested under different voltage and temperature conditions to determine the maximum performance of every device [24]- which is not an option due to the limited test budget. Thus, SLT is expensive in terms of test time and handling [25]. The third approach is to use indirect monitoring structures. There are many types of such indirect methods. However, they all used indirect metrics that allowed them to conclude performance [26, 27, 28, 29, 30, 31, 21]. Razor FF [26, 27] and In-situ slack monitors [28] are some types of indirect monitoring structures. Razor FFs are additional FFs that observe speciÔ¨Åc paths on the design and check if the timing is met. Also, in-situ slack monitors observe the remaining slack of a speciÔ¨Åc path and give an alarm if the slack margin disappears. Both approaches can be used for performance determination in small circuits where some known paths are timing critical. However, for large MCUs in state-of-the-art CMOS technology, the timing of a design gets more complex [32], and it is challenging to deÔ¨Åne discrete time-critical paths. It may b"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_17", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 17, "text": "s are timing critical. However, for large MCUs in state-of-the-art CMOS technology, the timing of a design gets more complex [32], and it is challenging to deÔ¨Åne discrete time-critical paths. It may be that paths, which seem non-critical in the pre-silicon phase may become critical in the post-silicon phase due to process variations in manufacturing [33]. The degradation mechanism also 4 1. Introduction affects the performance [34]. Thus, it is essential to monitor numerous paths in the design. Consequently, many Razor FFs and in-situ monitors will add a considerable area ‚Äì which should be prevented due to cost reasons. Another indirect monitoring structure for performance screening is the use of ring oscilla- tors (ROs). Such ROs are divided into two basic variants - generic ROs and design-dependent ROs [29]. Generic ROs are made from precisely one kind of standard library cell, e.g., inverters or AND gates. Design-dependent ROs are synthesized according to the design of the chip. Several paths of the chip are being selected, synthesized, and designed as ROs. However, such RO structures occupy much area because all structures need to be placed on the chip; in contrast, functional "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_18", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 18, "text": "eral paths of the chip are being selected, synthesized, and designed as ROs. However, such RO structures occupy much area because all structures need to be placed on the chip; in contrast, functional path ROs can solve the disadvantage of the area requirement. Wu et al. [30] proposed the basic concept of functional path ROs. A functional path RO uses existing paths in the design and creates an RO structure from such paths. In the basic concept, path ROs are used to test small circuits. Further development of functional path RO was proposed by Wang et al. [31, 21] - called Path-RO . Here, the main focus is on measuring speciÔ¨Åc path delays as precisely as possible, which is only accompanied by high area and effort. However, efÔ¨Åcient implementation is only one aspect of performance screening with functional path ROs. There are millions of functional paths on a large MCU, and the path selection directly affects the quality of performance monitoring. Many previous research was conducted to characterize timing effects [35, 36, 37, 33] in functional path ROs. Rangan et al. investigated the design of ROs in terms of PVT sensitivity [38]. Therefore, the accuracy of the performance screening"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_19", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 19, "text": "characterize timing effects [35, 36, 37, 33] in functional path ROs. Rangan et al. investigated the design of ROs in terms of PVT sensitivity [38]. Therefore, the accuracy of the performance screening strongly depends on the sensitivity of the performance monitors used. [39]. In summary, there is a lack of efÔ¨Åcient and automatic implementation of functional path ROs. The implemented ROs should Ô¨Åt into industrial design Ô¨Çows and use the industrial test and control infrastructures like the DFT environment. Another open point is selecting the functional paths to catch the right paths for performance screening. There is also a lack of measurement data from silicon. Furthermore, last but not least, how good are the functional path ROs for performance screening? 1.2.1. SMON Benchmark Module in this Work In order to have a baseline against which the functional path ROs can be compared, an SMON (Speed MONitor) module is used in this work. This SMON module, utilized as a benchmark, contains different types of ROs as performance monitors. The structure of the SMON module originates from [24], but the SMONs have been re-implemented in the newer 28 nm CMOS technology used for this research to "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_20", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 20, "text": "ferent types of ROs as performance monitors. The structure of the SMON module originates from [24], but the SMONs have been re-implemented in the newer 28 nm CMOS technology used for this research to serve as a valid baseline. 5 1. Introduction Inside the SMON module is a mix of generic and design-dependent ROs. The module is conceptualized as a compact block positioned on the MCU. The various generic ROs consist of inverter gates, NAND gates, and NOR gates from different cell libraries. The design-dependent ROs on the SMON module emulate functional paths from the design. The SMON module is designed to contain up to 255 different ROs. However, to serve as a benchmark, the SMONs contain 27 ROs that have been used in previous work ([24]). 1.3. Contribution of this Work The main contribution of this work is in the area of functional path ROs for performance screening. In particular, the contribution can be settled along the development process of an MCU from the per-silicon design part through the manufacturing until the post-silicon evaluation of an MCU in state-of-the-art technology. Parts of the approaches proposed in this work have been peer-reviewed and published in ofÔ¨Åcial scien"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_21", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 21, "text": "rough the manufacturing until the post-silicon evaluation of an MCU in state-of-the-art technology. Parts of the approaches proposed in this work have been peer-reviewed and published in ofÔ¨Åcial scientiÔ¨Åc conferences proceedings [40, 41, 42, 43] and workshop proceedings [44, 45, 46, 47, 48]. In addition, parts of this work have been published in the IEEE Transactions on Very Large Scale Integration (VLSI) Systems in June 2023 [49]. In order to emphasize the novelty of this work, two patents are published and granted in two different countries. Another outstanding achievement of this work is that [41] was honored with the Best Paper Award at the IEEE European Test Symposium (ETS) 2022. Besides this, there are considerable co-contributions in peer-reviewed conferences [24, 50] and a publication in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) [51]. The following listing associates the core contributions with this work‚Äôs publications and related sections in this thesis. \u000fAutomatic and scalable implementation of functional path ROs in large automotive MCU designs is presented in Section 3.1 of which parts are published in [40, 44, 45]. \u000fThe develo"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_22", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 22, "text": "ions in this thesis. \u000fAutomatic and scalable implementation of functional path ROs in large automotive MCU designs is presented in Section 3.1 of which parts are published in [40, 44, 45]. \u000fThe development of advanced implementation methods is presented in Section 3.2, which emphasizes the so-called self-enabling approach and natural loops. The self- enabling approach was published in [41], and a DE and US patent [52] was granted. The natural loop approach was published in [47] and patented in DE (granted) and US (published) [53]. \u000fA path selection methodology was developed and validated using analog simulation and sensitivity analysis of the circuitry, this is presented in Section 4, and parts were published in [42, 46]. 6 1. Introduction \u000fFunctional path RO results are presented, derived from a large automotive MCU, and their beneÔ¨Åts for performance screening are presented in Part II. Sections of this part were presented in [42, 43, 48] and [49]. 1.4. Outline of this Dissertation Chapter 2 Part I Part II Chapter 10 Chapter 3 Chapter 4 Chapter 5 Chapter 7 Chapter 8Chapter 6 Chapter 9 PRE-Silicon POST-SiliconBackground InformationFunctional Path ROsPath Selection MethodologyVerific"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_23", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 23, "text": "pter 2 Part I Part II Chapter 10 Chapter 3 Chapter 4 Chapter 5 Chapter 7 Chapter 8Chapter 6 Chapter 9 PRE-Silicon POST-SiliconBackground InformationFunctional Path ROsPath Selection MethodologyVerification and ValidationMeasurement and ValidationPerformance ScreeningConclusion and Future WorkTape - out Figure 1.3.: Outline of the thesis. The structure of this thesis is presented in Figure 1.3. Chapter 2 provides the background knowledge for this work. The industrial development Ô¨Çow of an MCU is recapped, and the timing and performance challenges are explained. Also, the fundamental testing knowledge is provided, and the most substantial Machine Learning (ML) approaches are explained. The subsequent work is then divided into two parts: Part I: pre-silicon and Part II: post- silicon. Part I presents the concept and implementation of the functional path ROs in Chapter 3. Chapter 4 presents the path selection methodology to Ô¨Ånd the best suitable functional paths for RO implementation. The pre-silicon veriÔ¨Åcation and validation is explained in Chapter 5, followed by a comprehensive summary of Part I. Part II presents the Ô¨Årst measurement results and their validation in Chapter 7. Chapte"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_24", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 24, "text": "pre-silicon veriÔ¨Åcation and validation is explained in Chapter 5, followed by a comprehensive summary of Part I. Part II presents the Ô¨Årst measurement results and their validation in Chapter 7. Chapter 8 presents the use and results of functional path ROs for performance screening. A summary in Chapter 9 concludes Part II. The last Chapter ‚Äì Chapter 10 ‚Äì in this work concludes the thesis, including obstacles in an industrial context and further work. 7 2. Background The background section provides an overview of the microcontroller (MCU) development and timing of digital circuits. Afterward, the testing of modern MCUs is reviewed, especially the performance screening. Machine learning (ML) use cases in SoC testing and the quality standards for automotive MCUs are also elaborated. The terms SoC and MCU are used as synonyms in this work and are not further distinguished. 2.1. Digital MCU Development Flow In order to get an overview of the phases in which the proposed methods proceed, the industrial MCU design and test Ô¨Çow are presented. All methods in this work are suitable for industrial development Ô¨Çows. However, only a condensed overview of the MCU development Ô¨Çow is presented, as"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_25", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 25, "text": " industrial MCU design and test Ô¨Çow are presented. All methods in this work are suitable for industrial development Ô¨Çows. However, only a condensed overview of the MCU development Ô¨Çow is presented, as the detailed process is much more extensive [54]. The digital MCU development Ô¨Çow to develop a prototype MCU is shown in Figure 2.1. MCU Specification & ArchitectureRTL Design & VerificationLogic Synthesis Netlist Scan Insertion Mod. NetlistPhysical Design & Place and RouteDesign Verifi- cation, STA, LEC, DRC-checkECO-phase Tape- out SoC ManufacturingWafer Probe Frontend TestPackagingFinal Test - Backend Test Prototype MCUPRE - Silicon POST - SiliconIteration Figure 2.1.: Development Ô¨Çow of a prototype MCU divided into Pre-Silicon and Post-Silicon. In general, the development process can be divided into the Pre-Silicon (Pre-Si) and Post- Silicon (Post-Si) phases. The arrival of the Ô¨Årst MCU prototype indicates the transition from 8 2. Background Pre-Si to Post-Si. The functional speciÔ¨Åcation has to be deÔ¨Åned in the initial phase, and the architectural chip elements, including all modules and submodules, are deÔ¨Åned. The described functionality is translated into a hardware description "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_26", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 26, "text": "ion has to be deÔ¨Åned in the initial phase, and the architectural chip elements, including all modules and submodules, are deÔ¨Åned. The described functionality is translated into a hardware description language and a synthesizable register-transfer level (RTL) representation. With a proper RTL representation, the logic synthesis is started, and the abstracted RTL representation of the functionality is then translated into a logical gate-level design called netlist . The netlist of a design is a composition of logic gates and Ô¨Çip-Ô¨Çops (FFs) implementing a particular functionality previously described in RTL. The RTL representation and the netlist are constantly veriÔ¨Åed to check the desired functionality [55]. Once the netlist is veriÔ¨Åed, it is further modiÔ¨Åed with the Design for Testability (DfT) process (e.g., scan insertion ), which results in a modiÔ¨Åed netlist. The DfT process enables proper testing of the manufactured chips; more details are explained in Section 2.4.1. The modiÔ¨Åed netlist is then passed to the physical design. Floorplanning of the design, including power planning, clock tree synthesis, and place-and-route, is performed. The physical design is extensively veriÔ¨Åed a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_27", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 27, "text": "list is then passed to the physical design. Floorplanning of the design, including power planning, clock tree synthesis, and place-and-route, is performed. The physical design is extensively veriÔ¨Åed and, if necessary, optimized. An essential step in the design veriÔ¨Åcation is ensuring the design‚Äôs timing closure with the static timing analysis (STA). All setup and hold times must be within the speciÔ¨Åcations under all allowed conditions. Plenty of other veriÔ¨Åcation steps are also done, for example, the Logic Equivalence Check (LEC), Design Rule Check (DRC), IR droop is veriÔ¨Åed and cross-talk, and many more checks [55]. If there are issues with the functionality and timing of the design, an engineering change order (ECO) is usually used to solve the issue. An ECO is a process for Ô¨Åxing any design problems in a late design stage and is typically one of the last stages in the Pre-Si phase. The ECO can cause a minor modiÔ¨Åcation in the netlist and the resulting change in the physical design. This ECO process is executed, and an incremental compilation run is performed. This means that only the parts of the design that are affected by the ECO process are changed. The rest of the design rem"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_28", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 28, "text": "This ECO process is executed, and an incremental compilation run is performed. This means that only the parts of the design that are affected by the ECO process are changed. The rest of the design remains unchanged. Once the whole design is successfully veriÔ¨Åed, and all targets are met, the manufacturing of the MCU design is started, which is known as the tape-out . This is also the transition from Pre-Si to Post-Si phase. The manufacturing process of MCUs in advanced complementary metal oxide semiconduc- tor (CMOS) technology is a complex and elaborating process with plenty of chemical and physical steps on a silicon wafer. Multiple chips, also denoted as dies, are contained on a single wafer. After the wafer manufacturing, the MCUs are tested for the Ô¨Årst time, called the front-end (FE) wafer test. The wafer is mounted on a chuck during the front-end (FE) wafer test. Afterward, the dies are separated by sawing the wafer into bare dies. The bare die, where the FE test is passed, is assembled in a package. The next step is the burn-in to detect early fails and ensure high reliability, followed by the Ô¨Ånal back-end (BE) test. The 9 2. Background Ô¨Ånally produced MCU is extensively ch"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_29", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 29, "text": "sembled in a package. The next step is the burn-in to detect early fails and ensure high reliability, followed by the Ô¨Ånal back-end (BE) test. The 9 2. Background Ô¨Ånally produced MCU is extensively characterized, and it is validated, if the functionality is correct and all requirements are fulÔ¨Ålled. This is the terminus of the prototype development. If issues are identiÔ¨Åed, a redesign might be performed, or minor improvements are required. Finally, the MCU is transferred to mass production [56]. Note that the development process explained is a high-level overview; the entire MCU Ô¨Çow has much more detail that is neglected in this explanation. 2.2. Timing and Performance of digital Circuits Modern MCUs consist of numerous architectural components. A large part consists of digital circuit elements, which is also the focus of this work. Besides that, there are also memories, analog circuit parts, and various interfaces on modern MCUs. Digital circuits are built on CMOS combinational and sequential circuit elements. All such circuit elements are part of a cell library containing CMOS circuit elements (FFs, Inverter, NOR - gates, AND - gates, . . . ) of different sizes, speeds, power, an"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_30", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 30, "text": "quential circuit elements. All such circuit elements are part of a cell library containing CMOS circuit elements (FFs, Inverter, NOR - gates, AND - gates, . . . ) of different sizes, speeds, power, and other factors and denoted as standard cells . All CMOS elements are built using NMOS and PMOS transistors. The logic synthesis translates the RTL description into a netlist using such cell libraries. The synchronous digital design uses edge-triggered FFs as sequential circuit elements. The FFs are triggered by a synchronous clock signal CLK distributed via the clock tree. Thus, there can be distinguished between clock paths and data paths. The clock tree distributes the clock signal over the chip, and data paths care for the chip‚Äôs functionality. The data paths with combinational logic elements are arranged between the clock-triggered FFs. Thus, the data signal must propagate from the designated launch FF ( FF1) through the combinatorial logic to the desired capture FF ( FF2) in each clock cycle, as shown in Figure 2.2. CLKD1 Q1 FF1 CLKD2 Q2 FF2data in CLKFunctional Combinatorial Logic Figure 2.2.: Synchronous combinational logic path with launch and capture FF. The clock-triggered F"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_31", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 31, "text": "ck cycle, as shown in Figure 2.2. CLKD1 Q1 FF1 CLKD2 Q2 FF2data in CLKFunctional Combinatorial Logic Figure 2.2.: Synchronous combinational logic path with launch and capture FF. The clock-triggered FFs typically have 3ports, 2input ports and 1output port. The port Dis the input from the data path (data_in), and the port Qis the output for the data path. The clock signal is connected to the port CLK . Once the CLK port detects a positive edge, the data is transferred from DtoQ. Thus, the data on D1 in Figure 2.2 is latched from D1toQ1with a rising clock edge. The 10 2. Background data then traverses the data path and the data should arrive at D2before the rising clock edge and then be latched from D2 to Q2 on another rising clock edge. However, there is no instantaneous propagation from launch FF to capture FF due to individual delay time of the combinational logic elements of the data path. The data path delay is the sum of the delay of the individual library gates and the respective interconnects. In order to ensure proper functionality of the synchronous circuit, the timing between clock and circuit is essential. Therefore, certain timing constraints have to be met within the se"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_32", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 32, "text": "interconnects. In order to ensure proper functionality of the synchronous circuit, the timing between clock and circuit is essential. Therefore, certain timing constraints have to be met within the sequential circuits. Important timing constraints for the FF are the setup and hold time. The setup time tsetup is the minimal time previous to the positive clock edge in which the data input requires a stable signal. During the hold time thold, the data input has to remain stable after the positive clock edge. The relation between the minimum clock period Tand the time constraints can be expressed as [57] T\u0015tc\u0000q+dPath MAX+tsetup, (2.1) and the hold time hast to ensure such timing constrains tc\u0000q+dPath MIN\u0015thold. (2.2) Here, the clock-to-Q-delay tc\u0000qis the internal propagation delay required by the FFs to propagate the D to Q on a positive clock edge. For Equation 2.1, the worst-case propagation delay dPath MAXof the path must be considered. Whereas in Equation 2.2 the best case consideration dPath MINof the path is taken into account. Timing constraints must be met in terms of setup and hold time for a given clock period; otherwise, timing is violated. A valid timing of the circuit illu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_33", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 33, "text": "n dPath MINof the path is taken into account. Timing constraints must be met in terms of setup and hold time for a given clock period; otherwise, timing is violated. A valid timing of the circuit illustrated in Figure 2.2 is shown in Figure 2.3. CLK Data at D2 Data can toggleStable Data can toggletsetup tholdslack Figure 2.3.: Timing diagram of a capture FF in a synchronous digital circuit illustrating setup and hold time and slack. The slack is also indicated in the Figure 2.3. The slack is the difference between the required arrival time where the tsetup is met and the actual arrival time. The setup timing is met when 11 2. Background the slack is positive (greater or equal to 0). A synchronous MCU design consists of several millions of paths which all have to meet the timing given the clock period. Thus the performance FMAX (maximum achievable clock frequency) of an MCU can be expressed as FMAX =1 T. (2.3) The shorter the clock period T, the higher the performance of an MCU. However, the timing constraints must be observed under all circumstances. The Process-Voltage-Temperature (PVT) variation plays an important role here. 2.3. PVT Variations The Process-Voltage-Temperature (PV"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_34", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 34, "text": ", the timing constraints must be observed under all circumstances. The Process-Voltage-Temperature (PVT) variation plays an important role here. 2.3. PVT Variations The Process-Voltage-Temperature (PVT) variation signiÔ¨Åcantly impacts the timing of digital circuits, and it is becoming more critical in shrinking technology nodes [58, 59]. The digital circuitry has to ensure error-free working within the speciÔ¨Åed PVT range. The process variation is related to the variation in semiconductor manufacturing due to the complex process steps. The voltage variation impacts the operating voltage of the CMOS transistors, and the temperature is related to the die temperature, which also has a signiÔ¨Åcant impact. In this section, PVT variations and their effects are explained. It also presents the methodology for handling the sources of variation in modern MCUs. 2.3.1. Process Variations Process variation arises from the variability of process parameters during the complex manufacturing process of semiconductors. The process variation is caused by the limited control of such process parameters, which results in variability from the deÔ¨Åned design target [60]. MCUs are manufactured by multiple chem"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_35", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 35, "text": "miconductors. The process variation is caused by the limited control of such process parameters, which results in variability from the deÔ¨Åned design target [60]. MCUs are manufactured by multiple chemical and mechanical processes based on a silicon wafer. A sequence of different process steps is executed called photolithography. Masks are used in the steps to build CMOS transistors on the plain silicon wafer. The hypothetical number of masks for building an inverter is six; however, the number and complexity of masks used for large MCUs can be enormous. The process steps, e.g., epitaxy, deposition, and implantation, are repeated until the MCU is manufactured. The metallization and interconnects are also part of the manufacturing process. Such parts connect the sources, drains, and gates accordingly and ensure power distribution [61]. The process variation impacts the Ô¨Ålm thickness, lateral dimensions, and doping concentra- tion, resulting in variations in channel length and threshold voltage [62]. This impacts the 12 2. Background timing of the MCU and, therefore, the performance of each manufactured device [60]. The impact of the process variation can be classiÔ¨Åed into inter-die a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_36", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 36, "text": "oltage [62]. This impacts the 12 2. Background timing of the MCU and, therefore, the performance of each manufactured device [60]. The impact of the process variation can be classiÔ¨Åed into inter-die and intra-die variations. 2.3.1.1. Inter-die variation Inter-die variations are process variations that affect all transistors on a die similarly, e.g., all transistors‚Äô channel length on a die might be too long related to the speciÔ¨Åed value. Those process variations are also called global process variations. The inter-die variation is further distinguished into lot-to-lot (L2L) variations, wafer-to-wafer (W2W) variations, and die-to-die (D2D) variations [61]. The wafers are processed in stacks called lots. There might be some maintenance steps from lot to lot, impacting the process variation. The same is also for W2W variation, which causes a different timing behavior from wafer to wafer. The D2D variation is visible on the wafer; e.g., a die on the wafer edge behaves differently from the die in the wafer center, mainly caused by D2D variations in manufacturing [61]. A wafer signature caused by D2D variation is shown in Figure 2.4, where the frequency of an RO is plotted for each die o"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_37", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 37, "text": "die in the wafer center, mainly caused by D2D variations in manufacturing [61]. A wafer signature caused by D2D variation is shown in Figure 2.4, where the frequency of an RO is plotted for each die on the wafer. Ring oscillator frequency lowhigh Figure 2.4.: Wafermap shows the D2D variations from the frequency of an RO. The same RO is integrated at each die on the wafer. The dies on the wafer edge have a lower frequency of the RO than those in the center. Thus there is a radial D2D variation visible on the wafer [60]. Besides such centric radial D2D variation, several other wafer signatures are present in semiconductor manufacturing, which can also lead to defects on the wafer [63]. 2.3.1.2. Intra-die variation The intra-die variations affect various parts of the chip or transistors differently. They are also known as local variations or within-die (WID) variations. The WID variations were smaller in mature nodes than the D2D variations; however, they became more important in nanometer process nodes [61, 64]. Such WID variations can be categorized into two types: pure random variation and spatially correlated variations. Pure random variations are local variations that are, by nat"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_38", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 38, "text": "r process nodes [61, 64]. Such WID variations can be categorized into two types: pure random variation and spatially correlated variations. Pure random variations are local variations that are, by nature, randomly distributed across the chip with no recognizable pattern or signature. The main root cause of such variations 13 2. Background are random dopant Ô¨Çuctuations (RDF) and line edge roughness (LER) [65]. The spatially correlated variations are also known as location-dependent variations. It shows that the parameter change of one device is correlated with the change of the same parameter of all other devices on the chip. The magnitude of the correlation between the parameters varies depending on their physical position on the chip. The main physical transistor parameters affected by spatially correlated variations are channel length ( L), channel width ( W), and oxide thickness ( Tox) [60]. 2.3.1.3. Interconnects In addition to process variation in transistors, process variation in interconnects is also an important factor. The interconnects are wires that are used to connect the transistors, and they also have a signiÔ¨Åcant contribution to the delay due to their resistance and "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_39", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 39, "text": " interconnects is also an important factor. The interconnects are wires that are used to connect the transistors, and they also have a signiÔ¨Åcant contribution to the delay due to their resistance and capacitive components called RC delay . The process variations affect the line width and spacing, the metal and dielectric thickness, and the contact resistance. This variation, in turn, affects the RC delay. Also, long wires have signiÔ¨Åcant resistance that dominates the RC delay of an interconnect. State-of-the-art MCU do have multiple layers of closely packed interconnects to cope with the design complexity on the MCU; therefore, the interconnects, and their RC delay become increasingly important [61]. 2.3.2. Voltage Variations Besides the process variation, the environmental operating conditions, such as voltage and temperature, signiÔ¨Åcantly impact the timing of the circuitry and, therefore, its performance. The voltage variation is due to the supply voltage of the transistor. Since the manufactured nodes are rapidly decreasing, the power delivery network (PDN) and packaging follow at different paces. The supply voltage variation can be caused outside the chip due to the power suppl"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_40", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 40, "text": " manufactured nodes are rapidly decreasing, the power delivery network (PDN) and packaging follow at different paces. The supply voltage variation can be caused outside the chip due to the power supply and within the chip due to the package and interconnects. State-of-the-art MCUs operate in the sub-threshold region and are even more sensitive to voltage variation. Voltage variations are categorized into two main categories: IR drop and current derivative di/dtnoise [66]. The IR drop is also called voltage drop. It is caused mainly by the resistive components. That can be either off-chip (e.g., contact resistance, imperfect power supply) or on-chip caused by PDN. The IR drop is independent of the frequency and follows Ohm‚Äôs Law. On the other hand, the parasitic inductance causes the noise of the current derivative. The switching activity of the transistors has the most signiÔ¨Åcant inÔ¨Çuence on the noise of the current derivative. Strong load jumps can cause voltage undershoots or voltage overshoots [66]. Depending on the root cause of the voltage variation, the duration can be in the nanosecond 14 2. Background range for high-dynamic events until voltage variations in the microsecond"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_41", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 41, "text": " overshoots [66]. Depending on the root cause of the voltage variation, the duration can be in the nanosecond 14 2. Background range for high-dynamic events until voltage variations in the microsecond range, depending on how fast the power supply can compensate for the variation. The voltage deviations impact the timing of the entire chip. The gate delay time is proportional to the voltage and follows the formula [67] tgate¬µV (VTH\u0000V)a. (2.4) Where V(VDD\u0000VSS) is the supply voltage, VTHis the threshold voltage of the transistor, and ais a technology-dependent parameter. Thus, if the Vis close to the VTH, the voltage variation does have a major impact on the timing. There is a need to monitor the voltage precisely and react to occurring voltage variations immediately in designing a robust PDN, e.g., by using considerable supporting capacities. The tolerable voltage variation often found in the literature and on product data sheets is \u000610 % of V[68, 69, 17, 61]. 2.3.3. Temperature Variations The second environmental condition which has a major impact on the timing behavior is the temperature. The temperature of the chips can be inÔ¨Çuenced by the ambient temperature or thermal hotspots o"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_42", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 42, "text": "ns The second environmental condition which has a major impact on the timing behavior is the temperature. The temperature of the chips can be inÔ¨Çuenced by the ambient temperature or thermal hotspots on the chip itself. The ambient temperature depends on whether the chip is operated in different climatic regions (desert climate or polar regions) or how powerful the external thermal system (heating or cooling) is at the system level as well as on the application area (e.g., commercial, military) [61]. Thermal hotspots occur in high-switching active areas due to the power dissipated by the transistors. This also depends on how effective the thermal conduction of the chip can dissipate the heat from chip regions. Compared with the voltage variations, the temperature variations have a higher time constant in the range of milliseconds to seconds [69]. An increase in temperature elevates the delay of the interconnects due to their parasitic resistance. The temperature behavior of the gate propagation delay depends on the voltage, especially if the device is operated in the sub-threshold region due to weak carrier mobility [70]. This effect is called inverse temperature dependence (IDT). T"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_43", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 43, "text": "pagation delay depends on the voltage, especially if the device is operated in the sub-threshold region due to weak carrier mobility [70]. This effect is called inverse temperature dependence (IDT). The timing behavior and, therefore, the performance of a device depends on the dominance of the IDT. If long intercon- nect delays dominate the timing behavior of a device, the device will most likely be limited at high temperatures. If logic gates dominate the timing, cold temperatures are worse. In conclusion, considering PVT variation in MCUs is crucial for reliable device timing and performance. Much effort is needed to ensure a proper function over the speciÔ¨Åed operation window. This includes that all hold and setup constraints are met. In order to achieve this, the timing behavior for each PVT case must be covered and veriÔ¨Åed during the design phase as well as validated in the Post-Si phase. 15 2. Background 2.3.4. Methods to cope with PVT Variation The PVT variations need to be considered during the design in the Pre-Si and the Post-Si phase since their timing inÔ¨Çuence is tremendous. Figure 2.5 comprehensively demonstrates the inÔ¨Çuence of the PVT variations with respect to the pe"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_44", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 44, "text": "dered during the design in the Pre-Si and the Post-Si phase since their timing inÔ¨Çuence is tremendous. Figure 2.5 comprehensively demonstrates the inÔ¨Çuence of the PVT variations with respect to the performance [71]. ProcessPerformance worst bestslowfastP VoltagePerformance low highV slowfast TemperaturePerformance IDT low highT slowfast Figure 2.5.: Relation between PVT variations and performance. The most common methodology to cope with the PVT variations in the Pre-Si design phase is performing corner analysis to investigate the speciÔ¨Åed PVT space with the help of powerful electronic design automation (EDA) tools. The Post-Si validation uses corner lots to explore the process range in manufacturing, and voltage and temperature are environmental components addressed with the test setup. 2.3.4.1. Corner Analysis in Design Phase Corner analysis, also known as corner case analysis or process corner analysis, is a technique used in design to evaluate the timing and performance of integrated circuits under different operating conditions. It involves simulating the circuit behavior across the PVT range in so-called corners. Especially, corner analysis aims to assess how the circuit beha"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_45", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 45, "text": "ed circuits under different operating conditions. It involves simulating the circuit behavior across the PVT range in so-called corners. Especially, corner analysis aims to assess how the circuit behaves under the worst-case conditions. In terms of process corners, the transistor manufacturing processes are clustered into slow (S) ,typical (T) (also called nominal ), and fast (F) . The CMOS technology uses two types of transistors: the nMOS and pMOS. The two transistor types are treated independently. That results in the process corners shown in Figure 2.6. The Ô¨Årst character corresponds to the process corner of the nMOS, and the second character to the pMOS - as color-coded in Figure 2.6 [61]. Besides the transistor process corners, the interconnects are also considered with their parasitic RC components. The RC components are also simulated as slow, typical, and fast. The environmental conditions - voltage and temperature - are also considered in the same way to be S,T, or F. The fast corresponds to high voltage and low temperature and slow corresponds to low voltage and high temperature, in between such conditions is the typical case [61]. Due to the IDT, the worst temperature c"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_46", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 46, "text": "t corresponds to high voltage and low temperature and slow corresponds to low voltage and high temperature, in between such conditions is the typical case [61]. Due to the IDT, the worst temperature case can change depending on the design, 16 2. Background nMOSpMOS SSFF TT FSSF slowfast fast Figure 2.6.: Corner cases of a CMOS transistor. as explained in Section 2.3.3. In order to ensure a proper function of the design, a multi-corner analysis is required to ensure the correct timing behavior in each speciÔ¨Åed corner. The nomenclature of such a multi-corner is usually expressed in the three design corners ( S,T,F) cases. Therefore an SFTSS corresponds to a slow nMOS, a fastpMOS, a typical RC, slow voltage (min), and slow temperature (hot). The design must be veriÔ¨Åed in every corner. Timing veriÔ¨Åcation using tools like Simulation Program with Integrated Circuit Empha- sis (SPICE) is not feasible due to the complexity of large designs and limited computing power [72]. In addition, such tools are primarily intended for analog simulations at the transistor level. Therefore, a powerful method called static timing analysis (STA) is used to perform timing veriÔ¨Åcation in digital circuits. T"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_47", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 47, "text": "ols are primarily intended for analog simulations at the transistor level. Therefore, a powerful method called static timing analysis (STA) is used to perform timing veriÔ¨Åcation in digital circuits. The STA is a method to investigate and verify the timing of the MCU without simulating the full design. The entire design is analyzed to determine if all timing constraints are met for every corner. The setup critical timing paths are typically suspected in the slow corners, whereas the fast corners face hold time violations. The term static refers to the circumstance that the design is analyzed in a static condition by not taking care of any input or output data - which is the case in performing a simulation. The STA is performed as one of the last steps before tape out to ensure the design‚Äôs timing closure. EDA tools exist to accomplish an STA on the design and identify weaknesses. Especially the worst-case corners are focused on ensuring a robust design [71, 73]. However, the STA using the corner-based approach has limitations. Especially when WID variation becomes dominant, this can not be handled with the corner-based STA [74, 17]. There are methods like statistical static timing a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_48", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 48, "text": "he corner-based approach has limitations. Especially when WID variation becomes dominant, this can not be handled with the corner-based STA [74, 17]. There are methods like statistical static timing analysis (SSTA) [64] that manage the WID variations in designs - however, SSTA still needs to be consistently adopted across the industry [75, 32]. The typical approach to mitigate timing uncertainties caused by WID and noise is the use of additional margins. Those margins are on top added to the STA results, 17 2. Background adding pessimism and reducing the risk in the overall timing veriÔ¨Åcation [71]. 2.3.4.2. Corner Lots in Post-Silicon In distinction to Pre-Si veriÔ¨Åcation, the manufactured device must also be validated across the PVT corners in Post-Si. In order to cover the entire PVT space, corner lot wafers are manufactured. Such corner lot wafers are special Ô¨Çavors of wafer in which the manufacturing parameters are reÔ¨Çected. For example, the manufacturing parameters of all nMOS transistors on the wafer are tweaked to be slow. In contrast, all pMOS transistors in the wafer are manufactured to be fast - in other words, an SFcorner lot wafer. The same parameter changes can be made "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_49", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 49, "text": "sistors on the wafer are tweaked to be slow. In contrast, all pMOS transistors in the wafer are manufactured to be fast - in other words, an SFcorner lot wafer. The same parameter changes can be made for all manufacturing parameters that can be selectively inÔ¨Çuenced - these can be transistor parameters as well as interconnect parameters. The amplitude of the deviation can also be adjusted from the typical value, which is given in sigma steps . The corner analysis of the environmental parameters voltage and temperature is easier to cover. The ambient temperature of the chip is adjusted using advanced temperature sources in the validation set-up. Even when the devices are on the wafer, such wafers are mounted on a chuck with very high-temperature stability. High-performance, high-precision power supplies can take over the power supply and allow the entire operating voltage range to be validated. The PVT validation of a device is part of the product characterization process [76]. 2.3.5. Additional Safety Margins Besides the PVT variation considered with the corner-based analysis, additional safety margins are required to ensure proper function. There are several reasons why those addi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_50", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 50, "text": "dditional Safety Margins Besides the PVT variation considered with the corner-based analysis, additional safety margins are required to ensure proper function. There are several reasons why those additional safety margins are required. Two reasons for additional margins in the timing veriÔ¨Åcation are explained. Modern MCUs operate with a clock frequency of several hundred megahertz. In operating mode with such high frequencies, electromagnetic cross-talk can occur, which impairs the signal integrity and, thus, the timing behavior. That electromagnetic cross-talk is, in most cases, an aggressor-victim scenario where the noise and emission of one particular region affect another region in which the timing error occurs [54]. The second added margin is the safety margin for aging. The MCU manufacturer has to ensure proper function in the delivery status and at the end of the life of the MCU. Several aging effects become more important in shrinking technology nodes, such as negative bias temperature instability (NBTI) and hot carrier injection (HCI), which also affect the timing behavior of the circuit [34, 77, 78]. The margins required to guardband the aging over the lifetime depend str"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_51", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 51, "text": "perature instability (NBTI) and hot carrier injection (HCI), which also affect the timing behavior of the circuit [34, 77, 78]. The margins required to guardband the aging over the lifetime depend strongly on the mission proÔ¨Åle. In order to ensure a proper function independent from the mission proÔ¨Åle, the added safety margins are intended to 18 2. Background cover the worst-case scenarios. This leads to the claim that the added safety margins are too pessimistic [79]. However, the additional safety margins in electromagnetic cross-talk and aging are manda- tory if the MCU controls safety-critical applications in automotive. 2.4. Testing of MCUs Since modern MCUs consist of more than hundreds of millions of transistors, the complex manufacturing process might lead to defects. Due to these defects, the MCUs might not be working properly. Thus, testing MCUs is essential in detecting such defects and ensuring an error-free operation. EfÔ¨Åcient testing ensures functionality, timing, and performance, making it crucial for modern electronic devices. Design for Testability (DfT) is an essential method to enable test. The basic principle of DfT and its infrastructure and approaches are expla"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_52", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 52, "text": "ormance, making it crucial for modern electronic devices. Design for Testability (DfT) is an essential method to enable test. The basic principle of DfT and its infrastructure and approaches are explained in this section. 2.4.1. Design for Testability (DfT) DfT is a bunch of approaches used to make testing easier and more effective. DfT is adding further logic and components to the design to create an infrastructure for the test of the design. This infrastructure is inserted along the industrial design process, as Figure 2.1 explains with an important DfT step - the scan insertion. A common DfT technique is the scan test ; this includes scan insertion and scan compression and utilizing various fault models to detect defects efÔ¨Åciently. The following section (section 2.4.1.1) will describe this method because of the fundamental importance of this work. Another common technique in DfT are boundary scan and memory/logic built-in self-test (BIST). Boundary Scan, or Joint Test Action Group (JTAG), is a technology used to test and debug MCUs without direct access to their pins. Instead, a standardized interface called JTAG is used to communicate with the MCUs. BIST is an on-chip test inf"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_53", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 53, "text": "(JTAG), is a technology used to test and debug MCUs without direct access to their pins. Instead, a standardized interface called JTAG is used to communicate with the MCUs. BIST is an on-chip test infrastructure to detect defects without using external test equipment. There are approaches to testing digital logic built-in self-test (LBIST) and on-board memory built-in self-test (MBIST), and those methods can also perform in-Ô¨Åeld tests [55]. 2.4.1.1. Scan Test Scan test is a standard technique used in digital MCUs nowadays. This is a structural test method to detect defects in the circuit deterministically. In order to realize this, some scan infrastructure is necessary. This process is called scan insertion. 19 2. Background Scan Insertion The scan insertion is done in two steps. First, the FFs and latches in the design are replaced with the so-called scan FFs . The scan FF is built with a multiplexer (MUX) and an ordinary FF; the scan FF is shown in Figure 2.7. CLKD Q0 1 CLKQD SI SE Figure 2.7.: Scan FF contains an ordinary FF and a MUX. Besides the data input port (D) and data output port (Q), and the clock (CLK), the scan FF has two additional ports: the scan input port (SI, sca"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_54", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 54, "text": "igure 2.7.: Scan FF contains an ordinary FF and a MUX. Besides the data input port (D) and data output port (Q), and the clock (CLK), the scan FF has two additional ports: the scan input port (SI, scan_in) and the scan enable port (SE, scan_en). The scan_en controls whether the latched input data of the internal FF captures from D input - called functional (or mission) mode- or the data is captured via the scan_in port - called scan mode. The second step is the connection of the previously placed scan FF to the so-called scan chains . The circuitry connectivity after the scan insertion is schematically shown in Figure 2.8 for a small circuit, demonstrating three scan FFs connected in one scan chain. CLKSID Q SECLKSID Q SECLKSID Q SEscan inscan out data indata out scan enCLKFunctional Combinatorial Logic Scan Chain Functional Path Figure 2.8.: Scan insertion replaces three FFs with scan FFs and connects them to a scan chain. The scan chain is colored in blue and runs from the scan_in through the SI of the Ô¨Årst scan FF. From the Q of the Ô¨Årst scan FF, the scan chain is connected to the SI of the next FF; this interconnection continues in this way. This is repeated until the last outp"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_55", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 55, "text": "rough the SI of the Ô¨Årst scan FF. From the Q of the Ô¨Årst scan FF, the scan chain is connected to the SI of the next FF; this interconnection continues in this way. This is repeated until the last output of the scan FF within the scan chain, which is the scan_out - the output of the scan chain. Large MCUs contain a large number of scan chains. The scan_en is valid for all scan chains. 20 2. Background If the MCU is in scan mode (scen_en is high), the scan chains are sequentially loaded with 0 or 1 until all scan FFs have the desired value. After that load phase, the scan_en is switched off, and one or more functional at-speed pulses occur, called launch and capture. Once this is done, the scan_en turns on again, and captured values are unloaded from the scan chains. Such unload values are compared with the expected values. The MCU passes the test if every captured value equals the expected value. Such scan test procedure is shown in Figure 2.9. CLK scan enshift capture shift 1 0 1 0 shift in data shift out data Figure 2.9.: Scan test procedure with a capture pulse. The input values are called test/scan vectors or patterns. The scan test is repeated and consists of thousands of scan "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_56", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 56, "text": "ft in data shift out data Figure 2.9.: Scan test procedure with a capture pulse. The input values are called test/scan vectors or patterns. The scan test is repeated and consists of thousands of scan patterns. This provides controllability and observability for every scan FF during the scan test. Scan Compression The scan chains become more extensive since more sequential scan FFs are included to cover the entire MCU. This would result in long scan chains and high effort to load and unload all scan chains with the scan pattern. Scan compression is an efÔ¨Åcient method to reduce the length of the scan chain and subsequently reduce the test time by introducing a decompressor and compactor. Figure 2.10 shows the scan compression methodology. Scan ChainsDecompressor Compactorscan in Pin scan out Pin SoC Figure 2.10.: Scan compression allows the parallel loading of scan chains with a decompressor and compactor through a single pin. The scan chains are arranged between the decompressor and the compactor. In that way, the length of the scan chains is reduced. The scan chains are loaded and unloaded at high-speed 21 2. Background scan_in and scan_out ports. The shift speed of the scan chains"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_57", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 57, "text": " compactor. In that way, the length of the scan chains is reduced. The scan chains are loaded and unloaded at high-speed 21 2. Background scan_in and scan_out ports. The shift speed of the scan chains remains nearly the same. However, the overall test time is reduced with this approach. 2.4.2. Fault Models The test vectors/ scan patterns are not randomly chosen sequences of bits; instead, the test vectors are associated with fault models. Fault models are a formal abstraction where a fault is a logic description of the effect when a defect is present in the digital logic circuitry of the MCU. Dedicated test vectors are calculated using such fault models to test the digital logic for correct functionality. Such fault models aim to ensure defect-free circuitry after applying all variants of the dedicated fault model to all gates of the logic circuit. The metric to quantify the covered defect-free logic is called fault coverage . The fault coverage is calculated for each fault model, and several fault models are in use. There are two classes of fault models: static fault models and dynamic fault models. Static fault models focus on static defects in the circuitry independent of any ti"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_58", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 58, "text": "several fault models are in use. There are two classes of fault models: static fault models and dynamic fault models. Static fault models focus on static defects in the circuitry independent of any timing constraint. Commonly used static fault models are the Stuck-at-Fault model and the Bridging-Fault model [80, 81]. Such fault models are also used for IDDQ tests. Dynamic fault models, in turn, consider the circuit‚Äôs timing behavior and are executed at speed. Widely used dynamic fault models are the Transition Fault, Gate Delay Fault, and Path Delay Fault Models. The Transition Fault model and Gate Delay Fault are aiming localized timing faults within the logic circuit. The path delay fault model considers the timing behavior of the entire path. The path delay fault model is used in this work and described in detail in the following. Path Delay Fault Model The path delay fault model [82] aims to check if the path‚Äôs timing is met within the clock cycle. In order to do this, the path delay fault model is executed at speed in the capture phase in contrast to the sequence shown in Figure 2.9. Therefore, two clock pulses are executed during the capture phase; the Ô¨Årst is the launch puls"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_59", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 59, "text": "ay fault model is executed at speed in the capture phase in contrast to the sequence shown in Figure 2.9. Therefore, two clock pulses are executed during the capture phase; the Ô¨Årst is the launch pulse, and the second is the capture clock pulse. The test sequence is shown in Figure 2.11. CLK scan enshift capture shiftlaunch capture1 0 1 0 shift in data shift out data Figure 2.11.: Scan test using a path delay fault model. During the shift in phase, the path to be tested is prepared, also known as path sensitization. 22 2. Background This means that all side inputs of the path need to be on a stable value. In addition, the side input needs to be on a non-controlling value. Once these requirements are fulÔ¨Ålled and the path is sensitized, the launch pulse is executed at the launch point; this is a controllable and observable point in the circuitry - a scan FF. The launched transition is then propagated through the sensitized path and is captured with the second clock pulse - the capture pulse - at the capture point, which is usually also a scan FF. The time between launch and capture clock pulse is at regular operation clock speed. The captured value is then shifted out, and the actua"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_60", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 60, "text": "ulse - at the capture point, which is usually also a scan FF. The time between launch and capture clock pulse is at regular operation clock speed. The captured value is then shifted out, and the actual captured values are compared with expected values. If the expected values equal the actual values, the path delay test is successful. The path description to be tested must be provided for every path delay test. The path delay fault patterns are distinguished in several modes based on sensitization criteria. The weakest path sensitization is functional sensitizable, which means that the path propagates the transition during the test, but the side inputs do not need to be stable. The non-robust mode ensures that the side inputs are only on a stable non-controlling value during the capture clock pulse. The tightest mode is the robust one, which requires stable non-controlling values at all side inputs during the launch and capture clock pulse [83, 84]. There is also the additional option of the hazard-free mode, which is even a little stricter than the robust mode. In this mode, an attempt is made to prevent glitches and reconvergence in the path [68]. Dependent on the sensitization mo"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_61", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 61, "text": "f the hazard-free mode, which is even a little stricter than the robust mode. In this mode, an attempt is made to prevent glitches and reconvergence in the path [68]. Dependent on the sensitization mode chosen, it becomes more challenging to calculate a path delay test pattern that fulÔ¨Ålls all sensitization requirements. In addition to the sensitization mode, the clock handling can also be adjusted, the launch- off-shift (LOS) and launch-off-capture (LOC) mode [85, 86]. The LOC method was implicitly introduced in Figure 2.11. Such a mode allows a clear distinction between shift and capture - the shift phase cares for path sensitization, and the two at-speed clock pulses are executed in the capture phase. Instead, LOS squeezes the launch clock pulse into the end of the shift phase. Both approaches have their advantages and disadvantages [68]. Due to strict separation in shift and capture, the LOC will be the essential mode in this work. There are many constraints in the calculation of scan patterns for large MCUs, so EDA tools are used, especially the automatic test pattern generation (ATPG). 2.4.2.1. Automatic Test Pattern Generation ATPG is a methodology to generate test patterns "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_62", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 62, "text": "can patterns for large MCUs, so EDA tools are used, especially the automatic test pattern generation (ATPG). 2.4.2.1. Automatic Test Pattern Generation ATPG is a methodology to generate test patterns used in the industrial environment by considering the fault models mentioned in Section 2.4.2. An ATPG tool is a software tool that generates test patterns for a given MCU design. The ATPG tool requires the netlist of the design with the already placed scan infrastructure. Based on the fault model determined, the ATPG tool calculates scan patterns to achieve high fault coverage for a wide range of potential faults in the circuit. The resulting scan patterns are in an ASCII Ô¨Åle format called 23 2. Background waveform generation logic (WGL) or standard test interface language (STIL). The scan pattern in WGL/STIL format is required to test an MCU in an industrial test environment using automatic test equipment (ATE). 2.4.3. Automatic Test Equipment The automatic test equipment (ATE) is the hardware instrument on which the DUT is mounted during the test procedure. The ATE provides power to the DUT and applies all test patterns. The ATE itself is a complex real-time system that can leverage"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_63", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 63, "text": "rdware instrument on which the DUT is mounted during the test procedure. The ATE provides power to the DUT and applies all test patterns. The ATE itself is a complex real-time system that can leverage many DfT methodologies. The scan patterns in WGL format are read into the ATE. Regarding the execution of the test, the ATE generates the stimuli for the scan_in port and loads the scan chains. The clock signal is also controlled via the ATE, as well as the comparison of the scan_out values with the expected values is checked on the ATE. Such MCU testing can be done on the wafer level where the pads on the die are connected with needles from a probe card to the ATE or with package MCU which is then mounted on a socket through the ATE. With the ATE, fast, precise, and automated execution is enabled [87, 55]. 2.5. Performance testing In this section, the performance testing is explained. The performance of an MCU is the maximal achievable clock frequency of the device under worst case conditions. The perfor- mance of an MCU is also denoted as FMAX . The approach to test the performance is called performance screening , in which the FMAX of every device is checked. The term speed binning"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_64", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 64, "text": "tions. The perfor- mance of an MCU is also denoted as FMAX . The approach to test the performance is called performance screening , in which the FMAX of every device is checked. The term speed binning is also used for this approach which suggests an instantaneous sorting in categories according to the speed of the devices. The performance testing of large modern MCUs is challenging due to the complex design and PVT variations. Structural dynamic scan patterns (see Section 2.4.1.1 - transition fault pattern, path delay fault pattern) are not suitable for precise performance testing. This has two reasons, the scan patterns provide only a pass/fail criterion, and second is not possible to determine the unique performance limiting paths. Many near-critical timing paths are in modern MCU designs, resulting in a timing wall. As a result, it is practically impossible to determine the path that is causing the performance limitation on large MCUs. Therefore, other approaches are necessary to determine the performance of the chip. The following sections present two commonly used methods which are central pillars of this work. Note that the performance testing does not aim to detect devices w"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_65", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 65, "text": "termine the performance of the chip. The following sections present two commonly used methods which are central pillars of this work. Note that the performance testing does not aim to detect devices with physical defects (e.g., shorts, opens); structural scan tests are used for this purpose. 24 2. Background 2.5.1. Performance Monitors One way to determine the performance of a chip is to use indirect performance monitors [26, 27, 28, 29, 30, 31, 21]. Such performance monitors are ring oscillators (ROs). An RO is an odd number of Ninverting logic gates connected serially, forming a closed loop. The basic structure of an RO using inverter gates is shown in Figure 2.12. 1 2 3 4 N out ‚Ä¢ feedback loop Figure 2.12.: Basic principle of an RO using inverter gates. Each logic gate in the RO and the interconnects in between add delay to the overall timing of the RO. A positive or negative edge is launched at the start of the RO once the power supply is switched on, and the signal propagates through the logic gates in the RO. Due to the odd number of logic gates and, therefore, the implicit inverting behavior of the RO, the positive/negative edge becomes inverted at the end of the RO. Then th"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_66", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 66, "text": "ugh the logic gates in the RO. Due to the odd number of logic gates and, therefore, the implicit inverting behavior of the RO, the positive/negative edge becomes inverted at the end of the RO. Then the inverted edge is propagated through the feedback loop, triggering the next negative/positive edge. This results in a continuous oscillation where the frequency of the RO is the critical metric that is measured on the output. The oscillation frequency fof an RO is expressed as f=1 2TRO, (2.5) where TROis the delay time of the RO. TROis calculated as follows, TRO=TGate\u0001N+TLoop. (2.6) TGateis the propagation delay for each of the Ngates in the RO, and TLoopis the interconnect delay. The timing of the gates used in the circuit behaves similarly to those used for the ROs. This is why such ROs can be used as indirect performance monitors. In order to utilize ROs for performance testing, more than the basic RO structure shown in Figure 2.12 is needed. Thus there are various RO designs proposed and analyzed in literature. A fundamental distinction can be made between the two types of ROs: generic ROs and design-dependent ROs [29]. Generic ROs consist of a homogeneous logic gate type, e.g., i"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_67", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 67, "text": "and analyzed in literature. A fundamental distinction can be made between the two types of ROs: generic ROs and design-dependent ROs [29]. Generic ROs consist of a homogeneous logic gate type, e.g., inverter or NAND gate. Standard gate libraries used in large MCUs designs typically consist of several standard logic 25 2. Background gates in different driver strengths and further variations in the number of inputs/outputs and threshold voltages. Building one RO out of each used logic gate in the cell libraries would result in hundreds of generic ROs. Another way is to leverage the design information of the chip and build so-called design-dependent ROs. Such ROs aim to mimic the design of the chip. In order to do this, several methods are used, from straightforward path replicas to sophisticated synthesis algorithms considering the entire PVT space [38]. In the end, the performance test‚Äôs accuracy and quality highly depend on the sensitivity of the performance monitors used [39, 88]. Also, the value of Nhas a signiÔ¨Åcant impact. The visibility of D2D and WID process variation within an RO depends on the number of logic gates Nin the RO. Especially for smaller technology nodes ( <40 nm"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_68", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 68, "text": "o, the value of Nhas a signiÔ¨Åcant impact. The visibility of D2D and WID process variation within an RO depends on the number of logic gates Nin the RO. Especially for smaller technology nodes ( <40 nm ), the WID variability is only visible with short ROs containing less than 10gates. In comparison, the D2D variation is independent of N[88, 89]. Such ROs follow the process variation, usually Gaussian distributed [90]. In addition, Nalso affects the oscillation frequency, which is a considerable limitation for the frequency measuring gear and the resulting accuracy, and each additional gate contributes to the leakage current, which is also a critical variable in MCU requirements [87]. 2.5.2. Functional Testing Another fundamental approach in performance testing is the execution of functional tests. A functional test is named due to the fact that the functional test cases are executed on the MCU. Such functional test cases simulate different workloads or functional test cases of the MCU to Ô¨Ånd defects and complement structural testing [10]. The functional test is distinguished into two subgroups. The Ô¨Årst method is the traditional functional testing where small code pieces are uploade"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_69", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 69, "text": "o Ô¨Ånd defects and complement structural testing [10]. The functional test is distinguished into two subgroups. The Ô¨Årst method is the traditional functional testing where small code pieces are uploaded to the MCU on the automatic test equipment (ATE) and executed. The second method is the system-level test (SLT). The SLT is a time-consuming test where the MCU is mounted in an application-like board, and several test cases are executed. Such test cases can be customer application test cases of reusing veriÔ¨Åcation stimuli [13]. SLTs require lots of test time and are challenging in high volume production [25]. In contrast to the structural scan test, traditional functional testing and SLT do not have straightforward coverage metrics, making it difÔ¨Åcult to determine the testing quality [13]. In order to use the functional test for performance testing, there is a particular procedure. The clock frequency (execution frequency) of the DUT is executed at a low frequency in an inÔ¨Ånite loop. Then step by step, the clock frequency is increased. This is continued until the maximal execution frequency without a failure. Using that approach, the performance of a device is determined given the pa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_70", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 70, "text": "n step by step, the clock frequency is increased. This is continued until the maximal execution frequency without a failure. Using that approach, the performance of a device is determined given the particular functional test case [11]. 26 2. Background 2.6. Machine Learning in IC Testing 2.6.1. Machine Learning Basics The term machine learning was introduced by Arthur Samuel in 1959 [91]. machine learning (ML) describes a subÔ¨Åeld of artiÔ¨Åcial intelligence . ML facilitates computers (machines) to learn from existing data and predict the outcome of non-seen data without explicitly programming the computer. ML uses mathematical and statistical methods to identify the provided data‚Äôs patterns, relations, or similarities. The Ô¨Åeld of ML has been rapidly increasing in the last decades. Meanwhile, ML-based techniques can be found in numerous applications and industrial scenarios. The scope of ML is to Ô¨Ånd a function fthat describes the relation between the input data x and the output data y:f:x7!y. Since the function fis unknown and shall be learned by ML, the ML calculates an approximation function ÀÜfusing the provided dataset X-ÀÜfis also known as the ML model. Thus the input data xand o"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_71", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 71, "text": ":x7!y. Since the function fis unknown and shall be learned by ML, the ML calculates an approximation function ÀÜfusing the provided dataset X-ÀÜfis also known as the ML model. Thus the input data xand output data yare vectors. Each input xiis called a feature , and the output yiis called a label. In order to create an ML model, the provided dataset is split into a training set Sand a test setT(or validation set). The training set is used to train the ML model, which means Ô¨Ånding a suitable approximation function that maps the features of Sto the labels. Once the training is done and the ML model exists, the ML model is validated. The ML model validation feeds unseen features from the test set Tinto the ML model, and ÀÜyjis calculated. Then the ÀÜyjand known yjdeviation from the test set is compared. The ML model is scored depending on how well the predicted data and the known data Ô¨Åt. Scoring metrics are, for example, the mean absolute error (MAE) and the root mean square error (RMSE). ML can be divided into different subÔ¨Åelds as shown in Figure 2.13. The subÔ¨Åelds used in this work are supervised learning and unsupervised learning . Machine Learning Unsupervised Supervised Clustering D"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_72", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 72, "text": "can be divided into different subÔ¨Åelds as shown in Figure 2.13. The subÔ¨Åelds used in this work are supervised learning and unsupervised learning . Machine Learning Unsupervised Supervised Clustering Dim. Reduction ClassiÔ¨Åcation Regression Figure 2.13.: ML overview of approaches in this work. Supervised ML is the learning approach in which the features are mapped to the labels, and the ML model is considered a black box. Such a supervised learning algorithm aims to calculate a model that maps the input to the output data. Using the trained ML model, it is possible to predict the outcome of non-seen data using only the input data. The supervised ML can be categorized into classiÔ¨Åcation and regression [92]. 27 2. Background The classiÔ¨Åcation-based ML classiÔ¨Åes the labels into discrete categories or classes. Therefore the labels should be in a categorial data format. A straightforward example is the classiÔ¨Åcation into TRUE or FALSE based on the given features. The feature data type does not have to be categorical. In contrast, regression-based ML provides continuous numerical values for the output variable. They are often used to make precise numerical predictions. Unsupervised ML is a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_73", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 73, "text": "t have to be categorical. In contrast, regression-based ML provides continuous numerical values for the output variable. They are often used to make precise numerical predictions. Unsupervised ML is applied when only features are available for the training, and the labels are unknown. Thus it is not supervised by the labels - therefore, unsupervised. This type of learning intends to Ô¨Ånd patterns and statistical dependence in the features without prior knowledge of the outcome. Two often used unsupervised methodologies in ML are clustering and dimensionality reduction [92]. Clustering describes the process of dividing a dataset with features into groups or clusters with the same or similar characteristics. The clustering algorithm uses distance-based, density- based, or hierarchical approaches to cluster the dataset into distinct groups [93, 94, 95]. On the other hand, dimensionality reduction intends to transform (or Ô¨Ålter) the features into a reduced feature set. This should be done by keeping valuable information from the dataset. An often-used approach in dimensionality reduction is principal component analysis (PCA) which transforms the feature space into a reduced feature spac"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_74", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 74, "text": "y keeping valuable information from the dataset. An often-used approach in dimensionality reduction is principal component analysis (PCA) which transforms the feature space into a reduced feature space by considering the eigenvalues [96]. Dependent on the ML approach, there are different scoring and error metrics explained once used in the later sections. 2.6.2. Machine Learning in Testing Modern MCUs have become larger and more complex over recent years. This results in higher effort in testing to ensure the same or even higher quality. ML has become a well-established method for making testing more efÔ¨Åcient and manageable in the testing of MCUs [97, 98]. However, once ML is applied to real-world problems, it can help and harm. One of the most crucial things in ML applied to test is the choice of the training set. On the one hand, it shall identify outliers that are a risk for proper training. On the other hand, the trained ML model shall be robust and able to generalize. Thus, ML helps to determine devices in pass and fail and many other areas in testing. This work uses ML to manage the difÔ¨Åcult task of performance screening in automotive MCUs. 28 2. Background 2.7. Automotive Qu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_75", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 75, "text": "ps to determine devices in pass and fail and many other areas in testing. This work uses ML to manage the difÔ¨Åcult task of performance screening in automotive MCUs. 28 2. Background 2.7. Automotive Quality Automotive MCUs means that such MCUs are used in automotive applications that are often responsible for safety-critical systems. Such functional safety systems can be braking, steering, airbag systems, and numerous other automotive applications. Also, functional safety is essential for advanced driver-assistance systems (ADAS) and autonomous vehicles. The guidelines and standards for electronic components in functional safety automotive environments are described in ISO 26262 [99]. In addition, there are qualiÔ¨Åcation speciÔ¨Åcations and requirements deÔ¨Åned in AEC Component Technical Committee [5] agreed upon and deÔ¨Åned by a large automotive community. These guidelines and requirements show how important it is to deliver high-quality automotive MCUs. The quality and reliability of automotive MCUs are speciÔ¨Åed in defective parts per million (DPPM). In literature, the term PPM and the notation in defective parts per billion (DPPB) can be found. The critical metric remains the number o"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_76", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 76, "text": "otive MCUs are speciÔ¨Åed in defective parts per million (DPPM). In literature, the term PPM and the notation in defective parts per billion (DPPB) can be found. The critical metric remains the number of defective devices that successfully pass the test. Here, the devices are related to several ground truths (millions, billions). However, no severe rule exists for DPPM rates in the automotive industry [100]. Nevertheless, there is a solid strive to ensure zero defect quality, which means 0 DPPM accepted [101]. One of the most essential things to ensure zero defect quality is high qualitative testing [100, 102, 6]. The outcome of semiconductor testing is either the device passes all tests, or it fails the testing (one or more tests). On the other hand, there is the chance that the testing result is not correct. Either the test indicates that the device is pass whereas the actual device should fail or vice versa. This circumstance can be visualized in the confusion matrix shown in Figure 2.14. Such a metric can be used for all classiÔ¨Åcation problems and ML classiÔ¨Åcation. Actual DevicePredictedPositive workingNegative not workingNegative Positive True Negative (TN)False Negative (FN) Fa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_77", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 77, "text": ".14. Such a metric can be used for all classiÔ¨Åcation problems and ML classiÔ¨Åcation. Actual DevicePredictedPositive workingNegative not workingNegative Positive True Negative (TN)False Negative (FN) False Positive (FP)True Positive (TP) Figure 2.14.: Confusion matrix of a classiÔ¨Åcation problem. The confusion matrix have four potential outcomes. The true positive (TP) and true negative (TN) is clear - the test (predicted) result equals the actual state of the device. A false negative 29 2. Background (FN) that is tested fail but is actually pass will cause yield loss. Yield describes the proportion between devices tested as non-defective and the total number of tested devices. In order to make it clear: FN are fault-free devices that are thrown away due to the test result - the yield decreases. However, concerning automotive quality, the false positive (FP) devices are the most critical, also known as escapes, and harm the quality. In order to handle and manage this issue to guarantee automotive quality, the six sigma criterion can be deployed. 2.7.1. The Six Sigma Guardband The six sigma approach [103, 104] is a quality enhancement methodology and was invented by Bill Smith in the 1"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_78", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 78, "text": "tomotive quality, the six sigma criterion can be deployed. 2.7.1. The Six Sigma Guardband The six sigma approach [103, 104] is a quality enhancement methodology and was invented by Bill Smith in the 1980s. This approach aims to deliver high-quality products with as low defect rates as possible. This approach is applied to various quality management approaches to reach the ultimate quality goal. The six sigma approach assumes a Normal Distribution of the data under investigation. Thus, the mean is the center of the distribution, and one sis the average deviation distance from the mean value. 68% of the distribution area is between \u00061sof the mean value. Therefore, with a \u00066srange, there are at least 99.99966% in the distribution area. This corresponds in a statistical term with a defect rate of at least 3.4 defective parts per million (DPPM) - known as the Six Sigma Level [104]. The six sigma level of 3.4 DPPM assumes that a \u00061.5sshift of the Normal Distribution around the mean value is present. The shift margin is considered a batch-to-batch variation (D2D process variation) of the production concerning the high-quality level. If the process is perfectly centered, the resulting six "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_79", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 79, "text": "present. The shift margin is considered a batch-to-batch variation (D2D process variation) of the production concerning the high-quality level. If the process is perfectly centered, the resulting six sigma approach shows only a theoretical value of two defective parts per billion [103]. Hence, translating this into the testing environment, a margin of up to six sigma is needed to ensure automotive quality with minimal DPPM rates. The six sigma approach can be applied to ensure speciÔ¨Åc DPPM rates in performance testing, e.g., performance screening. 30 Chapter 2 Part I Part II Chapter 10 Chapter 3 Chapter 4 Chapter 5 Chapter 7 Chapter 8Chapter 6 Chapter 9 PRE-Silicon POST-SiliconBackground InformationFunctional Path ROsPath Selection MethodologyVerification and ValidationMeasurement and ValidationPerformance ScreeningConclusion and Future WorkTape - outOutline of Part I. Part I. PRE-Silicon 31 3. Functional Path Ring Oscillators 3.1. Basic Concept The functional path RO approach uses functional combinational logic paths within the MCU. The functional combinational logic paths run directly from register to register or from memory to memory and are typically used in the functional appl"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_80", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 80, "text": "ctional combinational logic paths within the MCU. The functional combinational logic paths run directly from register to register or from memory to memory and are typically used in the functional application of the MCU. Therefore, the behavior of the MCU is represented by the functional paths. A functional path in the design is denoted as pi. Two signiÔ¨Åcant changes in the circuitry are required to create a functional path RO out of an ordinary functional path, as shown in Figure 3.1. A multiplexer (MUX) is inserted at the start point of the combinational logic path, and a feedback loop is inserted connecting the end point of the path with the start point of the path. An RO requires inverting behavior by default (see. Section 2.5.1); the same requirements apply to the functional path RO. If the functional path behaves non-inverting, an inverter can be placed along the feedback loop. The MUX can be switched between functional mode (0) and oscillation mode (1); the latter can only be activated for test purposes. The control infrastructure maintains the control pin of the MUX ( enable ). Also, the oscillation frequency ( observe ) for further processing is connected with the control in"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_81", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 81, "text": "vated for test purposes. The control infrastructure maintains the control pin of the MUX ( enable ). Also, the oscillation frequency ( observe ) for further processing is connected with the control infrastructure. For further details regarding the control infrastructure, see Section 3.4. 0 1 enableMUX combinational logic path ‚Ä¢observe inverting behaviorREG/MEM REG/MEM Figure 3.1.: Example of a functional path RO. Adapted from [40] c IEEE 2021. However, the path by itself will not oscillate unless all supporting logic into the path is constrained to propagate the oscillating values along the path. Therefore the functional com- binational logic path has to be sensitized for a stable oscillation. The sensitization guarantees 32 3. Functional Path Ring Oscillators that all side inputs must be on a non-controlling stable value to ensure a stable oscillation of the functional path RO. A path sensitization with the respective side inputs is described in Figure 3.2. 12 3N ‚Ä¢ ‚Ä¢ observeSICLKD Q SE SICLKD Q SESICLKD Q SESICLKD Q SE SICLKD Q SE0 1 enable feedback loopscan enable scan enablescan enable scan enable scan enableclockclockclockclock clock01 0 1/01/01/0 0/1 1/00/1 Figure 3.2.: Path s"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_82", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 82, "text": "E SICLKD Q SESICLKD Q SESICLKD Q SE SICLKD Q SE0 1 enable feedback loopscan enable scan enablescan enable scan enable scan enableclockclockclockclock clock01 0 1/01/01/0 0/1 1/00/1 Figure 3.2.: Path sensitization of a functional path RO with the scan architecture. Adapted from [40] c IEEE 2021. When the MUX changes from functional mode to oscillation mode and the path is sensitized, the functional path RO oscillates by default due to its inverting behavior. Path sensitization can be accomplished by adding supporting logic to constrain all side inputs. Such an approach leads to many additional logic gates to the design and, therefore, much area overhead, which must be prevented in the competitive MCU market. The preferred solution is to use the existing DfT environment placed by scan insertion. A commercial ATPG tool is used to compute scan patterns based on an existing scan architecture that supports all logical assignments. Commercial ATPG tools support many DfT fault models. Fault models are classiÔ¨Åed into static and dynamic fault models. Static fault models, e.g., Stuck-at and IDDQ, can not handle the sensitization automatically. Each side input of a gate along the path under te"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_83", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 83, "text": "dels are classiÔ¨Åed into static and dynamic fault models. Static fault models, e.g., Stuck-at and IDDQ, can not handle the sensitization automatically. Each side input of a gate along the path under test (PUT) has to be constrained with the non-controlling value. Such constraining has to be done manually in static fault models. Thus, much effort is required, and the ATPG tool has difÔ¨Åculties handling the constraints, as it has to calculate a scan pattern (e.g., stuck-at), taking into account all constraints of the side inputs. This, however, is not possible in many cases. Dynamic fault models can support sensitization. In particular, the ATPG tool can perform dedicated path sensitization using the path delay fault model. The PUT is passed to the ATPG tool, and the tool attempts to sensitize the path with a scan pattern in path delay mode. This eliminates the need for manual handling of boundary conditions. The calculated path 33 3. Functional Path Ring Oscillators delay pattern ensures the oscillation of the functional path RO. The ATPG tool in path delay mode has different levels of sensitization. The robust detection provides the most powerful path sensitization, independent of a "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_84", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 84, "text": "the oscillation of the functional path RO. The ATPG tool in path delay mode has different levels of sensitization. The robust detection provides the most powerful path sensitization, independent of a clock event. In addition, the LOC method [85] is needed to generate the path delay pattern. This is because a fully sequential procedure is required to sensitize and measure the functional path ROs. Approaching the sensitization problem with ATPG has the disadvantage of limited path delay efÔ¨Åciency of commercial ATPG tools, which means that only a limited number of paths can be sensitized using a suitable robust detection algorithm. Also, the LOC method reinforces such limitations due to the sequential ATPG algorithm of the ATPG tool in the LOC method [86]. However, the lack of path delay efÔ¨Åciency is not a signiÔ¨Åcant limitation for functional path ROs. In large automotive MCUs, many paths can be sensitized with the ATPG tool in path delay mode. The path delay fault model using the LOC method has a Ô¨Åxed test procedure, including clock activity (see Figure 2.11). The resulting path delay scan pattern must be modiÔ¨Åed in some way to be suitable for the functional path RO approach. A typic"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_85", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 85, "text": "hod has a Ô¨Åxed test procedure, including clock activity (see Figure 2.11). The resulting path delay scan pattern must be modiÔ¨Åed in some way to be suitable for the functional path RO approach. A typical path delay pattern has three phases, the shift-in phase , the at-speed phase (for the launch and capture pulse), and theshift-out phase [86]. An additional phase is required when applying such a pattern for the functional paths ROs. The additional phase is the RO frequency measurement phase , which is inserted after the shift-in phase. The four phases of the functional path RO pattern are shown in Figure 3.3. CLK scan enshift measure capture shift t1 t2 launch capture1 0 1 0 Figure 3.3.: The test sequence during the scan test pattern. Adapted from [40] c IEEE 2021. The PUT is sensitized during the shift-in phase. At t1the MUX is switched from functional mode to oscillation mode, and the functional path RO starts to oscillate by itself. The oscillation frequency is measured in the measurement phase from t1tot2. During the measurement phase, the ATE determines the oscillation frequency of the RO. The frequency value is stored in the test database for further processing. The at-speed l"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_86", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 86, "text": "ement phase from t1tot2. During the measurement phase, the ATE determines the oscillation frequency of the RO. The frequency value is stored in the test database for further processing. The at-speed launch and capture phase is irrelevant to the functionality of the functional path ROs. The integration of the functional path RO measurement into the context of the ATPG scan pattern enables a fast measurement. The functional path ROs can then be activated with the 34 3. Functional Path Ring Oscillators scan pattern and thus easily implemented in the industrial design Ô¨Çow. The basic implementation presented above is called Option 0 . All functional paths pithat can be sensitized with a path delay pattern vpiare in the set P. The set Pcontains nfunctional paths, which can be represented in this way: P=fp1, . . . , png. All paths in Pare eligible for the Option 0. However, the main disadvantage of the Option 0 is the routing overhead, especially for the MUX‚Äôs enable signal and the observe signal used to measure the frequency. Both signals (enable and observe) have to be routed across the MCU for each RO individually. Accordingly, there will be many routing paths added in a large automoti"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_87", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 87, "text": "gnal used to measure the frequency. Both signals (enable and observe) have to be routed across the MCU for each RO individually. Accordingly, there will be many routing paths added in a large automotive MCU, especially when the functional path ROs are spatially distributed across the chip. Therefore, the upcoming section focuses on advanced implementation concepts to make the functional path ROs more efÔ¨Åcient in terms of implementation. 3.2. Advanced Implementation Concepts The functional path RO approach saves a lot of chip area compared with conventional RO approaches and enables a promising monitor structure by utilizing the DfT scan environment. However, the automotive MCU market is competitive, and every additional gate or routing line impacts the margin in the subsequent mass production of such MCUs. Therefore, this section focuses on concepts to implement the functional path ROs more efÔ¨Åciently to (i) minimize the impact on the functional circuitry and (ii) require as few additional gates and routing lines as possible. In doing so, the natural properties of the circuit are exploited by an intelligent combination and selection of functional paths. 3.2.1. Circuitry-Wise Optimi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_88", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 88, "text": "onal gates and routing lines as possible. In doing so, the natural properties of the circuit are exploited by an intelligent combination and selection of functional paths. 3.2.1. Circuitry-Wise Optimization The functional paths are distributed across the MCU. The idea of circuit-wise optimization is to Ô¨Ånd functional paths that inherently cause low routing overhead if they are implemented as ROs. Each functional path RO runs from the launch FF to the capture FF; both FFs are scan controlled. In state-of-the-art large MCUs, many such FFs are multi-bit FFs. This means they have numerous in- and output pins using the same synchronous clock signal. Consequently, there is a high likelihood that some functional paths share the same FF using different pins. There are four types of path topologies identiÔ¨Åed that indicate lower routing effort. The goal is to Ô¨Ånd functional paths which share the same FFs. The four types are shown in Figure 3.4. The launch / capture FF of a path pi/jis denoted as LFF pi/j/CFF pi/j. The Ô¨Årst type, Type 1 (Figure 3.4a) analyzes each path pi. If the LFF piis equal to the CFF pi, it can be assumed that 35 3. Functional Path Ring Oscillators launch point LFF pi ca"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_89", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 89, "text": " LFF pi/j/CFF pi/j. The Ô¨Årst type, Type 1 (Figure 3.4a) analyzes each path pi. If the LFF piis equal to the CFF pi, it can be assumed that 35 3. Functional Path Ring Oscillators launch point LFF pi capture point CFF pipi (a) Type 1 launch point LFF pipi pjcapture point CFF pi (b) Type 2 launch point LFF pipi pjcapture point CFF pi capture point CFF pj (c) Type 3 capture point CFF pipi pjlaunch point LFF pi launch point LFF pj (d) Type 4 Figure 3.4.: Four path topologies of functional paths. the path is self-contained, which means that the path is a cycle. In this case, routing for the feedback loop is not necessary. Figure 3.4b presents Type 2 the parallel paths, which checks if two paths ( piand pj) share the same LFF piand LFF pi. In that case, they can share the feedback loop because only one RO is activated during functional path RO measurement. Therefore, only one feedback loop is necessary for path topologies in Type 2. Furthermore, also only one routing line for the observe signal is needed. Type 3 (Figure 3.4c) and Type 4 (Figure 3.4d) are less restricted scenarios of Type 2. Instead of simultaneously checking for the same LFF piand CFF pi, Type 3 only checks for the same l"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_90", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 90, "text": "al is needed. Type 3 (Figure 3.4c) and Type 4 (Figure 3.4d) are less restricted scenarios of Type 2. Instead of simultaneously checking for the same LFF piand CFF pi, Type 3 only checks for the same launch FF, and Type 4 checks for the same capture point. The advantages are that only a single enable signal or a single observe signal is required. Each path is investigated regarding similarities of Type 1, 2, 3, 4. As described in Section 3.1 all functional paths must be sensitizable with a path delay pattern. Those functional paths, which are sensitizable and have the properties from Type 1, 2, 3, 4, are in the subsets PType 1,Type 2,Type 3,Type 4\u0012P. Another way to use topological properties is the concept of Natural Loops . Instead of looking for common FFs of the functional paths, natural loops look at the course of the paths across the chip. 3.2.2. Natural Loops The concept of natural loops is to use two or more functional paths and connect the end-point of one path to the start-point of the following path to create a functional path RO. The goal is to identify paths that can be connected with a natural loop in a way that the additional 36 3. Functional Path Ring Oscillators rout"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_91", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 91, "text": "t of the following path to create a functional path RO. The goal is to identify paths that can be connected with a natural loop in a way that the additional 36 3. Functional Path Ring Oscillators routing needed for the feedback loop becomes minimal. Figure 3.5 shows an example of two natural-looped paths. 0 1 01enable enableMUX ‚Ä¢ ‚Ä¢observe launch point LFF pi launch point LFF pjcapture point CFF pi capture point CFF pjpi pj Figure 3.5.: Basic concept of the natural loop approach. Path piis used as a forward line, Path pjis in the opposite direction and is used as a return line. This eliminates the need for a large part of the feedback loop and the signal buffers of the feedback loop. Thus, paths with long feedback loops are the primary candidates for this approach. Note that the inverting behavior of the paths within the natural loops must be ensured by additional inverters or a suitable selection of the paths. The natural loop functional path RO functionality in Figure 3.5 can be described as follows. The circuitry is in functional operation mode as long as the MUX switches are OFF (0). Once the MUXes are switched ON (1) and both paths are sensitized, the oscillation will start thr"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_92", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 92, "text": "ibed as follows. The circuitry is in functional operation mode as long as the MUX switches are OFF (0). Once the MUXes are switched ON (1) and both paths are sensitized, the oscillation will start through both paths. A prerequisite for this concept is that the ATPG tool can sensitize the connected paths with one path delay pattern. A modern ATPG tool tries to sensitize as many paths as possible with as few patterns as possible. Thus, one path delay pattern can be used to sensitize many paths. The patterns used for the natural loop approach must be able to sensitize at least two paths. All coordinates of each cell are known for the paths which are sensitized by a pattern. Thus, the start- and end-points of each path are known. Also, the physical length of the path can be calculated, given those coordinates. The coordinates of the start- and end-point and the physical path length are fed into an optimization algorithm. Based on the coordinate and length information, the algorithm decides whether the paths should be combined into a natural loop or remain independent functional path ROs. A criterion of the algorithm to select the natural loops is the overall path length and the expecte"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_93", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 93, "text": " whether the paths should be combined into a natural loop or remain independent functional path ROs. A criterion of the algorithm to select the natural loops is the overall path length and the expected length of the feedback loop. If both lengths are below a certain threshold value, the paths are not considered as natural loops. The threshold value needs to be set individually for an MCU design. Another criterion is the distance from the end-point of one path to the start-point of another path. If there are paths that run in the opposite direction and have their start- and end- points nearby, they are excellent candidates for the natural loop approach. 37 3. Functional Path Ring Oscillators Paths that have such properties are usually unidirectional buses. These buses run over a long distance, are in opposite directions and arranged in parallel. Whereas Section 3.2 focuses on concepts using topological properties of the functional path to reduce the routing and additional buffers, the following section presents the self-enabling approach. 3.3. Self Enabling The self-enabling approach targets reducing the routing of the enable and observe signal lines for the functional path ROs. The"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_94", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 94, "text": "ollowing section presents the self-enabling approach. 3.3. Self Enabling The self-enabling approach targets reducing the routing of the enable and observe signal lines for the functional path ROs. The prerequisite of the functional paths for such an approach is that they have to be in P- which implies the functional paths must be sensitizable with an appropriate path delay pattern. The implementations of the functional path RO published so far [40, 31, 21] require a separate enable signal that activates the oscillation. This enable signal must be generated and routed individually for each RO, which causes considerable effort, especially when implementing many functional path ROs. The self-enabling approach eliminates the need for the individual enable signal for the functional path ROs. The self-enabling approach activates the RO using the appropriate circuits and DfT methodology. The basic principle of a self-enabling functional path RO is shown in Figure 3.6, where the select pin of the MUX is connected to the corresponding launch FF LFF piof the path pi. Thus, the MUX is activated by the corresponding LFF pi. In other words, the functional path RO enables itself. 23N ‚Ä¢ SICLKD Q "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_95", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 95, "text": "the MUX is connected to the corresponding launch FF LFF piof the path pi. Thus, the MUX is activated by the corresponding LFF pi. In other words, the functional path RO enables itself. 23N ‚Ä¢ SICLKD Q SE SICLKD Q SE0 1scan enableself-enable combinational logic path pi launch FF MUXclockclock feedback loop‚Ä¢ 1/01/0 0/1 1/00/1 Figure 3.6.: The basic principle of the self-enabling approach of a functional path RO. Adapted from [41] c IEEE 2022. Each path piis sensitized with a corresponding path delay scan pattern vpi. When the scan 38 3. Functional Path Ring Oscillators pattern vpiis applied, all side inputs of piare at a stable non-controlling value. Furthermore, it is assumed that all FFs within the circuit are scan FFs. Consequently, all FFs are controllable with the DfT scan environment. The launch FF of path piis called LFF pi.LFF pienables the corresponding path pi. An ATPG tool is used to control LFF pi. In commercial ATPG tools, scan FFs can be restricted to a speciÔ¨Åc valuef0, 1,Xgduring the scan pattern generation. Those restrictions are called ATPG constraints . The ATPG constraints for a speciÔ¨Åc path piarecpi. This particular cpiis a tuple of f0, 1gconstraints for all LFF pi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_96", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 96, "text": "during the scan pattern generation. Those restrictions are called ATPG constraints . The ATPG constraints for a speciÔ¨Åc path piarecpi. This particular cpiis a tuple of f0, 1gconstraints for all LFF pithat launch paths in P. The LFF piofpimust be constrained to 1, while all other launch FFs of the remaining paths must be constrained to 0. The constraint ensures that only the selected path is activated. The constraint can be formulated as follows: cpi:= (cpi1,cpi2, . . . , cpin) with cpij:=( 1 if i=j 0 otherwise. Suppose Pconsists of n=100paths P=fp1,. . .,p100g; when checking self-enabling for a particular path, e.g., p3, the launch FF LFF p3must be restricted with ATPG constraint 1. The other 99paths\b pijpi2Pnfp3g,i=f1,. . ., 100g with the corresponding launch FFs must be constrained with ATPG constraint 0. Thus, cp3must look like the following: cp3= (0, 0, 1, 0, 0, . . . , 0 ). The constraint tuple cp3is allocated to the ATPG tool before the path delay pattern generation. The tool attempts to generate a new path delay pattern fvp3given the ATPG constraints. If the tool can generate a suitable scan pattern fvp3for the path p3given cp3,p3 is included in the new subset ePcontaining a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_97", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 97, "text": "empts to generate a new path delay pattern fvp3given the ATPG constraints. If the tool can generate a suitable scan pattern fvp3for the path p3given cp3,p3 is included in the new subset ePcontaining all paths that can be used with the self-enabling approach. In case the ATPG tool cannot generate a pattern for a path considering the ATPG constraints, the path is rejected. The check is performed for all paths in P. If a path is rejected, it will automatically end up in ÀÜP. The implementation of the basic concept in a large MCU in the automotive design Ô¨Çow requires a standardized approach. Therefore, a new library gate, the so-called RO-MUX , is introduced. This is necessary in order to implement all self-enabling functional path ROs automatically and uniformly. The RO-MUX is shown in Figure 3.7. The RO-MUX itself has seven ports, an INand OUT port, a local enable, general enable, feedback, feedback , and observe port. Included in the RO-MUX are a 2-to-1 MUX, 2 AND gates and an inverter. Note that the RO-MUX is unbundled into the individual gates after 39 3. Functional Path Ring Oscillators AND1 AND2‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢ 0 1Local Enable General Enable ObserveOUTIN Feedback Feedback Figure 3.7.:"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_98", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 98, "text": "Note that the RO-MUX is unbundled into the individual gates after 39 3. Functional Path Ring Oscillators AND1 AND2‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢ 0 1Local Enable General Enable ObserveOUTIN Feedback Feedback Figure 3.7.: The library gate called RO-MUX. Adapted from [49] c IEEE 2023. the implementation. This unbundling prevents the generation of new error states in more complex gates that may be difÔ¨Åcult to test from DfT perspective. The RO-MUX is implemented between the launch FF LFF piand the Ô¨Årst gate of the path pi to create a functional path RO. The INport is connected to the LFF piand the OUT port is connected to the Ô¨Årst gate of pi. Ifpiitself is inverting, the endpoint of the path is connected to the feedback port; if not, the feedback port is chosen. The local enable is connected to the output of LFF pi. Furthermore, the activation of the functional path ROs during functional mode of the MCU must be prevented. A general enable signal to unlock the oscillation mode, similar to the scan enable signal, ensures this. This signal is set by a protected bit and can be further gated in order to provide freedom from interference , which is necessary for safety-critical applications [99]. One signal is "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_99", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 99, "text": "l, ensures this. This signal is set by a protected bit and can be further gated in order to provide freedom from interference , which is necessary for safety-critical applications [99]. One signal is used for all functional path ROs on the chip. The AND1 gate inside of the RO-MUX ensures that the RO-MUX is enabled if and only if local enable and general enable are active. Then, the MUX switches from functional mode (0) to oscillation mode (1), and the RO oscillates. Parallelly, the AND1 output controls also the observe signal via the upper input of AND2 . If the MUX is in oscillation mode, the upper input of the AND2 gate is on a non-controlling value and, therefore, transparent. Thus the oscillation frequency is passed from the feedback port directly to the observe port. The AND2 prevents the observe signal from uncontrolled toggling during the functional mode. The observe signal, on which the frequency of the RO is measured, is spacially compacted with an XOR-tree. The AND2 in each RO-MUX ensures only one RO toggles during functional path RO test mode, which also reduces the cross talk and switching activity. The compaction of the observe signal by an XOR-tree can be seen in Figu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_100", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 100, "text": "O-MUX ensures only one RO toggles during functional path RO test mode, which also reduces the cross talk and switching activity. The compaction of the observe signal by an XOR-tree can be seen in Figure 3.8. The implementation of the XOR tree can easily be done as part of the implementation 40 3. Functional Path Ring Oscillators Functional Path ROFunctional Path ROFunctional Path ROFunctional Path RO observeobserve observeobserve GPIOControl Unit Figure 3.8.: XOR-tree for compacting the observe signals and forwarding it to a GPIO. Adapted from [49] c IEEE 2023. process of the functional path ROs. Thus, the XOR-tree is implemented efÔ¨Åciently and accurately by the EDA tools as a tailored solution. Two options are proposed for implementing the concept of self-enabling- Option 1 and Option 2 . 3.3.1. Option 1 - the Direct Self-Enabling Option 1 is also denoted as direct self-enabling because the local enable signal is connected to the launch FF of the corresponding path. The enabling of the path is accomplished with ATPG constraints, and the functional path has to be in set eP. The detailed implementation of Option 1, is shown in Figure 3.9. 12N SICLKD Q SE SICLKD Q SESICLKD Q SESICLKD"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_101", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 101, "text": "e path is accomplished with ATPG constraints, and the functional path has to be in set eP. The detailed implementation of Option 1, is shown in Figure 3.9. 12N SICLKD Q SE SICLKD Q SESICLKD Q SESICLKD Q SE SICLKD Q SE‚Ä¢‚Ä¢scan enable scan enablescan enable clockclockclockclock clock‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢ ObserveLocal Enable General Enable OUTIN Feedback FeedbackRO MUX Figure 3.9.: Detailed implementation of Option 1. Adapted from [49] c IEEE 2023. The implementation in Option 1 requires ATPG constraints. The ATPG constraints are 41 3. Functional Path Ring Oscillators assigned prior to pattern generation. Therefore, the ATPG tool must consider these ATPG constraints for pattern generation, which can lead to limitations. If the ATPG tool has too many ATPG constraints, it may have difÔ¨Åculty generating enough path delay patterns because they constrain the ATPG tool too tightly. However, the limitation of the ATPG tool depends strongly on the DfT environment. In addition, Option 2 is proposed, which does not have the drawback of the ATPG con- straints. 3.3.2. Option 2 - the Indirect Self-Enabling The main advantage is that Option 2 no longer uses the ATPG constraint. For this purpose, the local enable "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_102", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 102, "text": "ot have the drawback of the ATPG con- straints. 3.3.2. Option 2 - the Indirect Self-Enabling The main advantage is that Option 2 no longer uses the ATPG constraint. For this purpose, the local enable of the RO-MUX is no longer connected to the corresponding launch FF. However, a new combinational logic gate called unlock gate is introduced. The output of the unlock gate controls the local enable signal. The inputs of the unlock gate are connected to surrounding scan FFs. The general enable signal and all other circuitry functions are treated as in Option 1 . The suitable paths for this option are in ÀÜP=PneP. An elementary implementation is shown in Figure 3.10 where the unlock gate contains an AND gate connected to two surrounding FFs. 12N SICLKD Q SE SICLKD Q SESICLKD Q SESICLKD Q SE SICLKD Q SESICLKD Q SE SICLKD Q SE ‚Ä¢‚Ä¢ scan enable scan enablescan enable clockclockclockclock clockclock clockFFU1 FFU2 ‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢ ObserveLocal Enable General Enable OUTIN Feedback FeedbackUnlock Gate RO MUX‚Ä¢ Figure 3.10.: Option 2 - the indirect self-enabling controlled by three surrounding scan FFs. The scan pattern vpi, which sensitizes pi, is deterministic and the values of all scan FFs are known f"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_103", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 103, "text": "UX‚Ä¢ Figure 3.10.: Option 2 - the indirect self-enabling controlled by three surrounding scan FFs. The scan pattern vpi, which sensitizes pi, is deterministic and the values of all scan FFs are known for every vpi. If the functional path is sensitized with vpi, all scan FFs on the chip remain in a steady state since no clock pulse is triggered for the time being. Furthermore, there exists exactly only one pattern vpithat sensitizes pi, thus, the combination of the assigned values of all scan FFs is unique. In order to enable the RO-MUX with the local enable, the output of the unlock gate has to be1. In the example from Figure 3.10, the two FFs ( FFU1and FFU2) must have a 1value, if vpi 42 3. Functional Path Ring Oscillators is applied. If FFU1and FFU2have a high value, the local enable is high, given that the unlock gate contains a two input AND gate. The FFU1and FFU2are two arbitrary scan FFs that are near the RO-MUX and have, by default, a high value, if vpiis assigned to the circuit. The fact that the FFs for unlock gate are selected with the knowledge that all scan FF values are known allows getting rid of the ATPG constraints. Therefore, the ATPG tool is not restricted by const"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_104", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 104, "text": " The fact that the FFs for unlock gate are selected with the knowledge that all scan FF values are known allows getting rid of the ATPG constraints. Therefore, the ATPG tool is not restricted by constraints during the pattern generation. The number of unlock FFs is not limited and any combination is allowed; only the unlock gate is designed accordingly. The unlock gate consists of standard logic cells that are adapted to the corresponding use case for every path pi2ÀÜP. The combinational logic of the unlock gate and its complexity depend strongly on the design, the scan environment, and the number of ROs to be imple- mented. In the elementary case (Figure 3.10), the combinational logic within the unlock gate is an AND gate. However, the combinational logic could be even more complex. Thus, the level of protection against incidental enablement corresponds directly to the effort spent on the combinational logic of the unlock gate. Theoretically, any sensitizable functional path ( P) can be implemented in Option 2 ; however, Option 2 is much more complex and sophisticated. Thus it is a backup solution, if the ATPG tool struggles with the constraining for Option 1 . 3.4. Control Infrast"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_105", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 105, "text": "e implemented in Option 2 ; however, Option 2 is much more complex and sophisticated. Thus it is a backup solution, if the ATPG tool struggles with the constraining for Option 1 . 3.4. Control Infrastructure EfÔ¨Åcient implementation of the functional path RO is one factor; the second factor is ensuring an adequate control infrastructure. The control infrastructure is responsible for enabling the functional path ROs and forwarding the oscillation frequency to a general purpose input/output (GPIO) pad or counter structure. Furthermore, the control infrastructure should be scalable and must handle all implementation options. There are three options for implementing the functional path RO on the design. Option 0 needs a distinct enable and observe signal (see Section 3.1). Option 1 and Option 2 are the self-enabling approaches that reduce the routing effort but need ATPG constraints (see Section 3.3.1), or the unlock gate (see Section 3.3.2). The properties of each option with its advantages and disadvantages are stated in Table 3.1. Thus, all options have advantages for different use cases, so the control infrastructure should be suitable for all three options. Finally, the functional "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_106", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 106, "text": "s and disadvantages are stated in Table 3.1. Thus, all options have advantages for different use cases, so the control infrastructure should be suitable for all three options. Finally, the functional path RO oscillation frequency is the desired output independent of how the functional path ROs are implemented. In order to demonstrate the control infrastructure with its functionality, Ô¨Årst, a simplistic solution is presented that allows control of 8functional path ROs implemented in Option 0. Such control infrastructure is shown in Figure 3.11. The control infrastructure in Figure 3.11 consists of a scan-controllable register with three 43 3. Functional Path Ring Oscillators Table 3.1.: Properties of Option 0, Option 1, and Option 2. Traditional enable Self-enable Option 0 Option 1 Option 2 suitable path set P,ÀÜP eP P ,ÀÜP RO-MUX 7 3 3 local enable signal control infrastructure Launch FF Nearby FFs general enable signal 7 control infrastructure control infrastructure observe signal control infrastructure XOR- Tree XOR- Tree Pro easy to implement reduced routing effort high Ô¨Çexibility Cons high routing effort ATPG constraints high complexity CLKSIQ SECLKSIQ SECLKSIQ SEscan in scan out"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_107", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 107, "text": "ol infrastructure XOR- Tree XOR- Tree Pro easy to implement reduced routing effort high Ô¨Çexibility Cons high routing effort ATPG constraints high complexity CLKSIQ SECLKSIQ SECLKSIQ SEscan in scan outEnable 0:7 Observe 0:7 MUX Scan FF 1 Scan FF 2 Scan FF 31 0 000100000 scan enCLK‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ GPIO‚Ä¢ ‚Ä¢ 1-hot encoding Divider Figure 3.11.: Basic control infrastructure for the functional path ROs with 8 ports. scan FFs. The scan FFs are connected in series and are part of a scan chain. Therefore, they can be controlled via the ATPG tool. The three scan FFs are generating a 3-bit binary coding. Subsequently, the 3-bit binary code of the scan FFs is translated into a one-hot-encoded selection bus. Thus, the 3-bit binary signal is converted to an 8-one-hot coded selection bus. The one-hot-encoded selection bus is responsible for enabling the respective MUX of the eight implemented functional path ROs. The same one-hot-encoded selection bus also maintains the control infrastructure‚Äôs internal MUX, compressing the observe signal with the oscillation frequency from the selected functional path RO. The selected observe signal is then divided by a static internal divider stage and forwarde"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_108", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 108, "text": "nal MUX, compressing the observe signal with the oscillation frequency from the selected functional path RO. The selected observe signal is then divided by a static internal divider stage and forwarded to the GPIO pin. The divider stage is necessary to divide the oscillation signal to a suitable frequency in which the GPIO can process it. The third functional path RO is enabled in Figure 3.11. For this, the three scan FFs (FF 1, FF 2, FF 3) are constrained with the values 0,1,0. Thus the third functional path RO is activated due to the one-hot-encoding. The active ports are colored green in Figure 3.11. The constraining of the scan FF is accomplished in the path delay pattern generation for 44 3. Functional Path Ring Oscillators the respective functional path RO. Thus, the control infrastructure‚Äôs information on which functional path RO is active and maintained is contained in the respective scan pattern. However, the presented example can facilitate only eight functional path ROs of Option 0. Therefore a more generalized solution is developed. In order to combine these three options, ahybrid concept is introduced. This hybrid concept is a control infrastructure that can handle all"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_109", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 109, "text": "ption 0. Therefore a more generalized solution is developed. In order to combine these three options, ahybrid concept is introduced. This hybrid concept is a control infrastructure that can handle all options, the traditional implementation (Option 0) as well as the self-enabling approaches (Option 1 and Option 2). The hybrid control infrastructure is shown in Figure 3.12. CLKSIQ SECLKSIQ SECLKSIQ SEscan in scan outEnable Option 0 (2k‚àí1Ports )Observe Option 0 (2k‚àí1Ports ) MUX Scan FF 1 Scan FF 2 Scan FF k scan enCLK‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ ‚Ä¢ GPIO1-hot encoding DividerXOR TreeGeneral Enable Figure 3.12.: The control infrastructure for the functional path ROs. Adapted from [49] c IEEE 2023. The hybrid control infrastructure consists of a scan controllable register with kscan FFs and a one-hot encoded selection bus. This results in 2kone-hot encoded ports. Such ports control the enable signals for the functional path ROs, in particular for Option 0. In total 2k\u00001 enable and observe pins are available to be used for the functional path ROs implemented in Option 0. The general enable signal for the functional path ROs in Option 1 and Option 2 is generated on the last pin. Moreover, on the res"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_110", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 110, "text": "ilable to be used for the functional path ROs implemented in Option 0. The general enable signal for the functional path ROs in Option 1 and Option 2 is generated on the last pin. Moreover, on the respective last observe pin, the root of the XOR-tree is connected. Such a hybrid solution of the control unit is a scalable and efÔ¨Åcient methodology to combine the implementation of Options 0, 1 and 2. If only Option 1 (or 2) is needed, kis set to 1, and the general enable signal and the XOR-tree are connected. An essential advantage is that the infrastructure is controllable with scan pattern, which means all settings are integrated into the scan pattern itself, which is very efÔ¨Åcient in terms of test time. The substantial advantage of the scan-controlled infrastructure is that the scan pattern that sensitizes one particular functional path RO also contains the information for the control infrastructure. There is no need for additional settings of test structures or a speciÔ¨Åc test mode; all that is needed is managed within a scan pattern. 45 3. Functional Path Ring Oscillators 3.5. Implementation Flow The concept and technique of functional path ROs have been described in the preceding "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_111", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 111, "text": " that is needed is managed within a scan pattern. 45 3. Functional Path Ring Oscillators 3.5. Implementation Flow The concept and technique of functional path ROs have been described in the preceding sections; this section focuses on implementing such structures on silicon in the industrial design Ô¨Çow. The implementation of the functional path ROs in the design is done in two stages. First, the control infrastructure is implemented, and in the second stage, the functional path ROs are implemented. The control infrastructure is implemented in the register-transfer level (RTL) description in the early design phase. The scan-controlled FFs in the control infrastructure are part of the scan chains. Inserting them later would drastically affect the overall scan environment, which should be avoided. The enable and observe ports remain open and are not connected. The wiring of these ports will be done later. The general requirements for the MCU to be developed are also deÔ¨Åned in the early design phase. This means it is known which area, performance, and time speciÔ¨Åcations the MCU should have, and the control infrastructure can be adapted accordingly. The hybrid solution of the control inf"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_112", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 112, "text": "ign phase. This means it is known which area, performance, and time speciÔ¨Åcations the MCU should have, and the control infrastructure can be adapted accordingly. The hybrid solution of the control infrastructure allows, for example, the use of a certain number of functional paths RO in Option 0 - this is predeÔ¨Åned by the number of enable/observe ports. At the same time, the self-enabling approach allows the implementation of an additional, scalable number of functional path ROs in Option 1 or 2. Therefore the Ô¨Ånal number of implementable functional path ROs is very Ô¨Çexible and independent of the deÔ¨Åned size of the control infrastructure. Example : The control infrastructure consists of 5scan FFs ( 32one-hot encoded ports). Thus, 31functional path ROs can be implemented in Option 0, and port number 32is for the general enable signal for Option 1 or 2. This allows any scalable number of functional path ROs to be implemented in Option 1/2. After the control infrastructure is described in RTL, the industrial design Ô¨Çow of an MCU continues until a late design phase - here, the second stage of the implementation starts. The second stage is the implementation of the functional path ROs vi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_113", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 113, "text": "RTL, the industrial design Ô¨Çow of an MCU continues until a late design phase - here, the second stage of the implementation starts. The second stage is the implementation of the functional path ROs via an engineering change order (ECO). Such implementation Ô¨Çow is shown in Figure 3.13. The ECO implementation process starts in a late design phase after synthesis and place-and- route have been performed. At this stage, the paths of the design do not change considerably, which is an essential prerequisite for a smooth implementation process. A static timing analysis (STA) tool analyzes the netlist and reports functional paths from the design. Such STA report contains all physical design information (launch FF, capture FF, all gates, coordinates of all gates, etc.) of the paths with the respective timing information. The STA path report with all functional paths from the design is then pre-Ô¨Åltered and pre-processed. In the pre-Ô¨Åltering process, some functional paths that are unsuitable for the RO implementation are discarded. Such discarded paths are, for example, false paths. These 46 3. Functional Path Ring Oscillators Synthesis / Place and Route STA / Path Extraction Pre-filtering an"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_114", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 114, "text": "the RO implementation are discarded. Such discarded paths are, for example, false paths. These 46 3. Functional Path Ring Oscillators Synthesis / Place and Route STA / Path Extraction Pre-filtering and Pre-processing Path Delay ATPG Self-enabling Check Option 0 Option 1 Path Selection Path Selection ECO Imple- mentation Verification Tape ‚Äì Out Clustering Final Sel.Final PathsBuck.1 Buck.2 Buck.3 Buck.N/tildewiderPÀÜPPonly Opt. 0 Figure 3.13.: Implementation Ô¨Çow of functional path RO. Adapted from [49] c IEEE 2023. 47 3. Functional Path Ring Oscillators are paths that are not valid in functional mode but are included in the STA report. Other discarded functional paths have, for example, a short delay time. That would lead to a high oscillation frequency when implemented as RO. The measurement test setup can accurately measure only a speciÔ¨Åc frequency window of the oscillation frequency. Thus, all paths of which RO frequencies are outside the expected measurement window are discarded. After that, the pre-Ô¨Åltered STA report is pre-processed. The path report is parsed and key properties of the paths are extracted, called path characteristics . For example, path characteristics from a pa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_115", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 115, "text": "er that, the pre-Ô¨Åltered STA report is pre-processed. The path report is parsed and key properties of the paths are extracted, called path characteristics . For example, path characteristics from a path report with physical design data contain physical path length, cumulative cell driver strength, cell count, and other characteristics that are primarily used in the selection of the functional paths as ROs in the later implementation process. The remaining functional paths after pre-Ô¨Åltering are passed to a commercial ATPG tool which is in path delay mode. The ATPG tool attempts to sensitize each functional path with a robust path delay pattern. Only a subset of the initially passed path list can be robustly sensitized. These functional paths then constitute the set P. The following step is the self-enabling check, which checks the possible implementation of the functional paths in P. Paths that can be implemented with Option 1 are in the subset eP, and paths that can be implemented with Option 0 or Option 2 are in ÀÜP. However, the self-enabling check can be skipped if Option 0 (or Option 2) is the desired im- plementation method (dotted line in Figure 3.13). In this case, all paths"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_116", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 116, "text": "h Option 0 or Option 2 are in ÀÜP. However, the self-enabling check can be skipped if Option 0 (or Option 2) is the desired im- plementation method (dotted line in Figure 3.13). In this case, all paths in Pare automatically assigned to the set ÀÜP. Afterwards the selection process starts. The path selection process (see Section 4) works independently of the underlying set - whether ePorÀÜP. Finally, the selected functional paths and the options (Option 0, 1, or 2) used for the implementation are then provided to the physical implementation. An ECO accomplishes the physical implementation, and an incremental compile run creates the functional path ROs in the netlist. The ECO script needs the start and end points of the path to create the feedback loop and the MUX or RO-MUX placement and, the option for implementation. For the implementation in Option 0 (or Option 2), the ports to be used in the control infrastructure for the observe and enable signal are needed. For implementation in Option 1, the RO-MUX is placed and connected, and the XOR-tree is built. Option 2 also requires the information for the unlock gate and its wiring. During the implementation of the functional path ROs all "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_117", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 117, "text": "n 1, the RO-MUX is placed and connected, and the XOR-tree is built. Option 2 also requires the information for the unlock gate and its wiring. During the implementation of the functional path ROs all design guidelines within the EDA tool are considered; for example, additional signal buffers are placed on long routing lines to ensure a certain slew rate of the signals. The entire information is then included in the ECO command script and the incremental compile run is executed. As a result, the netlist is modiÔ¨Åed accordingly and the selected functional path ROs are implemented in the design. 48 3. Functional Path Ring Oscillators All ECO commands can be scripted in a tool command language (TCL) sequence to automate the implementation process. Thanks to this implementation process, the functional path ROs are placed in the industrial design environment with a push button solution. However, before the tape-out of the MCU is launched, the implemented ROs must be veriÔ¨Åed for their function and the correctness of the implementation, which is explained in Section 5. Before coming to that, the results of this chapter are shown in the following. 3.6. Results In order to evaluate the presen"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_118", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 118, "text": " and the correctness of the implementation, which is explained in Section 5. Before coming to that, the results of this chapter are shown in the following. 3.6. Results In order to evaluate the presented methodology of functional path ROs, the functional path ROs are implemented for this purpose in the context of the development of a new generation automotive MCU. This section is divided into four subsections. The Ô¨Årst subsection provides some back- ground information on the automotive MCU test chip. Subsection 3.6.2 presents the general advantages of functional path ROs in terms of area and leakage. The following subsection provides a proof of concept for the advanced implementation concepts. The routing beneÔ¨Åts of the self-enabling approach are presented in Subsection 3.6.4. 3.6.1. The Automotive Microcontroller Test Chip The functional path ROs are implemented on a large automotive MCU in advanced CMOS technology. In order to cope with the complexity of such a large MCU, the MCU is divided into several modules with a hierarchical scan infrastructure [105]. Three dedicated modules were selected as test modules to implement the functional path RO. All modules of the MCU have their"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_119", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 119, "text": "divided into several modules with a hierarchical scan infrastructure [105]. Three dedicated modules were selected as test modules to implement the functional path RO. All modules of the MCU have their own scan infrastructure. The three selected modules were chosen to be fundamentally different in their size as well as their functionalities. Some basic information about the three selected modules can be seen in Table 3.2. Table 3.2.: Basic information of the MCU modules. Module Scan FFs Scan chains Area A 414 803 5247 Large B 204 565 3072 Medium C 135 165 1452 Small The three modules are arranged in descending order according to their area and the size of the scan environment. Module A is the most extensive module, and Module C is the smallest. Module A and Module C contain combinatorial logic and have integrated CPUs, 49 3. Functional Path Ring Oscillators while Module B has much integrated memory. The shape of the different modules also varies from oblong rectangular to square, which impacts the routing. The functional path RO approach is benchmarked against traditional RO structures such as the SMON module (see Section 1.2.1). 3.6.2. Implementation BeneÔ¨Åts In order to demonstrate"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_120", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 120, "text": "impacts the routing. The functional path RO approach is benchmarked against traditional RO structures such as the SMON module (see Section 1.2.1). 3.6.2. Implementation BeneÔ¨Åts In order to demonstrate the implementation of functional path ROs, two functional paths were selected from the design and implemented as functional path ROs. In this section, Option 0 is used to illustrate the basic implementation concept of functional path ROs. One path ( Path a ) is a long path with a relatively large number of cells. The cumulative driver strength is also high. In contrast, Path b is very short, has a small number of cells, and the driver strength is approximately one-tenth compared with Path a . The path characteristics are shown in Table 3.3. Table 3.3.: Path characteristics of Path a and Path b . Demo Path Cell CountCumulative Driver StrengthPath Length [mm] a 27 2014 1459 b 12 220 90 The two paths were obtained from the set ÀÜPafter pre-Ô¨Åltering and self-enabling check, as explained in Section 3.5. The implementation of paths aand bcan be seen on the Ô¨Çoor plan in Figure 3.14 and Figure 3.15. The functional paths are marked in yellow in the Ô¨Çoor plans. The MUX is located at the start po"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_121", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 121, "text": "tion 3.5. The implementation of paths aand bcan be seen on the Ô¨Çoor plan in Figure 3.14 and Figure 3.15. The functional paths are marked in yellow in the Ô¨Çoor plans. The MUX is located at the start point of each path, and the feedback loop (red) connects the end point of the path to the start point. The enable signal (light red) is routed from the control infrastructure to the MUX at the start point. The observation signal (red) is also connected to the feedback loop at an arbitrary location along the feedback loop and forwarded to the control infrastructure. As can be seen in Figure 3.15, the routing from the functional path to the control in- frastructure is one major drawback of the Option 0 implementation. Some signal buffers must be placed for such long routing lines, especially for the enable and observe signals. The signals buffers can cause a signiÔ¨Åcant amount of cell contribution in modern CMOS technologies [106]. The timing impact on the functional path due to MUX insertion ranges from 2 %to3 % delay increase for all considered functional path ROs. By selecting non-critical timing paths for RO integration of the functional path, the increased delay has no actual impact. P"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_122", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 122, "text": "anges from 2 %to3 % delay increase for all considered functional path ROs. By selecting non-critical timing paths for RO integration of the functional path, the increased delay has no actual impact. Pre- 50 3. Functional Path Ring Oscillators (a)Option 0 (b)Option 1 Figure 3.14.: Implementation on layout based on Path a after ECO. Adapted from [40] c IEEE 2021. (a)Option 0 (b)Option 1 Figure 3.15.: Implementation on layout based on Path b after ECO. Adapted from [40] c IEEE 2021. Ô¨Åltering in the implementation Ô¨Çow ensures that only those functional paths pass through the Ô¨Çow for implementation that are within a particular timing window to avoid generating timing violations by the later MUX insertion. The insertion of buffers on the feedback line also inÔ¨Çuences the RO‚Äôs absolute oscillation frequency. However, only the relative frequencies are needed to correlate the RO frequencies with the device performance. The main advantage of the functional path ROs will be evident when comparing the cell area saved with functional path RO to conventional on-chip RO structures e.g. the SMON module (see Section 1.2.1). The experiment was executed on Module C with a chip area of approximately 1."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_123", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 123, "text": "the cell area saved with functional path RO to conventional on-chip RO structures e.g. the SMON module (see Section 1.2.1). The experiment was executed on Module C with a chip area of approximately 1.5 mm2and a leakage power consumption of 175 mW. The impact of the physical implementation via the ECO on the chip is minimal. An addi- tional MUX has an area impact of 1.2e \u00006 % in relation to the chip area under consideration. The area impact of one buffer is 0.37e\u00006 %. The number of buffers to be placed depends on 51 3. Functional Path Ring Oscillators the length of the feedback loop and the connection line to the observe signal. The longer the signal line, the more buffers must be used to ensure the corresponding transition slew rates. Path a has a long feedback loop that requires some buffers for transition edge slew rates, whereas Path b is compact and needs only one buffer for the decoupling from the functional path. The EDA tool by itself will care for sufÔ¨Åcient slew rates and the buffering after ECO according to the design rules. The control infrastructure is scalable to the desired number of functional path ROs to be needed. The estimated area overhead and leakage increase for"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_124", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 124, "text": "uffering after ECO according to the design rules. The control infrastructure is scalable to the desired number of functional path ROs to be needed. The estimated area overhead and leakage increase for the considered chip area is shown in Table 3.4. Table 3.4.: Estimated area overhead and leakage increase of the control infrastructure. No of ROs Scan Bits Area [%] Leakage [%] 8 3 1.0e \u00005 0.18e\u00005 32 5 3.4e \u00005 0.63e\u00005 128 7 13.3e \u00005 2.4e\u00005 512 9 52.0e \u00005 9.5e\u00005 Assume there are 128ROs to be implemented. This number is either implemented as functional path ROs or conventional ROs via an SMON module. Thus the SMON module is tailored to 128contained SMONs, and the percentage amount of required area is calculated. The insertion effort of the MUX for the functional path ROs is also estimated. In addition, four buffers per functional path RO are inserted by default. This is a practical number based on trial implementation runs on the design under investigation; some ROs need only one, some ROs need more buffering, and the central control unit is also considered. The estimated area and leakage consumption in Module C is shown in Table 3.5. Table 3.5.: Area overhead and leakage increase of 12"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_125", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 125, "text": "need more buffering, and the central control unit is also considered. The estimated area and leakage consumption in Module C is shown in Table 3.5. Table 3.5.: Area overhead and leakage increase of 128functional path ROs in comparison to an equal sized SMON module. RO-Type Area [%] Leakage [%] Functional Path ROs 0.091 0.39e \u00003 SMON module 2.4 10.1e \u00003 Savings 96.2 96.1 Thus, over 96 % of the area and leakage can be saved by implementing functional path ROs instead of using traditional approaches. Most of this area and leakage advantage is due to the fact that all the functional cells of the RO are already present in the design. Only the control infrastructure needs to be added. 52 3. Functional Path Ring Oscillators 3.6.3. Proof of concept of the Advanced Implementation Concepts Concerning the advanced implementation methods, a proof of concept is being conducted to investigate whether and how many paths can be used for the methods from Section 3.2. 3.6.3.1. Path Analysis Approach The path analysis approach aims to Ô¨Ånd functional paths that have, by default, beneÔ¨Åts if implemented as functional path ROs. For that, the design is checked to see if any functional paths can be allocat"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_126", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 126, "text": " path analysis approach aims to Ô¨Ånd functional paths that have, by default, beneÔ¨Åts if implemented as functional path ROs. For that, the design is checked to see if any functional paths can be allocated in four types (see Section 3.2.1). An STA path report is extracted from each of the three modules of the MCU design and examined for the included path types, the results of which are shown in Table 3.6. Table 3.6.: Path analysis analysing the structure of the functional paths. Module A Module B Module C Pre-Ô¨Åltered Paths from STA report 27 374 7594 12 687 Type 1 - Self-contained paths 4 13 13 Type 2 - Parallel paths 0 0 0 Type 3 - same launch point 26 774 7425 12 553 Type 4 - same capture point 0 0 0 Independent paths 600 169 134 Unique launch FFs 1863 575 518 Unique capture FFs 27 374 7594 12 687 After ATPG path sensitization All sensitizable paths ( P) 2096 699 3860 Type 1 - Self-contained paths ( PType 1) 1 0 0 Type 2 - Parallel paths ( PType 2) 0 0 0 Type 3 - same launch point ( PType 3) 1970 619 3789 Type 4 - same capture point ( PType 4) 0 0 0 Independent paths 125 80 71 Unique launch FFs 306 220 193 Unique capture FFs 2096 699 3860 For example, if Module A is considered, most"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_127", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 127, "text": "pe 3) 1970 619 3789 Type 4 - same capture point ( PType 4) 0 0 0 Independent paths 125 80 71 Unique launch FFs 306 220 193 Unique capture FFs 2096 699 3860 For example, if Module A is considered, most functional paths use multibit FFs, as can be seen from the number of unique starts FFs of 1863 . Thus, a substantial proportion of paths start with the same launch FFs. However, all paths ( 27 374 ) use unique capture FFs. On the other hand, 600paths are completely independent, which means those paths that use neither any shared start FFs nor the capture FFs. The same magnitudes of the number of paths related to the analyzed path types are also observed after path sensitization with the 53 3. Functional Path Ring Oscillators ATPG tool. In the end, 1970 functional path ROs are of Type 3 and can be implemented as functional path ROs. If the three modules are compared, Type 3 is the only possibility to use the path analysis. Finally, such an analysis is highly dependent on the actual design. 3.6.3.2. Proof of Concept - Natural Loops As explained in Section 3.2.2, the natural loops are the second approach of advanced imple- mentation concepts. Also, a proof of concept is conducted on the "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_128", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 128, "text": " 3.6.3.2. Proof of Concept - Natural Loops As explained in Section 3.2.2, the natural loops are the second approach of advanced imple- mentation concepts. Also, a proof of concept is conducted on the three modules for such an approach. The same pre-Ô¨Åltered STA report is used as in the section before, and the ATPG tool is used to sensitize the functional path ROs with a path delay pattern. One path delay pattern can sensitize multiple functional paths; the results are shown in Table 3.7. Table 3.7.: ATPG results reveal the number of patterns necessary for path sensitization. Module Input Paths Sensitizable Paths Patterns A 27 374 2096 529 B 7594 699 178 C 12 687 3860 1012 The input paths are the paths that are fed to the ATPG tool. The tool can only sensitize a subset of the paths. The number of sensitizable paths varies from below 10 % to30 % in Module C. The number of generated patterns also Ô¨Çuctuates among the modules. Such numbers depend on the design as well as the scan environment. Consequently, there are enough patterns that sensitize more than one path. Module A is chosen for a detailed consideration. Figure 3.16 shows how many paths are sensitized with one pattern in the th"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_129", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 129, "text": ". Consequently, there are enough patterns that sensitize more than one path. Module A is chosen for a detailed consideration. Figure 3.16 shows how many paths are sensitized with one pattern in the three modules. Accordingly, over 470patterns can sensitize at least two paths. The same behavior can be seen in Module B and Module C. 0 100 200 300 400 500 # of Pattern010203040# of Paths per PatternModule A (a)Module A 0 25 50 75 100 125 150 175 # of Pattern0204060# of Paths per PatternModule B (b)Module B 0 200 400 600 800 1000 # of Pattern020406080# of Paths per PatternModule C (c)Module C Figure 3.16.: Sensitizable paths per pattern for three modules. 54 3. Functional Path Ring Oscillators In Figure 3.17a, two paths that are promising candidates for the natural loop approach are shown on the design in Module A. The paths run in opposite directions and can be implemented as a natural loop functional path RO. Figure 3.17b reveals how many paths are sensitizable with a particular pattern in Module B and how the paths are spatially distributed over the whole module. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 x [nm] √ó1062.002.252.502.753.003.253.503.754.00y[nm]√ó106 startendstart end2 Paths on Module A "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_130", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 130, "text": "n Module B and how the paths are spatially distributed over the whole module. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 x [nm] √ó1062.002.252.502.753.003.253.503.754.00y[nm]√ó106 startendstart end2 Paths on Module A (a) Module A with 2 paths. 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 x [nm] √ó1060.00.51.01.52.02.53.03.54.0y[nm]√ó10656 paths on Module B with one pattern start end (b) Module B with 56 paths. Figure 3.17.: Candidates for natural loops. The focus of this section was to provide a proof of concept; the actual savings and routing are strongly dependent on where and which functional paths are chosen. Therefore, no attempt was made to quantify the methodology with exact numbers, as these are limited to the present design and cannot be generalized. The following section presents the results of the self-enabling approach. 3.6.4. Routing BeneÔ¨Åts of the Self-enabling Approach The advantage in terms of routing reduction is investigated among the three modules in this section. For that, the implementation in Option 0 (basic concept) and Option 1 (direct self-enabling) are compared. In addition, an estimation is given for a feasibility study for implementing Option 2. 55 3. Functional Path Ring Oscillato"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_131", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 131, "text": "n Option 0 (basic concept) and Option 1 (direct self-enabling) are compared. In addition, an estimation is given for a feasibility study for implementing Option 2. 55 3. Functional Path Ring Oscillators 3.6.4.1. Self-enabling Option 1 First, the self-enabling check is applied to determine how many paths are suitable for implementation in Option 1 - which requires ATPG constraints. Second, routing reduction estimation is performed to compare the implementations of Options 0 and 1. An STA report is requested in a late design stage from each of the three modules. Then, the implementation Ô¨Çow starts and determines how many paths can be implemented in Option 0 and Option 1. The results are shown in Table 3.8. Table 3.8.: Number of paths suitable for functional path RO implementation. SetModule A Module B Module C Count Percent Count Percent Count Percent STA Input 27 374 100 % 7594 100 % 12 687 100 % P 2096 7.66 % 699 9.20 % 3850 30.35 % eP 1362 4.98 % 698 9.19 % 3284 25.88 % ÀÜP 734 2.68 % 1 0.01 % 566 4.46 % The Ô¨Årst row indicates the number of functional paths from the STA. After the pre-Ô¨Åltering and the ATPG tool run in path delay mode, a subset of the functional paths can be sensiti"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_132", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 132, "text": "1 0.01 % 566 4.46 % The Ô¨Årst row indicates the number of functional paths from the STA. After the pre-Ô¨Åltering and the ATPG tool run in path delay mode, a subset of the functional paths can be sensitized. In the modules A and B, the ATPG tool can sensitize less than 10 % , while in Module C, the ATPG tool can sensitize over 30 % . However, for large automotive MCUs, there are still enough paths left for RO implementation. The last two lines in Table 3.8 show the subset of functional paths that are suitable for the self-enabling approach ( eP) and those that are only suitable for implementation in Option 0 ( ÀÜP). It can be observed that a large number of the paths in Pare also suitable for the self-enabling approach. This shows that Option 1 is a feasible implementation approach for large MCUs. The number of paths in the subset for Option 1 basically depends on how the ATPG tool can handle the constraints; this, in turn, depends strongly on the DfT scan environment, the chip size, and the scan compression used. For the automotive MCU under investigation, Option 1 is the means of choice for routing critical modules. The reduction in routing is then estimated to quantify the beneÔ¨Åts b"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_133", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 133, "text": "he scan compression used. For the automotive MCU under investigation, Option 1 is the means of choice for routing critical modules. The reduction in routing is then estimated to quantify the beneÔ¨Åts between Option 0 and Option 1 in terms of routing. For estimating the routing effort, the Manhattan Distance is used, which is the sum of the absolute distance of the Cartesian coordinates. This distance is assumed to correspond to the worst-case scenario for routing. There are eight paths selected from each of the three modules. The functional paths are chosen from the subsets ePand implemented in Option 0 and Option 1. All paths are selected to be spatially distributed over each module. The schematic Ô¨Çoorplans of the implementation in Option 0 are shown in Figure 3.18. The same functional paths are implemented in Option 1 56 3. Functional Path Ring Oscillators in Figure 3.19 (a) Module A (b) Module B (c) Module C Figure 3.18.: Routing visualization of 8 sample paths implemented in Option 0. In Figure 3.18 the enable and observe signals of the functional path ROs are routed to the respective control infrastructure. Each of the signals is routed individually. In contrast, the self-enabl"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_134", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 134, "text": "0. In Figure 3.18 the enable and observe signals of the functional path ROs are routed to the respective control infrastructure. Each of the signals is routed individually. In contrast, the self-enabling approach Option 1 is used in Figure 3.19. As a result, the control signal becomes obsolete. In order to provide a fair comparison of the routing overhead, the XOR tree is also summarized at the control infrastructure. In this example, routing can be reduced by close to 70 % in Module A and C and over 77 % in Module B. Routing reduction was simulated for all three modules with a larger number of functional path ROs in Option 1 compared with Option 0. The paths were chosen to ensure spatially distribution on the chip. The results are shown in Table 3.9. Table 3.9.: Routing reduction of the RO implementation for Option 1 . Impl. ROsModule A Reduction [%]Module B Reduction [%]Module C Reduction [%] 8 69.67 77.55 69.25 50 77.52 85.98 79.39 100 78.20 87.43 80.47 150 79.49 88.19 79.46 The routing reduction is more than 70 % across modules, in some cases even up to 80 % . Module B achieves the best results. The chip shape has a non-negligible inÔ¨Çuence in the 57 3. Functional Path Ring Osci"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_135", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 135, "text": "ting reduction is more than 70 % across modules, in some cases even up to 80 % . Module B achieves the best results. The chip shape has a non-negligible inÔ¨Çuence in the 57 3. Functional Path Ring Oscillators (a) Module A (b) Module B (c) Module C Figure 3.19.: Routing visualization of 8 sample paths implemented in Option 1. analysis. Particularly in Module C, which had a stretched rectangular shape, the routing reduction declines again ( 1percent point) in the case of 150implemented paths. It is assumed that modern EDA tools can further reduce the routing overhead by optimizing the XOR tree for the observe signal. The general enable signal was neglected in the previous routing simulation in Table 3.9. In order to estimate the routing overhead of the general enable signal, the dimensions of respective modules were considered. The general enable signal must expand over the entire module if all ROs are distributed over the entire module. This is simulated by calculating the diagonal of each module and adding three factors (1x, 1.5x, 2x) to the original routing reduction. For each factor, a separate calculation is done to see the impact of the general enable signal. The resulting overa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_136", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 136, "text": "ch module and adding three factors (1x, 1.5x, 2x) to the original routing reduction. For each factor, a separate calculation is done to see the impact of the general enable signal. The resulting overall routing reduction and the deviation from the previous estimate are shown in Table 3.10. For a few implemented functional paths ROs (for example, 8ROs), the general enable signal has a non-negligible inÔ¨Çuence. This is true for all three factors, especially for the twofold factor of the diagonal. However, if a more signiÔ¨Åcant number of functional path ROs are implemented, the inÔ¨Çuence becomes negligible and is around one percent for 150 implemented ROs. Thus, the general enable signal is negligible for a high number of ROs, indicating the method‚Äôs scalability. As a result of the routing reduction due to the self-enabling approach, the cell utilization can be increased, thus reducing the overall area of the chip. In addition, a large part of the signal buffers required for long routing distances can be eliminated, saving area and leakage. 58 3. Functional Path Ring Oscillators Table 3.10.: Routing reduction of the RO implementation for Option 1 including the general enable signal. Impl"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_137", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 137, "text": "tances can be eliminated, saving area and leakage. 58 3. Functional Path Ring Oscillators Table 3.10.: Routing reduction of the RO implementation for Option 1 including the general enable signal. Impl. ROs1x diagonal 1.5x diagonal 2x diagonal Mod. A Mod. B Mod. C Mod. A Mod. B Mod. C Mod. A Mod. B Mod. C 8 52.13 67.63 51.41 43.54 62.74 42.45 34.95 57.84 33.48 50 74.83 84.14 76.93 73.49 83.22 75.70 72.15 82.30 74.47 100 76.95 86.48 79.36 76.32 86.01 78.80 75.70 85.54 78.25 150 78.70 87.57 78.78 78.30 87.26 78.43 77.91 86.95 78.09 deviation deviation deviation 8 17.18 9.79 17.92 25.77 14.69 26.88 34.36 19.59 35.85 50 2.69 1.84 2.46 4.03 2.76 3.69 5.37 3.68 4.92 100 1.25 0.95 1.11 1.87 1.42 1.67 2.50 1.90 2.22 150 0.79 0.62 0.69 1.19 0.93 1.03 1.59 1.24 1.38 Nevertheless, quantiÔ¨Åable numbers are difÔ¨Åcult to determine, as this depends heavily on the design. This section has revealed how powerful the self-enabling approach is using Option 1. Due to the high number of paths that can be implemented in Option 1, the implementation of Option 2 is obsolete for this large MCU. However, a short investigation is done for Option 2. 3.6.4.2. Self-enabling Option 2 The previous section has shown t"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_138", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 138, "text": "mented in Option 1, the implementation of Option 2 is obsolete for this large MCU. However, a short investigation is done for Option 2. 3.6.4.2. Self-enabling Option 2 The previous section has shown that ePcontains relatively few paths (only one in Module B) compared with ÀÜP(see Table 3.8). Therefore this experiment is conducted to subset P . If Option 2 is implemented, the unlock gate is placed and connected to nearby scan FFs. The design is analyzed to clarify how many scan FFs are nearby the launch point of the functional path. The amount of functional paths with a scan FF closer to 10 mmis shown in Table 3.11. Table 3.11.: Paths with nearby FFs per module. Module A Module B Module C P 2096 699 3860 \u001510mm 1396 684 3458 <10mm 700 15 402 10mmw.r.t. diag. 0.22 0.28 0.40 Exactly 700functional paths in Module A have FFs closer than 10mmfrom the respective launch point. However, in Module B there are only 15paths that have very close scan FFs 59 3. Functional Path Ring Oscillators around them. The 10mmis about 0.2 % -0.4 % percent of the module diameter. Thus, it shows up also here that already, with three considered modules, no generally valid statement can be made concerning the gen"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_139", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 139, "text": "them. The 10mmis about 0.2 % -0.4 % percent of the module diameter. Thus, it shows up also here that already, with three considered modules, no generally valid statement can be made concerning the general advantage of an option concerning another implementation option. Option 2 is feasible since adjacent FFs can be found, but as far as the actual routing savings are concerned, no statement can be made. As a general rule for the three modules of the large automotive MCU, Option 1 is the preferred solution, and Option 0 is suggested as a backup. 60 4. Path Selection Methodology 4.1. Selection Flow This chapter deals with the selection of functional paths and introduces a methodology that uses physical design data in order to determine functional paths for performance screening. An essential step in the implementation of the functional path RO is the selection of the appropriate paths that contribute to the performance prediction. This path selection is independent of the implementation option (Option 0, 1, or 2), since only the functional path itself is important. Path selection aims to Ô¨Ånd paths that represent the performance of the entire chip by trying to select a diverse set of p"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_140", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 140, "text": "ption (Option 0, 1, or 2), since only the functional path itself is important. Path selection aims to Ô¨Ånd paths that represent the performance of the entire chip by trying to select a diverse set of paths on the MCU. The physical-aware path selection approach is suitable for any implementation concept and is revealed in Figure 4.1. Clustering Final Sel.Final PathsP ÀÜP /tildewidePBuck.1 Buck.2 Buck.3 Buck.N Figure 4.1.: Physical-aware functional path selection Ô¨Çow. Path selection is independent of whether it is performed on the set P(for Option 0), eP(for Option 1) or set ÀÜP(for Option 2). Therefore, assume that the set Pis a set of msensitizable functional paths P=fp1, . . . , pmgthat could be a set from P,eP, or ÀÜP. For each of the functional paths in Psome characteristics chiare extracted during the preprocessing. The characteristics can be described by an l-dimensional vector chi= (chi1,chi2,. . .,chil)|where chijdenotes the value of the j-th characteristic of the path pi. Characteristics extracted from a physical design data path report include, for example, cell count ( chi1), accumulated cell driver strength ( chi2), physical path length ( chi3), and other characteristics ( c"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_141", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 141, "text": "istics extracted from a physical design data path report include, for example, cell count ( chi1), accumulated cell driver strength ( chi2), physical path length ( chi3), and other characteristics ( chi4,. . .,chil). Characteristics are deÔ¨Åned using the designers‚Äô knowledge and previously published research [36, 37, 38, 88, 17]. 61 4. Path Selection Methodology The cell count (characteristic chi1) is the number of individual cells within the path. The cell count is calculated as follows chi1=n √• k=11gk2pi (4.1) where gkrepresents the logic cell of the the design. This characteristic is beneÔ¨Åcial to cope with process variations. The process variation, in general, can be divided into die-to-die (D2D) and within-die (WID) variations (see Sec- tion 2.3.1). Whereas the D2D variation affects all die transistors, identically, the WID variation affects each transistor individually. Paths with low cell count are more sensitive to WID varia- tion, whereas paths with high cell count balance the WID variation and are more sensitive to D2D variation [88]. Thus, both cases are needed to cope with the process variation in detail. In modern CMOS technologies, the WID becomes more prominent than in"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_142", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 142, "text": "ID variation and are more sensitive to D2D variation [88]. Thus, both cases are needed to cope with the process variation in detail. In modern CMOS technologies, the WID becomes more prominent than in mature technologies [17]. The accumulated cell driver strength chi2is the sum of the strengths of each cell on the path, and can be expressed as chi2=n √• k=1Pgk2pi. (4.2) Each logic cell has a certain driver strength Pgk. The driver strength depends mainly on the load to be driven by the cell, i.e. how many other logic cells are being supplied by the output of the driving cell, which is also called fan-out. The higher the driver strength is, the more fan-out the cell has. Considering multiple driver strengths is advantageous to monitor nonlinearities within the cell characteristics. Only some operating conditions are characterized in the cell char- acterization of the standard cell library. If an operating condition is needed between the characterized conditions, the cell behavior is interpolated based on the available data. Thus, potential nonlinearities are not captured. Considering paths with different driver strengths can thus reveal behaviors that are not evident in the character"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_143", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 143, "text": "rpolated based on the available data. Thus, potential nonlinearities are not captured. Considering paths with different driver strengths can thus reveal behaviors that are not evident in the characterization [37]. The physical path length chi3is the sum of the Euclidean distance from cell to cell within the path. The STA report contains all the coordinates of the cells along the path; therefore, the distance can be calculated as follows chi3=n √• k=1dgk2pi. (4.3) The dgkrepresents the Euclidean distance between two cells of the path. However, the calculated Euclidean distance does not exactly match the length of the routing lines on the chip. Nevertheless, this approach is well suited for path selection, as a mixture of short, 62 4. Path Selection Methodology medium, and long paths should be covered. In addition, the cell coordinates and path length can be used to cover a reasonable spatially distribution of observed paths on the chip and to detect process variations. The resulting matrix looks as follows p1b=ch11 ch12. . . ch1l p2b=ch21 ch22. . . ch2l ...b=............ pmb=chm1chm2. . . chml. In order to reduce the complexity and merge similar paths, the functional paths are cluste"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_144", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 144, "text": "ix looks as follows p1b=ch11 ch12. . . ch1l p2b=ch21 ch22. . . ch2l ...b=............ pmb=chm1chm2. . . chml. In order to reduce the complexity and merge similar paths, the functional paths are clustered into so-called buckets according to the chosen path characteristics. Each functional path is assigned to a particular bucket. In total, there are NbucketsB=fB1, . . . , BNg. There are several algorithms for this unsupervised clustering problem. The K-means algorithm is used, which is a distance-based unsupervised methodology [93]. The algorithm aims to group paths with similar path characteristics. This is a multivariant optimization problem. The number of buckets is determined with the elbow criterion [94]. The K-means algorithm starts with only one bucket, and the within-cluster-sum-of-squares (WCSS) is calculated as a measure of within-cluster variance. In the case of N=1, the WCSS is the highest. The algorithm run is repeated by increasing the number of buckets, and the WCSS starts to decrease. The relation between the WCSS and the number of buckets results in a graph with an elbow shape. From a certain number of buckets, the WCSS drop is no longer as steep as before - such a p"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_145", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 145, "text": " to decrease. The relation between the WCSS and the number of buckets results in a graph with an elbow shape. From a certain number of buckets, the WCSS drop is no longer as steep as before - such a point is called the elbow point. The number of buckets at this elbow point is theK-means clustering best choice. Other cluster algorithms can also work Ô¨Åne, e.g., the density-based DBSCAN [95]; that depends mainly on the dataset and the algorithm‚Äôs settings. For the distance-based clus- tering (e.g. K-means), it is essential to standardize the characteristics set previous to the clustering [107]. Each bucket contains paths that appear similar according to the speciÔ¨Åed characteristics. The main target of the cluster approach is not to have sharp disjunct buckets, which would be impossible due to the high correlation among the characteristics. The intention is instead to cluster structurally different paths; therefore, the speciÔ¨Åc choice of a particular algorithm (distance-based, density-based, or hierarchical-based) to perform the clustering has only a minor inÔ¨Çuence on the results. The Ô¨Ånal selection of paths to be implemented as ROs in the design is made after clustering. There are thr"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_146", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 146, "text": "d, or hierarchical-based) to perform the clustering has only a minor inÔ¨Çuence on the results. The Ô¨Ånal selection of paths to be implemented as ROs in the design is made after clustering. There are three different ways of handling this. One way is to randomly pick a path from each of the Nbuckets and select a Ô¨Ånal subset for the implementation. Such an approach is straightforward, and a subset of paths has, by 63 4. Path Selection Methodology default, a diverse mixture of path types because the paths are out of the different buckets. The second way of selecting the Ô¨Ånal subset is a more sophisticated approach that involves the coordinates of the paths. This ensures that the ROs are spatially distributed, in addition to being from different buckets. For example, some paths from the same bucket are picked, but the paths are spatially distributed across the chip. The third way takes a step back to clustering. The results of the elbow method are ignored, and the number of buckets is chosen according to how many functional path ROs are to be implemented. If it is known in advance that 32ROs are to be implemented, for example, the number of buckets for clustering is also set to 32. The Ô¨Ån"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_147", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 147, "text": "according to how many functional path ROs are to be implemented. If it is known in advance that 32ROs are to be implemented, for example, the number of buckets for clustering is also set to 32. The Ô¨Ånal selection approach depends on the buckets‚Äô granularity and the number of functional path ROs to be implemented. Finally, the selected paths are then handed to the ECO Ô¨Çow, and the functional path ROs are implemented on the netlist. 4.2. Results The path selection is executed on each of the three modules. The used set of the functional paths to demonstrate the path selection and clustering is eP. The characteristics are already extracted during the pre-processing. There are 10charac- teristics extracted from each path. Thus, the matrix of Module A has the dimensionality of 10\u00021362, because the set contains 1362 paths (see Table 3.8). On each of the three modules, the K-means cluster algorithm is started to group the paths in individual buckets. In order to determine the suitable number of buckets, the elbow method is used. The results are shown in Figure 4.2. 0 5 8 10 15 20 25 30 Number of Buckets50100150200250300WCSSElbow plot Module A data (a)Module A 0 5 8 10 15 20 25 30 Number of"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_148", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 148, "text": "f buckets, the elbow method is used. The results are shown in Figure 4.2. 0 5 8 10 15 20 25 30 Number of Buckets50100150200250300WCSSElbow plot Module A data (a)Module A 0 5 8 10 15 20 25 30 Number of Buckets255075100125150175WCSSElbow plot Module B data (b)Module B 0 5 8 10 15 20 25 30 Number of Buckets100200300400500600700WCSSElbow plot Module C data (c)Module C Figure 4.2.: Elbow plots of the three modules. The elbow diagrams show how the WCSS behaves as the number of buckets increases. The 64 4. Path Selection Methodology sweet spot is marked in the diagrams with the dashed line, as the recommended number of buckets for clustering should be chosen. Coincidentally, in all three modules, the number derived from the graph is 8. Thus, Nis set to 8, and K-means clustering is performed on every module. The functional paths of each module are grouped into 8buckets. The number of functional paths per bucket varies a lot, as shown in Table 4.1. Table 4.1.: Number of paths per bucket after the K-means clustering. BucketModule A Module B Module C Count % Count % Count % 0 386 28.3 186 26.7 949 29.0 1 179 13.1 148 21.2 615 18.8 2 160 11.7 95 13.6 549 16.7 3 153 11.2 81 11.6 546 16.6 4 149 "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_149", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 149, "text": "he K-means clustering. BucketModule A Module B Module C Count % Count % Count % 0 386 28.3 186 26.7 949 29.0 1 179 13.1 148 21.2 615 18.8 2 160 11.7 95 13.6 549 16.7 3 153 11.2 81 11.6 546 16.6 4 149 10.9 73 10.3 184 5.6 5 117 8.6 46 6.6 182 5.5 6 111 8.1 35 5.0 160 4.8 7 107 7.9 34 4.9 99 3.0 total 1362 100 698 100 3284 100 The three modules‚Äô largest buckets contain almost 30 % of the respective functional paths. In contrast, some buckets contain just 3 %of the respective paths, for example, in Module C. In order to present the contribution of the characteristics, ( chi1), (chi2), and ( chi3) are plotted for the different buckets in Module B. The plots are shown in Figure 4.3. 0 1 2 3 4 5 6 7 Bucket1015202530Cell CountModule B (a) Cell count. 0 1 2 3 4 5 6 7 Bucket01234Path Length [ ¬µm]√ó106 Module B (b) Path Length. 0 1 2 3 4 5 6 7 Bucket0500100015002000250030003500Power [arb.unit]Module B (c) Accumulated driver strength. Figure 4.3.: Violin plots presenting the distribution of paths on Module B according to the deÔ¨Åned path characteristics. 65 4. Path Selection Methodology The violin diagrams show that the individual buckets differ. On the X-axis, the 8buckets are plotted. In Figu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_150", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 150, "text": "on Module B according to the deÔ¨Åned path characteristics. 65 4. Path Selection Methodology The violin diagrams show that the individual buckets differ. On the X-axis, the 8buckets are plotted. In Figure 4.3a, the number of cells in the different 8buckets is plotted on the Y-axis, and the length of the path is plotted in Figure 4.3b. In Figure 4.3c the accumulated driver strength is plotted on the Y-axis. Looking at buckets 2and 3, both have nearly identical cell counts. Bucket 2, however, contains very short paths, while bucket 3contains long paths also with respect to the driver strength; the two buckets differ signiÔ¨Åcantly. Such differences can be observed for all characteristics. From each of the buckets, the Ô¨Ånal paths can be selected and implemented as ROs via the ECO. There are three selection methods proposed in the previous section. 4.2.1. The Ô¨Ånal Selection for the Test Chip The presented selection Ô¨Çow is part of the overall implementation Ô¨Çow, as shown in Figure 3.13. Up to 8functional path ROs shall be implemented on the three Modules. Option 0 is chosen as the implementation option. The implementation Ô¨Çow is started, and the path selection is executed. The Ô¨Ånal selected"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_151", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 151, "text": "functional path ROs shall be implemented on the three Modules. Option 0 is chosen as the implementation option. The implementation Ô¨Çow is started, and the path selection is executed. The Ô¨Ånal selected - and implemented - functional paths are shown in Table 4.2. The implemented functional path ROs show a large diversity regarding the deÔ¨Åned char- acteristics. The 22functional path ROs are implemented in the design, and the MCU is fabricated. The entire process is fully automated and has a low turn-around time. Less than 24 h elapse from the generation of STA reports to the incremental compilation run. Thus, a smooth design process can be guaranteed, and the tape-out is not delayed. 66 4. Path Selection Methodology Table 4.2.: Final selected functional path to be implemented as an RO. RO Module Bucket Cell CountDriver StrengthPath Length [mm] 0 A A-3 16 560 1145 1 A A-7 9 315 478 2 A A-5 26 1322 1383 3 A A-3 20 898 900 4 A A-6 12 527 1007 5 A A-0 35 1759 844 6 A A-1 19 627 467 7 A A-4 30 989 345 8 B B-3 20 2030 2726 9 B B-0 19 1089 905 10 B B-2 26 2970 3847 11 B B-3 21 2320 3749 12 B B-7 9 140 142 13 B B-1 20 1200 846 14 B B-6 20 510 565 15 C C-3 19 468 301 16 C C-2 9 470 1280 17 C C"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_152", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 152, "text": " 989 345 8 B B-3 20 2030 2726 9 B B-0 19 1089 905 10 B B-2 26 2970 3847 11 B B-3 21 2320 3749 12 B B-7 9 140 142 13 B B-1 20 1200 846 14 B B-6 20 510 565 15 C C-3 19 468 301 16 C C-2 9 470 1280 17 C C-0 11 307 475 18 C C-5 27 1965 1251 19 C C-6 10 370 348 20 C C-7 16 318 147 21 C C-1 31 2620 1062 67 5. PRE-Silicon VeriÔ¨Åcation and Validation This section presents the last steps in the Pre-Silicon part. The functional path ROs are selected and implemented via an ECO. Figure 5.1 presents an overview of this section and at which point in time the described methodology Ô¨Åts in the MCU development Ô¨Çow. Section 5.1 PRE-Silicon VerificationSection 5.2 First Silicon PreparationSection 5.3 PRE-Silicon ValidationPart II. POST - SiliconDesign FabricationTape - outECO First Silicon Figure 5.1.: Overview of the Section Pre-Silicon veriÔ¨Åcation and validation. 5.1. PRE-Silicon VeriÔ¨Åcation of the Functional Path ROs The Ô¨Çow described below is one way of verifying the functional paths. Still, it is also possible to create a different veriÔ¨Åcation Ô¨Çow compatible with the given design Ô¨Çow. The ECO is executed in an incremental compilation run and the functional path ROs have been implemented in the desi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_153", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 153, "text": "possible to create a different veriÔ¨Åcation Ô¨Çow compatible with the given design Ô¨Çow. The ECO is executed in an incremental compilation run and the functional path ROs have been implemented in the design. This compilation run results in a new netlist that contains the ECO changes. This new netlist must be veriÔ¨Åed to ensure that the compile run does not affect the functionality of the entire MCU. In addition, it is necessary to check that the functional path ROs are implemented and working correctly. The Logic Equivalence Check (LEC) is used to check the functionality of the MCU. The LEC compares the given netlist with the RTL representation of the Golden Reference , the latest RTL design. The netlist must be logically equivalent to the Golden Reference RTL design throughout the physical design Ô¨Çow. A successful LEC is essential for the incremental compilation runs associated with ECOs performed late in the design phase [55]. A successful LEC ensures that the implemented functional path ROs do not inÔ¨Çuence the functionality of the MCU. Once the LEC is successful, the veriÔ¨Åcation of the functional path ROs starts. The imple- mented functional path ROs are checked by gate-level timing "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_154", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 154, "text": "ROs do not inÔ¨Çuence the functionality of the MCU. Once the LEC is successful, the veriÔ¨Åcation of the functional path ROs starts. The imple- mented functional path ROs are checked by gate-level timing simulation. For such gate-level simulation, the netlist after incremental compile run is needed, and the functional path RO path delay patterns vpiare required for the simulation. The netlist must contain the timing 68 5. PRE-Silicon VeriÔ¨Åcation and Validation information for the oscillation to work properly; otherwise, no oscillation occurs because the feedback loop is a short circuit. One such netlist format is the back-annotated standard delay format (SDF). That SDF Ô¨Åle allows accurate timing simulation. The test sequence of a functional path RO with the respective modiÔ¨Åed path delay pattern is shown schematically in Figure 3.3. The gate-level simulation with the SDF Ô¨Åle and the functional path RO pattern follows this test sequence. In the measurement phase, the actual oscillation frequency occurs due to the timing back-annotation of the SDF File. Thus, the simulation has two aspects: (i) the functional behavior of the functional path ROs is veriÔ¨Åed, and (ii) the expected oscillatio"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_155", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 155, "text": "ency occurs due to the timing back-annotation of the SDF File. Thus, the simulation has two aspects: (i) the functional behavior of the functional path ROs is veriÔ¨Åed, and (ii) the expected oscillation frequency is simulated and stored as initial silicon limits for production test. 5.1.1. Functional VeriÔ¨Åcation Figure 5.2 shows a section of the gate-level simulation. The end of the shift-in phase and the start of the measurement phase are shown. Figure 5.2.: Digital simulation snapshot at the beginning of the oscillation. Adapted from [49] c IEEE 2023. At the beginning of the simulation window shown, all signals are stationary, the shift-in phase is completed, and the functional path RO is sensitized. The upper signal shows the enable signal that triggers the oscillation. Below that is the observe signal, which is stabilized to allow the RO to oscillate once activated. The next signal shows the GPIO pin as measured by the ATE. The scan enable is on a high state since the MCU is in the shift-in phase. The clock signal is shown for the sake of completeness. At time t1, the measurement phase begins, and oscillation is activated. The scan enable is deactivated, and the enable signal sw"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_156", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 156, "text": "shift-in phase. The clock signal is shown for the sake of completeness. At time t1, the measurement phase begins, and oscillation is activated. The scan enable is deactivated, and the enable signal switches the MUX instantaneously to the oscillation mode. Thus, the observe signal follows the oscillation frequency of the functional path RO. A divider is inserted between the observe signal and the signal from the GPIO. Thus, the divided oscillation signal is received at the GPIO pin. The Ô¨Årst few oscillation periods cannot be used to determine the oscillation frequency due to the initial random state of the divider and transient effects. At t1, the divider has an instantaneous high state, and the Ô¨Årst pulses 69 5. PRE-Silicon VeriÔ¨Åcation and Validation Figure 5.3.: Digital simulation sequence with 6 functional path ROs. are absorbed until the divider‚Äôs shift register operates properly. However, such transient effects can be masked, and the frequency at the GPIO pin is measured after a few hundred nanoseconds. The oscillation itself is independent of any clock event. Verifying each functional path RO by an individual simulation run is inefÔ¨Åcient. Therefore, the functional path RO patt"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_157", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 157, "text": "w hundred nanoseconds. The oscillation itself is independent of any clock event. Verifying each functional path RO by an individual simulation run is inefÔ¨Åcient. Therefore, the functional path RO patterns are merged into one large pattern. That large pattern is used for the veriÔ¨Åcation and in the production test. The functional path ROs are sequentially activated and measured. A snapshot of the gate-level simulation is shown in Figure 5.3, where six functional path ROs are sequentially activated. The Ô¨Årst six signals are the enable signals for the functional path ROs; below them are the observe signals. The GPIO pin, the scan enable, and the clock signal are unique to the chip and are therefore used for all functional path ROs. In the simulation run, the six functional path ROs are activated sequentially. The simulation starts with the shift-in phase to sensitize the Ô¨Årst functional path RO. The clock signal has high activity in the shift-in phase; thus, all scan-FFs are loaded with the respective values. Then the oscillation starts, and the frequency is measured. At the end of the oscillation, two small clock pulses can be seen. These clock pulses are the launch and capture at-spe"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_158", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 158, "text": "e respective values. Then the oscillation starts, and the frequency is measured. At the end of the oscillation, two small clock pulses can be seen. These clock pulses are the launch and capture at-speed pulses from the path delay pattern. After the at-speed pulses, the shift-out phase starts. Since the individual patterns are merged, the Ô¨Årst pattern‚Äôs end is the start of the second pattern. Thus after the shift-out phase, there is a smooth transition into the shift-in phase of the second pattern. After the shift-in phase of the second pattern, the second functional path RO oscillates and is measured. This procedure is continued until all functional path ROs are tested. The veriÔ¨Åcation is successful when all functional path ROs inserted via the ECO have been tested and oscillated. Thus, the functional path ROs are correctly implemented, and the design is released for tape-out. 5.1.2. Test-limit Extraction As mentioned, the gate-level simulation has an additional beneÔ¨Åt. The measured oscillation frequencies of the functional path ROs within the simulation run are stored for the production test. Thus, the stored simulation values act as the Ô¨Årst test limits for the production. 70 5. "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_159", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 159, "text": "cillation frequencies of the functional path ROs within the simulation run are stored for the production test. Thus, the stored simulation values act as the Ô¨Årst test limits for the production. 70 5. PRE-Silicon VeriÔ¨Åcation and Validation 0 5 10 15 20 RO0.20.40.60.81.0Frequency(Hz)√ó108 fupper piatPVTbest flower piatPVTworst Figure 5.4.: Limits from the digital simulation using the worst and best case SDF. In order to be more accurate, there is more than one SDF Ô¨Åle. This is because the timing of the MCU depends on the PVT conditions. There is one SDF Ô¨Åle for each PVT condition. Thus, each simulation run with the different SDF Ô¨Åles gives a different result because the timing behavior in each PVT condition is different. The worst-case PVT ( PVT worst) and best-case PVT ( PVT best) conditions are used to determine the lower flower piand upper fupper pitest limits for each functional path RO. The best case represents a fast MCU under the best voltage and temperature conditions, resulting in the highest achievable oscillation frequency. Slow MCUs under the worst voltage and temperature conditions result in a low oscillation frequency. Two simulation runs are started with two different S"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_160", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 160, "text": "n the highest achievable oscillation frequency. Slow MCUs under the worst voltage and temperature conditions result in a low oscillation frequency. Two simulation runs are started with two different SDF Ô¨Åles - the worst-case and best-case conditions, and the oscillation frequencies are stored as lower and upper test limits; the results are shown in Figure 5.4. The 22implemented functional path ROs are plotted on the X-axis, and the simulated frequencies fupper piand flower pifor each RO are plotted on the Y-axis. The expected frequency range varies from 10 MHz atflower p10up to 110 MHz atfupper p20. The lower flower piand upper fupper pi bounds are considered during performance measurement on silicon. 5.2. SI Bring-up Preparation 5.2.1. Changes previous to Tape-out As described in Section 2.1, where the overall digital MCU development Ô¨Çow is explained, the ECO phase is the last opportunity for changes in the design. Parallel to the functional path RO implementation in the ECO phase, there are plenty of checks and last-minute Ô¨Åxes during this phase - especially for large designs. For example, timing Ô¨Åxes, design rule checks, and IR issues are Ô¨Åxed [54]. 71 5. PRE-Silicon VeriÔ¨Åcation"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_161", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 161, "text": "ere are plenty of checks and last-minute Ô¨Åxes during this phase - especially for large designs. For example, timing Ô¨Åxes, design rule checks, and IR issues are Ô¨Åxed [54]. 71 5. PRE-Silicon VeriÔ¨Åcation and Validation In productive design Ô¨Çow, such ECO runs are grouped and executed together, and some iteration ECO runs are needed if some parts of a design need special treatment. Such large automotive MCUs are developed with a large team of engineers where everyone is responsible for only a tiny design part or issue. Therefore, as a matter of fact, implementing the functional path ROs as the very last step before tape-out is difÔ¨Åcult. As a result, the design might change at the last minute when the functional path RO implementation is already done. In order to check the inÔ¨Çuence of implementing the functional path ROs before the tape out of the MCU, the associated changes are reviewed. The functional path ROs are implemented in the ECO phase, where also other ECOs are executed. Therefore, the extracted path characteristics are compared pre- and post-tape-out. The clustering and path selection were executed based on the path characteristics of the pre-tape-out databases. The post-tape-"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_162", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 162, "text": " the extracted path characteristics are compared pre- and post-tape-out. The clustering and path selection were executed based on the path characteristics of the pre-tape-out databases. The post-tape-out data represents the actual state of the chip, including changes made to the design in the late ECOs. The logical composition of the gates in the path was protected after implementation, so everything remained the same in the basic logical composition of the path; otherwise, it might not be possible to sensitize the path. However, it is allowed to insert buffers, make cell swaps (concerning driver strength and transistor type), or make other optimizations that do not change the logical behavior. The graphical representation of 3 path characteristics is shown in Figure 5.5, and Table 5.1 shows the mean and median deviation values of overall selected paths from pre- to post-tape- out. Table 5.1.: Deviation of the implemented functional path ROs pre- and post-tape-out. Cell count chi1Path length chi2Driver strength chi3 Mean 2.22 % 2.68 % 6.48 % Median 0.00 % 0.18 % 4.45 % Only a minor impact can be seen regarding cell count in Figure 5.5a and path length in Figure 5.5b. Also, the mean"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_163", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 163, "text": "length chi2Driver strength chi3 Mean 2.22 % 2.68 % 6.48 % Median 0.00 % 0.18 % 4.45 % Only a minor impact can be seen regarding cell count in Figure 5.5a and path length in Figure 5.5b. Also, the mean and median average values indicate that there are only minor deviations. The slightly higher mean value also indicates some dominant paths (e.g., RO20in Figure 5.5a) because the mean value is more outlier sensitive than the median value. Impact due to driver strength (Figure 5.5c) is slightly higher. Increasing driver strength indicates that timing issues have been Ô¨Åxed in the ECO runs. Either buffers have been inserted with contributions now to the driver strength of the path, or logic cells have been replaced by cells with a higher strength that can drive higher loads. However, complete destruction of the paths pre- and post-tape-out cannot be observed - even for the other characteristics. The original path selection is kept after all further ECOs are 72 5. PRE-Silicon VeriÔ¨Åcation and Validation 012345678910111213141516171819202122 ROs05101520253035Cell CountCell Count Pre/Post Tape-out Post Pre (a) Cell count chi1 012345678910111213141516171819202122 ROs0.00.51.01.52.02.53.03.54.0P"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_164", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 164, "text": "alidation 012345678910111213141516171819202122 ROs05101520253035Cell CountCell Count Pre/Post Tape-out Post Pre (a) Cell count chi1 012345678910111213141516171819202122 ROs0.00.51.01.52.02.53.03.54.0Path lenght√ó106 Path lenght Pre/Post Tape-out Post Pre (b) Path length chi2 012345678910111213141516171819202122 ROs050010001500200025003000Driver strengthDriver strength Pre/Post Tape-out Post Pre (c) Driver strength chi3 Figure 5.5.: Path characteristic pre- and post-tape-out. performed. A negligible deviation can also be seen in the individual buckets. 5.2.2. Simulation with Functional Patterns A part of the MCU development Ô¨Çow is the IR drop analysis. Static and Dynamic IR drop is investigated to verify the MCU‚Äôs power delivery network (PDN) and ensure uniform distribution of VDD and VSS on the chip. A tool such as Ansys RedHawk-SC [108] is used for such investigations and is equipped with a graphical interface that shows the switching activities and the IR drop on the Ô¨Çoor plan. Therefore, it would be of interest to know whether the selected and implemented functional path ROs are located in areas of signiÔ¨Åcant IR drop. For example, Wang et al. [21] had reported an IR drop that aff"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_165", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 165, "text": "ore, it would be of interest to know whether the selected and implemented functional path ROs are located in areas of signiÔ¨Åcant IR drop. For example, Wang et al. [21] had reported an IR drop that affected the functional path RO results of the chip. The authors reported a static IR drop of more than 10 %. In contrast, the static IR drop of the MCU design in this work is minimal due to the excellent connection to the power grid and the high power integrity of the package. Therefore 73 5. PRE-Silicon VeriÔ¨Åcation and Validation the simulated static IR drop can be neglected. However, the dynamic IR drop strongly depends on the use case and is simulated with some use cases. Two use cases and the dynamic IR drop and toggling activity can be seen in Figure 5.6. /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015 /uni00000014/uni00000048/uni0000001a/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni0000"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_166", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 166, "text": "uni00000011/uni00000015 /uni00000014/uni00000048/uni0000001a/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000048/uni0000001a /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f (a) Dynamic IR drop functional pattern. /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015 /uni00000014/uni00000048/uni0000001a/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni000000"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_167", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 167, "text": "ni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000048/uni0000001a /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f (b) Dynamic IR drop test pattern. /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015 /uni00000014/uni00000048/uni0000001a/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000048/uni0000001a /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni0"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_168", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 168, "text": "14/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000048/uni0000001a /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f (c) Toggle rate functional pattern. /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015 /uni00000014/uni00000048/uni0000001a/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000048/uni0000001a /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f /uni00000026/uni00000052/uni00000051/uni00000057/uni000000"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_169", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 169, "text": "i00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f (d) Toggle rate test pattern. Figure 5.6.: Ansys RedHawk-SC simulation on Module A including the visualization of the implemented functional path ROs. Figure 5.6a shows the dynamic IR drop on Module A in a highly active time domain of a functional customer-oriented test pattern, and in Figure 5.6c, the corresponding toggle activity during the simulated time domain is shown. A toggling activity can be seen across 74 5. PRE-Silicon VeriÔ¨Åcation and Validation the module, whereas the dynamic IR drop occurs only in the module‚Äôs upper region. At least one of the functional path ROs was implemented in the region with some dynamic IR drop. However, if a different customer use case is simulated, the dynamic IR drop may change and occur at other locations on the chip. Therefore, harvesting all regions in detail with functional path ROs in advance in functional use cases is challenging. However, the IR drop that occurs in the design is in the low single-digit percentage"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_170", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 170, "text": "efore, harvesting all regions in detail with functional path ROs in advance in functional use cases is challenging. However, the IR drop that occurs in the design is in the low single-digit percentage range, which is not worth mentioning for a robust design. On the other hand, in Figure 5.6b and Figure 5.6d, one of the most aggressive test patterns is simulated. The toggling activity covers a wide area, and a dynamic voltage drop occurs in the module. The functional path ROs are implemented in the areas with higher IR drop and the areas with lower IR drop. Here, too, the IR drop is in the single-digit percentage range. The simulation showed an IR drop, but it is not noticeable (static) or very small (dynamic). In order to monitor possible weak areas in the design concerning the PDN, it is good to have as many functional path ROs as possible and distributed over a wide area. 5.3. PRE- Silicon Validation and Improvement In this section, the Pre-Silicon validation is done based on analog simulations, focusing on validating and improving the path selection Ô¨Çow. Section 4.1 describes the path selection Ô¨Çow as a heuristic Ô¨Çow with a low turn-around time that Ô¨Åts perfectly into the indust"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_171", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 171, "text": "simulations, focusing on validating and improving the path selection Ô¨Çow. Section 4.1 describes the path selection Ô¨Çow as a heuristic Ô¨Çow with a low turn-around time that Ô¨Åts perfectly into the industrial design Ô¨Çow. However, path selection must be validated, and a heuristic is an imperfect process that strives to improve. The time between the tape-out and the Ô¨Årst silicon usually takes weeks to months. Thus, this Pre-Si validation Ô¨Çow is proposed to get early feedback from the selection Ô¨Çow. Then, there is no need to wait until the Ô¨Årst silicon is available. The validation of the selection Ô¨Çow can be done either by simulating the paths or with the measurements on silicon. As mentioned, if the measurement approach on silicon is chosen, there is a certain amount of downtime until the sample measurements are available for a statistically relevant basis. In addition, many corner lots and measurement conditions are required to cover the entire PVT range, which is difÔ¨Åcult to reach in the tightly scheduled engineering phase and with limited resources. The standard test program usually covers only some discrete voltage or temperature conditions, for example, and not a continuous sweep of"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_172", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 172, "text": "ightly scheduled engineering phase and with limited resources. The standard test program usually covers only some discrete voltage or temperature conditions, for example, and not a continuous sweep of the whole range. Therefore, the simulation-based approach is favorable in that case. Thus, we can validate the physical design-based path selection and improve the selection Ô¨Çow for future derivatives and redesigns in the same technology. 75 5. PRE-Silicon VeriÔ¨Åcation and Validation 5.3.1. Model Generation After tape-out, the design is Ô¨Åxed and will not be changed. At this point, model generation begins. Model generation is used to create the most accurate circuit representation possible in a simulatable SPICE (Simulation Program with Integrated Circuit Emphasis) [72] model. The MCU design contains various gates and components, all of which have a unique designation. The designation of all components is equal to the designation in the STA path report used in Section 3.5 and Section 4.1. The model extraction extracts only the components from the design that are part of the functional path STA report. The goal of the extraction is to obtain a simulatable analog SPICE model from the func"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_173", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 173, "text": "he model extraction extracts only the components from the design that are part of the functional path STA report. The goal of the extraction is to obtain a simulatable analog SPICE model from the functional path RO, including the parasitic elements that act on the functional path RO in the chip. Three components are necessary to start the model extraction. One is the chip design representation, including the parasitic components, the so-called standard parasitic exchange format (SPEF) Ô¨Åle; second, the path information Ô¨Åle containing all functional path ROs; and third, the standard cell library Ô¨Åle containing the description of the gates used in the design. The process of the model extraction can be seen in Figure 5.7. SPEF-File Path List LibrariesModel ExtractorSPICE Models Figure 5.7.: SPICE Model extractor with data in- and output. Adapted from [42] c IEEE 2022. The SPEF Ô¨Åle contains the parasitic resistance and capacitance, which must be considered to mimic the exact behavior of the functional path ROs on the chip. All functional paths are listed in the path information Ô¨Åle, which are implemented as functional path ROs. The path information Ô¨Åle also contains the gates in the fee"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_174", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 174, "text": " functional path ROs on the chip. All functional paths are listed in the path information Ô¨Åle, which are implemented as functional path ROs. The path information Ô¨Åle also contains the gates in the feedback loop. In some cases, an inverter is placed to ensure the path‚Äôs inversion, or some buffers are added during the implementation to provide a reasonable slew rate of the oscillating signal. In addition, the path list can also contain sensitizable functional paths without the RO implementation. The library Ô¨Åle has comprehensive information of all gates in the design, including the boolean function, characterization data, and the analog transistor model. These three Ô¨Åles are passed to the model extractor, and the output are analog SPICE models of the input path lists. Exactly one SPICE model is created per entry in the path list. The side inputs of the path are terminated with the non-controlling value, so the extracted path is sensitized by default. The parasitic elements are also included in the SPICE models. 76 5. PRE-Silicon VeriÔ¨Åcation and Validation As mentioned, the path list can contain either functional path ROs or sensitizable functional paths. The model extractor recognize"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_175", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 175, "text": "ded in the SPICE models. 76 5. PRE-Silicon VeriÔ¨Åcation and Validation As mentioned, the path list can contain either functional path ROs or sensitizable functional paths. The model extractor recognizes the difference and decides what kind of SPICE model to be extracted. Figure 5.8 shows a sketch of the SPICE model after extraction from a functional path (5.8a) and from a functional path RO (5.8b). TI TE RN D CP Q D C B A Z A Z A Z D C B A Z TI TE RN D1 D0 CP Q1 Q0 (a) Extracted functional path. TI TE RN D3 D2 D1 D0 CP Q3 Q2 Q1 Q0 S A1 A0 Z D C B A Z A Z A Z A Z B A Z TI TE RN D7 D6 D5 D4 D3 D2 D1 D0 CP Q7 Q6 Q5 Q4 Q3 Q2 Q1 Q0 Z A (b) Extracted functional path RO. Figure 5.8.: Two alternatives of the extracted analog SPICE models. Adapted from [42] c IEEE 2022. The generation of the SPICE model from the SPEF Ô¨Åle ensures realistic behavior, since the paths on the chip are exposed to parasitic effects. Therefore, the extracted SPICE models are very close to reality. The extracted SPICE models are used to investigate the sensitivities of the functional path ROs. Thus, the heuristic path selection process is validated with the sensitivity analysis of the SPICE models. A second use case "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_176", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 176, "text": "dels are used to investigate the sensitivities of the functional path ROs. Thus, the heuristic path selection process is validated with the sensitivity analysis of the SPICE models. A second use case of the SPICE models is to perform model-hardware correlation once the silicon arrives from manufacturing which is not further investigated. 5.3.2. Sensitivity Analysis of the Functional path ROs The extracted SPICE models are analyzed with respect to their sensitivity under different PVT conditions. The resulting output parameters are the delay time dpiof a path or the frequency fpiof the functional path RO. The delay time of the sensitizable functional paths (Figure 5.8a) is further distinguished for the falling ( df all pi) and rising ( drise pi) edge. In the case of a functional path RO (Figure 5.8b), the oscillation frequency is additionally determined, which 77 5. PRE-Silicon VeriÔ¨Åcation and Validation results from the superposition of the rising and falling case fpi=1 df all pi+drisepi. Sensitivity analysis investigates the sensitivity of such delay/frequency values at different PVT conditions. Thus, it can be indicated which paths react particularly sensitively to certain PVT pa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_177", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 177, "text": "pi. Sensitivity analysis investigates the sensitivity of such delay/frequency values at different PVT conditions. Thus, it can be indicated which paths react particularly sensitively to certain PVT parameters. The investigation of PVT conditions is divided into the individual process, voltage, and temperature components and considered separately. Thus, a path‚Äôs delay/frequency sensitivi- ties are determined by varying one of the three separate components (P ‚Äì V ‚Äì T) and keeping everything else the same. The voltage and temperature sensitivity of the SPICE models are investigated with a transient analysis. Here, the voltage and temperature conditions are varied in discrete steps over the speciÔ¨Åed operating range provided in the datasheet of the MCU. Thus a sensitivity around the nominal operating point can be calculated in terms of voltage and temperature sensitivities of the functional path ROs. Such analysis does not consider local dynamic voltage droops or temperature effects of gates within the analyzed path. However, these simpliÔ¨Åcations are sufÔ¨Åcient to give a general order of magnitude of the sensitivity of the analyzed paths. The investigation of IR drop was shown in Section"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_178", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 178, "text": "s within the analyzed path. However, these simpliÔ¨Åcations are sufÔ¨Åcient to give a general order of magnitude of the sensitivity of the analyzed paths. The investigation of IR drop was shown in Section 5.2.2. The voltage and temperature analysis is done with the transient analysis on a SPICE simulator; the process sensitivity is analyzed with the MunEDA WiCkeDTMTool Suite [109]. The WiCkeD tool performs the sensitivity of the process parameters with the SPICE simulation in the background. The WiCkeD tool investigates all design parameters (geometry of transistors and passive elements) under a given statistical process variation and mismatch based on the provided voltage and temperature condition [110]. The sensitivity of the output parameters (delay/frequency) is analyzed, given the global process variation of the design parameters. The sensitivities of the output parameters are given for each simulated functional path RO. A sensitivity analysis with respect to process parameters using the WiCkeD tool consumes less set-up effort and simulation time than an extensive Monte-Carlo simulation. The sensitivity analysis described above with respect to the PVT conditions provides an initia"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_179", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 179, "text": "the WiCkeD tool consumes less set-up effort and simulation time than an extensive Monte-Carlo simulation. The sensitivity analysis described above with respect to the PVT conditions provides an initial indication of how good the path selection Ô¨Çow is. In addition, the sensitivity analysis of the functional paths can be used to improve the selection Ô¨Çow further. 5.3.3. Improvement of the Heuristic Selection The heuristic process of selecting paths based on physical design data, explained in Section 4.1, may result in some functional paths that are sensitive to speciÔ¨Åc parameters not being selected as functional path ROs. This deÔ¨Åciency in path selection is that the deÔ¨Åned characteristics do not adequately cover speciÔ¨Åc parameters that affect performance. The analysis focuses on the process parameters in functional paths (see Figure 5.8a). The aim is to Ô¨Ånd lacking process parameter sensitivities and try to deÔ¨Åne an additional or 78 5. PRE-Silicon VeriÔ¨Åcation and Validation improved selection characteristic. However, the process parameters consist of a large number of individual parameters. Some individual process parameters dominate the sensitivity analysis of a functional path. Dif"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_180", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 180, "text": "ction characteristic. However, the process parameters consist of a large number of individual parameters. Some individual process parameters dominate the sensitivity analysis of a functional path. Different individual process parameters may be dominant if other functional path ROs are considered. Thus a bunch of randomly selected sensitizable functional paths is fed into the model extractor, and SPICE models are generated, as in Figure 5.8a. The resulting SPICE models are analyzed for their delay sensitivity concerning the process parameters. Assuming that this sensitivity analysis results in certain path types with a very high sensitivity to precisely one or more process parameters, they can be analyzed with respect to the physical design characteristics and new selection features can be deÔ¨Åned. In this way, new features can be added to the path selection process, and the heuristic selection process can be continuously improved. 5.3.4. PRE- Silicon Validation Results In order to show the quality of the path selection process for the 22implemented functional path ROs, the SPICE models are extracted using the methodology proposed in Section 5.3.1. Thus, 22SPICE models of the functio"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_181", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 181, "text": "the quality of the path selection process for the 22implemented functional path ROs, the SPICE models are extracted using the methodology proposed in Section 5.3.1. Thus, 22SPICE models of the functional path ROs (see Figure 5.8) are generated, and the PVT sensitivities are investigated to validate the selection process based on physical design data. The voltage and temperature sensitivities of the selected paths are calculated. The normal- ized sensitivity of voltage and temperature with respect to the RO frequency fpiis shown in Figure 5.9. The normalization deÔ¨Ånes the lowest occurring sensitivity of a path as 0 %and the highest sensitivity as 100 %. 0123456789101112131415161718192021 RO0%20%40%60%80%100%SensitivityFunctional Path Sensitivities Voltage Temperature Figure 5.9.: Voltage and temperature sensitivity of the functional path ROs. Adapted from [42] c IEEE 2022. Some paths are more sensitive to voltage, others to temperature. It is noticeable that ROs 79 5. PRE-Silicon VeriÔ¨Åcation and Validation with a long functional path length are more susceptible to temperature (see RO10&11). Thus, the path selection process Ô¨Ånds a very heterogeneous set of ROs that differ in their se"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_182", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 182, "text": "ation and Validation with a long functional path length are more susceptible to temperature (see RO10&11). Thus, the path selection process Ô¨Ånds a very heterogeneous set of ROs that differ in their sensitivity to the voltage and temperature parameters, which is the goal. The selected functional path ROs are also investigated regarding their sensitivities in terms of process parameters. The technology used has almost 100individual process parameters; their change will be analyzed for frequency sensitivity. Figure 5.10 shows that all process parameters are covered with the selected 22 functional path ROs. Process Parameter Variance Combined Positive Negative Figure 5.10.: Variance of the frequency sensitivity with respect to the individual process parameters of all selected functional paths ROs. Adapted from [42] c IEEE 2022. All individual process parameters are listed on the X-axis, and the variance of the sensitivity to frequency is shown on the Y-axis. A distinction can be made between positive frequency changes and negative frequency changes. Some paths react with a positive frequency change to certain parameters, others with a negative one. The absolute value is shown in blue a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_183", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 183, "text": "en positive frequency changes and negative frequency changes. Some paths react with a positive frequency change to certain parameters, others with a negative one. The absolute value is shown in blue and results from the sum of the positive and negative frequency change. By looking at each functional path RO individually, some paths are sensitive to the process parameter as a whole, and others are not. The variance of the frequency sensitivity of the selected functional paths ROs with respect to all process parameters is shown in Figure 5.11. The portions of the individual process parameters have been cumulated. Thus, some paths are more sensitive to the process than others. By combining the results, the heuristic path selection process Ô¨Ånds paths with different frequency sensitivities with respect to the whole PVT conditions, which was also the intention of the methodology. Note that the absolute frequency change varies signiÔ¨Åcantly within PVT conditions. Much of the frequency change occurs due to the variation of voltage and temperature - voltage, in particular, has an enormous impact. The effects of process parameters on frequency sensitivity are the smallest over the entire PVT "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_184", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 184, "text": "ccurs due to the variation of voltage and temperature - voltage, in particular, has an enormous impact. The effects of process parameters on frequency sensitivity are the smallest over the entire PVT range. Therefore, the oscillation frequency must be measured with high precision to resolve the sensitivity of all PVT parameters. 80 5. PRE-Silicon VeriÔ¨Åcation and Validation Figure 5.11.: Variance of the frequency sensitivity of the selected functionalpaths ROs with respect to all process parameters. Adapted from [42] c IEEE 2022. 5.3.4.1. Results on Improving the Heuristic Selection In order to verify the assumption made in Section 5.3.3, thirty randomly selected functional paths of the design are also selected, and SPICE models are generated using the model extractor. The SPICE models are then analyzed regarding their sensitivity to the process parameters to Ô¨Ånd paths that are even more sensitive to speciÔ¨Åc parameters and thus improve the heuristic approach. The number of paths, in this case, is limited to thirty to illustrate the methodology; in reality, many more paths are examined in this way. Figure 5.12 shows that some paths have a signiÔ¨Åcant variance and, thus, a considerable"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_185", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 185, "text": "s case, is limited to thirty to illustrate the methodology; in reality, many more paths are examined in this way. Figure 5.12 shows that some paths have a signiÔ¨Åcant variance and, thus, a considerable sensitivity in process parameter change. Figure 5.12.: Variance of the delay sensitivity of the randomly selected sensitizable functional paths with respect to all process parameters. Adapted from [42] c IEEE 2022. 81 5. PRE-Silicon VeriÔ¨Åcation and Validation The majority of the paths have low sensitivity because they were randomly selected, but a few paths are very sensitive (Path No. 9 & No. 27). Such sensitive functional paths will be further investigated to determine if additional features for the physical design data-based path selection can be derived. For example, if a particular cell topology is very sensitive, the physical design data-based path selection can be optimized to consider these cell topologies in the selection as well. In this way, the heuristic path selection is improved with this feedback and is ready for future derivations and designs. 82 6. PRE-SI Summary This part explains and illustrates the Pre-Silicon activities to implement, select, and validate functiona"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_186", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 186, "text": "oved with this feedback and is ready for future derivations and designs. 82 6. PRE-SI Summary This part explains and illustrates the Pre-Silicon activities to implement, select, and validate functional path ROs. For this purpose, the most essential segments are divided into three chapters. Chapter 3 presents the basic concept of the functional path RO, including the implementa- tion methods and related infrastructure. The basic implementation of functional path ROs is presented and illustrated by two functional paths that are implemented as ROs. It is shown that functional path ROs have an advantage in terms of area and leakage current of over 96 % compared with traditional RO structures for 128implemented ROs. A proof-of-concept is conducted concerning the advanced implementation concepts. In particular, two concepts are proposed on how to select functional paths to ensure efÔ¨Åcient implementation. It is examined whether sufÔ¨Åcient paths can be sensitized with a single pattern for the natural loops approach - which is the case. The novel concept of self-enabling functional path ROs is presented, and a feasibility study is conducted. The use of the self-enabling approach can save mor"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_187", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 187, "text": "atural loops approach - which is the case. The novel concept of self-enabling functional path ROs is presented, and a feasibility study is conducted. The use of the self-enabling approach can save more than 70 % of routing resources and, in some cases, even up to 80 % for the investigated MCU. Furthermore, two options are proposed for self-enabling: Option 1 and Option 2. Option 1, also labeled direct self-enabling, uses ATPG constraints of the launch FF of the path itself. Option 2 (indirect self-enabling) utilizes nearby launch FF and an unlock gate for enabling. A scan-controlled control infrastructure is introduced. Due to its hybrid properties, the control infrastructure can utilize the basic concept of functional path ROs and the self-enabling functional path ROs. The main advantage is that the sensitization of the functional path and the settings of the control infrastructure are maintained with a single scan pattern. The entire implementation Ô¨Çow of the functional path RO is compatible with standard implementation Ô¨Çows used in the industry. The path selection methodology is presented in Chapter 4. The chapter presents a clustering- based selection Ô¨Çow to select a representa"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_188", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 188, "text": "mpatible with standard implementation Ô¨Çows used in the industry. The path selection methodology is presented in Chapter 4. The chapter presents a clustering- based selection Ô¨Çow to select a representative subset of functional paths on the design for an RO implementation. 22functional paths are selected in the MCU under investigation and implemented as ROs. The path selection Ô¨Çow provides a very low turnaround time and sorts the paths into buckets. The paths in the buckets have similar properties concerning the deÔ¨Åned path characteristics. The last chapter in the Pre-Silicon part describes the Pre-Si veriÔ¨Åcation and validation of 83 6. PRE-SI Summary functional path ROs. The implemented functional path ROs are veriÔ¨Åed for their functionality via simulation. A side beneÔ¨Åt of timing-aware simulation-based veriÔ¨Åcation is an early estimation of the oscillation frequency of the implemented functional path. This is used for a Ô¨Årst test-limit setting. Also, the circumstance is analyzed in that the ECO implementation of the functional path ROs is combined with additional last-minute chances before the tape-out. The results show no signiÔ¨Åcant changes in the functional path selection. Also, a"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_189", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 189, "text": " the ECO implementation of the functional path ROs is combined with additional last-minute chances before the tape-out. The results show no signiÔ¨Åcant changes in the functional path selection. Also, a Ô¨Årst analysis of the PDN stability of the regions with functional path ROs is conducted. The path selection Ô¨Çow is validated via sensitivity analysis of the functional path ROs. A methodology is presented to extract analog SPICE models from the design and analyze them regarding PVT sensitivity. This also allows a continuous improvement of the path selection process. The sensitivity analysis shows that the implemented 22functional path ROs are more diverse than those not using the path selection process. 84 Chapter 2 Part I Part II Chapter 10 Chapter 3 Chapter 4 Chapter 5 Chapter 7 Chapter 8Chapter 6 Chapter 9 PRE-Silicon POST-SiliconBackground InformationFunctional Path ROsPath Selection MethodologyVerification and ValidationMeasurement and ValidationPerformance ScreeningConclusion and Future WorkTape - outOutline of Part II. Part II. POST-Silicon 85 Part II of the thesis is dedicated to the Post-Silicon phase. Once the Ô¨Årst silicon arrives from the manufacturing and assembly, the MCU"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_190", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 190, "text": "ture WorkTape - outOutline of Part II. Part II. POST-Silicon 85 Part II of the thesis is dedicated to the Post-Silicon phase. Once the Ô¨Årst silicon arrives from the manufacturing and assembly, the MCU is tested, validated, and characterized in depth. The number of produced devices in the early engineering phase is small compared with later mass production. Before ramping to volume production, the devices are extensively tested and analyzed to Ô¨Ånd design weaknesses and test the speciÔ¨Åed functionality. The devices in the engineering phase are also manufactured as corner lots to have a considerable spread in the process parameters. An essential part of this phase is the performance characterization and development of an efÔ¨Åcient performance screening strategy for the high-volume phase. What also changes is the abstraction level. The MCU at the top-level is now considered instead of any chip partitions such as Module A, B, or C. In addition to the three modules considered, the MCU consists of further modules that are all merged to top-level design and then manufactured into a uniform MCU. The functional path ROs do not aim to detect defects in the devices for which conventional structu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_191", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 191, "text": " of further modules that are all merged to top-level design and then manufactured into a uniform MCU. The functional path ROs do not aim to detect defects in the devices for which conventional structural test methods are responsible. Instead, the goal is to determine performance by considering only the frequencies of the functional path ROs. In this thesis, 22functional path ROs are implemented on each of the MCUs. The functional path ROs must be measured and validated to determine if they are working as expected, which will be explained in Section 7. The section is basically looking for the RO frequencies themselves. The Section 8 will describe the methodology of performance characterization and the development of a machine learning (ML) based performance screening. The main research question in this section is how the functional path ROs perform on the performance screening. 86 7. Measurement and Validation of the Functional Path RO 7.1. Functional Path RO Measurement Results The functional path ROs are measured on automatic test equipment (ATE) load-board using a digital probe card extension that taps the frequency of the functional path ROs on the GPIOs of the packaged device. "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_192", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 192, "text": "ctional path ROs are measured on automatic test equipment (ATE) load-board using a digital probe card extension that taps the frequency of the functional path ROs on the GPIOs of the packaged device. The measurement sequence is explained in Section 3.1. During the shift-in of the scan pattern, the functional path ROs are sensitized. When the functional path RO is enabled - enable signal is high - the ATE receives a handshake signal, and the digital probe card is activated. As soon as the frequency measurement is completed and the measured frequency is within the expected range, the procedure is continued with the subsequent functional path RO measurement. If a frequency is outside the expected range, the root cause of the discrepancy must be identiÔ¨Åed, which can be very broad. The measurement of the functional path ROs should be at a stable voltage and temper- ature condition to have a high reproducibility of the measurements. In order to check the reproducibility, the 22functional path ROs are repetitively measured on the same device. A repetition of 100times the measurement procedure is shown in Figure 7.1. The measured frequencies of each RO are normalized since the frequencies "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_193", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 193, "text": "h ROs are repetitively measured on the same device. A repetition of 100times the measurement procedure is shown in Figure 7.1. The measured frequencies of each RO are normalized since the frequencies of the ROs are in different ranges. RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO210.00.20.40.60.81.0Normalized Frequency 100 Measurements Figure 7.1.: Repetitive measurement of the functional path ROs on a normalized scale. 87 7. Measurement and Validation of the Functional Path RO The repetitive measurements show only a few outliers in some of the ROs. Except for these rare occurring outliers, the measurements show a stable distribution around the mean. In order to quantify the reproducibility, the coefÔ¨Åcient of variation (CV) is calculated. The CV is a dimensionless number that reÔ¨Çects the relative accuracy of a measurement [111]. The CV is calculated with the standard deviation ratio to the measurements‚Äô mean and is expressed as a percentage value. The target is to have a CV close to 0 %that indicates perfect reproducibility of the measurement. The calculated CV is shown in Figure 7.2. RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_194", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 194, "text": "centage value. The target is to have a CV close to 0 %that indicates perfect reproducibility of the measurement. The calculated CV is shown in Figure 7.2. RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO210.010.020.030.040.050.060.070.08CV (%)CoeÔ¨Écient of variation of 100 measurements Figure 7.2.: CoefÔ¨Åcient of variation of 100 repetitive measurements. The overall CV is below 0.08 % , which indicates the high repeatability of the functional path RO measurement. The experiments are executed on two packaged devices, and the CV is in the same range in both measured devices. Thus the functional path ROs can be measured with high reproducibility using the GPIOs and the ATE. In order to compare the measured frequency range with the expected frequency range, a statistically relevant amount of devices is measured. The measured RO frequencies are then compared with the test limits determined in the Pre-Si phase. Section 5.1.2 determined an upper fupper piand lower flower pitest limit for each RO. Ideally, all measured RO frequencies are within the determined test limits. The test limits of the functional path ROs are compared among 3858 devic"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_195", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 195, "text": "fupper piand lower flower pitest limit for each RO. Ideally, all measured RO frequencies are within the determined test limits. The test limits of the functional path ROs are compared among 3858 devices from 25wafers to see if the measured RO frequencies are in the expected range. The results are shown in Figure 7.3. All measured functional path ROs are within the pre-determined test limits. Therefore, the functional path RO frequencies on silicon correspond to the values speciÔ¨Åed in Section 5.1.2. Thus, the functional path ROs all work within the veriÔ¨Åed frequencies. The functional path ROs deliver promising reproducibility and expected frequency range results. However, checking the voltage at the chip is also essential since the functional path RO measurement requires stable voltage conditions. At-speed test patterns, such as the path 88 7. Measurement and Validation of the Functional Path RO 0 5 10 15 20 RO0.20.40.60.81.0Frequency(Hz)√ó108 fupper piatPVTbest flower piatPVTworst Measurement Data Figure 7.3.: Measurement data from 3858 devices of 25 wafers and the simulated test limits. delay pattern, can signiÔ¨Åcantly impact the overall power supply stability and cause voltage droo"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_196", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 196, "text": "rement Data Figure 7.3.: Measurement data from 3858 devices of 25 wafers and the simulated test limits. delay pattern, can signiÔ¨Åcantly impact the overall power supply stability and cause voltage droops [17]. This is especially true during changes in the circuitry mode, e.g., from the shift-in phase (long clock cycles ) to the capture phase (short at-speed clock pulse) [112]. Those abrupt transient events can cause voltage droop, which is hazardous to measurement where a stable voltage condition is needed. In order to investigate the voltage stability in the functional path RO measurement, the voltage of the MCU is sensed and observed with a scope. The voltage is observed at the load board of the test head, where the DUT is mounted on the test socket. The transition of the shift-in phase to the measurement phase is observed where the MUX of the respective functional path RO is enabled. The snapshot of the scope is shown in Figure 7.4. Figure 7.4.: Voltage drop measurements. The three traces in the snapshot are CH1 (yellow), the supply voltage measured in the 89 7. Measurement and Validation of the Functional Path RO sense pins of the MCU; CH2 (turquoise), the trigger signal, which "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_197", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 197, "text": "races in the snapshot are CH1 (yellow), the supply voltage measured in the 89 7. Measurement and Validation of the Functional Path RO sense pins of the MCU; CH2 (turquoise), the trigger signal, which is the enable signal of the MUX; and CH3 (magenta), the GPIO pin oscillation signal of the RO. The critical trace is the yellow signal which does not reveal any droop in the presented transition phase. That conÔ¨Årms the Pre-Si dynamic voltage droop simulation in Section 5.2.2, where only a little voltage droop is expected at the MCU level during transient events. Thus it can be eliminated that any signiÔ¨Åcant transient effects in the supply voltage are happening in the transitional period of the phases in the functional path RO measurement. The functional path ROs‚Äô frequencies can also visualize the die-to-die gradient over the wafers. One functional path RO is selected, and the frequency is observed for all dies on a wafer. Such an approach makes the D2D process variation visible and can be used to track process stability or other manufacturing issues. A visualization of the D2D process variation based on a functional path RO frequency is shown in Figure 7.5. Wafer_x Wafer_yRO Frequency"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_198", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 198, "text": " used to track process stability or other manufacturing issues. A visualization of the D2D process variation based on a functional path RO frequency is shown in Figure 7.5. Wafer_x Wafer_yRO Frequency 3.553.603.653.703.753.803.853.901e7 Figure 7.5.: Wafermap of the frequency distribution of an functional path RO. The observed RO frequency can be abstracted as a donut shape , which is one of the possible shapes that can be observed in wafer maps [63]. This is only one example of a dedicated use case in which the functional path RO frequencies can help to improve and monitor the manufacturing process. 90 8. Performance Screening Using Functional Path RO 8.1. Method and Data Set for the Performance Screening The main goal of the functional path ROs is to use such structures as performance monitors for performance screening. The performance screening is part of the MCU test process, which is shown in Figure 8.1. Each device has to pass the performance screening for a successful Ô¨Ånal back-end (BE) test. The functional path RO measurement is part of the front-end (FE) and BE tests. Therefore for each manufactured device, the functional path RO data is obtained. Also, the SMON module is m"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_199", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 199, "text": "nd (BE) test. The functional path RO measurement is part of the front-end (FE) and BE tests. Therefore for each manufactured device, the functional path RO data is obtained. Also, the SMON module is measured. Based on the obtained RO data, the performance screening is done as part of the Ô¨Ånal BE test using the RO data as monitors. The device can be shipped if the performance screening and the Ô¨Ånal test are passed. ManufacturingWafer Probe FE TestPackaging Burn-inFinal Test BEShipping Performance Screen.RO meas. RO meas. FMAX Char- acterization Figure 8.1.: Test Ô¨Çow of an MCU including the performance screening. However, the performance screening is a challenging process. The performance screening shall be done by only considering the RO measurement data. Therefore, the RO measurement data is used as input for the performance screening, and the output is the pass / fail decision. In order to initialize the performance screening, a set of golden devices is obtained for an elaborate FMAX characterization used as the ground truth . Such characterization is a high- effort and time-consuming process executed on these golden devices. In the Ô¨Årst part of this section, the FMAX characteriza"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_200", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 200, "text": "characterization used as the ground truth . Such characterization is a high- effort and time-consuming process executed on these golden devices. In the Ô¨Årst part of this section, the FMAX characterization is explained; afterward, the data set and principles for the performance screening are described. 91 8. Performance Screening Using Functional Path RO 8.1.1. FMAX Characterization As stated previously, the performance determination of an MCU is challenging. No mea- surement gear can measure the precise performance of a particular device in a one-shot measurement, as in voltage or current measurement. This is because the performance of the MCU depends on many conditions. e.g., use-case, PVT conditions, and many more. However, to have an initial reference set to correlate the RO data with the device performance, a set of golden devices is deeply analyzed with a FMAX characterization. The FMAX characterization determines the performance of a device with an elaborate process that is similar to a system- level test (SLT). The SLT initially tests the devices to Ô¨Ånd defects. In the FMAX characterization, the SLT setup is used to determine the performance of a device in a particular condi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_201", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 201, "text": "ar to a system- level test (SLT). The SLT initially tests the devices to Ô¨Ånd defects. In the FMAX characterization, the SLT setup is used to determine the performance of a device in a particular condition for a particular use case. The outcome of the FMAX characterization is the maximum achievable clock frequency FmaxTifor a given functional test pattern Ti(i2N). The FmaxTiis the highest frequency at which the functional test pattern is executed under a predeÔ¨Åned condition (voltage, temperature) without errors. Each golden device is packaged and mounted on an SLT board for FMAX characterization. The SLT board has a high-precision radio frequency (RF) socket with low resistance and the lowest possible parasitics. In addition, the SLT board has high power integrity and built-in energy storage capacity to prevent voltage drop during testing. During characterization, the temperature and voltage of the MCU can be precisely controlled and are continuously sampled by on-chip voltage and temperature sensors. The DUT is placed on the SLT board in the RF socket with a semiconductor test handling system to improve the repeatability of the measurement process. The voltage and temperature are s"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_202", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 202, "text": "rature sensors. The DUT is placed on the SLT board in the RF socket with a semiconductor test handling system to improve the repeatability of the measurement process. The voltage and temperature are set to deÔ¨Åned voltage Vcritand temperature Tcritconditions. The MCU is programmed with the Ô¨Årmware when the voltage and temperature conditions reach the deÔ¨Åned steady-state values. The MCU‚Äôs clock frequency can also be controlled with the SLT setup. Then the functional pattern Tiis uploaded and launched in an inÔ¨Ånite loop on the MCU. The MCU starts executing the functional pattern at a low frequency. The frequency is slowly increased in each loop until the functional pattern fails. The process is repeated several times to ensure that the failure frequency of the MCU remains at the same value. The last working frequency prior to the MCU failure frequency is considered and stored as FmaxTiof the functional pattern Ti. The measurement of Fmaxis performed with several functional patterns [24]. The applied functional patterns in the FMAX characterization show a wide variety in stressing different design units of the MCU. The functional patterns are designed with the intention that no custome"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_203", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 203, "text": "The applied functional patterns in the FMAX characterization show a wide variety in stressing different design units of the MCU. The functional patterns are designed with the intention that no customer application fails at a lower frequency than a functional pattern. Therefore, some patterns are designed to exhaust the maximum power of the MCU as 92 8. Performance Screening Using Functional Path RO speciÔ¨Åed in the data sheet. These patterns result in high-load jumps and create massive cross- talk between functional blocks. Other functional patterns stress speciÔ¨Åc design parts, such as dedicated data bus lines or repetitively executing a speciÔ¨Åc instruction. Thus, all functional patterns attempt to force the MCU to its power limit. However, some Fmaxuncertainty remains in the characterization, caused by (i) the diversity of possible customer applications, (ii) measurement uncertainty and (iii) defective devices. i): An automotive MCU is intended for a large number of applications. Thus there are thousands of use cases, and each application puts more strain on some parts of the MCU than on others. Therefore, the applied functional pattern stresses the MCU over the speciÔ¨Åed operating "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_204", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 204, "text": "there are thousands of use cases, and each application puts more strain on some parts of the MCU than on others. Therefore, the applied functional pattern stresses the MCU over the speciÔ¨Åed operating range and ensures a robust MCU in each customer application. However, in order to avoid omitting customer use cases and to avoid the applied functional patterns stressing some areas, a guardband is needed in performance screening that covers these contingencies. ii): Some measurement uncertainties also affect the FMAX characterization process. The characterization is performed under worst-case operating conditions in terms of voltage ( Vcrit) and temperature ( Tcrit) at the limits of the speciÔ¨Åed operating window. Even minor deviations of the voltage and temperature conditions affect the measurement result. In addition, small mechanical vibrations cause a change in the base resistance, or statistical noise changes the result. Another consequence is that error messages of the FMAX measurement software are due to contact problems during the measurement. Some GPIO pads are also activated in the functional pattern; errors can occur in the presence of a contact problem. Since the measuremen"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_205", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 205, "text": "nt software are due to contact problems during the measurement. Some GPIO pads are also activated in the functional pattern; errors can occur in the presence of a contact problem. Since the measurement process is automated, the setup has appropriate error handling so that errors that occur do not interrupt the characterization. If an error occurs in an FMAX test pattern, the characterization of the device continues, and the speciÔ¨Åc error-prone test is marked with a not-a-number value. These errors are rare but are worth mentioning. Therefore, many hard-to-predict factors inÔ¨Çuence the FMAX characterization during acquisition, so careful attention must be paid to any measurement uncertainties and errors when processing the measurement data. iii): Another cause of discrepancies in the FMAX characterization are physical defects in the golden devices (e.g., shorts, opens). Those defective devices are usually detected within the productive test Ô¨Çow with stuck-at, transition, or path-delay tests. However, at the point in time when the golden devices are obtained from the production test Ô¨Çow, the production test is not technically mature because the entire product is still in the engineeri"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_206", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 206, "text": "sts. However, at the point in time when the golden devices are obtained from the production test Ô¨Çow, the production test is not technically mature because the entire product is still in the engineering phase. Consequently, a small fraction of golden devices exhibits a defect. These devices must be removed since the performance screening does not target defective devices. Therefore, it is essential to 93 8. Performance Screening Using Functional Path RO have defect-free golden devices for FMAX characterization since the characterization is the benchmark for the whole performance screening process, and defective devices signiÔ¨Åcantly disturb the screening process. Outlier detection is used to address the three effects mentioned in the FMAX characterization. Outlier detection aims to Ô¨Ålter out devices that deviate from the wafer median. It is assumed that the effects mentioned above cause such deviating components. The FMAX characterization for each test is considered on its own, and devices deviating more than Ntimes the standard deviation from the wafer median are discarded. An example of outlier detection is shown in Figure 8.2. T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SLT97.5100.0102.5105.01"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_207", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 207, "text": "ces deviating more than Ntimes the standard deviation from the wafer median are discarded. An example of outlier detection is shown in Figure 8.2. T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SLT97.5100.0102.5105.0107.5110.0112.5115.0Frequency (%) Figure 8.2.: FMAX characterization results from a wafter after the SLT. The boxplot shows the distribution of a wafer with 109FMAX -characterized devices for ten functional test cases. The \u00063sigma border is shown as a red triangle for each distribution. InT9a device deviates from the wafer median by more than three sigma. Accordingly, such devices are discarded in the overall FMAX characterization even if they are inconspicuous in the other test cases. However, one device is slightly below the whiskers in T7but within the deÔ¨Åned sigma border of the test case. This device is not discarded according to the deÔ¨Åned rule. 8.1.2. The Data Set for Performance Screening The data set used for the performance screening can be distinguished into two groups: theunlabeled data set and the labeled data set . In order to understand the nomenclature, the terms feature and label (explained in Section 2.6) are assigned to the context of performance 94 8. Performance Scre"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_208", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 208, "text": "ed data set and the labeled data set . In order to understand the nomenclature, the terms feature and label (explained in Section 2.6) are assigned to the context of performance 94 8. Performance Screening Using Functional Path RO screening. The features - that are the input data in machine learning (ML) problems - are the RO frequency data. So each measured RO acts as one feature. The labels - that are the output data in ML problems - are the FMAX of a particular device. Each device that undergoes the FMAX characterization has multiple labels FmaxTifor the different test cases Ti. Thus, a manufactured device that has passed the production test Ô¨Çow from Figure 8.1 is, by default, an unlabeled device. The set of golden devices which are FMAX characterized are denoted as labeled devices. The schematic structure of the two data sets is shown in Figure 8.3. The unlabeled data set contains the chip ID, which is the unique identiÔ¨Åcation number for each manufactured chip, and the RO data from all measured ROs during production. The labeled data set also contains the FMAX values from the FMAX characterization. The labeled data set is the ground truth to set up and model the performance pro"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_209", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 209, "text": " all measured ROs during production. The labeled data set also contains the FMAX values from the FMAX characterization. The labeled data set is the ground truth to set up and model the performance process. In the later production, there are only unlabeled devices available. In order to deÔ¨Åne the performance screening process, which is done in the next section, the labeled data set is used. Unlabeled Dataset Labeled Dataset Chip ID RO Frequencies Manufacturing Production TestChip ID RO Frequencies FMAX Manufacturing Production Test FMAX Ch. Figure 8.3.: Data set structure from unlabeled and labeled devices. 8.1.3. The Principle Concept for Performance Screening The main objective of the performance screening is to assess if a device meets the speciÔ¨Åed performance requirements. The frequency of the RO structures as indirect performance monitors provide the input for this judgment: Functional path ROs and SMONs. Thus the quality of the performance screening depends strongly on the RO structures. The process is visualized in Figure 8.4. The RO frequencies are passed into the performance screening process, and the process decides whether the device passes or fails. The performance scree"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_210", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 210, "text": "ctures. The process is visualized in Figure 8.4. The RO frequencies are passed into the performance screening process, and the process decides whether the device passes or fails. The performance screening process, at Ô¨Årst glance, can be approximated as a classiÔ¨Åcation problem - numerical input data (RO frequencies) is used to classify the device as pass or fail. The classiÔ¨Åcation problem also has a signiÔ¨Åcant disadvantage: having a Ô¨Åxed pass/fail border. The entire performance screening model has a Ô¨Åxed border on which all devices are classiÔ¨Åed. If the border changes slightly, e.g. due to 95 8. Performance Screening Using Functional Path RO RO frequenciesPerformance Screening ProcessOutputPass / Fail based on FMAX Figure 8.4.: Performance screening process basics. a change in data sheet performance requirements, the entire model is invalid and must be revised if the requirements change. Therefore, the model can be formulated as a regression problem. The numerical RO frequencies are fed into the performance screening regression model, and a numerical FMAX is predicted for the device. That approach has a signiÔ¨Åcant advantage: a model valid over the whole FMAX range. The classiÔ¨Åcation"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_211", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 211, "text": " into the performance screening regression model, and a numerical FMAX is predicted for the device. That approach has a signiÔ¨Åcant advantage: a model valid over the whole FMAX range. The classiÔ¨Åcation and regression are classical supervised ML problems. Therefore ML is used to build and train a model for the performance screening. For this training, the labeled data set is used. Once the model is trained, it can be deployed for performance screening based only on the RO frequencies on unlabeled data. The process for training and evaluating the ML model with the labeled and deploying the ML model on unlabeled data is shown in Figure 8.5. Train and Evaluate Model Deploy ModelRO freq. Features FMAX Ch. Labels PreprocessingML Algorithm for Performance Screening ProcessOutputML Model forFMAX prediction Labeled DatasetML Model forFMAX predictionRO freq. Features FMAXUnlabeled Dataset Figure 8.5.: Performance screening process learning and deploying. Train and Evaluate the Model: The initial data set for the training is the labeled set of golden devices with their features (RO frequencies) and the labels from the FMAX charac- terization. The labeled data set is preprocessed before being f"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_212", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 212, "text": "data set for the training is the labeled set of golden devices with their features (RO frequencies) and the labels from the FMAX charac- terization. The labeled data set is preprocessed before being fed into the ML algorithm of the performance screening. The preprocessing steps and obtained analysis will be further explained in Section 8.2. After this, the performance screening Ô¨Çow is deÔ¨Åned, and the algorithm is developed, trained, and validated; Section 8.3 describes this process. 96 8. Performance Screening Using Functional Path RO Deploy the Model: Once the model is trained and the performance veriÔ¨Åcation process is deÔ¨Åned, the model can be applied to unlabeled data, in other words, in the production test. This makes the resource-intensive FMAX characterization obsolete by using only the features for the performance screening. The more accurate the performance screening is, the better it is for automotive quality and yield gain. The utilization of the model and the quality and yield impact will be described in Section 8.4. 8.2. Preprocessing of the Data Set The input data for preprocessing must be labeled devices (see Figure 8.3). The data set is checked for consistency and pla"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_213", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 213, "text": "d impact will be described in Section 8.4. 8.2. Preprocessing of the Data Set The input data for preprocessing must be labeled devices (see Figure 8.3). The data set is checked for consistency and plausibility, for example, for missing entries or negative numbers. The FMAX characterization (see Section 8.1.1) includes outlier Ô¨Åltering, so there is a very low probability that such outliers are still present in the labeled data set. The features (RO frequencies) must be within the predeÔ¨Åned upper and lower frequency limits of the production test Ô¨Çow (see Section 5.1.2). Once the data set has passed these checks, the dimensionality reduction starts as the second part of the data preprocessing. This process aims to reduce the complexity of the feature set from a sample feature space, as explained in Section 2.6. The feature selection is performed in this work with the Correlation coefÔ¨Åcient to get an indication of the behavior of the features among themself as well as to the labels. The data set with the functional path ROs as features competes with the SMONs as features. The aim is to identify which input features perform better and which ROs have a high correlation with the labels. I"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_214", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 214, "text": "ta set with the functional path ROs as features competes with the SMONs as features. The aim is to identify which input features perform better and which ROs have a high correlation with the labels. In contrast, the feature reduction transforms the input feature set into a new feature space using, for example, principal component analysis (PCA). PCA decomposes the input feature into its principal components [96]. Thus, it analyzes how many different pieces of information are contained in a data set and how these can be mapped into their principal components without information loss, if possible. The more diverse the data set is, the more principal components are needed to represent the data set. This method is used to investigate which data set contains more information density. The dimensionality reduction approaches used in this paper aim to compare the two feature sets, the functional path ROs versus the SMONs, to clarify how good the functional path ROs are as performance monitors. 8.3. Performance Screening Flow The high-quality preprocessed data set is applied as input data for the performance screening process. The data set contains either the functional path ROs as features"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_215", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 215, "text": " 8.3. Performance Screening Flow The high-quality preprocessed data set is applied as input data for the performance screening process. The data set contains either the functional path ROs as features or the SMONs as 97 8. Performance Screening Using Functional Path RO features. Two fundamentally different classes of ML are used for performance screening: clas- siÔ¨Åcation and regression. Within the two classes, different algorithms are utilized. However, since there are many algorithms with as many different complexities, this work will focus on a few commonly used algorithms.The main focus is on which ROs are better suited for performance screening - with a particular emphasis on the functional path ROs. In order to get a Ô¨Årst overview of the two approaches, namely the classiÔ¨Åcation and the regression approach, Table 8.1 compares the two approaches. Table 8.1.: Differences and similarities between the classiÔ¨Åcation approach and the regression approach. Metric ClassiÔ¨Åcation Regression Input Data Labeled data set Labeled data set Output Model Pass/Fail ClassiÔ¨Åer Numerical Regression Encoding Binary NO Applying FTH Beginning End Train/Test Split YES YES Cross Validation YES YES Helper"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_216", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 216, "text": "nput Data Labeled data set Labeled data set Output Model Pass/Fail ClassiÔ¨Åer Numerical Regression Encoding Binary NO Applying FTH Beginning End Train/Test Split YES YES Cross Validation YES YES Helper Function Feature Selection NO Average Complexity Low Medium Ease of use High Medium Screening Quality Medium High Automotive Quality DifÔ¨Åcult Guardbanding The main difference is that the classiÔ¨Åcation approach generates a model for a pass/fail decision given a dedicated threshold frequency FTHat which the performance pass/fail border is set. In contrast, the regression approach provides a predicted numerical device performance, and the dedicated performance threshold value is applied afterward for a pass/fail decision. The regression model can reach automotive quality requirements using a guard banding technique. The two approaches are explained in the following two subsections. The approaches are independent of which kind of ROs are used. Notation: In order to simplify the domain-speciÔ¨Åc problem into standard ML notation, the following notation is used: \u000fSet of labeled devices !X \u000fSet of unlabeled devices !U \u000fFeatures (RO frequencies) of a device j!xj \u000fMeasured Label ( FMAX character"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_217", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 217, "text": " problem into standard ML notation, the following notation is used: \u000fSet of labeled devices !X \u000fSet of unlabeled devices !U \u000fFeatures (RO frequencies) of a device j!xj \u000fMeasured Label ( FMAX characterization) of a device j!yj 98 8. Performance Screening Using Functional Path RO \u000fPredicted Label (from ML Model) of a device j!ÀÜyj SpeciÔ¨Åcation: The following performance screening aims to use the input vector xi(RO frequencies) to predict onelabel yiin contrast to the work in [51], where a multilabel perfor- mance screening is developed. Thus, onemodel is generated for onefunctional test pattern. That way, the relation between the input features and the functional test cases from the FMAX characterization is more visible. 8.3.1. Performance Screening using ClassiÔ¨Åcation The classiÔ¨Åcation-based performance screening trains a function fthat classiÔ¨Åes the devices in pass (1) or fail (0), given a dedicated target frequency FTH. The labeled data set Xis binary coded in the Ô¨Årst step to transform the numeric value into a binary value depending on FTH. For each device jinX, an encoded label y\u0003 jis generated according to y\u0003 j:=( 1 if yj\u0015FTH 0 otherwise. The set Xis then partitioned into a trai"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_218", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 218, "text": "m the numeric value into a binary value depending on FTH. For each device jinX, an encoded label y\u0003 jis generated according to y\u0003 j:=( 1 if yj\u0015FTH 0 otherwise. The set Xis then partitioned into a training set Sand test set T, where X=S[Tand S\\T=?. The training set is used to train the model. Once this is done, the test set is used to validate the model and derive critical metrics, e.g., error and model quality. A reasonable split ratio of the initial set into training and test set is 2/3to4/5[113]. The test set should contain at least 30samples to make an adequate statistical statement concerning error and prediction quality [114]. Such a training/test split approach is called Hold-Out . The set Sis used to train the model. Depending on the used algorithm, Sneeds normaliza- tion or standardization. Two common classiÔ¨Åcation algorithms are trained with the set S: the logistic regression and the random forest [115]. Logistic regression is a linear binary classiÔ¨Åcation model categorizing the devices into pass or fail. In order to do that, logistic regression utilizes a linear regression and applies the outcome of the regression model to the so-called sigmoid function. The sigmoid funct"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_219", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 219, "text": "he devices into pass or fail. In order to do that, logistic regression utilizes a linear regression and applies the outcome of the regression model to the so-called sigmoid function. The sigmoid function employs the linear regression outcome, providing a probability value between 0 and 1 [113]. The higher the sigmoid function value, the higher the probability that the current device is classiÔ¨Åed as pass and vice versa. The model aims to Ô¨Ånd a hyperplane according to which the devices are classiÔ¨Åed as pass or fail; that is, the model‚Äôs outcome. The logistic regression model fLRis trained with the set Sand evaluated with the set T. In order to measure how well the models perform, key metrics such as accuracy and F1 Score are used. In contrast to the logistic regression, a more advanced model is also applied for the 99 8. Performance Screening Using Functional Path RO classiÔ¨Åcation problem: the random forest. The random forest is a decision tree-based classiÔ¨Åer. It is established on the Bagging [116] and uses a randomized feature selection to build multiple uncorrelated decision trees, which are combined in the random forest model [117]. The ease of implementation, low computational e"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_220", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 220, "text": "agging [116] and uses a randomized feature selection to build multiple uncorrelated decision trees, which are combined in the random forest model [117]. The ease of implementation, low computational effort, and good generalization [117] make the random forest a good-Ô¨Åtting model for performance screening. The random forest model fRFis trained with the set Sand evaluated with the set T. In addition to the accuracy and F1 Score to evaluate the model, the trained random forest model also provides a feature importance ranking. Such ranking indicated which ROs are more critical for the model. Depending on the features used (functional path ROs or SMONs), the trained classiÔ¨Åcation models provide different results, which in turn indicate how well the features are suited for performance screening. This classiÔ¨Åcation model-based performance screening is always tailored to the determined FTH. If the FTHchanges, the entire model must be retrained and replaced. In contrast, regression-based performance screening works differently. Scoring metrics for ClassiÔ¨Åcation: The scoring metrics for the classiÔ¨Åcation-based perfor- mance screening are the accuracy and F1 score. The metrics are calculated "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_221", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 221, "text": "mance screening works differently. Scoring metrics for ClassiÔ¨Åcation: The scoring metrics for the classiÔ¨Åcation-based perfor- mance screening are the accuracy and F1 score. The metrics are calculated using the trained model applied to the evaluation set T. The accuracy is based on the nomenclature used in the confusion metrics (see Figure 2.14). This allows a speciÔ¨Åc device to be classiÔ¨Åed into four categories based on the actual device and the result of the prediction model: \u000fTP: the actual device is pass, and the model predicts the device as pass \u000fTN: the actual device is fail, and the model predicts the device as fail \u000fFP: the actual device is fail, and the model predicts the device as pass )Quality issue \u000fFN: the actual device is pass, and the model predicts the device as fail )Yield loss The accuracy of a model is calculated with the formula [92] Accuracy =True positives +True negatives True positives +True negatives +False positives +False negatives(8.1) applied to the devices in T. Such an accuracy metric represents the ratio between cor- rectly predicted devices and the population. However, the accuracy does not provide a fair comparison if the data set is unbalanced [118]."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_222", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 222, "text": " T. Such an accuracy metric represents the ratio between cor- rectly predicted devices and the population. However, the accuracy does not provide a fair comparison if the data set is unbalanced [118]. In an unbalanced data set, the proportion of passing and failing devices is unequal, which is usually the case in performance screening 100 8. Performance Screening Using Functional Path RO since the slow tail of the distribution is screened. Therefore a second metrics is introduced: the Matthews correlation coefÔ¨Åcient (MCC). The MCC can be calculated as follows [118]: MCC =TP\u0001TN\u0000FP\u0001FNp (TP\u0000FP)\u0001(TP+FN)\u0001(TN+FP)\u0001(TN+FN)(8.2) The MCC is a more recent evaluation score, especially for binary classiÔ¨Åcation problems, as in the present work. Thus the MCC is a suitable metric that also considers the prediction accuracy in the corner cases [118]. 8.3.2. Performance Screening using Regression In contrast to the previously explained classiÔ¨Åcation approach, the regression approach behaves differently. A regression model is used that does not require any threshold level previous to the training; also, the binary coding is not applicable anymore. The trained regression model is valid for the entire "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_223", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 223, "text": " A regression model is used that does not require any threshold level previous to the training; also, the binary coding is not applicable anymore. The trained regression model is valid for the entire FMAX range of the set X. The threshold level FTH is applied afterward to the model outcome. This approach aims for a one-Ô¨Åts-all solution independent of the targeted threshold. The regression model f:x7!ÀÜyjuses the numerical values of the features xi(RO frequen- cies) and predicts a numerical FMAX for a particular label ÀÜyj. Exactly one model is trained on one FMAX characterization test Ti. In order to train the regression model, the same train/test split approach is used as in Section 8.3.1. The set Xis split into a training set Sand test set T.Sis used to train the regression model andTis used for validating the model. Whether normalization or standardization of the data must be performed depends on the model algorithm used. The regression algorithm provides the numerical FMAX in contrast to the classiÔ¨Åcation model, where only a pass/fail decision is the model‚Äôs outcome. That numerical outcome made the regression approach more suitable for performance screening because a slight chang"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_224", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 224, "text": "t to the classiÔ¨Åcation model, where only a pass/fail decision is the model‚Äôs outcome. That numerical outcome made the regression approach more suitable for performance screening because a slight change in the threshold level FTHdoes not require retraining of the model. In this work, three regression models are used, which are fundamentally different in their underlying algorithms: RidgeCV ,PCA Regression , and Random Forest Regression . The RidgeCV regression fRidge combines a built-in K-Fold cross-validation, which is ben- eÔ¨Åcial in overÔ¨Åtting, especially in small data sets and Ridge Regression . The built-in K-Fold cross-validation divides the training set into K equal parts. Then the training uses K-1 parts, and the built-in test uses the remaining part of the training set. This procedure is repeated until all K parts are used for the built-in test. Such cross-validation in training provides a more robust model concerning overÔ¨Åtting and generalization. The Ridge regression is a model based on the linear least squares function. It is a more advanced model that efÔ¨Åciently 101 8. Performance Screening Using Functional Path RO implements collinearity in the multiple linear regressio"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_225", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 225, "text": "l based on the linear least squares function. It is a more advanced model that efÔ¨Åciently 101 8. Performance Screening Using Functional Path RO implements collinearity in the multiple linear regression context [119]. The Principal Component Regression fPCRcombines the PCA and linear regression tech- niques [120]. The PCA transforms the given feature set into a new, reduced one. The dimensionality of the new feature set is determined in the PCR settings of the algorithm. The resulting new feature set is then passed to a linear regression algorithm. Furthermore, the Random Forest Regression fRFris an extension for the Random forest classiÔ¨Åer. The RFR deals with numerical values and deploys averaging and multiple decision trees to serve as a regression model [115]. Such an algorithm is different from the two models proposed before - which are based on a linear least square approach - the RFR is a tree-based approach. Scoring metrics for Regression: The regression models have slightly different scoring metrics compared with the classiÔ¨Åcation approach. The two widely used metrics are the mean absolute error (MAE) and the root mean square error (RMSE), calculated as follows [92]: MAE =√•n"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_226", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 226, "text": "erent scoring metrics compared with the classiÔ¨Åcation approach. The two widely used metrics are the mean absolute error (MAE) and the root mean square error (RMSE), calculated as follows [92]: MAE =√•njÀÜy\u0000yj N RMSE =r √•n(ÀÜy\u0000y)2 N,(8.3) where N is the number of devices in the test set T. The RMSE is less sensitive to a few outliers but is a more sensitive error metric than the MAE [92]. In order to compare the error metric across the different test cases and to previous research, the metrics are normalized as follows: nMAE =MAE mean (y) nRMSE =RMSE mean (y).(8.4) The above error metrics may not correctly reÔ¨Çect the prediction accuracy of the regression model in some cases, so an additional metric is used: the coefÔ¨Åcient of determination, also known as the R2score [121]. R2=1\u0000√•n(y\u0000ÀÜy)2 √•n(y\u0000mean (y))2(8.5) The regression model makes a good prediction if the R2score is between 0 and 1. In such cases, the R2score can also be considered identical to the percentage of correctness obtained by the regression [121]. As a result, the scoring metrics are used to evaluate the regression models and the prediction 102 8. Performance Screening Using Functional Path RO accuracy using the labeled da"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_227", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 227, "text": "the regression [121]. As a result, the scoring metrics are used to evaluate the regression models and the prediction 102 8. Performance Screening Using Functional Path RO accuracy using the labeled data set Xwith the different feature sets - the functional path ROs and the SMONs. The resulting prediction value ÀÜyjis then compared with the target frequency value FTH. IfÀÜyj\u0015FTH, the device is pass; otherwise, the device is fail. However, to ensure automotive quality (see Section 2.7), a guardband is needed for the performance screening with the regression approach. Guardband for Regression to ensure automotive Quality: The guardband was introduced in [24] and denoted as guardband G. The guardband intends to ensure automotive quality by considering the accuracy of the trained regression model. In other words, the guardband is the value by which the target frequency must be increased to ensure that no more than a certain false positives are in production. The guardband is calculated with the residual error ( e=ÀÜyj\u0000yj) considering the test set T, with yjbeing the measurements and ÀÜyjbeing the predicted values. The resulting distribution of the residual error is assumed to be approximate"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_228", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 228, "text": "he residual error ( e=ÀÜyj\u0000yj) considering the test set T, with yjbeing the measurements and ÀÜyjbeing the predicted values. The resulting distribution of the residual error is assumed to be approximately Gaussian distributed, and the mean( me) and standard deviation ( se) are computed. The guardband is considering the six-sigma approach and is deÔ¨Åned as: G=me+6se (8.6) Gis reported in the experiments as a percentage of the target threshold frequency FTH. Involving the inverse normal distribution, it can be seen that the calculated guardband corresponds with a defective level of below 0.001 ppm . For example, to reach a defect level of 0.1 ppm , a5.2sein Equation 8.6 is required. Nevertheless, the calculated guardband is valid on the utilized test set; deploying Gfor the production screening requires statistical methods like bootstrapping to have conÔ¨Ådence. However, no such methods are used in this work, and Equation 8.6 is utilized for the calculation. The screening frequency in automotive quality grade FSCREEN is calculated with FSCREEN =FTH+G. (8.7) Such screening frequency ensures that the screening quality is following the six-sigma approach. Equation 8.7 suggests that the model"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_229", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 229, "text": "ive quality grade FSCREEN is calculated with FSCREEN =FTH+G. (8.7) Such screening frequency ensures that the screening quality is following the six-sigma approach. Equation 8.7 suggests that the model‚Äôs accuracy impacts the later screening frequency since G is one crucial part. The target is to reduce this guardband by a very accurate performance screening as much as possible - either using the functional path ROs or the SMONs. As shown in Figure 8.5, the previously explained training and evaluation steps are per- formed on the labeled devices. Once the trained model is accomplished, it is used on unlabeled devices U, as they will also occur in later production. 103 8. Performance Screening Using Functional Path RO 8.4. Deploy the Performance Screening The RO frequencies xjof the unlabeled devices Uare provided to the trained model (classiÔ¨Åcation-based or regression-based). The trained model provides a pass/fail deci- sion for the classiÔ¨Åcation-based approach for each device. The regression model provides a numerical frequency, and the pass/fail decision is then made on the FTH- or for automo- tive grade screening on FSCREEN . This approach makes the extensive FMAX characterization"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_230", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 230, "text": "ssion model provides a numerical frequency, and the pass/fail decision is then made on the FTH- or for automo- tive grade screening on FSCREEN . This approach makes the extensive FMAX characterization obsolete, since only the RO frequencies are used. Error metrics like those proposed for the training are not usable for unlabeled devices, since the device has no reference label ( FMAX ). The metric used for unlabeled devices is yield . The yield is calculated with yield =Total number o f non \u0000de f ective devices Total number o f manu f actured devices. (8.8) The yield describes the ratio between the non-defective devices and the total number of manufactured devices. The goal is to have a product with a yield close to 100 % . The yield is, therefore, a measure of the entire manufacturing process. In this work, however, only the yield attributable to performance screening is reported. Thus, the non-defective devices in Equation 8.8 are those devices that pass the performance screening. 8.5. Results of the Performance Screening This section reports the performance screening results using the classiÔ¨Åcation and regression approaches. Both approaches are performed using the functional pat"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_231", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 231, "text": "5. Results of the Performance Screening This section reports the performance screening results using the classiÔ¨Åcation and regression approaches. Both approaches are performed using the functional path ROs versus the SMONs. The key objective is to analyse how well the implemented functional path ROs perform using them as performance monitors. The large automotive MCU proposed in Part I is manufactured using a 28 nm CMOS technology. The MCU contains 22functional path ROs and an SMON module (Section 1.2.1) containing 27SMONs. This section‚Äôs results slightly deviate from those published in [42] and [49] due to a larger and more mature data set in this work. This section is divided into four parts: \u000fSection 8.5.1: The data set that is used for the analysis. \u000fSection 8.5.2: Results of performance screening using the classiÔ¨Åcation approach. \u000fSection 8.5.3: Results of performance screening using the regression approach. \u000fSection 8.5.4: The applied performance screening on unlabeled data. 104 8. Performance Screening Using Functional Path RO 8.5.1. The data set The data set used for the results consists of the labeled data set Xand unlabeled data set U. Xconsists of 1923 golden devices whi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_232", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 232, "text": "8. Performance Screening Using Functional Path RO 8.5.1. The data set The data set used for the results consists of the labeled data set Xand unlabeled data set U. Xconsists of 1923 golden devices which are derived from different wafers. Such wafers come from multiple corner lots. Thus a large process variety is covered. All golden devices Xundergo the production test Ô¨Çow shown in Figure 8.1 until the Ô¨Ånal test. Afterwards, the devices are passed to the FMAX characterization. In each device, 10SLT test cases ( T0\u0000T9) are performed, and their maximum achievable clock frequency FmaxTiis stored. All Fmaxvalues are normalized in this work so that the design‚Äôs target frequency Fmax equals 100 % . All SLTs are performed with the worst-case voltage Vcritand temperature Tcrit conditions. The results of the T0 to T9 are shown in Figure 8.6. T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SLT9095100105110115120Frequency (%) Figure 8.6.: Violin plot of the 10 SLT test cases of the FMAX characterization. The violin plot shows that all SLTs are in the same frequency region. However, T0and T8 are performing slightly worse than the other SLTs. Thus T0and T8are deÔ¨Åned as the most critical test cases. The data is al"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_233", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 233, "text": " plot shows that all SLTs are in the same frequency region. However, T0and T8 are performing slightly worse than the other SLTs. Thus T0and T8are deÔ¨Åned as the most critical test cases. The data is already outlier Ô¨Åltered in Figure 8.6; thus, the SLT test case might have fewer devices as initially passed through the test. The number of devices in the different test cases after Ô¨Åltering is shown in Table 8.2. Table 8.2.: Number of devices after the Ô¨Åltering in the SLT. SLT T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 Devices 1824 1817 1738 1686 1796 1737 1779 1782 1809 1814 In order to evaluate the relation between the SLTs and the ROs, the Pearson correlation 105 8. Performance Screening Using Functional Path RO coefÔ¨Åcient (PCC) is calculated for all SLTs with the 22functional path ROs to see the 1- to-1 correlation between the features and labels as well as the labels and features among themselves. The results are shown in Figure 8.7. T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO21T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO210.8 0.8"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_234", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 234, "text": " RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO21T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO210.8 0.80.97 0.81 0.97 0.98 0.97 0.85 0.86 0.87 0.81 0.95 0.95 0.95 0.86 0.81 0.97 0.99 0.98 0.86 0.96 0.81 0.97 0.98 0.99 0.86 0.96 0.98 0.98 0.78 0.78 0.79 0.95 0.79 0.79 0.79 0.79 0.97 0.98 0.97 0.84 0.95 0.98 0.97 0.76 0.92 0.76 0.76 0.77 0.89 0.77 0.77 0.77 0.90.74 0.88 0.66 0.66 0.67 0.84 0.66 0.67 0.67 0.86 0.64 0.91 0.87 0.8 0.8 0.80.86 0.81 0.82 0.80.85 0.79 0.94 0.85 0.89 0.78 0.78 0.78 0.88 0.79 0.79 0.78 0.87 0.76 0.95 0.91 0.97 0.89 0.69 0.69 0.69 0.86 0.69 0.69 0.70.87 0.67 0.95 0.93 0.88 0.92 0.76 0.68 0.69 0.67 0.75 0.68 0.70.69 0.75 0.68 0.82 0.76 0.85 0.86 0.77 0.90.69 0.7 0.70.87 0.70.71 0.70.88 0.68 0.93 0.95 0.88 0.93 0.94 0.8 0.83 0.77 0.78 0.77 0.82 0.78 0.79 0.78 0.81 0.76 0.89 0.83 0.96 0.96 0.83 0.87 0.87 0.89 0.74 0.73 0.73 0.86 0.75 0.74 0.74 0.87 0.71 0.96 0.86 0.92 0.92 0.93 0.77 0.88 0.85 0.90.77 0.77 0.77 0.88 0.78 0.79 0.78 0.88 0.76 0.95 0.91 0.96 0.98 0.92 0.86 0.94 0.95 0.92 0.70.69 0.68 0.67 0.69 0.69 0.69 0.69 0.69 0.67 0.80.61 0.85 0.77 0.71 0.67 0.62 0.7"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_235", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 235, "text": "92 0.93 0.77 0.88 0.85 0.90.77 0.77 0.77 0.88 0.78 0.79 0.78 0.88 0.76 0.95 0.91 0.96 0.98 0.92 0.86 0.94 0.95 0.92 0.70.69 0.68 0.67 0.69 0.69 0.69 0.69 0.69 0.67 0.80.61 0.85 0.77 0.71 0.67 0.62 0.76 0.88 0.76 0.78 0.68 0.67 0.67 0.76 0.68 0.67 0.68 0.77 0.65 0.87 0.72 0.85 0.81 0.83 0.66 0.73 0.74 0.95 0.80.95 0.88 0.71 0.72 0.72 0.85 0.71 0.72 0.72 0.86 0.70.91 0.92 0.87 0.92 0.90.81 0.94 0.87 0.85 0.93 0.61 0.69 0.85 0.75 0.76 0.75 0.84 0.76 0.77 0.76 0.83 0.74 0.91 0.87 0.94 0.96 0.87 0.86 0.91 0.97 0.86 0.97 0.71 0.73 0.91 0.89 0.75 0.75 0.75 0.87 0.76 0.76 0.76 0.87 0.74 0.94 0.91 0.94 0.97 0.91 0.84 0.94 0.95 0.89 0.98 0.71 0.76 0.94 0.97 0.84 0.76 0.77 0.76 0.84 0.76 0.79 0.77 0.83 0.76 0.87 0.84 0.91 0.93 0.81 0.85 0.87 0.94 0.79 0.93 0.65 0.65 0.88 0.94 0.93 0.91 0.66 0.66 0.67 0.86 0.67 0.67 0.67 0.88 0.64 0.94 0.94 0.86 0.91 0.94 0.76 0.95 0.83 0.90.92 0.66 0.77 0.91 0.87 0.92 0.86 0.90.68 0.68 0.69 0.87 0.68 0.69 0.69 0.88 0.66 0.92 0.94 0.86 0.91 0.92 0.78 0.95 0.85 0.85 0.92 0.6 0.70.93 0.89 0.93 0.89 0.96 0.91 0.76 0.76 0.76 0.88 0.77 0.78 0.76 0.89 0.75 0.95 0.90.96 0.96 0.91 0.84 0.93 0.94 0.92 0.97 0.77 0.81 0.91 0.94 0.96 0.94 0.94 0.94 0.87 0.78 0.78 0.78 0.8"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_236", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 236, "text": "5 0.92 0.6 0.70.93 0.89 0.93 0.89 0.96 0.91 0.76 0.76 0.76 0.88 0.77 0.78 0.76 0.89 0.75 0.95 0.90.96 0.96 0.91 0.84 0.93 0.94 0.92 0.97 0.77 0.81 0.91 0.94 0.96 0.94 0.94 0.94 0.87 0.78 0.78 0.78 0.86 0.79 0.80.78 0.85 0.77 0.91 0.84 0.95 0.94 0.86 0.83 0.87 0.94 0.90.94 0.80.81 0.86 0.93 0.93 0.92 0.88 0.88 0.96 0.89 0.68 0.68 0.69 0.85 0.68 0.69 0.69 0.86 0.67 0.89 0.92 0.82 0.89 0.90.73 0.94 0.81 0.82 0.89 0.55 0.67 0.91 0.86 0.90.86 0.94 0.95 0.90.84 0.85 0.78 0.78 0.78 0.85 0.79 0.80.79 0.84 0.77 0.90.83 0.96 0.95 0.84 0.86 0.87 0.97 0.86 0.95 0.76 0.75 0.87 0.95 0.94 0.96 0.87 0.88 0.96 0.96 0.85 0.600.650.700.750.800.850.900.95 Figure 8.7.: Correlation heatmap between functional path ROs and SLTs. The labels among themself are presenting a high correlation (upper left section in Figure 8.7). The correlation heatmap shows two signiÔ¨Åcant subgroups within the SLTs with a very high correlation. T0,T4, and T8belong to one subgroup; the remaining SLTs belong to the other subgroup. The correlation of the functional path ROs varies more. Especially RO10and RO11 show a different behavior than the other ROs. The correlation of the functional path ROs concerning the SLT is the most cr"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_237", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 237, "text": "e correlation of the functional path ROs varies more. Especially RO10and RO11 show a different behavior than the other ROs. The correlation of the functional path ROs concerning the SLT is the most critical metric. In order to obtain and create a high-quality ML model, the ROs must correlate as well as possible with the SLTs. Especially RO0and T0show a PCC of more than 92 %. Figure 8.8 presents the correlation heatmap of the SMONs concerning the SLTs. The SMONs also achieve a PCC in the range of 91 % by looking at T0. The overall correlation of the SMONs with the SLTs is lower than the results with the functional path ROs. Some SMONs share the same structure seen in their high correlation between themselves (e.g., SMON 19to SMON 24). The minimum, median, and maximum PCCs are determined from Figure 8.7 and Figure 8.8 and shown in Table 8.3. 106 8. Performance Screening Using Functional Path RO T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SMON0 SMON1 SMON2 SMON3 SMON4 SMON5 SMON6 SMON7 SMON8 SMON9 SMON10 SMON11 SMON12 SMON13 SMON14 SMON15 SMON16 SMON17 SMON18 SMON19 SMON20 SMON21 SMON22 SMON23 SMON24 SMON25 SMON26T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SMON0 SMON1 SMON2 SMON3 SMON4 SMON5 SMON6 SMON7 SMON8 SM"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_238", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 238, "text": "10 SMON11 SMON12 SMON13 SMON14 SMON15 SMON16 SMON17 SMON18 SMON19 SMON20 SMON21 SMON22 SMON23 SMON24 SMON25 SMON26T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SMON0 SMON1 SMON2 SMON3 SMON4 SMON5 SMON6 SMON7 SMON8 SMON9 SMON10 SMON11 SMON12 SMON13 SMON14 SMON15 SMON16 SMON17 SMON18 SMON19 SMON20 SMON21 SMON22 SMON23 SMON24 SMON25 SMON260.8 0.80.97 0.81 0.97 0.98 0.97 0.85 0.86 0.87 0.81 0.95 0.95 0.95 0.86 0.81 0.97 0.99 0.98 0.86 0.96 0.81 0.97 0.98 0.99 0.86 0.96 0.98 0.98 0.78 0.78 0.79 0.95 0.79 0.79 0.79 0.79 0.97 0.98 0.97 0.84 0.95 0.98 0.97 0.76 0.90.77 0.77 0.77 0.88 0.77 0.78 0.77 0.88 0.76 0.70.74 0.74 0.73 0.71 0.73 0.77 0.74 0.69 0.73 0.85 0.89 0.62 0.61 0.62 0.84 0.62 0.62 0.62 0.87 0.59 0.92 0.66 0.91 0.67 0.67 0.68 0.87 0.68 0.68 0.68 0.89 0.65 0.93 0.66 0.98 0.64 0.69 0.69 0.66 0.66 0.68 0.72 0.69 0.63 0.68 0.79 0.97 0.61 0.6 0.65 0.72 0.72 0.70.67 0.71 0.75 0.72 0.65 0.72 0.78 0.96 0.60.59 0.98 0.67 0.73 0.73 0.71 0.69 0.72 0.76 0.73 0.66 0.72 0.81 0.98 0.63 0.62 0.99 0.98 0.68 0.75 0.76 0.74 0.71 0.75 0.78 0.76 0.68 0.75 0.82 0.98 0.63 0.64 0.98 0.97 0.99 0.69 0.78 0.78 0.76 0.71 0.77 0.81 0.78 0.68 0.78 0.81 0.96 0.61 0.62 0.95 0.98 0.97 0.97 0.67 0.72 0.72 0.70.68 0.71 0.75 0."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_239", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 239, "text": "0.76 0.74 0.71 0.75 0.78 0.76 0.68 0.75 0.82 0.98 0.63 0.64 0.98 0.97 0.99 0.69 0.78 0.78 0.76 0.71 0.77 0.81 0.78 0.68 0.78 0.81 0.96 0.61 0.62 0.95 0.98 0.97 0.97 0.67 0.72 0.72 0.70.68 0.71 0.75 0.72 0.66 0.72 0.83 0.97 0.63 0.63 0.95 0.96 0.96 0.96 0.96 0.64 0.69 0.69 0.67 0.66 0.68 0.72 0.69 0.63 0.68 0.79 0.98 0.61 0.59 0.99 0.98 0.99 0.98 0.96 0.95 0.64 0.69 0.69 0.68 0.66 0.69 0.72 0.70.64 0.68 0.80.98 0.62 0.60.98 0.97 0.98 0.97 0.95 0.95 0.98 0.63 0.68 0.68 0.66 0.66 0.67 0.72 0.69 0.63 0.68 0.78 0.96 0.60.58 0.98 0.97 0.98 0.97 0.95 0.94 0.98 0.95 0.67 0.73 0.73 0.71 0.69 0.72 0.76 0.73 0.66 0.72 0.81 0.98 0.63 0.62 0.99 0.98 10.99 0.97 0.96 0.99 0.98 0.97 0.67 0.73 0.73 0.71 0.69 0.72 0.76 0.73 0.66 0.72 0.82 0.98 0.63 0.63 0.97 0.96 0.98 0.98 0.96 0.96 0.97 0.99 0.94 0.98 0.66 0.71 0.72 0.69 0.69 0.71 0.75 0.72 0.66 0.71 0.80.96 0.62 0.61 0.97 0.97 0.98 0.97 0.96 0.95 0.97 0.95 0.99 0.98 0.95 0.69 0.76 0.76 0.75 0.71 0.76 0.79 0.76 0.68 0.76 0.82 0.98 0.63 0.63 0.98 0.97 0.99 0.99 0.98 0.96 0.98 0.97 0.96 0.99 0.98 0.97 0.69 0.76 0.77 0.75 0.71 0.76 0.79 0.76 0.68 0.76 0.83 0.98 0.63 0.64 0.96 0.96 0.98 0.98 0.96 0.96 0.96 0.98 0.93 0.98 0.99 0.94 0.98 0.68 0.74 0.74 0"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_240", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 240, "text": ".99 0.99 0.98 0.96 0.98 0.97 0.96 0.99 0.98 0.97 0.69 0.76 0.77 0.75 0.71 0.76 0.79 0.76 0.68 0.76 0.83 0.98 0.63 0.64 0.96 0.96 0.98 0.98 0.96 0.96 0.96 0.98 0.93 0.98 0.99 0.94 0.98 0.68 0.74 0.74 0.72 0.70.73 0.77 0.74 0.67 0.74 0.81 0.96 0.62 0.62 0.97 0.96 0.98 0.98 0.96 0.95 0.97 0.94 0.98 0.98 0.94 0.99 0.98 0.94 0.89 0.62 0.62 0.63 0.84 0.63 0.62 0.63 0.87 0.60.92 0.66 0.99 0.98 0.61 0.61 0.63 0.63 0.62 0.63 0.61 0.62 0.60.63 0.63 0.62 0.63 0.63 0.62 0.87 0.61 0.61 0.61 0.82 0.62 0.61 0.62 0.85 0.58 0.91 0.65 0.98 0.96 0.59 0.59 0.61 0.61 0.60.62 0.59 0.62 0.56 0.61 0.64 0.58 0.61 0.64 0.58 0.98 0.88 0.60.59 0.60.83 0.6 0.6 0.60.86 0.58 0.90.62 0.97 0.95 0.58 0.58 0.6 0.60.59 0.60.58 0.57 0.60.59 0.57 0.62 0.60.58 0.63 0.97 0.92 0.91 0.68 0.67 0.68 0.87 0.68 0.68 0.68 0.89 0.65 0.93 0.66 0.98 0.99 0.60.59 0.62 0.64 0.62 0.63 0.59 0.60.58 0.62 0.63 0.60.63 0.64 0.62 0.98 0.96 0.95 0.89 0.66 0.66 0.67 0.85 0.67 0.66 0.67 0.87 0.64 0.92 0.64 0.96 0.97 0.56 0.57 0.60.61 0.60.62 0.57 0.60.53 0.60.63 0.56 0.61 0.64 0.57 0.96 0.98 0.91 0.98 0.89 0.63 0.63 0.64 0.85 0.64 0.64 0.64 0.87 0.62 0.91 0.62 0.96 0.97 0.57 0.57 0.59 0.60.59 0.60.57 0.55 0.58 0.59 0.57 0.61 0.60.58 0.62 0.9"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_241", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 241, "text": "7 0.60.53 0.60.63 0.56 0.61 0.64 0.57 0.96 0.98 0.91 0.98 0.89 0.63 0.63 0.64 0.85 0.64 0.64 0.64 0.87 0.62 0.91 0.62 0.96 0.97 0.57 0.57 0.59 0.60.59 0.60.57 0.55 0.58 0.59 0.57 0.61 0.60.58 0.62 0.96 0.92 0.98 0.97 0.92 0.66 0.72 0.72 0.70.68 0.71 0.75 0.72 0.66 0.72 0.81 0.99 0.62 0.61 0.98 0.97 0.99 0.99 0.96 0.96 0.99 0.98 0.97 0.99 0.98 0.97 0.99 0.98 0.96 0.62 0.61 0.58 0.61 0.60.58 0.91 0.76 0.76 0.76 0.89 0.77 0.78 0.77 0.89 0.75 0.98 0.84 0.94 0.95 0.79 0.78 0.81 0.82 0.81 0.81 0.79 0.79 0.78 0.81 0.81 0.80.82 0.82 0.81 0.94 0.92 0.92 0.94 0.92 0.92 0.81 0.60.70.80.9 Figure 8.8.: Correlation heatmap between the SMONs and SLTs. Table 8.3.: PCC comparison between functional path ROs and SMONs. Labelfunctional path ROs SMONs Min Median Max Min Median Max T0 70.0% 88.3% 92.0% 63.4% 68.5% 91.1% T1 65.6% 74.4% 80.4% 59.5% 71.8% 77.9% T2 65.7% 74.0% 80.0% 59.4% 72.0% 77.9% T3 66.5% 74.3% 79.9% 59.6% 69.9% 77.0% T4 69.4% 85.7% 89.5% 65.6% 70.6% 89.0% T5 66.2% 75.1% 81.2% 60.3% 71.0% 77.3% T6 66.6% 75.0% 81.6% 60.2% 75.0% 80.7% T7 66.6% 74.6% 80.4% 60.1% 71.9% 78.0% T8 69.4% 85.9% 89.9% 63.0% 78.2% 89.1% T9 63.8% 72.4% 78.7% 57.5% 71.6% 77.8% The minimum, median and maximum PCCs o"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_242", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 242, "text": "77.3% T6 66.6% 75.0% 81.6% 60.2% 75.0% 80.7% T7 66.6% 74.6% 80.4% 60.1% 71.9% 78.0% T8 69.4% 85.9% 89.9% 63.0% 78.2% 89.1% T9 63.8% 72.4% 78.7% 57.5% 71.6% 77.8% The minimum, median and maximum PCCs of the functional path ROs are higher in all SLT than the SMONs. The functional path ROs exceed the SMONs if only the PCC is considered. 107 8. Performance Screening Using Functional Path RO 8.5.2. ClassiÔ¨Åcation-based Performance Screening The classiÔ¨Åcation-based performance screening is trained with the labeled data set Xusing a dedicated frequency FTH. The FTHis normalized to 100 % . The classiÔ¨Åcation model is trained with the functional path ROs as features and the SMONs as features, respectively. For each SLT test case, a separate model is trained and evaluated. The results using the functional path ROs are presented in Table 8.4. Table 8.4.: Results of the classiÔ¨Åcation-based ML models using functional path ROs. LabelLogistic Reg. Random Forest TP TN FP FN ACC MCC TP TN FP FN ACC MCC T0 336 50 47 23 84.65% 0.50 342 80 17 17 92.54% 0.78 T1 435 2 14 4 96.04% 0.19 438 5 11 1 97.36% 0.50 T2 420 5 9 1 97.70% 0.53 419 5 9 2 97.47% 0.49 T3 402 4 12 4 96.21% 0.34 405 4 12 1 96.92% 0.44 T4 "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_243", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 243, "text": "0 336 50 47 23 84.65% 0.50 342 80 17 17 92.54% 0.78 T1 435 2 14 4 96.04% 0.19 438 5 11 1 97.36% 0.50 T2 420 5 9 1 97.70% 0.53 419 5 9 2 97.47% 0.49 T3 402 4 12 4 96.21% 0.34 405 4 12 1 96.92% 0.44 T4 376 24 36 13 89.09% 0.45 380 41 19 9 93.76% 0.71 T5 412 3 18 2 95.40% 0.28 411 10 11 3 96.78% 0.59 T6 430 1 14 0 96.85% 0.25 427 4 11 3 96.85% 0.38 T7 420 2 21 3 94.62% 0.17 421 4 19 2 95.29% 0.32 T8 361 35 44 13 87.42% 0.50 362 61 18 12 93.38% 0.76 T9 436 2 13 3 96.48% 0.22 435 2 13 4 96.26% 0.19 The calculated accuracy in the SLT cases ranges between 84.65 % and 97.70 % deploying the logistic regression and between 92.54 % and 97.47 % for the random forest. The accuracy inT0,T4, and T8 is signiÔ¨Åcantly lower than in the other SLTs. The MCC also has a substantial deviation. However, the random forest model has a higher MCC score than the logistic regression, which also applies to the comparison of the accuracy of the two models. Therefore, the random forest is the preferable model in nearly all SLTs. The results using the SMONs as features are presented in Table 8.5. There is no signiÔ¨Åcant difference compared with the functional path ROs. In some test cases, the SMONs perform better; i"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_244", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 244, "text": "y all SLTs. The results using the SMONs as features are presented in Table 8.5. There is no signiÔ¨Åcant difference compared with the functional path ROs. In some test cases, the SMONs perform better; in other test cases, the functional path ROs are better. Therefore a third run uses the combined features set (functional path ROs and SMONs). The results are shown in Table 8.6. Also, in this case, the accuracy and MCC depend on the SLT. There is a slight beneÔ¨Åt, e.g., inT0, with respect to both scoring metrics. The MCC overall shows slightly higher results in the combined data set. The functional path ROs and the SMONs provide good accuracy in the performance screening using the classiÔ¨Åcation-based approach. The classiÔ¨Åcation-based screening provides a satisfactory result to get a Ô¨Årst estimation of the accuracy achieved in the performance 108 8. Performance Screening Using Functional Path RO Table 8.5.: Results of the classiÔ¨Åcation-based ML models using SMONs. LabelLogistic Reg. Random Forest TP TN FP FN ACC MCC TP TN FP FN ACC MCC T0 330 62 35 29 85.96% 0.57 338 78 19 21 91.23% 0.74 T1 434 5 11 5 96.48% 0.37 436 7 9 3 97.36% 0.54 T2 418 2 12 3 96.55% 0.22 419 2 12 2 96.78% 0.25 T3 4"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_245", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 245, "text": "orest TP TN FP FN ACC MCC TP TN FP FN ACC MCC T0 330 62 35 29 85.96% 0.57 338 78 19 21 91.23% 0.74 T1 434 5 11 5 96.48% 0.37 436 7 9 3 97.36% 0.54 T2 418 2 12 3 96.55% 0.22 419 2 12 2 96.78% 0.25 T3 403 1 15 3 95.73% 0.11 404 6 10 2 97.16% 0.52 T4 363 31 29 26 87.75% 0.46 380 44 16 9 94.43% 0.75 T5 408 8 13 6 95.63% 0.45 412 11 10 2 97.24% 0.65 T6 427 7 8 3 97.53% 0.56 427 9 6 3 97.98% 0.66 T7 421 5 18 2 95.52% 0.38 421 3 20 2 95.07% 0.26 T8 362 64 15 12 91.39% 0.68 362 64 15 12 94.04% 0.79 T9 436 6 9 3 97.36% 0.50 436 5 10 3 97.14% 0.44 Table 8.6.: Results of the classiÔ¨Åcation-based ML models using the combined data set. LabelLogistic Reg. Random Forest TP TN FP FN ACC MCC TP TN FP FN ACC MCC T0 334 72 25 25 89.04% 0.67 340 81 16 19 92.23% 0.77 T1 436 5 11 3 96.92% 0.42 438 7 9 1 97.80% 0.61 T2 415 3 11 6 96.09% 0.25 420 3 11 1 97.24% 0.39 T3 400 4 12 6 95.73% 0.30 406 5 11 0 97.39% 0.55 T4 361 38 22 28 88.86% 0.54 378 41 19 11 93.32% 0.70 T5 409 8 13 5 95.86% 0.46 413 11 10 1 97.47% 0.68 T6 429 5 10 1 97.53% 0.52 428 7 8 2 97.75% 0.59 T7 420 6 17 3 95.52% 0.40 422 5 18 1 95.74% 0.41 T8 363 56 23 11 92.49% 0.73 365 64 15 9 94.70% 0.81 T9 433 5 10 6 96.48% 0.37 436 3 12 3 96.70% 0."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_246", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 246, "text": "0.68 T6 429 5 10 1 97.53% 0.52 428 7 8 2 97.75% 0.59 T7 420 6 17 3 95.52% 0.40 422 5 18 1 95.74% 0.41 T8 363 56 23 11 92.49% 0.73 365 64 15 9 94.70% 0.81 T9 433 5 10 6 96.48% 0.37 436 3 12 3 96.70% 0.30 screening. The classiÔ¨Åcation-based accuracy of the approach is also strongly dependent on the SLT used. 8.5.3. Regression-based Performance Screening The regression-based performance screening is utilized for the labeled data set X. In contrast to the classiÔ¨Åcation-based approach, the regression model provides a numerical performance value which is the precise performance value of the SLTs. Three different ML models are separately trained on the data set. A scatter plot shows the predicted performance value vs. the measured performance value from the labeled devices. The scatter plot using the functional path ROs as features and the RidgeCV regression is shown in Figure 8.9 employing 109 8. Performance Screening Using Functional Path RO SLT T0. 95 100 105 110 115 Measured Frequency in %95100105110Predicted Frequency in %Training Test Pred. = Meas. Figure 8.9.: Measured vs. predicted performance for T0. The solid line within the scatter plot represents the ideal line where the model‚Äô"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_247", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 247, "text": "95100105110Predicted Frequency in %Training Test Pred. = Meas. Figure 8.9.: Measured vs. predicted performance for T0. The solid line within the scatter plot represents the ideal line where the model‚Äôs predicted frequency equals the FMAX characterization‚Äôs measured frequency. Each dot represents one device in the scatter plot; the red devices belong to the training set S, and the blue to the validation set T. The nRMSE of this scatter plot is 1.68 %. The results of the different ML models using the functional path ROs and the SMONs are presented in Table 8.7 and Table 8.8. Table 8.7.: Prediction accuracy on the functional path ROs. LabelRidgeCV PCA Reg. Rand. For. nMAE nRMSE R2G nMAE nRMSE R2G nMAE nRMSE R2G T0 1.34% 1.68% 85.3% 10.5% 1.42% 1.80% 82.9% 11.3% 1.36% 1.71% 84.7% 10.8% T1 1.66% 2.04% 64.7% 13.0% 1.67% 2.06% 64.9% 12.9% 1.71% 2.15% 61.6% 13.6% T2 1.63% 2.03% 66.9% 13.0% 1.68% 2.08% 65.7% 13.3% 1.80% 2.22% 61.1% 14.2% T3 1.65% 2.09% 68.0% 13.5% 1.67% 2.12% 67.7% 13.5% 1.79% 2.26% 63.3% 14.3% T4 1.41% 1.77% 78.7% 11.2% 1.45% 1.83% 77.2% 11.6% 1.44% 1.77% 78.4% 11.1% T5 1.50% 1.87% 67.9% 12.0% 1.55% 1.95% 65.6% 12.2% 1.60% 2.01% 63.4% 12.6% T6 1.61% 2.00% 67.6% 12.8% 1.63%"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_248", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 248, "text": "2.26% 63.3% 14.3% T4 1.41% 1.77% 78.7% 11.2% 1.45% 1.83% 77.2% 11.6% 1.44% 1.77% 78.4% 11.1% T5 1.50% 1.87% 67.9% 12.0% 1.55% 1.95% 65.6% 12.2% 1.60% 2.01% 63.4% 12.6% T6 1.61% 2.00% 67.6% 12.8% 1.63% 2.04% 67.0% 13.0% 1.68% 2.12% 64.2% 13.5% T7 1.55% 1.97% 65.5% 12.7% 1.62% 2.06% 63.1% 12.9% 1.74% 2.20% 58.5% 13.5% T8 1.34% 1.68% 85.4% 10.7% 1.34% 1.69% 85.3% 10.7% 1.34% 1.69% 85.3% 10.4% T9 1.66% 2.06% 66.2% 13.2% 1.73% 2.12% 64.4% 13.6% 1.78% 2.19% 62.3% 13.8% Regression models for both feature sets provide the lowest error in T0,T4,and T8; in such SLTs, the classiÔ¨Åcation approaches (see Section 8.5.2) performed worst. Comparing the results of the functional path ROs with the SMONs, it can be seen that the SMONs provide a lower 110 8. Performance Screening Using Functional Path RO Table 8.8.: Prediction accuracy on the SMONs. LabelRidgeCV PCA Reg. Rand. For. nMAE nRMSE R2G nMAE nRMSE R2G nMAE nRMSE R2G T0 1.32% 1.68% 85.4% 10.3% 1.41% 1.78% 83.4% 11.1% 1.38% 1.76% 83.9% 11.1% T1 1.32% 1.68% 76.0% 10.7% 1.36% 1.73% 74.9% 10.9% 1.53% 1.92% 69.5% 12.1% T2 1.44% 1.80% 74.0% 11.4% 1.46% 1.85% 72.6% 11.9% 1.63% 2.05% 66.6% 13.2% T3 1.39% 1.78% 76.7% 11.4% 1.44% 1.85% 75.3% 11.8% 1.69%"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_249", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 249, "text": "2% 1.68% 76.0% 10.7% 1.36% 1.73% 74.9% 10.9% 1.53% 1.92% 69.5% 12.1% T2 1.44% 1.80% 74.0% 11.4% 1.46% 1.85% 72.6% 11.9% 1.63% 2.05% 66.6% 13.2% T3 1.39% 1.78% 76.7% 11.4% 1.44% 1.85% 75.3% 11.8% 1.69% 2.15% 67.1% 13.6% T4 1.37% 1.73% 79.5% 10.9% 1.40% 1.76% 78.9% 11.1% 1.43% 1.79% 78.0% 11.3% T5 1.29% 1.61% 76.3% 10.0% 1.32% 1.65% 75.3% 10.3% 1.45% 1.81% 70.3% 11.5% T6 1.37% 1.71% 76.5% 10.9% 1.39% 1.74% 75.7% 11.1% 1.53% 1.94% 70.2% 12.3% T7 1.41% 1.75% 72.6% 11.2% 1.42% 1.76% 73.0% 11.0% 1.61% 2.06% 63.5% 12.8% T8 1.37% 1.69% 85.1% 10.7% 1.40% 1.71% 84.8% 10.9% 1.39% 1.73% 84.6% 10.7% T9 1.39% 1.71% 76.5% 10.9% 1.42% 1.76% 75.2% 11.4% 1.62% 1.99% 68.8% 12.7% error in nearly all SLTs. However, in SLT T8, the functional path ROs show a lower error. Also, a third run is performed with the combined data set in the regression-based screening. The results of the combined feature set are shown in Table 8.9. Table 8.9.: Prediction Accuracy on the Combined data set. LabelRidgeCV PCA Reg. Rand. For. nMAE nRMSE R2G nMAE nRMSE R2G nMAE nRMSE R2G T0 1.25% 1.58% 87.0% 9.7% 1.38% 1.74% 84.1% 10.9% 1.32% 1.67% 85.5% 10.6% T1 1.29% 1.63% 77.5% 10.4% 1.41% 1.77% 73.9% 11.1% 1.52% 1.93% 69.1% 12.1%"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_250", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 250, "text": ". For. nMAE nRMSE R2G nMAE nRMSE R2G nMAE nRMSE R2G T0 1.25% 1.58% 87.0% 9.7% 1.38% 1.74% 84.1% 10.9% 1.32% 1.67% 85.5% 10.6% T1 1.29% 1.63% 77.5% 10.4% 1.41% 1.77% 73.9% 11.1% 1.52% 1.93% 69.1% 12.1% T2 1.33% 1.68% 77.3% 10.7% 1.46% 1.84% 73.1% 11.8% 1.62% 2.03% 67.4% 13.0% T3 1.30% 1.68% 79.2% 10.8% 1.43% 1.85% 75.5% 11.7% 1.65% 2.12% 67.9% 13.4% T4 1.28% 1.62% 82.1% 10.2% 1.39% 1.74% 79.3% 11.0% 1.39% 1.71% 79.8% 10.8% T5 1.21% 1.50% 79.3% 9.4% 1.34% 1.69% 74.1% 10.6% 1.47% 1.84% 69.4% 11.6% T6 1.25% 1.55% 80.6% 9.9% 1.40% 1.77% 75.1% 11.3% 1.47% 1.89% 71.7% 12.0% T7 1.31% 1.64% 76.1% 10.5% 1.40% 1.78% 72.4% 11.1% 1.55% 2.02% 65.0% 12.4% T8 1.27% 1.58% 87.0% 10.0% 1.30% 1.63% 86.3% 10.3% 1.34% 1.66% 85.9% 10.2% T9 1.27% 1.60% 79.6% 10.1% 1.46% 1.81% 74.1% 11.6% 1.59% 1.98% 69.2% 12.5% In all SLTs, the nMAE and nRMSE are lowered compared with the separate feature set. The regression models can utilize the beneÔ¨Åts of the functional path ROs and the SMONs to reduce the error further and minimize the screening guardband. The comparison of the screening guardband needed is presented in Figure 8.10. Also, the screening guardband can be reduced by using the combined features set in all"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_251", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 251, "text": "d minimize the screening guardband. The comparison of the screening guardband needed is presented in Figure 8.10. Also, the screening guardband can be reduced by using the combined features set in all SLTs. A characteristic of the random forest algorithm is the built-in feature importance ranking based on the mean decrease in impurity. That provides an overview of the features‚Äô im- portance in the trained ML model. In order to get an overview of the contributions and importance of the ROs, the cumulated mean decrease in impurity is calculated for all SLTs 111 8. Performance Screening Using Functional Path RO T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 SLT02468101214Guardband in %Screening Guardband Fpath SMONs Combined Figure 8.10.: Guardband comparison using the RidgeCV regression. and shown in Figure 8.11. The combined feature set from Table 8.9 is used in this analysis. RO0 RO1 RO2 RO3 RO4 RO5 RO6 RO7 RO8 RO9 RO10 RO11 RO12 RO13 RO14 RO15 RO16 RO17 RO18 RO19 RO20 RO21 SMON0 SMON1 SMON2 SMON3 SMON4 SMON5 SMON6 SMON7 SMON8 SMON9 SMON10 SMON11 SMON12 SMON13 SMON14 SMON15 SMON16 SMON17 SMON18 SMON19 SMON20 SMON21 SMON22 SMON23 SMON24 SMON25 SMON26 Cummulated Mean Decrease of Impurity0.00.51.01.52"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_252", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 252, "text": "4 SMON5 SMON6 SMON7 SMON8 SMON9 SMON10 SMON11 SMON12 SMON13 SMON14 SMON15 SMON16 SMON17 SMON18 SMON19 SMON20 SMON21 SMON22 SMON23 SMON24 SMON25 SMON26 Cummulated Mean Decrease of Impurity0.00.51.01.52.02.5T0 T1 T2 T3 T4 T5 T6 T7 T8 T9 Figure 8.11.: Cumulated RO importance. The cumulated mean decrease in impurity reveals that some dedicated ROs ( RO0,RO2, SMON 3, and SMON 8) have substantial importance in predicting some SLTs. The regression-based results suggest that the functional path ROs provide good perfor- mance screening results; however, the SMONs in most SLTs give a more satisfactory result. A reasonable performance screening can be made with both types of ROs, which meet the auto- motive quality requirements. Performance screening with the highest accuracy is achieved by combining the two sets of ROs. Thus, the functional path ROs are one central pillar in the performance screening Ô¨Çow. 112 8. Performance Screening Using Functional Path RO 8.5.4. Applied Performance Screening on unlabeled Data This section deploys the developed ML models using the regression-based approach to unlabeled data U. Then the yield is calculated based on the performance screening results. This an"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_253", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 253, "text": "on unlabeled Data This section deploys the developed ML models using the regression-based approach to unlabeled data U. Then the yield is calculated based on the performance screening results. This analysis is only done for the regression-based performance screening using the RidgeCV since the calculated guardband is investigated to achieve automotive quality. Each manufactured device is, by default, an unlabeled device since the RO measurements are part of the test program. However, the unlabeled devices are produced in the engineering phase, in which the process is less stable than in the later high-volume production. There- fore, this estimation and analysis do not represent the later production screening from the yield perspective. Also, FTHand the resulting FSCREEN are theoretically selected. In this experimental performance screening, six lots that have been manufactured under similar process conditions are selected. Thus, the selected devices have a Ô¨Årst approximation of natural process variation as found in later production. Ucontains 13 565 devices from the 6 production lots. The functional path RO frequencies of the unlabeled devices are then passed to the pre- trained ML"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_254", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 254, "text": " process variation as found in later production. Ucontains 13 565 devices from the 6 production lots. The functional path RO frequencies of the unlabeled devices are then passed to the pre- trained ML model, and the performance of each device is predicted. The results of using the functional path ROs and T0 are shown in Figure 8.12 for the RidgeCV algorithm. 90 95 100 105 110 115 120 125 130 FMAX in %050100150200250300350CountFTH FSCREEN Fpath FSCREEN SMONs FSCREEN Combined Figure 8.12.: Guardband comparison RidgeCV regression for T0. The dotted line is the deÔ¨Åned FTHfor which the performance screening is set. The colored vertical lines divide the resulting distribution into pass and fail. The different colors are the resulting FSCREEN for the different feature sets: the functional path ROs, the SMONs, and the combined feature set. All devices on the left side of this screening border are fail, and the pass devices are on the right. In particular, the screening frequency using the combined feature caused a signiÔ¨Åcant shift left of the border - since the prediction does have a higher accuracy. This can also be seen in the calculated performance yield. The performance-related yield i"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_255", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 255, "text": "ined feature caused a signiÔ¨Åcant shift left of the border - since the prediction does have a higher accuracy. This can also be seen in the calculated performance yield. The performance-related yield is 113 8. Performance Screening Using Functional Path RO calculated for the unlabeled devices in all SLTs. The FSCREEN is calculated using Equation 8.7, and the yield is calculated using Equation 8.8. The results are shown in Table 8.10. Table 8.10.: FSCREEN and yield estimation for performance screening. LabelFSCREEN Yield Yield Gain (Combined vs. SMONs) (Pct. Points)Fpath SMON Combined Fpath SMON Combined T0 110.5% 110.3% 109.7% 25.4% 26.0% 28.6% 2.6 T1 113.0% 110.7% 110.4% 20.4% 31.9% 34.4% 2.5 T2 113.0% 111.4% 110.7% 21.4% 31.1% 34.8% 3.7 T3 113.5% 111.4% 110.8% 20.0% 31.3% 34.7% 3.4 T4 111.2% 110.9% 110.2% 24.5% 26.2% 29.3% 3.1 T5 112.0% 110.0% 109.4% 24.3% 34.2% 37.6% 3.4 T6 112.8% 110.9% 109.9% 21.9% 33.2% 37.9% 4.7 T7 112.7% 111.2% 110.5% 19.5% 28.0% 32.7% 4.7 T8 110.7% 110.7% 110.0% 27.7% 27.7% 30.4% 2.7 T9 113.2% 110.9% 110.1% 19.2% 31.8% 36.1% 4.3 The ML model accuracy and the resulting FSCREEN are in the same range for T0,T4, and T8 using the functional path ROs and the SMON"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_256", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 256, "text": "% 27.7% 27.7% 30.4% 2.7 T9 113.2% 110.9% 110.1% 19.2% 31.8% 36.1% 4.3 The ML model accuracy and the resulting FSCREEN are in the same range for T0,T4, and T8 using the functional path ROs and the SMONs, as highlighted in the previous section. In the other SLTs, the SMONs provide a better prediction and, therefore, a lower FSCREEN , resulting in a higher yield. The right column in Table 8.10 shows the yield gain of the combined data set compared with the SMONs. Thus, the positive effect of the functional path ROs on the yield becomes evident here. For every SLT, a yield gain of 2.5up to 4.7percentage point is achieved by using the combined data set. Thus the functional path ROs act as a supporting structure to make the performance screening more accurate and help to increase the yield. 114 9. POST-SI Summary The Post-Silicon part presents the activities once the manufactured MCU contains the imple- mented functional path ROs. Chapter 7 presents how the functional path ROs are measured and validates the quality of the measurements. The results show that the functional path ROs are accurately measured with a high reproducibility on the ATE. Chapter 8 elaborates on using the functional"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_257", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 257, "text": "nd validates the quality of the measurements. The results show that the functional path ROs are accurately measured with a high reproducibility on the ATE. Chapter 8 elaborates on using the functional path RO as a performance monitor. The basics of performance screening and the data set needed for that are discussed. ML is used to determine the performance of an MCU based on indirect monitors such as functional path ROs. In particular, two approaches are presented: the classiÔ¨Åcation-based performance screening and the regression-based performance screening. For both approaches, the functional path ROs are used for performance screening, and in order to compare the functional path RO results with a benchmark, the SMON module is used in the same manner for performance screening. The combined dataset is used in the third use case, which means functional path RO and the SMON module. Also, several algorithms are used in the ML. The results of classiÔ¨Åcation-based performance screening show good accuracy in performance screening with all data sets used. In some test cases, the functional path ROs are better; in others, the SMONs. Whereas with the regression-based approach, the results cha"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_258", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 258, "text": "ood accuracy in performance screening with all data sets used. In some test cases, the functional path ROs are better; in others, the SMONs. Whereas with the regression-based approach, the results change. First of all, both structures (functional path ROs and SMONs) provide good accuracy in performance screening. However, the SMONs show slightly better results then the functional path ROs in most test cases. The signiÔ¨Åcant advantage is the combined data set. The combination of functional path ROs and SMONs in performance screening improved the accuracy of performance screening in all test cases, resulting in a lower screening guardband. The impact of the reduced screening guardband is evaluated on a more considerable amount of production data, and the resulting yield is shown. Using the functional path ROs as supporting monitors in the combined data set reduces the yield loss by 2.5up to 4.7percentage points. This indicates the signiÔ¨Åcant advantage of the functional path ROs as performance monitors especially by combining them with dedicated SMONs. However, it should be mentioned here that only 22functional path ROs were used in this analysis; the number of implemented ROs can be i"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_259", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 259, "text": "ance monitors especially by combining them with dedicated SMONs. However, it should be mentioned here that only 22functional path ROs were used in this analysis; the number of implemented ROs can be increased due to the scalable implementa- tion. 115 10. Conclusion 10.1. Summary of Key Contributions The automotive Microcontrollers (MCUs) have high-quality requirements. This is the reason for the extensive testing of such MCUs, and one crucial test is the performance screening. The performance screening is a challenging task and requires effort. A well-established and accurate methodology uses indirect performance monitors, namely the Ring oscillators (ROs). However, the accuracy of the performance screening depends strongly on the structure of such ROs. Furthermore, traditional ROs add a signiÔ¨Åcant area and leakage overhead to the design. In this work, the functional path ROs are presented, which are on-chip integrated monitors for performance screening. This work is divided into two main parts: Part I - the Pre-Silicon part, and Part II - the Post-Silicon part. Part I presents the implementation of functional path ROs, including methodologies to improve the functional path ROs reg"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_260", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 260, "text": "ain parts: Part I - the Pre-Silicon part, and Part II - the Post-Silicon part. Part I presents the implementation of functional path ROs, including methodologies to improve the functional path ROs regarding routing and efÔ¨Åciency. The main contributions of this work in that part are: \u000fThe scalable implementation of the functional path RO in an industrial design, which leads up to 96 % savings in terms of leakage and area compared to the traditional RO structures. \u000fTwo advanced implementation methods to reduce the implementation effort: the concept of natural loops and the Best Paper Award- winning concept of self-enabling. \u000fThe self-enabling approach which leads to a signiÔ¨Åcant reduction in routing effort. \u000fThe path selection Ô¨Çow selects promising functional paths for RO implementation with minimal turnaround time and compatibility with industrial design Ô¨Çows. \u000fThe path selection Ô¨Çow is validated through analog simulation and sensitivity analysis to continuously improve the path selection Ô¨Çow in the speciÔ¨Åed PVT space. In Part II, the implemented functional path ROs on silicon are measured and validated. Ultimately, their frequencies are used for the performance screening. The main "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_261", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 261, "text": "on Ô¨Çow in the speciÔ¨Åed PVT space. In Part II, the implemented functional path ROs on silicon are measured and validated. Ultimately, their frequencies are used for the performance screening. The main contributions of this work in that part are: 116 10. Conclusion \u000fThe measured functional path RO frequencies have high quality and repeatability and meet the expected pre-silicon simulation results. \u000fThe measured frequencies are used for the ML-based performance screening that provides a high accuracy. \u000fThe ML problem is modeled as a classiÔ¨Åcation problem and regression problem, and the accuracy using the functional path ROs is discussed. \u000fThe performance screening accuracy can be signiÔ¨Åcantly improved by combining the functional path ROs with the SMONs. Finally, the functional path ROs can compete with the traditional SMONs in terms of prediction accuracy in all test cases. The Functional path ROs are considerably more efÔ¨Åcient than traditional SMONs, particularly regarding leakage, area consumption, and routing effort. Combining a few dedicated SMONs and functional path ROs provides outstanding performance monitors for highly accurate screening. Thus, the functional path ROs contribu"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_262", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 262, "text": "consumption, and routing effort. Combining a few dedicated SMONs and functional path ROs provides outstanding performance monitors for highly accurate screening. Thus, the functional path ROs contribute to producing more sustainable and economical MCUs. 10.2. Obstacles in an Industrial Context In addition to the many advantages of functional path ROs, such structures can lead to obstacles in the industrial environment that should be mentioned. The ECO implementation of the functional path ROs can lead to an obstacle - however, it is only applicable in the industrial context. Ideally, the MCU design passes through the design Ô¨Çow step by step, the ECO phase Ô¨Åxes all issues, and the functional path ROs are implemented. In reality, there is a time to market pressure, which accelerates the design Ô¨Çow. Thus, the timeline becomes tighter in the ECO phase - one of the last steps before tape-out. The tight timeline results in the optimized ECO phase, and the functional path RO implementation is executed with some other ECO steps in parallel. The impact is shown in Section 5.2.1, which has not had a signiÔ¨Åcant impact in the test case in this thesis. However, that could be changed in other de"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_263", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 263, "text": " executed with some other ECO steps in parallel. The impact is shown in Section 5.2.1, which has not had a signiÔ¨Åcant impact in the test case in this thesis. However, that could be changed in other designs. Therefore, carefully planning the functional path RO implementation via ECO is necessary. Another potential obstacle is the circumstance of the path delay fault model for path sensitization. In this work, there were no barriers due to a large automobile MCU with an extensive DfT environment. However, this might change in other designs. In this work, many functional paths can be sensitized using a commercial ATPG tool in path delay fault mode. The number of sensitizable paths and the used scan environment are crucial for this path 117 10. Conclusion sensitization. Therefore, the functional path RO approach may have limited applicability for designs with few sensitizable paths. 10.3. Future Work The thesis delivers a proof of concept for implementing and using functional path ROs. Even the22implemented functional path ROs improve the performance screening and increase the yield. Future MCUs products shall have several hundreds of functional path ROs, including the self-enabling me"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_264", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 264, "text": "n the22implemented functional path ROs improve the performance screening and increase the yield. Future MCUs products shall have several hundreds of functional path ROs, including the self-enabling mechanism and all architectural and conceptional methodologies presented in this work. In addition, the path selection process shall be continually improved with the sensitivity-based approach proposed in Section 5.3. With such improvements, a further decrease in the screening guardband is possible. As mentioned in Section 10.2, the sensitization using commercial ATPG tools in path delay fault mode can lead to obstacles. In order to overcome this obstacle, a particular path sensitization mode for functional path ROs is meaningful. That additional mode will not be forced to ensure path sensitization during clock events since the oscillation of the functional path ROs is clock-independent. With such ATPG mode in place, more functional paths can be enabled for the RO implementation. The ATE is used to sensitize and measure the functional path ROs. Such utilization allows the measurement of functional path ROs in the initial production state on ATE. An in-Ô¨Åeld usage of the functional path RO"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_265", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 265, "text": "used to sensitize and measure the functional path ROs. Such utilization allows the measurement of functional path ROs in the initial production state on ATE. An in-Ô¨Åeld usage of the functional path ROs can be enabled by using a deterministic scan pattern on-chip. Methods to do this are proposed in [122]. Using such an approach, path sensitization and in-Ô¨Åeld measurement of the functional path RO frequencies is possible using an on-chip counter. Such an approach can enable functional path RO for predictive maintenance and lifecycle monitoring. In the end, functional path ROs are promising and efÔ¨Åcient structures for performance screening, and they are even more powerful by utilizing ML approaches. The further work proposal indicates the potential of functional path ROs, either for more advanced performance screening or emerging applications for in-Ô¨Åeld usage. 118 List of Figures 1.1. Process window after tightening the limits. . . . . . . . . . . . . . . . . . . . . . 3 1.2. Test approaches for FMAX testing. . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3. Outline of the thesis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.1. Development Ô¨Çow of"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_266", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 266, "text": "ches for FMAX testing. . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3. Outline of the thesis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.1. Development Ô¨Çow of a prototype MCU divided into Pre-Silicon and Post-Silicon. 8 2.2. Synchronous combinational logic path with launch and capture FF. . . . . . . 10 2.3. Timing diagram of a capture FF in a synchronous digital circuit illustrating setup and hold time and slack. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.4. Wafermap shows the D2D variations from the frequency of an RO. . . . . . . . 13 2.5. Relation between PVT variations and performance. . . . . . . . . . . . . . . . . 16 2.6. Corner cases of a CMOS transistor. . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.7. Scan FF contains an ordinary FF and a MUX. . . . . . . . . . . . . . . . . . . . . 20 2.8. Scan insertion replaces three FFs with scan FFs and connects them to a scan chain. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.9. Scan test procedure with a capture pulse. . . . . . . . . . . . . . . . . . . . . . . 21 2.10. Scan compression allows the parallel loading"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_267", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 267, "text": " . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.9. Scan test procedure with a capture pulse. . . . . . . . . . . . . . . . . . . . . . . 21 2.10. Scan compression allows the parallel loading of scan chains with a decompres- sor and compactor through a single pin. . . . . . . . . . . . . . . . . . . . . . . . 21 2.11. Scan test using a path delay fault model. . . . . . . . . . . . . . . . . . . . . . . 22 2.12. Basic principle of an RO using inverter gates. . . . . . . . . . . . . . . . . . . . . 25 2.13. ML overview of approaches in this work. . . . . . . . . . . . . . . . . . . . . . . 27 2.14. Confusion matrix of a classiÔ¨Åcation problem. . . . . . . . . . . . . . . . . . . . . 29 3.1. Example of a functional path RO. Adapted from [40] c IEEE 2021. . . . . . . . 32 3.2. Path sensitization of a functional path RO with the scan architecture. Adapted from [40] c IEEE 2021. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.3. The test sequence during the scan test pattern. Adapted from [40] c IEEE 2021. 34 3.4. Four path topologies of functional paths. . . . . . . . . . . . . . . . . . . . . . . 36 3.5. Basic concept of the natural loop approach. . . . ."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_268", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 268, "text": "n test pattern. Adapted from [40] c IEEE 2021. 34 3.4. Four path topologies of functional paths. . . . . . . . . . . . . . . . . . . . . . . 36 3.5. Basic concept of the natural loop approach. . . . . . . . . . . . . . . . . . . . . . 37 3.6. The basic principle of the self-enabling approach of a functional path RO. Adapted from [41] c IEEE 2022. . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 3.7. The library gate called RO-MUX. Adapted from [49] c IEEE 2023. . . . . . . . 40 119 List of Figures 3.8. XOR-tree for compacting the observe signals and forwarding it to a GPIO. Adapted from [49] c IEEE 2023. . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.9. Detailed implementation of Option 1. Adapted from [49] c IEEE 2023. . . . . 41 3.10. Option 2 - the indirect self-enabling controlled by three surrounding scan FFs. 42 3.11. Basic control infrastructure for the functional path ROs with 8 ports. . . . . . . 44 3.12. The control infrastructure for the functional path ROs. Adapted from [49] c IEEE 2023. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.13. Implementation Ô¨Çow of functional path RO. Adapted from [49] c IEEE 2023. 47 3.14"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_269", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 269, "text": "Os. Adapted from [49] c IEEE 2023. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.13. Implementation Ô¨Çow of functional path RO. Adapted from [49] c IEEE 2023. 47 3.14. Implementation on layout based on Path a after ECO. Adapted from [40] c IEEE 2021. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.15. Implementation on layout based on Path b after ECO. Adapted from [40] c IEEE 2021. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.16. Sensitizable paths per pattern for three modules. . . . . . . . . . . . . . . . . . 54 3.17. Candidates for natural loops. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 3.18. Routing visualization of 8 sample paths implemented in Option 0. . . . . . . . 57 3.19. Routing visualization of 8 sample paths implemented in Option 1. . . . . . . . 58 4.1. Physical-aware functional path selection Ô¨Çow. . . . . . . . . . . . . . . . . . . . 61 4.2. Elbow plots of the three modules. . . . . . . . . . . . . . . . . . . . . . . . . . . 64 4.3. Violin plots presenting the distribution of paths on Module B according to the deÔ¨Åned path characteristics. . ."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_270", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 270, "text": " plots of the three modules. . . . . . . . . . . . . . . . . . . . . . . . . . . 64 4.3. Violin plots presenting the distribution of paths on Module B according to the deÔ¨Åned path characteristics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5.1. Overview of the Section Pre-Silicon veriÔ¨Åcation and validation. . . . . . . . . . 68 5.2. Digital simulation snapshot at the beginning of the oscillation. Adapted from [49] c IEEE 2023. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.3. Digital simulation sequence with 6 functional path ROs. . . . . . . . . . . . . . 70 5.4. Limits from the digital simulation using the worst and best case SDF. . . . . . 71 5.5. Path characteristic pre- and post-tape-out. . . . . . . . . . . . . . . . . . . . . . 73 5.6. Ansys RedHawk-SC simulation on Module A including the visualization of the implemented functional path ROs. . . . . . . . . . . . . . . . . . . . . . . . . 74 5.7. SPICE Model extractor with data in- and output. Adapted from [42] c IEEE 2022. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.8. Two alternatives of the extracted analog SPICE models. Adapt"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_271", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 271, "text": "n- and output. Adapted from [42] c IEEE 2022. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.8. Two alternatives of the extracted analog SPICE models. Adapted from [42] c IEEE 2022. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 5.9. Voltage and temperature sensitivity of the functional path ROs. Adapted from [42] c IEEE 2022. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.10. Variance of the frequency sensitivity with respect to the individual process parameters of all selected functional paths ROs. Adapted from [42] c IEEE 2022. 80 120 List of Figures 5.11. Variance of the frequency sensitivity of the selected functionalpaths ROs with respect to all process parameters. Adapted from [42] c IEEE 2022. . . . . . . . 81 5.12. Variance of the delay sensitivity of the randomly selected sensitizable functional paths with respect to all process parameters. Adapted from [42] c IEEE 2022. 81 7.1. Repetitive measurement of the functional path ROs on a normalized scale. . . 87 7.2. CoefÔ¨Åcient of variation of 100 repetitive measurements. . . . . . . . . . . . . . . 88 7.3. Measurement dat"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_272", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 272, "text": "81 7.1. Repetitive measurement of the functional path ROs on a normalized scale. . . 87 7.2. CoefÔ¨Åcient of variation of 100 repetitive measurements. . . . . . . . . . . . . . . 88 7.3. Measurement data from 3858 devices of 25 wafers and the simulated test limits. 89 7.4. Voltage drop measurements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 7.5. Wafermap of the frequency distribution of an functional path RO. . . . . . . . 90 8.1. Test Ô¨Çow of an MCU including the performance screening. . . . . . . . . . . . 91 8.2. FMAX characterization results from a wafter after the SLT. . . . . . . . . . . . . 94 8.3. Data set structure from unlabeled and labeled devices. . . . . . . . . . . . . . . 95 8.4. Performance screening process basics. . . . . . . . . . . . . . . . . . . . . . . . . 96 8.5. Performance screening process learning and deploying. . . . . . . . . . . . . . 96 8.6. Violin plot of the 10 SLT test cases of the FMAX characterization. . . . . . . . . 105 8.7. Correlation heatmap between functional path ROs and SLTs. . . . . . . . . . . 106 8.8. Correlation heatmap between the SMONs and SLTs. . . . . . . . . . . . . . . . 107 8.9. Measured vs. predicted performan"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_273", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 273, "text": "ation heatmap between functional path ROs and SLTs. . . . . . . . . . . 106 8.8. Correlation heatmap between the SMONs and SLTs. . . . . . . . . . . . . . . . 107 8.9. Measured vs. predicted performance for T0. . . . . . . . . . . . . . . . . . . . . 110 8.10. Guardband comparison using the RidgeCV regression. . . . . . . . . . . . . . . 112 8.11. Cumulated RO importance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 8.12. Guardband comparison RidgeCV regression for T0. . . . . . . . . . . . . . . . . 113 121 List of Tables 3.1. Properties of Option 0, Option 1, and Option 2. . . . . . . . . . . . . . . . . . . 44 3.2. Basic information of the MCU modules. . . . . . . . . . . . . . . . . . . . . . . . 49 3.3. Path characteristics of Path a and Path b . . . . . . . . . . . . . . . . . . . . . . . . 50 3.4. Estimated area overhead and leakage increase of the control infrastructure. . . 52 3.5. Area overhead and leakage increase of 128functional path ROs in comparison to an equal sized SMON module. . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 3.6. Path analysis analysing the structure of the functional paths. . . . . . . . . . . 53 3.7. ATPG results revea"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_274", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 274, "text": " an equal sized SMON module. . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 3.6. Path analysis analysing the structure of the functional paths. . . . . . . . . . . 53 3.7. ATPG results reveal the number of patterns necessary for path sensitization. . 54 3.8. Number of paths suitable for functional path RO implementation. . . . . . . . 56 3.9. Routing reduction of the RO implementation for Option 1 . . . . . . . . . . . . . 57 3.10. Routing reduction of the RO implementation for Option 1 including the general enable signal. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 3.11. Paths with nearby FFs per module. . . . . . . . . . . . . . . . . . . . . . . . . . . 59 4.1. Number of paths per bucket after the K-means clustering. . . . . . . . . . . . . 65 4.2. Final selected functional path to be implemented as an RO. . . . . . . . . . . . 67 5.1. Deviation of the implemented functional path ROs pre- and post-tape-out. . . 72 8.1. Differences and similarities between the classiÔ¨Åcation approach and the regres- sion approach. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 8.2. Number of devices after the Ô¨Åltering in "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_275", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 275, "text": "ilarities between the classiÔ¨Åcation approach and the regres- sion approach. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 8.2. Number of devices after the Ô¨Åltering in the SLT. . . . . . . . . . . . . . . . . . . 105 8.3. PCC comparison between functional path ROs and SMONs. . . . . . . . . . . . 107 8.4. Results of the classiÔ¨Åcation-based ML models using functional path ROs. . . . 108 8.5. Results of the classiÔ¨Åcation-based ML models using SMONs. . . . . . . . . . . 109 8.6. Results of the classiÔ¨Åcation-based ML models using the combined data set. . . 109 8.7. Prediction accuracy on the functional path ROs. . . . . . . . . . . . . . . . . . . 110 8.8. Prediction accuracy on the SMONs. . . . . . . . . . . . . . . . . . . . . . . . . . 111 8.9. Prediction Accuracy on the Combined data set. . . . . . . . . . . . . . . . . . . 111 8.10. FSCREEN and yield estimation for performance screening. . . . . . . . . . . . . . 114 122 Acronyms ATE automatic test equipment 4, 24, 26, 34, 69, 87, 88, 115, 118 ATPG automatic test pattern generation 23, 33, 34, 37, 39, 41‚Äì44, 48, 54, 56, 83, 117, 118, 122 BE back-end 9, 91 BIST built-in self-test 19 CMOS complementar"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_276", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 276, "text": "pment 4, 24, 26, 34, 69, 87, 88, 115, 118 ATPG automatic test pattern generation 23, 33, 34, 37, 39, 41‚Äì44, 48, 54, 56, 83, 117, 118, 122 BE back-end 9, 91 BIST built-in self-test 19 CMOS complementary metal oxide semiconductor 9, 10, 12, 16, 17, 49, 50, 62, 119 CV coefÔ¨Åcient of variation 88 D2D die-to-die 13, 26, 30, 62, 90, 119 DfT Design for Testability 9, 19, 24, 33, 35, 38‚Äì40, 42, 56, 117 DPPM defective parts per million 29, 30 DRC Design Rule Check 9 DUT device under test 24, 26, 89, 92 ECO engineering change order 9, 46, 48, 49, 51, 52, 64, 66, 68, 70‚Äì72, 84, 117, 120 EDA electronic design automation 16, 17, 23, 41, 48, 52, 58 FEfront-end 9, 91 FFÔ¨Çip-Ô¨Çop 9‚Äì11, 20, 21, 23, 35, 36, 38‚Äì46, 53, 59, 60, 83, 119, 120, 122 GPIO general purpose input/output 43, 44, 69, 70, 87, 88, 90, 93 HCI hot carrier injection 18 ICintegrated circuit 1 123 Acronyms IDT inverse temperature dependence 15, 16 JTAG Joint Test Action Group 19 L2L lot-to-lot 13 LBIST logic built-in self-test 19 LEC Logic Equivalence Check 9, 68 LOC launch-off-capture 23, 34 LOS launch-off-shift 23 MAE mean absolute error 27, 102, 111 MBIST memory built-in self-test 19 MCC Matthews correlation coefÔ¨Åcient 101, 108 MCU mi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_277", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 277, "text": "quivalence Check 9, 68 LOC launch-off-capture 23, 34 LOS launch-off-shift 23 MAE mean absolute error 27, 102, 111 MBIST memory built-in self-test 19 MCC Matthews correlation coefÔ¨Åcient 101, 108 MCU microcontroller 1‚Äì10, 12‚Äì15, 17‚Äì26, 28, 29, 32‚Äì35, 37, 39, 40, 46, 49, 53, 56, 59‚Äì61, 66, 68, 69, 71‚Äì73, 76, 83, 86, 89‚Äì93, 104, 115‚Äì119, 121, 122 ML machine learning 8, 27‚Äì29, 86, 95, 96, 98, 99, 106, 108‚Äì111, 113, 114, 117‚Äì119, 122 MUX multiplexer 20, 32‚Äì35, 37‚Äì40, 44, 48, 50‚Äì52, 69, 89, 90, 119 NBTI negative bias temperature instability 18 PCA principal component analysis 28, 97, 102 PCC Pearson correlation coefÔ¨Åcient 105‚Äì107, 122 PDN power delivery network 14, 15, 73, 75, 84 Post-Si Post-Silicon 8, 9, 15, 16, 18, 86, 115, 116, 119 Pre-Si Pre-Silicon 8, 9, 16, 18, 68, 75, 83, 88, 90, 116, 119, 120 PUT path under test 33, 34 PVT Process-Voltage-Temperature 2, 12, 15, 16, 18, 24, 26, 71, 75, 77‚Äì80, 84, 92, 116, 119 RFradio frequency 92 124 Acronyms RMSE root mean square error 27, 102, 110, 111 RO ring oscillator 3, 5, 13, 25, 26, 32‚Äì41, 43‚Äì52, 56, 58, 63, 64, 66, 69, 76, 79, 80, 83, 86, 88, 90‚Äì92, 95‚Äì101, 104‚Äì106, 111‚Äì113, 115, 116, 118‚Äì121 RTL register-transfer level 9, 10, 46, 68 SDF "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_278", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 278, "text": "111 RO ring oscillator 3, 5, 13, 25, 26, 32‚Äì41, 43‚Äì52, 56, 58, 63, 64, 66, 69, 76, 79, 80, 83, 86, 88, 90‚Äì92, 95‚Äì101, 104‚Äì106, 111‚Äì113, 115, 116, 118‚Äì121 RTL register-transfer level 9, 10, 46, 68 SDF standard delay format 69, 71, 120 SLT system-level test 26, 92, 94, 105‚Äì112, 114, 121, 122 SMON speed monitor ring oscillator 50‚Äì52, 91, 95, 97, 100, 103, 104, 106‚Äì115, 117, 121, 122 SoC system-on-chip 1, 3, 8 SPEF standard parasitic exchange format 76, 77 SPICE Simulation Program with Integrated Circuit Emphasis 17 SSTA statistical static timing analysis 17 STA static timing analysis 9, 17, 46, 48, 53, 54, 56, 62, 66, 76 STIL standard test interface language 24 TCL tool command language 49 W2W wafer-to-wafer 13 WCSS within-cluster-sum-of-squares 63, 64 WGL waveform generation logic 24 WID within-die 13, 17, 26, 62 125 Bibliography [1] 117th United States Congress. Research and Development, Competition, and Innovation Act Supreme Court Security Funding Act of 2022 . Accessed: 2023-08-11. url:https: //www.govinfo.gov/content/pkg/PLAW-117publ167/pdf/PLAW-117publ167.pdf . [2] EUROPEAN COMMISSION. REGULATION OF THE EUROPEAN P ARLIAMENT AND OF THE COUNCIL establishing a framework of measure"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_279", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 279, "text": "rl:https: //www.govinfo.gov/content/pkg/PLAW-117publ167/pdf/PLAW-117publ167.pdf . [2] EUROPEAN COMMISSION. REGULATION OF THE EUROPEAN P ARLIAMENT AND OF THE COUNCIL establishing a framework of measures for strengthening Europe‚Äôs semiconductor ecosystem (Chips Act) . Accessed: 2023-08-11. url:https://eur- lex. europa.eu/legal-content/EN/TXT/?uri=celex:52022PC0046 . [3] S. Pateras and T. -P . Tai. ‚ÄúAutomotive semiconductor test‚Äù. In: International Symposium on VLSI Design, Automation and Test (VLSI-DAT) . IEEE, Apr. 2017. doi:10.1109/vlsi- dat.2017.7939655 . [4] G. Georgakos, U. Schlichtmann, R. Schneider, and S. Chakraborty. ‚ÄúReliability chal- lenges for electric vehicles: From devices to architecture and systems software‚Äù. In:50th ACM/EDAC/IEEE Design Automation Conference (DAC) . 2013, pp. 1‚Äì9. doi: 10.1145/2463209.2488855 . [5] AEC Component Technical Committee. AEC Documents .url:http://www.aecouncil. com/AECDocuments.html . [6] R. Raina. ‚ÄúAchieving Zero-Defects for Automotive Applications‚Äù. In: IEEE International Test Conference . 2008, pp. 1‚Äì10. doi:10.1109/TEST.2008.5483611 . [7] S. Mitra, E. Volkerink, E. McCluskey, and S. Eichenberger. ‚ÄúDelay defect screening using process "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_280", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 280, "text": "cations‚Äù. In: IEEE International Test Conference . 2008, pp. 1‚Äì10. doi:10.1109/TEST.2008.5483611 . [7] S. Mitra, E. Volkerink, E. McCluskey, and S. Eichenberger. ‚ÄúDelay defect screening using process monitor structures‚Äù. In: 22ndIEEE VLSI Test Symposium . IEEE, 2004. doi: 10.1109/vtest.2004.1299224 . [8] B. Cory, R. Kapur, and B. Underwood. ‚ÄúSpeed binning with path delay test in 150-nm technology‚Äù. In: IEEE Design & Test of Computers . IEEE, Sept. 2003, pp. 41‚Äì45. doi: 10.1109/mdt.2003.1232255 . [9] J. Zeng, M. Abadir, G. Vandling, L. -C. Wang, S. Karako, and J. Abraham. ‚ÄúOn cor- relating structural tests with functional tests for speed binning of high performance design‚Äù. In: Fifth International Workshop on Microprocessor Test and VeriÔ¨Åcation (MTV‚Äô04) . 2004, pp. 103‚Äì109. doi:10.1109/MTV.2004.17 . 126 Bibliography [10] P . Maxwell, I. Hartanto, and L. Bentz. ‚ÄúComparing functional and structural tests‚Äù. In: IEEE International Test Conference (ITC) . 2000, pp. 400‚Äì407. doi:10.1109/TEST.2000. 894231 . [11] R. McLaughlin, S. Venkataraman, and C. Lim. ‚ÄúAutomated Debug of Speed Path Failures Using Functional Tests‚Äù. In: 27th IEEE VLSI Test Symposium . IEEE, May 2009. doi:10.1109/vts.200"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_281", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 281, "text": "2000. 894231 . [11] R. McLaughlin, S. Venkataraman, and C. Lim. ‚ÄúAutomated Debug of Speed Path Failures Using Functional Tests‚Äù. In: 27th IEEE VLSI Test Symposium . IEEE, May 2009. doi:10.1109/vts.2009.53 . [12] P . Bernardi, M. Restifo, M. S. Reorda, D. Appello, C. Bertani, and D. Petrali. ‚ÄúApplica- tive System Level Test introduction to Increase ConÔ¨Ådence on Screening Quality‚Äù. In: 23rd International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS) . IEEE, Apr. 2020. doi:10.1109/ddecs50862.2020.9095569 . [13] I. Polian, J. Anders, S. Becker, P . Bernardi, K. Chakrabarty, N. ElHamawy, M. Sauer, A. Singh, M. S. Reorda, and S. Wagner. ‚ÄúExploring the Mysteries of System-Level Test‚Äù. In:29th Asian Test Symposium (ATS) . IEEE, Nov. 2020. doi:10.1109/ats49688.2020. 9301557 . [14] J. Chen, L. -C. Wang, P . -H. Chang, J. Zeng, S. Yu, and M. Mateja. ‚ÄúData learning techniques and methodology for Fmax prediction‚Äù. In: International Test Conference . IEEE, Nov. 2009. doi:10.1109/test.2009.5355620 . [15] J. Chen, J. Zeng, L. -C. Wang, J. Rearick, and M. Mateja. ‚ÄúSelecting the most relevant structural Fmax for system Fmax correlation‚Äù. In: 28th VLSI Test Symposium (V"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_282", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 282, "text": "oi:10.1109/test.2009.5355620 . [15] J. Chen, J. Zeng, L. -C. Wang, J. Rearick, and M. Mateja. ‚ÄúSelecting the most relevant structural Fmax for system Fmax correlation‚Äù. In: 28th VLSI Test Symposium (VTS) . IEEE, Apr. 2010. doi:10.1109/vts.2010.5469604 . [16] S.-P . Mu, M. C. -T. Chao, S. -H. Chen, and Y. -M. Wang. ‚ÄúStatistical Framework and Built- In Self-Speed-Binning System for Speed Binning Using On-Chip Ring Oscillators‚Äù. In:IEEE Transactions on Very Large Scale Integration (VLSI) Systems . IEEE, May 2016, pp. 1675‚Äì1687. doi:10.1109/tvlsi.2015.2478921 . [17] S. Asai, ed. VLSI Design and Test for Systems Dependability . Springer Japan, 2019. doi: 10.1007/978-4-431-56594-9 . [18] M. Sadi, S. Kannan, L. Winemberg, and M. Tehranipoor. ‚ÄúSoC Speed Binning Using Machine Learning and On-Chip Slack Sensors‚Äù. In: IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems . IEEE, May 2017, pp. 842‚Äì854. doi: 10.1109/tcad.2016.2602806 . [19] T.-B. Chan, P . Gupta, A. B. Kahng, and L. Lai. ‚ÄúSynthesis and Analysis of Design- Dependent Ring Oscillator (DDRO) Performance Monitors‚Äù. In: IEEE Transactions on Very Large Scale Integration (VLSI) Systems . IEEE, Oct. 2014, pp. 21"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_283", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 283, "text": "g, and L. Lai. ‚ÄúSynthesis and Analysis of Design- Dependent Ring Oscillator (DDRO) Performance Monitors‚Äù. In: IEEE Transactions on Very Large Scale Integration (VLSI) Systems . IEEE, Oct. 2014, pp. 2117‚Äì2130. doi: 10.1109/tvlsi.2013.2282742 . 127 Bibliography [20] J. Heo, K. Jeong, T. Kim, and K. Choi. ‚ÄúSynthesis of Hardware Performance Monitoring and Prediction Flow Adapting to Near-Threshold Computing and Advanced Process Nodes‚Äù. In: 25th Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC) . IEEE, Jan. 2020. doi:10.1109/asp-dac47756.2020.9045392 . [21] X. Wang, M. Tehranipoor, and R. Datta. ‚ÄúA novel architecture for on-chip path delay measurement‚Äù. In: International Test Conference . IEEE, Nov. 2009. doi:10.1109/test. 2009.5355742 . [22] J. Waicukauski, E. Lindbloom, B. Rosen, and V . Iyengar. ‚ÄúTransition Fault Simulation‚Äù. In:IEEE Design & Test of Computers . IEEE, 1987, pp. 32‚Äì38. doi:10.1109/mdt.1987. 295104 . [23] C. J. Lin and S. Reddy. ‚ÄúOn Delay Fault Testing in Logic Circuits‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, Sept. 1987, pp. 694‚Äì 703. doi:10.1109/tcad.1987.1270315 . [24] R. Cantoro, M. Huch, T. Kilian, R. M"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_284", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 284, "text": "Circuits‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, Sept. 1987, pp. 694‚Äì 703. doi:10.1109/tcad.1987.1270315 . [24] R. Cantoro, M. Huch, T. Kilian, R. Martone, U. Schlichtmann, and G. Squillero. ‚ÄúMa- chine Learning based Performance Prediction of Microcontrollers using Speed Mon- itors‚Äù. In: IEEE International Test Conference (ITC) . IEEE, Nov. 2020. doi:10.1109/ itc44778.2020.9325253 . [25] A. D. Singh. ‚ÄúAn Adaptive Approach to Minimize System Level Tests Targeting Low Voltage DVFS Failures‚Äù. In: IEEE International Test Conference (ITC) . IEEE, Nov. 2019. doi:10.1109/itc44170.2019.9000173 . [26] D. Ernst, N. S. Kim, S. Das, S. Pant, R. Rao, T. Pham, C. Ziesler, D. Blaauw, T. Austin, K. Flautner, and T. Mudge. ‚ÄúRazor: a low-power pipeline based on circuit-level timing speculation‚Äù. In: 36th Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-36. 2003, pp. 7‚Äì18. doi:10.1109/MICRO.2003.1253179 . [27] D. Blaauw, S. Kalaiselvan, K. Lai, W. -H. Ma, S. Pant, C. Tokunaga, S. Das, and D. Bull. ‚ÄúRazor II: In Situ Error Detection and Correction for PVT and SER Tolerance‚Äù. In: IEEE International Solid-State Circuits Conference - "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_285", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 285, "text": "n, K. Lai, W. -H. Ma, S. Pant, C. Tokunaga, S. Das, and D. Bull. ‚ÄúRazor II: In Situ Error Detection and Correction for PVT and SER Tolerance‚Äù. In: IEEE International Solid-State Circuits Conference - Digest of Technical Papers . IEEE, Feb. 2008. doi:10.1109/isscc.2008.4523226 . [28] A. Benhassain, S. Mhira, F. Cacho, V . Huard, and L. Anghel. ‚ÄúIn-situ slack monitors: taking up the challenge of on-die monitoring of variability and reliability‚Äù. In: 1st IEEE International VeriÔ¨Åcation and Security Workshop (IVSW) . IEEE, July 2016. doi: 10.1109/ivsw.2016.7566606 . 128 Bibliography [29] T.-B. Chan, P . Gupta, A. B. Kahng, and L. Lai. ‚ÄúDDRO: A novel performance monitoring methodology based on design-dependent ring oscillators‚Äù. In: Thirteenth International Symposium on Quality Electronic Design (ISQED) . IEEE, Mar. 2012. doi:10.1109/isqed. 2012.6187559 . [30] W. C. Wu, C. L. Lee, M. S. Wu, J. E. Chen, and M. S. Abadir. ‚ÄúOscillation ring delay test for high performance microprocessors‚Äù. In: Journal of Electronic Testing . Springer Science and Business Media LLC, 2000, pp. 147‚Äì155. doi:10.1023/a:1008365428314 . [31] X. Wang, M. Tehranipoor, and R. Datta. ‚ÄúPath-RO: A novel on-chip critical"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_286", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 286, "text": "Journal of Electronic Testing . Springer Science and Business Media LLC, 2000, pp. 147‚Äì155. doi:10.1023/a:1008365428314 . [31] X. Wang, M. Tehranipoor, and R. Datta. ‚ÄúPath-RO: A novel on-chip critical path delay measurement under process variations‚Äù. In: 2008 IEEE/ACM International Conference on Computer-Aided Design . IEEE, Nov. 2008. doi:10.1109/iccad.2008.4681644 . [32] U. Schlichtmann. ‚ÄúFrontiers of timing‚Äù. In: ACM/IEEE International Workshop on System Level Interconnect Prediction (SLIP) . IEEE, June 2017. doi:10.1109/slip.2017.7974912 . [33] F. Firouzi, F. Ye, K. Chakrabarty, and M. B. Tahoori. ‚ÄúRepresentative critical-path selec- tion for aging-induced delay monitoring‚Äù. In: 2013 IEEE International Test Conference (ITC) . IEEE, Sept. 2013. doi:10.1109/test.2013.6651924 . [34] D. Lorenz, M. Barke, and U. Schlichtmann. ‚ÄúAging analysis at gate and macro cell level‚Äù. In: IEEE/ACM International Conference on Computer-Aided Design (ICCAD) . IEEE, Nov. 2010. doi:10.1109/iccad.2010.5654309 . [35] Y. Hu, J. YE, Z. Shi, and X. LI. ‚ÄúLAPS: Layout-Aware Path Selection for Post-Silicon Timing Characterization‚Äù. In: IEICE Transactions on Information and Systems . Feb. 2017, pp. 323‚Äì331. d"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_287", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 287, "text": "4309 . [35] Y. Hu, J. YE, Z. Shi, and X. LI. ‚ÄúLAPS: Layout-Aware Path Selection for Post-Silicon Timing Characterization‚Äù. In: IEICE Transactions on Information and Systems . Feb. 2017, pp. 323‚Äì331. doi:10.1587/transinf.2016EDP7184 . [36] N. Callegari, P . Bastani, L. -C. Wang, S. Chakravarty, and A. Tetelbaum. ‚ÄúPath selection for monitoring unexpected systematic timing effects‚Äù. In: Asia and South PaciÔ¨Åc Design Automation Conference . IEEE, Jan. 2009. doi:10.1109/aspdac.2009.4796575 . [37] P . Bastani, N. Callegari, L. -C. Wang, and M. Abadir. ‚ÄúDiagnosis of design-silicon timing mismatch with feature encoding and importance ranking - the methodology explained‚Äù. In: IEEE International Test Conference . IEEE, Oct. 2008. doi:10.1109/test. 2008.4700588 . [38] J. K. Rangan, N. P . Aryan, J. Bargfrede, C. Funke, and H. Graeb. ‚ÄúTiming Variability Analysis of Digital CMOS Circuits‚Äù. In: Reliability by Design; 9. ITG/GMM/GI-Symposium . 2017, pp. 1‚Äì2. [39] C.-L. Chang and C. H. -P . Wen. ‚ÄúAccurate performance evaluation of VLSI designs with selected CMOS process parameters‚Äù. In: IET Circuits, Devices & Systems . Institution of Engineering and Technology (IET), 2018, pp. 116‚Äì123. doi:https:/"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_288", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 288, "text": "ate performance evaluation of VLSI designs with selected CMOS process parameters‚Äù. In: IET Circuits, Devices & Systems . Institution of Engineering and Technology (IET), 2018, pp. 116‚Äì123. doi:https://doi.org/10. 1049/iet-cds.2017.0097 . 129 Bibliography [40] T. Kilian, H. Ahrens, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúA Scalable Design Flow for Performance Monitors Using Functional Path Ring Oscillators‚Äù. In: IEEE International Test Conference (ITC) . IEEE, Oct. 2021. doi:10.1109/itc50571.2021.00041 . [41] T. Kilian, M. Hanel, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúReducing Routing Overhead by Self-Enabling Functional Path Ring Oscillators‚Äù. In: IEEE European Test Symposium (ETS) . IEEE, May 2022. doi:10.1109/ets54262.2022.9810382 . [42] T. Kilian, M. Hanel, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúA Path Selection Flow for Functional Path Ring Oscillators using Physical Design Data‚Äù. In: IEEE International Test Conference (ITC) . IEEE, Sept. 2022. [43] T. Kilian, A. Sengupta, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúAn efÔ¨Åcient High- Volume Production Performance Screening using On-Chip Ring Oscillators‚Äù. In: 2023 IEEE International Symposium on Defect and Fault Tolerance in "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_289", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 289, "text": "Tille, M. Huch, and U. Schlichtmann. ‚ÄúAn efÔ¨Åcient High- Volume Production Performance Screening using On-Chip Ring Oscillators‚Äù. In: 2023 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT) . Oct. 2023, pp. 1‚Äì6. [44] T. Kilian, H. Ahrens, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúScalable Implemen- tation of Functional Path Ring Oscillator for MCU Performance Screening‚Äù. In: 33. GI/GMM/ITG Testmethoden und Zuverl√§ssigkeit von Schaltungen und Systemen (TuZ 2021) . 2021. [45] T. Kilian, H. Ahrens, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúAutomatic and Scalable Implementation Flow of Performance Monitors for Automotive MCU Using Functional Path Ring Oscillators‚Äù. In: ARTe 2021 - First International Workshop on Automotive Reliability and Test in Europe . 2021. [46] T. Kilian, H. Ahrens, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúA Layout-aware Selection Flow for Functional Path Ring Oscillators‚Äù. In: 34. GI/GMM/ITG Testmethoden und Zuverl√§ssigkeit von Schaltungen und Systemen (TuZ 2022) . 2022. [47] T. Kilian, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúReducing Routing Overhead using Natural Loops‚Äù. In: eARTS 2022 - European Automotive Reliabi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_290", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 290, "text": "it von Schaltungen und Systemen (TuZ 2022) . 2022. [47] T. Kilian, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúReducing Routing Overhead using Natural Loops‚Äù. In: eARTS 2022 - European Automotive Reliability, Test and Safety workshop . 2022. [48] T. Kilian, D. Tille, M. Huch, and U. Schlichtmann. ‚ÄúThe Capabilities of Functional Path Ring Oscillators for Performance Screening‚Äù. In: 36. GI/GMM/ITG Testmethoden und Zuverl√§ssigkeit von Schaltungen und Systemen (TuZ 2024) . 2024. [49] T. Kilian, D. Tille, M. Huch, M. Hanel, and U. Schlichtmann. ‚ÄúPerformance Screening Using Functional Path Ring Oscillators‚Äù. In: IEEE Transactions on Very Large Scale Integration (VLSI) Systems . IEEE, 2023, pp. 711‚Äì724. doi:10.1109/tvlsi.2023.3252471 . 130 Bibliography [50] N. Bellarmino, R. Cantoro, M. Huch, T. Kilian, R. Martone, U. Schlichtmann, and G. Squillero. ‚ÄúExploiting Active Learning for Microcontroller Performance Prediction‚Äù. In:IEEE European Test Symposium (ETS) . IEEE, May 2021. doi:10.1109/ets50041.2021. 9465472 . [51] N. Bellarmino, R. Cantoro, M. Huch, T. Kilian, R. Martone, U. Schlichtmann, and G. Squillero. ‚ÄúA Multi-Label Active Learning Framework for Microcontroller Performance Screening‚Äù"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_291", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 291, "text": "1.2021. 9465472 . [51] N. Bellarmino, R. Cantoro, M. Huch, T. Kilian, R. Martone, U. Schlichtmann, and G. Squillero. ‚ÄúA Multi-Label Active Learning Framework for Microcontroller Performance Screening‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . 2023. doi:10.1109/TCAD.2023.3245989 . [52] T. Kilian, H. Ahrens, M. Huch, and D. Tille. INTEGRATED CIRCUIT, TEST ASSEMBLY AND METHOD FOR TESTING AN INTEGRATED CIRCUIT . InÔ¨Åneon Technologies AG. US Patent US 2023079599 A1, Mar. 2023. DE Patent DE 102021123889 B3, Feb. 2023. [53] T. Kilian, H. Ahrens, M. Huch, and D. Tille. INTEGRATED CIRCUIT, TEST ASSEMBLY AND METHOD FOR TESTING AN INTEGRATED CIRCUIT . InÔ¨Åneon Technologies AG. US Patent US 20230138651 A1, Mar. 2023. DE Patent DE 102021128331 B3, Mar. 2023. [54] V . S. Chakravarthi and S. R. Koteshwar. SoC Physical Design . Springer International Publishing, 2022. doi:10.1007/978-3-030-98112-9 . [55] V . S. Chakravarthi. A Practical Approach to VLSI System on Chip (SoC) Design . Springer International Publishing, 2020. doi:10.1007/978-3-030-23049-4 . [56] R. J. Baker. CMOS: Circuit Design, Layout, and Simulation . WILEY, July 2019. isbn : 1119481511. ur"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_292", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 292, "text": "on Chip (SoC) Design . Springer International Publishing, 2020. doi:10.1007/978-3-030-23049-4 . [56] R. J. Baker. CMOS: Circuit Design, Layout, and Simulation . WILEY, July 2019. isbn : 1119481511. url:https://www.ebook.de/de/product/36062569/r_jacob_baker_ cmos_circuit_design_layout_and_simulation.html . [57] M. Chanda, S. De, and A. Sarkar. Low Power VLSI Design . Gruyter, Walter de GmbH, Aug. 2016. isbn : 3110455293. url:https://www.ebook.de/de/product/33538502/ manash_chanda_swapnadip_de_angsuman_sarkar_low_power_vlsi_design.html . [58] S. Mittal. ‚ÄúA Survey of Architectural Techniques for Managing Process Variation‚Äù. In: ACM Computing Surveys . Association for Computing Machinery (ACM), Feb. 2016, pp. 1‚Äì29. doi:10.1145/2871167 . [59] S. Borkar. ‚ÄúDesigning Reliable Systems from Unreliable Components: The Challenges of Transistor Variability and Degradation‚Äù. In: IEEE Micro . IEEE, Nov. 2005, pp. 10‚Äì16. doi:10.1109/mm.2005.110 . [60] V . Champac and J. G. Gervacio. Timing Performance of Nanometer Digital Circuits Under Process Variations . Springer International Publishing, 2018. doi:10.1007/978-3-319- 75465-9 . 131 Bibliography [61] N. Weste. CMOS VLSI design : a circuits and sy"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_293", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 293, "text": " of Nanometer Digital Circuits Under Process Variations . Springer International Publishing, 2018. doi:10.1007/978-3-319- 75465-9 . 131 Bibliography [61] N. Weste. CMOS VLSI design : a circuits and systems perspective . Boston: Addison Wesley, 2011. isbn : 9780321547743. [62] K. Bernstein, K. M. Carrig, C. M. Durham, P . R. Hansen, D. Hogenmiller, E. J. Nowak, and N. J. Rohrer. High Speed CMOS Design Styles . Springer US, 1999. doi:10.1007/978- 1-4615-5573-5 . [63] Q. Xu, N. Yu, and F. Essaf. ‚ÄúImproved Wafer Map Inspection Using Attention Mech- anism and Cosine Normalization‚Äù. In: Machines . MDPI AG, Feb. 2022, p. 146. doi: 10.3390/machines10020146 . [64] D. Blaauw, K. Chopra, A. Srivastava, and L. Scheffer. ‚ÄúStatistical Timing Analysis: From Basic Principles to State of the Art‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, Apr. 2008, pp. 589‚Äì607. doi:10.1109/ tcad.2007.907047 . [65] S. Bhunia and S. Mukhopadhyay. Low-Power Variation-Tolerant Design in Nanometer Silicon . Springer US, 2011. doi:10.1007/978-1-4419-7418-1 . [66] M. Wirnshofer. Variation-Aware Adaptive Voltage Scaling for Digital CMOS Circuits . Springer Netherlands, 2013."}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_294", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 294, "text": "nt Design in Nanometer Silicon . Springer US, 2011. doi:10.1007/978-1-4419-7418-1 . [66] M. Wirnshofer. Variation-Aware Adaptive Voltage Scaling for Digital CMOS Circuits . Springer Netherlands, 2013. doi:10.1007/978-94-007-6196-4 . [67] T. Sakurai and A. Newton. ‚ÄúAlpha-power law MOSFET model and its applications to CMOS inverter delay and other formulas‚Äù. In: IEEE Journal of Solid-State Circuits . IEEE, Apr. 1990, pp. 584‚Äì594. doi:10.1109/4.52187 . [68] L.-T. Wang, C. E. Stroud, and N. A. Touba. System-on-chip test architectures. nanometer design for testability . Morgan Kaufmann Publishers, 2008, p. 856. isbn : 9780123739735. [69] K. Bernstein, D. J. Frank, A. E. Gattiker, W. Haensch, B. L. Ji, S. R. Nassif, E. J. Nowak, D. J. Pearson, and N. J. Rohrer. ‚ÄúHigh-performance CMOS variability in the 65-nm regime and beyond‚Äù. In: IBM Journal of Research and Development . IBM, July 2006, pp. 433‚Äì449. doi:10.1147/rd.504.0433 . [70] M. Cho, M. Khellah, K. Chae, K. Ahmed, J. Tschanz, and S. Mukhopadhyay. ‚ÄúChar- acterization of Inverse Temperature Dependence in logic circuits‚Äù. In: IEEE Custom Integrated Circuits Conference . IEEE, Sept. 2012. doi:10.1109/cicc.2012.6330659 . [71] R. C. J. B"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_295", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 295, "text": "khopadhyay. ‚ÄúChar- acterization of Inverse Temperature Dependence in logic circuits‚Äù. In: IEEE Custom Integrated Circuits Conference . IEEE, Sept. 2012. doi:10.1109/cicc.2012.6330659 . [71] R. C. J. Bhasker. Static Timing Analysis for Nanometer Designs . Springer-Verlag New York Inc., Apr. 2009. isbn : 0387938192. url:https://www.ebook.de/de/product/ 8020071/j_bhasker_rakesh_chadha_static_timing_analysis_for_nanometer_ designs.html . [72] L. W. Nagel and D. Pederson. SPICE (Simulation Program with Integrated Circuit Empha- sis). Tech. rep. EECS Department, University of California, Berkeley, 1973. 132 Bibliography [73] B. Li, M. Hashimoto, and U. Schlichtmann. ‚ÄúFrom Process Variations to Reliability: A Survey of Timing of Digital Circuits in the Nanometer Era‚Äù. In: IPSJ Transactions on System LSI Design Methodology . Information Processing Society of Japan, 2018, pp. 2‚Äì15. doi:10.2197/ipsjtsldm.11.2 . [74] Q. Liu and S. S. Sapatnekar. ‚ÄúConÔ¨Ådence Scalable Post-Silicon Statistical Delay Predic- tion under Process Variations‚Äù. In: 44th ACM/IEEE Design Automation Conference . 2007, pp. 497‚Äì502. doi:10.1145/1278480.1278609 . [75] A. B. Kahng. ‚ÄúNew game, new goal posts‚Äù. In: 52nd ACM/IEE"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_296", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 296, "text": "Predic- tion under Process Variations‚Äù. In: 44th ACM/IEEE Design Automation Conference . 2007, pp. 497‚Äì502. doi:10.1145/1278480.1278609 . [75] A. B. Kahng. ‚ÄúNew game, new goal posts‚Äù. In: 52nd ACM/IEEE Design Automation Conference . ACM, June 2015. doi:10.1145/2744769.2747937 . [76] X. Liu, A. M. Gough, and J. Li. ‚ÄúSemiconductor corner lot generation robust to process variation: Modeling and analysis‚Äù. In: IISE Transactions . Informa UK Limited, Nov. 2017, pp. 126‚Äì139. doi:10.1080/24725854.2017.1383636 . [77] D. Lorenz, M. Barke, and U. Schlichtmann. ‚ÄúEfÔ¨Åciently analyzing the impact of aging effects on large integrated circuits‚Äù. In: Microelectronics Reliability . Elsevier BV, Aug. 2012, pp. 1546‚Äì1552. doi:10.1016/j.microrel.2011.12.029 . [78] S. S. Sapatnekar. ‚ÄúWhat happens when circuits grow old: Aging issues in CMOS design‚Äù. In: International Symposium on VLSI Technology, Systems and Application (VLSI- TSA) . IEEE, Apr. 2013. doi:10.1109/vlsi-tsa.2013.6545621 . [79] S. Karapetyan and U. Schlichtmann. ‚ÄúIntegrating aging aware timing analysis into a commercial STA tool‚Äù. In: VLSI Design, Automation and Test(VLSI-DAT) . IEEE, Apr. 2015. doi:10.1109/vlsi-dat.2015.7114528 . [80] J. M"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_297", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 297, "text": "d U. Schlichtmann. ‚ÄúIntegrating aging aware timing analysis into a commercial STA tool‚Äù. In: VLSI Design, Automation and Test(VLSI-DAT) . IEEE, Apr. 2015. doi:10.1109/vlsi-dat.2015.7114528 . [80] J. M. Galey, R. E. Norby, and J. P . Roth. ‚ÄúTechniques for the diagnosis of switching circuit failures‚Äù. In: IEEE Transactions on Communication and Electronics . IEEE, Sept. 1964, pp. 509‚Äì514. doi:10.1109/tcome.1964.6539498 . [81] R. D. Eldred. ‚ÄúTest Routines Based on Symbolic Logical Statements‚Äù. In: Journal of the ACM . Association for Computing Machinery (ACM), Jan. 1959, pp. 33‚Äì37. doi: 10.1145/320954.320957 . [82] G. L. Smith. ‚ÄúModel for Delay Faults Based Upon Paths.‚Äù In: International Test Conference (ITC) . 1985, pp. 342‚Äì351. [83] E. S. Park. ‚ÄúRobust and nonrobust tests for path delay faults in a combinational circuit‚Äù. In:International Test Conference (ITC) . 1987, pp. 1027‚Äì1034. [84] A. Pramanick and S. Reddy. ‚ÄúOn the detection of delay faults‚Äù. In: International Test Conference (ITC) . IEEE. doi:10.1109/test.1988.207872 . 133 Bibliography [85] J. Savir and S. Patil. ‚ÄúBroad-side delay test‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE,"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_298", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 298, "text": ") . IEEE. doi:10.1109/test.1988.207872 . 133 Bibliography [85] J. Savir and S. Patil. ‚ÄúBroad-side delay test‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, 1994, pp. 1057‚Äì1064. doi:10.1109/43. 298042 . [86] N. Ahmed, M. Tehranipoor, C. P . Ravikumar, and K. M. Butler. ‚ÄúLocal At-Speed Scan Enable Generation for Transition Fault Testing Using Low-Cost Testers‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, May 2007, pp. 896‚Äì906. doi:10.1109/tcad.2006.884405 . [87] M. Bhushan and M. B. Ketchen. CMOS Test and Evaluation . Springer New York, 2015. doi:10.1007/978-1-4939-1349-7 . [88] H. Onodera and H. Terada. ‚ÄúCharacterization of WID delay variability using RO-array test structures‚Äù. In: IEEE 8thInternational Conference on ASIC . IEEE, Oct. 2009. doi: 10.1109/asicon.2009.5351332 . [89] M. Bhushan, A. Gattiker, M. Ketchen, and K. Das. ‚ÄúRing Oscillators for CMOS Process Tuning and Variability Control‚Äù. In: IEEE Transactions on Semiconductor Manufacturing . IEEE, Feb. 2006, pp. 10‚Äì18. doi:10.1109/tsm.2005.863244 . [90] K. Maragos, G. Lentaris, and D. Soudris. ‚ÄúIn-the-Field Mitigation of Process Variabi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_299", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 299, "text": ": IEEE Transactions on Semiconductor Manufacturing . IEEE, Feb. 2006, pp. 10‚Äì18. doi:10.1109/tsm.2005.863244 . [90] K. Maragos, G. Lentaris, and D. Soudris. ‚ÄúIn-the-Field Mitigation of Process Variability for Improved FPGA Performance‚Äù. In: IEEE Transactions on Computers . IEEE, July 2019, pp. 1049‚Äì1063. doi:10.1109/tc.2019.2898833 . [91] A. L. Samuel. ‚ÄúSome Studies in Machine Learning Using the Game of Checkers‚Äù. In: IBM Journal of Research and Development . IBM, July 1959, pp. 210‚Äì229. doi:10.1147/rd. 33.0210 . [92] A. V . Joshi. Machine Learning and ArtiÔ¨Åcial Intelligence . Springer International Publishing, 2020. doi:10.1007/978-3-030-26622-6 . [93] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning . Springer New York, 2009. doi:10.1007/978-0-387-84858-7 . [94] M. A. Syakur, B. K. Khotimah, E. M. S. Rochman, and B. D. Satoto. ‚ÄúIntegration K-Means Clustering Method and Elbow Method For IdentiÔ¨Åcation of The Best Cus- tomer ProÔ¨Åle Cluster‚Äù. In: IOP Conference Series: Materials Science and Engineering . IOP Publishing, Apr. 2018. doi:10.1088/1757-899x/336/1/012017 . [95] M. Ester, H. -P . Kriegel, J. Sander, and X. Xu. ‚ÄúA Density-Based Algorithm for Di"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_300", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 300, "text": "ence Series: Materials Science and Engineering . IOP Publishing, Apr. 2018. doi:10.1088/1757-899x/336/1/012017 . [95] M. Ester, H. -P . Kriegel, J. Sander, and X. Xu. ‚ÄúA Density-Based Algorithm for Discov- ering Clusters in Large Spatial Databases with Noise‚Äù. In: 2nd International Conference on Knowledge Discovery . 1996, pp. 226‚Äì231. [96] G. R. Naik, ed. Advances in Principal Component Analysis . Springer Singapore, 2018. doi: 10.1007/978-981-10-6704-4 . 134 Bibliography [97] H.-G. Stratigopoulos. ‚ÄúMachine learning applications in IC testing‚Äù. In: IEEE 23rd European Test Symposium (ETS) . IEEE, May 2018. doi:10.1109/ets.2018.8400701 . [98] M. Rapp, H. Amrouch, Y. Lin, B. Yu, D. Z. Pan, M. Wolf, and J. Henkel. ‚ÄúMLCAD: A Survey of Research in Machine Learning for CAD‚Äù. In: IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems . IEEE, Oct. 2022, pp. 3162‚Äì3181. doi: 10.1109/tcad.2021.3124762 . [99] ISO 26262. Road vehicles ‚Äì Functional safety . Norm. 2018. [100] A. Ralf. ‚ÄúA Tutorial of How to Ensure High Automotive Microcontroller Quality‚Äù. In: IEEE European Test Symposium (ETS) . IEEE, May 2021. doi:10.1109/ets50041.2021. 9465379 . [101] U. Abelein, H. Lochn"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_301", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 301, "text": "A. Ralf. ‚ÄúA Tutorial of How to Ensure High Automotive Microcontroller Quality‚Äù. In: IEEE European Test Symposium (ETS) . IEEE, May 2021. doi:10.1109/ets50041.2021. 9465379 . [101] U. Abelein, H. Lochner, D. Hahn, and S. Straube. ‚ÄúComplexity, quality and robustness - the challenges of tomorrow‚Äôs automotive electronics‚Äù. In: Design, Automation and Test in Europe Conference (DATE) . IEEE, Mar. 2012. doi:10.1109/date.2012.6176573 . [102] N. Mukherjee and J. Rajski. ‚ÄúDigital Testing of ICs for Automotive Applications‚Äù. In: 29th International Conference on VLSI . IEEE, Jan. 2016. doi:10.1109/vlsid.2016.134 . [103] B. Smith. ‚ÄúSix-sigma design (quality control)‚Äù. In: IEEE Spectrum . IEEE, 1993, pp. 43‚Äì47. doi:10.1109/6.275174 . [104] N. Vivekananthamoorthy and S. Shanmuganathan. Six Sigma . IntechOpen, 2011. isbn : 9533073705. url:https://www.ebook.de/de/product/37154332/six_sigma.html . [105] J. Remmers, D. Lee, and R. Fisette. ‚ÄúHierarchical DFT with enhancements for AC scan, test scheduling and on-chip compression - a case study‚Äù. In: IEEE International Conference on Test, 2005. 2005. doi:10.1109/TEST.2005.1584034 . [106] R. S. Shelar and M. Patyra. ‚ÄúImpact of Local Interconnects on Timi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_302", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 302, "text": "and on-chip compression - a case study‚Äù. In: IEEE International Conference on Test, 2005. 2005. doi:10.1109/TEST.2005.1584034 . [106] R. S. Shelar and M. Patyra. ‚ÄúImpact of Local Interconnects on Timing and Power in a High Performance Microprocessor‚Äù. In: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems . IEEE, Oct. 2013, pp. 1623‚Äì1627. doi:10.1109/tcad. 2013.2266404 . [107] I. B. Mohamad and D. Usman. ‚ÄúStandardization and Its Effects on K-Means Clustering Algorithm‚Äù. In: Research Journal of Applied Sciences, Engineering and Technology . Maxwell ScientiÔ¨Åc Publication Corp., Sept. 2013, pp. 3299‚Äì3303. doi:10.19026/rjaset.6.3638 . [108] ANSYS Inc. https://www.ansys.com/de- de/products/semiconductors/ansys- redhawk-sc . Accessed: 2022-03-09. [109] MunEDA GmbH. https://www.muneda.com/circuit-analysis-and-verification- tools/ . Accessed: 2022-03-09. 135 Bibliography [110] H. Dornelas, A. Schmidt, G. Strube, and E. Fabris. ‚ÄúNew Technology Migration Methodology for Analog IC Design using MunEDA tools‚Äù. In: 2015. doi:10.13140/ RG.2.2.32187.41767 . [111] R. B. Bendel, S. S. Higgins, J. E. Teberg, and D. A. Pyke. ‚ÄúComparison of skewness coefÔ¨Åcient, coefÔ¨Åcient of "}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_303", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 303, "text": "r Analog IC Design using MunEDA tools‚Äù. In: 2015. doi:10.13140/ RG.2.2.32187.41767 . [111] R. B. Bendel, S. S. Higgins, J. E. Teberg, and D. A. Pyke. ‚ÄúComparison of skewness coefÔ¨Åcient, coefÔ¨Åcient of variation, and Gini coefÔ¨Åcient as inequality measures within populations‚Äù. In: Oecologia . Springer Science and Business Media LLC, 1989, pp. 394‚Äì 400. doi:10.1007/bf00379115 . [112] X. Lin. ‚ÄúPower Supply Droop and Its Impacts on Structural At-Speed Testing‚Äù. In: IEEE 21st Asian Test Symposium . IEEE, Nov. 2012. doi:10.1109/ats.2012.63 . [113] Z.-H. Zhou. Machine Learning . Springer Singapore, 2021. doi:10.1007/978-981-15- 1967-3 . [114] T. M. Mitchell. Machine Learning . McGraw Hill, 1997. [115] L. Breiman. ‚ÄúRandom forests‚Äù. In: Machine Learning . Springer Science and Business Media LLC, 2001, pp. 5‚Äì32. doi:10.1023/a:1010933404324 . [116] L. Breiman. ‚ÄúBagging predictors‚Äù. In: Machine Learning . Springer Science and Business Media LLC, Aug. 1996, pp. 123‚Äì140. doi:10.1007/bf00058655 . [117] D. Zhang and X. Wang. ‚ÄúAn on-chip binning sensor for low-cost and accurate speed binning‚Äù. In: 2ndIEEE International Conference on Integrated Circuits and Microsystems (ICICM) . IEEE, Nov. 2017. doi:"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_304", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 304, "text": " D. Zhang and X. Wang. ‚ÄúAn on-chip binning sensor for low-cost and accurate speed binning‚Äù. In: 2ndIEEE International Conference on Integrated Circuits and Microsystems (ICICM) . IEEE, Nov. 2017. doi:10.1109/icam.2017.8242158 . [118] D. Chicco and G. Jurman. ‚ÄúThe advantages of the Matthews correlation coefÔ¨Åcient (MCC) over F1 score and accuracy in binary classiÔ¨Åcation evaluation‚Äù. In: BMC Genomics . Springer Science and Business Media LLC, Jan. 2020. doi:10.1186/s12864- 019-6413-7 . [119] G. C. McDonald. ‚ÄúRidge regression‚Äù. In: Wiley Interdisciplinary Reviews: Computational Statistics . Wiley, July 2009, pp. 93‚Äì100. doi:10.1002/wics.14 . [120] J. M. Sutter, J. H. Kalivas, and P . M. Lang. ‚ÄúWhich principal components to utilize for principal component regression‚Äù. In: Journal of Chemometrics . Wiley, July 1992, pp. 217‚Äì225. doi:10.1002/cem.1180060406 . [121] D. Chicco, M. J. Warrens, and G. Jurman. ‚ÄúThe coefÔ¨Åcient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation‚Äù. In: PeerJ Computer Science . PeerJ, July 2021. doi:10.7717/peerj-cs.623 . [122] Y. Liu, N. Mukherjee, J. Rajski, S. M. Reddy, and J. Tyszer. ‚ÄúDeterministi"}
{"id": "Performance Prediction of Microcontrollers.pdf::chunk_305", "source": "Performance Prediction of Microcontrollers.pdf", "chunk_index": 305, "text": " and RMSE in regression analysis evaluation‚Äù. In: PeerJ Computer Science . PeerJ, July 2021. doi:10.7717/peerj-cs.623 . [122] Y. Liu, N. Mukherjee, J. Rajski, S. M. Reddy, and J. Tyszer. ‚ÄúDeterministic Stellar BIST for In-System Automotive Test‚Äù. In: IEEE International Test Conference (ITC) . IEEE, Oct. 2018. doi:10.1109/test.2018.8624872 . 136"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_0", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 0, "text": "Univ ersity of T exas at El P aso Univ ersity of T exas at El P aso ScholarW orks@UTEP ScholarW orks@UTEP Open Access Theses & Disser tations 2021-12-01 Predicting Z ero Bin In The Semiconduct or Manufacturing Predicting Z ero Bin In The Semiconduct or Manufacturing Industr y: Machine Learning Algorithms Industr y: Machine Learning Algorithms Yazmin Mont oya The Univ ersity of T exas at El P aso Follow this and additional works at: https:/ /scholar works.utep.edu/open_etd Part of the Industrial Engineering Commons Recommended Citation Recommended Citation Mont oya, Yazmin, \"Pr edicting Z ero Bin In The Semiconduct or Manufacturing Industr y: Machine Learning Algorithms\" (2021). Open Access Theses & Disser tations . 3576. https:/ /scholar works.utep.edu/open_etd/3576 This is br ought t o you for fr ee and open access b y ScholarW orks@UTEP . It has been accepted for inclusion in Open Access Theses & Disser tations b y an authoriz ed administr ator of ScholarW orks@UTEP . For mor e information, please contact lweber@utep.edu . PREDICTING ZERO BIN IN THE SEMICONDUCTOR MANUFACTURING INDUSTRY: MACHINE LEARNING ALGORITHMS YAZMIN MONTOYA Master 's Program in Systems Engineering APPROVED: "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_1", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 1, "text": "mation, please contact lweber@utep.edu . PREDICTING ZERO BIN IN THE SEMICONDUCTOR MANUFACTURING INDUSTRY: MACHINE LEARNING ALGORITHMS YAZMIN MONTOYA Master 's Program in Systems Engineering APPROVED: Sreenath Chalil Madathil , Ph.D., Chair Megan Vaughan Kendall, Ph.D. Jose Espiritu Nolasco , Ph.D. Stephen L. Crites , Jr., Ph.D. Dean of the Graduate School Dedication This thesis is dedicated to me : great job on your commitment , ambition, passion for education, and willingness to challenge yourself, even during the Covid -19 Pandemic. PREDICTING ZERO BIN IN THE SEMICONDUCTOR MANUFACTURING INDUSTRY: MACHINE LEARNING ALGORITHMS by YAZMIN MONTOYA , B.S. ENG INEERING LEADERSHIP, MBA THESIS Presented to the Faculty of the Graduate School of The University of Texas at El Paso in Partial Fulfillment of the Requirements for the Degree of MASTER OF SCIENCE Department of Industrial, Manufacturing and Systems Engineering THE UNIVERSITY OF TEXAS AT EL PASO December 2021 iv Abstract The semiconductor industry has faced supply chain manufacturing shortages that ultimately led to a worldwide chip shortage during the COVID -19 pandemic. These chip manufacturers use sophisticated and advanced manuf"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_2", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 2, "text": "or industry has faced supply chain manufacturing shortages that ultimately led to a worldwide chip shortage during the COVID -19 pandemic. These chip manufacturers use sophisticated and advanced manufacturing machinery in their fabs to manufacture chips. As experienced during the pandemic, m anufacturing unavailability is often due to the lack of critical manufacturing -related spare parts. This thesis evaluates the effectiveness of machine learning algorithms to identify significant factors contributing to manufacturing part outages (i.e., zero-bin) to keep manufacturing equipment running at total capacity within the organization . We propose clustering methods to segment the data and use logistic regression, logistic lasso regression, random forest, and kNN approaches to identify impor tant factors for those parts that could go to zero-bin. Extant research applies classic inventory management strategies based on expenditure, criticality, or usage to manage their parts' inventory throughout the year. Instead, the proposed methods explore whether predefined, static inventory parameters can predict whether a spare part reaches zero bin. To demonstrate the viability of this approach,"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_3", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 3, "text": "ughout the year. Instead, the proposed methods explore whether predefined, static inventory parameters can predict whether a spare part reaches zero bin. To demonstrate the viability of this approach, we present a case study using one year's worth of data from a leading chip manufacturing company . Based on the modeling approaches, a lasso -based logistic regression proved the best predictive model amongst the five clusters with lead -time, current quantity available , days on inventory (usage remained relevant), and the part's reorder point being the most significant parameters. v Table of Contents Dedication ................................ ................................ ................................ ................................ ....... ii Abstract ................................ ................................ ................................ ................................ .......... iv List of Tables ................................ ................................ ................................ ................................ . vi List of Figures ................................ ................................ ................................ ................."}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_4", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 4, "text": "............................. ................................ . vi List of Figures ................................ ................................ ................................ ............................... vii Chapter 1: Intro duction ................................ ................................ ................................ .................... 1 Chapter 2: Methods ................................ ................................ ................................ .......................... 6 Data Cleanup and Validation ................................ ................................ ................................ ..6 Clustering ................................ ................................ ................................ ................................ 7 K-Means ................................ ................................ ................................ ................................ ..8 Logistic Regression ................................ ................................ ................................ ................. 9 Logistic Lasso Regression ................................ ................................ ................................ ..."}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_5", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 5, "text": ".................. ................................ ................. 9 Logistic Lasso Regression ................................ ................................ ................................ ......9 Chapter 3: Experimentation Setup ................................ ................................ ................................ .11 Identifying the Problem ‚Äì Output ................................ ................................ ......................... 11 Data Cleanup ‚Äì Output ................................ ................................ ................................ .......... 12 Data Validation ................................ ................................ ................................ ..................... 14 K-Means ................................ ................................ ................................ ................................ 16 Chapter 4: Results ................................ ................................ ................................ .......................... 18 Chapter 5: Conclusions and Future Work ................................ ................................ ...................... 21 References ......................."}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_6", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 6, "text": ".... .......................... 18 Chapter 5: Conclusions and Future Work ................................ ................................ ...................... 21 References ................................ ................................ ................................ ................................ ......23 Appendix A ................................ ................................ ................................ ................................ ....26 Vita ................................ ................................ ................................ ................................ .............. 33 vi List of Tables Table 1.1: Current Inventory Management Research ................................ ................................ ..... 5 Table 2.2: K -Fold Analysis Example ................................ ................................ ............................ 10 Table 3.1: Parameters ................................ ................................ ................................ .................... 13 Table 3.2: Cluster Descriptions ................................ ................................ ................................ ..... 17 Table 4.1: Coeffi"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_7", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 7, "text": ".................. .................... 13 Table 3.2: Cluster Descriptions ................................ ................................ ................................ ..... 17 Table 4.1: Coefficients Table ................................ ................................ ................................ ........ 20 vii List of Figures Figure 1.1: Spare Parts Supply Chain Overview. ................................ ................................ ........... 1 Figure 3.1: Part Availability Fishbone Diagram . ................................ ................................ .......... 11 Figure 3.2: Histogram with Outliers. ................................ ................................ ............................ 14 Figure 3.3: Box Plot s with Outliers. ................................ ................................ ............................. 14 Figure 3. 4: Histogram with Log Scale . ................................ ................................ ......................... 15 Figure 3.5: Box Plots without Outliers . ................................ ................................ ........................ 15 Figure 3.6: Silhouette Method Results ...................."}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_8", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 8, "text": "... 15 Figure 3.5: Box Plots without Outliers . ................................ ................................ ........................ 15 Figure 3.6: Silhouette Method Results ................................. ................................ ......................... 15 Figure 3. 7: Elbow Method Plot . ................................ ................................ ................................ .... 16 Figure 3. 8: K-Means Clustering Results . ................................ ................................ ...................... 17 Figure 4.1: Confusion Matrices . ................................ ................................ ................................ ... 19 Figure 4.2: Confusion Matrices Comparison . ................................ ................................ ............... 19 1 Chapter 1: Introduction This thesis explores the importance of spare part inventory management in the semiconductor manufacturing sector. The machines , fabs, and manufacturing tools that manufacture chips use s pare parts whose size range s very small to very large. The cost of these spare parts varies from cents to thousands of dollars. The COVID -19 pandemic has adversely im"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_9", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 9, "text": "ls that manufacture chips use s pare parts whose size range s very small to very large. The cost of these spare parts varies from cents to thousands of dollars. The COVID -19 pandemic has adversely impacte d every supply chain in every sector (Helper and Soltas ). These spare parts have a unique supply chain dep ending on the manufacturer, country of origin, repairability , and several other parameters that the supply chain department manages . Figure 1.1 represents a high-level overview of the touchpoints for each part of the supply chain. The flow chart was created by interviewing all direct and indirect stakeholders. Figure 1.1: Spare Parts Supply Chain Each s pare part used in the manufacturing plant depends on the type of machine ry. Hence, identifying a spare part begins with the need and usage of a manufacturing tool. Next, the buyer 2 manually inputs the part's inventory information (maximum and minimum quantity and reorder point (ROP) , based on historical and forecast ed manufacturing plans ). The warehouse stocks most of these spare parts as inventory items for future use. Based on the usage of these spare parts, further orders can be placed for replacement , known as th"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_10", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 10, "text": "facturing plans ). The warehouse stocks most of these spare parts as inventory items for future use. Based on the usage of these spare parts, further orders can be placed for replacement , known as the 'replacement loop .' This is called a loop because , as Figure 1.1 illustrates, the part enter s a repair cyc le or 'loop.' The plant uses these spare parts from the inventory as needed . The system will analyze whether the new inventory level reached the ROP. Nothing is done if the inventory level is above ROP , and the replenishment loop continues until another part is pulled from the inventory. More spare parts are ordered to fulfill the inventory levels somewhere between the max imum and the ROP if the current inventory is below the ROP . The new spare parts tha t arrived at the systems stay in the inventory stock until the manufacturing tools need these parts for replacement or repair . Major supplier s have dedicated teams for managing their inventory levels . In contrast, a vendor -managed inventory (VMI) system manages mino r, site-specific , or niche -specific suppliers . In this case study, I review the data for a major supplier at one manufacturing site for a major semicon"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_11", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 11, "text": " -managed inventory (VMI) system manages mino r, site-specific , or niche -specific suppliers . In this case study, I review the data for a major supplier at one manufacturing site for a major semiconductor manufacturer. The inventory management system documents e very step in the process that creates a log of the movement of each part and records the reason for th at part's movement. This extensive part history with thousands of parts and millions of data records is known as big data. Big data is characterize d as large or complex datasets usually larger than an exabyte used for descriptive, predictive, or prescriptive analytics (Romeral et al., 177). I work with a portion of this big data in this research. The world is in the middle of developin g smart factories through an industrial revolution known as Industry 4.0 focused on three paradigms: \"the smart product, smart machine, and augmented operator \" (Weyer et al. , 580). The Smart Product plays an active role within the system 3 documenting data such as usage , run time , environment, and users that can improve its role in the overall system. The Smart Machine can self-organize by understanding its role in the system and impr"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_12", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 12, "text": "documenting data such as usage , run time , environment, and users that can improve its role in the overall system. The Smart Machine can self-organize by understanding its role in the system and improv ing its operations (Loskyll et al., 742) . Finally, t he Augmented Operator make s decisions based on data vs. needing years of experience to understand how their machine, cell, department work (Weyer et al., 580) . The goal in the Industry 4.0 movement is to make strategic decisions instantly to optimize any system . This research explores how a spare part , as a smart product, can play a role in predicting its usage. Current inventory management research includes 1) inventory management to provide a product to a customer and 2) inventory management used in man ufacturing. This research focuses on the latter. Both research strategies heavily rely on historical consumption to build predictive models (K B et al. , 867 ). The goal of these predictive models is to obtain the necessary inventory levels to prevent the outage of critical manufacturing tools' spare parts (prevent zero -bin). Preventing these outages is vital to maintaining productivity and improving profit . Markov decisio"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_13", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 13, "text": "ntory levels to prevent the outage of critical manufacturing tools' spare parts (prevent zero -bin). Preventing these outages is vital to maintaining productivity and improving profit . Markov decision -making is also relevant in the literature due to the cause -and-effect nature of the supply chain ; however , the time-dependent Markovian processes are rare (Nasr and Elshar, 199). Data -based decision -making is not new to the spare parts inventory managemen t principles . Still, the type of characteristics used for decision -making is unique within the inventory management strategies . Current research identified inventory levels, lead-time, forecast based on usage, issues in the last 6 -12 months, a risk measure , and minimum inventory quantities as significant factors using classical logistic regressions techniques (De Santis et al. , 5). However, I will only use predefined inventory parameters captured by the company's data in this research due to their inventory management policies . This inventory management policy uses the part 's lead time provided by the supplier and the days on inventory based on the period designated by the 4 manufacturing company . Table 1.1 outlines t"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_14", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 14, "text": "es . This inventory management policy uses the part 's lead time provided by the supplier and the days on inventory based on the period designated by the 4 manufacturing company . Table 1.1 outlines the analyzed paramete rs. This research proved to be as accurate as current research that considers many more parameters that often need extensive research to create . The significance of this research revolves around the simplicity of the parameters and the model 's ability to predict the zero -bin parts accurately . 5 Table 1.1: Current Inventory Management Research Paper Methods Supply chain design and optimization: Challenges and opportunities (Garcia and You, 159) - Multi -Scale Life-Cycle Optimization Frameworks - Multi -Objective Optimization Decision Support Model for Inventory Management Using AHP Approach: A Case Study on a Malaysian Semiconductor Firm (Wong, 56) - Analytic Hierarchy Process (AHP) - AHP in planning The fourth industrial revolution (Industry 4.0): technologies disruption on operations and supply chain management (Koh, Lenny , et al., 822) - Outcomes and Impacts of Industry 4.0 - Influence Policy Makers and Managers - Interdisciplinary Need Inventory Management "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_15", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 15, "text": "uption on operations and supply chain management (Koh, Lenny , et al., 822) - Outcomes and Impacts of Industry 4.0 - Influence Policy Makers and Managers - Interdisciplinary Need Inventory Management in the Era of Big Data (Bertsimas et al., 2009 ) - Perfect Forecast Policy - Conditional Stochastic Optimization Problem Predicting material backorders in inventory management using machine learning (de Santis et al., 2) - Supervised Learning - Imbalanced Learning ‚Äì SMOTE Inventory management in supply chains: a reinforcement learning approach (Giannoccaro and Pontrandolfo, 154) - Markov Decision Processes - Reinforcement Learning Continuous inventory control with stochastic and non-stationary Markovian demand (Nasr and Elshar, 212) - Markov Decision Processes - Monte -Carlo Simulation A simulation -based multi -objective optimization framework: A case study on inventory management (Tsai and Chen ,154) - Ranking and Selection Procedures - Multi -Objective Optimization Simulation Towards Industry 4.0 - Standardization as the crucial challenge for highly modular, multi - vendor production systems (Weyer et al. ,582) - Control Architectures - Manual Workstation - Smart Infrastructure - Pl"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_16", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 16, "text": "dustry 4.0 - Standardization as the crucial challenge for highly modular, multi - vendor production systems (Weyer et al. ,582) - Control Architectures - Manual Workstation - Smart Infrastructure - Plug and Produce - Production Line and Process Context -Based Orchestration for Control of Resource -Efficient Manufacturing Processes (Loskyll et al.,740) - Manufacturing Semantics Ontology - ADACOR -Ontology - AVILUS Ontology - Inventory Management Using Machine Learning (K B et al.,867) - XGBoost Regression Model - Decision Tre es - Demand For ecasting 6 Chapter 2: Methods I collected inventory data from a major semiconductor manufacturing company . The data is from the year 2020 , during the COVID -19 pandemic (when anything that could go wrong in a supply chain did) . The volatile year caused a greater risk of zero -bins and realized more zero-bins. The pandemic highlighted previously insignificant issues in every supply chain . These outages and the risk of outages in 2020 emphasized the need to prevent critical manufacturing spare parts from hitting zero -bin. The data better lends itself to predict ive analysis because of these issue s. With hundreds of suppliers at the chosen si"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_17", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 17, "text": "he need to prevent critical manufacturing spare parts from hitting zero -bin. The data better lends itself to predict ive analysis because of these issue s. With hundreds of suppliers at the chosen site, a major supplier was selected for the case study . The supplier was chosen based on the large spends and volume of individual parts managed with that supplier. I selected a year's worth of data to capture a clear picture of a part 's consumption history . The site was chosen because it is one of the company 's largest manufacturing sites . Supply chains are incredib ly complicated interconnecting systems made of subsystems . Narrowing the data to one supplier and one manufacturing site narrowed the case study 's scope . The following methods were used to simplify the available data further while respecting the complexity behind each parameter. Data Cleanup and Valid ation The raw data was reviewed and rearranged per the chosen programming language. All static columns which were the same for each line of data were removed. A fter reviewing with the end -users, irrelevant data such as parts with no current consumption were removed from the dataset. Dummy variables were made to have a"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_18", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 18, "text": "e for each line of data were removed. A fter reviewing with the end -users, irrelevant data such as parts with no current consumption were removed from the dataset. Dummy variables were made to have a binomial distinction between the part's various categories . Preliminary data analys es were conducted to review the data 's distributions. This consisted of histograms and boxplots with and without outliers. 7 CLUSTERING Clustering is defined as creating homogeneous data groups in a dataset ( Likas et al ., 1). Categorizing data promotes learning and decision -making in machine l earning . Machine learning is a 'component ' in artificial intelligence where problems are solved by typing or finding patterns within the data. There are two forms of machine learning : supervised and unsupervised. In supervised learning, the data is given a set of rules or controls that will predetermi ne how the data will be classified. In unsupervised learning , no predefined labels are assigned to the data, and rather patterns and inherent groups are foun d within t he data, and the data is assigned to the group that most accurately represents the relationships b etwe en the data (Alloghani et al., 4). "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_19", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 19, "text": " and rather patterns and inherent groups are foun d within t he data, and the data is assigned to the group that most accurately represents the relationships b etwe en the data (Alloghani et al., 4). Clustering is an unsupervised learning methodology. Clustering is broken down further into partitioning, hierarchical, density, or grid -based clustering. Hierarchical methods help create a decision tree on where and how each cluster is related to the whole data (Aggarwal and Reddy Ch. 19). The scope of this thesis does not cover creating these decision trees; therefore, this method was not chosen. Density -based methods focus on data regions with more values centered around specific points and ignore the areas with less data (Aggarwal and Re ddy Ch. 18). Since the data proved to have several outliers, th is clustering method would not be the right fit for the dataset. Grid-based clustering is similar to density -based methods . The regions with more data points are segregated in data space by cells and then categorized based on their densities (Aggarwal and Reddy Ch. 6). Again, due to the varying outliers and long ranges, this method was not selected . Clustering using p artitioning a"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_20", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 20, "text": "e by cells and then categorized based on their densities (Aggarwal and Reddy Ch. 6). Again, due to the varying outliers and long ranges, this method was not selected . Clustering using p artitioning algorithms work in a loop. The data points are plotted repeatedl y based on their distance to a local point . They ultimately get placed into clusters at the point where the sum of squared distances is minimized based on the identified local point (Aggarwal and Reddy , Ch. 17). This form of clustering made 8 the most sense with the dataset, where each cluster would be created based on the different local points for each cluste r. Therefore, I chose a partitioning method for this case study. K-means and K -Medoids are two partitionin g type clustering methods . K-Medoids uses a data point within the analyzed dataset to cluster the data points around. This aspect of the algorithm was concerning seeing the varying outliers within the dataset. K -means uses the Euclidean distance to find th e distance bet ween two points . The centralized point does not necessarily have to be a data point within the dataset but rather within space local to the specific cluster. K -means was chosen to analyz"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_21", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 21, "text": "istance bet ween two points . The centralized point does not necessarily have to be a data point within the dataset but rather within space local to the specific cluster. K -means was chosen to analyze the dataset (Alva , Ch. 8). K-MEANS With a defined K, the K -Means algorithm works by randomly choosing \"K\" number of centroids. Then, in a loop, each data point's distance to each centroid is calculated to properly place the data point in the cluster with the nearest centroid. Next in the lo op, the average distance of every data point in the cluster is calculated to verify that the chosen centroid for each cluster is valid. If the outcomes are different, new centroids are chosen again, averages recalculated and reverified until the centroids are accurate for each cluster, or the max number of iterations set up is met, and the loop is completed (Ahmad , 50). SELECTING K The K in K -means represents the number of clusters. This information must be known prior to run the K -Means algorithm. Calculating the correc t number of clusters can be a trial and error : running the algorithm with a different number of clusters, analyzing the descriptive statistics for each cluster , and validat"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_22", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 22, "text": "m. Calculating the correc t number of clusters can be a trial and error : running the algorithm with a different number of clusters, analyzing the descriptive statistics for each cluster , and validating the number of clusters that make sense based on the dataset. Two straightforward ways of verifying the number of clusters needed for analysis are the Elbow and Silhouette methods (Burkov, 114). 9 The Silhouette method is based on creating clusters that are equally separated from each other so that each cluster contains similar elements. This means \"the silhouette score is based on the principle of maximum internal cohesion and maximum cluster separ ation (Bonaccorso Ch. 6). The Elbow method is calculated using distortion . The larger the K value, the smaller the average distortion . This inverse relationship is because e very data point will be closer to the centroid data point. However, the improvements in average distortion will decrease as K increases, and the K value at which distortion is at its highest decline is represented by the inflection point (Bonnin Ch. 3 ). I took both methods into consideration when selecting the appropriate K value. LOGISTIC REGRESSION A logisti c r"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_23", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 23, "text": "rtion is at its highest decline is represented by the inflection point (Bonnin Ch. 3 ). I took both methods into consideration when selecting the appropriate K value. LOGISTIC REGRESSION A logisti c regression starts with a linear regression but uses log -odds that are passed through a sigmoid function to output a probability between 0 and 1 an d model the decision boundary for classification ( Rai, The math bhind Logistic Regression ). A first trial of the Logistic Regression proved that the data was not balanced . There were too few instances of zero -bin. I used the SMOTE method to balance the data, creating artificial data points based on the already existing data. Logistic regression was used on the SMOTE data. The data was modeled through a kNN regress ion and las so-based regression to compare and contrast confusion matrices results . LOGISTIC LASSO REGRESSION A Lasso -based regression is very similar to logistic regression . Still, i t has a hyperparameter ( ùùÄ ) and shrinkage that manipulate the coefficients to rid the model of the parameters/ coefficients that are not significantly impacting the model 's results. Another difference between the computation of the logistic r"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_24", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 24, "text": "hat manipulate the coefficients to rid the model of the parameters/ coefficients that are not significantly impacting the model 's results. Another difference between the computation of the logistic regression and the lasso-based regression is in this method I used a K-fold an alysis . This approach means the data is divided into K number of groups ; For this research, a n industry standard of K=5 was used. This method works iterativel y to test and train 10 the model using all of the available data. For example , when K=5, the data is divided into 5 test and train instances. In the first instance, all but one of the groups is used to train the model , and the final group is used to test. This is done until all groups have been used to either test or train the model (Brownlee , A Gentle Introduction to k -Fold Cross -Validation ). This approach ensures all of the available data is used in both the testing and training aspect of the model . Table 2.2 demonstrates the K -fold approach. Table 2.2: K-Fold Analysis Example The K -Nearest Neighbor Regression (kNN) also use s k-fold validation. As with K-means, K is identified . Based on the prediction point , the K training observations "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_25", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 25, "text": "able 2.2: K-Fold Analysis Example The K -Nearest Neighbor Regression (kNN) also use s k-fold validation. As with K-means, K is identified . Based on the prediction point , the K training observations closest to the prediction point and estimates the result using the average of the training data (Singh, K-Nearest Neighbors Algorithm: KNN Regression Python ). The significant parameters were identified and the n used to rerun the modeling formulas to analyze the final confusion matrices and develop a formula. K Test Train K = 1 ùíôùüè ,ùíôùüê,ùíôùüë,ùíôùüí ùíôùüì K = 2 ùíôùüè ,ùíôùüê, ùíôùüë,ùíôùüì ùíôùüí K = 3 ùíôùüè ,ùíôùüê, ùíôùüí,ùíôùüì ùíôùüë K = 4 ùíôùüè ,ùíôùüë, ùíôùüí,ùíôùüì ùíôùüê K = 5 ùíôùüê,ùíôùüë, ùíôùüí,ùíôùüì ùíôùüè 11 Chapter 3: Experimentation Setup Following the methods outlined in Chapter 2, the experimentation setup will focus on the results of the methods. The decisions made throughout the experiment are validated through the preliminary analysis results. As more assumptions are made , and the behavior of the data is better unde rstood , the following decision is validated. This section will shed light on the logic and reason for rejecting and selecting the experiment, choos ing the suitable parameters , selecting the best clustering method, and how I navigated "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_26", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 26, "text": "lidated. This section will shed light on the logic and reason for rejecting and selecting the experiment, choos ing the suitable parameters , selecting the best clustering method, and how I navigated selecting the predicti ve models. IDENTIFYING THE PROBLEM ‚Äì OUTPUT I met with industry experts in warehousing, procurement, commodity managers, supply chain engineers, department managers, tool engineers, and tool technicians. They all work on ensuring operations are running daily and are directly affected by zero -bins. W ith everyone working towards meeting their own goals, it is difficult for everyone to have a universal understanding of the entire process to procure and use a spare part. After identifying the various factors contributing to zero -bins, the research question had to be simplified further. By selecting one major supplier at one primary manufacturing site, the scope of the project was narrowed. Figure 3.1 Part Availability Fishbone Diagram 12 Expert input was also taken into consideration when deciding the supplier and man ufacturing location. I obtained raw manufacturing data that reflected a year's worth of spare part usage with the major supplier over the last calen"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_27", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 27, "text": "to consideration when deciding the supplier and man ufacturing location. I obtained raw manufacturing data that reflected a year's worth of spare part usage with the major supplier over the last calendar year. Figure 3.1 illustrates the cause -and-effect relationships that ultimately lead to zero -bin. I make the following significant assumptions: 1) All documented part information is accurate 2) Suppliers can meet demand 3) Parts without a reorder point are not stocked in the warehouse, and therefore will not be reviewed 4) Data without all measured parameter s will not be considered. Within the supply chain, major domains such as logistics, part repositories, inaccurate data entry, tools reaching the end of life (EOL), and human error (such as shipping the wrong part) can all contribute to zero -bin inventory. I recognize there are miscellaneous events such as the Covid -19 pandemic or weather -related delays that can significan tly impact the supply chain at any point. DATA CLEANUP ‚Äì OUTPUT The data file was cleaned and reviewed in Python, using an integrated dev elopment environment (IDE) JupyterLab. The language and IDE were chosen for being a simple, popular language with sev"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_28", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 28, "text": "‚Äì OUTPUT The data file was cleaned and reviewed in Python, using an integrated dev elopment environment (IDE) JupyterLab. The language and IDE were chosen for being a simple, popular language with several resources available for reference. The following are the packages I used: Numpy, Pandas, Statsmodels, Matplo tlib, Sklearn, Scipy . A year 's worth of data for one supplier accumulated to 1.38 million lines of data. The data is arranged on a week -by-week basis where each unique part number has a record of the quantity available for that week. The data w ere merge d with a separate file that included the part's category and lead -time. Table 3.1 lists all the parameters identified in the combin ed data set. 13 Table 3.1: Parameters Parameters Python Code Name Description Site Site The l ocation part is used in manufacturing Supplier Supplier Company the part is purchased from PN PN Unique Part Number Cost UnitCost_Org Cost of purchasing part Reorder point (ROP) ROP_Org Quantity at which to order more inventory Quantity Available QtyAvailable_Org Current stock available Days on Inventory (DOI) DOI_Org Quantity available to support manufacturing for X days Workweek (W.W.) WW_Org Cal"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_29", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 29, "text": "ch to order more inventory Quantity Available QtyAvailable_Org Current stock available Days on Inventory (DOI) DOI_Org Quantity available to support manufacturing for X days Workweek (W.W.) WW_Org Calendar workweek (Ex. WW1 = first workweek of the year) Category A_Org, B_Org, C_Org, D_Org, J_Org, Q_Org, U_Org, Rating is given to part based on purchasing history Leadtime LeadTime_Org Amount of ti me to get part from the supplier to the warehouse Zero Bin (Predicted Value) ZB_Org Variable created to identify wheth er a part has zero bin for that W .W. Lag ZB_Lag Inventory available in the previous week The site and supplier columns were dropped as these are the same for every single line item in the file. A column called 'Z .B.' was created by using dummy variables to indicate whether the quantity available for that week was zero -bin (1) or not (0). Data entries where ROP = 0 indicated that the part is not stocked. These data points were dropped from the file. Data entries where DOI = 9999 are entries showi ng the part had not been consumed in a considerable amount of time were also dropped (they are not relevant to current inventory consumption patterns). At this point, 78,217 line"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_30", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 30, "text": "999 are entries showi ng the part had not been consumed in a considerable amount of time were also dropped (they are not relevant to current inventory consumption patterns). At this point, 78,217 lines of data with all the identified parameters remained in the file. Dummy varia bles were also made for the eight unique part categories. A lag column was created by subtracting one from the work week and margining the data onto itself to see the quantity available the previous week and us ing the 'lag' (whether quantity was zero or no t the previous week) in the regression. All unnecessary and repeated columns were removed. The suffixes '_Org' and '_ Lag1' were used to 14 differentiate betw een the original data and the lag data. All rows with any NaN values were also dropped. A CSV file wa s then printed and saved to facilitate the coding process. The final data file consisted of 61,544 rows of data. DATA VALIDATION A preliminary data review w as done after cleaning up the data file. Figure 3.2 represents the Histograms for ROP, Leadtime, and Unit Cost. _Org, UnitCost_Org, and LeadTime_Org . These parameters were selected to cluster with because once assigned to the unit , they do not"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_31", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 31, "text": "re 3.2 represents the Histograms for ROP, Leadtime, and Unit Cost. _Org, UnitCost_Org, and LeadTime_Org . These parameters were selected to cluster with because once assigned to the unit , they do not change ; QtyAvailable, DOI, W .W., all change . The categories were not considered for th e data validation analysis due to the variability between the percentage s. Figure 3.3 represents the boxplots , and Figure 3.4 depic ts the boxp lots for the same three parameters without any outliers . As presented, the plots do not communicate any valuable information. Trends and densities are challenging to understand in this format. Based on the histograms , the data does not seem to have any distribution, and all look like one uninformative cluster. However, as dispersed as the information Figure 3.2: Histograms with Outliers Figure 3.3: Box Plots with Outliers 15 Figure 3.4: Boxplot without Outliers Figure 3.5: Histogram against Log Scale is, all the data points are real -world and valid data. They should all be considered for a fair analysis. Figure 3.5 illustrates the histogram of the three parameters when placed against a log scale. The Figure 3.6: Silhouette Method Results 16 data seem"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_32", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 32, "text": " They should all be considered for a fair analysis. Figure 3.5 illustrates the histogram of the three parameters when placed against a log scale. The Figure 3.6: Silhouette Method Results 16 data seems to have a more defined distribution. This led to the idea of transforming the data to facilitate the analysis. Considering that most of the data had v ast ranges and that there was no way of knowing which way to classify the data based on the cur rent parameters, clustering was proposed. Figure 3.7: Elbow Method Plot Figure 3. 6 depicts the results of the Silhouette Method. D ata peaks at n=6 by just under .012 at n=5 0and .001 at n=7. Based on the silhouette method, the appropriate number of clusters can be defined as 6. However , the elbow method Figure 3. 7 was proposed because the silhouette scores are very close in value. The resulting graph has an inflection point (elbow) at k=5. Because the silhouette method's results were very close for n =5, n=6, and n=7, the results of both the silhouette and elbow method concluded with choosing 5 clusters K-MEANS The clusters were named based on the descriptive statistics and distinctive attributes per cluster. The descriptive statistics f"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_33", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 33, "text": " silhouette and elbow method concluded with choosing 5 clusters K-MEANS The clusters were named based on the descriptive statistics and distinctive attributes per cluster. The descriptive statistics for each cluster can be found in Appendix A. Descriptive statistics (appendix A) can be used to fit new data into each cluster. Each cluster's data was made into its own data frame to be used for modeling. Figure 3.7 depicts the data distribution between 17 each cluster. Leadtime and UnitCost heavily influence the behavior of the clusters. Table 3.2 illustrates the defining characteristics of each cluster. It is important to note that K-means presents different results every time it is run. Although I do only have 4 clusters, the number associated with each cluster changes every time. Therefore the best way to categorize each cluster is through descriptive statistics. Table 3.2 dep icts the classification of each cluster. Appendix A provides the descriptive statistics for each cluster. Although the number assigned to the cluster can change, the Figure 3.8: K-Means Clustering Results number of instances per cluster tend s to remain about the same. Table 3.2 provides the de scriptions use"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_34", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 34, "text": "ough the number assigned to the cluster can change, the Figure 3.8: K-Means Clustering Results number of instances per cluster tend s to remain about the same. Table 3.2 provides the de scriptions used to label the cl usters. I chose average cost and average lead time because these two parameters highly influence the cluster's behaviors , as seen in the boxplot s. The a verage cost is rounded to the nearest ten dollars, and lead time to the n earest day. Table 3.2: Cluster Descriptions Cluster ID Number of Instances Avg Cost Avg Lead Time A 80 $61,250 35 Days B 307 $20,860 48 Days C 1,596 $8,700 37 Days D 6,454 $2,530 38 Days E 53,107 $240 25 Days 18 Chapter 4: Results Each cluster was modeled three times using the following three modeling techniques: Logistic Regression, Lasso -based Logistic Regression, and kNN. This methodology resulted in 15 unique confusion matrices. The accuracy, recall, precision, and F -measure of each confusion matrix are analyzed to select the best-performing model. kNN was not the best model for any of the clusters. The Lasso - based Logistic regression outperformed in three of the five clusters. The classic Logistic regression outperformed in the two cl"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_35", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 35, "text": " model. kNN was not the best model for any of the clusters. The Lasso - based Logistic regression outperformed in three of the five clusters. The classic Logistic regression outperformed in the two clusters with the least number of data points . In trying to prevent zero - bins, the recall and precision of the model are very significant, making the F -measure a great way to compare amongst the three models. The significant parameters are Unit Cost, ROP, QtyAvailable, LeadTime, and QtyAvailable_Lag . Confusion Matrices I used all three predictive models (Logistic ‚Äì Lasso, kNN, and Logistic Regression) on each cluster. This resulted in a total of 15 confusion matrices , as show n in Figure 4.1. The sums on the right of each confusion matrix are the number of data points used in the confusion matrix. The matrices for the Logistic -Lasso and kNN used all of the data points in the cluster due to the k- fold analysis method. I applied t he SMOTE method to the Logistic Regression and therefore used fewer data points on this model. Table 3.2 in the D esign Experiment presents the number of data points in each cluster. To compare the results of each model regardless of the number of i nstan"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_36", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 36, "text": "e used fewer data points on this model. Table 3.2 in the D esign Experiment presents the number of data points in each cluster. To compare the results of each model regardless of the number of i nstances used, I calculated the Accuracy, Recall, Precision, and F -Measures. The results of these calculations are represented in Figure 4.2. Accuracy represents the number of accurately made predictions over the total number of predictions. Recall calculate s the number of true positives 19 Figure 4.1 Confusion Matrices Figure 4.2: Confusion Matrices Comparison divided by the number of correctly predicted positives and correctly predicted negatives. Precision 20 communicates how precise the model was in detecting the number of true positives divided by the number of all predicted positives. The F -Measure is the harmonic mean between Recall and Precision . The goal of this model is to accurately predict the number of zero -bins, whic h means the F -measure is a great way to compare results amongst the models. Figure 4.1 illustrates the advantage that the Logistic -Lasso regression has over kNN . The classic Logistic regression with Logistic -Lasso outperforms in clusters C, D, and E. Clas"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_37", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 37, "text": "ongst the models. Figure 4.1 illustrates the advantage that the Logistic -Lasso regression has over kNN . The classic Logistic regression with Logistic -Lasso outperforms in clusters C, D, and E. Class ic-Logistic regression beat kNN and Logistic -Lasso in clusters A and B. The most significant parameters in the Logistic -Lasso are outlined in table 4.1. Below is the probability equation based on the significant parameters for the Logistic regression , keep ing in mind that a shrinkage parameter of ùúÜ=.05 was used in modeling. ùëÉ(ZeroBin =1|ùë•ùëñ) =Œ¶(ùõΩ0+ùõΩ1‚àóùëàùëõùëñùë°ùê∂ùëúùë† ùë°ùëÇùëüùëî+ùõΩ2‚àóùëÖùëÇùëÉùëÇùëüùëî+ùõΩ3‚àóùëÑùë°ùë¶ùê¥ùë£ùëéùëñùëôùëéùëèùëô ùëíùëÇùëüùëî +ùõΩ4‚àóùêøùëíùëéùëëùëáùëñùëö ùëíùëÇùëüùëî+ùõΩ5‚àóùê¥ùëÇùëüùëî+ùõΩ6‚àóùêµùëÇùëüùëî+ùõΩ7‚àóùê∑ùëúùëüùëî+ùõΩ8 ‚àóùëÑùë°ùë¶ùê¥ùë£ùëéùëñùëôùëéùëèùëô ùëíùêøùëéùëî 1+ùõΩ9‚àóùê∑ùëúùëñùêøùëéùëî 1 (1) Table 4.1: Coefficients Table Parameter A B C D E UnitCost_Org 0.000125943 3.19E-05 4.61E-05 -4.95E-05 -2.45E-06 ROP_Org 00.00058304 0 0.072292 0.035833 QtyAvailable_Org 0-0.00320413 -3.97488 -6.08909 -6.52321 LeadTime_Org 0.0239108 0.016295 0.006828 0.00536062 -0.00142 A_Org=0 00.00020599 0 0 0 B_Org=0 0-0.00036556 0 0 0 D_Org=0 00.00015725 0 0 0 QtyAvailable_Lag1 0-0.00126622 0 0.003796 DOI_Lag1 -0.0294556 -0.0876153 -0.00471 -0.0014888 -0.00065 21 Chapter 5: Conclusions and Future Work This research is inspired"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_38", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 38, "text": " 0 0 D_Org=0 00.00015725 0 0 0 QtyAvailable_Lag1 0-0.00126622 0 0.003796 DOI_Lag1 -0.0294556 -0.0876153 -0.00471 -0.0014888 -0.00065 21 Chapter 5: Conclusions and Future Work This research is inspired by the COVID -19 supply chain issue s in the semiconductor industry. I conducted a case study with a major semiconductor manufacturing company and analyzed a year's worth of inventory data with one of its major suppliers. The dat a lent itself to a 5 cluster K -Means analysis. The clustered data was modeled using a classic Logistic regression, Lasso -based logistic regression, and a kNN regression. Lasso -based Logistic regression proved to be the overall best predictive model with the most significant parameters listed in table 431. Future work involves running the models on data that has not been tested or trained and evaluat ing how the models function. Once the models are further validated, the next step is optimizing the models and implementing them. Research Bias The Logistic -Lasso model proved to be a better fit for 3/5 clusters. This is because the Logistic -Lasso model implemented K -fold analysis. The model is more accurate in most of the clusters beca use all of the data w"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_39", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 39, "text": " model proved to be a better fit for 3/5 clusters. This is because the Logistic -Lasso model implemented K -fold analysis. The model is more accurate in most of the clusters beca use all of the data was used in the testing and training of the model. The same cannot be said of the kNN model. More work needs to be done to obtain the best K value for the model. In this case , the industry standard of K=5 was used. K-fold analysis was n ot used on the classic logistic regression ; instead , SMOTE , an oversampling techn ique, was used , and the Logistic -Lasso still managed to outperform the oversampled data. Future Work ROP is a very significant parameter . Therefore further research is needed to validate the current ROP calculation method. Cluster categories (A_Org, B_Org, D_Org) are only significant in one cluster and can be removed from the overall analysis. The QtyAvailable for the previous 22 week was only s ignificant for the smallest and largest cluster . Further analysis with more data is needed to understand whether this is significant. In trying to keep the scope of the research project to only predefined characteristics of a unit, more parameters shoul d be included in futu"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_40", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 40, "text": " data is needed to understand whether this is significant. In trying to keep the scope of the research project to only predefined characteristics of a unit, more parameters shoul d be included in future model analysis. The l ocality is where the unit is located. If the unit is in the same state as the manufacturing site, then the risk of the amount of time to respond to a po ssible zero -bin is much less than were that unit in a diffe rent country. The next step with the current model results is to run new data in the model by fitting this data into the descriptive statics of each cluster and assigning a cluster. Implementing the model and understanding how untrained and untested data r esponds to the models. 23 References Aggarwal, Charu C., and Chandan K. Reddy. Data Clustering: Algorithms and Applications . Chapman and Hall/CRC, 2018. Alva, Jalil Villalobos. Beginning Mathematica and Wolfram for Data Science: Applications in Data Analysis, Machine Learning, and Neural Networks . Apress, 2021. Ahmad, Imran. \"The Logic of k -Means Clustering.\" 40 Algorithms Every Programmer Should Know: Hone Your Problem -Solving Skills by Learning Different Algorithms and Their Implementation in "}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_41", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 41, "text": "ess, 2021. Ahmad, Imran. \"The Logic of k -Means Clustering.\" 40 Algorithms Every Programmer Should Know: Hone Your Problem -Solving Skills by Learning Different Algorithms and Their Implementation in Pytho n, Packt, Birmingham, AL, 2020, pp. 50 ‚Äì200. Alloghani M., Al -Jumeily D., Mustafina J., Hussain A., Aljaaf A.J. (2020) A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science. In: Berry M., Mohamed A., Yap B. (eds) S upervised and Unsupervised Learning for Data Science. Unsupervised and Semi -Supervised Learning. Springer, Cham. https://doi.org/10.1007/978 -3-030-22475 -2_1 Bertsimas, Dimitris, et al. \"Inventory Management in the Era of Big Data. \" Production and Operations Management , vol. 25, no. 12, 2016, pp. 2006 ‚Äì2009., https://doi.org/10.1111/poms.2_12637. Bonaccorso, Giuseppe. \"Machine Learning Algorithms - Second Edition.\" O'Reilly Online Learning , Packt Publishing, 2018, https://learning.oreilly.com/library/view/machine - learning -algorithms/9781789347999/00886023 -626e -404d -9dab -3b9a45ec1124.xhtml Bonnin, Rodolfo. ‚ÄúClustering.‚Äù Machine Learning for Developers , Packt Publishing, 2017. Brownlee, Jason. \"A Gentle Introd uctio"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_42", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 42, "text": "algorithms/9781789347999/00886023 -626e -404d -9dab -3b9a45ec1124.xhtml Bonnin, Rodolfo. ‚ÄúClustering.‚Äù Machine Learning for Developers , Packt Publishing, 2017. Brownlee, Jason. \"A Gentle Introd uction to k -Fold Cross -Validation.\" Machine Learning Mastery , 2 Aug. 2020, https://machinelearningmastery.com/k -fold-cross -validation/. Burkov, Andriy. \"Unsupervised Learning .\" The Hundred -Page Machine Learning Book , Andriy Burkov, Quebec City, Canada, 2 019, pp. 107 ‚Äì121. Dangeti, Pratap. \"Statistics for Machine Learning. \" O'Reilly Online Learning , Packt Publishing, https://learning.oreilly.com/library/view/statistics -for-machine/9781788295758/c71ea970 - 0f3c-4973 -8d3a -b09a7a6553c1.xhtml . De Santis, Rodrigo Barbosa, et al. \"Predicting Material Backorders in Inventory Management Using Machine Learning. \" 2017 IEEE Latin Ame rican Conference on Computational Intelligence (LA -CCI) , 2017, pp. 1 ‚Äì6., https://doi.org/10.1109/la -cci.2017.8285684. Garcia, Daniel J., and Fengqi You. \"Supply Chain Design and Optimization: Challenges and Opportunities. \" Computers & Chemical Engineering , vol. 81, Mar. 2015, pp. 153 ‚Äì170., https://doi.org/10.1016/j.compchemeng.2015.03.015. 24 Giannoc"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_43", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 43, "text": "upply Chain Design and Optimization: Challenges and Opportunities. \" Computers & Chemical Engineering , vol. 81, Mar. 2015, pp. 153 ‚Äì170., https://doi.org/10.1016/j.compchemeng.2015.03.015. 24 Giannoccaro, Ilaria, and Pierpaolo Pontrandolfo. \"Inventory Management in Supply Chains: A Reinforcement Learning Approach .\" International Journal of Product ion Economics , vol. 78, no. 2, 2002, pp. 153 ‚Äì161., https://doi.org/10.1016/s0925 -5273(00)00156 -0. Helper, Susan, and Evan Soltas. \"Why the Pandemic Has Disrupted Supply Chains. \" The White House , The United States Government, 30 Nov. 2021, https://www.whit ehouse.gov/cea/written -materials/2021/06/17/why -the-pandemic -has- disrupted -supply -chains/. James, Gareth, et al. An Introduction to Statistical Learning: With Applications in R . 2nd ed., Springer, 2021. Jayaswal, Vaibhav. \"Performance Metrics: Confusion Matrix, Precision, Recall, and F1 Score. \" Medium , Towards Data Science, 15 Sept. 2020, https://towardsdatascience.com/performance -metrics -confusion -matrix -precision -recall - and-f1-score -a8fe076a2262. K B, Praveen, et al. \"Inventory Management Using Machine Learning.\" International Journal of Engineering Research An"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_44", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 44, "text": "rmance -metrics -confusion -matrix -precision -recall - and-f1-score -a8fe076a2262. K B, Praveen, et al. \"Inventory Management Using Machine Learning.\" International Journal of Engineering Research And , vol. V9, no. 06, 2020, pp. 866 ‚Äì869., https://doi.org/10.17577/ijertv9is060661. Koh, L., Orzes, G. and Jia, F.(J). (2019), \"The fourth industrial revolution (Industry 4.0): technologies disruption on operations and supply chain management\", International Journal of Operations & Production Management, Vol. 39 No. 6/7/8, pp. 817 -828. https://doi.org/10.1108/IJOPM -08-2019 -788 Likas, Aristidis, et al. \"The Global K -Means Clustering Algori thm.\" Pattern Recognition, vol. 36, no. 2, 2003, pp. 451 ‚Äì461., https://doi.org/10.1016/s0031 -3203(02)00060 -2. Loskyll, Matthias, et al. \"Context -Based Orchestration for Control of Resource -Efficient Manufacturing Processes.\" Future Internet , vol. 4, no. 3, 2012, pp. 737 ‚Äì761., https://doi.org/10.3390/fi4030737. Nasr, Walid W., and Ibrahim J. Elshar. \"Continuous Inventory Control with Stochastic and Non - Stationary Markovian Demand. \" European Journal of Operational Research , vol. 270, no. 1, 2018, pp. 198 ‚Äì217., https://doi.org/10.1016/j.e"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_45", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 45, "text": "har. \"Continuous Inventory Control with Stochastic and Non - Stationary Markovian Demand. \" European Journal of Operational Research , vol. 270, no. 1, 2018, pp. 198 ‚Äì217., https://doi.org/10.1016/j.ejor.2018.03.023. Performance by Michael Keith, Machine Learning with Regression in Python: With Ordinary Least Squares, Ridge, Decision Trees and Neural Networks , Apress, a Springer Nature Company, Sept. 2020, https://learnin g.oreilly.com/videos/machine -learning - with/9781484265833/9781484265833 -Keith_Overview/. Accessed 2021. Rai, Khushwant. \"The Math behind Logistic Regression.\" Medium , Analytics Vidhya, 14 June 2020, https://medium.com/analytics -vidhya/the -math -behind -logistic -regression - c2f04ca27bca. 25 Romeral Jos eÃÅ Luis, A., O. R. R., & Prieto, D. M. (2020). Chapter 10 / Big Data Analytics and Its Applications in Supply Chain Manageme nt. In New trends in the use of Artificial Intelligence for the industry 4.0 (pp. 175 ‚Äì193). essay, IntechOpen. Singh, Aishwarya. ‚ÄúK -Nearest Neighbors Algorithm: KNN Regression Python.‚Äù Analytics Vidhya , 25 May 2020, https://www.analyticsvidhya.com/blog/2018/08/k -nearest -neighbor - introduction -regression -python/. Tibshirani, Rob"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_46", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 46, "text": "rest Neighbors Algorithm: KNN Regression Python.‚Äù Analytics Vidhya , 25 May 2020, https://www.analyticsvidhya.com/blog/2018/08/k -nearest -neighbor - introduction -regression -python/. Tibshirani, Robert. \"Regression Shrinkage and Selecti on via the Lasso: A Retrospective. \" Journal of the Royal Statistical Society: Series B (Statistical Methodology) , vol. 73, no. 3, 2011, pp. 273 ‚Äì282., https://doi.org/10.1111/j.1467 -9868.2011.00771.x. Tsai, Shing Chih, and Sin Ting Chen. \"A Simulation -Base d Multi -Objective Optimization Framework: A Case Study on Inventory Management. \" Omega , vol. 70, 2017, pp. 148 ‚Äì 159., https://doi.org/10.1016/j.omega.2016.09.007. Weyer, Stephan, et al. \"Towards Industry 4.0 - Standardization as the Crucial Challenge for Highly Modular, Multi -Vendor Production System.\" 15th IFAC Symposium OnInformation Control Problems in manufacturing , vol. 48, no. 3, 2015, pp. 1 ‚Äì6., https://doi.org/10.1016/j.ifacol.2015.06.143. Accessed 2021. Wong, Wai Peng. \"Decision Support Model for Inventory Management Using AHP Approach: A Case Study on a Malaysian Semiconductor Firm. \" California Journal of Oper ations Management , vol. 8, no. 2, Nov. 2010, pp. 55 ‚Äì71., https:"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_47", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 47, "text": "upport Model for Inventory Management Using AHP Approach: A Case Study on a Malaysian Semiconductor Firm. \" California Journal of Oper ations Management , vol. 8, no. 2, Nov. 2010, pp. 55 ‚Äì71., https://doi.org/www.researchgate.net/publication/266606613. 26 Appendix A Descriptive Statistics The following are the descriptive statistics for each cluster based on the three clustered parameters. Cluster Zero Descriptive Statistics Cluster One Descriptive Statistics 27 Cluster Two Descriptive Statistics Cluster Three Descriptive Statistics 28 Cluster Four Descriptive Statistics 29 Vita Yazmin Montoya earned her B.S. in Engineering Leadershi p 2017 , MBA 2018 , and Master of Systems Engineering 2021 from the University of Texas at El Paso. During her undergrad, she worked on biomedical engineering research in low-cost prosthetics. She also conducted research in engineering education and published two papers titled \"Student -led curriculum development and instruction of introduction to engineering leadership course \" and \"Developing Leaders by Putting Students in the Curriculum Development Driver Seat .\" She interned in oil and gas, aerospace, and mining. After earning her MBA, s he worked"}
{"id": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf::chunk_48", "source": "Predicting Zero Bin In The Semiconductor Manufacturing Industry_.pdf", "chunk_index": 48, "text": "ring leadership course \" and \"Developing Leaders by Putting Students in the Curriculum Development Driver Seat .\" She interned in oil and gas, aerospace, and mining. After earning her MBA, s he worked in several aspects of a supply chain in a copper mining company while pursuing her M aster of Systems Engineering degree with a focus on mod eling and simulation. She moved into program management after transition ing into the tech sector. She co -founded a nonprofit organization , 'Nontraditional College Success ,' where she helps students lan d their dream jobs."}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_0", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 0, "text": "ProÔ¨Åt Maximization through Process Variation Aware High Level Synthesis with Speed Binning Zhao Mengying City University of Hong KongOrailoglu Alex University of California, San DiegoXue Chun Jason City University of Hong Kong Abstract ‚ÄîAs integrated circuits continuously scale up, pro- cess variation plays an increasingly signiÔ¨Åcant role in system design and semiconductor economic return. In this paper, we explore the potential of proÔ¨Åt improvement under the inherent semiconductor variability based on the speed binning technique. We Ô¨Årst accordingly propose a set of high level synthesis techniques, including allocation, scheduling and resource binding, thus essentially constructing designs that maximize the number of chips that can be sold at the most advantageous price, leading to the maximization of the overall proÔ¨Åt. We explore subsequently the optimal bin placement strategy for further proÔ¨Åt improvement. Experimental results conÔ¨Årm the superiority of the high level synthesis results and the associated improvement in proÔ¨Åt margins. I. I NTRODUCTION With the continuous scaling of integrated circuits, fabri- cation size is shrinking in nanometer regimes. As a result, production t"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_1", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 1, "text": "ts and the associated improvement in proÔ¨Åt margins. I. I NTRODUCTION With the continuous scaling of integrated circuits, fabri- cation size is shrinking in nanometer regimes. As a result, production to ensure predictable performance can no longer be guaranteed. Transistor parameters, such as channel length, gate-oxide thickness and threshold voltage, deviate from nom- inal values, thus introducing ambiguities on the optimal course to be taken in processor design. Intel lab results show a twenty-fold variation in leakage power for a 30% variation in performance based on a design in 180nm technology [1]. When looked at from the vantage point of total power, a 40%-70% variation is associated with a 20%-50% variation in frequency, as [2] reports. Due to the transistor parameter Ô¨Çuctuations resulting from process variation, fabricated chips vary from each other in performance. Manufactured products of the same design may end up being used as high performance 1 GHz chips, or end up being used as lower-performance 600 MHz chips. In such a manufacturing environment, the issue of speed binning is brought to the forefront. Speed binning refers to the test procedures that help qualita- tively"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_2", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 2, "text": "d as lower-performance 600 MHz chips. In such a manufacturing environment, the issue of speed binning is brought to the forefront. Speed binning refers to the test procedures that help qualita- tively categorize working chips into different bins according to the highest speed test that they could pass, so that chips could be offered to customers with the appropriate frequency grades [3]. For instance, the MPC7455 microprocessor has been offered in 6 grades, i.e. 6 bins: 600, 733, 800, 867, 933 MHz and 1GHz [4]. Chips in different bins are correspondingly offered with various price grades, thus delivering distinct economic returns. The proÔ¨Åt is deÔ¨Åned as follows: Profit =income \u0000cost =n‚àë i=1pi\u0001ni\u0000cost (1) where nis the number of bins, piandnirepresent the price of the ithbin and the number of chips falling into this bin, and cost denotes the cost of the design. Figure 1 shows one example with 3 bins. The price is a stair-case function of Tclk delay. ProÔ¨Åt is maximized by intelligently distributing chipsinto bins for aggressive income and retaining a low design cost at the same time. As one indispensable step in system design, high level synthesis (HLS) translates the behavioral desc"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_3", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 3, "text": "istributing chipsinto bins for aggressive income and retaining a low design cost at the same time. As one indispensable step in system design, high level synthesis (HLS) translates the behavioral description into a corresponding register level structure description, including resource allocation (functional unit type selection), scheduling (assigning operations into clock steps) and binding (resource instance mapping) [5]. Due to the process variation, the concept of performance yield is developed and widely used as HLS optimization criterion. It describes the probability of a certain design meeting the predeÔ¨Åned performance constraints space [6], e.g. 90% performance yield means 90% of the chips statistically satisfy design constraints. A number of researchers conduct variation-aware HLS based on this yield theory to deal with process variation, like minimizing latency [7] [8] or area [9] while guaranteeing satisfactory performance yield. Our objective is to build a satisfactory circuit performance distribution ( Tclk) by HLS solutions, which determines the economic proÔ¨Åt in the context of speed binning. Fig. 1. Income calculation. The binning result is affected by all the system "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_4", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 4, "text": "it performance distribution ( Tclk) by HLS solutions, which determines the economic proÔ¨Åt in the context of speed binning. Fig. 1. Income calculation. The binning result is affected by all the system design levels. Prior work on proÔ¨Åt-aware design considers economic issues for proÔ¨Åt maximization at the circuit design level [10] [11], whereas we focus at HLS. In this paper, we explore the potential HLS approaches to strive for proÔ¨Åt improvement under process variation, and build up a set of HLS techniques to maximize the number of chips that can be sold at the most advantageous price, thus maximizing overall proÔ¨Åt. To the best of our knowledge, this is the Ô¨Årst work discussing speed binning in the context of embedded system processors. In particular, our contributions are summarized as follows: \u000fIntroduce speed binning into the HLS domain to derive maximal economic return. \u000fDevelop a set of HLS approaches for proÔ¨Åt maximization, including allocation, scheduling and binding. \u000fPropose a strategy for optimal bin placement. The remainder of this paper is organized as follows. Section II shows an example to illustrate how the HLS decisions affect economic proÔ¨Åt. Section III accordingly i"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_5", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 5, "text": "trategy for optimal bin placement. The remainder of this paper is organized as follows. Section II shows an example to illustrate how the HLS decisions affect economic proÔ¨Åt. Section III accordingly introduces proÔ¨Åt- aware HLS strategies. Section IV presents the optimal bin 978-3-9815370-0-0/DATE13/ c‚Éù2013 EDAA Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. selection approach. Section V presents the experimental setup and results. Section VI offers a brief set of conclusions. II. M OTIVATION In this section, we present an example to illustrate how the HLS decisions affect proÔ¨Åt, i.e. the difference between income and the expense associated in generating it. Figure 2(a) shows the given DFG and resource library. Each operation can be mapped to either of two types, mnemonically denoted as Fast and Slow . Figure 2(b) presents four distinct HLS solutions. S1achieves the best performance with the fastest modules. S2ignores process variation and is imple- mented with the lowest cost. However, when applied to speed binning, neither deliver a satisfactory proÔ¨Åt. Two bins are set: bin1 is set at "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_6", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 6, "text": " fastest modules. S2ignores process variation and is imple- mented with the lowest cost. However, when applied to speed binning, neither deliver a satisfactory proÔ¨Åt. Two bins are set: bin1 is set at a clock cycle delay of 9 and bin2 is set at 12, with the price of 200 and 70, respectively. All chips slower than 12 are discarded and deliver no economic return. Figure 2(c) lists the economic features. Though S2has the lowest implementation cost, due to the uncertainties resulting from process variation, 51% of the chips are discarded, and the other 49% are only eligible for the slower bin, resulting in a com- paratively lower income, which falls short of compensating for the cost and thus delivers no proÔ¨Åt. In contrast, S1derives the best income (with 100% eligible chips sold at the higher price), yet also with the most expensive design cost, resulting in an unsatisfactory proÔ¨Åt. Consequently, a tradeoff between high income and low cost should be taken into account for proÔ¨Åt optimization. In this case, by intelligently selecting the appropriate cost-effective components and an associated binding strategy, S3andS4attain various tradeoffs. Both of them deliver a quite high income, whi"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_7", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 7, "text": "n. In this case, by intelligently selecting the appropriate cost-effective components and an associated binding strategy, S3andS4attain various tradeoffs. Both of them deliver a quite high income, which not only sufÔ¨Åces to compensate for the comparatively high cost, but also delivers additional proÔ¨Åt. + < < ++ ++ < < ++ + S1 S2 S3+ < < ++ ++ < < ++ + S4+F_2+F_1 <F_1 <F_2 +F_1 +F_3+S_1 <S_1 <F_1 +S_1 +S_2+S_3+S_1 <F_1 <F_2 +S_1 +S_2 +F_1+F_1 <S_1 <F_1 +S_1 +F_1+S_2+/<: operation F/S: type, Fast or Slow _1/_2/_3: component number+ < < ++ + A B C DE F CCT=12 CCN=2 (a) (b) (c)Resource Library operations types +Delay (Œº,Œ¥ )cost S (6, 0.6) 15F (2, 0.2) 40+ + < S (4, 0.4) 6F (1, 0.1) 20< < Bin Setting: Bin1=9, Bin2=12 Bin Price: p(Bin1)=200, p(Bin2)=70 Fig. 2. HLS example. Clock cycle time=12. Clock cycle number=2. (a) DFG and settings. Each operation has two types: Fast and Slow. (b) Four possible HLS solutions. (c) Economic features of these four solutions. To sum it, as HLS steps, allocation decides the cost; scheduling and binding determine the income by intelligentlydistributing chips into various speed bins. In this paper, we explore the intertwined HLS solutions for the best tradeo"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_8", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 8, "text": "on decides the cost; scheduling and binding determine the income by intelligentlydistributing chips into various speed bins. In this paper, we explore the intertwined HLS solutions for the best tradeoff between income and cost so as to achieve proÔ¨Åt maximization. An optimal bin placement strategy is also proposed for further proÔ¨Åt improvement. III. P ROFIT -AWARE HLS UNDER PROCESS VARIATION In this section, we present the proÔ¨Åt-aware HLS considering process variation. Algorithm 1 ProÔ¨Åt-aware HLS under process variation. Input: DFG , Resource Library, price proÔ¨Åle P, bin setting Output: HLS solution for DFG 1:map all the operations to the fastest components 2:do scheduling; //objective: equalizing slacks of all clock cycles 3:while 1do 4: assign each node one corresponding nodePriority NP; 5: for each operation calculate the operationPriority OP; 6: operationToSlowDown =maxfOP(i)ji2operation of DFGg; 7: ifoperationToSlowDown < 0then 8: break; //no operation can be slowed down 9: else 10: slowDown( operationToSlowDown ); 11: end if 12:end while 13:do binding; //objective: resource sharing among critical paths among all clock cycles Intuitively, we start with the design with the highe"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_9", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 9, "text": ": slowDown( operationToSlowDown ); 11: end if 12:end while 13:do binding; //objective: resource sharing among critical paths among all clock cycles Intuitively, we start with the design with the highest income, by mapping all the operations to the fastest components, and then iteratively slow down some of them based on deÔ¨Åned priorities, until we pinpoint the best tradeoff between perfor- mance and cost, thus maximizing the proÔ¨Åt (Algorithm 1). The slowdown procedure is conducted for all clock cycles simultaneously. For example, if each clock cycle has one adder candidate to slow down, they should be degraded at the same time. Differentially slowing down a component across clock cycles consistently leads to guaranteed suboptimal solutions, as allocation is determined by the maximum cardinality of each type. Consequently, for one operation, only the global slowdown of a component in allclock cycles may conceivably deliver proÔ¨Åt1. The operation to slow down is selected by operation priority ( OP), which is computed based on node priority ( NP). We will apply the proposed HLS solutions on the example shown in Figure 2 for a detailed explanation. A. Equal-slacks guided scheduling As th"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_10", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 10, "text": "ity ( OP), which is computed based on node priority ( NP). We will apply the proposed HLS solutions on the example shown in Figure 2 for a detailed explanation. A. Equal-slacks guided scheduling As the initial allocation before scheduling, all the nodes are mapped to the fastest components, with traditional ASAP (as soon as possible) and ALAP (as late as possible) applied to determine mobilities for each node. Then scheduling assigns each node into an appropriate clock cycle. We deÔ¨Åne the nodeList of one clock cycle as the set of nodes it possibly holds. It is initialized with all nodes whose mobility spans the clock cycle in question. At each step, one unscheduled node will be removed from one of the nodeList s thus narrowing down the scheduling space. At termination, the nodeList s denotes the exact scheduling result for all the cycles. For a particular clock cycle, the most problematic case (with the smallest slack) would happen when the nodes in its nodeList are all scheduled in this cycle. A variable, denoted 1The strategy of uniformly degrading component performance can be relaxed when clock cycles do not fully utilize resources of the particular component type. Authorized li"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_11", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 11, "text": "is cycle. A variable, denoted 1The strategy of uniformly degrading component performance can be relaxed when clock cycles do not fully utilize resources of the particular component type. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. dangerSlack , is proposed to describe this characteristic. It is deÔ¨Åned as the slack of one clock cycle when all nodes in itsnodeList are scheduled into it. DangerSlack outperforms the real slack by considering the potential danger to clock cycles, because it considers not only the nodes that have been scheduled into this cycle, but also those having possibilities to be scheduled in. In the proposed strategy, scheduling starts from the most dangerous clock cycle, namely the one with the smallest dangerSlack, and excludes components out of itsnodeList to relieve the impact of overcrowding. Thus the excluded node loses one degree of freedom in its mobility and is eventually Ô¨Åxed to a particular clock cycle when only one possibility is left. Algorithm 2 Equal-slacks Guided Scheduling Input: an original DFG Output: theDFG with all nodes scheduled into appropria"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_12", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 12, "text": " eventually Ô¨Åxed to a particular clock cycle when only one possibility is left. Algorithm 2 Equal-slacks Guided Scheduling Input: an original DFG Output: theDFG with all nodes scheduled into appropriate clock cycles 1:apply ASAP and ALAP on the DFG 2:foreach clock cycle Cido 3: initialize available resource of Ciwith resource library; 4: initialize nodeList ofCi, the set of nodes having mobility across Ci, and corresponding startNodeList ,endNodeList ; 5:end for 6:while not all nodes are Ô¨Åxed do 7: //dangerSlack exclusion 8: foreach clock cycle Cido 9: derive dangerSlack ofCi; 10: end for 11: get the most dangerous clock cycle Cdanwith the smallest dangerSlack ; 12: Ô¨Ånd the functional unit FUexcto exclude ; 13: exclude FUexcfrom Cdan; 14: update nodeList ,startNodeList andendNodeList ofCdan; 15: update the ASAP or ALAP of related nodes accordingly; 16:end while Algorithm 2 describes the scheduling process. DangerSlack exclusion (Line 7-15) protects dangerous clock cycles that po- tentially have the smallest slack by excluding one component at each iteration. The functional unit (FU) to be excluded is chosen as follows (Line 12). Firstly, its exclusion should impose least impact on "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_13", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 13, "text": "ally have the smallest slack by excluding one component at each iteration. The functional unit (FU) to be excluded is chosen as follows (Line 12). Firstly, its exclusion should impose least impact on others, so it is chosen from either startNodeList orendNodeList of the danger cycle. Secondly, it is suboptimal to exclude one FU whose ASAP (or ALAP) is the danger step, since it imposes a signiÔ¨Åcant restriction for both itself and its successors (or predecessors). Last but not least, the exclusion should bring the current clock cycle the maximum delay reduction to get this cycle a bigger dangerSlack . Even, if no delay reduction can be obtained by excluding any component because of the parallelism, the exclusion may still be reasonable because delay reduction can possibly be attained in cognition with subsequent exclusions. Table I shows the scheduling procedure of the example in Figure 2. The scheduling result based on the DFG equipped with fastest components is shown in Figure 3(a). After scheduling, every node of the DFG will have been Ô¨Åxed into the appropriate clock cycle and the slacks of each clock step are at that point typically evenly distributed. In the following section, w"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_14", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 14, "text": "ter scheduling, every node of the DFG will have been Ô¨Åxed into the appropriate clock cycle and the slacks of each clock step are at that point typically evenly distributed. In the following section, we will introduce approaches to replace some of the modules with slower and cheaper module types. Prior to that, we expose the proÔ¨Åt beneÔ¨Åt measure of slowing one node, i.e. the node priority.TABLE I SCHEDULING PROCEDURE OF THE EXAMPLE IN FIGURE 2. G IVEN 2 CLOCK CYCLES . Step NodeList DangerSlack Action / Result 1 CC1 ABCDEF 4 exclude F / F Ô¨Åxed in CC2 CC2 ABCDEF 4 - 2 CC1 ABCDE 6 - CC2 ABCDEF 4 exclude A / A Ô¨Åxed in CC1 3 CC1 ABCDE 6 exclude D / D Ô¨Åxed in CC2 CC2 BCDEF 6 - 4 CC1 ABCE 6 exclude E / E Ô¨Åxed in CC2 CC2 BCDEF 6 - 5 CC1 ABC 8 - CC2 BCDEF 6 exclude B / B Ô¨Åxed in CC1 6 CC1 ABC 8 - CC2 CDEF 7 exclude C / C Ô¨Åxed in CC1 7 CC1 ABC CC2 DEF scheduling completed. + < < ++ ++A B C DE F+ < < ++ +++F_1 <S_1 +S_1 +S_2 +F_1<F_1A F (a)A B C DE FA (c) (d) (b)A B C DE FA2 2 2 11 1 Fig. 3. HLS decisions. (a) Scheduling. (b) Commonality Factors. (c) Allocation. (d) Binding. AandFshare the same adder . B. Node Priority (NP) Node priority of one vertex is developed to denote the potential proÔ¨Åt"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_15", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 15, "text": "ecisions. (a) Scheduling. (b) Commonality Factors. (c) Allocation. (d) Binding. AandFshare the same adder . B. Node Priority (NP) Node priority of one vertex is developed to denote the potential proÔ¨Åt beneÔ¨Åt when slowed down. When a node is replaced with a slower component, both the cost and income would potentially drop, with the proÔ¨Åt beneÔ¨Åt being determined by the severity of the individual decreases. NP =costReduction \u0000incomeReduction \u0003criticalFactor commonalityFactor (2) 1) CostReduction: The costReduction is the price differ- ence between the previously assigned fast type and its replace- ment. In the previous example, it would be 40\u000015 = 25 if the fast adder is replaced with the slow type. 2) IncomeReduction: Before deÔ¨Åning incomeReduction , we explore approaches to estimate income . Given the price proÔ¨Åle and bin settings, income is determined by the Tclkdistribution. However, it is hard to derive the exact Tclkdistribution without allocation, scheduling and binding information from HLS. Based on the fact that Tclkis mainly decided by the critical path, we approximate Tclkby the expectation delay of the critical paths of each clock cycle. In the income estimation, the Tclkd"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_16", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 16, "text": " from HLS. Based on the fact that Tclkis mainly decided by the critical path, we approximate Tclkby the expectation delay of the critical paths of each clock cycle. In the income estimation, the Tclkdistribution is assumed to follow a Gaussian distribution (\u0016; \u001b) with \u001b=\u0016 = 0:1. We choose Gaussian because com- ponent delays are widely estimated as Gaussian distributions and the circuit SSTA result can accurately be approximated by Gaussian distributions [12]. TABLE II Tclk-INCOME ESTIMATION TABLE FOR incomeReduction ESTIMATION Tclk(10\u000010s)‚â§6 7 8 9 10 11 12 income (price unit) 200 199 186 134 89 62 36 Table II shows the estimation with settings in Figure 2. For example, with clock cycle time being 12 and two bins set at Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. 9, 12 respectively, when the expectation delay of the critical path is 8, the income is estimated by Tclkfollowing ( 8;0:82), which computes to 186. Note the critical path here refers to the longest path in one clock cycle instead of the whole DFG. Thus the incomeReduction is deÔ¨Åned as the income differ- ence between critical"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_17", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 17, "text": "hich computes to 186. Note the critical path here refers to the longest path in one clock cycle instead of the whole DFG. Thus the incomeReduction is deÔ¨Åned as the income differ- ence between critical path delays of the current clock cycle before and after one node slowing down. In this example, if Ais slowed down, the duration of the critical path ‚ÄòA-B-C‚Äô would increase from 4 to 8, resulting in incomeReduction = income (4)\u0000income (8) = 14 . 3) Critical Factor (criF): CriF , ranging in [0,1], represents the impact on the critical path delay of this slowdown. CriF = 1means the node is in the critical path and its slowdown directly results in the income reduction. criF =max fdelay ofpaths that contain this node g delay ofthecritical path ofDFG (3) Due to process variation and multi-types for each operation, the critical path is not readily recognizable. Our solution is to derive the expectation delay of one component under process variation. It is derivable because the delays follow certain delay distributions, either Gaussian or non-Gaussian. As we map all the nodes to the fastest components at Ô¨Årst and then slow them down, at each step, the module type is determined. In this way, "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_18", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 18, "text": "tain delay distributions, either Gaussian or non-Gaussian. As we map all the nodes to the fastest components at Ô¨Årst and then slow them down, at each step, the module type is determined. In this way, the delays of each path can be calculated and then used for criF calculation. For node Ain this example, criF = 1because the longest path containing Ais ‚ÄòA-B-C-E- F‚Äô, which is exactly the critical path of this DFG. 4) Commonality Factor (comF): For a vertex, to measure how much its replacement with a slower component is go- ing to prevent other vertices in the DFG from also being replaced by slower components, we apply the identical concept ofcommonality factor proposed in [13]. In Figure 3(b), comF (C)> comF (E)since the slowdown of Cprevents all others‚Äô slowdown, whereas the slowdown of Estill gives a chance to Dbecause of their parallelism2. Based on all the previously deÔ¨Åned variables: NP(A) =25\u0000(income (4)\u0000income (8))\u000312 12 2= 5.5; NP(B)=NP(C) =14\u0000(income (4)\u0000income (7))\u000311 11 2= 6.5. Similarly, NP(D) = 25 ;NP(E) = NP(F) = 11 . C. Component slowdown based on Operation Priority (OP) OPis the criterion of choosing the operation to slow down. It is determined as the minimal positive "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_19", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 19, "text": " Similarly, NP(D) = 25 ;NP(E) = NP(F) = 11 . C. Component slowdown based on Operation Priority (OP) OPis the criterion of choosing the operation to slow down. It is determined as the minimal positive NPof nodes belonging to this operation, implying the lower bound of the proÔ¨Åt beneÔ¨Åt of degrading this operation globally. In the previous example: OP(<)=min fNP(B), NP(C) g=6.5; OP(+)=min fNP(A), NP(D), NP(E), NP(F) g=5.5. The operation to slow down would be the one with the biggest OP, i.e. ‚Äò<‚Äôin this example. According to the pro- cedure described in Algorithm 3, at each clock cycle, among all the components of <, the one having the biggest NPis picked to slow down. In cycle 1, BandChave the same NP and we replace Bwith one slow unit. Clock cycle 2 has no < operation and is thus not subject to component degradation. Past the Ô¨Årst iteration, the algorithm would encounter NP(A) =\u000056;NP(C) =\u000048;NP(D) = 25 ;NP(E) = NP(F) = 11 . So ‚Äò+‚Äôis chosen as the slowdown operation 2The detailed derivation of comF can be found in [13].and component Dis degraded to the slow type. Notice that the negative NPindicates that the reduction in income can not compensate the reduction in cost, degrading proÔ¨Å"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_20", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 20, "text": "ion of comF can be found in [13].and component Dis degraded to the slow type. Notice that the negative NPindicates that the reduction in income can not compensate the reduction in cost, degrading proÔ¨Åt. After another slowdown iteration, in which Eis degraded to the slow type, all the NPs become negative, indicating that the allocation has been completed, as shown in Figure 3(c). Algorithm 3 SlowDown Input: DFG , operation to slow down oper picked based on OP 1:foreach clock cycle jofDFG do 2: ifthere are components of operation oper then 3: node the one with biggest NPin all oper components; 4: t= module type of node ; 5: m= currently occupied resource # of operation oper, type t in cycle j; 6: end if 7:end for D. Binding The binding procedure maps the operations to particular hardware resources. Our objective is the resource sharing among different clock cycles, so as to tighten the correlations among all cycles, which beneÔ¨Åts the performance according to timing analysis. The longest path dominates Tclk, so nodes in the longest paths from all clock cycles ideally should be merged into the same hardware as much as possible. To implement this approach, each clock step maintains one "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_21", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 21, "text": "path dominates Tclk, so nodes in the longest paths from all clock cycles ideally should be merged into the same hardware as much as possible. To implement this approach, each clock step maintains one longPath , which is the longest path in this cycle with at least one component unbound. Among the longPath s of all clock cycles, the longest one is referred to as the criticalPath of the Ô¨Çow graph. The objective of the binding algorithm is to match the same FU-instance mapping between all other longPath s and the criticalPath . The match starts from the biggest unbound component in the criticalPath , because it has the biggest criticality to determine the chip frequency. So it is assigned one current available resource. Then for every longPath , if there is one unbound component that shares the same type with the Ô¨Årst assigned one, it will be matched to the same instance if the resource is available. After each mapping iteration, the criticalPath andlongPath s are updated, to replace paths that have completed binding with the second longest one. The binding result of the previous example is shown in Figure 3(d), which can be seen to be S4in Figure 2(b). IV. O PTIMAL BIN PLACEMENT In t"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_22", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 22, "text": "s that have completed binding with the second longest one. The binding result of the previous example is shown in Figure 3(d), which can be seen to be S4in Figure 2(b). IV. O PTIMAL BIN PLACEMENT In this section we present the optimal bin placement strategy under the assumption that the bin placement can be adjusted by designers. The optimal bin placement problem is deÔ¨Åned as follows. Given the circuit Tclkdistribution D, the price proÔ¨Åle P and the desirable bin number n, to Ô¨Ånd the corresponding n places for the bin setting, so as to maximize proÔ¨Åt. In this problem formulation, system design is assumed to have been completed, implying that the exact Tclkdistribution has been derived and the cost is Ô¨Åxed. ProÔ¨Åt maximization is consequently solely converted to income maximization, which is implemented by adjusting bin positions and thus chip numbers in each bin based on the cognizant Tclkdistribution (Equation 1). If the number of bins is not restricted, the ideally maximal income would be derived with inÔ¨Ånite bins, as every chip is then placed in an individual bin and sold at the most advantageous price. The ideal income is calculated by the Authorized licensed use limited to: Hoch"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_23", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 23, "text": " be derived with inÔ¨Ånite bins, as every chip is then placed in an individual bin and sold at the most advantageous price. The ideal income is calculated by the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. convolution of circuit distribution and price: Income = convolution (D; P ). Figure 4 shows that the Income rises at various rates for different delay regions. For example, in [7, 9] the proÔ¨Åt rises sharply, which means that setting a bin here beneÔ¨Åts more than setting one in the range [9, 11]. The bin density in a certain range is directly determined by the proÔ¨Åt improvement. Algorithm 4 Optimal bin boundary selection (OBBS). Input: circuit Tclkdistribution D, price proÔ¨Åle P, bin number n Output: bin boundaries BB 1:Income =convolution( D,P);//derive the ideal income 2:a=min( Income ); 3:b=max( Income ); 4:equally divide region [ a,b] by n-1 boundaries, stored in R; 5:Income‚Äô =inverse( Income );//derive the inverse function of Income 6:fori=1:n-1 do 7: BB(i) =Income‚Äô(R(i)) ; 8:end for 9:in [BB(n-1) ,b], Ô¨Ånd a boundary pthat makes set BB(1:n-1)[p give highest income; //determine the "}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_24", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 24, "text": "Income );//derive the inverse function of Income 6:fori=1:n-1 do 7: BB(i) =Income‚Äô(R(i)) ; 8:end for 9:in [BB(n-1) ,b], Ô¨Ånd a boundary pthat makes set BB(1:n-1)[p give highest income; //determine the last bin 10:BB(n) =p; Algorithm 4 presents the optimal bin selection strategy (OBBS). After deriving the ideal Income function (Line 1), theIncome region is equally divided into npartitions, where ndenotes the bin number. These corresponding partition boundaries, calculated by the inverse function of Income , are selected as bins. Note that the last bin is somewhat special. If it is selected at the rightmost boundary, which is close to the clock cycle time, almost all the remaining chips would fall into this bin. It delivers a good economic return when the price curve is Ô¨Çat. However, when the price curve is sharp in this region, placing the last bin at the biggest delay results in a much lower bin price, which signiÔ¨Åcantly degrades the chip values in the last bin. To handle this, we use the exhaustive search for the last bin in range [2nd-last-bin, clock-cycle-time] (Line 4 - 10). The last bin then will typically be selected as somewhat in the middle of this region when the price curv"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_25", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 25, "text": "he exhaustive search for the last bin in range [2nd-last-bin, clock-cycle-time] (Line 4 - 10). The last bin then will typically be selected as somewhat in the middle of this region when the price curve is sharp and the exact clock cycle time when the price is extremely Ô¨Çat. Figure 4 illustrates the OBBS for S4in Figure 2(b) when 3 bins are needed. Fig. 4. OBBS for S4in Figure 2(b). Given bin number n=3. Based on the fact that the bins are essentially selected as the tradeoff between chip numbers in each bin and the bin price, the algorithm places bins according to the derivative of the ideal Income function. The algorithm can be understood as follows. First, we derive the derivative curve of Income , and tend to put more bins in the range with bigger derivative values. Then we distribute the bins proportionally according to the area under the derivative curve, as the integral of the derivative function would signify the original Income . Consequently, the bins are selected as the boundaries of the equal division of the Income range.V. E XPERIMENTS We have tested the proposed design approaches on the same HLS benchmarks used in [14]. They provide a representative spectrum because of"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_26", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 26, "text": "aries of the equal division of the Income range.V. E XPERIMENTS We have tested the proposed design approaches on the same HLS benchmarks used in [14]. They provide a representative spectrum because of the differences in size and parallelism ( nodes/critical path ). We adopt the price proÔ¨Åle of Intel Prescott processors, which is simulated from the data given in [10]. p= 0:0000139 \u0003e3:384\u0003fre+ 1:473; (4) where fredenotes the labeled speed of one chip when sold. A. Evaluation of the proÔ¨Åt-aware HLS under process variation The proposed strategy is both process variation aware and proÔ¨Åt aware, which is denoted as double-aware ( DA). To evaluate the necessity of process variation awareness, we compare the proÔ¨Åt derived by the proposed DAstrategy with process variation unaware ( PV-unA ) approach. To conÔ¨Årm the importance of tradeoff between income and cost, we also compare the proÔ¨Åt performance between DAand performance- yield-optimization ( PYO) based method. The PV-unA method is implemented by aggressive schedul- ing and blind binding. The aggressive scheduling step sched- ules components to the current clock cycle as long as the overall delay is smaller than the clock cycle time. The"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_27", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 27, "text": "ed by aggressive schedul- ing and blind binding. The aggressive scheduling step sched- ules components to the current clock cycle as long as the overall delay is smaller than the clock cycle time. The blind binding step matches available components to operations in de- scending speed order and subject to the constraint of ensuring no timing constraint violations in the clock cycle. The PYO strategy maximizes the chip numbers in the most expensive bin. It selects the components with best performance, performs equal-slack guided scheduling and maximizes the resource sharing among critical paths of all the clock cycles in binding. Monte Carlo methods are applied to simulate the inherent correlations between clock cycle distributions that share the same resource. To make the experiment consistent and efÔ¨Å- cient, for all test benches, the clock cycle time is chosen to be18, with the two bins set at 14 and 18, respectively. TABLE III PROFIT IMPROVEMENT WITH COMPONENTS FOLLOWING GAUSSIAN DELAY DISTRIBUTIONS . test Clock cycle time = 18. Bin setting: (14, 18). Bench proÔ¨Åt proÔ¨Åt improvement (%) PV-unA PYO DA DA v.s. PV-unA DA v.s. PYO ARF 0.67 0.90 0.98 46.6 8.9 EWF 0.66 0.96 1.10 67.2 14.6"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_28", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 28, "text": "Y DISTRIBUTIONS . test Clock cycle time = 18. Bin setting: (14, 18). Bench proÔ¨Åt proÔ¨Åt improvement (%) PV-unA PYO DA DA v.s. PV-unA DA v.s. PYO ARF 0.67 0.90 0.98 46.6 8.9 EWF 0.66 0.96 1.10 67.2 14.6 Cos1 0.58 0.70 0.93 61.5 32.4 Cos2 0.55 0.77 0.86 56.4 12.0 jWBH 0.48 0.60 0.76 60.4 26.6 mMM 0.39 0.56 0.66 68.0 18.9 jFDCT 0.79 1.16 1.44 83.9 24.4 Average 63.4 19.7 Table III shows the proÔ¨Åt improvement with components following Gaussian distributions. On average, the proposed DA has a 63.5% proÔ¨Åt improvement in comparison to PV-unA , and a 19.7% improvement in comparison to the PYO method. The improvement over PV-unA beneÔ¨Åts from the handling with process variation, whereas the advantage over PYO results from design cost reduction. Take jFDCT , for example. Due to the process-variation-unaware strategy, PV-unA aggressively schedules too many components in one clock cycle, resulting in only 59% of the chips eligible for Bin2 and no chip in Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. Bin1. Evidently the low income is the reason for unsatisfactory proÔ¨Åt. PYO achieves the highest income"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_29", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 29, "text": " Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply. Bin1. Evidently the low income is the reason for unsatisfactory proÔ¨Åt. PYO achieves the highest income but is also equipped with the most expensive cost.DAslows down 27% of the components used by PYO, thus signiÔ¨Åcantly lowering the cost. At the same time, it keeps 98% chips sold at the higher price and the other 2% falling into the second bin, thus retaining a satisfactory income . TABLE IV PROFIT IMPROVEMENT WITH COMPONENTS FOLLOWING NON GAUSSIAN (UNIFORM AND TRIANGLE )DELAY DISTRIBUTIONS . test proÔ¨Åt improvement (%) Bench nonGaussian-Uniform nonGaussian-Triangle DAv.s.PV-unA DAv.s.PYO DAv.s.PV-unA DAv.s.PYO ARF 44.8 7.5 54.1 8.6 EWF 66.5 14.0 67.1 22.9 Cos1 60.9 31.1 61.4 47.1 Cos2 55.8 11.5 67.4 13.4 jWBH 80.9 45.9 71.8 41 mMM 68.6 19.2 80.0 20.3 jFDCT 84.6 24.8 89.6 28.9 Average 66.0 22.0 70.2 26.0 We also conduct the identical experiments with compo- nents that follow a non-Gaussian delay distribution, shown in Table IV. Comparing with PV-unA andPYO,DAachieves 66.0% and 22.0% for Uniform component distributions; 70.2% and 26.0% for Triangle distributions. This evinces that the pro"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_30", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 30, "text": "elay distribution, shown in Table IV. Comparing with PV-unA andPYO,DAachieves 66.0% and 22.0% for Uniform component distributions; 70.2% and 26.0% for Triangle distributions. This evinces that the proposed HLS approach is suitable for both Gaussian and non-Gaussian distributions and superior at dealing with big variations, furthermore. B. Evaluation of the optimal bin placement One previous work also presents a heuristic of the optimal bin placement for proÔ¨Åt maximization, in which the bins are initialized by equally dividing the performance yield and the bins are shifted gradually until no proÔ¨Åt improvement can be observed [10]. We refer to it as EY (equal-yield based) approach in this paper. Though we have the same problem deÔ¨Ånition, the EY strategy is applicable only when Tclkfollows a Gaussian distribution. In contrast, the proposed OBBS (optimal bin boundary selection) method is suitable for any kind of dis- tribution. In order to compare with the EY strategy, we Ô¨Årst evaluate the OBBS with Gaussian distributions, and then test it on the benchmarks with complicated non-Gaussian Tclkdistributions, to evaluate the proÔ¨Åt compared with the exhaustive bin boundary search. TABLE V I"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_31", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 31, "text": " OBBS with Gaussian distributions, and then test it on the benchmarks with complicated non-Gaussian Tclkdistributions, to evaluate the proÔ¨Åt compared with the exhaustive bin boundary search. TABLE V INCOME RESULT FOR GAUSSIAN DISTRIBUTIONS (\u0016,\u001b).\u0016= 10 . \u001b= 0:8 \u001b= 1:0 \u001b= 1:2 Bin# n=2 n=4 n=10 n=2 n=4 n=10 n=2 n=4 n=10 EY [10] 4.17 5.17 6.13 4.23 5.35 6.49 4.32 5.59 6.96 OBBS 4.46 5.47 6.33 4.43 5.65 6.81 4.51 6.00 7.49 optimal 4.48 5.48 6.36 4.44 5.67 6.83 4.52 6.01 7.50 Table V presents the income results for Gaussian distribu- tions. Without loss of generality, we set the mean as 10 and test various deviations. The results show that the proposed OBBS strategy has a 5.7% income improvement on average in comparison to the EY method and always performs better than 99.5% of the optimal results. OBBS outperforms EY more signiÔ¨Åcantly with severe process variation (bigger \u001b=\u0016) and more bins.We also apply OBBS on test benches HLS solutions. To evaluate the proÔ¨Åt performance, exhaustive search is conducted to obtain the optimal bin placement. Figure 5 presents the proÔ¨Åt relative to the optimal solution, implying 98.9% of the optimal solution on average. Fig. 5. ProÔ¨Åt relative to the optima"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_32", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 32, "text": " is conducted to obtain the optimal bin placement. Figure 5 presents the proÔ¨Åt relative to the optimal solution, implying 98.9% of the optimal solution on average. Fig. 5. ProÔ¨Åt relative to the optimal bin placement, when applying OBBS on test benches. VI. C ONCLUSION In this paper, we introduce speed binning into the HLS do- main to help derive maximal economic return. Taking process variation into account, we develop a set of HLS approaches for proÔ¨Åt maximization, including allocation, scheduling and binding. Experimental results conÔ¨Årm the superiority of HLS results and the associated improvement in proÔ¨Åt margins, when said components follow Gaussian, Uniform and Triangle delay distributions. We also propose an optimal bin boundary selection (OBBS) algorithm, delievering a near-optimal perfor- mance. To sum it, this paper constructs both process variation aware and proÔ¨Åt aware HLS designs in the context of speed binning, delivering maximal economic proÔ¨Åt. ACKNOWLEDGMENT This work is partially supported by grants from the Research Grants Council of the Hong Kong Special Administrative Region, China [Project No. CityU 123811 and 123210]. REFERENCES [1] T. Karnik, S. Borkar, and V."}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_33", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 33, "text": " partially supported by grants from the Research Grants Council of the Hong Kong Special Administrative Region, China [Project No. CityU 123811 and 123210]. REFERENCES [1] T. Karnik, S. Borkar, and V. De, ‚ÄúSub-90 nm technologies-challenges and opportunities for cad,‚Äù in ICCAD , 2002, pp. 203‚Äì206. [2] R. Teodorescu and J. Torrellas, ‚ÄúVariation-aware application scheduling and power management for chip multiprocessors,‚Äù in ISCA , 2008, pp. 363‚Äì374. [3] B. Cory, R. Kapur, and B. Underwood, ‚ÄúSpeed binning with path delay test in 150-nm technology,‚Äù IEEE Design and Test of Computers , vol. 20, pp. 41‚Äì45, 2003. [4] D. Belete, A. Razdan, W. Schwarz, R. Raina, C. Hawkins, and J. More- head, ‚ÄúUse of DFT techniques in speed grading a 1 GHz+ microproces- sor,‚Äù in ITC, 2002, pp. 1111‚Äì1119. [5] D. D. Gajski, N. D. Dutt, A. C.-H. Wu, and S. Y.-L. Lin, High-level synthesis: introduction to chip and system design . Kluwer, 1992. [6] F. Wang, C. Nicopoulos, X. Wu, Y. Xie, and N. Vijaykrishnan, ‚ÄúVariation-aware task allocation and scheduling for MPSoC,‚Äù in ICCAD , 2007, pp. 598‚Äì603. [7] Y. Chen, J. Ouyang, and Y. Xie, ‚ÄúILP-based scheme for timing variation- aware scheduling and resource binding,‚Äù in"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_34", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 34, "text": "on-aware task allocation and scheduling for MPSoC,‚Äù in ICCAD , 2007, pp. 598‚Äì603. [7] Y. Chen, J. Ouyang, and Y. Xie, ‚ÄúILP-based scheme for timing variation- aware scheduling and resource binding,‚Äù in International SOC Confer- ence, 2008, pp. 27‚Äì30. [8] J. Jung and T. Kim, ‚ÄúScheduling and resource binding algorithm considering timing variation,‚Äù IEEE Transactions on Very Large Scale Integration (VLSI) Systems , vol. 19, pp. 205‚Äì216, 2011. [9] F. Wang, Y. Xie, and A. Takach, ‚ÄúVariation-aware resource sharing and binding in behavioral synthesis,‚Äù in ASPDAC , 2009, pp. 79‚Äì84. [10] A. Datta, S. Bhunia, J. H. Choi, S. Mukhopadhyay, and K. Roy, ‚ÄúSpeed binning aware design methodology to improve proÔ¨Åt under parameter variations,‚Äù in ASPDAC , 2006, pp. 712‚Äì717. [11] A. Davoodi and A. Srivastava, ‚ÄúVariability driven gate sizing for binning yield optimization,‚Äù IEEE Transactions on Very Large Scale Integration (VLSI) Systems , vol. 16, pp. 683‚Äì692, 2008. [12] A. Datta, S. Bhunia, S. Mukhopadhyay, N. Banerjee, and K. Roy, ‚ÄúStatistical modeling of pipeline delay and design of pipeline under process variation to enhance yield in sub-100nm technologies,‚Äù in DATE , 2005, pp. 926‚Äì931. [13] S. Baks"}
{"id": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf::chunk_35", "source": "Profit_maximization_through_process_variation_aware_high_level_synthesis_with_speed_binning.pdf", "chunk_index": 35, "text": ", N. Banerjee, and K. Roy, ‚ÄúStatistical modeling of pipeline delay and design of pipeline under process variation to enhance yield in sub-100nm technologies,‚Äù in DATE , 2005, pp. 926‚Äì931. [13] S. Bakshi and D. Gajski, ‚ÄúComponent selection for high-performance pipelines,‚Äù IEEE Transactions on Very Large Scale Integration (VLSI) Systems , vol. 4, pp. 181‚Äì194, 1996. [14] J. Jung and T. Kim, ‚ÄúTiming variation-aware high-level synthesis con- sidering accurate yield computation,‚Äù in ICCD , 2009, pp. 207‚Äì212. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:04:40 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_0", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 0, "text": "The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 https://doi.org/10.1007/s00170-025-15685-7 ORIGINAL ARTICLE Recognition and ranking using similarity on defective wafer bin maps YoungWook Kwon1¬∑SuMin Oh1¬∑HyunJin Kim1 Received: 2 November 2024 / Accepted: 5 May 2025 / Published online: 10 May 2025 ¬© The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2025 Abstract As semiconductor manufacturing technology has been rapidly advanced, conventional approaches cannot classify new waferdefect patterns without retraining. To overcome this, we propose an image matching-based pattern search method to analyze the similarity between the wafer defect patterns using new pre-processing and similarity metrics. The proposed search method Ô¨Ånds the correlation of wafer defect patterns to determine the similarity value between wafer bin maps (WBMs). The pre-processing performs the denoising to reduce the effects of non-signiÔ¨Åcant defect patterns. Besides, we propose two metrics for performing robust pattern searches based on the shape, location, and area of defect patterns. Experimental results show that the proposed method "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_1", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 1, "text": "t defect patterns. Besides, we propose two metrics for performing robust pattern searches based on the shape, location, and area of defect patterns. Experimental results show that the proposed method is effective on industrial-driven datasets WM-811K and MixedWM38, having signiÔ¨Åcant beneÔ¨Åtsof the pre-processing and similarity metrics in the search for various defect patterns. Keywords Deep learning ¬∑Image matching ¬∑Semiconductor manufacturing ¬∑Wafer defect patterns ¬∑Mixed pattern detection ¬∑ Single pattern detection 1 Introduction After electrical testing in semiconductor manufacturing,defects are visualized on wafer bin maps (WBMs). By ana- lyzing recurring defect patterns on WBMs, engineers can diagnose problematic processes [ 1]. Furthermore, as semi- conductor manufacturing processes become more complex, the importance of accurate defect pattern analysis contin- ues to grow [ 2]. Conventional methods for defect pattern analysis are categorized into two main approaches: Super-vised and unsupervised learning. Supervised learning-based methods achieve high accuracy and have been widely applied in defect detection tasks. Recent studies have explored deeplearning-based classiÔ¨Åcation"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_2", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 2, "text": "and unsupervised learning. Supervised learning-based methods achieve high accuracy and have been widely applied in defect detection tasks. Recent studies have explored deeplearning-based classiÔ¨Åcation methods [ 3‚Äì8], achieving state- Y oungWook Kwon and SuMin Oh contributed equally to this work. B HyunJin Kim hyunjin2.kim@gmail.com Y oungWook Kwon kyw96@naver.com SuMin Oh osm040836@gmail.com 1Department of Electronics and Electrical Engineering,Dankook University, 152, Jukjeon-ro, Suji-gu, Y ongin-si16890, Gyeonggi-do, Republic of Koreaof-the-art performance. However, these methods require large amounts of labeled data, which are time-consuming and labor-intensive. Furthermore, semiconductor defect datasetsoften suffer from data imbalance, where certain defect pat- terns are signiÔ¨Åcantly outnumbered by other patterns [ 9,10]. This leads to model bias and reduced detection accuracy.Most of all, technological advances increase the diversity of defect patterns, further complicating the labeling process and requiring frequent model retraining to maintain performance. On the other hand, unsupervised learning-based methods have been proposed to reduce reliance on labeled data [ 11‚Äì 14]. "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_3", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 3, "text": "beling process and requiring frequent model retraining to maintain performance. On the other hand, unsupervised learning-based methods have been proposed to reduce reliance on labeled data [ 11‚Äì 14]. These methodologies have demonstrated potential in identifying novel defect patterns and addressing the emer-gence of diverse defects. However, they rely on statistical distributions which should be predeÔ¨Åned using domain knowledge from expertise in the Ô¨Åeld [ 15]. In addition, the limited interpretability of unsupervised learning makes it difÔ¨Åcult for engineers to validate the detected patterns and integrate them into manufacturing processes. Recently, similarity-based methods have been widely studied [ 16‚Äì19] to overcome these limitations of traditional methods. By comparing defect patterns using similarity met- rics such as Euclidean distance, engineers can search andanalyze similar defects from the dataset. In other words, iden- tifying and searching for similar defect patterns enables rapid analysis of recurring defects without relying on labeled data 123 2140 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 and domain knowledge. Recent studies h"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_4", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 4, "text": " rapid analysis of recurring defects without relying on labeled data 123 2140 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 and domain knowledge. Recent studies have adopted vari- ous feature extraction techniques and similarity metrics toimprove search accuracy. However, despite their attempts, existing similarity-based methods still face key challenges. They fail to account for variations in defect location andsize, which can lead to inaccurate search. Furthermore, previ-ous studies have primarily focused on global defect patterns, which may not effectively capture localized defect patterns in real-world semiconductor manufacturing scenarios. To address the above issues, this work proposes a novel pattern search method that accounts for variations in the area and location of the defect pattern in the WBM whileensuring robust and accurate pattern searching. The pro- posed method has three main processes as follows: Ô¨Årst, we propose to pre-process the WBMs to reÔ¨Åne defect patterns.This step removes non-signiÔ¨Åcant defects, reducing noise andenhancing the robustness of subsequent analysis. By elimi- nating irrelevant defects, the method improves "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_5", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 5, "text": "the WBMs to reÔ¨Åne defect patterns.This step removes non-signiÔ¨Åcant defects, reducing noise andenhancing the robustness of subsequent analysis. By elimi- nating irrelevant defects, the method improves the accuracy of defect search and similarity calculations. Second, imagematching-based defect pattern analysis is performed. After extracting keypoints and descriptors from reÔ¨Åned defect regions of WBMs, the matching score (Mscore) is com-puted between defect patterns. Notably, this process does not require labeled WBMs, allowing the method to gen- eralize to new defect patterns without retraining a neuralnetwork model. Third, similarity calculation using the pro-posed ConÔ¨Ådence and match of defects (MoD) scores is applied. The ConÔ¨Ådence score evaluates the reliability of matched defect patterns by assessing the consistency oftheir feature representations across WBMs. A higher ConÔ¨Å- dence score indicates a more reliable match, helping to Ô¨Ålter out incorrect or ambiguous pattern searching. Meanwhile,the MoD score addresses a key limitation of conventional similarity-based methods, which often overlook variations in defect location and area. By applying a penalty based onthe partial dist"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_6", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 6, "text": "Meanwhile,the MoD score addresses a key limitation of conventional similarity-based methods, which often overlook variations in defect location and area. By applying a penalty based onthe partial distribution and size of matched defect patterns,the MoD score ensures that similarity measurements remain consistent across different WBMs. The main contributions of this work are as follows: ‚Ä¢Pre-processing for reÔ¨Åned defect patterns: AW B M pre-processing is introduced to remove non-signiÔ¨Åcant defects, reducing noise and improving searching accu- racy. ‚Ä¢Similarity calculation with ConÔ¨Ådence and MoD scores: We propose the ConÔ¨Ådence score to assess the reliability of matched patterns and the MoD score toaccount for defect shape, location, and size, ensuring robust pattern search. ‚Ä¢Enhanced pattern searching performance: Experi- mental evaluations on two industry-driven datasetsdemonstrate that the proposed method substantially out- performs existing similarity-based techniques in searchaccuracy. The rest of the paper is organized as follows. Sec- tion 2provides background information on existing meth- ods for wafer defect pattern analysis. Section 3introduces the proposed pattern search m"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_7", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 7, "text": "cy. The rest of the paper is organized as follows. Sec- tion 2provides background information on existing meth- ods for wafer defect pattern analysis. Section 3introduces the proposed pattern search method, including the pre- processing, keypoint-based image matching, and similaritymetrics. Section 4evaluates the performance of our method using industry-driven datasets, comparing it with existing similarity-based methods. The conclusions are provided in Section 5. 2 Background 2.1 Traditional similarity-based methods for WBM defect analysis Similarity-based methods use geometrical distance to mea- sure the similarity between a source WBM and target WBMs.By comparing problematic processes of WBMs with higher similarity, root cause analysis can be facilitated. Thus, while classiÔ¨Åcation-based methods existing methods such assupervised- and unsupervised learning-based methods strug- gle to analyze defect patterns that have the same labels or overlapping defects, similarity-based methods offer greaterÔ¨Çexibility. For similarity measures, template matching has been widely adopted. [ 20] Ô¨Årst adopted template matching for wafer defect analysis to rank WBMs based on similarity. Inaddition, "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_8", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 8, "text": "fer greaterÔ¨Çexibility. For similarity measures, template matching has been widely adopted. [ 20] Ô¨Årst adopted template matching for wafer defect analysis to rank WBMs based on similarity. Inaddition, [ 16] employed template matching to segment defect patterns in WBMs. More recently, [ 17] adopted a differ- ent type of template matching called best-buddies similarity,which enhances matching accuracy by identifying mutually nearest neighbors between two distributions. Beyond tem- plate matching, alternative similarity measures have beenexplored to improve defect analysis. For instance, [ 18] introduced a WBM similarity measurement framework that integrates a mountain clustering algorithm and weightedmodiÔ¨Åed Hausdorff distance. Besides, [ 21] adopted deep learning-based similarity models to learn feature represen- tations of WBMs, allowing for more adaptive and scalable similarity evaluations. These approaches aim to overcome thelimitations of purely template matching methods by incorpo- rating spatial information and non-linear feature mappings. Despite these advances, template matching may suf- fer from inherent limitations, as it struggles with complex transformations, non-rigid de"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_9", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 9, "text": "rating spatial information and non-linear feature mappings. Despite these advances, template matching may suf- fer from inherent limitations, as it struggles with complex transformations, non-rigid deformations, and ambiguous variations of images [ 22]. Furthermore, deep learning-based similarity models may face the same challenges as supervised 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2141 learning-based methods since they require labeled WBM datasets. To address these limitations, image matching can serve as a more effective approach. To the best of our knowledge, image matching has not yet been applied to wafer defectanalysis. However, its ability to extract distinctive featuresand establish robust correspondences under geometric varia- tions makes it a promising alternative to template matching. The following subsection introduces key image matchingmethodologies and demonstrates their potential applicabil- ity to WBM similarity analysis. 2.2 Image matching algorithms Image matching algorithms have been developed for various computer vision tasks (e.g., object recognition and imagestitching). Generally, these algorithms identify key"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_10", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 10, "text": "s. 2.2 Image matching algorithms Image matching algorithms have been developed for various computer vision tasks (e.g., object recognition and imagestitching). Generally, these algorithms identify key features called keypoints in images and establish correspondences between them to enable accurate matching and alignment.SpeciÔ¨Åcally, they consist of three key processes: feature detection, description, and matching. In feature detection, classical methods such as scale invariant feature trans-form (SIFT) [ 23] and oriented FAST and rotated BRIEF (ORB) [ 24] detect keypoints by identifying regions with sharp changes in brightness or contrast, relying on hand- crafted operations such as difference of Gaussian Ô¨Åltering. Infeature description, these methods then generate descriptors based on histograms of gradient orientations, ensuring invari- ance to rotation and scale. In feature matching, techniquessuch as brute-force matching or approximate nearest neigh- bor are commonly used, comparing feature vectors using similarity metrics such as Euclidean distance. Recent studies have leveraged deep learning-based appro- aches to enhance the robustness of image matching. Instead of relying on"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_11", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 11, "text": "g feature vectors using similarity metrics such as Euclidean distance. Recent studies have leveraged deep learning-based appro- aches to enhance the robustness of image matching. Instead of relying on handcrafted operations, they utilize convo- lutional neural networks (CNNs) to learn keypoint rep-resentations from real or synthetic keypoint datasets. For example, [ 25‚Äì27] adopted supervised learning to train detec- tors and descriptors, while [ 28,29] employed self-supervised learning to improve the consistency of keypoint detection and description across varying conditions. In feature matching, graph neural networks (GNNs) and attention mechanisms,which model relationships between keypoints beyond simplepairwise comparisons, have been widely adopted. Super- Glue [ 30] employed GNNs with self- and cross-attention to reÔ¨Åne matching, while local feature matching with transform-ers [ 31] adopted transformer architecture [ 32] to incorporate global context, further improving accuracy in feature match- ing. More recently, lightweight models such as local featurematching at light speed [ 33] have been proposed to optimize attention-based feature matching for real-time applications. As w"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_12", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 12, "text": "eature match- ing. More recently, lightweight models such as local featurematching at light speed [ 33] have been proposed to optimize attention-based feature matching for real-time applications. As we noted in Section 2.1, template matching strug- gles with complex transformations and ambiguous shapesof defect patterns, making it less effective for WBM analy- sis. Similarly, traditional image matching methods can facethe same challenges as they rely on handcrafted features and local similarity metrics, leading to inconsistent key- point detection and false correspondences. Thus, we adopteddeep learning-based image matching methods that leveragekeypoint detection, descriptor learning, and attention-based feature matching. Depending on hardware resources and search purposes, various image matching algorithms canbe utilized for WBM analysis. While lightweight methods may be suitable for real-time searches, transformer-based methods can capture both local and global defect patterns.However, for a strong and stable baseline, we selected Super- Point and SuperGlue for wafer defect analysis, as they have demonstrated robust performance across various geometrictransformations and noise co"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_13", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 13, "text": "r, for a strong and stable baseline, we selected Super- Point and SuperGlue for wafer defect analysis, as they have demonstrated robust performance across various geometrictransformations and noise conditions. The following sectionprovides detailed information on the proposed pattern search method and discusses how different image matching algo- rithms can be integrated into WBM defect analysis. 3 Proposed pattern search method In this section, we propose the pattern search method designed to improve WBM defect analysis. Our approach integrates keypoint-based image matching with a pre-proces-sing step to reÔ¨Åne defect patterns. The method consists of three main components: (1) pre-processing, which eliminates non-signiÔ¨Åcant defect patterns to enhance the reliability ofsimilarity calculations; (2) image matching, which extracts keypoints and descriptors from defect patterns and estab- lishes correspondences between source and target WBMs;and (3) similarity measurement, which adjusts Mscores usingConÔ¨Ådence and MoD scores to improve robustness against variations in defect shape, location, and area. The follow- ing subsections provide details on the key components of theproposed method."}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_14", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 14, "text": "res usingConÔ¨Ådence and MoD scores to improve robustness against variations in defect shape, location, and area. The follow- ing subsections provide details on the key components of theproposed method. 3.1 Image matching for WBM defect analysis The image matching for the proposed pattern search algo-rithm in WBMs has four main sub-functions: (1) detection,(2) description, (3) matching, and (4) scoring. The detection function detects salient pixels called key- points from the defect patterns in each WBM. Then, the description function extracts descriptors around keypoints toenhance robustness against rotational and scale variations of the defect patterns. Figure 1a shows an example of the key- point detection and description processes in WBM. On theother hand, the matching function matches keypoints from different defect patterns based on their descriptors. Figure 1b shows an example of the keypoint matching processes inWBM. Finally, the scoring function calculates the match- 123 2142 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 Fig. 1 Keypoint detection, description, and matching of the proposed pattern search method ing score, which refers to "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_15", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 15, "text": "e International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 Fig. 1 Keypoint detection, description, and matching of the proposed pattern search method ing score, which refers to similarity scores, using distance metrics between descriptors, such as dot products and theEuclidean distance. In the scoring function, the proposed two metrics can be applied by incorporating the average Mscore between matched descriptors and the geometric char-acteristics of defect patterns. The Ô¨Ånal similarity value is obtained by adjusting the average Mscore using the calcu- lated ConÔ¨Ådence or MoD score, ensuring a more accuratecomparison between defect patterns in the source WBM and target WBMs. 3.2 Implementation details of the proposed method The pseudo-code of the proposed search method is shown in Algorithm 1. Let us assume that there are a source WBMdenoted as sand target WBMs denoted as t k‚àà1,...,K. Several terms and functions are deÔ¨Åned to clarify the pseudo-code:‚Ä¢/vectorkpx: Keypoints detected from the defect patterns in WBM x‚àà{s,tk‚àà1,...,K}. ‚Ä¢/vectordes x: Descriptors from the keypoints from the defect pat- terns in WBM x‚àà{s,tk‚àà1,...,K}. ‚Ä¢Detection ( x,Dmax(/vectorkpx)): "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_16", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 16, "text": "eypoints detected from the defect patterns in WBM x‚àà{s,tk‚àà1,...,K}. ‚Ä¢/vectordes x: Descriptors from the keypoints from the defect pat- terns in WBM x‚àà{s,tk‚àà1,...,K}. ‚Ä¢Detection ( x,Dmax(/vectorkpx)): A function of detecting key- points /vectorkpx‚àà RDmax(/vectorkpx)from WBM image x‚àà {s,tk‚àà1,...,K}, where Dmax(/vectorkpx)is the maximum dimen- sion of keypoints /vectorkpx. ‚Ä¢Description ( x,/vectorkpx,D(/vectordes x)): A function of generating descriptors /vectordes x‚ààRD(/vectordes x)from keypoints /vectorkpxof defect patterns in WBM x‚àà{s,tk‚àà1,...,K}, where D(/vectordes x)the dimension of the descriptors /vectordes x. ‚Ä¢Pre-processing ( x): A function of performing the pre- processing for WBM x‚àà{s,tk‚àà1,...,K},a ss h o w ni n Fig. 2b. ‚Ä¢Matching ( /vectorkps,/vectordes s,/vectorkptk,/vectordes tk): A function of perform- ing image matching between pairs of ( /vectorkps,/vectordes s)f r o m the defect patterns in WBM sand ( /vectorkptk,/vectordes tk)f r o mt h e 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2143 Fig. 2 Visualization of the proposed search algorithm defect patterns WBM tk. This function can produce the vector of Mscores /vectormdes "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_17", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 17, "text": "f Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2143 Fig. 2 Visualization of the proposed search algorithm defect patterns WBM tk. This function can produce the vector of Mscores /vectormdes j‚Üîdes i. ‚Ä¢Matched descriptors: In the source WBM s,i fa n y descriptor des i‚àà/vectordes sis matched with the descriptor of a target WBM denoted as des j‚àà/vectordes tkfor a target WBM tk, the matched descriptors are denoted as des j‚Üîdes i ordes i‚Üîdes j.T e r m s iand jare for the indices of defect patterns from the source WBM and target WBM, respectively. ‚Ä¢ConÔ¨Ådence ( s,/vectormdes j‚Üîdes i,tk): A function of calculating the ConÔ¨Ådence score between WBMs sandtkbased on the vector of Mscores /vectormdes j‚Üîdes ifrom matching( /vectorkps, /vectordes s,/vectorkptk,/vectordes tk). ‚Ä¢MoD ( s,/vectormdes j‚Üîdes i,tk): A function of calculating the MoD score between two WBM images sandtk, based on the vector of Mscores /vectormdes j‚Üîdes ifrom matching( /vectorkps, /vectordes s,/vectorkptk,/vectordes tk). The description of Algorithm 1 is as follows: source WBM sand target WBMs tk‚àà1,...Kare the inputs of Algorithm 1. The maximum dimension of keypoints and the dimension of descriptors can be given as"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_18", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 18, "text": "). The description of Algorithm 1 is as follows: source WBM sand target WBMs tk‚àà1,...Kare the inputs of Algorithm 1. The maximum dimension of keypoints and the dimension of descriptors can be given as the inputs, which are not shown for clarity. Term pre‚àà{T,F}indicates whether the pre-processing is performed ( T) or not ( F). Term score ‚àà {ConÔ¨Ådence ,MoD}is the name of the function to calculate the similarity between defect patterns of sandtk‚àà1,...K.A f t e r extracting keypoints and descriptors from sand tk(Lines 5‚Äì12), the vector of Mscores /vectormdes j‚Üîdes iis calculated from the matching function (Line 13). Then, the similarity of the two defect patterns from sand tkdenoted as sim is cal- culated, where either ConÔ¨Ådence or MoD score is obtained depending on score (Line 14). In other words, the calculated ConÔ¨Ådence or MoD score can be the similarity denoted assim. Finally, the similarity between defect patterns of sand t k‚àà1,...Kis appended into the array of similarities denoted assim(s,t1,...k‚àí1)(Line 15). We note that image matching with extracted keypoints and their descriptors can be performedusing SuperGlue in the matching function (Line 13). How- ever, any keypoint-based "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_19", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 19, "text": "sim(s,t1,...k‚àí1)(Line 15). We note that image matching with extracted keypoints and their descriptors can be performedusing SuperGlue in the matching function (Line 13). How- ever, any keypoint-based image matching algorithm instead of SuperGlue can calculate the above Mscores (Line 13). It isnoted that the ConÔ¨Ådence or MoD score in Line 14 is neededto normalize and adjust the average Mscore depending on the location and area of defect patterns. The sub-processes of the proposed algorithm are explained in the following sub-sections. Algorithm 1 Pseudo code of the proposed pattern search algorithm. Input: Source WBM s,T a r g e tW B M s tk‚àà1,...K,pre‚àà{T,F},score ‚àà {ConÔ¨Ådence ,MoD} Output: Array sim(s,k‚àà1,...K) 1:sim(s,t1,...k)‚Üê‚àÖ 2:ifpre=Tthen 3: s‚Üêpre-processing (s) 4:end if 5:/vectorkps‚Üêdetection (s,Dmax(/vectorkps)) 6:/vectordes s‚Üêdescription (s,/vectorkps,D(/vectordes s)) 7:fork‚àà{1,..., K}do 8: ifpre=Tthen 9: tk‚Üêpre-processing (tk) 10: end if 11: /vectorkptk‚Üêdetection (tk,Dmax(/vectorkptk)) 12: /vectordes tk‚Üêdescription (tk,/vectorkptk,D(/vectordes tk)) 13: /vectormdes j‚Üîdes i‚Üêmatching (/vectorkps,/vectordes s,/vectorkptk,/vectordes tk)) 14: sim‚Üêscore(s,/vectormdes j‚Üîdes i,tk) 15"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_20", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 20, "text": "rkptk)) 12: /vectordes tk‚Üêdescription (tk,/vectorkptk,D(/vectordes tk)) 13: /vectormdes j‚Üîdes i‚Üêmatching (/vectorkps,/vectordes s,/vectorkptk,/vectordes tk)) 14: sim‚Üêscore(s,/vectormdes j‚Üîdes i,tk) 15: sim(s,t1,...k)‚ÜêAppend (sim(s,t1,...k‚àí1),sim) 16:end for 3.3 Image pre-processing for pattern search Pre-processing techniques, such as denoising, have been widely used in image analysis [ 34]. However, their applica- 123 2144 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 tion to defect pattern analysis requires careful consideration due to the unique characteristics of semiconductor defect pat-terns, including their spatial distribution, variation in size, and noise from non-signiÔ¨Åcant defects. In [ 20,35‚Äì37], the location and area of defect patterns affect the matching resultsof defect patterns. In other words, the repetitive malfunctionof the manufacturing process is signiÔ¨Åcantly related to the defect patterns having close locations or similar areas. How- ever, general keypoint-based image matching algorithmshave rotation and scale invariant properties. These proper- ties can degrade the results of pattern search, because the location and area "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_21", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 21, "text": "s. How- ever, general keypoint-based image matching algorithmshave rotation and scale invariant properties. These proper- ties can degrade the results of pattern search, because the location and area of the defect patterns are not considered. To overcome this problem, we propose a WBM pre- processing method using object detection, which is per- formed in the pre-processing function in Algorithm 1. Bypre-processing, signiÔ¨Åcant defect patterns in WBMs aredetected and localized while non-signiÔ¨Åcant noise is Ô¨Åltered out [ 35]. Our proposed pre-processing method addresses the limitations of supervised learning methods by employing thepre-processing function exclusively for denoising and defect pattern reÔ¨Ånement, rather than integrating it as a core com- ponent of pattern search or similarity analysis. This ensuresthat our approach avoids the data dependency and retrainingchallenges associated with supervised learning-based meth- ods. The details of the pre-processing function are explained with Fig. 3as follows: Ô¨Årstly, as shown in Fig. 3a, c, and e, an object detector builds the bounding box (denoted as bbox),which Ô¨Ånds the location and area of the signiÔ¨Åcant defectpatterns. Secondly, "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_22", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 22, "text": "with Fig. 3as follows: Ô¨Årstly, as shown in Fig. 3a, c, and e, an object detector builds the bounding box (denoted as bbox),which Ô¨Ånds the location and area of the signiÔ¨Åcant defectpatterns. Secondly, the dies out of bbox are included in non- signiÔ¨Åcant defect patterns called noise in this paper. Then, so-called denoising is performed to erase the non-signiÔ¨Åcant defect patterns in the WBM in Fig. 3b, d, and f. The pat- tern search can continue after performing the pre-processed WBMs from the aforementioned two steps. 3.4 Image matching with keypoints and descriptors The matching function in Line 13 of Algorithm 1 usesthe keypoints and descriptors as its inputs. The keypointsand their descriptors can be obtained from classical image matching algorithms such as SIFT and ORB. The gener- ated descriptors capture essential photometric informationof keypoints. In general, the image matching using the aboveclassical algorithms calculates Euclidean distance between two descriptors des i‚àà/vectordes sfor source WBM sanddes j‚àà Fig. 3 Denoising in image pre-processing 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2145 /vectordes tkfor target WBM tk‚àà1,.."}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_23", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 23, "text": "des sfor source WBM sanddes j‚àà Fig. 3 Denoising in image pre-processing 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2145 /vectordes tkfor target WBM tk‚àà1,...,K, which is formulated as/radicalBig/summationtextd z=1(desz i‚àídesz j)2fordes i,des j‚ààRd.T e r m ddenotes the dimension of each descriptor. To Ô¨Ånd a matched descrip- tordes j‚àà/vectordes tkwith a des i, the nearest-neighbor search can be applicable, where a matched descriptor des jwith des i denoted as des j‚Üîdes iis calculated as follows: des j‚Üîdes i=argmin des j/radicaltp/radicalvertex/radicalvertex/radicalbtd/summationdisplay z=1(desz i‚àídesz j)2 fordes i,des j‚ààRd.(1) On the other hand, SuperPoint and SuperGlue can be used in image matching. Unlike classical image matching algo-rithms, both SuperPoint and SuperGlue are learning-based. We think that the above learning-based approaches can be effective in the pattern search for speciÔ¨Åc types of defectpatterns in WBMs. In other words, the models in Super- Point and SuperGlue can be trained from WBM datasets. Then, the trained models in SuperPoint and SuperGlue areused in the image matching for defect patterns in WBMs,which is the main d"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_24", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 24, "text": "odels in Super- Point and SuperGlue can be trained from WBM datasets. Then, the trained models in SuperPoint and SuperGlue areused in the image matching for defect patterns in WBMs,which is the main difference from the classical algorithms. The pre-trained CNNs of SuperPoint can detect keypoints in real time. On the other hand, the matcher in SuperGluecalculates Mscores from the given keypoints and descrip- tors from SuperPoint. SuperGlue considers the positional relationships between keypoints based on graph attentionnetworks (GA Ts), enabling robust matching for both single and mixed defect patterns. The model used in SuperGlue is trained to update the weights of GA Ts extracted from thesame defect patterns. In this process, while each keypoint isrepresented as a node, the relationships between keypoints are represented as edges. Considering the above advantages, SuperPoint and SuperGlue can be mainly adopted in the pro-posed pattern searching method. It is noted that SuperGlue does not output the class of matched defect patterns, which is different from the trained models in the classiÔ¨Åcation-basedimage matching [ 38]. The detailed process using SuperPoint and SuperGlue is descr"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_25", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 25, "text": "not output the class of matched defect patterns, which is different from the trained models in the classiÔ¨Åcation-basedimage matching [ 38]. The detailed process using SuperPoint and SuperGlue is described as follows: for the pattern searching, the imagematching algorithm extracts keypoints from SuperPoint forthe source WBM s. Unnecessary keypoints can be removed by specifying the maximum number of keypoints denoted as D max(/vectorkpx)in Algorithm 1. Then, descriptors are generated from the extracted keypoint, where each descriptor contains both the position and visual information of a keypoint kpx. All descriptors are embedded into a high-dimensional vectordenoted as (0)/vectorxithrough multi-layer perceptron (MLP) as follows: (0)/vectorxi=/vectordes i+MLP(/vectorpos i), (2)where the superscript (0)denotes that(0)/vectorxiis the input for the following attentional aggregation. In Eq. 2,des i‚àà/vectordes s,tk and pos i‚àà/vectorpos s,tkrepresents a visualized descriptor and its position, respectively. The keypoints of the defect patterns in two WBMs are extracted by attentional aggregation between similar sourceWBM and targets via GA Ts. The keypoints are then com- bined to make a so-"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_26", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 26, "text": "respectively. The keypoints of the defect patterns in two WBMs are extracted by attentional aggregation between similar sourceWBM and targets via GA Ts. The keypoints are then com- bined to make a so-called message denoted as msg in [39, 40] and connected via edges . Edges for all keypoints can be denoted as j:(i,j)‚ààŒµ, where iand jindicate the indexes of any keypoints having connections via edges Œµ. In this case, the aggregated result from all keypoints of the source and tar-get WBMs is denoted by message msg Œµ‚Üíi. The message is formulated as follows: msgŒµ‚Üíi=/summationdisplay j:(i,j)‚ààŒµŒ±ijvj, (3) where Œ±ijcan be calculated using the Softmax over the key- query similarities [ 30]. Term Œ±ijis formulated as follows: Œ±ij=Sof tmax j(q/latticetop ikj). (4) In Eqs. 3and 4,vj,qi, and kjdenote values, queries, and keys, which are computed as a linear projection of deepfeatures of the GNNs [ 30]. The matched descriptors for keypoints between target WBM t kand source WBM sare represented by the following linear projection: ftk i=W¬∑xtk i+b. (5) fs j=W¬∑xs j+b. (6) A score matrix denoted as S(i,j)=<ftk i,fs j>is obtained from the inner product of ftk i,fs j, where operator <a,b> denotes the inner"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_27", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 27, "text": "llowing linear projection: ftk i=W¬∑xtk i+b. (5) fs j=W¬∑xs j+b. (6) A score matrix denoted as S(i,j)=<ftk i,fs j>is obtained from the inner product of ftk i,fs j, where operator <a,b> denotes the inner product of any aandb[30]. Each element of the score matrix means Mscore from the matching between two keypoints. 3.5 Refining similarity measurement by adjusting Mscore with Confidence and MoD scores In the matching function, SuperGlue and several existing image matching algorithms [ 26,28,31] use the average Mscore to measure the similarity between image patterns. As far as we know, it is noted that no metric-based methods have been developed to adjust the average Mscore consider-ing the characteristics of the pattern search for defect patterns in WBMs. Therefore, we propose two similarity metrics for adjusting the matching results between defect patterns inWBMs. 123 2146 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 3.5.1 ConÔ¨Ådence score In the pattern search of general image dataset, the scale and dimension of the target images can determine the Mscore between any matched descriptors from keypoints. In theimage matching using unsupervised learn"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_28", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 28, "text": "ern search of general image dataset, the scale and dimension of the target images can determine the Mscore between any matched descriptors from keypoints. In theimage matching using unsupervised learning, the increas-ing redundant descriptors can degrade the image matching results between defect and noisy patterns. To address the above problem, we proposed to normalize the Mscore m‚àà /vectorm des j‚Üîdes iin Algorithm 1 to reduce the inÔ¨Çuence of the noisy patterns. When a mis normalized considering the maximum and minimum values of Mscore denoted as mmax andmmin, the normalized Mscore of mis denoted as mnorm , which is equated in Eq. 7as follows: mnorm=m‚àímmin mmax‚àímmin, (7) where conÔ¨Ådence denoted as con f:=mnorm represents the conÔ¨Ådence for the matched descriptors from keypoints. The visualization of con f s for all matched keypoints is shown in Fig. 4. We note that because the matched descriptors are generated from the keypoints, the matched keypoints can be visualized. Then, ConÔ¨Ådence score denoted as score con f is calculated by averaging all conÔ¨Ådences con f sf r o ma l l matches in xandtk, which is equated as follows: score con f k=/summationdisplay ‚àÄdes j‚Üîdes icon f2 length (/v"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_29", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 29, "text": "score denoted as score con f is calculated by averaging all conÔ¨Ådences con f sf r o ma l l matches in xandtk, which is equated as follows: score con f k=/summationdisplay ‚àÄdes j‚Üîdes icon f2 length (/vectormdes j‚Üîdes i). (8) By averaging all con f s, it is concluded that Eq. 8can adjust the average Mscore from the matching result betweendefect patterns. 3.5.2 MoD score In the general image matching algorithm, each Mscore contains the matching result between descriptors for the same-sized patterns. Therefore, in the matching for defect Fig. 4 Visualization of the con f s of the all matched keypointspatterns in WBMs, the naive calculation of Mscore does not consider the characteristics of pattern search in WBMsbecause each naive Mscore cannot consider the location and area of defect patterns detected from an object detector in the pre-processing function. Therefore, we propose a newmetric called MoD score, which can be used as similarityafter adjusting the average Mscore from the image matching of the denoised defect patterns after pre-processing. In the search process, a bounding box (bbox) with x- and y-axes coordinate values are obtained from the object detector in the pre-processi"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_30", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 30, "text": "tching of the denoised defect patterns after pre-processing. In the search process, a bounding box (bbox) with x- and y-axes coordinate values are obtained from the object detector in the pre-processing function. In Eq. 9, the area of the defect pattern is calculated by multiplying the width and height ofthe bbox as follows: A bbox=Wbbox√óHbbox, (9) which is visualized in Fig. 5a. Then, a penalty APkdepending on the area of each defect pattern is formulated as follows: APk=/braceleftBiggAtk As,if As‚â•Atk, As Atk,if As<Atk,(10) where Asand Atkrefer to the defect pattern area of source WBM sand target WBMs tk, respectively. As shown in Eq.10,APkcan be calculated by one of the following three cases: (1) the area in a source WBM Asis larger than the area of a target WBM Atk;( 2 ) Atkis larger than As;( 3 )t h e defect pattern is undetected in any region of either sandtk. By applying a penalty depending on various cases, the pattern search can be sensitive to the area variations of the defect pat- terns. A penalty on the location of the defect pattern denotedasLP kis calculated by Eq. 11as follows: LPk=Region s/intersectiontexttk Region s. (11) While APkconsiders the ratio of AstoAtk,LPkc"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_31", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 31, "text": " pat- terns. A penalty on the location of the defect pattern denotedasLP kis calculated by Eq. 11as follows: LPk=Region s/intersectiontexttk Region s. (11) While APkconsiders the ratio of AstoAtk,LPkconsiders the ratio of an overlapped area in each location between sand tk. An example of calculating LPkis visualized in Fig. 5b, where a WBM is divided into multiple cells ‚àà{A,..., P}. The total area of the cells in the bbox is deÔ¨Åned as Region .I f Region s‚àà{A,B,E,F}andRegion tk‚àà{E,F},LPk=0 . 5 . As a result, a MoD score denoted as score MoD is calculated Fig. 5 Area and cells of a defect pattern 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2147 by assigning the above penalty to the average Mscore for all the matched descriptors between sandtk, which is equated in Eq. 12as follows: score MoD k=LPk√óAPk√ó/summationdisplay ‚àÄdes j‚Üîdes im length (/vectormdes j‚Üîdes i). (12) Engineers can choose either ConÔ¨Ådence score or MoD score as the similarity between defect patterns according to the purpose of their pattern search and the usage of pre-processing. While the normalized image matching resultsof ConÔ¨Ådence score can be useful in pattern searches wi"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_32", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 32, "text": "een defect patterns according to the purpose of their pattern search and the usage of pre-processing. While the normalized image matching resultsof ConÔ¨Ådence score can be useful in pattern searches with- out using pre-processing, score MoD can be preferred in the pattern search for signiÔ¨Åcant defect patterns after pre-processing. In the following section, the similarity of MoD score after pre-processing shows better performance in the visualized search results for detected signiÔ¨Åcant defect pat-terns. 4 Experimental results and analysis 4.1 Experimental setup We evaluated the proposed search algorithms on industry- driven WM-811K [ 20] and MixedWM38 [ 41] datasets. The WM-811K dataset has 811,457 WBMs with 8 single defectpattern classes ( Center ,Donut ,Loc,Edge-Loc ,Edge-Ring , Scratch ,Near-full , and Random ). The MixedWM38 dataset has 38,015 WBMs with 38 single and mixed defect pat- tern classes, which includes the above 8 classes from theWM-811K dataset. In [ 20], it is noted that the WM-811K dataset originated from real wafers of Taiwan Semiconductor Manufacturing Company. The WM-811K and MixedWM38datasets have a wide range of resolutions from 26 √ó26 to 50√ó60.For the pre-proc"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_33", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 33, "text": " the WM-811K dataset originated from real wafers of Taiwan Semiconductor Manufacturing Company. The WM-811K and MixedWM38datasets have a wide range of resolutions from 26 √ó26 to 50√ó60.For the pre-processing, we chose you only look once (YO LO) v8 [ 42] as the object detector. The detailed description for training the YOLOv8 was as follows. We used Adam [ 43] optimizer, having the learning rate of 1e‚àí2 and the number of epochs of 20. We also used a small weight decay of 5e‚àí4 to improve generalization performance and avoid overÔ¨Åtting.Note that we manually created an annotation Ô¨Åle for the defect patterns of the WBMs used in training. In the proposed pat- tern search, SuperPoint [ 28] was used to extract keypoints and generate descriptors. Besides, SuperGlue [ 30] was used as the matcher to calculate Mscores between matched descriptors. During training, all WBMs were resized to 640 √ó480 for SuperPoint and 640 √ó640 for SuperGlue. Then, the resized images were converted to grayscale. The Adam optimizer was used, having the learning rate of 1e‚àí4, no weight decay- ing, and 20 training epochs. Since the training is to extractkeypoints and perform image matching, we did not perform the pre-"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_34", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 34, "text": "am optimizer was used, having the learning rate of 1e‚àí4, no weight decay- ing, and 20 training epochs. Since the training is to extractkeypoints and perform image matching, we did not perform the pre-processing on WBMs. 4.2 Experiments on single defect patterns Figure 6shows single defect patterns for classes Center , Donut , and Edge-Loc on the WM-811K dataset. Figure 6a shows 5 similar WBMs ordered based on each ConÔ¨Å- dence score without using pre-processing. A term Rank -iis assigned in descending order of high similarity. The patternsearch for Center in a source WBM shows that the defect pat- terns of Rank-1 and Rank-2 had close locations and similar areas with the defect pattern in the source WBM. On the otherhand, the pattern search for Donut shows that the defect pat- terns of highly ranked WBMs had different shapes from each other. Instead, the defect patterns of Rank-4 andRank-5 were very similar to the defect pattern in the source WBM. We con-clude that the ConÔ¨Ådence scores were high due to keypoints extracted from non-signiÔ¨Åcant defect patterns called noise. In the search for Edge-Loc , the defect pattern of Rank-1 is very similar to that of the source WBM. However, Edge"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_35", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 35, "text": "ere high due to keypoints extracted from non-signiÔ¨Åcant defect patterns called noise. In the search for Edge-Loc , the defect pattern of Rank-1 is very similar to that of the source WBM. However, Edge-Loc in the source WBM differs from the defect patterns from Rank- Fig. 6 Visualized search results for single defect patterns 123 2148 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2toRank-5 in their locations. Therefore, the pattern search without pre-processing did not show acceptable performancedue to the noise in WBMs. The above weakness was improved by the proposed pre- processing in the following. Figure 6bs h o w ss e v e r a lW B M s after performing the image pre-processing and their MoDscores. In the search results of Center , high MoD scores were assigned to the defect patterns with close locations and similar areas. Besides, Donut looks clearer after denoising from the pre-processing. Figure 6b shows that defect pat- terns with close locations and similar areas were searched well with high similarity values. In the search for Center andEdge-Loc , the difference of locations in Rank-5 showed a signiÔ¨Åcant drop in the MoD score. Besides, "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_36", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 36, "text": "ions and similar areas were searched well with high similarity values. In the search for Center andEdge-Loc , the difference of locations in Rank-5 showed a signiÔ¨Åcant drop in the MoD score. Besides, in the search forEdge-Loc , differences in the area of the defect patterns between source and target WBMs degraded the MoD scoreinRank-2 . Therefore, the cases with lowered MoD scores show that the pre-processing and application in the MoD score adjusted the naive image matching results consideringthe varying locations and areas of the defect patterns in the proposed pattern search method. Table 1summarizes the pattern searches on WM-811K dataset with single defect patterns, where the defect patterns with high similarity between a source WBM and other 1977 target WBMs were searched. When the average Mscore wasused as the similarity between defect patterns, the imagematching results were not adjusted without applying the penalty of ConÔ¨Ådence score or MoD score. Although the pattern search did not classify the defect patterns into pre-determined classes, the class of the searched Rank-1 defect pattern in a target WBM gave information about how well the searched patterns were similar to t"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_37", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 37, "text": "id not classify the defect patterns into pre-determined classes, the class of the searched Rank-1 defect pattern in a target WBM gave information about how well the searched patterns were similar to the defect pattern of a sourceWBM. The term Best means the similarity of Rank-1 WBM. Besides, the term Worst means the lowest similarity among search results. When using the naive average Mscore andConÔ¨Ådence score, 4 and 3 defect patterns had different labelsfrom those of the defect patterns in source WBM, respec- tively. On the other hand, with the proposed MoD score, only one defect pattern in a target WBM had a label differentfrom that of the source WBM. Therefore, we note that the similarity using pre-processing and MoD score can be useful in the search for defect patterns on the WM-811K dataset. Whereas the Best values did not refer to outstanding dif- ferences among the pattern searches with different similarity metrics, the Worst values of ConÔ¨Ådence score and MoD score were smaller than those of the average Mscore. Notably, theWorst andMean values of MoD score were smaller than those of the average Mscore and ConÔ¨Ådence score. We expect that the pattern search using the MoD score "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_38", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 38, "text": "han those of the average Mscore. Notably, theWorst andMean values of MoD score were smaller than those of the average Mscore and ConÔ¨Ådence score. We expect that the pattern search using the MoD score as a similarity met-ric can Ô¨Ålter out so-called vaguely similar defect patterns by assigning them a small similarity, so that denoised defect patterns in WBMs can be well searched. On the other hand,when a defect pattern appeared in the large area of a WBMsuch as Loc,Edge-Loc , and Scratch , the pre-processing can detect the defect pattern by showing large bboxes, whichproves that the trained YOLOv8 detector can be effective in Ô¨Ånding the defect patterns that appear on the entire region of a WBM. In the search for Near-full , because the defects were scattered on the entire region, the penalty of the difference inlocations and areas in the MoD score could not be applied. However, considering the searched defect patterns and their characteristics in Table 1, the proposed pattern search using MoD score was effective in Ô¨Ånding a single defect pattern using pre-processing. 4.3 Experiments on mixed defect patterns In Fig. 7, we conducted experiments on the MixedWM38 dataset to evaluate the "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_39", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 39, "text": "g MoD score was effective in Ô¨Ånding a single defect pattern using pre-processing. 4.3 Experiments on mixed defect patterns In Fig. 7, we conducted experiments on the MixedWM38 dataset to evaluate the proposed image search for the follow- ing mixed defect patterns: ‚Ä¢CaseI: Center &Edge-Ring ‚Ä¢CaseII: Donut &Loc &Scratch ‚Ä¢CaseIII: Donut &Loc &Edge-Loc &Scratch . Figure 7a visualizes the search results and lists their Con- Ô¨Ådence scores without using pre-processing. The pattern search for CaseI from Rank-1 toRank-3 shows acceptable visualized results for similar defect patterns without usingpre-processing. However, in the search for the defect pat- terns of Rank-4 and Rank-5 with Donut shape, the pattern search without using pre-processing seemed to be confusedbetween Center andDonut . The pattern search of CaseII in Fig. 7a shows low similarity values in the pattern search- ing for CaseII due to the different locations and areas in themixed Loc and Scratch . The pattern search for CaseIII also shows low similarity values in the pattern search for the Edge- Loc. However, in the pattern searches for Cases II and III in Fig. 7a,Donut was well searched in Rank-1 ,Rank-2 , and Rank-3 . The"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_40", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 40, "text": " also shows low similarity values in the pattern search for the Edge- Loc. However, in the pattern searches for Cases II and III in Fig. 7a,Donut was well searched in Rank-1 ,Rank-2 , and Rank-3 . Therefore, when pre-processing was not adopted, the effects of noise on defect patterns were signiÔ¨Åcant in mixed defect patterns. Besides, the ConÔ¨Ådence scores listedin Fig. 7a were lowered by the difference in locations and areas between pattern searches. On the other hand, Fig. 7b shows the pattern search using pre-processing. The pattern search for CaseI performed wellfor all target WBMs having mixed two defect patterns, show- ing the signiÔ¨Åcant defect patterns in any ranked WBMs. However, in the pattern search for CaseII, because differ-ent signiÔ¨Åcant defect patterns were mixed, it is expected that the locations and areas of defect patterns could determine the similarity between defect patterns. The visualizations forDonut and Loc and Scratch in CaseII show that the defect patterns with close locations and similar areas can be well searched. There were many keypoints extracted for Edge-Loc because it created a bbox on the entire region of a WBM. 123 The International Journal of Advanc"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_41", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 41, "text": "lose locations and similar areas can be well searched. There were many keypoints extracted for Edge-Loc because it created a bbox on the entire region of a WBM. 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2149 Table 1 Average Mscore, ConÔ¨Ådence score, and MoD score in searches for 8 defect patterns Average Mscore (w/o pre-processing) ConÔ¨Ådence score (w/o pre-processing) MoD score (using pre-processing) Source WBM Rank-1 Best Worst Mean Rank-1 Best Worst Mean Rank-1 Best Worst Mean Center Center 73.9% 34.8% 67.9% Center 71.6% 20.3% 67.9% Center 73.3% 2.4% 6.9% Donut Donut 73.7% 24.1% 61.3% Donut 71.8% 10.0% 56.3% Donut 73.7% 0.9% 25.9%Loc Center 75.4% 30.2% 68.9% Center 73.8% 14.3% 65.7% Loc 68.9% 1.3% 17.9%Edge-Loc Center 76.9% 27.4% 69.2% Edge-Loc 74.3% 11.8% 66.0% Edge-Loc 33.5% 0.8% 10.7%Edge-Ring Edge-Ring 76.3% 28.8% 67.8% Edge-Ring 74.8% 13.9% 64.3% Edge-Ring 77.5% 0.09% 41.4%Scratch Random 71.9% 27.1% 61.4% Loc 67.5% 10.0% 56.4% Scratch 42.0% 6.3% 18.8%Near-full Center 80.8% 37.4% 74.9% Random 80.0% 37.4% 72.9% Random 78.8% 0.05% 32.2%Random Random 68.9% 21.2% 47.2% Random 66.6% 10.0% 37.9% Random 70.5% 0.2% 35.9% 123 2150 The Inter"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_42", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 42, "text": " 42.0% 6.3% 18.8%Near-full Center 80.8% 37.4% 74.9% Random 80.0% 37.4% 72.9% Random 78.8% 0.05% 32.2%Random Random 68.9% 21.2% 47.2% Random 66.6% 10.0% 37.9% Random 70.5% 0.2% 35.9% 123 2150 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 Fig. 7 Visualized search results for mixed defect patterns Therefore, in the pattern search for CaseIII, Edge-Loc sig- niÔ¨Åcantly degraded the pattern search results for Donut and Scratch . Whereas a single Edge-Loc in Fig. 6b can be well searched, complex extracted keypoints from Edge-Loc can disturb the search for other defect patterns such as Scratch andLoc in the search for mixed patterns. Therefore, it is con- cluded that when small defect patterns among mixed patterns were scattered on the entire region of a WBM such as Edge- Loc, the scattered defect pattern signiÔ¨Åcantly degraded the pattern search results. As a result, we note that pre-processing signiÔ¨Åcantly improves the accuracy of the search when deal- ing with mixed defect patterns. While a single defect patternor signiÔ¨Åcant defect patterns among mixed defect patterns were well matched, the pattern search for scattered defect patterns on the entire re"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_43", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 43, "text": " with mixed defect patterns. While a single defect patternor signiÔ¨Åcant defect patterns among mixed defect patterns were well matched, the pattern search for scattered defect patterns on the entire region of a WBM remains challengingin the proposed method. Further research should be done toaddress the weakness of the above case. 4.4 Comparison with state-of-the-art models To enhance the evaluation and demonstrate the effective-ness of the proposed method, we conducted comparativeexperiments with state-of-the-art (SOTA) models. Whileconventional approaches rely on labeled data during training or require labels for testing, our method does not require classlabels during training and testing. Therefore, we adopted a metric based on nearest-neighbor similarity to ensure a fair comparison. During evaluation, we computed the similarity between WBM in the test set and all WBMs in the train set using ConÔ¨Ådence and MoD scores. Based on the similarity, we searched the Top- Nmost similar WBMs in the train set. If the ground-truth label of the test WBM appeared among the labels of Top- Nmost similar WBMs, the prediction was con- sidered correct. The resulting metric was deÔ¨Åned as Top- N accura"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_44", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 44, "text": "the train set. If the ground-truth label of the test WBM appeared among the labels of Top- Nmost similar WBMs, the prediction was con- sidered correct. The resulting metric was deÔ¨Åned as Top- N accuracy formulated as follows: Top- NAccuracy =1 NtestNtest/summationdisplay i=11/parenleftBig yi‚ààT(N) i/parenrightBig , (13) where T(N) idenotes the set of labels from the Top- Nmost similar training WBMs to the i-th test WBM, and yiis the ground-truth label of the i-th test WBM. The indicator func- tion1returns 1 if the ground-truth label yiis found within the Top- Nset, and 0 otherwise. Table 2shows a performance Table 2 Comparison of wafer defect classiÔ¨Åcation methodsacross WM-811K andMixedWM38 datasetsDataset Method Input Parameters (M) Accuracy (%) WM-811K U-Net+CBAM [ 3] 256 √ó256√ó1- 9 6 Opt-RseDCNN [ 4]9 6 √ó96√ó1- 9 0 MFFP-Net [ 5] 224 √ó224√ó3 48.1 97 ModiÔ¨Åed VGG16 [ 6]6 4 √ó64√ó1- 7 3 ACDDPM-ResNet [ 8]4 8 √ó48√ó3 25.5 97 Proposed w/o pre-proc. 640 √ó480√ó1 11.2 90/88 Proposed w/ pre-proc. 640 √ó480√ó1 14.5 94/92 MixedWM38 ModiÔ¨Åed VGG16 64 √ó64√ó1- 9 6 CNN+Augmentation [ 7]5 2 √ó52√ó1- 9 6 ACDDPM-ResNet 48 √ó48√ó3 25.5 98 Proposed w/o pre-proc. 640 √ó480√ó1 11.2 80/71 Proposed w/ pre-proc. 640 √ó480√ó1"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_45", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 45, "text": "√ó480√ó1 14.5 94/92 MixedWM38 ModiÔ¨Åed VGG16 64 √ó64√ó1- 9 6 CNN+Augmentation [ 7]5 2 √ó52√ó1- 9 6 ACDDPM-ResNet 48 √ó48√ó3 25.5 98 Proposed w/o pre-proc. 640 √ó480√ó1 11.2 80/71 Proposed w/ pre-proc. 640 √ó480√ó1 14.5 91/84 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2151 comparison of the proposed method with several SOTA mod- els in terms of input resolution, model size, and classiÔ¨Åcationaccuracy. To ensure clarity in presentation, the classiÔ¨Åcation accuracy of our method is represented in the format of Top-5 accuracy/Top-1 accuracy. On the WM-811K dataset, MFFP-Net and ACDDPM- ResNet showed the highest Top-1 accuracy among different models. Besides, MFFP-Net and ACDDPM-ResNet relied on RGB inputs and required approximately 23.7M and 25.5Mparameters, respectively. In particular, ACDDPM-ResNet operated on a very low input resolution of 48 √ó48, which may lead to loss of critical pattern information when appliedin practical industrial applications. In contrast, the proposed method with pre-processing used grayscale inputs with fewer parameters and achieved 92% Top-1 and 94% Top-5 accu-racieo. These results demonstrate that the proposed methodperforms "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_46", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 46, "text": "trast, the proposed method with pre-processing used grayscale inputs with fewer parameters and achieved 92% Top-1 and 94% Top-5 accu-racieo. These results demonstrate that the proposed methodperforms comparably with SOTA models, despite not requir- ing class labels. On the MixedWM38 dataset, most models showed com- petitive classiÔ¨Åcation performance. Most of all, ACDDPM- ResNet achieved the highest Top-1 accuracy of 98%, fol- lowed by CNN+Augmentation with 94%. However, ACDDPM-ResNet used 25.5M parameters and RGB inputs, while CNN+Augmentation operated on a very low input resolu- tion of 48 √ó48, which may result in the loss of critical information when applied in practical industrial environ-ments. On the other hand, the proposed method achieved 91% Top-5 and 84% Top-1 accuracies using grayscale inputs and 14.5M parameters when pre-processing was applied. With-out pre-processing, the performance slightly decreased to 80% Top-5 and 71% Top-1 accuracies. This performance gap indicates that pre-processing improves the consistencyof defect pattern representation, which directly contributes to the accuracy of similarity-based search. Notably, although the proposed method was trained wit"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_47", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 47, "text": "at pre-processing improves the consistencyof defect pattern representation, which directly contributes to the accuracy of similarity-based search. Notably, although the proposed method was trained without any class labels,it achieved Top-5 accuracy that is comparable to those ofSOTA models that adopted supervised learning-based meth- ods. This result suggests that the similarity-based searchapproach is capable of identifying relevant defect patterns even without explicit class information. As a result, the experimental results on both WM-811K and MixedWM38 datasets demonstrate that the proposed pat- tern search method provides comparable performance to theSOTA models, while requiring fewer parameters and operat-ing with lower input resolution. Furthermore, the consistent accuracy across datasets suggests that the method is applica- ble to industrial scenarios where labeled data is limited andpattern search is preferred over classiÔ¨Åcation. 4.5 Visualized evaluation of the proposed pattern search To evaluate the effectiveness of the proposed pattern search method, additional visualizations and analyzes are provided. 4.5.1 Advantages of image matching over template matching In templat"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_48", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 48, "text": "rn search To evaluate the effectiveness of the proposed pattern search method, additional visualizations and analyzes are provided. 4.5.1 Advantages of image matching over template matching In template matching, the primary focus is on identifying geo- metric similarity between defect patterns. Figure 8a presents a centered defect pattern from a source WBM used as the template, while Fig. 8b shows a defect pattern in the target WBM with a shape resembling the template in Fig. 8a. How- ever, when similarity is assessed using Euclidean distance, the spatial difference between the template and the defectpattern in the target WBM becomes a signiÔ¨Åcant challenge. Since Euclidean distance directly measures the displacement between corresponding pixels, even minor location shiftscan substantially impact the similarity measurement. Thesevisual examples in Fig. 8illustrate why naive template match- ing may not be well-suited for pattern search in WBMs. Figure 9further elaborates on the performance of tem- plate matching by presenting visualized search results for both single and mixed defect patterns. The datasets adopted for experiments were the same as previously used for singleand mixed p"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_49", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 49, "text": "ce of tem- plate matching by presenting visualized search results for both single and mixed defect patterns. The datasets adopted for experiments were the same as previously used for singleand mixed pattern analysis in Sects. 4.2and 4.3.I nF i g . 9a, the results for single defect patterns demonstrate high sim- Fig. 8 Matched Center using template matching 123 2152 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 Fig. 9 Visualized search results for single and mixed defect patterns using template matching ilarity scores, ranging from 64.1 to 99.6% across source and target WBMs. It demonstrates that template matchingis highly effective for single, well-deÔ¨Åned defect patterns, as the geometric similarity between the template and target is consistent, with minimal interference from other patterns.However, Fig. 9b shows the results for mixed defect patterns, where similarity scores drop signiÔ¨Åcantly, ranging from 44.7 to 87.4%. This decline occurs because mixed defect patterns introduce complexity and overlapping features, which con-fuse the Euclidean distance-based similarity measurement. The presence of multiple, spatially overlapping defects dis- r"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_50", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 50, "text": " mixed defect patterns introduce complexity and overlapping features, which con-fuse the Euclidean distance-based similarity measurement. The presence of multiple, spatially overlapping defects dis- rupts the precise alignment required for effective templatematching, leading to reduced search accuracy and reliability in pattern search for mixed defects. 4.5.2 Advantages of denoising in keypoint-based image matching The keypoint-based matching algorithm is robust to the vary- ing location and area of defect patterns. In the experiments of keypoint extraction, Fig. 10visualizes extracted keypoints in red. Figure 10shows that many keypoints were found around the centered defect pattern. Besides, the defects around thewafer edge also produced the keypoints around the edge of the WBM. In semiconductor manufacturing, defects aroundthe wafer edge are common, which means that almost all WBMs can have keypoints around the edge of WBMs. Thecommon defects around the edge can be mixed with other defect patterns, being any noise in the search for other sig- niÔ¨Åcant defect patterns. In other words, the common defectpatterns could be considered non-signiÔ¨Åcant defect patterns. The randomly scatter"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_51", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 51, "text": "efect patterns, being any noise in the search for other sig- niÔ¨Åcant defect patterns. In other words, the common defectpatterns could be considered non-signiÔ¨Åcant defect patterns. The randomly scattered small patterns in Fig. 10ap r o - duced the scattered keypoints on the entire region, which can be another non-signiÔ¨Åcant defect pattern. In Fig. 10b, when a signiÔ¨Åcant defect pattern and its keypoints in the center of the WBM are visualized, the keypoints around the edge and scattered on the entire region are Ô¨Åltered out. Whereasmany keypoints from the non-signiÔ¨Åcant defect patterns are matched in Fig. 11a, b shows the matching results between source WBM and Rank-1 after denoising, which proves that the keypoints in source WBM and target WBMs from thesigniÔ¨Åcant defect pattern were well matched. Figures 12and 13prove the effectiveness of the proposed denoising with additional visualizations of the searcheddefect patterns. Additional experiments were conducted on 5 complex single defect patterns: Loc,Donut ,Edge-Ring , Scratch , and Random . The results of pattern searches without denoising are presented in Fig. 12. The experiments showed that except for Random , the source WBM and t"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_52", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 52, "text": "patterns: Loc,Donut ,Edge-Ring , Scratch , and Random . The results of pattern searches without denoising are presented in Fig. 12. The experiments showed that except for Random , the source WBM and target Rank- 1s in the pattern search only using ConÔ¨Ådence score had the Fig. 10 Impact of pre-processing on keypoint extraction 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2153 Fig. 11 Matched defect patterns depending on denoising same labels. However, Random in source WBM was matched with Edge-Ring , showing that defect patterns without denois- ing cannot be well searched. In Fig. 13, the searched patterns after denoising had the same labels in all cases, showing that Random in source WBM was matched with Random in a target WBM. 4.5.3 Advantages of deep learning-based image matching In Fig. 14, we compared the performance of traditional image matching methods, such as SIFT and ORB, with the adopteddeep learning-based image matching method, SuperPoint. Asshown in Fig. 14a and b, traditional methods rely on hand- crafted keypoint detection, which struggles with detecting defect patterns in WBMs. Due to variations in defect size,shape, and int"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_53", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 53, "text": "rPoint. Asshown in Fig. 14a and b, traditional methods rely on hand- crafted keypoint detection, which struggles with detecting defect patterns in WBMs. Due to variations in defect size,shape, and intensity, traditional methods frequently fail to extract keypoints effectively, leading to unreliable keypoint detection results. In contrast, SuperPoint, which leveragesa deep learning-based keypoint detection and description process, signiÔ¨Åcantly improves detection performance. By learning feature representations from a synthetic dataset,SuperPoint achieves higher robustness against geometricvariations and noise, enabling more consistent keypoint detection in complex defect patterns. The results in Fig. 14c demonstrate that SuperPoint successfully detects keypointsin defect patterns where SIFT and ORB fail, highlighting its advantages in WBM analysis. These Ô¨Åndings suggest that deep learning-based image matching algorithms provide amore effective solution for defect pattern analysis in WBMs,making them a suitable choice for semiconductor manufac- turing applications. 4.6 Processing time comparison for different WBM resolutions and methods The speed of the proposed pattern search depend"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_54", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 54, "text": "s,making them a suitable choice for semiconductor manufac- turing applications. 4.6 Processing time comparison for different WBM resolutions and methods The speed of the proposed pattern search depends on the res- olution of each WBM, so we compared the processing timesdepending on the resolutions of WBMs. Besides, by compar- ing with the processing times of template matching [ 44], the computational overhead of the keypoint-based image match-ing can be analyzed in the experiments. Figure 15shows the inference times of the models used in the proposed search depending on 6 different resolutions, where the image match- ing with two WBMs was performed in each inference. Thesetup for source WBM and target WBMs was based on the experiments in Table 1. The processing times were estimated on an NVIDIA RTX 4090 and AMD Ryzen Threadripper16-core PRO 5955WX. In the inference, all WBMs from the WM-811K dataset were resized to one of the 6 resolutions in Fig. 15. Template matching was implemented using the functions provided by OpenCV and their default settings. In Fig. 15, while template matching was the fastest on low-resolution WBMs, it became dramatically slow on high- resolution WBMs. On "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_55", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 55, "text": "using the functions provided by OpenCV and their default settings. In Fig. 15, while template matching was the fastest on low-resolution WBMs, it became dramatically slow on high- resolution WBMs. On the other hand, the proposed patternsearch also increased the processing times with resolutions. However, the increase in the ratio of processing time to its res- olution was not as steep as in the cases of template matching.In 2560 √ó1920 resolution, the proposed pattern search with- Fig. 12 Searches without denoising 123 2154 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 Fig. 13 Searches after denoising out using pre-processing showed 0.188s inference time for each WBM. Therefore, about 459,574 pattern searches canbe performed to calculate the similarity between WBMs ina day. Using the pre-processing, the proposed pattern search required about 0.263 s inference time for each WBM in thesame resolution. The above estimations show that the pre- Fig. 14 Comparison of different keypoint detectors 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2155 Fig. 15 Processing time comparison of different methods based on "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_56", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 56, "text": "omparison of different keypoint detectors 123 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 2155 Fig. 15 Processing time comparison of different methods based on resolution processing can reduce the number of extracted keypoints and the processing times in the pattern search. 5 Conclusion This paper proposes a pattern search method to analyze the similarity between wafer defect patterns based on the image matching algorithm. To overcome the weakness of exist-ing supervised and unsupervised methods, we propose anew robust pattern search method, including pre-processing, detection, description, and matching functions. Notably, experimental data prove the effectiveness of denoising, whichfocuses on the signiÔ¨Åcant defect patterns. The similarity met- rics called ConÔ¨Ådence and MoD score adjust the Mscores of the image matching in WBMs by considering the nor-malization and the location and area of defect patterns. In experiments on the industry-driven datasets, we veriÔ¨Åed that the proposed pattern search method performs well in thesearches for both single and mixed defect patterns. Consider-ing the experimental data and analysis, the proposed method "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_57", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 57, "text": "tasets, we veriÔ¨Åed that the proposed pattern search method performs well in thesearches for both single and mixed defect patterns. Consider-ing the experimental data and analysis, the proposed method is useful to enhance the results of pattern searches in WBMs. Author contribution Conceptualization: Y oungWook Kwon, SuMin Oh. Methodology: Y oungWook Kwon, SuMin Oh. Formal analysis andinvestigation: Y oungWook Kwon, SuMin Oh, HyunJin Kim. Writing‚Äîoriginal draft preparation: Y oungWook Kwon, SuMin Oh, HyunJinKim. Writing‚Äîreview and editing: Y oungWook Kwon, SuMin Oh,HyunJin Kim. Funding acquisition: HyunJin Kim. Supervision: Hyun-Jin Kim Funding This paper was result of the research project supported by SK hynix Inc. Also, this research was results of a study on the ‚ÄúHPCSupport‚Äù Project, supported by the ‚ÄúMinistry of Science and ICT‚Äù andNIPA.Declarations ConÔ¨Çict of interest The authors declare no competing interests. References 1. Taha K (2025) Observational and experimental insights into machine learning-based defect classiÔ¨Åcation in wafers. J IntellManuf 1‚Äì51 2. Geng H, Sun Q, Chen T, Xu Q, Ho T-Y , Y u B (2023) Mixed-type wafer failure pattern recognition (invited paper). In: 2023"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_58", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 58, "text": "o machine learning-based defect classiÔ¨Åcation in wafers. J IntellManuf 1‚Äì51 2. Geng H, Sun Q, Chen T, Xu Q, Ho T-Y , Y u B (2023) Mixed-type wafer failure pattern recognition (invited paper). In: 2023 28th Asiaand South PaciÔ¨Åc Design Automation Conference (ASP-DAC). pp727‚Äì732 3. Cha J, Jeong J (2022) Improved U-Net with residual attention block for mixed-defect wafer maps. Appl Sci 12(4):2209 4. Wang F-K, Chou J-H, Amogne ZE (2022) A deep convolutional neural network with residual blocks for wafer map defect patternrecognition. Qual Reliab Eng Int 38(1):343‚Äì357 5. Chen Y , Zhao M, Xu Z, Li K, Ji J (2023) Wafer defect recogni- tion method based on multi-scale feature fusion. Front Neurosci17:1202985 6. Bae Y , Kang S (2023) Supervised contrastive learning for wafer map pattern classiÔ¨Åcation. Eng Appl Artif Intell 126:107154 7. Shim J, Kang S (2023) Learning from single-defect wafer maps to classify mixed-defect wafer maps. Expert Syst Appl 233:120923 8. Li J, Tao R, Chen R, Chen Y , Zhao C, Huang X (2024) Sample- imbalanced wafer map defects classiÔ¨Åcation based on auxiliaryclassiÔ¨Åer denoising diffusion probability model. Comput Ind Eng192:110209 9. Saqlain M, Abbas Q, Lee JY (2020) "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_59", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 59, "text": "o C, Huang X (2024) Sample- imbalanced wafer map defects classiÔ¨Åcation based on auxiliaryclassiÔ¨Åer denoising diffusion probability model. Comput Ind Eng192:110209 9. Saqlain M, Abbas Q, Lee JY (2020) A deep convolutional neural network for wafer defect identiÔ¨Åcation on an imbalanced dataset in semiconductor manufacturing processes. IEEE Trans SemicondManuf 33(3):436‚Äì444 10. Lim C, Hur Y (2024) TripletMatch: wafer map defect detection using semi-supervised learning and triplet loss with mixup. IEEEAccess 11. Ezzat AA, Liu S, Hochbaum DS, Ding Y (2021) A graph-theoretic approach for spatial Ô¨Åltering and its impact on mixed-type spa-tial pattern recognition in wafer bin maps. IEEE Trans SemicondManuf 34(2):194‚Äì206 12. De La Torre J, Kent D, Pivin D, St Pierre E Dimensionality reduc- tion and clustering by yield signatures to identify candidates forfailure analysis. In: International symposium for testing and fail-ure analysis, vol 84741. ASM International, pp 1‚Äì6 13. Hou X, Qin G, Lu Y , Yi M, Chen S (2024) A defect detection method of mixed wafer map using neighborhood path Ô¨Åltering clus-tering algorithm. J Electron Test 40(4):419‚Äì433 14. Kang M-S, Shin J-S, Lee D-H (2024) Similarity"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_60", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 60, "text": "Yi M, Chen S (2024) A defect detection method of mixed wafer map using neighborhood path Ô¨Åltering clus-tering algorithm. J Electron Test 40(4):419‚Äì433 14. Kang M-S, Shin J-S, Lee D-H (2024) Similarity searching for wafer bin maps by measuring shape, location, and size similarities ofdefect patterns. Comput Ind Eng 196:110486 15. Alawieh MB, Boning D, Pan DZ (2020) Wafer map defect pat- terns classiÔ¨Åcation using deep selective learning. In: 2020 57thACM/IEEE Design Automation Conference (DAC). IEEE, pp 1‚Äì6 16. Barone M (2020) Image wafer inspection based on template match- ing. Comput Sci Inf Technol 17. Wang R, Wang S (2023) Similarity searching for fault diagnosis of defect patterns in wafer bin maps. Comput Ind Eng 185:109679 18. Hsu C-Y , Chen W-J, Chien J-C (2020) Similarity matching of wafer bin maps for manufacturing intelligence to empower industry 3.5for semiconductor manufacturing. Comput Ind Eng 142:106358 123 2156 The International Journal of Advanced Manufacturing Technology (2025) 138:2139‚Äì2156 19. Wang S, Yan S, Shen Q, Luo C, Ai J, Li L, Wang, D, Ding S, Xia Q (2021) Wafer defect map similarity search using deep learningin semiconductor manufacturing. In: 2021 China "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_61", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 61, "text": "y (2025) 138:2139‚Äì2156 19. Wang S, Yan S, Shen Q, Luo C, Ai J, Li L, Wang, D, Ding S, Xia Q (2021) Wafer defect map similarity search using deep learningin semiconductor manufacturing. In: 2021 China SemiconductorTechnology International Conference (CSTIC). IEEE, pp 1‚Äì4 20. Wu M-J, Jang J-SR, Chen J-L (2015) Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEETrans Semicond Manuf 28(1):1‚Äì12. https://doi.org/10.1109/TSM. 2014.2364237 21. Park S, Jang J, Kim CO (2021) Discriminative feature learning and cluster-based defect label reconstruction for reducing uncertaintyin wafer bin map labels. J Intell Manuf 32:251‚Äì263 22. Hashemi NS, Aghdam RB, Ghiasi ASB, Fatemi P (2016) Tem- plate matching advances and applications in image analysis.arXiv:1610.07231 23. Lowe DG (2004) Distinctive image features from scale-invariant keypoints. Int J Comput Vision 60:91‚Äì110 24. Rublee E, Rabaud V , Konolige K, Bradski G (2011) Orb: an efÔ¨Å- cient alternative to sift or surf. In: 2011 international conferenceon computer vision, pp. 2564‚Äì2571. https://doi.org/10.1109/ICCV . 2011.6126544 25. V erdie Y , Yi K, Fua P , Lepetit V (2015) Tilde: a temporally invari- ant"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_62", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 62, "text": " or surf. In: 2011 international conferenceon computer vision, pp. 2564‚Äì2571. https://doi.org/10.1109/ICCV . 2011.6126544 25. V erdie Y , Yi K, Fua P , Lepetit V (2015) Tilde: a temporally invari- ant learned detector. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp 5279‚Äì5288 26. Yi KM, Trulls E, Lepetit V , Fua P (2016) Lift: learned invariant fea- ture transform. In: Computer Vision‚ÄìECCV 2016: 14th EuropeanConference, Amsterdam, The Netherlands, October 11-14, 2016,Proceedings, Part VI 14. Springer, pp 467‚Äì483 27. Salti S, Tombari F, Spezialetti R, Di Stefano L (2015) Learning a descriptor-speciÔ¨Åc 3D keypoint detector. In: Proceedings of theIEEE international conference on computer vision. pp 2318‚Äì2326 28. DeTone D, Malisiewicz T, Rabinovich A (2018) Superpoint: self- supervised interest point detection and description. In: Proceedingsof the IEEE conference on computer vision and pattern recognitionworkshops. pp 224‚Äì236 29. Revaud J, De Souza C, Humenberger M, Weinzaepfel P (2019) R2D2: reliable and repeatable detector and descriptor. Adv NeuralInform Process Syst 32 30. Sarlin P-E, DeTone D, Malisiewicz T, Rabinovich A (2020) Super- glue: le"}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_63", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 63, "text": "Humenberger M, Weinzaepfel P (2019) R2D2: reliable and repeatable detector and descriptor. Adv NeuralInform Process Syst 32 30. Sarlin P-E, DeTone D, Malisiewicz T, Rabinovich A (2020) Super- glue: learning feature matching with graph neural networks. In:Proceedings of the IEEE/CVF conference on Computer Vision andPattern Recognition (CVPR) 31. Sun J, Shen Z, Wang Y , Bao H, Zhou X (2021) LoFTR: detector- free local feature matching with transformers. CVPR 32. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T, Dehghani M, Minderer M, Heigold G, Gelly S, etal. (2020) An image is worth 16x16 words: transformers for imagerecognition at scale. arXiv:2010.1192933. Lindenberger P , Sarlin P-E, Pollefeys M (2023) Lightglue: local feature matching at light speed. In: Proceedings of the IEEE/CVFinternational conference on computer vision. pp 17627‚Äì17638 34. Fan L, Zhang F, Fan H, Zhang C (2019) Brief review of image denoising techniques. Visual Comp Ind Biomed Art 2(1):7 35. Shinde PP , Pai PP , Adiga SP (2022) Wafer defect localiza- tion and classiÔ¨Åcation using deep learning techniques. IEEEAccess. 10:39969‚Äì39974. https://doi.org/10.1109/ACCESS.2022. 3166512 36. Y "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_64", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 64, "text": "7 35. Shinde PP , Pai PP , Adiga SP (2022) Wafer defect localiza- tion and classiÔ¨Åcation using deep learning techniques. IEEEAccess. 10:39969‚Äì39974. https://doi.org/10.1109/ACCESS.2022. 3166512 36. Y uan T, Kuo W, Bae SJ (2011) Detection of spatial defect pat- terns generated in semiconductor fabrication processes. IEEE TransSemicond Manuf 24(3):392‚Äì403 37. Wang R, Chen N (2022) Detection and recognition of mixed- type defect patterns in wafer bin maps via tensor voting. IEEETrans Semicond Manuf 35(3):485‚Äì494. https://doi.org/10.1109/ TSM.2022.3183008 38. Koch G, Zemel R, Salakhutdinov R, et al (2015) Siamese neural networks for one-shot image recognition. In: ICML deep learningworkshop, vol 2. Lille, pp 1‚Äì30 39. Gilmer J, Schoenholz SS, Riley PF, Vinyals O, Dahl GE (2017) Neural message passing for quantum chemistry. In: Internationalconference on machine learning. PMLR, pp 1263‚Äì1272 40. Battaglia PW, Hamrick JB, Bapst V , Sanchez-Gonzalez A, Zam- baldi V , Malinowski M, Tacchetti A, Raposo D, Santoro A,Faulkner R, et al. (2018) Relational inductive biases, deep learning,and graph networks. arXiv:1806.01261 41. Wang J, Xu C, Yang Z, Zhang J, Li X (2020) Deformable con- volutional "}
{"id": "Recognition and ranking using similarity on defective wafer bin maps.pdf::chunk_65", "source": "Recognition and ranking using similarity on defective wafer bin maps.pdf", "chunk_index": 65, "text": "Raposo D, Santoro A,Faulkner R, et al. (2018) Relational inductive biases, deep learning,and graph networks. arXiv:1806.01261 41. Wang J, Xu C, Yang Z, Zhang J, Li X (2020) Deformable con- volutional networks for efÔ¨Åcient mixed-type wafer defect patternrecognition. IEEE Trans Semicond Manuf 33(4):587‚Äì596. https:// doi.org/10.1109/TSM.2020.3020985 42. Jocher G, Chaurasia A, Qiu J YOLO by Ultralytics (2023). https:// github.com/ultralytics/ultralytics 43. Kingma DP , Ba J (2014) Adam: a method for stochastic optimiza- tion. arXiv:1412.6980 44. Gonzalez R, Woods R (2001) Digital image processing. Addison- Eesle y Longman Publishing Co., Inc, Boston, MA, USA Publisher‚Äôs Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional afÔ¨Åliations. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with theauthor(s) or other rightsholder(s); author self-archiving of the acceptedmanuscript version of this article is solely governed by the terms of suchpublishing agreement and applicable law. 123"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_0", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 0, "text": "Sampling-based Buffer Insertion for Post-Silicon Yield Improvement under Process V ariability Grace Li Zhang, Bing Li and Ulf Schlichtmann Institute for Electronic Design Automation, Technische Universit ¬®at M ¬®unchen, Munich, Germany Email:{grace-li.zhang, b.li, ulf.schlichtmann }@tum.de Abstract ‚ÄîAt submicron manufacturing technology nodes process variations affect circuit performance signiÔ¨Åcantly. This trend leads to a large timing margin and thus overdesign to maintain yield.T o combat this pessimism, post-silicon clock tuning buffers can beinserted into circuits to balance timing budgets of critical pathswith their neighbors. After manufacturing, these clock buffers can be conÔ¨Ågured for each chip individually so that chips with timingfailures may be rescued to improve yield. In this paper , we propose a sampling-based method to determine the proper locations of these buffers. The goal of this buffer insertion is to reduce the number of buffers and their ranges, while still maintaining a good yield improvement. Experimental results demonstrate that our algorithm can achieve a signiÔ¨Åcant yield improvement (up to 35%) with onlya small number of buffers. I. I NTRODUCTION At advanc"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_1", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 1, "text": "ning a good yield improvement. Experimental results demonstrate that our algorithm can achieve a signiÔ¨Åcant yield improvement (up to 35%) with onlya small number of buffers. I. I NTRODUCTION At advanced technology nodes, process variations have be- come relatively larger, and thus caused expensive overdesignto guarantee yield. To alleviate the effect of process variations,many researchers have introduced special circuit components andmechanisms. For instance, post-silicon tuning components can beinserted into the circuit to alleviate the effect of process variations. Since physical parameters are Ô¨Åxed for each individual chip aftermanufacturing, tuning at the post-silicon stage can improve the performance speciÔ¨Åcally for each chip. A widely used post-silicon tuning technique is clock tuning using delay buffers. For example, the structure of the delaybuffer used in [1] is illustrated in Fig. 1. The delay of such a buffer can be changed by setting the conÔ¨Åguration bits in the three registers. In high-performance designs, these tuning buffersare inserted during the design phase. After manufacturing, thedelay values of these buffers are conÔ¨Ågured to allot critical pathsmore timing budg"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_2", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 2, "text": "ters. In high-performance designs, these tuning buffersare inserted during the design phase. After manufacturing, thedelay values of these buffers are conÔ¨Ågured to allot critical pathsmore timing budget by shifting clock edges toward the stageswith smaller combinational delays. These critical paths might bedifferent in individual chips due to process variations, so that onlypost-silicon tuning can counterbalance them effectively. With thispost-silicon tuning, chips that might have failed to meet timingspeciÔ¨Åcations can be revitalized, leading to an increased yield atthe expense of additional area required by these buffers. In this paper, we propose a method to insert post-silicon tuning buffers at the design phase for yield improvement. Thismethod uses Monte Carlo simulation to emulate produced chips and conÔ¨Åne tuning buffers to as few Ô¨Çip-Ô¨Çops as possible ineach sample. After the whole simulation is Ô¨Ånished, only thosebuffers that are critical to the yield are kept in the circuit. The proposed method captures the locations and ranges of tuningbuffers directly without an intermediate formulation so thatheuristics in statistical optimization are avoided. In addition,this direct simu"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_3", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 3, "text": " proposed method captures the locations and ranges of tuningbuffers directly without an intermediate formulation so thatheuristics in statistical optimization are avoided. In addition,this direct simulation method provides correlation information between buffer tuning values. This information is used to groupbuffers so that the total area taken by the buffers is reducedeffectively. The rest of this paper is organized as follows. In Section II we give an overview of timing constraints for circuits with post-silicon clock tuning buffers and formulate the buffer insertionproblem. We explain the proposed method in detail in Section III.Experimental results are shown in Section IV. Conclusion andfuture work are given in Section V.scanin012 shiftscanout conÔ¨Åguration bitsdelay element CLK IN CLK OUT Fig. 1. Post-silicon tuning buffer in [1]. II. T IMING CONSTRAINTS WITH CLOCK BUFFERS AND PROBLEM FORMULA TION The timing constraints with clock tuning buffers can be ex- plained using Fig. 2, where two Ô¨Çip-Ô¨Çops with such buffers areconnected by a combinational circuit. Assume that the clocksignal switches at reference time 0. Then the clock events at Ô¨Çip-Ô¨Çopsiandjhappen at time x iandxj, resp"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_4", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 4, "text": "re two Ô¨Çip-Ô¨Çops with such buffers areconnected by a combinational circuit. Assume that the clocksignal switches at reference time 0. Then the clock events at Ô¨Çip-Ô¨Çopsiandjhappen at time x iandxj, respectively. To meet the setup time and hold time constraints, the following inequationsmust be satisÔ¨Åed x i+dij‚â§xj+T‚àísj (1) xi+dij‚â•xj+hj (2) wherexiandxjare delay values of tuning buffers, dij(dij) is the maximum (minimum) delay of the combinational circuit betweenÔ¨Çip-Ô¨Çops iandj,s j(hj) is the setup (hold) time of Ô¨Çip-Ô¨Çop j, andTis the clock period. Here the clock buffers introduce two delay variables into the constraints (1) and (2). Without them,the two inequations fall back to the classic timing constraints ofdigital circuits. Owing to area constraints, the conÔ¨Ågurable delay of a clock buffer usually has a limited range. This range determines the size of the buffer so that it should be as small as possible. Assumethat the lower bound of the tuning values of buffer iisr iand the range of the buffer is œÑi. The delay value of buffer ican thus be constrained by a range window as ri‚â§xi‚â§ri+œÑi. (3) Unlike [2], here we model the range window of the tuning values as asymmetrical with respect t"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_5", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 5, "text": "he buffer is œÑi. The delay value of buffer ican thus be constrained by a range window as ri‚â§xi‚â§ri+œÑi. (3) Unlike [2], here we model the range window of the tuning values as asymmetrical with respect to 0 to achieve a maximalÔ¨Çexibility. Furthermore, x imay only take discrete values due to implementation issues. When process variations are considered, the combinational delaysdijanddij, setup time sjand hold time hjin (1) and (2) become random variables. In addition, the tuning delays xiand xjalso become statistical because the clock buffers are subject to process variations. Since these variations can be decomposed and merged with dij,dij,sjandhj, e.g., using the canonical form in [3], we assume henceforth that a tuning delay can be conÔ¨Åguredto a Ô¨Åxed value in (3) for simplicity. In real circuits, the number of clock tuning buffers is limited. To maintain a good yield improvement, the problem of buffer insertion can thus be described as Problem Buffer-Insertion: Select a set of Ô¨Çip-Ô¨Çops to insert clock tuning buffers to improve the yield of the circuit. The number and ranges of buffers should be kept as small as possible. In addition, the bounds of tuningranges should be determined, "}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_6", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 6, "text": "to insert clock tuning buffers to improve the yield of the circuit. The number and ranges of buffers should be kept as small as possible. In addition, the bounds of tuningranges should be determined, which can vary at different buffersand cover negative delays. The predominant challenge in solving the Buffer-Insertion problem comes from the random variables in (1) and (2). These 1457 978-3-9815370-7-9/DATE16/ c/circlecopyrt2016 EDAA Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:50:39 UTC from IEEE Xplore. Restrictions apply. xj xi clkiclk clkjcomb. circuit FF FF clkj clkclki reference time 0 xjhjsjxi Ti j Fig. 2. Timing of circuits with tuning buffers. variables make it very difÔ¨Åcult to model the formulation above as an optimization problem, since statistical optimization veryoften resorts to heuristic approximations based on Monte Carlosimulation such as in [2]. In addition, the variables x iandxjin (1) and (2) may only take discrete values in the range windowdeÔ¨Åned by (3). For example, a de-skew buffer in [4] can beconÔ¨Ågured to only 20 discrete delays. In this case, integer linear programming (ILP) becomes almost the only method a"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_7", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 7, "text": "alues in the range windowdeÔ¨Åned by (3). For example, a de-skew buffer in [4] can beconÔ¨Ågured to only 20 discrete delays. In this case, integer linear programming (ILP) becomes almost the only method available to deal with the constraint set deÔ¨Åned by (1)‚Äì(3). In the proposedmethod, we use ILP-based Monte Carlo simulation to identifythe buffer locations and tuning ranges directly. III.S OLVING THE BUFFER -INSERTION PROBLEM BY SAMPLING -BASED SIMULA TION To identify where buffers should be inserted, we use a sampling-based method to deal with the complexity from processvariations. The overall Ô¨Çow of the proposed method is shown inFig. 3. The input of the proposed method includes the circuitstructure, statistical gate delays and speciÔ¨Åcations of availableclock buffers such as the given maximum range and the numberof discrete steps. The proposed method improves the yield of thecircuit with respect to a give clock period T, the same as in [2]. The output of the proposed method are locations of buffers andthe reduced ranges of their tuning delays. The number and rangesof buffers should be kept as small as possible. In the proposed method, we Ô¨Årst assume that each Ô¨Çip-Ô¨Çop has a tuning buf"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_8", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 8, "text": " of buffers andthe reduced ranges of their tuning delays. The number and rangesof buffers should be kept as small as possible. In the proposed method, we Ô¨Årst assume that each Ô¨Çip-Ô¨Çop has a tuning buffer attached. We then sample the statisticalvariables in (1) and (2) and minimize the number of buffersrequired to achieve the given clock period for a speciÔ¨Åc sample.Here a sample can be considered as a representative chip aftermanufacturing. With enough samples, the trend where buffers should be inserted can thus be recognized, and only those buffers that affect the yield signiÔ¨Åcantly are kept in the circuit. The proposed method contains three major steps. In the Ô¨Årst step, we allow the lower bounds of buffers to Ô¨Çoat freely, becauseat this stage the lower bound r iin (3) is still unknown. For each sample, we minimize the number of required buffers andpush the tuning values of buffers toward 0. Because these tuning values should be covered by the given tuning range windows, this value concentration can narrow the distributions of tuningvalues effectively. At the end of this step, the lower bound r i is determined by Ô¨Ånding the range window with a range œÑithat covers the most tuning v"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_9", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 9, "text": "ncentration can narrow the distributions of tuningvalues effectively. At the end of this step, the lower bound r i is determined by Ô¨Ånding the range window with a range œÑithat covers the most tuning values in the simulation to maintain theyield. With the lower bounds determined, we rerun the sampling process in the second step. For each sample, we minimize thenumber of required buffers for each sample and then concentratetuning values toward their average. The latter is different fromthe previous step. In the Ô¨Årst step, the lower bounds of buffersÔ¨Çoat freely, so that an average of tuning values does not reÔ¨Çectthe center of a tuning range. Therefore, we focus on the reductionof buffer number by pushing tuning values toward 0. In the second step, the bounds of buffer ranges have been determined,so that the average can represent the trend of tuning values.Consequently, pushing tuning values toward this average mayreduce the ranges of buffers. Finally, the ranges of buffers are determined by the smallest and the largest tuning values,Circuit, Statistical gate delays, Buffer spec., Target T Find the minimum number of required buffers for each sample with Ô¨Çoating lower bounds Buffer prun"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_10", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 10, "text": "by the smallest and the largest tuning values,Circuit, Statistical gate delays, Buffer spec., Target T Find the minimum number of required buffers for each sample with Ô¨Çoating lower bounds Buffer pruning Push buffer values toward zero in each sample Assign Ô¨Çoating lower boundsdetermine buffer Ô¨Çoating bounds Concentrate buffer tuning Group buffers according toreduce buffer range Buffer locations and rangesvalues toward average correlation of tuning valuesIII-A1 III-A2 III-A3 III-A4 III-B1 III-B2 III-C(step 1) (step 2) (step 3)to narrow tuning ranges Find the minimum number of required buffers for each sample with Ô¨Åxed lower bounds Fig. 3. Overall Ô¨Çow to determine buffer locations and tuning ranges. The numbers are the sections in which the corresponding steps are described. respectively. In the last step, buffers are grouped according to their tuning correlation. If two buffers have highly correlated tuning values,they can share the same buffer to save area. The correlation information is a natural result of the sampling-based method sothat buffers can be grouped easily. The advantage of the simulation-based method is that it does not rely on the distributions of random variables. T"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_11", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 11, "text": "is a natural result of the sampling-based method sothat buffers can be grouped easily. The advantage of the simulation-based method is that it does not rely on the distributions of random variables. The challengeof this method is a large runtime, although it can be parallelizedeasily onto multiple CPU cores for acceleration. To solve theruntime problem, we introduce several techniques which canaccelerate the proposed method effectively. A. Determining lower bounds of the range windows In this step, we have no information about where to insert buffers and how to set the lower bounds of these buffers. Sincethe circuit structure and delay distributions all affect the locationsof buffers, we resort to sampling-based simulation to gatherpreliminary information. The basic idea is that we sample thedelays of the circuit and create an ILP model for each sampleto conÔ¨Åne the tunings of buffers to as few Ô¨Çip-Ô¨Çops as possible,while the lower bounds of the tuning ranges are allowed to Ô¨Çoatfreely. With a large number of samples, the trend where thebuffers should be inserted can be exposed by the concentrationof tunings to only a few Ô¨Çip-Ô¨Çops. These Ô¨Çip-Ô¨Çops are actuallythe critical ones affectin"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_12", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 12, "text": "ith a large number of samples, the trend where thebuffers should be inserted can be exposed by the concentrationof tunings to only a few Ô¨Çip-Ô¨Çops. These Ô¨Çip-Ô¨Çops are actuallythe critical ones affecting the yield of the circuit. To model whether a buffer should be adjusted, we use a binary variablec iassigned for the ith buffer and deÔ¨Åned as ci=/braceleftbigg 1theith buffer is adjusted, so that xi/negationslash=0, 0otherwise when xi=0.(4) According to [5], this constraint can be transformed to xi‚â§ciŒì (5) ‚àíxi‚â§ciŒì (6) whereŒìis very large constant. If xiis larger than 0, then cimust be 1. Ifxiis smaller than 0, cishould also be set to 1. The only situation that cican be set to 0 is when xiis 0, meaning that there is no tuning. From the analysis above, we can observe that ciis an upper bound of the tuning number for the ith buffer, since cican also be set to 1 even if xi=0. Accordingly, the sum of cis for all tuning buffers is an upper bound of the number of required buffers forthe sample. This upper bound can be expressed as c sum=/summationdisplay ici,i‚ààI (7) 1458 2016 Design, Automation & Test in Eur ope Conference & Exhibition (DATE) Authorized licensed use limited to: Hochschule He"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_13", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 13, "text": "This upper bound can be expressed as c sum=/summationdisplay ici,i‚ààI (7) 1458 2016 Design, Automation & Test in Eur ope Conference & Exhibition (DATE) Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:50:39 UTC from IEEE Xplore. Restrictions apply. 2055 1 5 191 51111 5 prune this node Fig. 4. Pruning buffers with low tuning numbers. whereIis the index set of all the tuning buffers. If we minimize this upper bound, the total number of tunings is also minimized. Besides minimizing the total number of buffers csum , we also hope that the tuning values are not scattered widely, so that theycan be covered by a range window with the range equal to œÑ i.T o achieve this goal, we minimize the distance between these valuesand 0. Consequently, the second objective of the optimization task is/summationtext I i=1|xi|, which is total distance of the tuning values to 0. In our formulation, the number of buffers has a priority in optimization, because fewer buffers mean a smaller area as wella simpler layout design. Therefore, we split the optimizationproblem into two. In the Ô¨Årst one we set the objective to c sum to Ô¨Ånd the minimum number of required "}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_14", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 14, "text": "r buffers mean a smaller area as wella simpler layout design. Therefore, we split the optimizationproblem into two. In the Ô¨Årst one we set the objective to c sum to Ô¨Ånd the minimum number of required buffers for each sample.This number is used as a constraint in the second optimization problem to minimize/summationtext I i=1|xi|. After the Ô¨Årst optimization, we prune buffers with few tunings so that the execution timeof solving the second optimization problem can be reducedsigniÔ¨Åcantly. 1) Minimizing buffer tuning with Ô¨Çoating lower bounds With the number of tunings c sum deÔ¨Åned in (7), we describe the Ô¨Årst optimization problem as follows. For each sample mk‚ààM, (8) Minimize csum (9) s.t. setup and hold time constraints (1) and (2) (10) constraints of required tuning buffers (5)‚Äì(7) (11) range constraints (3) (12) ri‚â§0andri+œÑi‚â•0 (13) wheremkrepresents the kth sample of the circuit. Mis the set of all samples in the simulation and its cardinality |M| is the number of samples in the simulation. In the formulation above, the lowerbounds of r iare variables and determined by the solver. The constraint (13) requires that 0 is covered by the range window.After the optimization problem (8)"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_15", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 15, "text": "ation. In the formulation above, the lowerbounds of r iare variables and determined by the solver. The constraint (13) requires that 0 is covered by the range window.After the optimization problem (8)‚Äì(13) is solved for the kth sample, we denote the tuning number of the whole circuit in thesamplem kbynk. 2) Buffer pruning Since the optimization problem above tries to reduce the num- ber of required buffers as much as possible, many buffers are not adjusted or adjusted only for a few times even with the Ô¨Çoatinglower bounds. Fig. 4 shows such an example, where nodesrepresent buffers and edges represent combinational connectionsbetween Ô¨Çip-Ô¨Çops. The numbers represent how many times in the|M| simulation samples the corresponding buffer is used. We remove the nodes whose tuning numbers are no large thanone and are not connected to other critical nodes. The latter is deÔ¨Åned as the nodes with tuning numbers no smaller than a givennumber, which is set to 5 as the number of simulation samplesis set to 10 000 in our experiments. For example, we remove thenode with dashed line from the graph in Fig. 4. This removalnot only accelerates the following steps due to fewer nodes inthe graph, but ma"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_16", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 16, "text": " set to 10 000 in our experiments. For example, we remove thenode with dashed line from the graph in Fig. 4. This removalnot only accelerates the following steps due to fewer nodes inthe graph, but may also reduce the problem space signiÔ¨Åcantlyby partitioning the graph into unconnected sub-graphs. 3) Concentrating tuning values around zero The optimization problem in (9)‚Äì(13) only reduces the number of tunings in each sample. Since the optimization problemsfor different samples are solved separately, the solver does not guarantee to use the same set of buffers in case more than one feasible solution exists. Consequently, the tuning values of abuffer from all the samples may become scattered into a wide distribution, as illustrated in Fig. 5a, where the x-axis representsthe tuning delays of a buffer in all simulation samples, and they-axis the number of occurrences of discrete delay values. To push the scattered tuning values into a narrower range, we minimize their absolute values in the optimization. In this way,the solver tries to return the buffer values around 0 as much aspossible, while maintaining the minimum tuning number n kof buffers in the kth simulation sample mkobtained"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_17", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 17, "text": "he optimization. In this way,the solver tries to return the buffer values around 0 as much aspossible, while maintaining the minimum tuning number n kof buffers in the kth simulation sample mkobtained by solving the problem (8)‚Äì(13). The latter constraint guarantees that the number of tuning is still optimal for each sample. For each sample mk‚ààM, (14) MinimizeI/summationdisplay i=1|xi| (15) s.t. constraints (10)‚Äì(13) (16) csum‚â§nk (17) where the objective function (15) can be transformed into a linear form easily [5]. 4) Assigning Ô¨Çoating lower bounds After tuning values are pushed toward 0, we try to cover all the tuning values using a range window of the maximum range œÑi.A s shown in Fig. 5b, the range window slides along the x-axis. Sincethe y-axis represents the numbers of the corresponding tuningvalues occurred in all simulation samples, the overall coveredbuffer tunings by the window is thus the sum of the tuningnumbers in the window. For yield improvement, we select therange window that covers the largest number of tuning values. In this way, the lower bound of the tuning range is determined as the leftmost value of the range window. B. Identify buffers with Ô¨Åxed lower bounds"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_18", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 18, "text": "ow that covers the largest number of tuning values. In this way, the lower bound of the tuning range is determined as the leftmost value of the range window. B. Identify buffers with Ô¨Åxed lower bounds With the lower bounds of buffers determined, the locations and ranges of buffers should be evaluated again since the Ô¨Åxed lowerbounds for all the buffers invalidate previous simulation results.The basic concept of learning from simulation is similar to thesteps above. 1) Minimizing buffer tunings with Ô¨Åxed range bounds After the lower bounds are Ô¨Åxed, the variables r iin (3) and (13) become constants. Therefore, we execute the simulation-optimization process (8)‚Äì(13) again to capture more realistictuning values of buffers. In practice, this simulation step can beskipped if the number of tunings outside the determined rangewindows is very small. In our method, we skip this simulationstep if the missing tunings appear in less than 0.1% of allsimulation samples. 2) Concentrating buffer tunings toward the average After running simulation samples with Ô¨Åxed buffer ranges, the tuning values are all conÔ¨Åned in given range windows. Theirvalues, however, may be scattered widely because the solv"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_19", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 19, "text": "gs toward the average After running simulation samples with Ô¨Åxed buffer ranges, the tuning values are all conÔ¨Åned in given range windows. Theirvalues, however, may be scattered widely because the solveronly returns feasible delays without considering the results ofprevious tuning values. This is the same problem described inSection III-A3. Similarly, we try to centralize the buffer valuesfurther toward the average tuning delays x avg,i of all the samples. The mathematical problem is formulated below. Here we also usethe minimum tuning numbers n kto guarantee that in this new round of simulation the solver does not increase the number ofbuffers. For each sample m k‚ààM, (18) MinimizeI/summationdisplay i=1|xi‚àíxavg,i| (19) s.t. constraints (10)‚Äì(13) (20) csum‚â§nk (21) This step is very similar to the problem formulation in (14)‚Äì (17). The only difference is that we centralize the delay tunings 2016 Design, Automation & Test in Eur ope Conference & Exhibition (DATE) 1459 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:50:39 UTC from IEEE Xplore. Restrictions apply. -5 5 10 15num. of occurrences adj. values 0 lower bound riof range window (a)"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_20", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 20, "text": "se limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:50:39 UTC from IEEE Xplore. Restrictions apply. -5 5 10 15num. of occurrences adj. values 0 lower bound riof range window (a)concentrate delay values 5 10num. of occurrences adj. values reduced buffer range0 (c)5 10 15num. of occurrences adj. values buffer range0 (b)concentrate delay valuestoward 0 toward average xavg,i Fig. 5. Concentrating tunings of a buffer in all samples. highly correlatedr(i,j)‚â•0.8 group buffersd(i,j)‚â§10 small distanceFF FFi j buffer groupingFF FFi j(xi,yi) (xj,yj)d(i,j)=|xi‚àíxj|+|yi‚àíyj| manhatten distance Fig. 6. Buffer grouping according to tuning correlation and distance. Correlation threshold rtis set to 0.8. Distance threshold dtbetween buffers is set to ten times of the minimum distance between Ô¨Çip-Ô¨Çops. toward the average instead of zero. In (14)‚Äì(17) we try to Ô¨Ånd the most effective lower bounds of buffers so that we use asfew buffers as possible. Consequently, we concentrate the tuningvalues around zero. In (18)‚Äì(21) the lower bounds have beenÔ¨Åxed and we only try to narrow the scattered tuning values toreduce the ranges of the buffers. Therefore, we push all tuningvalues toward"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_21", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 21, "text": "ningvalues around zero. In (18)‚Äì(21) the lower bounds have beenÔ¨Åxed and we only try to narrow the scattered tuning values toreduce the ranges of the buffers. Therefore, we push all tuningvalues toward the average instead of zero. Finally, the rangesof buffers are assigned according to the largest and the smallesttuning value, as illustrated in Fig. 5c. C. Grouping In the last step of buffer insertion, we group buffers with similar tuning values to reduce the number of buffers insertedinto the circuit. Buffers in the same group are implemented by only one physical buffer and the tuning values are shared by all the Ô¨Çip-Ô¨Çops connected to the buffer. The concept of grouping isillustrated in Fig. 6. In grouping buffers, we Ô¨Årst calculate the correlation coefÔ¨Å- cients of tuning values of individual buffer pairs. If the mutual correlation coefÔ¨Åcients between several buffers are all above thethreshold r tand their distance is smaller than dt, they are grouped together and implemented with only one physical buffer. Inpractice, designers can also constrain the total number of buffersin the circuit. If the buffer number after grouping still exceeds thespeciÔ¨Åed number, we remove the buffers wi"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_22", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 22, "text": " one physical buffer. Inpractice, designers can also constrain the total number of buffersin the circuit. If the buffer number after grouping still exceeds thespeciÔ¨Åed number, we remove the buffers with the fewest tuningsuntil the number of buffers meets the speciÔ¨Åcation. IV .E XPERIMENTAL RESULTS The proposed method was implemented in C++ and tested using a 3.20 GHz CPU with one thread. We demonstrate the results with circuits from the ISCAS89 benchmark set and from the TAU 2013 variation-aware timing analysis contest. To thesecircuits we also added clock skews so that they have more criticalpaths. Information about these circuits is shown in Table I, wheren sis the number of Ô¨Çip-Ô¨Çops and ngthe number of logic gates. We assumed that the maximum allowed buffer ranges were 1/8of the original clock period [4]. All tuning delays are assumeddiscrete with 20 steps. The logic gates in the circuits were mappedto a library from an industry partner. The standard deviations oftransistor length, oxide thickness and threshold voltage were setto 15.7%, 5.3% and 4.4% of the nominal values. The ILP solver for the optimization problems was Gurobi [6]. In the proposedmethod, we generate 10 000 samp"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_23", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 23, "text": "oxide thickness and threshold voltage were setto 15.7%, 5.3% and 4.4% of the nominal values. The ILP solver for the optimization problems was Gurobi [6]. In the proposedmethod, we generate 10 000 samples to capture the locations andranges of buffers. The experiment results are shown in Table I. To test a circuit, we Ô¨Årst run Monte Carlo simulation to calculate the mean Œº T and standard œÉTof the clock period without post-silicon tuning buffers. The original yields Yoof the circuits with the clock period equal toŒºT,ŒºT+œÉTandŒºT+2œÉTare thus about 50%, 84.13%, 97.72%, respectively. In Table I the columns Y(%) shows the yields with post-silicon tuning buffers. The columns Yi(%) show the yield improvements compared with the original yields withoutbuffers, equal to Y‚àíY o. From this comparison, we can see clearly that the yields of circuits can be improved signiÔ¨Åcantly(up to 35.97%). The numbers of buffers inserted into the circuits to achieve yield improvements above are shown in the columns N b. These numbers are less than 1% of the numbers of Ô¨Çip-Ô¨Çops in thecircuits for a signiÔ¨Åcant yield improvement. In addition to thenumbers of buffers, the average ranges of buffers are shown in thecolu"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_24", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 24, "text": "b. These numbers are less than 1% of the numbers of Ô¨Çip-Ô¨Çops in thecircuits for a signiÔ¨Åcant yield improvement. In addition to thenumbers of buffers, the average ranges of buffers are shown in thecolumnsA b. Since we centralize the buffer values as illustrated in Fig. 5c, the ranges of buffers are much smaller than the maximumbuffer range 20 so that the area taken by inserted buffers can bereduced. In Table I the columns T(s)show the runtimes of the proposed method in different settings. For the largest circuit pci bridge32, the proposed method needs 5124.25 seconds to Ô¨Ånish the com-putation. These runtimes are acceptable since buffer insertion is normally executed at a late design phase only for a few times. V. C ONCLUSION In this paper, we propose a sampling-based method to de- termine locations and ranges of post-silicon tuning buffers in acircuit to improve yield. Experimental results conÔ¨Årm that yield can be improved signiÔ¨Åcantly with a small number of buffers. Future work includes post-silicon testing and conÔ¨Åguration ofdelays buffers to achieve the given clock period. Challenges are a balance between testing cost and yield improvement in complex scenarios such as clock binni"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_25", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 25, "text": "s post-silicon testing and conÔ¨Åguration ofdelays buffers to achieve the given clock period. Challenges are a balance between testing cost and yield improvement in complex scenarios such as clock binning. R EFERENCES [1] S. Naffziger, B. Stackhouse, T. Grutkowski, D. Josephson, J. Desai, E. Alon, and M. Horowitz, ‚ÄúThe implementation of a 2-core, multi-threaded Itanium family proces- sor,‚Äù IEEE J. Solid-State Circuits , vol. 41, no. 1, pp. 197‚Äì209, Jan. 2006. [2] J.-L. Tsai, L. Zhang, and C. C.-P . Chen, ‚ÄúStatistical timing analysis driven post-silicon- tunable clock-tree synthesis,‚Äù in Proc. Int. Conf. Comput.-Aided Des. , 2005, pp. 575‚Äì 581. [3] C. Visweswariah, K. Ravindran, K. Kalafala, S. Walker, and S. Narayan, ‚ÄúFirst-order incremental block-based statistical timing analysis,‚Äù in Proc. Design Autom. Conf. , 2004, pp. 331‚Äì336. [4] S. Tam, S. Rusu, U. Nagarji Desai, R. Kim, J. Zhang, and I. Y oung, ‚ÄúClock generation and distribution for the Ô¨Årst IA-64 microprocessor,‚Äù IEEE J. Solid-State Circuits , vol. 35, no. 11, pp. 1545‚Äì1552, Nov. 2000. [5] D. Chen, R. Batson, and Y . Dang, Applied Integer Programming: Modeling and Solution . Wiley, 2011. [6] Gurobi Optimization, Inc., ‚ÄúGurob"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_26", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 26, "text": "tate Circuits , vol. 35, no. 11, pp. 1545‚Äì1552, Nov. 2000. [5] D. Chen, R. Batson, and Y . Dang, Applied Integer Programming: Modeling and Solution . Wiley, 2011. [6] Gurobi Optimization, Inc., ‚ÄúGurobi optimizer reference manual,‚Äù 2013. [Online]. Available: http://www.gurobi.com TABLE I. R ESULTS OF BUFFER NUMBER AND YIELD IMPROVEMENT Circuit ŒºT ŒºT+œÉT Œº+2œÉT nsng NbAbY(%)Yi(%)T(s)NbAbY(%)Yi(%)T(s)NbAbY(%)Yi(%)T(s) s9234 211 5597 2 12.50 77.11 27.11 54.22 2 12.00 95.94 11.81 47.11 2 11.00 99.18 1.46 7.79 s13207 638 7951 5 9.80 72.37 22.37 156.05 5 14.20 96.42 12.29 92.84 6 17.30 99.53 1.81 24.16 s15850 534 9772 5 19.80 69.34 19.34 223.09 5 19.40 94.33 10.20 90.89 5 15.20 99.12 1.40 23.42 s38584 1426 19253 11 9.74 85.97 35.97 1800.14 7 13.14 98.48 14.35 683.62 7 13.57 98.94 1.22 223.95 mem ctrl 1065 10327 10 11.90 67.11 17.11 1206.54 10 11.70 94.58 10.45 531.78 10 8.70 98.91 1.19 147.89 usb funct 1746 14381 17 17.18 71.77 21.77 2202.69 17 16.82 96.57 12.44 670.63 9 4.00 98.73 1.01 145.77 ac97 ctrl 2199 9208 21 15.10 75.05 25.05 2225.54 21 15.43 94.92 10.79 800.31 8 13.00 97.73 0.01 111.38 pci bridge32 3321 12494 32 13.84 73.66 23.66 5124.25 32 9.41 96.76 12.63 2594.26 8 9.50 98.67 0.9"}
{"id": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf::chunk_27", "source": "Sampling-based_buffer_insertion_for_post-silicon_yield_improvement_under_process_variability.pdf", "chunk_index": 27, "text": "ac97 ctrl 2199 9208 21 15.10 75.05 25.05 2225.54 21 15.43 94.92 10.79 800.31 8 13.00 97.73 0.01 111.38 pci bridge32 3321 12494 32 13.84 73.66 23.66 5124.25 32 9.41 96.76 12.63 2594.26 8 9.50 98.67 0.95 586.74 1460 2016 Design, Automation & Test in Eur ope Conference & Exhibition (DATE) Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:50:39 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_0", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 0, "text": "Expert Systems With Applications 238 (2024) 122301 Available online 31 October 2023 0957-4174/¬© 2023 Published by Elsevier Ltd. Contents lists available at ScienceDirect Expert Systems With Applications journal homepage: www.elsevier.com/locate/eswa Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN Siyamalan Manivannan Department of Computer Science, Faculty of Science, University of Jaffna, Sri Lanka A R T I C L E I N F O Keywords: Wafer bin map classification Semi-supervised learning Deep learning Semiconductor manufacturingA B S T R A C T Wafer Bin Map (WBM) defect patterns are a critical aspect of identifying the root cause of manufacturing defects in the semiconductor industry. Semi-supervised learning (SSL) approaches have gained popularity for this purpose, as they can leverage both labeled and unlabeled data to improve model performance. However, SSL of WBM defect patterns is challenging due to class imbalance, where some defect classes have many more examples than others. Most of the existing SSL approaches assume a balanced dataset and often fail to provide satisfactory results when applied to imbalanced class problems. To address th"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_1", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 1, "text": "ve many more examples than others. Most of the existing SSL approaches assume a balanced dataset and often fail to provide satisfactory results when applied to imbalanced class problems. To address this issue, this work proposes a novel Dual-Head Convolutional Neural Network (CNN) architecture that contains two classifier heads. One classifier head maximizes overall classification scores, while the other aims to maximize per-class classification scores, providing equal attention to both majority and minority classes. The proposed CNN architecture uses pseudo-labels selected based on the outputs of these two classifiers to expand the labeled training set, which is then used to retrain the CNN. In this way, highly confident pseudo-labels are selected even from the minority classes, leading to better model training. Experiments show that the proposed approach is effective in handling class-imbalanced classification of WBM defect patterns, reporting state-of-the-art classification with an F1 score of 0.918, accuracy of 98.2% and a mean per-class accuracy of 91.7% using a lightweight ResNet-10 model as the backbone on the real-world public WBM dataset, WM-811K. The proposed approach‚Äôs s"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_2", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 2, "text": "F1 score of 0.918, accuracy of 98.2% and a mean per-class accuracy of 91.7% using a lightweight ResNet-10 model as the backbone on the real-world public WBM dataset, WM-811K. The proposed approach‚Äôs success suggests that it could be a valuable tool for improving the accuracy and reliability of WBM defect pattern classification in semiconductor manufacturing. The code is available at https://github.com/M-Siyamalan/SSL-DHCNN . 1. Introduction Semiconductor devices are manufactured on circular slices of semi- conductor material, typically silicon, known as wafers. A Wafer Bin Map (WBM) ( Fig. 1) is a graphical representation that displays the areas of the wafer containing functional dies that meet specifications, as well as the areas that contain defective dies. The WBM is an important tool for semiconductor manufacturers, as it allows them to identify the root cause of defects in the manufacturing process. By analyzing the WBM, experts can identify patterns in the distribution of good and bad dies and adjust the manufacturing process to reduce the number of defects and increase the yield of good dies. However, manually identifying WBM defect patterns can be time-consuming and prone t"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_3", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 3, "text": "d bad dies and adjust the manufacturing process to reduce the number of defects and increase the yield of good dies. However, manually identifying WBM defect patterns can be time-consuming and prone to errors. Automatically identifying defect patterns in WBM is crucial for the semiconductor manufacturing industry. It enhances accuracy, reduces the time and costs associated with manual inspection, and improves overall efficiency. Several automated approaches have been proposed for WBM defect classification, most of which are based on fully supervised learning (FSL). These FSL approaches (e.g., Adly, Alhussein et al. (2015 ), Adly, E-mail address: siyam@univ.jfn.ac.lk .Yoo et al. (2015 ), Chen et al. (2023 ), Chien, Hsu, and Chen (2013 ), Piao, Jin, Lee, and Byun (2018 ), Shin, Kahng, and Kim (2022 ) and Shin and Yoo (2023 )) require large amount of labeled data to train, which is usually difficult to obtain as labeling is a tedious and costly process. In contrast, semi-supervised learning (SSL) (e.g., Kahng and Kim (2021 ), Sohn et al. (2020 ) and Zhang et al. (2021 )) leverages both labeled and unlabeled data for training the system and has been shown to improve performance over FS"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_4", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 4, "text": "ng (SSL) (e.g., Kahng and Kim (2021 ), Sohn et al. (2020 ) and Zhang et al. (2021 )) leverages both labeled and unlabeled data for training the system and has been shown to improve performance over FSL. However, most existing SSL approaches, including FixMatch ( Sohn et al. , 2020 ), assume a uniform distribution of the number of images from different classes, which is not representative of real-world scenarios. In reality, data often follows a long-tail distribution, with the majority of images belonging to one class and many classes having very few data points, resulting in data imbalance. In such cases, most existing SSL approaches fail to provide good results as the CNN trained on class imbalanced datasets are biased towards the classes which contains the majority of the data points. The classification of WBM is an example of highly imbalanced data classification, where the majority of WBM show no clear defect https://doi.org/10.1016/j.eswa.2023.122301 Received 26 July 2023; Received in revised form 17 September 2023; Accepted 20 October 2023 Expert Systems With Applications 238 (2024) 122301 2S. Manivannan Fig. 1. Example images from different classes of the WM-811K dataset.1."}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_5", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 5, "text": "ed in revised form 17 September 2023; Accepted 20 October 2023 Expert Systems With Applications 238 (2024) 122301 2S. Manivannan Fig. 1. Example images from different classes of the WM-811K dataset.1. patterns, while the remaining ones are distributed among different classes of defect patterns. This work proposes a novel SSL approach for WBM classification. The proposed approach is based on a Dual-Head CNN architecture that is designed to handle data imbalance effectively. The proposed architecture contains two classifier heads. The first classifier head aims to maximize overall accuracy values, while the second one aims to max- imize the average of per-class accuracy values. Initially, the proposed CNN is trained using the available labeled training data. Then, it is used to identify high-confident pseudo-labels from the unlabeled data using the output from both classifier heads. The experiments demon- strate that high confident pseudo-labels can be selected even from the minority classes with high precision and recall values by the proposed approach, leading to better CNN training. The newly selected data is then used to expand the labeled training set, which is subsequently used"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_6", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 6, "text": "sses with high precision and recall values by the proposed approach, leading to better CNN training. The newly selected data is then used to expand the labeled training set, which is subsequently used to retrain the proposed CNN. The proposed SSL approach is shown to be effective, particularly for imbalanced data classification of WBM. Comparative experiments indicate that the proposed approach is the new state-of-the-art for WBM defect classification. In the following, the work related to WBM defect classification using both FSL and SSL approaches are reviewed in Section 2. The proposed methodology is explained in detail in Section 3. The experiments and results are discussed in detail in Section 4, including the evaluation of the proposed approach against the state-of-the-art methods. Finally Section 5 concludes this work. 2. Related work Deep learning-based approaches for WBM classification have been widely studied in recent years. This section reviews these approaches under FSL and SSL setting. 2.1. FSL approaches These approaches use labeled data to train deep learning models. Various deep learning-based FSL approaches have been explored for WBM defect classification, with mos"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_7", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 7, "text": " SSL setting. 2.1. FSL approaches These approaches use labeled data to train deep learning models. Various deep learning-based FSL approaches have been explored for WBM defect classification, with most of them focusing on applying existing off-the-shelf CNN architectures for this problem. ResNet ( Mani- vannan , 2022 ; Shin & Yoo , 2023 ), DenseNet ( Manivannan , 2022 ), MobileNet ( Shin & Yoo , 2023 ; Tsai & Lee , 2020 ), and AlexNet ( Hsu & Chien , 2020 ) have been explored. For example, in Shin and Yoo (2023 ), different CNN architectures were compared, and MobileNet-V3 was found to be better in terms of both training speed and accuracy. In Tsai and Lee (2020 ), a deep learning-based method is proposed for WBM data augmentation and defect classification. In this approach, data 1https://www.kaggle.com/qingyi/wm811k-wafer-map .augmentation was based on a CNN encoder‚Äìdecoder architecture, and classification was performed using depthwise separable convolutions to reduce the number of parameters in the network. MixUp ( Zhang, Cisse, Dauphin, & Lopez-Paz , 2017 ) was used with CNN in Shin et al. (2022 ) to identify mixed-type defective patterns. Ensemble CNN-based approaches usually r"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_8", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 8, "text": "rameters in the network. MixUp ( Zhang, Cisse, Dauphin, & Lopez-Paz , 2017 ) was used with CNN in Shin et al. (2022 ) to identify mixed-type defective patterns. Ensemble CNN-based approaches usually report better performance than single model-based approaches, so they were also explored for WBM classification ( Hsu & Chien , 2020 ; Misra, Kim, Kim, Shin, & Kim , 2022 ; Piao & Jin , 2022 ). For example, in Hsu and Chien (2020 ), a weighted majority voting is adopted to ensemble CNN models to achieve higher predictive performance. In Misra et al. (2022 ), features extracted from multiple pre-trained CNN models are concatenated, and a classification layer is trained on this concatenated representation to predict the label. As discussed earlier, FSL approaches require large amount of labeled data which is usually difficult to obtain as the labeling is a costly and time consuming process. 2.2. SSL approaches SSL approaches are becoming increasingly popular for WBM defect classification as they leverage the available unlabeled data to improve model performance. However, the number of SSL approaches for WBM classification is still much lower compared to FSL approaches. An ensemble based S"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_9", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 9, "text": "hey leverage the available unlabeled data to improve model performance. However, the number of SSL approaches for WBM classification is still much lower compared to FSL approaches. An ensemble based SSL approach was recently proposed in Manivannan (2022 ) which involves training a set of CNN classifiers to predict the pseudo-label of each unlabeled image. The pseudo-labeled images are then used to update each CNN in the ensemble, resulting in improved performance over FSL baseline. Self-supervised learning approaches also utilize unlabeled data to improve model‚Äôs performance. However, they typically consists of two stages: In the first stage, a contrastive loss function is used with the available unlabeled data to pretrain the model to generate rich feature representations. In the second stage, the model is fine-tuned using la- beled data for classification. Self-supervised learning based approaches also have been proposed for WBM defect classification in Hu, He, and Li (2021 ) and Kahng and Kim (2021 ). In contrast to the above SSL approaches, the proposed approach is based on a Dual-Head CNN architecture that aims to handle imbal- anced class problems effectively. Experiments sho"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_10", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 10, "text": "ng and Kim (2021 ). In contrast to the above SSL approaches, the proposed approach is based on a Dual-Head CNN architecture that aims to handle imbal- anced class problems effectively. Experiments show that the proposed approach performs significantly better than the above approaches pro- posed for WBM defect classification. 3. Methodology The proposed approach is a pseudo labeling-based SSL technique that leverages unlabeled data to train the proposed Dual-Head CNN model. Initially, the CNN model is trained using the labeled data, and then this trained CNN is employed to select high-confident pseudo- labels from the unlabeled set. The selected subset, along with its Expert Systems With Applications 238 (2024) 122301 3S. Manivannan Table 1 Notations used throughout in this manuscript. Notation Meaning ÓâÑ Labeled set ùë•ùëñ A Labeled image ùë¶ùëñ Label ofùë•ùëñ ùëÅ Number of labeled images ÓâÅ Unlabeled set ùë¢ùëñ An unlabeled image ÃÇ ùë¶ùëñ Pseudo-label of ùë¢ùëñ ùëÄ Number of unlabeled images ùê∂ Number of classes ùêª Classifier head which is trained using the CE loss ùêªùëä Classifier head which is trained using the class balanced CE loss ùë§ùëê Class weight for the class ùëê ùëÅùëê Number of images from class ùëê ùõº Weak augmenta"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_11", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 11, "text": "Classifier head which is trained using the CE loss ùêªùëä Classifier head which is trained using the class balanced CE loss ùë§ùëê Class weight for the class ùëê ùëÅùëê Number of images from class ùëê ùõº Weak augmentation Óà≠ Strong augmentation pseudo-labels, is then considered as a labeled set and combined with the original labeled set to retrain the model. The overall procedure of the proposed SSL approach is summarized in Algorithm 1. The follow- ing section explains the notations used, the proposed Dual-Head CNN model and its motivation for SSL, the loss functions used for training, the proposed method for selecting highly confident pseudo-labeled data from the unlabeled set, and the overall training procedure. 3.1. Problem setting Assume that the training set consists of both labeled and unlabeled images. ÓâÑ= {(ùë•ùëñ,ùë¶ùëñ)}ùëÅ ùëñ=1be the labeled set, where each labeled image ùë•ùëñis associated with a label ùë¶ùëñ‚àà [0,ùê∂‚àí 1]. Here,ùê∂represents the total number of classes, and ùëÅrepresents the total number of labeled images. Similarly, the unlabeled set can be represented as ÓâÅ= {(ùë¢ùëñ)}ùëÄ ùëñ=1, whereùëÄrepresents the total number of unlabeled images. The label of each unlabeled image ùë¢ùëñis unknown. It is also assumed that"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_12", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 12, "text": "mages. Similarly, the unlabeled set can be represented as ÓâÅ= {(ùë¢ùëñ)}ùëÄ ùëñ=1, whereùëÄrepresents the total number of unlabeled images. The label of each unlabeled image ùë¢ùëñis unknown. It is also assumed that the distribution of the number of images from different classes follows a long-tail distribution, implying that the number of images in each class is highly imbalanced. The notations used throughout this manuscript are listed in Table 1. 3.2. Dual-head CNN When training the CNN model using the commonly employed Cross Entropy (CE) loss, without considering the issue of class imbalance, a significant bias toward the majority classes emerges. Consequently, the model tends to incorrectly classify most images as if they belong to the majority class, while selecting only a few or no data from the minority classes. Subsequent training using these erroneously chosen pseudo-labels adversely affects the model‚Äôs generalization ability, a phenomenon known as ‚Äò‚Äòconfirmation bias‚Äô‚Äô (Wang, Wu, Lian, & Yu, 2022). On the contrary, training the model with a class-balanced CE loss, which assigns equal importance to all classes, results in more accurate pseudo-label selection. Pseudo-labels from even the"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_13", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 13, "text": "u, 2022). On the contrary, training the model with a class-balanced CE loss, which assigns equal importance to all classes, results in more accurate pseudo-label selection. Pseudo-labels from even the minority classes are chosen in this scenario, proving highly beneficial for the subsequent semi-supervised training of the model. However, it is important to note that training a model with a balanced CE loss might not be suitable if the primary objective is to maximize the overall prediction accuracy. Therefore, in our proposed approach, a Dual-Head CNN model is introduced to effectively tackle the class imbalance issue, as depicted in Fig. 2. This model comprises two classifier heads, denoted as ùêªand ùêªùëä, which share the same backbone network. The pseudo-labels se- lected from both heads are utilized for semi-supervised learning (SSL). Classifier head ùêªùëäis trained using the balanced CE loss to facilitate the selection of pseudo-labels from minority classes. Meanwhile, classifier headùêªis trained to maximize overall prediction accuracy. During testing, the classification head ùêªcan be employed to make predictions that optimizes overall accuracy values.3.2.1. Classifier head ùêª The classi"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_14", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 14, "text": "trained to maximize overall prediction accuracy. During testing, the classification head ùêªcan be employed to make predictions that optimizes overall accuracy values.3.2.1. Classifier head ùêª The classifier head, ùêª, is focused on classifying images into a set of predefined classes without considering their imbalanced nature. i.e., ùêª is optimized using the CE loss function as follows: Óà∏ùõº= ‚àí1 ùëÅùëÅ‚àë ùëñ=1ùê∂‚àë ùëê=11ùë¶ùëñ=ùëêlogùëù(ùë¶ùëñ=ùëê|ùõº(ùë•ùëñ),ùêª) (1) where, 1ùë¶ùëñ=ùëêis the indicator function which returns 1 if ùë¶ùëñ=ùëê, and returns 0 otherwise, ùõº(ùë•ùëñ)is the augmented version (e.g., by applying rotation) of the image ùë•ùëñandùëù(ùë¶ùëñ=ùëê|ùõº(ùë•ùëñ),ùêª)is the predicted probability of the augmented image ùõº(ùë•ùëñ)belonging to the class ùëêby the classifier head ùêª. The CE loss has gained widespread adoption in SSL, exemplified by its use in prominent approaches like FixMatch (Sohn et al., 2020). It aligns well with the goal of maximizing the likelihood of the true labels given the model‚Äôs predictions. The choice of the CE loss function in SSL is rooted in its effectiveness for multiclass classification tasks and its suitability for generating pseudo-labels from unlabeled data. By optimizing this loss function on a combination of labeled"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_15", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 15, "text": "SL is rooted in its effectiveness for multiclass classification tasks and its suitability for generating pseudo-labels from unlabeled data. By optimizing this loss function on a combination of labeled and pseudo-labeled data, SSL aims to enhance the model‚Äôs generalization capabilities and overall performance. However, as explained earlier, this loss function does not account for the imbalanced nature of the classes. Consequently, its predictions may be biased towards the classes which contain majority of the data. This loss function would be more appropriate if the objective is to maximize the overall accuracy or the F1-score. When this classifier is used in SSL to select high confident pseudo-labels, the majority of the selected data would be from the majority classes, resulting in few or no data selected from the minority classes. 3.2.2. Classifier head ùêªùëä The classifier head ùêªùëäis designed to address the imbalanced nature of different classes by applying a class weighted CE loss. This loss assigns different weights to each class, giving equal importance to all classes and resulting in an unbiased classifier. Óà∏ùõº ùëä= ‚àí1 ùëÅ‚Ä≤ùëÅ‚àë ùëñ=1ùê∂‚àë ùëê=1ùë§ùëê1ùë¶ùëñ=ùëêlogùëù(ùë¶ùëñ=ùëê|ùõº(ùë•ùëñ),ùêªùëä) (2) where,ùë§ùëêis the wei"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_16", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 16, "text": "s loss assigns different weights to each class, giving equal importance to all classes and resulting in an unbiased classifier. Óà∏ùõº ùëä= ‚àí1 ùëÅ‚Ä≤ùëÅ‚àë ùëñ=1ùê∂‚àë ùëê=1ùë§ùëê1ùë¶ùëñ=ùëêlogùëù(ùë¶ùëñ=ùëê|ùõº(ùë•ùëñ),ùêªùëä) (2) where,ùë§ùëêis the weight applied to class ùëê, andùëÅ‚Ä≤is a normalization factor which can be given as ùëÅ‚Ä≤=‚àëùëÅ ùëñ=1‚àëùê∂ ùëêùë§ùëê1ùë¶ùëñ=ùëê. The class weight of the class ùëê,ùë§ùëê, is the normalized version of the inverse frequency of that class and it can be calculated as: ùë§ùëê=1 ùëÅùëê‚àëùê∂ ùëô=11 ùëÅùëô(3) where,ùëÅùëêis the number of images labeled as class ùëêand can be given asùëÅùëê=‚àëùëÅ ùëñ=11ùë¶ùëñ=ùëê, and in addition, ùëÅ=‚àëùê∂ ùëê=1ùëÅùëê. Eq. (3) assigns greater weight values to the minority classes and smaller weight values to the majority classes. Consequently, by incor- porating these weights into Eq. (2), it ensures that each class receives equal importance during model training. The class-weighted loss function (Eq. (2)) is particularly well-suited for maximizing the mean per-class accuracy (MCA) values, as demon- strated in Section 4.2.1 through experimental validation. This is be- cause it assigns equal importance to each class. Furthermore, this loss function proves to be more compatible with SSL settings, as it aids in selecting highly confident pseudo-l"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_17", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 17, "text": "lidation. This is be- cause it assigns equal importance to each class. Furthermore, this loss function proves to be more compatible with SSL settings, as it aids in selecting highly confident pseudo-labels, even from minority classes, thanks to its equitable treatment of all classes. 3.2.3. Joint training of ùêªandùêªùëä Using the weighted CE loss alone to train the CNN can maximize MCA values and assist SSL, however, it may result in low overall accuracy values and F1 scores (refer Section 4.2.1 for experimental validation). To address this issue, the dual-head CNN architecture is employed to enhance both SSL and F1 scores. Expert Systems With Applications 238 (2024) 122301 4S. Manivannan Fig. 2. The proposed Dual-Head CNN architecture under (a) FSL and (b) SSL. ùêªandùêªùëäare classifier heads which maximize the overall accuracy, and the per-class accuracies respectively. Two types of augmentations, weak ( ùõº) and strong ( Óà≠), are employed as they have been widely used by the recent SSL approaches, e.g., Fix- Match ( Sohn et al. , 2020 ). The classifier heads, ùêªandùêªùëä, are jointly trained using the following loss function. Óà∏ùëá=ùúÜ(Óà∏ùõº+Óà∏Óà≠)+ùúÜùëä(Óà∏ùõº ùëä+Óà∏Óà≠ ùëä)(4) where, Óà∏ùõºrepresents the CE loss which uses"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_18", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 18, "text": "s, e.g., Fix- Match ( Sohn et al. , 2020 ). The classifier heads, ùêªandùêªùëä, are jointly trained using the following loss function. Óà∏ùëá=ùúÜ(Óà∏ùõº+Óà∏Óà≠)+ùúÜùëä(Óà∏ùõº ùëä+Óà∏Óà≠ ùëä)(4) where, Óà∏ùõºrepresents the CE loss which uses no class weighting and uses weak augmentation using the classifier head ùêª(Eq. (1)). On the other hand, Óà∏Óà≠is the CE loss which uses strong augmentations. Similarly, Óà∏ùõº ùëäis the weighted CE loss with weak augmentation and based on the output of the classifier head ùêªùëä(Eq. (2)).ùúÜandùúÜùëäare the trade-off parameters. Weak augmentation typically generates clear, easily classifiable im- ages. In contrast, strong augmentation generates images that are more challenging to classify. Therefore, during training, both weak and strong augmentations are taken into consideration. 3.3. Pseudo-labeling based consistency regularization The proposed SSL approach makes use of a pseudo-labeling based consistency regularization approach as it has been widely used by the recent state-of-the-art SSL methods such as FixMatch ( Sohn et al. , 2020 ) and FlexMatch ( Zhang et al. , 2021 ). Consistency regularization enforces that the predictions of the perturbed versions of an input should be similar to each other. In"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_19", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 19, "text": "ixMatch ( Sohn et al. , 2020 ) and FlexMatch ( Zhang et al. , 2021 ). Consistency regularization enforces that the predictions of the perturbed versions of an input should be similar to each other. In pseudo labeling based consistency regularization, first the pseudo label, ÃÇ ùë¶ùëñ, of an unlabeled image, ùë¢ùëñ, is generated based on the weakly augmented version of that image as follows: ÃÇ ùë¶ùëñ= arg max(ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêª‚Ä≤)) (5) That is, the pseudo-label is identified as the class which corresponds to the maximum value in ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêª‚Ä≤). Here,ùêª‚Ä≤could be either ùêª orùêªùëä. This pseudo label is then considered as the true label for the strongly augmented version of that image when updating the CNN model which gives a form of consistency regularization. When updat- ing the model only the high confident pseudo-labels are considered, i.e., pseudo-labels with max(ùëù(ùë¶|ùõº(ùë¢ùëñ)))> ùúè, where,ùúèis a threshold value.3.4. Selection of high confident pseudo-labels based on Dual-Head CNN At each SSL iteration, a set of high confident pseudo-labels are selected from the unlabeled training set and added with the original labeled set to augment the labeled training set. This section explain how a set of high confident pseu"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_20", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 20, "text": " confident pseudo-labels are selected from the unlabeled training set and added with the original labeled set to augment the labeled training set. This section explain how a set of high confident pseudo-labels are generated from the Dual-Head CNN. High-confidence pseudo-labels can be generated from the output of the classifier ùêª. However, as explained earlier, this classifier is biased, and as a result, it may select a large number of pseudo-labeled data points from the majority classes while selecting none from the minority class. In addition, as it is a biased classifier the selected pseudo-labels may be too noisy and may hurt the subsequent training. On the other hand, the high-confident predictions can be selected based on the output from the class weighted classifier head, ùêªùëä, as it is trained to give equal importance to each class. The proposed approach uses bothùêªandùêªùëäto select the high-confident pseudo-labels. 3.4.1. Pseudo-label selection based only on ùêªùëä Based onùêªùëä, an unlabeled image can be identified as high- confident prediction if the corresponding prediction exceeds a thresh- oldùúè. i.e.,ùëûùëñ> ùúè, where,ùëûùëñ= max(ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêªùëä)). The threshold, ùúè, is set as the average value"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_21", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 21, "text": "ed image can be identified as high- confident prediction if the corresponding prediction exceeds a thresh- oldùúè. i.e.,ùëûùëñ> ùúè, where,ùëûùëñ= max(ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêªùëä)). The threshold, ùúè, is set as the average value of the prediction probabilities of the unlabeled data, i.e.,ùúè=‚àëùëÄ ùëñ=1ùëûùëñ 3.4.2. Pseudo-label selection based on both ùêªandùêªùëä Additional predictions can be selected based on considering the predictions made by both classifiers ùêªandùêªùëä. If both of these classifiersùêªandùêªùëäagree with the pseudo-label of ùë¢ùëñwith high confident,ùë¢ùëñcan also be added with the labeled data as a high confident prediction. Let ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêª)andùëù(ùë¶|ùõº(ùë¢ùëñ),ùêªùëä)represent the probability values obtained from the classifier heads ùêªandùêªùëärespectively for the unlabeled image ùë¢ùëñ, andÃÇ ùë¶ùëñandÃÇ ùë¶ùë§ ùëñrespectively represent the calculated pseudo-labels from these probabilities. An unlabeled image is considered high-confident if: (ÃÇ ùë¶ùëñ=ÃÇ ùë¶ùë§ ùëñ) ‚àß(ùëûùëñ+ùëûùë§ ùëñ 2>ùúè‚Ä≤) (6) where,ùëûùëñ= max(ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêª)),ùëûùë§ ùëñ= max(ùëù(ùë¶|ùõº(ùë¢ùëñ),ùêªùëä)),ùúè‚Ä≤=1 2ùëÄ‚àëùëÄ ùëñ=1 (ùëûùëñ+ùëûùë§ ùëñ)and‚àßis the logical-and operator. Expert Systems With Applications 238 (2024) 122301 5S. Manivannan Algorithm 1: Dual-Head CNN for SSL Input: Labeled set Óà∞ùêø, unlabeled set Óà∞ùëà, Dual-Head CNN ùëìùúÉ with the cla"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_22", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 22, "text": "is the logical-and operator. Expert Systems With Applications 238 (2024) 122301 5S. Manivannan Algorithm 1: Dual-Head CNN for SSL Input: Labeled set Óà∞ùêø, unlabeled set Óà∞ùëà, Dual-Head CNN ùëìùúÉ with the classifier heads ùêªandùêªùëä Output:ùëìùúÉ Procedure: 1fort=1 to T do 2 TrainùëìùúÉonÓà∞ùêøusing the loss function defined by Eq. (4) 3 Generate pseudo-labels for the weakly augmented version ofÓà∞ùëàusingùêªandùêªùëä(Section 3.3) 4 FormÓà∞‚Ä≤ ùêøby selecting high confident pseudo-labels (Section 3.4) 5 Expand the labeled set by Óà∞ùêø=Óà∞ùêø‚à™Óà∞‚Ä≤ ùêø 6 Update the class weights using Eq. (3) 3.5. The overall procedure for SSL based on the dual-head CNN The overall procedure of the proposed SSL approach is summarized in Algorithm 1. Initially, the Dual-Head CNN is trained using the avail- able labeled data and with the loss function defined by Eq. (4). Then this trained CNN is used to predict the pseudo-labels of each weakly augmented unlabeled data point ùë¢ùëñseparately using the classifier heads ùêªandùêªùëäas explained in Section 3.3. The high confident predictions are then selected together with their pseudo-labels as explained in Section 3.4 and the labeled training set is expanded with the addition of this high confident pseudo labeled "}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_23", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 23, "text": " confident predictions are then selected together with their pseudo-labels as explained in Section 3.4 and the labeled training set is expanded with the addition of this high confident pseudo labeled data. The class weights defined by Eq. (3) are updated using this expanded labeled data and the CNN model is then retrained using this expanded labeled data. The above steps were iterated for a few times (i.e., ùëá= 4). Note that weak augmentations are used when calculating pseudo- labels, as they typically represent clear images. Consequently, they are often far from the decision boundaries that distinguish different classes, resulting in high-confidence predictions. However, during model train- ing, strongly augmented images play a crucial role. These images are more challenging and tend to be closer to the decision boundaries, which aids in refining those boundaries. It is not advisable to employ strongly augmented images for calculating pseudo-labels because they are situated near the decision boundaries, leading to potentially noisy and less confident predictions. Hence, pseudo-labels are computed using weakly augmented images and then utilized as if they were the actual labels for "}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_24", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 24, "text": "cision boundaries, leading to potentially noisy and less confident predictions. Hence, pseudo-labels are computed using weakly augmented images and then utilized as if they were the actual labels for the strongly augmented images during model training, thereby enforcing consistency regularization and ensures more stable training. 4. Experiments, results and discussion In this section, the dataset, experimental settings are summarized, and the results are reported with discussion. 4.1. Dataset The proposed method was evaluated using the publicly accessible WBM dataset, known as the WM-811K2dataset. This dataset comprises 811,457 images collected from a real-world wafer fabrication process. However, labels are available for only a subset of this dataset, consist- ing of 172,950 images. Each image in this subset is annotated into one of the nine classes, with each class containing images ranging from 149 to 147,431, resulting in a highly imbalanced class distribution as shown in Table 2. 2https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map.4.2. Training configurations ImageNet pretrained CNN models are finetuned with a Stochas- tic Gradient Descent optimizer with a cosine learning"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_25", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 25, "text": "2https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map.4.2. Training configurations ImageNet pretrained CNN models are finetuned with a Stochas- tic Gradient Descent optimizer with a cosine learning rate decay (Loshchilov & Hutter, 2016), which sets the learning rate at the itera- tionùëòtoùúÇcos(7ùúãùëò 16ùêæ)whereùúÇis the initial learning rate, and ùêæis the total number of iterations. Section 4.2.1 reports the effect of the learning rateùëòwith different CNN architectures and settings. In all the reported experiments ùêæis set toùêæ= 80 . Following (Manivannan, 2022) a dropout rate of 0.5 was used before the classification layer of each CNN architecture and a label smoothing factor of 0.1 was used to reduce overfitting. Batch size and the learning rate were set to 128 and 0.05, respectively, unless otherwise specified. Variants of Resnet (He, Zhang, Ren, & Sun, 2016) and Densenet-121 (Huang, Liu, van der Maaten, & Weinberger, 2017) CNN architectures were used for comparison as they were widely used for image classification tasks. All the images were resized to 96 √ó96 pixels, and were normalized to have zero mean and unit standard deviation before feeding them to the CNN. The normalized images we"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_26", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 26, "text": "for image classification tasks. All the images were resized to 96 √ó96 pixels, and were normalized to have zero mean and unit standard deviation before feeding them to the CNN. The normalized images were used as the weakly augmented images. Random rotations, random flips (horizontal and vertical), and cutout were used as the strong augmentation. In the cutout augmenta- tion, a random square patch of size ùë†√óùë†whereùë†‚àà [1,20]pixels was selected at a random location within the image, and the pixels within the patch were replaced with zeros. The resized normalized images were used for testing without any other augmentations. The evaluation measures for the test set were reported as the mean and standard deviations of three repeated experiments. The macro F1 score and the mean of per-class accuracies (MCA) were used as evalua- tion measures to provide a balanced evaluation of the model‚Äôs ability to correctly classify instances across all classes. To ensure a fair compar- ison, the experimental settings used in Manivannan (2022) and Kahng and Kim (2021) were followed, whereby in each experimental run, 20% of the labeled data was randomly selected as the test set, and ùëù%, of the remaining la"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_27", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 27, "text": " settings used in Manivannan (2022) and Kahng and Kim (2021) were followed, whereby in each experimental run, 20% of the labeled data was randomly selected as the test set, and ùëù%, of the remaining labeled data was randomly sampled as the labeled training set. The value of p was varied across 1%,2%,5%,10%,25%, and 100%. Table 3 reports the number of images under each class when varying the value of ùëù. Additionally, 200,000 images were randomly selected from the rest of the data as the unlabeled training set for training the proposed SSL approach. 4.2.1. Investigation of FSL under different settings This section aims to investigate (1) the suitable CNN architecture and the appropriate learning rate for each architecture, (2) the effect of the class-weighted loss function for the classification of WBM, (3) the effect of the amount of labeled training data on the performance, (4) the effect of data augmentation, and (5) the effect of batch size. Two variants of ResNet (ResNet-10 and ResNet-18) and DenseNet- 121 were considered for comparison as Resnet (He et al., 2016) and Densenet (Huang et al., 2017) were widely used for image classifica- tion. The results are reported in Tables 4 a"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_28", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 28, "text": "t-18) and DenseNet- 121 were considered for comparison as Resnet (He et al., 2016) and Densenet (Huang et al., 2017) were widely used for image classifica- tion. The results are reported in Tables 4 and 5 respectively when 2% and 10% of labeled training data is considered for training the model with and without class weights. Note that a single head CNN model is used in all the experiments reported in this section. The following are the main observations from the experiments: (1) Simpler model, Resnet-10, performs better for WBM classification par- ticularly when the training data is limited compared to a more complex model. (2) Applying a class-weighted CE loss lead to better MCA as WBM is an imbalanced classification problem; however, a better F1- score was obtained when no class weights were used. (3) Increasing the size of labeled training data leads to better classification performance regardless of the CNN architecture as more labeled data helps to learn the CNN weights better. (4) More data augmentations leads to better performance as it improves the model‚Äôs ability to generalize well. (5) Small batch sizes (64,128, and 256) leads to better performance than a larger batch si"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_29", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 29, "text": "4) More data augmentations leads to better performance as it improves the model‚Äôs ability to generalize well. (5) Small batch sizes (64,128, and 256) leads to better performance than a larger batch size (i.e., 512) as smaller batch sizes improve the Expert Systems With Applications 238 (2024) 122301 6S. Manivannan Table 2 Detail of the WM-811K dataset. Class name Labeled Unlabeled Near-Full Donut Random Scratch Loc Center Edge-Loc Edge-Ring None No. of images 149 555 886 1193 3593 4294 5189 9680 147,431 638,507 Table 3 Number of training (labeled) and testing images under different settings. Class Training set Test set ùëù= 1%ùëù= 2%ùëù= 5%ùëù= 10%ùëù= 25%ùëù= 100% Near-Full 1 2 6 12 30 119 30 Donut 4 9 22 44 111 444 111 Random 7 14 35 69 173 693 173 Scratch 10 19 48 95 238 954 239 Loc 29 57 144 288 719 2,875 718 Center 34 69 172 344 859 3,435 859 Edge-Loc 42 83 207 415 1,038 4,151 1,038 Edge-Ring 77 155 387 774 1,936 7,744 1,936 None 1179 2359 5897 11,795 29,486 117,945 29,486 Total 1383 2767 6918 13,836 34,590 138,360 34,590 Table 4 FSL baseline: Classification performance of different CNN architectures with 2% of labeled training data. lr ResNet-10 ResNet-18 DenseNet-121 MCA F1 MCA F1 MCA F"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_30", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 30, "text": "8 13,836 34,590 138,360 34,590 Table 4 FSL baseline: Classification performance of different CNN architectures with 2% of labeled training data. lr ResNet-10 ResNet-18 DenseNet-121 MCA F1 MCA F1 MCA F1 Without class weights 0.001 48.1 ¬± 0.6.484 ¬±.008 62.1 ¬± 2.7.653 ¬±.038 ùüîùüî.ùüñ¬±ùüè.ùüí.ùüïùüèùüë¬±.ùüéùüèùüì 0.005 67.1 ¬± 0.7.710 ¬±.012 69.1 ¬± 1.7.729 ¬±.024 62.8 ¬± 9.3.653 ¬±.103 0.01 73.4 ¬± 3.7.778 ¬±.039 ùüïùüê.ùüè¬±ùüê.ùüí.ùüïùüìùüó¬±.ùüéùüëùüí 50.7 ¬± 3.2.532 ¬±.032 0.05 ùüïùüî.ùüí¬±ùüè.ùüì.ùüñùüèùüè¬±.ùüéùüèùüï 11.1 ¬± 0.0.102 ¬±.000 44.8 ¬± 4.4.485 ¬±.049 0.1 ùüïùüî.ùüí¬±ùüé.ùüï.ùüñùüèùüè¬±.ùüéùüèùüé 11.1 ¬± 0.0.102 ¬±.000 44.9 ¬± 3.2.489 ¬±.032 0.5 35.3 ¬± 17.4.350 ¬±.180 11.1 ¬± 0.0.102 ¬±.000 43.1 ¬± 3.3.475 ¬±.043 With class weights 0.001 82.8 ¬± 1.5.761 ¬±.018 ùüñùüè.ùüó¬±ùüé.ùüñ.ùüïùüìùüî¬±.ùüéùüèùüó ùüïùüì.ùüì¬±ùüê.ùüë.ùüîùüîùüí¬±.ùüéùüêùüé 0.005 ùüñùüê.ùüó¬±ùüè.ùüé.ùüïùüïùüî¬±.ùüéùüêùüè 61.9 ¬± 5.9.518 ¬±.045 71.4 ¬± 2.5.571 ¬±.029 0.01 80.7 ¬± 0.9.734 ¬±.028 42.7 ¬± 1.8.377 ¬±.024 62.8 ¬± 4.4.471 ¬±.071 0.05 46.5 ¬± 25.1.377 ¬±.258 11.1 ¬± 0.0.102 ¬±.000 42.4 ¬± 5.7.252 ¬±.059 0.1 22.3 ¬± 15.8.187 ¬±.120 11.1 ¬± 0.0.102 ¬±.000 30.9 ¬± 8.1.144 ¬±.062 Table 5 FSL baseline: Classification performance of different CNN architectures with 10% of labeled training data. lr ResNet-10 ResNet-18 DenseNet-121 MCA F1 MCA F1 MCA F1 Without class weights 0.0005 65.1 ¬± 4.4.675 ¬±.037 80.3"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_31", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 31, "text": "sification performance of different CNN architectures with 10% of labeled training data. lr ResNet-10 ResNet-18 DenseNet-121 MCA F1 MCA F1 MCA F1 Without class weights 0.0005 65.1 ¬± 4.4.675 ¬±.037 80.3 ¬± 0.1.831 ¬±.003 76.8 ¬± 1.1.798 ¬±.002 0.001 74.4 ¬± 1.2.759 ¬±.009 83.6 ¬± 1.1.860 ¬±.008 ùüïùüï.ùüó¬±ùüê.ùüê.ùüñùüèùüï¬±.ùüéùüèùüï 0.005 85.4 ¬± 1.5.877 ¬±.008 ùüñùüî.ùüí¬±ùüè.ùüê.ùüñùüïùüñ¬±.ùüéùüéùüì 73.9 ¬± 2.9.779 ¬±.025 0.01 ùüñùüî.ùüì¬±ùüè.ùüï.ùüñùüñùüì¬±.ùüéùüèùüé ùüñùüî.ùüí¬±ùüé.ùüñ.ùüñùüïùüñ¬±.ùüéùüéùüî 58.4 ¬± 4.3.619 ¬±.047 0.05 85.7 ¬± 1.7.876 ¬±.008 11.1 ¬± 0.0.102 ¬±.000 72.4 ¬± 5.6.748 ¬±.056 0.1 85.8 ¬± 0.9.875 ¬±.003 11.1 ¬± 0.0.102 ¬±.000 78.0 ¬± 1.6.800 ¬±.009 With class weights 0.005 90.4 ¬± 0.9.812 ¬±.006 89.9 ¬± 0.4.829 ¬±.004 87.8 ¬±0.3 0.788 ¬±0.011 0.001 91.0 ¬± 0.7.831 ¬±.008 ùüóùüé.ùüë¬±ùüé.ùüó.ùüñùüëùüê¬±.ùüéùüéùüì 87.2 ¬± 1.2 0.782 ¬± 0.019 0.005 ùüóùüè.ùüé¬±ùüè.ùüê.ùüñùüìùüè¬±.ùüéùüéùüí 87.2 ¬± 4.3.763 ¬±.026 81.5 ¬± 3.9 0.691 ¬± 0.040 0.01 90.5 ¬± 0.9.841 ¬±.011 50.6 ¬± 28.9.424 ¬±.236 76.3 ¬± 4.7 0.622 ¬± 0.036 0.05 51.9 ¬± 28.8.441 ¬±.240 11.1 ¬± 0.0.102 ¬±.000 51.2 ¬± 20.9 0.403 ¬± 0.207 0.1 16.0 ¬± 6.9.127 ¬±.035 11.1 ¬± 0.0.102 ¬±.000 61.1 ¬± 19.4 0.472 ¬± 0.204 generalization ability of the network ( Masters & Luschi , 2018 ). In the following these findings are explained in detail. Small model is better: Tables 4 and 5 demonstrate that when "}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_32", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 32, "text": "4 0.472 ¬± 0.204 generalization ability of the network ( Masters & Luschi , 2018 ). In the following these findings are explained in detail. Small model is better: Tables 4 and 5 demonstrate that when limited amounts of data are used for training, Resnet-10 significantly outper- forms the other models. This is due to Resnet-10 having relatively fewer parameters to train than the other considered models, allowing these parameters to be learned with a smaller amount of data. However,Table 6 Effect of different data augmentation with FSL when ùëù= 5% . Flip Rotation Cutout MCA F1 ‚úó ‚úó ‚úó 73.3 ¬± 0.4 .764 ¬±.006 ‚úì ‚úó ‚úó 79.2 ¬± 2.0 .817 ¬±.011 ‚úì ‚úì ‚úó 83.4 ¬±1.9 .853 ¬±.006 ‚úì ‚úì ‚úì 83.4 ¬±1.4 .855 ¬±.005 Fig. 3. Effect of batch size: Learning rate (x-axis) vs. F1-scores (y-axis) for different batch sizes with unweighted CE loss. experiments revealed that further reducing the depth of the Resnet- 10 model resulted in a significant drop in performance, and thus these results were not reported in Table 4. CE loss vs. CE loss with class weights: It can be observed from Tables 4 and 5 that using a class-weighted CE loss (corresponds to ùúÜùëä= 1and ùúÜ= 0in Eq. (4)) leads to better MCA scores compared to using an u"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_33", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 33, "text": "ss vs. CE loss with class weights: It can be observed from Tables 4 and 5 that using a class-weighted CE loss (corresponds to ùúÜùëä= 1and ùúÜ= 0in Eq. (4)) leads to better MCA scores compared to using an unweighted CE loss (corresponds to ùúÜùëä= 0andùúÜ= 1in Eq. (4)), regardless of the CNN architecture used. This is because the class- weighted CE loss assigns equal importance to each class, maximizing the MCA metric. However, using CE loss without weights results in better F1-scores, indicating that the macro F1-score is influenced by the accuracy of the majority class‚Äôs prediction. Better performance with more labels: When increasing the labeled training data classification performance improves significantly regard- less of the CNN architecture. For example, when Resnet-10 architecture is considered, an improvement of ‚àº 8% in MCA was observed (from 82.9% to 91.0%) when increasing the amount of training data from ùëù= 2% toùëù= 10% (with the class weighted CE loss). Better results with data augmentation: Table 6 reports the classifica- tion performances when different data augmentations are considered with the unweighted CE loss. An improvement of 10% in MCA was obtained when applying all the au"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_34", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 34, "text": "tion: Table 6 reports the classifica- tion performances when different data augmentations are considered with the unweighted CE loss. An improvement of 10% in MCA was obtained when applying all the augmentations (random flipping, ro- tation and cutout) compared to using only the original images without any augmentations. This improvement can be attributed to the fact that augmentations increase the size of the training set and hence, improve the generalization ability of the network. Effect of batch size: Fig. 3 illustrates the F1-scores for different batch sizes and learning rates. Batch sizes of 64, 128, and 256 demonstrate nearly identical performances (albeit with varying learning rates) when contrasted with the performance achieved using a batch size of 512. The larger batch size of 512 results in inferior classification perfor- mance. This is because the generalization ability of the network is improved by smaller batch sizes ( Masters & Luschi , 2018 ). Compared to the work of Manivannan (2022 ) this work reports improved performance by the FSL baseline due to the careful selection Expert Systems With Applications 238 (2024) 122301 7S. Manivannan Table 7 Classification perfo"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_35", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 35, "text": "anivannan (2022 ) this work reports improved performance by the FSL baseline due to the careful selection Expert Systems With Applications 238 (2024) 122301 7S. Manivannan Table 7 Classification performance of the proposed Dual-Head CNN architecture for different percentage of labeled training data with FSL and SSL. ùëù FSL/SSL ùêªùëä ùêª Both MCA F1 MCA F1 MCA F1 1%FSL 77.0 ¬± 3.2 .760 ¬±.037 67.5 ¬± 3.4 .729 ¬±.025 73.5 ¬± 3.1 .770 ¬±.029 SSL 82.3 ¬± 2.7 .781 ¬±.013 80.2 ¬± 3.3 .793 ¬±.025 81.3 ¬± 3.1 .791 ¬±.013 2%FSL 84.7 ¬± 0.8 .813 ¬±.011 76.5 ¬± 0.2 .814 ¬±.004 81.1 ¬± 0.6 .829 ¬±.006 SSL 87.7 ¬± 0.5 .812 ¬±.012 85.9 ¬± 0.5 .833 ¬±.013 86.8 ¬± 0.4 .831 ¬±.012 5%FSL 89.4 ¬± 1.1 .836 ¬±.003 83.7 ¬± 1.2 .860 ¬±.004 86.7 ¬± 1.1 .861 ¬±.003 SSL 90.7 ¬± 0.5 .827 ¬±.008 89.3 ¬± 0.3 .853 ¬±.007 89.9 ¬± 0.3 .842 ¬±.006 10%FSL 90.3 ¬± 1.6 .855 ¬±.005 85.5 ¬± 2.1 .879 ¬±.010 87.9 ¬± 1.9 .877 ¬±.009 SSL 91.8 ¬± 1.3 .846 ¬±.003 90.3 ¬± 1.4 .875 ¬±.005 91.0 ¬± 1.2 .865 ¬±.003 25%FSL 92.0 ¬± 0.6 .881 ¬±.007 87.1 ¬± 1.2 .897 ¬±.008 89.5 ¬± 0.8 .896 ¬±.005 SSL 93.0 ¬± 0.2 .867 ¬±.011 91.3 ¬± 0.6 .901 ¬±.008 92.1 ¬± 0.6 .896 ¬±.012 100%FSL 94.1 ¬± 0.5 .896 ¬±.003 90.2 ¬± 0.9 .918 ¬±.006 92.3 ¬± 0.7 .915 ¬±.006 SSL 94.2 ¬± 0.5 .893 ¬±.005 91.7 ¬± 1.1 .918 ¬±.008 93.1 ¬± "}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_36", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 36, "text": " SSL 93.0 ¬± 0.2 .867 ¬±.011 91.3 ¬± 0.6 .901 ¬±.008 92.1 ¬± 0.6 .896 ¬±.012 100%FSL 94.1 ¬± 0.5 .896 ¬±.003 90.2 ¬± 0.9 .918 ¬±.006 92.3 ¬± 0.7 .915 ¬±.006 SSL 94.2 ¬± 0.5 .893 ¬±.005 91.7 ¬± 1.1 .918 ¬±.008 93.1 ¬± 1.0 .915 ¬±.008 Fig. 4. SSL over iterations: (a) MCA over different iterations (horizontal axis), (b) F1 score over iterations, (c) number of selected images by the SSL over iterations. The first iteration (iteration 1) corresponds to the FSL approach. of the learning rate and additional data augmentation (rotations and cutout). For example, this work reports a F1-score of .855(Table 6) compared to the F1-score of 0.760 reported in Manivannan (2022 ) when 5% of the labeled training data is considered with ResNet-10. Resnet-10 is used in all the below reported experiments as it gives the best classification performance compared to the other architectures considered. 4.2.2. Performance of the proposed dual-head CNN for FSL and SSL This section examines the classification performance of the pro- posed dual-head CNN architecture under the FSL and SSL settings and shows that SSL enhances the classification performance significantly compared to FSL. Table 7 reports the results of the FSL and "}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_37", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 37, "text": "o- posed dual-head CNN architecture under the FSL and SSL settings and shows that SSL enhances the classification performance significantly compared to FSL. Table 7 reports the results of the FSL and SSL approaches when different percentages of labeled data are used for training. Here, the results are reported based on the outputs of individual classification heads and their combination, where the combination is obtained by averaging their outputs and then predicting the label based on this average. The results show that ùêªùëäprovides significantly better MCA compared to ùêª. However, ùêªperforms better in terms of F1 score compared to ùêªùëä. When the results based on their combination are considered, they provide a reasonable balance between F1 score and MCA. For example, when ùëù= 5% ,ùêªùëägives a MCA of 89.4 and a F1 score of.836, andùêªgives a MCA of 83.7 and a F1 score of .860. On the other hand, the results which was obtained based on the combination of ùêªùëäandùêªgives a MCA of 86.7 and F1 score of .861. SSL improves the classification performance of FSL significantly. For example, when ùëù= 1%over 5% improvement in MCA, and ‚àº 0.02improvement in F1 score was observed from the output of ùêªùëä. However,"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_38", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 38, "text": "861. SSL improves the classification performance of FSL significantly. For example, when ùëù= 1%over 5% improvement in MCA, and ‚àº 0.02improvement in F1 score was observed from the output of ùêªùëä. However, when large amount of labeled data is used for training (e.g., ùëù= 25% ) the improvement obtained from SSL is limited as the results started to saturate. Fig. 4 shows how SSL improves the classification performance over the SSL iterations and the amount of pseudo-labels selected at the end of each iterations. Based on the experiments reported in Section 4.2.1 , the learn- ing rate,ùúÜandùúÜùëäwere set to 0.05, 1 and 0.1 respectively for the experiments reported based on the proposed Dual-Head CNN.4.2.3. Comparison of different methods for pseudo-label selection Table 8 reports the number of high confident predictions selected for pseudo-labeling from different classes by different approaches to- gether with their Precision and the Recall scores when the system is trained using 2% of labeled data and tested on the test set. The last row of this table reports the total number of pseudo-labels selected and their average Precision and Recall values under different settings. FixMatch ( Sohn et al."}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_39", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 39, "text": "and tested on the test set. The last row of this table reports the total number of pseudo-labels selected and their average Precision and Recall values under different settings. FixMatch ( Sohn et al. , 2020 ) (corresponds the selection based on the classifier head ùêª) selects high confident predictions by applying a fixed threshold value ( ùúè= 0.9) on the predicted probabilities. However, Table 8 shows that out of the total 30,458 images selected as high confidence predictions by FixMatch, the majority (27,465) belonged to the class ‚Äònone‚Äô, with no data selected from the minority class ‚Äònear- full‚Äô. This indicates the inability of FixMatch in handling imbalanced data and results in bias towards the majority class. On the other hand, FlexMatch ( Zhang et al. , 2021 ), a recently proposed SSL method, addresses this issue by applying per-class adap- tive thresholds based on the model‚Äôs learning status for each class to select high-confident predictions. FlexMatch selects a large number of high confident predictions, including data from the minority classes. However, the selected data, particularly from the minority classes, are inaccurate, with very low precision and recall values (pre"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_40", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 40, "text": "high confident predictions, including data from the minority classes. However, the selected data, particularly from the minority classes, are inaccurate, with very low precision and recall values (precision of 0.743 for the minority class ‚Äònear-full‚Äô). Adding this impure data to the labeled data during model training may result in a noisy model with reduced performance. Similarly, SimiS ( Chen et al. , 2022 ), a recent SSL approach, shows improved performance over many SSL approaches, including FixMatch (Sohn et al. , 2020 ) and ReMixMatch ( Berthelot et al. , 2019 ), for imbal- anced class classification problems in Chen et al. (2022 ). SimiS uses the difference in class distribution between a particular class and the most frequent class and selects more pseudo-labels from the less frequent classes than the frequent classes. This approach, however, may not be suitable for the extreme imbalance case, as most of the data from the infrequent classes may be selected with noisy pseudo-labels. Table 8 demonstrates that this approach leads to the worst precision and recall values. In contrast, the proposed approach efficiently handles the class imbalance problem, enabling the selection o"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_41", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 41, "text": "ls. Table 8 demonstrates that this approach leads to the worst precision and recall values. In contrast, the proposed approach efficiently handles the class imbalance problem, enabling the selection of highly accurate labeled Expert Systems With Applications 238 (2024) 122301 8S. Manivannan Table 8 The number of high confident predictions selected from each class for pseudo-labeling by different approaches and the Precision and Recall scores of the selected pseudo-labels. Class name Based on ùêªùëä Based onùêªùëä&ùêª FixMatch Sohn et al. (2020) FlexMatch Zhang et al. (2021) SimiS Chen et al. (2022) # Prec. Recall # Prec. Recall # Prec. Recall # Prec. Recall # Prec. Recall Near-full 131.000 0.928 131.000 0.928 0 0.000 0.000 35 0.743 0.867 35 0.743 0.867 Donut 70 0.957 0.985 70 0.957 0.985 58 1.000 0.983 120 0.808 0.898 122 0.803 0.883 Random 133 0.872 0.991 133 0.872 0.991 117 0.949 0.982 212 0.741 0.924 248 0.645 0.925 Scratch 71 0.958 0.944 72 0.958 0.945 53 1.000 0.768 158 0.816 0.832 314 0.567 0.745 Loc 236 0.987 0.932 237 0.987 0.925 208 0.990 0.876 554 0.834 0.764 755 0.678 0.713 Center 619 0.982 0.998 624 0.982 0.998 554 0.989 0.989 824 0.929 0.968 943 0.849 0.932 Edge-Loc 460 0.941 0."}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_42", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 42, "text": "7 0.745 Loc 236 0.987 0.932 237 0.987 0.925 208 0.990 0.876 554 0.834 0.764 755 0.678 0.713 Center 619 0.982 0.998 624 0.982 0.998 554 0.989 0.989 824 0.929 0.968 943 0.849 0.932 Edge-Loc 460 0.941 0.979 468 0.942 0.978 346 0.974 0.926 921 0.805 0.878 1,282 0.671 0.829 Edge-Ring 1,672 1.000 0.996 1,675 1.000 0.996 1,657 1.000 0.997 1,899 0.974 0.975 1,937 0.962 0.963 None 21,672 0.999 0.998 22,909 0.999 0.998 27,465 0.997 0.999 27,458 0.997 0.993 28,954 0.992 0.974 Total/Avg. 24,946 ùüé.ùüóùüîùüî ùüé.ùüóùüïùüë 26,201 ùüé.ùüóùüîùüî ùüé.ùüóùüïùüê 30,458 0.878 0.836 32,181 0.850 0.900 34,590 0.768 0.870 # -number of confident predictions selected from each class. Prec. - Precision score. Table 9 Comparison of F1 scores for different percentage of labeled training data with SSL approaches. Method 1% 2% 5% 10% 25% 100% Self-supervised representation learning (Kahng & Kim, 2021)‚Äì ‚Äì .815.839.864.897 Ladder networks (Kong & Ni, 2018, 2020)‚Äì ‚Äì .814.823.838.863 SSL (without Ensemble) (Manivannan, 2022)‚Äì ‚Äì .834.859.883.902 SSL Ensemble (Manivannan, 2022)‚Äì ‚Äì .850.871.900.912 Proposed Dual-Head CNN for SSL.ùüïùüóùüé.ùüñùüíùüë.ùüñùüîùüè.ùüñùüñùüê.ùüóùüéùüè.ùüóùüèùüñ data, even from the minority classes. The selection based on both ùêªùëäandùêªselects more data than th"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_43", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 43, "text": "Ensemble (Manivannan, 2022)‚Äì ‚Äì .850.871.900.912 Proposed Dual-Head CNN for SSL.ùüïùüóùüé.ùüñùüíùüë.ùüñùüîùüè.ùüñùüñùüê.ùüóùüéùüè.ùüóùüèùüñ data, even from the minority classes. The selection based on both ùêªùëäandùêªselects more data than the selection based solely on ùêªùëä, without compromising overall precision and recall values. Further- more, the selected data, even from the minority classes, are highly accurate, demonstrating the effectiveness of the proposed approach for imbalanced class SSL. 4.2.4. Comparison with the state-of-the-art In this section, a comparison is made between the proposed ap- proach and the current state-of-the-art approaches for WBM classi- fication. The results of the proposed approach show significant im- provements over the existing methods and establishes itself as the new state-of-the-art, especially when dealing with limited labeled data during the training phase. Table 9 presents the results of various SSL approaches proposed for WBM classification and compares them with the proposed approach when different amounts of labeled data are used for training. The proposed approach achieves an F1 score of .79with only 1% labeled training data, demonstrating its effectiveness in limited data scena"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_44", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 44, "text": "when different amounts of labeled data are used for training. The proposed approach achieves an F1 score of .79with only 1% labeled training data, demonstrating its effectiveness in limited data scenarios. Moreover, when 2% of labeled training data is used, the proposed approach outperforms all other single-model-based approaches that use a relatively larger amount of labeled data, i.e., ùëù= 5% . Furthermore, the recently proposed ensemble-based SSL method achieves an F1 score of .850with 5% labeled training data. In contrast, the proposed approach in this work achieves an F1 score of .861using a single lightweight model without ensembling. Table 10 provides a comparison of the proposed approach with other approaches and reports a new state-of-the-art F1 score of .918 when all the labeled training data is used for training. Note that both Tables 9 and 10 contain gaps in their data due to the absence of results from existing approaches in certain scenarios. For instance, in Table 9, none of the existing methods provide outcomes for training with just 1% and 2% of labeled data. However, considering that the proposed method achieved commendable results even with such limited labeled da"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_45", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 45, "text": " of the existing methods provide outcomes for training with just 1% and 2% of labeled data. However, considering that the proposed method achieved commendable results even with such limited labeled data, the results have been included for reference.Table 10 Comparison with the state-of-the-art approaches. Method MCA F1 Acc Hand-crafted features + SVM (Wu, Jang, & Chen, 2015)‚Äì ‚Äì 94.6 Decision tree ensemble (Piao et al., 2018)‚Äì ‚Äì 90.5 Light-weight CNN (Tsai & Lee, 2020)‚Äì 0.800 97.0 MobileNet-V3 (Shin & Yoo, 2023) ‚Äì 0.895 98.0 Self-supervised representation learning (Kahng & Kim, 2021)‚Äì 0.897 ‚Äì Convolutional Neural Nets (Batool, Shapiai, Fauzi, & Fong, 2020)‚Äì 0.900 98.0 SSL (without Ensemble) (Manivannan, 2022)‚Äì 0.902 ‚Äì SSL Ensemble (Manivannan, 2022)‚Äì 0.914 98 .2 Proposed Dual-Head CNN for SSLùüóùüè.ùüï ùüé .ùüóùüèùüñ ùüóùüñ .ùüê It is worth noting that none of the existing approaches furnish informa- tion on the MCA. Nevertheless, MCA is a valuable metric, particularly for imbalanced data classification scenarios. Consequently, MCA values have been included in Table 10 to facilitate future comparisons and assessments of MCA performance within similar contexts. 5. Conclusion SSL approaches have gained i"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_46", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 46, "text": "enarios. Consequently, MCA values have been included in Table 10 to facilitate future comparisons and assessments of MCA performance within similar contexts. 5. Conclusion SSL approaches have gained immense popularity in recent years due to their ability to utilize both labeled and unlabeled data for training deep learning models. However, many existing SSL approaches assume that the training data follows a uniform distribution, where each class consists of approximately an equal number of images. This assumption often results in the failure of these methods to handle highly imbal- anced data, where the number of images belonging to one or more classes is significantly less than the others. To address this issue, this work proposes a Dual-Head CNN architecture based SSL approach for imbalanced class WBM defect classification. The proposed approach overcomes the class imbalanced problem by using two classification heads,ùêªandùêªùëä, whereùêªfocuses on the overall classification accuracy, and ùêªùëäfocuses on improving the accuracy of the minority classes by giving equal importance to all the classes. Experimental results demonstrate that the proposed approach outperforms recent SSL learning ap"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_47", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 47, "text": "ùëäfocuses on improving the accuracy of the minority classes by giving equal importance to all the classes. Experimental results demonstrate that the proposed approach outperforms recent SSL learning approaches for imbalanced class WBM defect classification. In particular, the proposed approach achieves a significant improvement over the state-of-the-art ensemble-based SSL approach, with a single lightweight model and without ensembling. Overall, the proposed ap- proach provides a promising solution for addressing the challenges of imbalanced datasets in SSL for deep learning. Future work could focus Expert Systems With Applications 238 (2024) 122301 9S. Manivannan on the integration of advanced clustering techniques (e.g., Hu, Chan, Yuan, and Xiong (2019) and Hu, Yang, Tang, He, and Luo (2023)) with the proposed Dual-Head CNN architecture. This integration aims to derive cluster-level labels, thereby reducing the inclusion of noisy labels. Additionally, exploring clustering as a regularization technique to promote smoother decision boundaries and enhance generalization. CRediT authorship contribution statement Siyamalan Manivannan: Conceptualization, Methodology, Soft- ware, Validat"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_48", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 48, "text": "ization technique to promote smoother decision boundaries and enhance generalization. CRediT authorship contribution statement Siyamalan Manivannan: Conceptualization, Methodology, Soft- ware, Validation, Writing ‚Äì review & editing. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability The dataset is available for public use. References Adly, F., Alhussein, O., Yoo, P. D., Al-Hammadi, Y., Taha, K., Muhaidat, S., et al. (2015). Simplified subspaced regression network for identification of defect patterns in semiconductor wafer maps. IEEE Transactions on Industrial Informatics ,11(6), 1267‚Äì1276. Adly, F., Yoo, P. D., Muhaidat, S., Al-Hammadi, Y., Lee, U., & Ismail, M. (2015). Randomized general regression network for identification of defect patterns in semiconductor wafer maps. IEEE Transactions on Semiconductor Manufacturing , 28(2), 145‚Äì152. Batool, U., Shapiai, M. I., Fauzi, H., & Fong, J. X. (2020). Convolutional neural network for imbalanced data classification of silicon wafer defects. In IEEE international c"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_49", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 49, "text": "cturing , 28(2), 145‚Äì152. Batool, U., Shapiai, M. I., Fauzi, H., & Fong, J. X. (2020). Convolutional neural network for imbalanced data classification of silicon wafer defects. In IEEE international colloquium on signal processing and its applications (pp. 230‚Äì235). Berthelot, D., Carlini, N., Cubuk, E. D., Kurakin, A., Sohn, K., Zhang, H., et al. (2019). ReMixMatch: Semi-supervised learning with distribution alignment and augmentation anchoring. arXiv:1911.09785. Chen, H., Fan, Y., Wang, Y., Wang, J., Schiele, B., Xie, X., et al. (2022). An embarrassingly simple baseline for imbalanced semi-supervised learning. arXiv preprint arXiv:2211.11086. Chen, S., Liu, M., Hou, X., Zhu, Z., Huang, Z., & Wang, T. (2023). Wafer map defect pattern detection method based on improved attention mechanism. Expert Systems with Applications ,230, Article 120544. Chien, C.-F., Hsu, S.-C., & Chen, Y.-J. (2013). A system for online detection and classification of wafer bin map defect patterns for manufacturing intelligence. International Journal of Production Research ,51(8), 2324‚Äì2338. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In IEEE conference on comp"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_50", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 50, "text": "ing intelligence. International Journal of Production Research ,51(8), 2324‚Äì2338. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In IEEE conference on computer vision and pattern recognition (pp. 770‚Äì778). Hsu, C.-Y., & Chien, J.-C. (2020). Ensemble convolutional neural networks with weighted majority for wafer bin map pattern classification. Journal of Intelligent Manufacturing , 1‚Äì14. Hu, L., Chan, K. C., Yuan, X., & Xiong, S. (2019). A variational Bayesian framework for cluster analysis in a complex network. IEEE Transactions on Knowledge and Data Engineering ,32(11), 2115‚Äì2128.Hu, H., He, C., & Li, P. (2021). Semi-supervised wafer map pattern recognition using domain-specific data augmentation and contrastive learning. In 2021 IEEE international test conference (ITC) (pp. 113‚Äì122). IEEE. Hu, L., Yang, Y., Tang, Z., He, Y., & Luo, X. (2023). FCAN-MOPSO: An improved fuzzy-based graph clustering algorithm for complex networks with multi-objective particle swarm optimization. IEEE Transactions on Fuzzy Systems , 1‚Äì16. Huang, G., Liu, Z., van der Maaten, L., & Weinberger, K. Q. (2017). Densely connected convolutional networks. In IEEE con"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_51", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 51, "text": "ective particle swarm optimization. IEEE Transactions on Fuzzy Systems , 1‚Äì16. Huang, G., Liu, Z., van der Maaten, L., & Weinberger, K. Q. (2017). Densely connected convolutional networks. In IEEE conference on computer vision and pattern recognition (pp. 2261‚Äì2269). Kahng, H., & Kim, S. B. (2021). Self-supervised representation learning for wafer bin map defect pattern classification. IEEE Transactions on Semiconductor Manufacturing , 34(1), 74‚Äì86. Kong, Y., & Ni, D. (2018). Semi-supervised classification of wafer map based on ladder network. In IEEE international conference on solid-state and integrated circuit technology (pp. 1‚Äì4). Kong, Y., & Ni, D. (2020). A semi-supervised and incremental modeling framework for wafer map classification. IEEE Transactions on Semiconductor Manufacturing ,33(1), 62‚Äì71. Loshchilov, I., & Hutter, F. (2016). Sgdr: Stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983. Manivannan, S. (2022). An ensemble-based deep semi-supervised learning for the classification of wafer bin maps defect patterns. Computers & Industrial Engineering , 172, Article 108614. Masters, D., & Luschi, C. (2018). Revisiting small batch training for de"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_52", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 52, "text": "ed learning for the classification of wafer bin maps defect patterns. Computers & Industrial Engineering , 172, Article 108614. Masters, D., & Luschi, C. (2018). Revisiting small batch training for deep neural networks. CoRR abs/1804.07612. arXiv:1804.07612. Misra, S., Kim, D., Kim, J., Shin, W., & Kim, C. (2022). A voting-based ensemble feature network for semiconductor wafer defect classification. Scientific Reports , 12(1), 16254. Piao, M., & Jin, C. H. (2022). CNN and ensemble learning based wafer map failure pattern recognition based on local property based features. Journal of Intelligent Manufacturing , 1‚Äì23. Piao, M., Jin, C. H., Lee, J. Y., & Byun, J.-Y. (2018). Decision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features. IEEE Transactions on Semiconductor Manufacturing ,31(2), 250‚Äì257. Shin, W., Kahng, H., & Kim, S. B. (2022). Mixup-based classification of mixed-type defect patterns in wafer bin maps. Computers & Industrial Engineering ,167, Article 107996. Shin, E., & Yoo, C. D. (2023). Efficient convolutional neural networks for semiconductor wafer bin map classification. Sensors ,23(4), 1926. Sohn, K., Berthelot, D., Li, C"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_53", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 53, "text": "eering ,167, Article 107996. Shin, E., & Yoo, C. D. (2023). Efficient convolutional neural networks for semiconductor wafer bin map classification. Sensors ,23(4), 1926. Sohn, K., Berthelot, D., Li, C., Zhang, Z., Carlini, N., Cubuk, E. D., et al. (2020). FixMatch: Simplifying semi-supervised learning with consistency and confidence. CoRR abs/2001.07685. arXiv:2001.07685. Tsai, T.-H., & Lee, Y.-C. (2020). A light-weight neural network for wafer map classification based on data augmentation. IEEE Transactions on Semiconductor Manufacturing ,33(4), 663‚Äì672. Wang, X., Wu, Z., Lian, L., & Yu, S. X. (2022). Debiased learning from naturally imbalanced pseudo-labels. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 14647‚Äì14657). Wu, M.-J., Jang, J.-S. R., & Chen, J.-L. (2015). Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Transactions on Semiconductor Manufacturing ,28(1), 1‚Äì12. Zhang, H., Cisse, M., Dauphin, Y. N., & Lopez-Paz, D. (2017). MixUp: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412. Zhang, B., Wang, Y., Hou, W., Wu, H., Wang, J., Okumura, M., et al. (2021). Flexmatch: Bo"}
{"id": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf::chunk_54", "source": "Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN.pdf", "chunk_index": 54, "text": "in, Y. N., & Lopez-Paz, D. (2017). MixUp: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412. Zhang, B., Wang, Y., Hou, W., Wu, H., Wang, J., Okumura, M., et al. (2021). Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling. Advances in Neural Information Processing Systems ,34, 18408‚Äì18419."}
{"id": "sensors-22-01382.pdf::chunk_0", "source": "sensors-22-01382.pdf", "chunk_index": 0, "text": "/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001 /gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Zhang, D.; Ren, Q.; Su, D. On-Chip Structures for FmaxBinning and Optimization. Sensors 2022 ,22, 1382. https://doi.org/10.3390/ s22041382 Received: 3 December 2021 Accepted: 5 February 2022 Published: 11 February 2022 Publisher‚Äôs Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional afÔ¨Ål- iations. Copyright: ¬© 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/). sensors Article On-Chip Structures for FmaxBinning and Optimization‚Ä† Dongrong Zhang, Qiang Ren * and Donglin Su School of Electronic and Information Engineering, Beihang University, Beijing 100191, China; dongrongzhang@buaa.edu.cn (D.Z.); sdl@buaa.edu.cn (D.S.) *Correspondence: qiangren@buaa.edu.cn ‚Ä† This paper is an extended version of our paper published in 2017 2nd IEEE International Conference on Integrated Circuits and Microsyste"}
{"id": "sensors-22-01382.pdf::chunk_1", "source": "sensors-22-01382.pdf", "chunk_index": 1, "text": " sdl@buaa.edu.cn (D.S.) *Correspondence: qiangren@buaa.edu.cn ‚Ä† This paper is an extended version of our paper published in 2017 2nd IEEE International Conference on Integrated Circuits and Microsystems (ICICM), Nanjing, China, 8‚Äì11 November 2017. Abstract: Process variations during manufacturing lead to differences in the performance of the chips. In order to better utilize the performance of the chips, it is necessary to perform maximum operation frequency ( Fmax) tests to place the chips into different speed bins. For most Fmaxtests, signiÔ¨Åcant efforts are put in place to reduce test cost and improve binning accuracy; e.g., our conference paper published in ICICM 2017 presents a novel binning sensor for low-cost and accurate speed binning. However, by promoting chips placed at the lower bins, because of conservative binning, into higher bins, the overall proÔ¨Åt can greatly increase. Therefore, this paper, extended based on a conference paper, presents a novel and adaptive methodology for speed binning, in which the paths impacting the speed bin of a speciÔ¨Åc IC are identiÔ¨Åed and adapted by our proposed on-chip Binning Checker and Binning Adaptor . As a result, some parts at a bin "}
{"id": "sensors-22-01382.pdf::chunk_2", "source": "sensors-22-01382.pdf", "chunk_index": 2, "text": " for speed binning, in which the paths impacting the speed bin of a speciÔ¨Åc IC are identiÔ¨Åed and adapted by our proposed on-chip Binning Checker and Binning Adaptor . As a result, some parts at a bin margin can be promoted to higher bins. The proposed methodology can be used to optimize the Fmaxyield of a digital circuit when it has redundant timing in clock tree, and it can be integrated into current Fmaxtests with low extra cost. The proposed adaptive system has been implemented and validated on Ô¨Åve benchmarks from ITC, ISCAS89, and OpenSPARCT2 core on 28 nm Altera FPGAs. Measurement results show that the number of higher bin chips is improved by 7‚Äì16%, and our cost analysis shows that the proÔ¨Åt increase is between 1.18% and 3.04%. Keywords: on-chip sensor; speed binning; yield optimization; dynamic adaptation 1. Introduction Process variation during manufacturing impacts the oxide thickness, threshold voltage, etc. of the transistor in integrated circuits, resulting in path delay Ô¨Çuctuations [ 1,2]. Due to these Ô¨Çuctuations, the performance of chips is different; hence, chips (microprocessors, DSPs, micro controllers, and sometimes even ASICs) can be placed into different speed "}
{"id": "sensors-22-01382.pdf::chunk_3", "source": "sensors-22-01382.pdf", "chunk_index": 3, "text": "ctuations [ 1,2]. Due to these Ô¨Çuctuations, the performance of chips is different; hence, chips (microprocessors, DSPs, micro controllers, and sometimes even ASICs) can be placed into different speed bins [ 3,4]. Chips with higher performance are placed into higher speed bins, which can bring more proÔ¨Åt. For instance, the price of the fastest Intel PrescottTMand AMD64 VeniceTMdevice is about three times higher than that of the slowest parts [ 5]. To obtain more proÔ¨Åt, it is necessary to promote the proportion of faster chips. Hence, efÔ¨Åciently and accurately Fmaxtests are required to prevent high-performance chips from being placed into low bins. Another approach is to make efforts to promote low-end chips to higher bins and improve the proportion of high-end chips. Generally, speed binning can be achieved by performing at-speed Fmaxtests [ 6], which can be divided into functional, structural (scan-based), and sensor-based tests. The func- tional Fmaxtest is to Ô¨Ånd the maximum operation frequency at which the chip can operate normally by applying test patterns at different clock frequencies in the functional mode [ 7]. This requires the use of high-end automated test equipment (ATE"}
{"id": "sensors-22-01382.pdf::chunk_4", "source": "sensors-22-01382.pdf", "chunk_index": 4, "text": "n frequency at which the chip can operate normally by applying test patterns at different clock frequencies in the functional mode [ 7]. This requires the use of high-end automated test equipment (ATE) to apply and analyze a large number of test patterns at high speed, resulting in high test overhead. In order to reduce the cost of testing, part of the work adopts a Software-Based Self-Test (SBST) [ 8‚Äì10] Sensors 2022 ,22, 1382. https://doi.org/10.3390/s22041382 https://www.mdpi.com/journal/sensors Sensors 2022 ,22, 1382 2 of 18 to perform on-chip storing and analyzing of test patterns, which reduces the requirements for high-end ATE. SBST usually requires large on-chip memory storage. The structural (scan-based) Fmaxtest includes LOC (launch on shift), LOS (launch on capture), and LOES (launch on extra shift) tests [ 11‚Äì13]. During the structural Fmaxtest, at-speed test patterns are shifted through scan chains with a low speed scan clock, and then, the test is performed with one or two high-speed functional clock cycles [14‚Äì16]. The test responses are scanned out for analyzing to get the actual speed bins. [ 17] investigates the correlation between functional test frequency and th"}
{"id": "sensors-22-01382.pdf::chunk_5", "source": "sensors-22-01382.pdf", "chunk_index": 5, "text": "o high-speed functional clock cycles [14‚Äì16]. The test responses are scanned out for analyzing to get the actual speed bins. [ 17] investigates the correlation between functional test frequency and that of structural test patterns. In [ 18], a formula relating structural critical path testing frequency to system operation frequency is offered, which shows that a structural test can be employed to reduce the speed binning dependency on functional tests. Using the on-chip programmable PLL circuitry to obtain high-frequency clocks for an at-speed scan test is presented in [ 19]. Ref. [ 20] focuses on generating high-quality structural binning patterns considering the impact of process variations and proposes a new pattern-generation methodology for speed binning. Generally, the speed bin of a chip is determined by the delay of critical paths. Hence, on-chip sensors, which can measure the delay of the critical paths [ 21‚Äì26], or monitor the worst slack of critical paths [ 27‚Äì29], are adopted to infer the speed bins of the chip. A low-overhead solution for characterizing the Fmaxof a circuit is proposed in [ 30], which chooses a small set of representative paths in a circuit and dynamic"}
{"id": "sensors-22-01382.pdf::chunk_6", "source": "sensors-22-01382.pdf", "chunk_index": 6, "text": "ed to infer the speed bins of the chip. A low-overhead solution for characterizing the Fmaxof a circuit is proposed in [ 30], which chooses a small set of representative paths in a circuit and dynamically conÔ¨Ågures them into ring oscillators to compute the Fmax.Sensors combined with machine learning [ 31‚Äì33] and data mining are also applied to the speed binning test. Refs. [ 34,35] predict Fmaxthrough data mining of the measured on-chip performance monitors. In addition, for higher proÔ¨Åt, a methodology is proposed in [ 36,37] to adjust the bin boundaries according to the test result. An Fmaxtest based on on-chip sensors has a lower requirement for high-end external equipment than a functional test [ 38], and it takes less time than a structural test. This type of test has gradually become popular in recent years. Due to process variations and noise, a path fails at a binning frequency with a certain statistical probability. At the same time, the failing paths are different from one chip to another. Therefore, to increase the Fmaxyield (here, Fmaxyield is deÔ¨Åned as minimizing misplacing chips at lower bins and increasing the number of chips placed at higher bins), it is important to"}
{"id": "sensors-22-01382.pdf::chunk_7", "source": "sensors-22-01382.pdf", "chunk_index": 7, "text": "p to another. Therefore, to increase the Fmaxyield (here, Fmaxyield is deÔ¨Åned as minimizing misplacing chips at lower bins and increasing the number of chips placed at higher bins), it is important to accurately identify and adapt the failing paths at a binning frequency. Hence, in this paper, a novel on-chip adaptive speed-binning system for Fmaxyield optimization is proposed, which can be used to optimize the Fmaxyield of a digital circuit when it has redundant timing in clock tree, the advantages of which are summarized below: ‚Ä¢ Based on the Fmaxtest results, the proposed system can improve the Fmaxyield and increase the overall proÔ¨Åt by promoting chips from lower speed bins to higher speed bins. ‚Ä¢ The proposed system can work seamlessly with existing Fmaxtests, including func- tional, structural, and sensor-based tests. ‚Ä¢ The proposed on-chip adaptive speed-binning system is all digital with negligible area and test overhead. It should be noted that this paper is an extended version of our paper published in the 2017 2nd IEEE International Conference on Integrated Circuits and Microsystems (ICICM) [ 29]. The ICICM 2017 paper [ 29] only focuses on a novel binning sensor for low-"}
{"id": "sensors-22-01382.pdf::chunk_8", "source": "sensors-22-01382.pdf", "chunk_index": 8, "text": "n of our paper published in the 2017 2nd IEEE International Conference on Integrated Circuits and Microsystems (ICICM) [ 29]. The ICICM 2017 paper [ 29] only focuses on a novel binning sensor for low-cost and accurate speed binning, while this paper focuses on promoting chips placed in the lower bins into higher bins. This paper improves the binning sensor architecture in the ICICM paper, and it proposes a novel on-chip adaptation binning and Fmaxyield optimization system. Moreover, it presents a novel and adaptive methodology for yield optimization, in which the paths impacting the speed bin of a speciÔ¨Åc IC are identiÔ¨Åed and adapted by our proposed on-chip Binning Checker and Binning Adaptor . As a result, some ICs placed in the lower bins can be promoted into higher bins. Hence, the overall proÔ¨Åt can be increased. Due to the different design purposes and test method, the two papers provide different experimental results. In summary, there is about a 70‚Äì80% difference between the ICICM paper [29] and this paper. Sensors 2022 ,22, 1382 3 of 18 The rest of the paper is organized as follows. The architecture of the proposed system is described in Section 2. The system implementation "}
{"id": "sensors-22-01382.pdf::chunk_9", "source": "sensors-22-01382.pdf", "chunk_index": 9, "text": "M paper [29] and this paper. Sensors 2022 ,22, 1382 3 of 18 The rest of the paper is organized as follows. The architecture of the proposed system is described in Section 2. The system implementation and Fmaxyield optimization Ô¨Çow is presented in Section 3. Section 4 shows the experimental and measurement results. Finally, Section 5 gives the concluding remarks. 2. Architecture The proposed on-chip adaptive binning and Fmaxyield optimization system is com- posed of Binning Checkers ,Binning Adaptors , and some on-chip Ô¨Çash memory, as shown in Figure 1. Binning Critical Path Binning Adaptor Binning Checker Normal Path SOC SRAM Analog peripheralIP Core I IP Core II Registers controlled by external memory Sea of Gates IP Core III JTAG Figure 1. Overview of the proposed on-chip adaptive binning and Fmaxyield optimization system. 2.1. The Binning Checker Generally, the speed bin of a chip is determined by some of the longest paths, which are named as Binning Critical Paths . The Binning Critical Path selection methodology is presented in detail in Section 4.3. Due to process variations and noise, a Binning Critical Path ‚Äôs delay may exceed the bin boundary, which means the output of the"}
{"id": "sensors-22-01382.pdf::chunk_10", "source": "sensors-22-01382.pdf", "chunk_index": 10, "text": "tical Path selection methodology is presented in detail in Section 4.3. Due to process variations and noise, a Binning Critical Path ‚Äôs delay may exceed the bin boundary, which means the output of the path switches after the capture clock. Therefore, the capture Ô¨Çip-Ô¨Çop obtain obtains wrong data, making the chip drops drop to a lower bin during response analysis. The proposed Binning Checker utilizes this feature to monitor whether the timing critical path‚Äôs delay is longer than the applied clock frequency. The detailed structure of the Binning Checker is shown in Figure 2 . As the Binning Checker only includes a few standard gates, a dedicated Binning Checker can be attach attached at the end of each Binning Critical Path . The Binning Checker has two tasks: ‚Ä¢ Task 1: It locates the paths causing the Fibinning failure on silicon, where Fiis the frequency boundary between biniand its higher bin bini\u00001. ‚Ä¢ Task 2: It evaluates whether the located Binning Critical Paths can be adapted to bini\u00001 by the proposed Binning Adaptor . If both (1) and (2) are satisÔ¨Åed, the output of Binning Checker (Adapt _EN), as shown in Figure 2, is switched to 1, which initiates the adaptive binning and F"}
{"id": "sensors-22-01382.pdf::chunk_11", "source": "sensors-22-01382.pdf", "chunk_index": 11, "text": "bini\u00001 by the proposed Binning Adaptor . If both (1) and (2) are satisÔ¨Åed, the output of Binning Checker (Adapt _EN), as shown in Figure 2, is switched to 1, which initiates the adaptive binning and Fmaxyield optimization. As shown in Figure 2, the Binning Checker is used to monitor the output of Binning Critical Path . The clock frequency of the critical path is the binning frequency Fi. Assume the adaptable margin is S0, which is equal to the delay of BUFF 0inside the Binning Checker . To achieve Task 1, the two inputs of the XOR 0gate come from the output of the critical path Sensors 2022 ,22, 1382 4 of 18 (node Data in Figure 2) and the critical path output signal through the BUFF 0, respectively. Thus, the XOR 0gate outputs 1if the data transit from 0to1or1to0within S0. The OR 0 gate and FF2together form a ‚Äústicky‚Äù structure, which means that once FF2outputs 1, the value of FF2remains 1until it is reset. Before binning optimization, all FF2s inBinning Checker are reset. BUFF 1is composed by several buffer cells, and its delay is equal to the sum of the delay of BUFF 0,XOR 0, and OR 0, as shown in Figure 2. Hence, FF2can monitor data transition after the capture edge of CLK wit"}
{"id": "sensors-22-01382.pdf::chunk_12", "source": "sensors-22-01382.pdf", "chunk_index": 12, "text": "omposed by several buffer cells, and its delay is equal to the sum of the delay of BUFF 0,XOR 0, and OR 0, as shown in Figure 2. Hence, FF2can monitor data transition after the capture edge of CLK within S0. If the Data (the output of Binning Critical Path ) transition occurs within S0after the clock capturing, the output of Binning Checker (Adapt _EN) would turn to 1.Adapt _EN=1means that (i) the delay of the Binning Critical Path is greater than 1/Fi, and (ii) the delay of Binning Critical Path is smaller than 1/Fi+S0. To make the detected failing path recoverable, BUFF 0inside the Binning Checker needs to be the same as BUFF 2inside the Binning Adaptor (Figure 2). The Binning Adaptor is introduced in detail in Section 2.2. By employing the design above, Task 1 and 2 mentioned above are fully achieved. Figure 2. The Binning Checker and Binning Adaptor . Figure 3 shows the output of Adapt _ENunder different Data transition conditions. In Figure 3a, the variable Data turns to 1before clock capturing, which means that the monitored path does not cause binning failure at Fi. Hence, the output of Adapt _ENstays at 0. In Figure 3b , the variable Data turns to 1within S0after clock capt"}
{"id": "sensors-22-01382.pdf::chunk_13", "source": "sensors-22-01382.pdf", "chunk_index": 13, "text": "lock capturing, which means that the monitored path does not cause binning failure at Fi. Hence, the output of Adapt _ENstays at 0. In Figure 3b , the variable Data turns to 1within S0after clock capturing, which means that the monitored path is an adaptable Binning Critical Path . Thus, the output of Adapt _ENturns to 1to initiate adaptive binning. In Figure 3c, there is a glitch in S0after capturing. Then, the output of Adapt _ENstays at 0to avoid misjudgement and wrong adaptation. In Figure 3d , the moment that the variable Data turns to 1is out of adaptable range, which means that the monitored path is an unadaptable Binning Critical Path . Thus, the output of Adapt _ENstays at0. 2.2. The Binning Adaptor The Binning Adaptor is designed to recover the identiÔ¨Åed adaptable failure Binning Critical Paths . The circuit for Binning Adaptor is also shown in Figure 2. The Binning Adaptors are inserted into the selected Binning Critical Paths , which moves the launching clock ahead to achieve a longer clock cycle. In other words, the Binning Adaptor can borrow a redundant margin from its upper stream path when necessary. Gate MUX 0of the Binning Adaptor is inserted at the end of the ori"}
{"id": "sensors-22-01382.pdf::chunk_14", "source": "sensors-22-01382.pdf", "chunk_index": 14, "text": "ve a longer clock cycle. In other words, the Binning Adaptor can borrow a redundant margin from its upper stream path when necessary. Gate MUX 0of the Binning Adaptor is inserted at the end of the original clock network for FF0. To make the Binning Adaptor insertion have little impact on the already closed timing, a number of buffers in the original clock tree need to be removed to cancel the effect of MUX insertion. From Figure 2, it can be seen that there are two conÔ¨Ågurable routes for the clock ( CLK ) going through the Binning Adaptor , namely the Timing Closure Clock Route and the After Adaptation Clock Route . Clearly, the clock cycle of After Adaptation Clock Route isS0longer than the Timing Closure Clock Route . The MUX 0is controlled by the Binning Checker inserted into the same path. When the adaptation decision is made by the Binning Adaptor , the Binning Checker switches the Sensors 2022 ,22, 1382 5 of 18 route of launch clock to After Adaptation Clock Route . Thus, the failed adaptable Binning Critical Path can be recovered. Then, Adapt _ENis written into a directly accessible Ô¨Çash memory to guarantee the function of the path for the later powering ups. Threshold of Sl"}
{"id": "sensors-22-01382.pdf::chunk_15", "source": "sensors-22-01382.pdf", "chunk_index": 15, "text": "led adaptable Binning Critical Path can be recovered. Then, Adapt _ENis written into a directly accessible Ô¨Çash memory to guarantee the function of the path for the later powering ups. Threshold of Slack(S 0) CLK Data Adapt_EN1/Fi (a) 1/Fi CLK Data Adapt_EN (b) 1/Fi CLK Data Adapt_EN (c) CLK Data Adapt_EN1/Fi (d) Figure 3. Four conditions of data/clock transition at FF1(FF2), and the adaptation decision made by the Binning Checker . (a) The monitored path does not cause binning failure, Adapt_EN stays at 0; (b) The monitored path is an adaptable Binning Critical Path ,Adapt_EN switches to 1; (c) Glitch exists within S0after capturing clock. Adapt_EN stays at 0to avoid misjudgement and wrong adaptation; (d) The monitored path is an unadaptable Binning Critical Path .Adapt_EN stays at 0. Figure 4 shows the timing of a Binning Critical Path and the margin borrowed from its upper stream path. To make the margin borrowing possible, the upper stream path should still function after lending margin S0to the failed Binning Critical Path . Hence, the upper stream path should have a margin larger than S0. Therefore, the upper stream path and Binning Critical Path could both support binning bo"}
{"id": "sensors-22-01382.pdf::chunk_16", "source": "sensors-22-01382.pdf", "chunk_index": 16, "text": "argin S0to the failed Binning Critical Path . Hence, the upper stream path should have a margin larger than S0. Therefore, the upper stream path and Binning Critical Path could both support binning boundary frequency Fi. It should be noted that when the upper stream path has sufÔ¨Åcient margin, only one Binning Adaptor is needed to be inserted, as shown in Figure 5a. However, sometimes, the timing margin of the upper stream path does not meet this requirement. Then, multiple Binning Adaptors are needed, as shown in Figure 5b. Binning Adaptor I is inserted into the launch Ô¨Çip-Ô¨Çop of the Binning Critical Path and Binning Adaptor II is inserted into the launch Ô¨Çip-Ô¨Çop of the upper stream path. The Binning Adaptor II keeps borrowing extra slack S0from the higher upper stream path ( P2), which ensures that the upper stream path ( P1) has an abundant margin to lend to the binning critical path. In addition, if the timing margin of both P1and P2is less than S0, then S0should be reduced. One Clock Cycle One Clock CycleMargin of Upper Stream PathS0Slack of the Binning Critical Path (‚â•‚ÄìS 0) Delay of the Upper Stream Path Delay of the Binning Critical Path Figure 4. Binning Adaptor borrows unus"}
{"id": "sensors-22-01382.pdf::chunk_17", "source": "sensors-22-01382.pdf", "chunk_index": 17, "text": "ck Cycle One Clock CycleMargin of Upper Stream PathS0Slack of the Binning Critical Path (‚â•‚ÄìS 0) Delay of the Upper Stream Path Delay of the Binning Critical Path Figure 4. Binning Adaptor borrows unused timing margin from the upper stream path to an adaptable Binning Critical Path . Sensors 2022 ,22, 1382 6 of 18 Binning Critical Path ( P1)Binning Checker Upper Stream Path ( P2) with Abundant Slack Binning Adaptor (Borrow S 0 from P 2) (a) Higher Stream Path ( P3) with Abundant Slack Upper Stream Path ( P2) with Insufficient Slack Binning Checker Binning Adaptor ƒä (Borrow S 0 from P 3) Binning Critical Path ( P1)Binning Adaptor ƒâ (Borrow S 0 from P 2) (b) Figure 5. The insertion of Binning Adaptor under two different scenarios. ( a) The upper stream path of theBinning Critical Path has a slack larger than S0. Then only one Binning Adaptor is needed; ( b) The upper stream path of the Binning Critical Path has a slack smaller than S0. Hence multiple Binning Adaptors are inserted. It should be noted that there could be more than one upper stream path ending at FF0 in Figure 2. Therefore, we should certify that the longest one has a slack larger than S0. 2.3. Utilized Flash Memory To p"}
{"id": "sensors-22-01382.pdf::chunk_18", "source": "sensors-22-01382.pdf", "chunk_index": 18, "text": "ld be noted that there could be more than one upper stream path ending at FF0 in Figure 2. Therefore, we should certify that the longest one has a slack larger than S0. 2.3. Utilized Flash Memory To permanently place the chip into the promoted bin, it is essential to store the Adapt _ENinto non-volatile memory such as Ô¨Çash after the binning adaptation, as shown in Figures 1 and 2. It needs to be noted that Ô¨Çash memory is not easy to be integrated in the same die with digital electronics. Considering that most chips have to load some conÔ¨Åguration information at boot time, adaptation results (values of Adapt _EN) could be included in the conÔ¨Åguration information, which is stored in external memory, such as Ô¨Çash. The Binning Adaptor s can read proper adaptation results from Ô¨Çash through on-chip registers after powering on or rebooting. The Ô¨Çash should be directly accessible by the proposed scheme. Therefore, the Binning Adaptor can read a proper adaptation signal directly from Ô¨Çash after powering on or rebooting. It should be noted that the utilized Ô¨Çash memory addresses should be writable only during the Fmaxoptimization process, which means the output of Binning Checker loses the co"}
{"id": "sensors-22-01382.pdf::chunk_19", "source": "sensors-22-01382.pdf", "chunk_index": 19, "text": "powering on or rebooting. It should be noted that the utilized Ô¨Çash memory addresses should be writable only during the Fmaxoptimization process, which means the output of Binning Checker loses the control of Binning Adaptor after the optimization. In addition, if cost allows, the designer can integrate the one-time programmable (OTP) memory directly into the chip for Adapt _ENsignals storage. 2.4. The Limitation and Yield Optimization Rate Estimation The bin promotion may not be successful for all devices. Figure 6 shows the silicon delay distributions of all speed-paths of a device, which can be binned at Fi. In other words, all speed-paths should have a probability of locating on the right side of the binning boundary. However, some Gaussian curves almost fully locate on the right side of the binning boundary, which represents the paths with little probability of causing binning failure at Fi. Meanwhile, the other Gaussian curves have a non-negligible part locating on the left side of the binning boundary, which represents the paths causing Fi binning failure frequently. The shaded Gaussian curves in Figure 6 represent the selected Binning Critical Paths , and the \u0000S0boundary ma"}
{"id": "sensors-22-01382.pdf::chunk_20", "source": "sensors-22-01382.pdf", "chunk_index": 20, "text": "of the binning boundary, which represents the paths causing Fi binning failure frequently. The shaded Gaussian curves in Figure 6 represent the selected Binning Critical Paths , and the \u0000S0boundary marks the adaptability of Binning Adaptor with process variations. Hence, there are two cases in which the bin promotion may not be achieved: ‚Ä¢ Case 1: A chip can be promoted to the higher bin only if all silicon failure paths are successfully adapted. However, the selected Binning Critical Paths may not cover all silicon failure paths. If the delay of an unselected path exceeds the binning boundary on silicon, such as Path 1in Figure 6, then the chip cannot be promoted to the higher bin. ‚Ä¢ Case 2: Even if all silicon failure paths are selected as Binning Critical Paths , and equipped with Binning Checker s and Adaptor s, if the actual slack of a Binning Critical Path is smaller than \u0000S0, such as Path 2in Figure 6, which means some failing paths are out of the adaptation range, then the bin promotion of the device also fails. Hence, if we deÔ¨Åne the Yield Optimization Rate as the probability of successfully promoting a device to the higher bin, then it can be calculated as Equation (1), w"}
{"id": "sensors-22-01382.pdf::chunk_21", "source": "sensors-22-01382.pdf", "chunk_index": 21, "text": "promotion of the device also fails. Hence, if we deÔ¨Åne the Yield Optimization Rate as the probability of successfully promoting a device to the higher bin, then it can be calculated as Equation (1), where mis the number of unselected paths with a probability of silicon failure belonging to Case 1, and nis the number of selected paths with a probability of being unadaptable belonging to Sensors 2022 ,22, 1382 7 of 18 Case 2. Here, ndepends on the manufacturing technology, which is uncontrollable during the design stage. Reducing the number of mand adjusting S0are the best ways to improve theYield Optimization Rate , which is introduced in Section 4.3. Yield Optimization Rate =m √ï i=1Z+¬• 0p(t)dt\u0002n √ï i=1Z0 \u0000S0p(t)dt (1) Note that process variations may affect the Binning Checker s and Binning Adaptor s. The impacts include (i) the scope of critical paths that the Binning Checker can recognize and (ii) the extra margin the Binning Adaptor can give. (i) and (ii) are designed to be the same as S0; however, variations may make (i) and (ii) deviate from S0. Hence, to reduce the impact of process variations, it is suggested to use the lowest variation rate (LVT large cell) to build theBinni"}
{"id": "sensors-22-01382.pdf::chunk_22", "source": "sensors-22-01382.pdf", "chunk_index": 22, "text": "as S0; however, variations may make (i) and (ii) deviate from S0. Hence, to reduce the impact of process variations, it is suggested to use the lowest variation rate (LVT large cell) to build theBinning Checker s and Binning Adaptor s. Section 4 provides the simulated and measured yield optimization results considering process variations. In Section 4, the measurement results shows that the binning promotion rate is 7‚Äì16%. Figure 6. The Binning Critical Path selection and process variation affect the Yield Optimization Rate . 2.5. Application Scenarios The proposed method is to reduce the impact of process variations on chip perfor- mance through post-manufacturing adaptation. During the design phase, the designer can optimize the timing of the circuit as much as possible. For example, by inserting registers, paths with large delay can be transformed into a two or multi-stage pipeline. However, due to design and optimization constraints, there will always be some paths that have greater delay than most paths, which are critical paths. These paths are the ones that need to be focused on. Even if the clock distribution tree is highly optimized, there may still be a sufÔ¨Åcient margin i"}
{"id": "sensors-22-01382.pdf::chunk_23", "source": "sensors-22-01382.pdf", "chunk_index": 23, "text": "r delay than most paths, which are critical paths. These paths are the ones that need to be focused on. Even if the clock distribution tree is highly optimized, there may still be a sufÔ¨Åcient margin in the upper stream path of the critical path. To ensure that the critical path can run at the target frequency, if there is redundant timing in the clock tree, then we can adjust the clock tree so that the critical path can use the redundant timing of the clock distribution tree. This step can be performed during the design phase, or after being manufactured using the proposed method. However, it is know that the process variation causes a gap between design and manufacturing. Even if the designer has highly optimized the timing at the design phase, the critical path or even non-critical path after being manufactured still has the probability of falling to a lower bin. If the designer improper utilizes redundant timing of the clock distribution tree at the design phase, it may make the upper stream paths of critical paths fail at the binning boundary after being manufactured, which means there are still limitations to timing optimization at the design phase. For example, if the delay o"}
{"id": "sensors-22-01382.pdf::chunk_24", "source": "sensors-22-01382.pdf", "chunk_index": 24, "text": "er stream paths of critical paths fail at the binning boundary after being manufactured, which means there are still limitations to timing optimization at the design phase. For example, if the delay of a critical path is 980 ps, the delay of its upper stream path is 950 ps, the adaptable margin ( S0) is 10 ps, and the target clock period is 1000 ps. The adaptable margin is the margin that the upper stream path can lend to the critical path. Considering process variations, after being manufactured, the actual delay of the critical path may be 990 ps, the delay of its upper stream path may be 990 ps, and the adaptable margin ( S0) may be 11 ps. It is possible if the critical path is built with low variation cells (LVT large cells) for small delay, and the upper stream path is built with relatively higher variation cells (HVT small cells) for low area and low power overhead. If we perform timing adaptation at the design phase, both the critical path and its upper stream path could work at the target clock cycle during simulation. However, for the actual chip, the Sensors 2022 ,22, 1382 8 of 18 upper stream path would fail at the target clock period. However, if the designer adopts the"}
{"id": "sensors-22-01382.pdf::chunk_25", "source": "sensors-22-01382.pdf", "chunk_index": 25, "text": " the target clock cycle during simulation. However, for the actual chip, the Sensors 2022 ,22, 1382 8 of 18 upper stream path would fail at the target clock period. However, if the designer adopts the proposed binning optimization method, he/she can perform adaptation according to the actual testing result. In this case, according to the test result, no critical path adjustment is needed, and both the critical path and its upper stream path could work at the target clock period. Hence, timing adaptation based on manufacturing test results can effectively improve the performance of the chip (speed bins). In a digital circuit, optimizing and equalizing the pipeline stages is a common way to improve chip performance. Then, the upper stream path of the critical path may not have enough timing margin for adaptation. For this case, multiple Binning Adaptor s are needed, as shown in Figure 5b. It should be noted that the proposed method is not applicable if there are a large number of deep pipelines with close delay per stage in the circuit to be optimized. In addition, there are also some circuits that use pipelines with as few stages as possible for low power consumption. There are some"}
{"id": "sensors-22-01382.pdf::chunk_26", "source": "sensors-22-01382.pdf", "chunk_index": 26, "text": "pelines with close delay per stage in the circuit to be optimized. In addition, there are also some circuits that use pipelines with as few stages as possible for low power consumption. There are some critical paths in such circuits that have a large impact on the circuit speed bins. In such design, retiming is limited because of the higher area and power consumption overhead it introduces. As a result, there will be some redundant timing of the clock distribution tree. At the same time, timing optimization during design stage, such as employing the redundant timing of the clock distribution tree, is impacted by the process variations as discussed above. In this case, using our proposed method, which adjusts the critical path clock after being manufactured, the performance of the chip can be improved with low overhead. The proposed Binning Checker only works during the speed binning test, which brings little power consumption. As discussed above, considering the process variations, timing optimization using EDA tools during the design phase combined with timing adaptation using the proposed method after being manufactured is a better solution to achieve high chip performance. It sh"}
{"id": "sensors-22-01382.pdf::chunk_27", "source": "sensors-22-01382.pdf", "chunk_index": 27, "text": "ing optimization using EDA tools during the design phase combined with timing adaptation using the proposed method after being manufactured is a better solution to achieve high chip performance. It should be noted that there are limitations in the generality of the proposed adaptation methodology. In detail, the proposed methodology can be used to optimize the Fmaxyield of a digital circuit when it has redundant timing in the clock tree, so that the critical paths can borrow sufÔ¨Åcient timing margin from their upper stream paths for adaptation. If there is not enough timing margin for adaptation, multiple Binning Adaptors can be employed, as shown in Figure 5b. Our proposed methodology is not applicable if the circuit to be optimized has poor redundant timing in the clock tree, such as a circuit using a large number of deep pipelines with close delay per stage, which means that it would be hard for one stage to obtain sufÔ¨Åcient timing margin from the previous stage. 3. The Flow for FmaxBinning and Yield Optimization The Fmaxbinning and yield optimization Ô¨Çow based on the adaptation system is shown in Figure 7. Step 1: Binning Critical Path Selection. As discussed above, the Binning "}
{"id": "sensors-22-01382.pdf::chunk_28", "source": "sensors-22-01382.pdf", "chunk_index": 28, "text": "Binning and Yield Optimization The Fmaxbinning and yield optimization Ô¨Çow based on the adaptation system is shown in Figure 7. Step 1: Binning Critical Path Selection. As discussed above, the Binning Critical Path group size is limited by the acceptable overhead. However, to maximize the Yield Optimization Rate , the Binning Critical Path group should cover the paths causing speed binning failure with the highest probability. Therefore, designers should perform statistical timing analysis (STA) after layout generation and timing closure to select the most critical paths. The Binning Critical Path selection details and results for the implementation of this paper are shown in Section 4.3. Step 2: Binning Checker and Binning Adaptor Insertion. The Binning Checker s and Binning Adaptor s are inserted at the selected Binning Critical Paths . As discussed in Section 2, by replacing the clock buffers belonging to the original clock tree with the cells needed by the Binning Adaptor , the insertion process should not affect the already closed timing, and it requires minimum layout adjustments. The small overhead of the Binning Checker and Binning Adaptor helps to keep the overall area over"}
{"id": "sensors-22-01382.pdf::chunk_29", "source": "sensors-22-01382.pdf", "chunk_index": 29, "text": "rtion process should not affect the already closed timing, and it requires minimum layout adjustments. The small overhead of the Binning Checker and Binning Adaptor helps to keep the overall area overhead of the adaptation system low. Step 3: Binning the Chip Under Test at Fi. In this step, the fabricated chip can be binned at frequency Fiusing functional, structural, or sensor-based speed binning methodologies. At the same time, the adaptable Binning Critical Paths are identiÔ¨Åed by the proposed system. Sensors 2022 ,22, 1382 9 of 18 Step 4: Get Preliminary Binning Result. In this step, if the chip under test passes the test at Fi, then the binning frequency is increased until reaching Fmax. However, if the chip fails at Fi, the Binning Checkers identify adaptable Binning Critical Paths . Step 5: Perform Binning Adaptation. In this step, the Adapt_EN signals, which are the outputs of the Binning Checkers , are piped to a directly accessible non-volatile memory (DMA), and the binning adaptation is performed at the same time. The identiÔ¨Åed adaptable failing Binning Critical Paths in Step 4 are adapted. Step 6: Re-Binning at Fi. In this step, the chips under test are binned again at f"}
{"id": "sensors-22-01382.pdf::chunk_30", "source": "sensors-22-01382.pdf", "chunk_index": 30, "text": "aptation is performed at the same time. The identiÔ¨Åed adaptable failing Binning Critical Paths in Step 4 are adapted. Step 6: Re-Binning at Fi. In this step, the chips under test are binned again at frequency Fi. If all of the silicon failure paths of a device have been adapted successfully, the re-binning passes. Hence, a percentage of the chips falling into the lower bin can be promoted to the higher bins. However, if the re-binning failed, the data in DMA should be cleared to ensure the chip still functions at the already passed lower bin. Start Architecture Implementation Y NInsert Binning Checker and Adaptor and Adjust Layout Increase Binning FrequencyStep1: Step3:Step2: Step4: Step5: Step6:Speed Binning Success? Yield Optimization Binning the Chip Under Test at Fi Output the Maximum Clock Frequency and Locate Speed Bin \u000f\u0001 Get Promotion Rate for the First Silicon Select Binning Critical Path Re-Binning the Chip Under Test at Fi Label Chips with Marketing FrequencyStep7: Step8: Design Synthesis, Layout Generation, and Timing Closure Pipe Adapt_EN Signals to DMA (Flash). Note: Adaptation takes place at the same time Speed Binning Success? Clear the DMA (Flash) YN EndFabrication "}
{"id": "sensors-22-01382.pdf::chunk_31", "source": "sensors-22-01382.pdf", "chunk_index": 31, "text": "ign Synthesis, Layout Generation, and Timing Closure Pipe Adapt_EN Signals to DMA (Flash). Note: Adaptation takes place at the same time Speed Binning Success? Clear the DMA (Flash) YN EndFabrication Figure 7. The proposed Ô¨Çow for binning and Fmaxyield optimization. Step 7: Speed Bin Decision and Yield Optimization Rate Calculation. The speed bin of the chip under test can be decided according to whether the re-binning after adaptation is successful or not. By comparing the binning yield at Step 6 and Step 3, the Yield Optimization Rate can be obtained. Step 8: Label chips with Marketing Frequency. Aging and other factors would lead to performance degradation. Therefore, the marketing frequency of a device needs to add some additional margin based on the measured Fmax. As discussed above, the yield optimization Ô¨Çow can be integrated into all Fmaxtests, such as the methods mentioned in [ 7,14], and the binning adaptation system brings little impact on the existing tests. Sensors 2022 ,22, 1382 10 of 18 4. Experimental Results The proposed on-chip binning and Fmaxyield optimization system has been imple- mented onto several benchmarks from ITC‚Äô99, OpenSPARCT2 SoC, and ISCAS‚Äô89 bench-"}
{"id": "sensors-22-01382.pdf::chunk_32", "source": "sensors-22-01382.pdf", "chunk_index": 32, "text": "2, 1382 10 of 18 4. Experimental Results The proposed on-chip binning and Fmaxyield optimization system has been imple- mented onto several benchmarks from ITC‚Äô99, OpenSPARCT2 SoC, and ISCAS‚Äô89 bench- marks. The benchmarks equipped with the yield optimization system have been simulated in the 28 nm technology node [ 39] and implemented on a number of 28 nm Altera FPGAs. 4.1. The VeriÔ¨Åcation of the Binning Checker and Binning Adaptor To verify the proposed Binning Checker and Binning Adaptor , both are inserted into a b19Binning Critical Path with a delay of 851 ps. The preset adaptable margin ( S0) is 23 ps, and the slack of the upper stream path is 50 ps. The Spice model of the Binning Critical Path together with the attached Binning Checker and Binning Adaptor are extracted from the design layout. A stimulus pattern with a rising edge is applied at the launch Ô¨Çip-Ô¨Çops of the critical path. The clock frequency is set to 1.19 GHz, and its period is smaller than the delay of the critical path. As shown in Figure 8, before adaptation, at the Ô¨Årst capture, the path fails to make transition, which represents a 1.19 GHz binning failure. At the same time, the Binning Checker identiÔ¨Åes th"}
{"id": "sensors-22-01382.pdf::chunk_33", "source": "sensors-22-01382.pdf", "chunk_index": 33, "text": "l path. As shown in Figure 8, before adaptation, at the Ô¨Årst capture, the path fails to make transition, which represents a 1.19 GHz binning failure. At the same time, the Binning Checker identiÔ¨Åes that the monitored path is an adaptable Binning Critical Path , and it switches Adapt_EN to1, which initiates the adaptation. Thus, the same path functions again at the second capture, which means the path meets the 1.19 GHz binning frequency. The waveforms after adaptation in Figure 8 represent the case when the adaptation status of the speciÔ¨Åc path has been written into a directly accessible Ô¨Çash memory and applied to the path right after power up or rebooting. Then, when the same patterns are re-applied to path, the path always functions correctly at 1.19 GHz frequency. 91 10‚àí√ó Figure 8. The VeriÔ¨Åcation of Binning Checker and Binning Adaptor . Before adaptation, the Binning Critical Path fails at Ô¨Årst capture, and it recovers at the second capture when the adaptation is enabled. After the adaptation status is kept into a directly accessible Ô¨Çash memory, the Binning Critical Path stays in the higher bin all the time. 4.2. A Successful Bin Promotion Case For the ITC‚Äô99 b19 benchmark, th"}
{"id": "sensors-22-01382.pdf::chunk_34", "source": "sensors-22-01382.pdf", "chunk_index": 34, "text": " adaptation status is kept into a directly accessible Ô¨Çash memory, the Binning Critical Path stays in the higher bin all the time. 4.2. A Successful Bin Promotion Case For the ITC‚Äô99 b19 benchmark, through using statistical statistic timing analysis, a total of 120 top paths are selected as the Binning Critical Paths . According to the design of theBinning Checker and Binning Adaptor , the adaptable margin S0equals 0.3 ns. Then, the speed bin of a b19 circuit is simulated by HSpice with and without binning adaptation. Sensors 2022 ,22, 1382 11 of 18 As shown in Figure 9, the x-axis shows the slack of Binning Critical Paths , where Fi is the binning frequency equals to 167 MHz. Hence, the vertical line at 0represents the binning boundary. The path slack distribution before and after binning adaptation are shown as the dotted and shaded bars, respectively. It can be seen that without binning adaptation, 94 paths fall on the left side of the binning boundary, which means they cause the binning failure of the chip at 167 MHz. However, the worst slack of the failure path is 0.16 ns, which is within the adaptable margin S0= 0.3 ns. Hence, with Binning Checker and Binning Adaptor inserted"}
{"id": "sensors-22-01382.pdf::chunk_35", "source": "sensors-22-01382.pdf", "chunk_index": 35, "text": "nning failure of the chip at 167 MHz. However, the worst slack of the failure path is 0.16 ns, which is within the adaptable margin S0= 0.3 ns. Hence, with Binning Checker and Binning Adaptor inserted on the 120 Binning Critical Paths , which cover all 94 failing paths, after adaptation, the slack of all paths are re-distributed on the right side of the binning boundary (Figure 9), which means that this chip is successfully promoted to the 167 MHz bin. It should be noted that as discussed above, depending on the Binning Critical Path and adaptable margin S0selection, successful binning promotion may not always be possible. Section 4.3 discusses the impact of the above two factors on the number of devices promoted to the higher bin ( Yield Optimization Rate ). Figure 9. The slack distribution of a ITC‚Äô99 b19 sample, with 94 paths fail 167 MHz binning. With all failure paths correctly adapted, this sample is successfully promoted to the 167 MHz bin. 4.3. The Selection of Binning Critical Path and Adaptable Margin S 0 According to Equation (1), to maximize the Yield Optimization Rate , for a given Binning Critical Path group size (overhead), the silicon failure path coverage should be"}
{"id": "sensors-22-01382.pdf::chunk_36", "source": "sensors-22-01382.pdf", "chunk_index": 36, "text": " Path and Adaptable Margin S 0 According to Equation (1), to maximize the Yield Optimization Rate , for a given Binning Critical Path group size (overhead), the silicon failure path coverage should be maximized. Hence, for the Ô¨Årst silicon, when no silicon data are available, the designer needs to per- form Monte Carlo analysis to obtain the probability of each path to locate in a certain bin. Figure 10 shows the probability of b19‚Äôs speed paths (top 20% paths) located in bin1 (167 MHz), bin2 (100 MHz), and bin 3 (33 MHz) (considering 10% L, Nmos: vth0 = 17% toxref = 10% ; Pmos: vth0 = 18% toxref = 10% process variations, 1000 Monte Carlo simula- tions). It can be seen that as shown in Figure 10a, about 73% of the speed paths locate in bin1 with more than 90% probability, and 5% of the speed paths drop to bin2 with more than 70% probability, as shown in Figure 10b. If the Binning Critical Path selection criteria d is set as 70%, then the 5% of speed paths with more than dprobability dropping to bin2 (marked in Figure 10b) are selected as Binning Critical Paths . By comparing the curves in Figure 10b,c, the paths with higher probability of dropping to bin2 are the same group of path"}
{"id": "sensors-22-01382.pdf::chunk_37", "source": "sensors-22-01382.pdf", "chunk_index": 37, "text": "opping to bin2 (marked in Figure 10b) are selected as Binning Critical Paths . By comparing the curves in Figure 10b,c, the paths with higher probability of dropping to bin2 are the same group of paths with a lower probability to drop to bin3. Therefore, the same adaptation architectures help to promote chips from bin2 to bin1 as well as from bin3 to bin2. Figure 11 shows the average slack of the b19‚Äôs top 20% paths at Fiand their corre- sponding probability of transpassing the bin boundary. For example, for the paths with average slack smaller than 0, the y-axis represents the probability of the path locating in the higher bin ( Fi). While for the paths with average slack larger than 0, the y-axis represents the probability of the path falling to the lower bin. Hence, if we make the Binning Critical Path selection criteria das 70% (with a probability of ddropping to the lower bin, and a probability of 1 \u0000d= 30% staying in the Fibin), then the ideal adaptable margin S0can be Sensors 2022 ,22, 1382 12 of 18 decided, as shown in Figure 11. Hence, the BUFF 0and BUFF 2inside the Binning Checker and Binning Adaptor in Figure 2 can be selected accordingly. There is no doubt that the more"}
{"id": "sensors-22-01382.pdf::chunk_38", "source": "sensors-22-01382.pdf", "chunk_index": 38, "text": "22 ,22, 1382 12 of 18 decided, as shown in Figure 11. Hence, the BUFF 0and BUFF 2inside the Binning Checker and Binning Adaptor in Figure 2 can be selected accordingly. There is no doubt that the more paths that are selected as Binning Critical Paths with Binning Checker and Binning Adaptor inserted, the more chips can be promoted to higher bins. However, redundant Binning Checker and Binning Adaptor can bring higher overhead and may be not necessary. The ideal condition is that all paths drop out of bin Fi, and no paths within Fiare selected as Binning Critical Paths . However, this cannot be guaranteed based on the statistical results shown in Figure 10. Instead, the paths with a probability larger than d(the Binning Critical Paths selection criteria) are selected to compose the Binning Critical Paths group. (a) (b) 0 500 1000 1500 2000 Path ID05101520ProbabilityThe paths with high probability drop to bin2 also have low probability drop to bin3 which means the adaptation on Binning Critical Paths can both promote chips from bin2 to bin1 and from bin3 to bin2. (c) Figure 10. For the Ô¨Årst silicon, the Binning Critical Paths are selected based on statistical timing analysis. The pat"}
{"id": "sensors-22-01382.pdf::chunk_39", "source": "sensors-22-01382.pdf", "chunk_index": 39, "text": "ritical Paths can both promote chips from bin2 to bin1 and from bin3 to bin2. (c) Figure 10. For the Ô¨Årst silicon, the Binning Critical Paths are selected based on statistical timing analysis. The paths with high probability ( d= 70% in this implementation) falling into the lower bins are selected as Binning Critical Paths . (a) The probability of ITC‚Äô99 b19 top 20% paths locate in bin1; (b) The probability of ITC‚Äô99 b19 top 20% paths locate in bin2; ( c) The probability of ITC‚Äô99 b19 top 20% paths locate in bin3. Sensors 2022 ,22, 1382 13 of 18 91 10‚àí√ó Figure 11. The probability of paths transpassing bin boundaries with different slack. Adaptable margin S0is selected according to d(70% in this implementation). Figure 12 shows the impact of don the size of Binning Critical Paths group, as well as the Yield Optimization Rate (the percentage of devices being promoted to the higher bin), for b19. It can be seen that as ddecreases, the Binning Critical Path group size is increasing. However the Yield Optimization Rate almost remains stable after dreaches 70%. The reason is, according to Figure 11, with fixed S0, even more paths are selected as Binning Critical Paths by decreasing the s"}
{"id": "sensors-22-01382.pdf::chunk_40", "source": "sensors-22-01382.pdf", "chunk_index": 40, "text": "r the Yield Optimization Rate almost remains stable after dreaches 70%. The reason is, according to Figure 11, with fixed S0, even more paths are selected as Binning Critical Paths by decreasing the selection criteria d, the newly selected paths are with slacks out of the adaptable margin (S0). Therefore, over increasing the Binning Critical Path group size gives little help for yield optimization. It should be noted that different devices have different dandS0, but the method to find them is the same. 0102030405060708090 Œ¥ (%)02004006008001000The Size of Binning Critical Path GroupThe size of Binning Critical Path group Binning yield optimization rate 0246810 Binning Yield Optimization Rate (%) Figure 12. The impact of Binning Critical Path selection criteria ( d) on the size of Binning Critical Path group, as well as the Yield Optimization Rate , considering 10% L, Nmos: vth0 = 17% toxref = 10%; Pmos: vth0 = 18% toxref = 10% process variations for b19. As discussed above, the decision of adaptable margin S0, which is the timing margin borrowed from the upper stream path of a timing critical path, also affects the Yield Opti- mization Rate . To analyze S0‚Äôs impact, we introduce No"}
{"id": "sensors-22-01382.pdf::chunk_41", "source": "sensors-22-01382.pdf", "chunk_index": 41, "text": "n of adaptable margin S0, which is the timing margin borrowed from the upper stream path of a timing critical path, also affects the Yield Opti- mization Rate . To analyze S0‚Äôs impact, we introduce Normalized _S0deÔ¨Åned in Formula (2), where Tsysis the functional clock cycle length. It seems that the larger the Normalized _S0 is, the more binning failure paths can be recovered. However, Figure 13 shows the Yield Optimization Rate through increasing Normalized _S0. It can be seen that at the beginning, with the increment of Normalized _S0, the Yield Optimization Rate improves. However, as the timing margin of upper stream path is restricted, S0cannot keep increasing. A too- aggressive S0fails the upper stream path. Take b19 for example, as shown in the same Ô¨Ågure, with Normalized _S0increased to 6%, the Yield Optimization Rate starts to decrease. Therefore, for this implementation, it is suitable to set the value of Normalized _S0to 5%. Sensors 2022 ,22, 1382 14 of 18 Normalized _S0=S0 Tsys(2) Due to the existing of the difference between manufactural and statistical simulated path delay, the actual Binning Critical Paths might be different from the simulated ones. Therefore, to furt"}
{"id": "sensors-22-01382.pdf::chunk_42", "source": "sensors-22-01382.pdf", "chunk_index": 42, "text": "sys(2) Due to the existing of the difference between manufactural and statistical simulated path delay, the actual Binning Critical Paths might be different from the simulated ones. Therefore, to further improve the bin promotion rate, it is suggested to improve the timing library according to the silicon data. Figure 13. The inÔ¨Çuence of Normalized _S0onYield Optimization Rate for different benchmarks. 4.4. The ProÔ¨Åt Increment Due to Yield Optimization To mimic the actual speed binning scenario, the proposed binning adaptation system has been implemented on a number of FPGAs. The technology of the adopted FPGA is 28 nm, which has enough process variations. Each FPGA represents one or multiple benchmarks depending on the size of the implemented benchmark. The layout and mea- surement setup of FPGAs are shown in Figure 14. The chips will be projected into three bins according to their Fmaxtest results. Figure 14. Overview of 28 nm FPGA (Altera 5CEFA4F23C8N) chip planner and measurement setup. For b19, 120 paths are selected as the binning critical path and inserted with Binning Checker s and Binning Adaptor s, according to Figure 10. The distribution of 100 b19 chips Sensors 2022 ,22"}
{"id": "sensors-22-01382.pdf::chunk_43", "source": "sensors-22-01382.pdf", "chunk_index": 43, "text": "etup. For b19, 120 paths are selected as the binning critical path and inserted with Binning Checker s and Binning Adaptor s, according to Figure 10. The distribution of 100 b19 chips Sensors 2022 ,22, 1382 15 of 18 before and after binning adaptation is shown in Figure 15. It can be seen that considering the 100 b19 FPGA samples, for the Ô¨Årst silicon, two chips are promoted from bin3 into bin2, and seven chips are promoted from bin2 into bin1. Therefore, for the Ô¨Årst silicon, 9% chips are upgraded to higher bins with the proposed binning adaptation system, with Yield Optimization Rate equaling to 9%. Figure 15. The measured Yield Optimization Rate for b19. It is known that the proÔ¨Åt of higher bin chips is more than that of the lower bins chips. For instance, the price of higher bin Altera FPGA is about 1.2 times of the next bin [ 40]. This would help to evaluate the Value-Added ProÔ¨Åts ( V AP).V AP is deÔ¨Åned by Formula (3), where Num _a f terbin[i]and Num _be f orerbin[i]represent the number of chip fall in bin[i] after and before adaptation, respectively. ais the price of higher bin devices over the lower bin, and kis the number of bins. VAP =k √• i=1Num _a f terbin[i]ak\u0000i a √• k=1N"}
{"id": "sensors-22-01382.pdf::chunk_44", "source": "sensors-22-01382.pdf", "chunk_index": 44, "text": "number of chip fall in bin[i] after and before adaptation, respectively. ais the price of higher bin devices over the lower bin, and kis the number of bins. VAP =k √• i=1Num _a f terbin[i]ak\u0000i a √• k=1Num _be f orebin[i]ak\u0000i\u00001 (3) Asa= 1.2, and k= 3 for this implementation, the Yield Optimization Rate and Value- Added ProÔ¨Åt results for different benchmarks are shown in Table 1. From the table, it can be seen that under the given value of Binning Critical Path selection criteria dand adaptable margin S0, the Yield Optimization Rate is 7‚Äì16% and the V AP is 1.18‚Äì3.04%, Table 1. The Yield Optimization Rate and Value-Added ProÔ¨Åt ( V AP) with the proposed adaptation on various benchmarks. Benchmark s13207 s38417 s35932 b19 FGU Yield Optimization Rate 7% 8% 10% 9% 16% Value-added ProÔ¨Åt ( V AP) 1.18% 1.34% 1.85% 1.71% 3.04% 4.5. The Area Overhead Table 2 shows the number of Binning Checker and Binning Adaptor pairs inserted into different benchmarks and the overall area overhead of the proposed system. It can been seen that the proposed system has a low area overhead. Note that the overheads can be even smaller for a large-scale industrial application. Sensors 2022 ,22, 1382 16 of 18 Table "}
{"id": "sensors-22-01382.pdf::chunk_45", "source": "sensors-22-01382.pdf", "chunk_index": 45, "text": " system. It can been seen that the proposed system has a low area overhead. Note that the overheads can be even smaller for a large-scale industrial application. Sensors 2022 ,22, 1382 16 of 18 Table 2. The area overhead of the proposed system on different benchmarks. Benchmark s13207 s38417 s35932 b19 FGU Pairs of Checker and Adaptor 6 9 43 120 84 Total Area ( \u0016m2) 11,249.55 35,740.03 38,923.68 412,647.52 1,246,460.42 Overall Area Overhead 1.55% 0.73% 3.20% 0.85% 0.19% Required DMA Bit Number 6 9 43 120 84 5. Conclusions In this paper, a novel on-chip adaptation-based Fmaxbinning and optimization method- ology is proposed, which can upgrade marginal chips and improve the yield of high- performance chips. The proposed adaptive system has been implemented and validated on Ô¨Åve benchmarks from ITC, ISCAS89, and OpenSPARCT2 core. In addition, it has been veriÔ¨Åed on a number of FPGAs. The experiment result shows that the proposed Fmax binning and optimization methodology can improve the yield of high-end chips up to 7‚Äì16%, and improve the manufacturer‚Äôs proÔ¨Åt by 1.18‚Äì3.04% according to the V AP model. At the same time, the all-digital adaptation system brings low design overhead and low"}
{"id": "sensors-22-01382.pdf::chunk_46", "source": "sensors-22-01382.pdf", "chunk_index": 46, "text": "ld of high-end chips up to 7‚Äì16%, and improve the manufacturer‚Äôs proÔ¨Åt by 1.18‚Äì3.04% according to the V AP model. At the same time, the all-digital adaptation system brings low design overhead and low area overhead. Author Contributions: Conceptualization, D.Z.; methodology, D.Z.; data curation, D.Z.; writing‚Äî original draft preparation, D.Z.; writing‚Äîreview and editing, Q.R.; supervision, Q.R.; funding acquisition, D.S. All authors have read and agreed to the published version of the manuscript. Funding: This research was funded by the National Science Foundation of China (NSFC) under grant 61631002. Institutional Review Board Statement: Not applicable. Informed Consent Statement: Not applicable. Data Availability Statement: Not applicable. ConÔ¨Çicts of Interest: The authors declare no conÔ¨Çict of interest. References 1. Brand, K.; Mitra, S.; Volkerink, E.; McCluskey, E.J. Speed clustering of integrated circuits. In Proceedings of the 2004 International Conferce on Test, Charlotte, NC, USA, 26‚Äì28 October 2004; pp. 1128‚Äì1137. 2. Chang, K.W.; Huang, C.Y.; Mu, S.P .; Huang, J.M.; Chen, S.H.; Chao, M.C.T. DVFS Binning Using Machine-Learning Techniques. In Proceedings of the 2018 IEEE In"}
{"id": "sensors-22-01382.pdf::chunk_47", "source": "sensors-22-01382.pdf", "chunk_index": 47, "text": "USA, 26‚Äì28 October 2004; pp. 1128‚Äì1137. 2. Chang, K.W.; Huang, C.Y.; Mu, S.P .; Huang, J.M.; Chen, S.H.; Chao, M.C.T. DVFS Binning Using Machine-Learning Techniques. In Proceedings of the 2018 IEEE International Test Conference in Asia (ITC-Asia), Harbin, China, 15‚Äì17 August 2018; pp. 31‚Äì36. [CrossRef] 3. Butler, K.M.; Cheng, K.T.; Wang, L.C. Guest editors‚Äô introduction: Speed test and speed binning for complex ICs. IEEE Des. Test Comput. 2003 ,20, 6‚Äì7. [CrossRef] 4. Sartori, J.; Pant, A.; Kumar, R.; Gupta, P . Variation-aware speed binning of multi-core processors. In Proceedings of the 2010 11th International Symposium on Quality Electronic Design (ISQED), San Jose, CA, USA, 22‚Äì24 March 2010; pp. 307‚Äì314. [CrossRef] 5. Datta, A.; Bhunia, S.; Choi, J.H.; Mukhopadhyay, S.; Roy, K. Speed binning aware design methodology to improve proÔ¨Åt under parameter variations. In Proceedings of the 2006 Asia and South PaciÔ¨Åc Design Automation Conference, Yokohama, Japan, 24‚Äì27 January 2006; p. 6. 6. Pei, S.; Li, Z.; Li, H.; Li, X.; Wei, S. A uniÔ¨Åed architecture for speed-binning and circuit failure prediction and detection. In Proceedings of the 2012 IEEE International Conference on Computer Sci"}
{"id": "sensors-22-01382.pdf::chunk_48", "source": "sensors-22-01382.pdf", "chunk_index": 48, "text": " Pei, S.; Li, Z.; Li, H.; Li, X.; Wei, S. A uniÔ¨Åed architecture for speed-binning and circuit failure prediction and detection. In Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE), Zhangjiajie, China, 25‚Äì27 May 2012; Volume 2, pp. 418‚Äì421. [CrossRef] 7. Gong, M.; Zhou, H.; Li, L.; Tao, J.; Zeng, X. Binning Optimization for Transparently-Latched Circuits. IEEE Trans.-Comput.-Aided Des. Integr. Circuits Syst. 2011 ,30, 270‚Äì283. [CrossRef] 8. Wen, C.H.; Wang, L.; Cheng, K.T.; Liu, W.T.; Chen, J.J. Simulation-based target test generation techniques for improving the robustness of a software-based-self-test methodology. In Proceedings of the International Test Conference, Austin, TX, USA, 8 November 2005; p. 10. 9. Parvathala, P .; Maneparambil, K.; Lindsay, W. FRITS‚ÄîA Microprocessor Functional BIST Method. In Proceedings of the International Test Conference, Baltimore, MD, USA, 10 October 2002; pp. 590‚Äì598. 10. Hsu, H.J.; Tu, C.C.; Huang, S.Y. Built-In Speed Grading with a Process-Tolerant ADPLL. In Proceedings of the 16th Asian Test Symposium (ATS 2007), Beijing, China, 8‚Äì11 October 2007; pp. 384‚Äì392. [CrossRef] Sensors 2022 ,"}
{"id": "sensors-22-01382.pdf::chunk_49", "source": "sensors-22-01382.pdf", "chunk_index": 49, "text": " Huang, S.Y. Built-In Speed Grading with a Process-Tolerant ADPLL. In Proceedings of the 16th Asian Test Symposium (ATS 2007), Beijing, China, 8‚Äì11 October 2007; pp. 384‚Äì392. [CrossRef] Sensors 2022 ,22, 1382 17 of 18 11. Huang, S.Y.; Huang, T.H.; Tsai, K.H.; Cheng, W.T. A wide-range clock signal generation scheme for speed grading of a logic core. In Proceedings of the 2016 International Conference on High Performance Computing & Simulation (HPCS), Innsbruck, Austria, 18‚Äì22 July 2016; pp. 125‚Äì129. 12. Iyengar, V .; Johnson, M.; Anemikos, T.; Bassett, B.; Degregorio, M.; Farmer, R.; Grise, G.; Stevens, P .; Taylor, M.; Woytowich, F. Performance veriÔ¨Åcation of high-performance ASICs using at-speed structural test. In Proceedings of the 16th ACM Great Lakes Symposium on VLSI, Philadelphia, PA, USA, 30 April‚Äì1 May 2006; pp. 247‚Äì252. 13. Iyengar, V .; Johnson, M.; Anemikos, T.; Grise, G.; Taylor, M.; Farmer, R.; Woytowich, F.; Bassett, B. Design For At-Speed Structural Test and Performance VeriÔ¨Åcation of High-Performance ASICs. In Proceedings of the IEEE Custom Integrated Circuits Conference 2006, San Jose, CA, USA, 10‚Äì13 September 2006; pp. 567‚Äì570. [CrossRef] 14. Borda, P .; Prajapat"}
{"id": "sensors-22-01382.pdf::chunk_50", "source": "sensors-22-01382.pdf", "chunk_index": 50, "text": " VeriÔ¨Åcation of High-Performance ASICs. In Proceedings of the IEEE Custom Integrated Circuits Conference 2006, San Jose, CA, USA, 10‚Äì13 September 2006; pp. 567‚Äì570. [CrossRef] 14. Borda, P .; Prajapati, P . LOC, LOS and LOES At-speed Testing Methodology for Automatic Test Pattern Generation Using Transition Delay Fsult Model. IJRET Int. J. Res. Eng. Technol. 2014 ,3, 273‚Äì277. 15. Lee, D.; Mccluskey, E.J. Comparisons of Various Scan Delay Test Techniques. In SRC Report, Dec. ; Semiconductor Research Corporation: Durham, NC, USA, 2005. 16. Han, Q.; Guo, J.; Xu, Q.; Jone, W.B. On resilient system performance binning. In Proceedings of the 2015 Symposium on International Symposium on Physical Design, Monterey, CA, USA, 29 March‚Äì1 April 2015; pp. 119‚Äì125. 17. Zeng, J.; Abadir, M.; Vandling, G.; Wang, L.; Kolhatkar, S.; Abraham, J. On Correlating Structural Tests with Functional Tests for Speed Binning of High Performance Design. In Proceedings of the Fifth International Workshop on Microprocessor Test and VeriÔ¨Åcation (MTV‚Äô04), Austin, TX, USA, 9‚Äì10 September 2004; pp. 103‚Äì109. [CrossRef] 18. Cory, B.D.; Kapur, R.; Underwood, B. Speed binning with path delay test in 150-nm technology. IE"}
{"id": "sensors-22-01382.pdf::chunk_51", "source": "sensors-22-01382.pdf", "chunk_index": 51, "text": "cessor Test and VeriÔ¨Åcation (MTV‚Äô04), Austin, TX, USA, 9‚Äì10 September 2004; pp. 103‚Äì109. [CrossRef] 18. Cory, B.D.; Kapur, R.; Underwood, B. Speed binning with path delay test in 150-nm technology. IEEE Des. Test Comput. 2003 , 20, 41‚Äì45. [CrossRef] 19. Lin, X.; Press, R.; Rajski, J.; Reuter, P .; Rinderknecht, T.; Swanson, B.; Tamarapalli, N. High-frequency, at-speed scan testing. IEEE Des. Test Comput. 2003 ,20, 17‚Äì25. 20. Lin, L.; Wen, C.H.P . Speed binning with high-quality structural patterns from functional timing analysis (FTA). In Proceedings of the 2016 21st Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC), Macao, China, 25‚Äì28 January 2016; pp. 238‚Äì243. 21. Chakravarty, S. A process monitor based speed binning and die matching algorithm. In Proceedings of the 2011 Asian Test Symposium, New Delhi, India, 20‚Äì23 November 2011; pp. 311‚Äì316. 22. Shi, Q.; Wang, X.; Winemberg, L.; Tehranipoor, M.M. On-chip sensor selection for effective speed-binning. Analog. Integr. Circuits Signal Process. 2016 ,88, 369‚Äì382. [CrossRef] 23. Pei, S.; Li, H.; Li, X. A High-Precision On-Chip Path Delay Measurement Architecture. IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 2012 ,20,"}
{"id": "sensors-22-01382.pdf::chunk_52", "source": "sensors-22-01382.pdf", "chunk_index": 52, "text": "uits Signal Process. 2016 ,88, 369‚Äì382. [CrossRef] 23. Pei, S.; Li, H.; Li, X. A High-Precision On-Chip Path Delay Measurement Architecture. IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 2012 ,20, 1565‚Äì1577. [CrossRef] 24. Mu, S.P .; Chang, W.H.; Chao, M.C.T.; Wang, Y.M.; Chang, M.T.; Tsai, M.H. Statistical methodology to identify optimal placement of on-chip process monitors for predicting fmax. In Proceedings of the 35th International Conference on Computer-Aided Design, Austin, TX, USA, 7‚Äì10 November 2016; pp. 1‚Äì8. 25. Raychowdhury, A.; Ghosh, S.; Roy, K. A novel on-chip delay measurement hardware for efÔ¨Åcient speed-binning. In Proceedings of the 11th IEEE International On-Line Testing Symposium, French Riviera, France, 6‚Äì8 July 2005; pp. 287‚Äì292. 26. Wang, X.; Tehranipoor, M.; Datta, R. A novel architecture for on-chip path delay measurement. In Proceedings of the 2009 International Test Conference, Austin, TX, USA, 1‚Äì6 November 2009; pp. 1‚Äì10. 27. Sadi, M.; Tehranipoor, M.M.; Wang, X.; Winemberg, L. Speed Binning Using Machine Learning and On-chip Slack Sensors. In Proceedings of the 25th Edition on Great Lakes Symposium on VLSI, Pittsburgh, PA, USA, 20‚Äì22 May 2015; pp. 15"}
{"id": "sensors-22-01382.pdf::chunk_53", "source": "sensors-22-01382.pdf", "chunk_index": 53, "text": "Wang, X.; Winemberg, L. Speed Binning Using Machine Learning and On-chip Slack Sensors. In Proceedings of the 25th Edition on Great Lakes Symposium on VLSI, Pittsburgh, PA, USA, 20‚Äì22 May 2015; pp. 155‚Äì160. 28. Sadi, M.; Kannan, S.; Winemberg, L.; Tehranipoor, M. SoC speed binning using machine learning and on-chip slack sensors. IEEE Trans.-Comput.-Aided Des. Integr. Circuits Syst. 2016 ,36, 842‚Äì854. [CrossRef] 29. Zhang, D.; Wang, X. An on-chip binning sensor for low-cost and accurate speed binning. In Proceedings of the 2017 2nd IEEE International Conference on Integrated Circuits and Microsystems (ICICM), Nanjing, China, 8‚Äì11 November 2017; pp. 151‚Äì155. [CrossRef] 30. Paul, S.; Krishnamurthy, S.; Mahmoodi, H.; Bhunia, S. Low-overhead design technique for calibration of maximum frequency at multiple operating points. In Proceedings of the 2007 IEEE/ACM International Conference on Computer-Aided Design, San Jose, CA, USA, 5‚Äì8 November 2007; pp. 401‚Äì404. 31. Su, M.Y.; Lin, W.C.; Kuo, Y.T.; Li, C.M.; Fang, E.J.W.; Hsueh, S.S.Y. Chip Performance Prediction Using Machine Learning Techniques. In Proceedings of the 2021 International Symposium on VLSI Design, Automation and Test (VLSI-"}
{"id": "sensors-22-01382.pdf::chunk_54", "source": "sensors-22-01382.pdf", "chunk_index": 54, "text": "Y.T.; Li, C.M.; Fang, E.J.W.; Hsueh, S.S.Y. Chip Performance Prediction Using Machine Learning Techniques. In Proceedings of the 2021 International Symposium on VLSI Design, Automation and Test (VLSI-DAT), Taiwan, China, 19‚Äì22 April 2021; pp. 1‚Äì4. [CrossRef] 32. Cantoro, R.; Huch, M.; Kilian, T.; Martone, R.; Schlichtmann, U.; Squillero, G. Machine Learning based Performance Prediction of Microcontrollers using Speed Monitors. In Proceedings of the 2020 IEEE International Test Conference (ITC), Washington, DC, USA, 1‚Äì6 November 2020; pp. 1‚Äì5. 33. Bellarmino, N.; Cantoro, R.; Huch, M.; Kilian, T.; Martone, R.; Schlichtmann, U.; Squillero, G. Exploiting Active Learning for Microcontroller Performance Prediction. In Proceedings of the 2021 IEEE European Test Symposium (ETS), Bruges, Belgium, 24‚Äì28 May 2021; pp. 1‚Äì4. 34. Mu, S.P .; Chao, M.C.; Chen, S.H.; Wang, Y.M. Statistical Framework and Built-In Self- Speed-Binning System for Speed Binning Using On-Chip Ring Oscillators. IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 2015 ,24, 1675‚Äì1687. [CrossRef] Sensors 2022 ,22, 1382 18 of 18 35. Heo, J.; Jeong, K.; Kim, T.; Choi, K. Synthesis of Hardware Performance Monitoring and Predicti"}
{"id": "sensors-22-01382.pdf::chunk_55", "source": "sensors-22-01382.pdf", "chunk_index": 55, "text": "ery Large Scale Integr. (VLSI) Syst. 2015 ,24, 1675‚Äì1687. [CrossRef] Sensors 2022 ,22, 1382 18 of 18 35. Heo, J.; Jeong, K.; Kim, T.; Choi, K. Synthesis of Hardware Performance Monitoring and Prediction Flow Adapting to Near- Threshold Computing and Advanced Process Nodes. In Proceedings of the 2020 25th Asia and South PaciÔ¨Åc Design Automation Conference (ASP-DAC), Beijing, China, 13‚Äì16 January 2020; pp. 139‚Äì144. 36. Datta, A.; Bhunia, S.; Choi, J.H.; Mukhopadhyay, S.; Roy, K. ProÔ¨Åt aware circuit design under process variations considering speed binning. IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 2008 ,16, 806‚Äì815. [CrossRef] 37. Das, A.; Ozdemir, S.; Memik, G.; Zambreno, J.; Choudhary, A. Microarchitectures for Managing Chip Revenues under Process Variations. IEEE Comput. Archit. Lett. 2008 ,7, 5‚Äì8. [CrossRef] 38. Maragos, K.; Lentaris, G.; Soudris, D. In-the-Ô¨Åeld mitigation of process variability for improved FPGA performance. IEEE Trans. Comput. 2019 ,68, 1049‚Äì1063. [CrossRef] 39. 2016. Available online: http://www.synopsys.com/Community/UniversityProgram/Pages/generic-libraries.aspx (accessed on 1 October 2016). 40. 2016. Available online: https://www.altera.com/buy/devi"}
{"id": "sensors-22-01382.pdf::chunk_56", "source": "sensors-22-01382.pdf", "chunk_index": 56, "text": "] 39. 2016. Available online: http://www.synopsys.com/Community/UniversityProgram/Pages/generic-libraries.aspx (accessed on 1 October 2016). 40. 2016. Available online: https://www.altera.com/buy/devices.html (accessed on 1 October 2016)."}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_0", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 0, "text": "Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 https://doi.org/10.1007/s10845-023-02242-w Shape prior guided defect pattern classiÔ¨Åcation and segmentation in wafer bin maps Rui Wang1¬∑Songhao Wang2¬∑Ben Niu3 Received: 16 March 2023 / Accepted: 9 October 2023 / Published online: 7 November 2023 ¬© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023 Abstract In semiconductor manufacturing, patterns formed by defective dies in a wafer bin map (WBM) reveal possible problemsduring the wafer fabrication process. Therefore, the identiÔ¨Åcation of these patterns is important for root cause diagnosis and yield enhancement. Recently, as the manufacturing process becomes increasingly complicated, mixed-type defect patterns have been frequently observed on the WBMs. The joint classiÔ¨Åcation and segmentation of each pattern contained in themixed-type pattern is challenging, especially when these patterns are connected or overlapped. This study proposes a shapeprior guided method in which the shape templates are deformed to match the patterns with a spatial transformer network. The deformation based method is able to give plausible resul"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_1", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 1, "text": "udy proposes a shapeprior guided method in which the shape templates are deformed to match the patterns with a spatial transformer network. The deformation based method is able to give plausible results while reducing computation cost of the network. Furthermore, the method is Ô¨Çexible and easily extended to deal with complex shapes by deÔ¨Åning different shape templates. The experimentalresults demonstrate the effectiveness of the proposed method in the identiÔ¨Åcation of the pattern types, as well as the separation of each isolated pattern. Keywords Semiconductor manufacturing ¬∑Wafer bin map ¬∑Shape prior ¬∑Defect pattern recognition Introduction Semiconductor manufacturing is a complex process which consists of hundreds of steps. Large amount of data are automatically generated, providing valuable information forprocess monitoring and yield enhancement. Among the col-lected data, wafer bin maps (WBMs) are widely examined, which encodes the spatial distribution of defective dies on the wafer (Kim & Behdinan, 2023 ). SpeciÔ¨Åcally, the defec- tive dies are represented with value 1 and the normal dies B Ben Niu drniuben@gmail.com Rui Wang r.wang@hit.edu.cn Songhao Wang wangsh2021@sustech.ed"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_2", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 2, "text": "r (Kim & Behdinan, 2023 ). SpeciÔ¨Åcally, the defec- tive dies are represented with value 1 and the normal dies B Ben Niu drniuben@gmail.com Rui Wang r.wang@hit.edu.cn Songhao Wang wangsh2021@sustech.edu.cn 1School of Mechanical Engineering and Automation, HarbinInstitute of Technology, Shenzhen, China 2School of Business, Southern University of Science and Technology, Shenzhen, China 3College of Management, Shenzhen University, Shenzhen, Chinawith value 0. WBMs may contain typical patterns formed by defective dies that are caused by speciÔ¨Åc manufacturing pro-cesses, and thus the detection and recognition of such patterns is of great signiÔ¨Åcance for the early detection of abnormal- ities and the analysis of root causes (Abd Al Rahman etal.,2021 ; Chien et al., 2013 ). Figure 1shows four typical examples of defect patterns. WBMs contain both systematic defects that form clusters, as well as random defects that are isolated and seen as noise to the patterns. These patterns cantrace back to assignable causes during the manufacturing pro- cess. For example, scratches are caused by machine handling problems, while ring patterns are generated by layer-to-layermisalignment in storage node a"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_3", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 3, "text": " assignable causes during the manufacturing pro- cess. For example, scratches are caused by machine handling problems, while ring patterns are generated by layer-to-layermisalignment in storage node and etching problems (Kim et al.,2018 ). Conventionally, the identiÔ¨Åcation of defect patterns in WBMs relies on manual inspection with the human eye,which is time-consuming and highly subjective (Hsu et al., 2020 ). In Recent years, deep learning methods are widely applied to solve practical problems in both academia andindustry. For example, Adly et al. ( 2015 ) proposed a simpli- Ô¨Åed subspaced regression framework for the identiÔ¨Åcation of defect patterns in WBMs. In Jin et al. ( 2020 ), features extracted from a convolutional neural network (CNN) were 123 320 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Fig. 1 Examples of WBMs with single patterns used to train an error-correcting output codes (ECOC) model for WBM pattern classiÔ¨Åcation. Y u and Liu ( 2020 ) built a two-dimensional principal component analysis-based con- volutional autoencoder for the recognition of defect patternsin WBMs. The framework of ensemble convolutional neural network (ECNN) (Hsu & Chien, 2022 ;P i a"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_4", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 4, "text": "al principal component analysis-based con- volutional autoencoder for the recognition of defect patternsin WBMs. The framework of ensemble convolutional neural network (ECNN) (Hsu & Chien, 2022 ;P i a o&J i n , 2023 )w a s also applied for WBM pattern classiÔ¨Åcation, and a weightedmajority was used to choose weights for the base CNN mod- els. Most of the existing studies focus on the identiÔ¨Åcation of single defect patterns. Nowadays, mixed-type defect pat-terns, where multiple types of defects exist in a piece of wafer, become more common due to the evolution of the manufac- turing technology. Multiple manufacturing problems can beidentiÔ¨Åed from mixed-type patterns, with each defect pattern assigned to its corresponding root cause (Y uan & Kuo, 2008 ). The appearance of the mixed-type patterns may vary in differ-ent sizes and locations with interactions in the WBMs. For the classiÔ¨Åcation of mixed-type defect patterns in WBMs, deep learning models have been widely used due to theirgreat power in image recognition. Kyeong and Kim ( 2018 ) classiÔ¨Åed mixed-type defect patterns in WBMs with combi- nations of individual CNN-based classiÔ¨Åcation models for each pattern. Wang et al. ( 2020 )"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_5", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 5, "text": "power in image recognition. Kyeong and Kim ( 2018 ) classiÔ¨Åed mixed-type defect patterns in WBMs with combi- nations of individual CNN-based classiÔ¨Åcation models for each pattern. Wang et al. ( 2020 ) introduced a deformable convolutional network to extract high-quality features for the mixed-type pattern recognition problem. Shin et al. ( 2022 ) proposed a Mixup-based strategy for training CNNs to detectmixed-type defects in WBMs using samples with only single- type patterns. These models successfully recognize multiple patterns in the WBMs, but they are not able to Ô¨Ånd the loca-tion of each speciÔ¨Åc pattern, which provides information forsubsequent analysis of scanning electron microscopy (SEM) and energy-dispersive x-ray (EDX) to determine the source of defect generation (O‚ÄôLeary et al., 2020 ). The joint identiÔ¨Åcation of the class and the location of mixed-type patterns is complicated, as the combination of patterns may vary in number, types and positions, etc. Thecomplexity of mixed-type patterns may confuse the classi- Ô¨Åers, while increasing the difÔ¨Åculty of pattern separation. To solve this problem, Kim et al. ( 2018 ) adopted a cluster- ing based method called the inÔ¨Ånite wa"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_6", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 6, "text": "d-type patterns may confuse the classi- Ô¨Åers, while increasing the difÔ¨Åculty of pattern separation. To solve this problem, Kim et al. ( 2018 ) adopted a cluster- ing based method called the inÔ¨Ånite warped mixture model(iWMM) to Ô¨Ånd different pattern clusters without the iden- tiÔ¨Åcation of number of groups. Wang and Chen ( 2022 )developed a tensor voting based approach to extract regions and curves from the WBM patterns, which were then recog- nized by a decision tree with the shape information. However, the clustering methods cannot give semantically interpretablecategories that are meaningful in real applications. Recently, Yan et al. ( 2023 ) proposed to use semantic segmenta- tion based approach to segment the WBM into differentpattern classes. Nag et al. ( 2022 ) presented WaferSegClass- Net (WSCN), a novel network based on encoder-decoder architecture, to perform simultaneous classiÔ¨Åcation and seg-mentation of both single and mixed-type defect patterns. Kim et al. ( 2022 ) applied the single shot detector (SSD), which is an object detection method, for the detection and localization of mixed-type patterns. Chiu and Chen ( 2021 ) utilized the instance segmentation model Mask R-"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_7", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 7, "text": " the single shot detector (SSD), which is an object detection method, for the detection and localization of mixed-type patterns. Chiu and Chen ( 2021 ) utilized the instance segmentation model Mask R-CNN with data augmentation for the segmentation and classiÔ¨Åcation of defect patterns. Existing solutions are capable of simulta-neously obtaining the class and the position information of the mixed-type patterns, when the patterns are connected. For the unwarpping of overlapped patterns, Kong and Ni(2019 ) Ô¨Årst used a CNN to classify WBMs with single or mixed-type patterns, and then located and classiÔ¨Åed the over- lapping patterns through template matching method. They (Kong & Ni, 2020 ) also developed a U-net based bound- ary detection and overlapped pattern unwarpping method for complex pattern segmentation, followed by a CNN to clas- sify the patterns. For current studies on the recognition ofmixed-type defect patterns, unsupervised clustering based methods require sophisticated algorithms to form clusters, while the clusters may not be assignable to typical WBM pat-terns. Segmentation based methods rely on deep models thatare computationally expensive, yet they fail to take the pat"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_8", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 8, "text": "hms to form clusters, while the clusters may not be assignable to typical WBM pat-terns. Segmentation based methods rely on deep models thatare computationally expensive, yet they fail to take the pat- tern overlap into account. Unlike a single end-to-end model, unwarpping methods represent a process of several steps,which appears more complicated and may need a greater amount of processing. Furthermore, although existing meth- ods can provide plausible result, there is no guarantee thatthe extracted patterns satisfy the desired shape constraints. Therefore, the segmentation and classiÔ¨Åcation of mixed-type pattern in WBMs is still challenging, especially when thesepatterns are overlapped or connected. In this study, we propose a practical approach for the segmentation and classiÔ¨Åcation of mixed-type patterns in 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 321 WBMs. Different from the conventional deep learning based segmentation models (Shelhamer et al., 2017 ; Ronneberger et al.,2015 ), which detect the objects by optimizing pixel-wise loss functions, our model adopts the shape priors during train- ing. Since the defect patterns in WBMs are usually commontypes, their"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_9", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 9, "text": "r et al.,2015 ), which detect the objects by optimizing pixel-wise loss functions, our model adopts the shape priors during train- ing. Since the defect patterns in WBMs are usually commontypes, their shape priors could be pre-determined. In the liter-ature, the incorporation of shape priors into network training have shown improved performance for image segmentation (Lee et al., 2019 ; Zotti et al., 2018 ). In our model, the seg- mentation is performed with deformations of the given shape prior, which gives plausible results that adhere to speciÔ¨Åc shape constraints, while reducing the computation cost ofneural networks. Spatial transformer network (STN) (Jader- berg et al., 2015 ), which was originally proposed to improve model invariance to image translation, scale and rotation, isused to perform afÔ¨Åne transformations to align the shape pri-ors to the patterns of interest. The STN could be applied for segmentation task with satisfactory performance, under the hypothesis that it requires much less precise features thana segmentation network (Pak et al., 2020 ). The use of STN allows the separation of overlapped and connected patterns by matching with pre-deÔ¨Åned pattern templates s"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_10", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 10, "text": "res much less precise features thana segmentation network (Pak et al., 2020 ). The use of STN allows the separation of overlapped and connected patterns by matching with pre-deÔ¨Åned pattern templates separately.To be speciÔ¨Åc, each pre-deÔ¨Åned shape template is deformed separately to match the pattern in the WBM to be examined. Consequently, each pattern type is extracted independentlyby the deformations of the corresponding shape template,making it possible for a pixel to be allocated to more than one pattern class, which eliminates the inÔ¨Çuence of the interac- tions between different patterns. Our proposed method is ableto locate and classify mixed-type patterns simultaneously, and can be easily extended with additional shape templates as input to the model. The remainder of this article is structured as follows. ‚ÄúMethodology ‚Äù section gives a detailed introduction to the proposed defect pattern classiÔ¨Åcation and segmentationmethod. In ‚Äú Experiments ‚Äù section, the experimental results are presented to demonstrate the effectiveness of the pro- posed model. Finally, ‚Äú Conclusion ‚Äù section concludes this paper. Methodology In this section, we propose a novel classiÔ¨Åcation and seg-menta"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_11", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 11, "text": "re presented to demonstrate the effectiveness of the pro- posed model. Finally, ‚Äú Conclusion ‚Äù section concludes this paper. Methodology In this section, we propose a novel classiÔ¨Åcation and seg-mentation model for mixed-type defect patterns in WBMs.The approach is inspired by the idea of network based regis- tration, and it takes shape priors as the additional input to the network. The segmentation is then performed by learning theoptimal deformations of the shape templates for the accurate alignment with the given image. An overview of the method is depicted in Fig. 2. The detailed description of the proposed method is presented in the following subsections.Shape templates The utilization of shape priors in segmentation networks can be in various forms, such as level sets (Cremers et al., 2006 ), statistical models (Milletari et al., 2017 ) and conditional ran- dom Ô¨Åelds (Zheng et al., 2015 ). In this paper, we deÔ¨Åne multiple templates manually as shape priors, and they are added to the network as auxiliary inputs that are deformed to match the patterns of interest. In this way, the model esti-mates the transformation of the templates regarding each class instead of a point-wise "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_12", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 12, "text": "the network as auxiliary inputs that are deformed to match the patterns of interest. In this way, the model esti-mates the transformation of the templates regarding each class instead of a point-wise segmentation map, which pro- vides a solution to the extraction of complex and overlappedpatterns. The segmentation and classiÔ¨Åcation results heav- ily rely on the deformation of the shape templates, which should be carefully chosen in order to match most of thesamples. Generally, these shape priors can be obtained withmanual selection of either real or simulated patterns. The templates should be typical, clear, and preferably without noise, to improve the accuracy of deformation. Network architecture We present a model that takes images and templates as input,and outputs images warped to the templates. Our modelenables the incorporation of any shape prior to segment and classify the mixed-type patterns, overcoming the difÔ¨Åculty when the patterns are connected or overlapped. In addition,the template deformation based pattern extraction reducesthe chance of discretization of the extracted patterns. Image features In this study, as the classiÔ¨Åcation and segmentation are per- formed at th"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_13", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 13, "text": "e template deformation based pattern extraction reducesthe chance of discretization of the extracted patterns. Image features In this study, as the classiÔ¨Åcation and segmentation are per- formed at the same time, a shared network is applied for image feature extraction to reduce the computation cost. The target images and shape templates are jointly sent to thenetwork as input, which extracts valuable information from the images under the guidance of the shape priors. Features should be carefully extracted to be representative in the tasksof both segmentation and classiÔ¨Åcation. We choose to use afeed-forward network architecture to perform feature extrac- tion in this stage. The residual network (ResNet) (He et al., 2016 ) has been widely applied in the Ô¨Åeld of image seg- mentation and object detection, outperforming other deep learning models in various tasks. It is possible to train much deeper networks without increasing the amount of parame-ters through skip connections between the layers (He et al., 2020 ). Therefore, the ResNet is applied for feature extrac- tion in our model. The extracted features are then Ô¨Çattenedfor further processing. 123 322 Journal of Intelligent Manuf"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_14", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 14, "text": " layers (He et al., 2020 ). Therefore, the ResNet is applied for feature extrac- tion in our model. The extracted features are then Ô¨Çattenedfor further processing. 123 322 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Fig. 2 Overview of the proposed model Pattern classiÔ¨Åcation The number of types grows in an exponential way for the mixed-type defect patterns. Theoretically, 2Ldefect patterns are identiÔ¨Åed considering the mixture of Ltype of single defect patterns. To simplify the representation of the defecttypes, one-hot encoding is applied to describe the mixed- type defect patterns with several single patterns (Wang et al.,2020 ). For a mixed-type defect pattern, the pattern type is deÔ¨Åned as a row vector y i=[y1 i,y2 i,..., yL i], where yj i‚àà{0,1}indicates the occurrence of the single defect pat- tern. For example, when L=4,yi=[0,1,0,1]indicates a mixture of defect pattern type two and four in a single WBM. For multi-label classiÔ¨Åcation, two fully-connectedlayers together with the Sigmoid activation function aredeÔ¨Åned to identify the inclusion of the pattern types. The output of the network is a vector of length L, with each ele- ment c j iranging from 0 to 1. The clas"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_15", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 15, "text": "with the Sigmoid activation function aredeÔ¨Åned to identify the inclusion of the pattern types. The output of the network is a vector of length L, with each ele- ment c j iranging from 0 to 1. The classiÔ¨Åcation is conducted by applying a threshold, if the value cj i‚â•0.5, then the WBM is predicted to contain the jth defect pattern type. Template deformation The model utilizes the idea of STN that deforms the shape prior template Tto match the input image Iby learning the transformation parameters Œ∏.TŒ∏(G), where Gis a reg- ular grid G={Gp}of pixels Gp=(xt p,yt p), is deÔ¨Åned as the function that maps the target coordinates (xt p,yt p)to the source coordinates (xs p,ys p). Each output pixel is computed by a sampling kernel applied to the template grid, and for 2DafÔ¨Åne transformation, the function is/parenleftbiggx s p ysp/parenrightbigg =TŒ∏(Gp)=/bracketleftbiggŒ∏11Œ∏12Œ∏13 Œ∏21Œ∏22Œ∏23/bracketrightbigg‚éõ ‚éùxt p yt p 1‚éû ‚é†. (1) This transformation deÔ¨Ånes six parameters that allows crop- ping, translation, rotation and scale of the templates. For WBMs, the template T, input image Iand the output feature map Vare all of size H√óW. The output feature map Vis then deÔ¨Åned by the sampling points TŒ∏(G)an"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_16", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 16, "text": "tion, rotation and scale of the templates. For WBMs, the template T, input image Iand the output feature map Vare all of size H√óW. The output feature map Vis then deÔ¨Åned by the sampling points TŒ∏(G)and the template T.V(p)is the output value of pixel pat location (xt p,yt p), determined by a sampling kernel k()applied to the input coordinates: V(p)=H/summationdisplay nW/summationdisplay lT(n,l)k(xs p‚àíl;/Phi1x)k(ys p‚àín;/Phi1y) ‚àÄp‚àà[1,..., HW], (2) where /Phi1xand/Phi1yare the parameters of the sampling kernel k(), and T(n,l)is the value at location (n,l). For the kernel k(), bilinear image interpolation is applied, that is V(p)=H/summationdisplay nW/summationdisplay lT(n,l)max(0,1‚àí|xs p‚àíl|)max(0,1‚àí|ys p‚àín|). (3) The deformation parameters Œ∏is learned by a neural net- work conditioned on the image Iand the template T.F o r simplicity, a multi-layer perceptron (MLP) with two fully- connected layers is applied for the estimation of deformationparameters. 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 323 Pattern segmentation The extracted pattern of each defect mode should have its original shape instead of making up new defective points. Therefore, the deformed shape priors "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_17", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 17, "text": "ing (2025) 36:319‚Äì330 323 Pattern segmentation The extracted pattern of each defect mode should have its original shape instead of making up new defective points. Therefore, the deformed shape priors are then multipliedwith the original input image Iby element-wise production, to capture the shape characteristics of the typical defect pat- tern. After the multiplication, the deformed shape priors may still match with the isolated defective points, which shouldbe avoided in the process of pattern extraction. To improve the accuracy of segmentation, the classiÔ¨Åcation results are combined to get the Ô¨Ånal prediction. That is, if the patternexists in the WBM, the segmentation mask is retained as it is in the prediction result. Otherwise, the mask of 0 values is returned, if the pattern is not detected in the WBM. Fora given WBM i, the proposed model is capable of jointly classifying the defect patterns y i‚àà{0,1}Land identifying the corresponding masks Mi‚àà{0,1}L√óH√óW, where Lis the number of defect pattern types on the WBM. The segmenta-tion mask of each pattern class is given as: Mj i=yj i¬∑Ii‚ó¶Vj i, (4) where ‚ó¶denotes the Hadamard product of two matrices. Model evaluation For multi-label "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_18", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 18, "text": "defect pattern types on the WBM. The segmenta-tion mask of each pattern class is given as: Mj i=yj i¬∑Ii‚ó¶Vj i, (4) where ‚ó¶denotes the Hadamard product of two matrices. Model evaluation For multi-label classiÔ¨Åcation, Hamming loss, mixed-type accuracy and exact match accuracy are commonly used to measure the performance (Chiu & Chen, 2021 ; Tsoumakas & Katakis, 2007 ). Hamming loss (HL) computes the propor- tion of labels that are incorrectly predicted, and smaller value gives better performance. Mixed-type accuracy (MTA) cal-culates the ratio of the size of the interaction set to the union set, measured between the actual and predicted classes. Exact match accuracy (EMA) is the percentage of WBMs that thepredicted classes exactly match the actual pattern. Highervalues of the two accuracy metrics indicate the superiority of the model. Let y iandÀÜyibe the actual and predicted defect pattern class, respectively. The metrics are deÔ¨Åned as: HL=1 NLN/summationdisplay i=1L/summationdisplay j=1I(ÀÜyj i/negationslash=yj i), (5) MT A =1 NN/summationdisplay i=1|ÀÜyi‚à©yi| |ÀÜyi‚à™yi|, (6) EMA =1 NN/summationdisplay i=1I(ÀÜyi=yi), (7) where Nis the number of WBMs. To quantify the segmentation quality, t"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_19", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 19, "text": "(ÀÜyj i/negationslash=yj i), (5) MT A =1 NN/summationdisplay i=1|ÀÜyi‚à©yi| |ÀÜyi‚à™yi|, (6) EMA =1 NN/summationdisplay i=1I(ÀÜyi=yi), (7) where Nis the number of WBMs. To quantify the segmentation quality, the intersection over union (IoU) (√ái√ßek et al., 2016 ) that rewards a complete andtotal match between predicted and ground-truth area is intro- duced. The IoU is deÔ¨Åned as the area of the overlapped patterndivided by the area of the union pattern. Io Uj i=Area(ÀÜMj i‚à©Mj i) Area(ÀÜMj i‚à™Mj i), (8) For each mixed-type pattern, the mean IoU (mIoU) is used to evaluate the model segmentation performance. mIo U i=1 LL/summationdisplay j=1Io Uj i, (9) where Mj iandÀÜMj idenote the actual and predicted mask of thejth pattern in the ith WBM. If pattern jis not detected in the WBM i, the IoU is not calculated. Experiments Data description The technique described in Kyeong and Kim ( 2018 )w a s used to generate mixed-type WBMs to evaluate the proposed method. The shape of the generated patterns was based on both real data and domain knowledge, with noise added tothe simulated patterns. The mixture of four single-type pat- terns were considered, i.e. Scratch, Zone, Ring and Center, as illustrated in F"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_20", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 20, "text": " on both real data and domain knowledge, with noise added tothe simulated patterns. The mixture of four single-type pat- terns were considered, i.e. Scratch, Zone, Ring and Center, as illustrated in Fig. 1. The size of each WBM was 56 √ó53, i.e., each WBM contained a total of 2968 dies. The percentageof defective dies ranged from 3% to 27%. Sixteen classes of mixed-type patterns were generated with combination of the four identiÔ¨Åed patterns. A total of 8000 samples weregenerated, 500 for each pattern. The data was separated into training, validation and testing datasets in a ratio of 8:1:1. Model training The shape priors used in our model are shown in Fig. 2.T h e shape templates were chosen from generated patterns man- ually after noise removal, which should be representative ofthe pattern types with clear and perfect shapes on the WBM.Zero padding were performed for the WBMs to be a perfect square with size 56 √ó56 for easier computation. For shared network that aims to extract valuable informa- tion from the images, ResNet was adopted for the network architecture. Commonly used number of layers in ResNet are 18, 34, 50 and 101. They gave similar results for the WBMclassiÔ¨Åcation a"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_21", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 21, "text": "le informa- tion from the images, ResNet was adopted for the network architecture. Commonly used number of layers in ResNet are 18, 34, 50 and 101. They gave similar results for the WBMclassiÔ¨Åcation and segmentation task identiÔ¨Åed in this study. Considering the computation cost and model performance, a simpliÔ¨Åed ResNet was chosen and the details of the net-work are shown in Fig. 3. The WBM samples together with 123 324 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Fig. 3 Schematic architecture of the shared network and the basic blocks used to construct the model shape templates were Ô¨Årst concatenated and sent to a convo- lutional layer, and the model was then connected with fourresidual blocks, before average pooling and Ô¨Çattened for fur-ther processing. The output size for the shared network was 512. The classiÔ¨Åcation and localization networks were cho- sen to have two fully-connected layers, with 256 neuronsfor the Ô¨Årst layer, before they were connected to the output layer with the corresponding number of neurons for classi- Ô¨Åcation and deformation. The Sigmoid activation functionwas adopted for the identiÔ¨Åcation of the pattern classes and the transformation parameters."}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_22", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 22, "text": "with the corresponding number of neurons for classi- Ô¨Åcation and deformation. The Sigmoid activation functionwas adopted for the identiÔ¨Åcation of the pattern classes and the transformation parameters. The transformation learned by the segmentation was applied to the shape templates tomatch the WBMs, and the result of the deformation was thencombined with the predicted classes to obtain the segmenta- tion results. The proposed model accomplishes both classiÔ¨Åcation and segmentation in the same model, so the loss function consists of two parts, i.e., the classiÔ¨Åcation loss and mask loss. Clas- siÔ¨Åcation loss calculates the cross entropy of the predictedclass and actual class. Mask loss is a weighted cross entropy function of the predicted and ground truth mask deÔ¨Åned as Loss M=‚àíw¬∑plog(q)‚àí(1‚àíp)log(1‚àíq), (10)where wis the weighting factor, pandqare target and pre- dicted distributions, respectively. Larger values of w> 1 penalize false negatives, which avoids predicting small pat-tern areas as background noise due to class imbalance of defective and normal pixels. Compared with the area in a whole WBM, the appearance of defect patterns is sparse,especially for scratches. Therefore, diff"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_23", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 23, "text": " as background noise due to class imbalance of defective and normal pixels. Compared with the area in a whole WBM, the appearance of defect patterns is sparse,especially for scratches. Therefore, different weights were chosen for these patterns, and the weight of [16,4,1,1]was adopted for the patterns Scratch, Zone, Ring and Center,considering the size and the segmentation difÔ¨Åculty of the patterns. The weights of the loss components can be adjusted, according to the signiÔ¨Åcance of the tasks. Loss=Loss y+Œª‚àóLoss M,Œª‚ààR+. (11) We chose the combination Œª=1 for this study, based on the results on the validation set. The model were trained for 2000epoches, and the batch size was set to 64. The Adam opti- mizer (Kingma & Ba, 2014 ) was applied with an exponential learning rate decay with initial learning rate of 0.01. Themodel was coded using Python 3.7, TensorFlow 1.15 envi- ronment on a Windows 10, and executed on a computer with a Core i9-10885 H CPU@2.40 GHz and a NVIDIA QuadroRTX 5000 GPU. 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 325 Fig. 4 Confusion matrix result of the mixed-type pattern classiÔ¨Åcation Results of pattern classification We Ô¨Årst examined the classiÔ¨Åc"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_24", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 24, "text": "U. 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 325 Fig. 4 Confusion matrix result of the mixed-type pattern classiÔ¨Åcation Results of pattern classification We Ô¨Årst examined the classiÔ¨Åcation performance of the proposed method. Figure 4presents the confusion matrix of the mixed-type pattern classiÔ¨Åcation. The percentage of WBMs that was accurately classiÔ¨Åed was shown in the matrixdiagonal, and mixed-type patterns were denoted with thecombination of the pattern initials. The overall accuracy reaches 97 .3% for the 16 pattern classes. The model gave sat- isfactory results ( ‚â•95%) for most of the classes, especially for patterns with single type and the mixture of two defect types. It was more difÔ¨Åcult to recognize patterns when three or more defect types exist on the same WBM, as their interac-tions may increase the probability of misclassiÔ¨Åcation. The recognition rates were 91% and 89% for the pattern SZC and SZRC, respectively. This may be caused by the connectiv-ity of the scratch and zone patterns at the edge, as well asthe scratch and center patterns at the middle part, while the scratch patterns appear long and thin that were hard to be detected. The classiÔ¨Åcation"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_25", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 25, "text": "he scratch and zone patterns at the edge, as well asthe scratch and center patterns at the middle part, while the scratch patterns appear long and thin that were hard to be detected. The classiÔ¨Åcation performance of the proposed method was compared with two CNN based models renamed as CNN_N (Nakazawa & Kulkarni, 2018 ) and CNN_T (Kyeong &K i m , 2018 ), which were used to recognize mixed-type defect patterns on WBMs. The comparison results are shown in Table 1. The Hamming loss, mixed-type accuray and exact match accuracy were computed for these three meth-ods. The values of MTA were higher than that of EMA,as EMA is more strict which measures the percentage of WBMs that were perfectly recognized. Overall, our method outperformed the two CNN based models for all the threeindices. For single-type defect patterns, the Normal, Scratch, Zone and Ring patterns were successfully identiÔ¨Åed, and the recognition rate of center patterns reached 98.2%, which wascompetitive with the CNN models. For mixed-type defectpatterns, our method gave better performance for most of the pattern types, especially for the two-type mixture patterns SZ, SR and ZR, which were perfectly classiÔ¨Åed in the test-in"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_26", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 26, "text": "r mixed-type defectpatterns, our method gave better performance for most of the pattern types, especially for the two-type mixture patterns SZ, SR and ZR, which were perfectly classiÔ¨Åed in the test-ing results. For complex defect patterns that contains three or more types of defect patterns, the performance of our method was superior for SZR, SRC and SZRC patterns. Though ourmethod performed relatively worse on the classes SZC and ZRC than CNN_N, it still obtained acceptable results, which demonstrated the effectiveness of the proposed method. Results of pattern segmentation For defect pattern segmentation, the IoU was calculated foreach pattern type, and the results are presented in Table 2.F o r single type defect patterns, zone patterns gave the best per- formance, with the average IoU reaches 0.936. The scratch patterns were relatively difÔ¨Åcult to be located, as they canappear at any positions in the WBMs and can be mixed up with the isolated noise due to their long and thin appearances. The results of center patterns were worse than that of zoneand ring patterns, which may be explained by the irregular- 123 326 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Table 1 Com"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_27", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 27, "text": "ances. The results of center patterns were worse than that of zoneand ring patterns, which may be explained by the irregular- 123 326 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Table 1 Comparison results of pattern classiÔ¨Åcation Pattern type HL EMA MTA Our method CNN_N CNN_K Our method CNN_N CNN_K Our method CNN_N CNN_K Normal 0.0000 0.0045 0.0133 1.000 0.982 0.946 1.000 0.982 0.946 S 0.0000 0 .0000 0 .0000 1 .000 1 .000 1 .000 1 .000 1 .000 1 .000 Z 0.0000 0.0068 0.0068 1.000 0.973 0.973 1.000 0.987 0.987 R 0.0000 0.0144 0.0048 1.000 0.942 0.981 1.000 0.952 0.981 C 0.0045 0.0000 0 .0000 0.982 1.000 1 .000 0.982 1.000 1 .000 SZ 0.0000 0.0330 0.0425 1.000 0.887 0.849 1.000 0.943 0.934 SR 0.0000 0.0100 0.0300 1.000 0.960 0.880 1.000 0.980 0.943 SC 0.0188 0.0000 0.0204 0.950 1.000 0.918 0.975 1.000 0.969 ZR 0.0000 0.0204 0.0255 1.000 0.918 0.898 1.000 0.963 0.959 ZC 0.0147 0.0227 0.0045 0.941 0.909 0.982 0.971 0.967 0.994 RC 0.0088 0.0102 0.0000 0.982 0.959 1.000 0.988 0.983 1.000 SZR 0.0047 0.0268 0.0268 0.981 0.911 0.893 0.993 0.964 0.964 SZC 0.0278 0.0532 0.0160 0.911 0.979 0.936 0.963 0.993 0.981 SRC 0.0108 0.0217 0.0326 0.978 0.935 0.913 0.989 0.976 0.964 ZRC 0.0127 0"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_28", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 28, "text": ".000 SZR 0.0047 0.0268 0.0268 0.981 0.911 0.893 0.993 0.964 0.964 SZC 0.0278 0.0532 0.0160 0.911 0.979 0.936 0.963 0.993 0.981 SRC 0.0108 0.0217 0.0326 0.978 0.935 0.913 0.989 0.976 0.964 ZRC 0.0127 0.0000 0.0048 0.949 1.000 0.981 0.988 1.000 0.995 SZRC 0.0266 0.0389 0.0667 0.894 0.844 0.733 0.964 0.961 0.933 Overall 0.0081 0.0134 0.0184 0.973 0.950 0.930 0.988 0.978 0.972 It shows the comparison results of different methods. The best results are shown in bold to highlight the superiority Table 2 Pattern segmentation results of different defect patterns Pattern type Extracted patterns Scratch Zone Ring Center S 0.825 ‚Äì ‚Äì ‚Äì Z ‚Äì 0.936 ‚Äì ‚ÄìR ‚Äì ‚Äì 0.907 ‚ÄìC ‚Äì ‚Äì ‚Äì 0.851SZ 0.729 0.918 ‚Äì ‚ÄìSR 0.649 ‚Äì 0.899 ‚ÄìSC 0.800 ‚Äì ‚Äì 0.852ZR ‚Äì 0.854 0.844 ‚ÄìZC ‚Äì 0.936 ‚Äì 0.852RC ‚Äì ‚Äì 0.906 0.841SZR 0.553 0.829 0.838 ‚ÄìSZC 0.702 0.918 ‚Äì 0.839SRC 0.630 ‚Äì 0.896 0.844ZRC ‚Äì 0.850 0.852 0.844 SZRC 0.541 0.817 0.832 0.833 Overall 0.678 0.882 0.872 0.844 ity and ambiguity of the region edges. For mixed-type defect patterns, the difÔ¨Åculty of pattern segmentation increased with the mixture of more defect pattern types, and therefore theaccuracy decreased with the complexity of mixed-type pat- terns. For the extraction o"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_29", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 29, "text": "s, the difÔ¨Åculty of pattern segmentation increased with the mixture of more defect pattern types, and therefore theaccuracy decreased with the complexity of mixed-type pat- terns. For the extraction of scratch patterns, the co-occurrence of ring patterns lowered the values of the IoU indice, as theywere both curves and their interactions at the wafer edgewere not easy to be resolved. The segmentation of ring pat- terns and the zone patterns were largely inÔ¨Çuenced by eachother, which were connected at the wafer edge. The center patterns, however, were not signiÔ¨Åcantly affected by other patterns, because the chances of their interactions were rela-tively lower. The segmentation performance of connected patterns is illustrated in Fig. 5. Three overlapped examples were given, in which the complex patterns were hard to be separatedinto clusters of single patterns. The four columns illustrated the separated patterns matched by the four corresponding templates, respectively. In all the three WBMs, the zone andring patterns were connected, which was often the case when they both appeared in the same WBM. In the Ô¨Årst WBM, the scratch was an arc with a large radius, which was connectedwith t"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_30", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 30, "text": "WBMs, the zone andring patterns were connected, which was often the case when they both appeared in the same WBM. In the Ô¨Årst WBM, the scratch was an arc with a large radius, which was connectedwith the center region. For the second WBM, it was hardto determine the location of the scratch pattern, as it was connected with the ring and the zone patterns. In the third example, the scratch and the zone regions were connectedand close to each other, making it difÔ¨Åcult to differentiate between the two patterns. It was observed from Fig. 5that our method performed well in the extraction of connectedand overlapped patterns of different shapes. Our method was also robust when dealing with isolated points, which were seen as noise to the defect patterns. The overall results fromrepresentative examples showed that our method was able toextract single defect patterns that were clear and complete, from noisy WBMs with complex patterns of arbitrary shapes. 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 327 Fig. 5 Extraction of connected patterns in the WBMs Fig. 6 Comparison of pattern segmentation results of the hierarchical clustering (HC), K-means, spectral clustering (SC), iWMM "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_31", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 31, "text": "2025) 36:319‚Äì330 327 Fig. 5 Extraction of connected patterns in the WBMs Fig. 6 Comparison of pattern segmentation results of the hierarchical clustering (HC), K-means, spectral clustering (SC), iWMM and our method To further evaluate the ability of our method for pattern segmentation, we compared our method with the conven- tional unsupervised clustering methods that was widelyapplied in the literature, namely, hierarchical clustering (HC), K-means, spectral clustering (SC) and iWMM (Kim et al., 2018 ). Our method was inherently robust to remove noisy points from the WBMs, so no additional denoising step wasrequired. For these clustering based methods to be com- pared, we applied the denoising method mentioned in Wang and Chen ( 2022 ) in order to compare the pattern separation performance. For hierarchical clustering, we followed the bottom-up approach. Average linkage and Euclidean distancewere chosen for the formation of clusters. To use K-means for clustering, the number of clusters Kis required. Here we choose K=5, i.e., Ô¨Åve clusters are constructed based on the defect points. Spectral clustering performed clustering task by Ô¨Årst constructing an afÔ¨Ånity matrix, and eigenvec- "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_32", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 32, "text": "rs Kis required. Here we choose K=5, i.e., Ô¨Åve clusters are constructed based on the defect points. Spectral clustering performed clustering task by Ô¨Årst constructing an afÔ¨Ånity matrix, and eigenvec- tors were then computed to form the new data points. Classicclustering algorithms were applied on the new data points toÔ¨Ånd the Ô¨Ånal clusters. We construct the afÔ¨Ånity matrix with the Euclidean distance and use K-means for the clustering of new data points. For iWMM, the same parameter settingof Kim et al. ( 2018 ) was applied. 123 328 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Table 3 mIoU results for different numbers of mixed pattern types Method Number of mixed pattern types Overall 01234 Our method 1.000 0 .879 0 .839 0.800 0.775 0.845 U-Net 0.982 0.577 0.627 0.746 0.877 0.682 WSCN 0.801 0.785 0.797 0.817 0.817 0.800 FCN 1.000 0.799 0.732 0.667 0.594 0.741SegNet 0.806 0.852 0.779 0.751 0.728 0.789 Figure 6compares the clustering performance of our method and the four competitive methods mentioned above.The Ô¨Årst column represents the three WBMs to be examined, and rows 2 to 6 show the results obtained using our method, HC, K-means, SC and iWMM, respectively. The colors "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_33", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 33, "text": "titive methods mentioned above.The Ô¨Årst column represents the three WBMs to be examined, and rows 2 to 6 show the results obtained using our method, HC, K-means, SC and iWMM, respectively. The colors indi-cate different clusters for each of the WBM. The results of our method was shown with superposition of the extracted pat- terns following the sequence of ring, zone, scratch and centerfor better visualization. Overall, our method was capable of removing noise and insigniÔ¨Åcant shapes, which was compa- rable with the existing denoising method in Wang and Chen(2022 ). In addition, our method shows better performance compared with traditional clustering based methods, which may group connected patterns into the same clusters or sepa- rate the same pattern into many fractions instead. For the Ô¨ÅrstWBM, HC, K-means and SC cannot separate the scratches from the cluster at the wafer center due to the connectivity of the two patterns. The iWMM was able to isolate the scratchcorrectly, but it cannot automatically combine connected ring patterns at the edge. For the second WBM, the ring and zone patterns at the edge cannot be differentiated using HC, K-means and SC, while iWMM shows good sepa"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_34", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 34, "text": "nnot automatically combine connected ring patterns at the edge. For the second WBM, the ring and zone patterns at the edge cannot be differentiated using HC, K-means and SC, while iWMM shows good separation results; however, it divided the edge pattern into two local clusters.All the methods gave similar clustering results for the last WBM, which failed to separate scratch and zone patterns when they were really close to each other. We also compared our model with four segmentation based baseline models: the U-net (Yan et al., 2023 ), WSCN (Nag et al., 2022 ), FCN (Shelhamer et al., 2017 ) and Seg- Net (Badrinarayanan et al., 2017 ). The cross entropy loss was utilized to compute the differentce between the pre- dicted mask and the ground truth, and hyperparameters were chosen with the grid search. Table 3illustrates the compari- son of mIoU results considering different numbers of pattern types included in the WBMs. For the overall performance, our method was signiÔ¨Åcantly better than the other methods.When the WBM has less than three patterns, which is typi-cally the case in practical applications, our method performed the best. This results demonstrate the effectiveness of our pr"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_35", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 35, "text": "the other methods.When the WBM has less than three patterns, which is typi-cally the case in practical applications, our method performed the best. This results demonstrate the effectiveness of our proposed method. When four patterns co-exist in the sameWBM, U-Net is better than our method, but the results in other classes are far less satisfactory. Figure 7further plots the mIoU values over different mixed-type pattern classes.Overall, the compared segmentation based methods show similar patterns, among which WSCN seems to provide bet- ter performance. Our method outperformed WSCN in almostall the classes, with the exception of patterns that containsZR, where results were also comparable. U-Net provided marginally higher performance in S, SZ, SZR and SZRC, but the mIoU results of other classes were signiÔ¨Åcantly worse,notably for R, C, ZC and RC. Furthermore, compared to other methods, which experienced signiÔ¨Åcant Ô¨Çuctuations, our method produced more stable results across the variouspattern classes. Fig. 7 The segmentation performance of our method and other segmentation models 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 329 Conclusion This paper proposes a shape pr"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_36", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 36, "text": "attern classes. Fig. 7 The segmentation performance of our method and other segmentation models 123 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 329 Conclusion This paper proposes a shape prior guided defect pattern clas- siÔ¨Åcation and segmentation method in WBMs. The spatial transformer network is applied to deform the shape priors inorder to match with the patterns for extraction. The deforma-tion is conducted by estimating a transformation Ô¨Åeld while optimizing the alignment between the template and the tar- get pattern. The registration based segmentation is able toextract single patterns from complex patterns composed of connected and overlapped patterns. Experiments show that the proposed method is effective for both classiÔ¨Åcation andseparation of mixed-type defect patterns in WBMs. The per- formance of the method is competitive with state-of-the-art segmentation algorithms, while it takes the connectivity andinteraction of the patterns into account. The proposed method could be easily extended by deÔ¨Ån- ing different representative shape priors, both real and hand-crafted ones are applicable. The model could also beseparately deÔ¨Åned, by training a network for each p"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_37", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 37, "text": " could be easily extended by deÔ¨Ån- ing different representative shape priors, both real and hand-crafted ones are applicable. The model could also beseparately deÔ¨Åned, by training a network for each pattern type individually and combining the results together. In addition, more than one templates can be determined for a pattern type,improving the capability of extracting different shapes of the same pattern. Our model could be applied in various Ô¨Åelds to solve computer vision problems, such as object detectionand image segmentation, especially when the targets are con-nected or overlapped. In other applications, the shape priors are not restricted to shape templates, Ô¨Çexible forms of shape priors, including probabilistic and geometric representations,could also be incorporated into the model. Author Contributions All authors contributed to the idea of the study. The Ô¨Årst draft of the manuscript was written by RW and all authors commented on previous versions of the manuscript. All authors readand approved the Ô¨Ånal manuscript. Funding The study is supported by Key Program of National Natu- ral Science Foundation of China (No. 72334004), General Programof National Natural Science Fou"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_38", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 38, "text": "ors readand approved the Ô¨Ånal manuscript. Funding The study is supported by Key Program of National Natu- ral Science Foundation of China (No. 72334004), General Programof National Natural Science Foundation of China (No. 71971143),Y outh Program of National Natural Science Foundation of China(No. 72101065, No. 72101106), Guangdong Basic and AppliedBasic Research Foundation (No. 2021A1515110336), GuangdongProvincial Philosophy and Social Sciences Planning Project (No.GD22CGL35), Special Projects in Key Fields of Ordinary Col-leges and Universities in Guangdong Province (No. 2022ZDZX2054),University Innovation Team Project of Guangdong Province (No.2021WCXTD002), and Shenzhen Science and Technology Program(No. RCBS20210609103119020, No. RCBS20221008093124063). Data availability The data that support the Ô¨Åndings of this study are available from the corresponding author upon request. Declarations Competing interests The authors declare that they have no known competing Ô¨Ånancial interests or personal relationships that could haveappeared to inÔ¨Çuence the work reported in this paper.References Abd Al Rahman, M., Danishvar, S., & Mousavi, A. (2021). An improved capsule network (wafercaps)"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_39", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 39, "text": "or personal relationships that could haveappeared to inÔ¨Çuence the work reported in this paper.References Abd Al Rahman, M., Danishvar, S., & Mousavi, A. (2021). An improved capsule network (wafercaps) for wafer bin map classiÔ¨Åcation basedon dcgan data upsampling. IEEE Transactions on Semiconductor Manufacturing, 35 (1), 50‚Äì59. https://doi.org/10.1109/TSM.2021. 3134625 Adly, F., Alhussein, O., Y oo, P . D., Al-Hammadi, Y ., Taha, K., Muhaidat, S., Jeong, Y .-S., Lee, U., & Ismail, M. (2015). SimpliÔ¨Åed subspacedregression network for identiÔ¨Åcation of defect patterns in semicon-ductor wafer maps. IEEE Transactions on Industrial Informatics, 11(6), 1267‚Äì1276. https://doi.org/10.1109/TSM.2018.2841416 Badrinarayanan, V ., Kendall, A., & Cipolla, R. (2017). Segnet: A deep convolutional encoder-decoder architecture for image seg-mentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (12), 2481‚Äì2495. https://doi.org/10.1109/TPAMI. 2016.2644615 Chien, C.-F., Hsu, C.-Y ., & Chen, P .-N. (2013). Semiconductor fault detection and classiÔ¨Åcation for yield enhancement and manufac-turing intelligence. Flexible Services and Manufacturing Journal, 25(3), 367‚Äì388. https://doi.or"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_40", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 40, "text": " Chen, P .-N. (2013). Semiconductor fault detection and classiÔ¨Åcation for yield enhancement and manufac-turing intelligence. Flexible Services and Manufacturing Journal, 25(3), 367‚Äì388. https://doi.org/10.1007/s10696-012-9161-4 Chiu, M.-C., & Chen, T.-M. (2021). Applying data augmentation and mask R-CNN-based instance segmentation method for mixed-typewafer maps defect patterns classiÔ¨Åcation. IEEE Transactions on Semiconductor Manufacturing, 34 (4), 455‚Äì463. https://doi.org/ 10.1109/TSM.2021.3118922 √ái√ßek, √ñ., Abdulkadir, A., Lienkamp, S.S., Brox, T., & Ronneberger, O. (2016). 3D U-Net: Learning dense volumetric segmentationfrom sparse annotation. In International conference on medical image computing and computer-assisted intervention (pp. 424- 432). https://doi.org/10.1007/978-3-319-46723-8_49 Cremers, D., Osher, S. J., & Soatto, S. (2006). Kernel density estimation and intrinsic alignment for shape priors in level set segmentation.International Journal of Computer Vision, 69 (3), 335‚Äì351. https:// doi.org/10.1007/s11263-006-7533-5 He, F., Liu, T., & Tao, D. (2020). Why resnet works? Residuals generalize. IEEE Transactions on neural Networks and Learn- ing Systems, 31 (12), 5349‚Äì"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_41", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 41, "text": "5‚Äì351. https:// doi.org/10.1007/s11263-006-7533-5 He, F., Liu, T., & Tao, D. (2020). Why resnet works? Residuals generalize. IEEE Transactions on neural Networks and Learn- ing Systems, 31 (12), 5349‚Äì5362. https://doi.org/10.1109/TNNLS. 2020.2966319 He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778). https://doi. org/10.48550/arXiv.1512.03385 Hsu, C.-Y ., Chen, W.-J., & Chien, J.-C. (2020). Similarity matching of wafer bin maps for manufacturing intelligence to empowerindustry 3.5 for semiconductor manufacturing. Computers & Industrial Engineering, 142 , 106358. https://doi.org/10.1016/j. cie.2020.106358 Hsu, C.-Y ., & Chien, J.-C. (2022). Ensemble convolutional neural networks with weighted majority for wafer bin map pattern clas-siÔ¨Åcation. Journal of Intelligent Manufacturing, 33 (3), 831‚Äì844. https://doi.org/10.1007/s10845-020-01687-7 Jaderberg, M., Simonyan, K., Zisserman, A., & kavukcuoglu, K. (2015). Spatial transformer networks. In: Cortes, C., Lawrence, N., Lee,D., Sugiyama, M., & Garnett, R. (Eds.), Advances in neural infor- mation process"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_42", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 42, "text": " Simonyan, K., Zisserman, A., & kavukcuoglu, K. (2015). Spatial transformer networks. In: Cortes, C., Lawrence, N., Lee,D., Sugiyama, M., & Garnett, R. (Eds.), Advances in neural infor- mation processing systems (V ol. 28). https://doi.org/10.48550/ arXiv.1506.02025 Jin, C. H., Kim, H.-J., Piao, Y ., Li, M., & Piao, M. (2020). Wafer map defect pattern classiÔ¨Åcation based on convolutional neuralnetwork features and error-correcting output codes. Journal of Intelligent Manufacturing, 31 (8), 1861‚Äì1875. https://doi.org/10. 1007/s10845-020-01540-x Kim, J., Lee, Y ., & Kim, H. (2018). Detection and clustering of mixed- type defect patterns in wafer bin maps. IISE Transactions, 50 (2), 99‚Äì111. https://doi.org/10.1080/24725854.2017.1386337 123 330 Journal of Intelligent Manufacturing (2025) 36:319‚Äì330 Kim, T., & Behdinan, K. (2023). Advances in machine learning and deep learning applications towards wafer map defect recognitionand classiÔ¨Åcation: A review. Journal of Intelligent Manufacturing, 34, 3215‚Äì3247. https://doi.org/10.1007/s10845-022-01994-1 Kim, T. S., Lee, J. W., Lee, W. K., & Sohn, S. Y . (2022). Novel method for detection of mixed-type defect patterns in wafer mapsbased on a s"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_43", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 43, "text": " 34, 3215‚Äì3247. https://doi.org/10.1007/s10845-022-01994-1 Kim, T. S., Lee, J. W., Lee, W. K., & Sohn, S. Y . (2022). Novel method for detection of mixed-type defect patterns in wafer mapsbased on a single shot detector algorithm. Journal of Intelli- gent Manufacturing, 33 (6), 1715‚Äì1724. https://doi.org/10.1007/ s10845-021-01755-6 Kingma, D.P ., & Ba, J. (2014). Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980 Kong, Y ., & Ni, D. (2019). Recognition and location of mixed-type pat- terns in wafer bin maps. In 2019 IEEE international conference on smart manufacturing, industrial & logistics engineering (SMILE)(pp. 4-8). https://doi.org/10.1109/SMILE45626.2019.8965309 Kong, Y ., & Ni, D. (2020). Qualitative and quantitative analysis of multi-pattern wafer bin maps. IEEE Transactions on Semiconduc- tor Manufacturing, 33 (4), 578‚Äì586. https://doi.org/10.1109/TSM. 2020.3022431 Kyeong, K., & Kim, H. (2018). ClassiÔ¨Åcation of mixed-type defect patterns in wafer bin maps using convolutional neural networks.IEEE Transactions on Semiconductor Manufacturing, 31 (3), 395‚Äì 402. https://doi.org/10.1109/TSM.2018.2841416 Lee, M. C. H., Petersen, K., Pawlowski, N., Glocke"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_44", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 44, "text": "maps using convolutional neural networks.IEEE Transactions on Semiconductor Manufacturing, 31 (3), 395‚Äì 402. https://doi.org/10.1109/TSM.2018.2841416 Lee, M. C. H., Petersen, K., Pawlowski, N., Glocker, B., & Schaap, M. (2019). TETRIS: Template transformer networks for imagesegmentation with shape priors. IEEE Transactions on Medical Imaging, 38 (11), 2596‚Äì2606. https://doi.org/10.1109/TMI.2019. 2905990 Milletari, F., Rothberg, A., Jia, J., & Sofka, M. (2017). Integrating statistical prior knowledge into convolutional neural networks.InInternational conference on medical image computing and computer-assisted intervention (pp. 161-168). https://doi.org/10. 1007/978-3-319-66182-7_19 Nag, S., Makwana, D., & R, S. C. T., Mittal, S., & Mohan, C. K. (2022). Wafersegclassnet‚ÄìA light-weight network for classiÔ¨Åca-tion and segmentation of semiconductor wafer defects. Computers in Industry, 142 , 103720. https://doi.org/10.1016/j.compind.2022. 103720 Nakazawa, T., & Kulkarni, D. V . (2018). Wafer map defect pattern clas- siÔ¨Åcation and image retrieval using convolutional neural network.IEEE Transactions on Semiconductor Manufacturing, 31 (2), 309‚Äì 314. https://doi.org/10.1109/TSM.2018.2795466 "}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_45", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 45, "text": " map defect pattern clas- siÔ¨Åcation and image retrieval using convolutional neural network.IEEE Transactions on Semiconductor Manufacturing, 31 (2), 309‚Äì 314. https://doi.org/10.1109/TSM.2018.2795466 O‚ÄôLeary, J., Sawlani, K., & Mesbah, A. (2020). Deep learning for classiÔ¨Åcation of the chemical composition of particle defectson semiconductor wafers. IEEE Transactions on Semiconductor Manufacturing, 33 (1), 72‚Äì85. https://doi.org/10.1109/TSM.2019. 2963656 Pak, D.H., Caballero, A., Sun, W., & Duncan, J.S. (2020). EfÔ¨Åcient aortic valve multilabel segmentation using a spatial transformernetwork. In 2020 IEEE 17th international symposium on biomedi- cal imaging (ISBI) (pp. 1738-1742). https://doi.org/10.1109/TMI. 2019.2905990 Piao, M., & Jin, C. H. (2023). CNN and ensemble learning based wafer map failure pattern recognition based on local property basedfeatures. Journal of Intelligent Manufacturing, 34 , 3599‚Äì3621. https://doi.org/10.1007/s10845-022-02023-xRonneberger, O., Fischer, P ., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. In Medical image computing and computer-assisted intervention‚ÄìMICCAI 2015:18th international conference, Munich, German"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_46", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 46, "text": "rox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. In Medical image computing and computer-assisted intervention‚ÄìMICCAI 2015:18th international conference, Munich, Germany , October 5‚Äì9, 2015, Proceedings, Part III 18 (pp. 234-241). https://doi.org/10. 1007/978-3-319-24574-4_28 Shelhamer, E., Long, J., & Darrell, T. (2017). Fully convolutional net- works for semantic segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (4), 640‚Äì651. https://doi. org/10.1109/TPAMI.2016.2572683 Shin, W., Kahng, H., & Kim, S. B. (2022). Mixup-based classiÔ¨Åca- tion of mixed-type defect patterns in wafer bin maps. Computers & Industrial Engineering, 167 , 107996. https://doi.org/10.1016/j. cie.2022.107996 Tsoumakas, G., & Katakis, I. (2007). Multi-label classiÔ¨Åcation: An overview. International Journal of Data Warehousing and Mining (IJDWM), 3 (3), 1‚Äì13. https://doi.org/10.4018/jdwm.2007070101 Wang, J., Xu, C., Yang, Z., Zhang, J., & Li, X. (2020). Deformable con- volutional networks for efÔ¨Åcient mixed-type wafer defect patternrecognition. IEEE Transactions on Semiconductor Manufacturing, 33(4), 587‚Äì596. https://doi.org/10.1109/TSM.2020.3020985 W"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_47", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 47, "text": "eformable con- volutional networks for efÔ¨Åcient mixed-type wafer defect patternrecognition. IEEE Transactions on Semiconductor Manufacturing, 33(4), 587‚Äì596. https://doi.org/10.1109/TSM.2020.3020985 Wang, R., & Chen, N. (2022). Detection and recognition of mixed- type defect patterns in wafer bin maps via tensor voting. IEEE Transactions on Semiconductor Manufacturing, 35 (3), 485‚Äì494. https://doi.org/10.1109/TSM.2022.3183008 Yan, J., Sheng, Y ., & Piao, M. (2023). Semantic segmentation based wafer map mixed-type defect pattern recognition. IEEE Transactions on Computer-Aided Design of Integrated Circuitsand Systems (Early Access) .https://doi.org/10.1109/TCAD.2023. 3274958 Y uan, T., & Kuo, W. (2008). Spatial defect pattern recognition on semiconductor wafers using model-based clustering and bayesianinference. European Journal of Operational Research, 190 (1), 228‚Äì240. https://doi.org/10.1016/j.ejor.2007.06.007 Y u, J., & Liu, J. (2020). Two-dimensional principal component analysis- based convolutional autoencoder for wafer map defect detection.IEEE Transactions on Industrial Electronics, 68 (9), 8789‚Äì8797. https://doi.org/10.1109/TIE.2020.3013492 Zheng, S., Jayasumana, S., Romera"}
{"id": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf::chunk_48", "source": "Shape prior guided defect pattern classification and segmentation in wafer bin maps.pdf", "chunk_index": 48, "text": "ased convolutional autoencoder for wafer map defect detection.IEEE Transactions on Industrial Electronics, 68 (9), 8789‚Äì8797. https://doi.org/10.1109/TIE.2020.3013492 Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V ., Su, Z., Du, D., Huang, C., & Torr, P .H. (2015). Conditional random Ô¨Åelds asrecurrent neural networks. In Proceedings of the IEEE interna- tional conference on computer vision (pp. 1529-1537). https://doi. org/10.1109/ICCV .2015.179 Zotti, C., Luo, Z., Lalande, A., & Jodoin, P .-M. (2018). Convolutional neural network with shape prior applied to cardiac MRI segmenta-tion. IEEE Journal of Biomedical and Health Informatics, 23 (3), 1119‚Äì1128. https://doi.org/10.1109/TMI.2019.2905990 Publisher‚Äôs Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional afÔ¨Åliations. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with theauthor(s) or other rightsholder(s); author self-archiving of the acceptedmanuscript version of this article is solely governed by the terms of suchpublishing agreement and applicable law. 123"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_0", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 0, "text": "Contents lists available at ScienceDirect Computers & Industrial Engineering journal homepage: www.elsevier.com/locate/caie Similarity matching of wafer bin maps for manufacturing intelligence to empower Industry 3.5 for semiconductor manufacturing Chia-Yu Hsua,b,‚Åé, Wei-Ju Chenb, Ju-Chien Chienb,c aDepartmentofIndustrialEngineeringandManagement,NationalTaipeiUniversityofTechnology,Taipei10608,Taiwan bArtificialIntelligenceforIntelligentManufacturingSystems(AIMS)ResearchCenter,MinistryofScience&Technology,Hsinchu30013,Taiwan cDepartmentofComputerScience,NationalTsingHuaUniversity,Hsinchu30013,Taiwan ARTICLE INFO Keywords: Wafer bin map Yield enhancement Defect diagnosis SimilarityManufacturing intelligence Industry 3.5ABSTRACT Yield improvement is increasingly important as advanced fabrication technologies are complicated and inter- relatedforsemiconductormanufacturing.Waferbinmaps(WBM)presentspecificfailurepatternswhichprovidecrucialinformationtotracktheprocessexcursionstoempowerintelligentmanufacturingforwaferfabrication. In practice, WBM identification is still subjective relied on domain knowledge and human-eye. As the semi- conductor industry continuously migrates for advanced "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_1", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 1, "text": "igentmanufacturingforwaferfabrication. In practice, WBM identification is still subjective relied on domain knowledge and human-eye. As the semi- conductor industry continuously migrates for advanced nano technologies, many rare defect patterns are alsogenerated by different pattern, pattern size, noise degree, pattern density, pattern shift, and wafer rotation.ExistingstudiesregardingWBMfocusonclassificationandlackofcapabilitytodetectararepattern.Inorderto overcome the shortage of WBM classification, the similar WBMs provide useful information of WBM identifi- cation.FollowingIndustry3.5asahybridstrategybetweenIndustry3.0andto-beIndustry4.0,thisstudyaimstodevelopanovelapproachtomeasurethesimilarityofdefectpatternsofWBMstoenhancedecisionqualityfor fault detection and defect diagnosis effectively and efficiently. In particular, the proposed approach applied a mountain clusteringalgorithm toenhancethe defectfeaturesdependingonclustering density. Then,WeightedModified Hausdorff Distance (WMHD) is employed to measure the similarity level. Furthermore, a decision support system embedded the developed algorithms is constructed. An empirical study of WBM clustering was conducted in a fab "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_2", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 2, "text": "WMHD) is employed to measure the similarity level. Furthermore, a decision support system embedded the developed algorithms is constructed. An empirical study of WBM clustering was conducted in a fab for validation. The results have shown practical viability of the proposed approach. 1. Introduction The manufacturing process of in semiconductors fabrication in- volves hundreds of steps, and amounts of big data including the wafer lot history, process recipe, inline metrology measurement, equipment sensor value, defect inspection, and electrical test data are auto- matically generated and recoded. The challenge in semiconductor companies not only integrate big data from various sources into a platformordatawarehouse,but alsolackintelligentanalyticsolutions to extract useful manufacturing intelligence and support decision making regarding production planning, process control, equipment monitoring, and yield enhancement (Chien, Dou, & Fu, 2018; Dou, Chien, Kacem, & Hsu, 2018; Dou, He, & Hsu, 2018). Wafer bin map (WBM) is outcome of circuit probe (CP) process, whichrecordsthespatialdistributionofdefectdiesonthewafer.WBM spatial patterns contain potentially useful information, in which "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_3", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 3, "text": "su, 2018). Wafer bin map (WBM) is outcome of circuit probe (CP) process, whichrecordsthespatialdistributionofdefectdiesonthewafer.WBM spatial patterns contain potentially useful information, in which spe- cific pattern refers to potential failure of a specific manufacturing process. Thus, analyzing spatial patterns of WBMs can provide usefulmanufacturing intelligence for engineers to track the problem in spe- cific manufacturing processes for fault detection and yield enhance- ment. In practice, most of semiconductor manufacturing companies still rely on domain knowledge and experience in which online engineers employ visual inspection and personal judgments to identify and clas- sify the patterns for the wafer bin maps in batch. However, existing judgementbyhuman-eyemaybesubjective,inconsistence,andlackof justification, while is also time consuming. Indeed, a number of studies have been done for WBM analysis and pattern recognition that can divided into two major categories: su- pervised approaches for defect classification and unsupervised ap- proaches for WBM clustering (Chien, Hsu, & Chen, 2013). However, supervised approaches have the advantage for quickly detecting the existi"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_4", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 4, "text": "sed approaches for defect classification and unsupervised ap- proaches for WBM clustering (Chien, Hsu, & Chen, 2013). However, supervised approaches have the advantage for quickly detecting the existingpatterns,yetwiththelimitationforextendingtheclassification rules in light of new defects from technology migration. On the other hand,unsupervisedapproacheshavetheadvantageforanalyzingallof the patterns, yet with the limitation for recognizing specific patterns https://doi.org/10.1016/j.cie.2020.106358‚ÅéCorresponding author at: Department of Industrial Engineering and Management, National Taipei University of Technology, Taipei 10608, Taiwan. E-mailaddress: chiayuhsu@mail.ntut.edu.tw (C.-Y. Hsu).Computers & Industrial Engineering 142 (2020) 106358 Available online 19 February 2020 0360-8352/ ¬© 2020 Elsevier Ltd. All rights reserved. T suchastheringpatterns(Hsu&Chien,2007).Withthedevelopmentof big data analytic and machine learning methods, adaptive resonance theory (ART) neural network (Liu, Chen, & Lu, 2002; Hsu & Chien, 2007; Liu & Chien, 2013), decision tree-based (Piao, Jin, Lee, & Byun, 2018), support vector machine (SVM) (Baly & Hajj, 2012; Liao, Hsieh, Huang, & Chien, 2014; Wu,"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_5", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 5, "text": "iu, Chen, & Lu, 2002; Hsu & Chien, 2007; Liu & Chien, 2013), decision tree-based (Piao, Jin, Lee, & Byun, 2018), support vector machine (SVM) (Baly & Hajj, 2012; Liao, Hsieh, Huang, & Chien, 2014; Wu, Jang, & Chen, 2015), and joint local and nonlocal lineardiscriminant analysis(Yu&Lu,2016)wereappliedfor WBM classification. Saqlain, Jargalsaikhan, and Lee (2019) extracted 66 features including density-based, geometry-based, and radon-based features from raw wafer images and four kinds of classifiers including logistic regression (LR), random forests (RFs), gradient boosting ma- chine(GBM),andartificialneuralnetwork(ANN)wereusedformodel training. The ensemble result is better than individual classifier. How- ever,relyingongeneratedfeaturesinadvancearenotenoughtocover all kind of WBM failure patterns. Convolutional neural network (CNN) was also applied for WBM classification (Nakazawa & Kulkarni, 2018; Yu, Zheng, & Liu, 2019) and segmentation (Nakazawa & Kulkarni, 2019). Various failure patterns are useful to facilitate rapidly identifying the associate root causes of low yield. As the semiconductor industry continuously migrates for advanced nano technologies, the involved complexity"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_6", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 6, "text": "atterns are useful to facilitate rapidly identifying the associate root causes of low yield. As the semiconductor industry continuously migrates for advanced nano technologies, the involved complexity of product design and manufacturing process is ex- ponentially increased. Many rare defect patterns are generated by dif- ferentpatternshape,patternsize,noisedegree,patterndensity,pattern shift, and wafer rotation. However, existing studies of WBMs focus on WBM classification and lack of capability to detect a rare pattern. In order to help engineers to recognize the rare defect patterns for root case identification as possible, the information about measuring the similarity between two WBMs are needed. As most of the industries may not be ready for migration, Industry 3.5 was proposed as hybrid strategy between the existing Industry 3.0 and to-be Industry 4.0 to empower industrial transformation (Chien, Chou, & Yu, 2016; Chien, Hong, & Guo, 2017). While the big data isaccumulated automatically during semiconductor manufacturing pro- cess, how to exploit the useful rule and extract the intelligence from amounts of equipment sensor data, inspection data, and production data to assist o"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_7", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 7, "text": "ically during semiconductor manufacturing pro- cess, how to exploit the useful rule and extract the intelligence from amounts of equipment sensor data, inspection data, and production data to assist operational decision-making has been changed the para- digm of semiconductor manufacturing. In particular, this study ad- dressed the WBM analysis problem and hybrid various methods to support the matching of defect patterns for root case identification. Thatis,similardefectpatternsmayprovidethecluesfortheengineerto trackpotentialrootcausesandnarrowscopefortroubleshooting.But, the similarity between two WBMs are difficult to determine by a mathematicalequationbecausethe‚Äúsimilarity‚Äùperceivedbyindividual engineers will be different subject to visual sensibility, physical or mental condition. Moreover, the main factors including pattern size, pattern noise, different pattern density, location shift and wafer rota- tion will lead to generate various kind of WBMs and increase the dif- ficulty of WBMs similarity matching Tofillthegapsandovercomethefactorswhicheffecttheprecision of analysis results, this study aims to develop a framework for WBM similarity matching and thus construct integrate"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_8", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 8, "text": " WBMs similarity matching Tofillthegapsandovercomethefactorswhicheffecttheprecision of analysis results, this study aims to develop a framework for WBM similarity matching and thus construct integrated WBM similarity measurement system to support engineers for smart production in real settings. In particular, the proposed framework consists of four phases topreparethedata,formulatethesimilaritymeasurementmodels,and effectively derive similarity indices to support the decision with a de- cision support system. Using data preparation method to enhance data quality and provide consistent analysis baseline. Next, the spatial dis- tribution of defective dice is transformed by mountain function. The similarity of two WBMs is measured by weighted modified Hausdorff distance (WMHD). To validate the effectiveness of the proposed fra- mework of WBM similarity matching, an empirical study from a semi- conductor company was conducted. To compare with the existing literature, the major contributions of thispaperareasfollows.First,theproposedmethodofWBMsimilarity matchingcanbeappliedtosearchthesimilardefectpatternsamongtheexisting detect pattern without any pre-defined features and classes. The "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_9", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 9, "text": "s of thispaperareasfollows.First,theproposedmethodofWBMsimilarity matchingcanbeappliedtosearchthesimilardefectpatternsamongtheexisting detect pattern without any pre-defined features and classes. The proposed method can be used for WBM identification with con- sideringthevariousfactorsincludingpatternsize,noisedegree,pattern density, pattern shift, and wafer rotation. It overcomes the shortage of existing classification-based methods in WBM analysis. Second, the proposed method can be used for not only the rare defect pattern but alsothepre-defineddefectpatternswithoutcollectionoflargeamounts of training data and training a classification model. The remainder of this paper is organized as follows. Section 2re- views the related studies on manufacturing intelligence and wafer bin map analysis. Section 3presents the proposed framework for WBM si- milaritymatching. Section4presentsanempiricalstudyinaworldwide leading semiconductor manufacturing company for validation. Section 5concludes with discussions of contribution and future research di- rections. 2. Fundamental After wafer fabrication, the wafers must go through serial pass-or- failfunctionaltests,so-calledthecircuitprobe(CP)yie"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_10", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 10, "text": "ith discussions of contribution and future research di- rections. 2. Fundamental After wafer fabrication, the wafers must go through serial pass-or- failfunctionaltests,so-calledthecircuitprobe(CP)yieldtest,totestthe electrical function of dies whether is well or fail (Hsu & Chien, 2007). TheCPtestisasignificantindexofyield,theCPyieldimprovementcan divideintotwoparts,oneisthebaselineyieldimprovement,improving thetoolperformanceandreducingfailurebytuningtheprocessrecipe; another is the low yield trouble shooting, monitoring and diagnosing thefactorleadtofailure(Chien,Hsu,&Chen,2013;Liaoetal.,2014). TheCP testdetermines thegradeof eachdie onawafer, thebetter grade would be assigned if the die is well-functional, and vice versa.Thegradeispresentedbyspecificbincode,differsondifferentproduct types and company (Liu et al., 2002). There are hundreds of testing itemsinCPtest. Fig.1illustrateaWBMwithmixeddefectbincode.For example,testdieiswell-functional,thetestbincodeisdenotedas1.Ifadie is failed to certain testing item, it will be denoted a corresponding bin code. The example in Fig. 1use green or ‚Äò‚Äò1‚Äù to denote well-func- tionaldies,andothercoloror‚Äò‚Äò0‚Äùtodenotedefectivedies.Thequality tes"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_11", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 11, "text": "led to certain testing item, it will be denoted a corresponding bin code. The example in Fig. 1use green or ‚Äò‚Äò1‚Äù to denote well-func- tionaldies,andothercoloror‚Äò‚Äò0‚Äùtodenotedefectivedies.Thequality test of CP test can be illustrated in spatial distribution, and result in wafer bin map (WBM). With different quality level, WBM is multi-di- mensional and have complex structures. To assist visualization and analysis,WBMisusuallytransformedintoabinarymapthatrepresents it using binary code. TypicalWBMfailurepatternsconsistofthreecategories:(I)Random defect,(II)Systematicdefectand(III)Mixeddefect(Hsu&Chien,2007; Chien, Hsu, & Chen, 2013; Liu & Chien, 2013). (1) Randomdefect:thedefectivechipsarerandomlydistributedinthe map. Random defects are usually caused by the manufacturing environment. Even in a near-sterile environment, the particles cannot be removed completely. (2) Systematicdefect:thepositionsofdefectivechipsinthewafershow the spatial correlation, for example, ring, edge-fail, checkerboard, ‚ÄúBull-eyes‚Äù and scratch shapes. These frequently-seen patterns usually represent different sources of process failure causes. This spatial information is an important clue for engineers to trace"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_12", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 12, "text": "oard, ‚ÄúBull-eyes‚Äù and scratch shapes. These frequently-seen patterns usually represent different sources of process failure causes. This spatial information is an important clue for engineers to trace the process problem. (3) Mixed defect: a combination of systematic defects and random de- fect in one map. Mixeddefectpatternsthatarecommoninthefab.Itisimportantfor WBM analysis to separate random noise to identify root causes of thesystematic defects for yield enhancement. The random defect might impact the identification of systematic defect, and cause difficulty to extractthefeatureofthemaindefect.However,themixeddefectisthe mostcommontypeofdefectinthefab.Toanalyzesuchtypeofdefect, theengineerrequiredtoeliminatethedefectscausedbyrandomnoises, since only the systematic defect can lead the engineer to discover the major process problem (Hsu & Chien, 2007).C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 2 Most of existing WBMs studies are focus on diagnosing systematic defects,patternrecognitionandclassification(Chao&Tong,2009;Hsu& Chien, 2007; Li & Huang, 2009; Liu et al., 2002; Taam & Hamada, 1993; Wang, 2008; Wang, Kuo, & Bensmail, 2006; Yuan, Bae, & Park, 2010;"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_13", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 13, "text": " defects,patternrecognitionandclassification(Chao&Tong,2009;Hsu& Chien, 2007; Li & Huang, 2009; Liu et al., 2002; Taam & Hamada, 1993; Wang, 2008; Wang, Kuo, & Bensmail, 2006; Yuan, Bae, & Park, 2010; Yuan, Kuo, & Bae, 2011). Few researchers proposed statistical model to detect whether there is specific defect patterns (Yuan et al., 2010; Yuan etal.,2011).Statisticmodelcanpreciselyrecognizesymmetricorcomplex patterns,howeverneedtowellandspecificallydefinethepatternfeature. Also less flexibility: for those rare and which doesn't have significant feature, developing a statistic model may consider an inefficient way. MachinelearningtechniquesincludingARTneuralnetwork(Hsu& Chien,2007;Liuetal.,2002),decisiontree(Hsu&Chien,2007),single- classSVM(Liaoetal.,2014),multi-classSVM(Chao&Tong,2009;Baly &Hajj,2012),self-organizingmap(SOM)(Li&Huang,2009),andCNN (Nakazawa&Kulkarni,2018)wasalsoappliedforWBMclassification. However, machine learning techniques may need large amounts of training data to learn the complex function and focus on common patternclassificationsuchascenter,donut,edge-local,edge-ring,local, and scratch (Wu et al., 2015). Bigdataanalyticsanddataminingapproacheshavebeenemployed"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_14", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 14, "text": "earn the complex function and focus on common patternclassificationsuchascenter,donut,edge-local,edge-ring,local, and scratch (Wu et al., 2015). Bigdataanalyticsanddataminingapproacheshavebeenemployed toexplorehugedatatoextractusefulrulestosupportsmartproduction forsemiconductormanufacturing(Chien&Chuang,2014;Chien,Liu,& Chuang, 2017; Khakifirooz, Chien, & Chen, 2018). Manufacturing in- telligence can be derived to enhance decision quality and operation efficiency of decision problems involved in smart production that are characterized by uncertainty and a need for tradeoff among various objectivesandjustificationforthedecisionsinshorttime(Chien&Hsu,2006; Chien & Hsu, 2011; Chien, Chen, & Peng, 2010; Kuo, Chien, & Chen, 2011; Chien, Hsu, & Hsiao, 2012; Chien, Hsu, & Chen, 2013; Chien & Hsu, 2014). In particular, based on domain knowledge, wafer fabrication with a lengthy process from a large number of correlated variables is structured. The information and intelligence are extracted by multivariate statistical approaches as well as big data analytics to provideanaidforfaultdetection anddefectdiagnosis toeliminatethe causes and thus improve the performance of the process and enhance"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_15", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 15, "text": " multivariate statistical approaches as well as big data analytics to provideanaidforfaultdetection anddefectdiagnosis toeliminatethe causes and thus improve the performance of the process and enhance the yield (Chien, Hsu, & Chen, 2013). Due to continuous migration of semiconductor industry, many rare defectpatternsthatnever beenseenbeforewillcausethelimitationof existing approaches to fulfill the needs in real settings. Rather than developinganintelligentsolutiontoreplacedomainexperts,thisstudy focusedondevelopadecisionsupportsystemwithsimilaritymatching to provide an effective solution to empower human judgments of the engineers, as proposed in Industry 3.5. 3. WBM similarity matching The proposed framework for WBM similarity matching consists of the following four steps as illustrated in Fig. 2. In the first step, a candidateWBMforsimilaritymatchingisselectedfirstanddenotedas ‚ÄúselectedWBM‚Äù.Inthesecondstep,therawdataofCPtestareturned intobinarymap,inwhichthedicepassallthetestingitemsaredenoted as 1 and the dice fail any testing items are denoted as 0. Then, the selected WBM is applied enhance the signal and remove the noise (ESRN) method (Hsu & Chien, 2007) to strength the featu"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_16", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 16, "text": "saredenoted as 1 and the dice fail any testing items are denoted as 0. Then, the selected WBM is applied enhance the signal and remove the noise (ESRN) method (Hsu & Chien, 2007) to strength the feature of defect Fig. 1.Illustration of wafer bin map with mixed defects.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 3 pattern and remove the unnecessary random defect. In order to con- sidertwosimilarWBMswithrotation,wealsoperformCartesian-Polar coordinate transformation. The third step is to build the similarity measurement model by using modified mountain function to enhance the feature of WBMs. The value of modified mountain function is also used as a weight for similarity measurement. Then, the similarity be- tween WBMs are determined by WMHD and the weight design by modified mountain function. Final step is to evaluate the performance and validate the effectiveness of the proposed method. The similarity results are used for failure analysis database with further application. Theterminologyandnotationusedinthisstudyaresummarizedas follows: dij: the distance between die iand the defective die j. djc: distance between defect die jand wafer centroid c m : kernel w"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_17", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 17, "text": "pplication. Theterminologyandnotationusedinthisstudyaresummarizedas follows: dij: the distance between die iand the defective die j. djc: distance between defect die jand wafer centroid c m : kernel width in mountain function m: parameter of determining kernel width : constant of kernel width, =d N1 jjc A: the dataset of defective die on selected waferB: the dataset of defective die on compared wafer a x y( , ) : coordinate x y( , ) for the selected wafer b x y( , ) : coordinate x y( , ) for the compared wafer ab : the weight of defective die abelong to Aand defective die b belong to B Nd : the number of defective die on a wafer N:the number of die per wafer NA : the number of defective die on the selected wafer NB : the number of defective die on the compared wafer No : the number of defective die on a selected wafer in which the spatialdistancebetweentheselectedwaferandthecomparedwafer are large than the maximum matching tolerance M(i): the mountain function Ma: the mountain value of defective die afrom the selected wafer Mb:themountainvalueofdefectivedie bfromthecomparedwafer Sout:themaximummatchingtoleranceoftwodefectivedice aandb h(A,B): the WMHD between the selected WBM and t"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_18", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 18, "text": " defective die afrom the selected wafer Mb:themountainvalueofdefectivedie bfromthecomparedwafer Sout:themaximummatchingtoleranceoftwodefectivedice aandb h(A,B): the WMHD between the selected WBM and the compared WBM S(A,B):thesimilaritybetweentheselectedWBMandthecompared WBM Selection of a candidate WBM Signal Enhancement and Noise ReductionWBMs Database with applying data preparation process Feature Transformation by Modified Mountain FunctionRaw Data IntegrationProblem Definition Data Preparation Similarity Measurement Model Model EvaluationSimilarity Measurement by WMHD Model Evaluation Is it acceptable Similarity Comparison with Root Cause Identification Weight Design N YWBM Normalization and RotationFig. 2.Research framework.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 4 3.1. Problemdefinition Contribute to the variation in manufacturing process and different settingofparameters,evensametypeofpatternresultindifferentlevel of shape change. Fig. 3illustrates the factors need to be considered in similarity matching such as pattern size, noise degree, pattern density,pattern shift, and wafer rotation. The pattern size denotes that the WBMs have same defect p"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_19", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 19, "text": "he factors need to be considered in similarity matching such as pattern size, noise degree, pattern density,pattern shift, and wafer rotation. The pattern size denotes that the WBMs have same defect pattern but the defective size is different. The noise degree represents the same defect pattern with different random defective die on a WBM. The pattern density denotes that the WBMs with same defect pattern but the distribution of defective dies is dif- ferent.Thepatternshiftmeansthesamedefectpatternbutthelocations ofpatternonawaferaredifferent.Thewaferrotationdenotesthatthe WBMs have the same defect pattern with the different angles. 3.2. Datapreparation Fig. 4illustrates the process of data preparation for WBMs. Data Cleaning:Toeliminatetheeffectcausebyrandomdefect(noise),using Enhance the signal and remove the noise (ESRN) (Hsu & Chien, 2007) methodtoenhancethesignalofclusterandremovethenoise.Weighing adjacent dies in King-Move neighborhood for each die on the wafer. Calculating the proportion of the adjacent neighbors, if the proportion ofwell-functionaldieachievedthedefinedcriteria,transferthecentral die into 1 (good); on the other hand, if the proportion of bad die achieved the"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_20", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 20, "text": "roportion of the adjacent neighbors, if the proportion ofwell-functionaldieachievedthedefinedcriteria,transferthecentral die into 1 (good); on the other hand, if the proportion of bad die achieved the defined criteria, transfer the central die into 0 (failure). Moreover, we also perform Cartesian-Polar coordinate transformation to solve wafer rotation problem due to the machine alignment.3.3. Similaritymeasurementmodel 3.3.1. Featuretransformation The mountain method is a simple and effective heuristic algorithm to estimate the approximate cluster centers (Yager & Filev, 1994). The mountain function is similar to Parzen window, which estimates the probability density function of the feature. Yang and Wu (2005) mod- ified the mountain clustering algorithm by defining on data points(defective die) instead the number of die on a wafer. Assume we have Nd defectivedice, =j N 1, 2, , d ,andthenumberofdieperwaferis N, =i N 1, 2, , , the mountain function M(i) is defined as: = = =M i md i ( ) exp( ), 1, 2, , N jN ij 1d (1) where =d N1 jjc denotesasthedefectivedie jtothewafercenter c. The variable dij is the distance between die iand the defective die j. Parameter is the normalization facto"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_21", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 21, "text": "exp( ), 1, 2, , N jN ij 1d (1) where =d N1 jjc denotesasthedefectivedie jtothewafercenter c. The variable dij is the distance between die iand the defective die j. Parameter is the normalization factor for the distance between de- fective die jand the wafer centroid c. Parameter mis a constant. Parameter m determines the approximate density shape of the wafer. For example, Fig. 5shows an example of a mountain value (z-axis) derived from wafer bin map. The x-axis and y-axis represent the co- ordinate of a wafer (x, y). Through mountain method, the feature of clustering can be ampli- fied.Also,themountainvaluecanprovideprofileofspecificpatternas showninFig.6.Inparticular, Fig.6(a)and Fig.6(b)representthatthe different mountain value (z-axis) of different pattern. Fig. 6(a) and Fig. 6(c) represent that the different mountain value of different pat- tern density. Fig. 6(a) and Fig. 6(d) show that the different mountain valueofdifferentpatterndensity.Throughmodifiedmountainfunction for each WBM, it can show the difference among the WBM with dif- ferent factors pattern size, pattern density, and pattern shift. 3.3.2. Similaritycalculation IntheshapematchingofWBMs,Hausdorffdistancecouldbe"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_22", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 22, "text": " WBM, it can show the difference among the WBM with dif- ferent factors pattern size, pattern density, and pattern shift. 3.3.2. Similaritycalculation IntheshapematchingofWBMs,Hausdorffdistancecouldbesimply applied to determine the quality of matching between two patterns. ThroughHausdorffisdistanceissimpleincalculating,itissensitiveto degradation such as noise and occlusions. The modified Hausdorff distance (MHD) have been proposed to decrease the impact from out- liners, such as partial Hausdorff distance (Huttenlocher & Rucklidge, 1992)andweightedHausdorffdistance(WHD)(Lu,Tan,Huang,&Fan, 2001). Assume the set of defective die on the selected wafer is A, and the set of defective die on the compared WBM is B. The distance between twopoints a A and b B isdefinedas a b incityblockdistance. Thus the weighted MHD (WMHD) can be determined as follows: Fig. 3.Illustration of considered factors. (a) ESRN (b) TransformationTransformation Wafer rotation0¬∞ 90¬∞ 180 ¬∞ 270 ¬∞ Fig. 4.Illustration of WBM by data preparation. M(i) x y Fig. 5.Example of a mountain value derived from wafer bin map.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 5 (a) original (b) different defect "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_23", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 23, "text": "WBM by data preparation. M(i) x y Fig. 5.Example of a mountain value derived from wafer bin map.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 5 (a) original (b) different defect pattern (c) different size (d) different density M(i) x yM(i) x y M(i) x yM(i) x yFig. 6.Example of a mountain value with different defect pattern, size, and density level. (a) The selected WBM (b) The compared WBM (c) The matching process Fig. 7.Illustration of matching process between selected WBM and compared WBM. Table 1 The setting of weight and outlier score in similarity measurement. Outliner score Weight Without(O 0) With(O 1) No weight(N) N-O0 N-O1 Weight 1(W 1) W1-O0 W1-O1 Weight 2(W 2) W2-O0 W2-O1Table 2Confusion Matrix. System prediction Actual label Similar Dissimilar Similar True Positive (TP) True Negative (TN) Dissimilar False Positive (FP) False Negative (FN)C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 6 = √ó =hNa b A B( , )1min( ) AaN b Bab 1A(2) where the parameter ab is a weight for WMHD. Considering the fea- tures of WBM, this study proposed three types of weight design as follows: (a)Noweight:Onlyusespatialdistanceassimilaritymeasurement. =1 "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_24", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 24, "text": "re the parameter ab is a weight for WMHD. Considering the fea- tures of WBM, this study proposed three types of weight design as follows: (a)Noweight:Onlyusespatialdistanceassimilaritymeasurement. =1 ab (3) (b) Weight design 1: The mountain value is applied here as weight ab and ba. Denote mountain value of a is Ma , mountain value of b is Mb : =M M M M| | max( , )aba b a b (4) (c)WeightDesign 2:Naive matchingkernel(theclosestvalue)will certainly fail and results into many false matches. Hence not only the interest point but the corresponding close local features in the image space, in which ‚Äùthe neighborhood‚Äù should also be considered. Fig. 8.WBM database composition. Table 3 Simulation design. Pattern Yield high/lowNoise (+)Density(‚àí)Shift Rotation trail Total Random (R) 0.6‚Äì1.0 N/A N/A N/A N/A 190 760A H:0.82L:0.705%,10%, 15%10%, 20%, 30%N/A N/A 4 48 B H:0.87 L:0.685%,10%, 15%10%, 20%, 30%N/A 0¬∞ 75¬∞2 48 C H:0.94L:0.755%,10%, 15%10%, 20%, 30%0%,5%N/A 2 48 D H:0.82 L:0.745%,10%,15%10%, 20%,30%0%,5%0¬∞75¬∞1 48 Complex E,F H:0.64 L:0.575%, 10%, 15%10%, 20%, 30%N/A N/A 1 48 H:0.63 L:0.59 Fig. 9.10 Selected WBMs.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 7 Case "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_25", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 25, "text": ", 20%,30%0%,5%0¬∞75¬∞1 48 Complex E,F H:0.64 L:0.575%, 10%, 15%10%, 20%, 30%N/A N/A 1 48 H:0.63 L:0.59 Fig. 9.10 Selected WBMs.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 7 Case ROC Curve PI/Rank Plot 1 2 3 4 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI Fig. 10.Similarity matching comparison result for various selected WBMs.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 8 =+ + + + + + + +M M M M| | max( , )aba x p y q b x p y q a x p y q b x p y qp ( 1,0,1),j ( 1,0,1)( , ) ( , ) ( , ) ( , )(5) where(x,y)isthecoordinateonawafer,theparameters pandqdenote astheadjacentlocationofdie(x,y)byKing-move(Hsu&Chien,2007). To magnify the difference between two W"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_26", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 26, "text": ",1),j ( 1,0,1)( , ) ( , ) ( , ) ( , )(5) where(x,y)isthecoordinateonawafer,theparameters pandqdenote astheadjacentlocationofdie(x,y)byKing-move(Hsu&Chien,2007). To magnify the difference between two WBMs with outlier of de- fective die, we define the maximum matching tolerance as Sout . Two defectdiesbeabletomatchonlyifthespatialdistanceislessthan Sout , otherwise offer Sout as punishment. Fig. 7illustrates the matching processbetweenselectedWBMandthecomparedWBM. Fig.7(a)isthe selectedWBMand Fig.7(b)isthecomparedWBM.Inparticular,notall defective die on the selected are used for similarity measurement and onlyspatialdistanceiswithinthematchingtolerancewillbecountedas showninthe Fig.7(c).Assumingthereare No detectivedicewithlarge difference.Therefore,thesimilarbetweentwoWBMsisthesummaryof WMHDh(A,B) and outliner score ( √óN So out ). 9 10 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI 0 0.05 0.1 0.15 0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI Fig. 10.(continued) Table 4 Maximum PI for each selected WBM. Without outliner d"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_27", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 27, "text": "0.2 0.25 0.300.10.20.30.40.50.60.70.80.91 1-SpecificitySensitivity 0 50 100 150 20000.10.20.30.40.50.60.70.80.91 rankPI Fig. 10.(continued) Table 4 Maximum PI for each selected WBM. Without outliner detection With outliner detection W0 W1 W2 W0W1W2 Case1 0.962 0.968 0.983 1.000 1.000 1.000 Case2 0.942 0.946 0.962 1.000 1.000 1.000Case3 0.669 0.672 0.735 0.996 0.987 0.998 Case4 0.779 0.900 0.812 0.987 0.994 1.000 Case5 0.854 0.779 0.911 1.000 0.998 1.000Case6 0.726 0.865 0.772 0.987 0.992 0.987 Case7 0.935 0.866 0.979 1.000 0.979 0.979 Case8 0.965 0.964 0.955 0.935 0.954 0.965 Case9 0.935 0.829 0.979 1.000 1.000 1.000 Case10 0.922 0.860 0.933 0.940 0.964 0.970average 0.869 0.865 0.902 0.985 0.987 0.990 Table 5 Sensitivity under specificity = 90%. Specificity = 90% Without outliner detection With outliner detection W0 W1 W2 W0W1W2 Case1 100.0% 100.0% 100.0% 100.0% 100.0% 100.0% Case2 79.2% 81.3% 100.0% 100.0% 100.0% 100.0%Case3 16.7% 25.0% 58.3% 100.0% 100.0% 100.0% Case4 79.2% 66.7% 87.5% 100.0% 100.0% 100.0% Case5 83.3% 75.0% 54.2% 100.0% 100.0% 100.0% Case6 100.0% 100.0% 100.0% 95.8% 100.0% 100.0% Case7 91.7% 83.3% 91.7% 91.7% 100.0% 100.0% Case8 35.3% 85.3% 100.0% 100.0% 100.0% 1"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_28", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 28, "text": "5% 100.0% 100.0% 100.0% Case5 83.3% 75.0% 54.2% 100.0% 100.0% 100.0% Case6 100.0% 100.0% 100.0% 95.8% 100.0% 100.0% Case7 91.7% 83.3% 91.7% 91.7% 100.0% 100.0% Case8 35.3% 85.3% 100.0% 100.0% 100.0% 100.0% Case9 100.0% 100.0% 100.0% 100.0% 100.0% 100.0% Case10 100.0% 83.3% 100.0% 100.0% 100.0% 100.0%average 78.5% 80.0% 89.2% 98.8% 100.0% 100.0%Table 6 Specificity under sensitivity = 90%. Sensitivity = 90% Without outliner detection With outliner detection W0 W1 W2 W0W1W2 Case1 89.6% 89.6% 92.5% 100.0% 100.0% 100.0% Case2 92.5% 94.2% 97.1% 100.0% 100.0% 100.0%Case3 48.3% 46.7% 52.5% 99.2% 99.6% 100.0% Case4 83.3% 74.2% 87.5% 100.0% 99.6% 100.0% Case5 95.4% 94.6% 94.6% 92.1% 95.8% 97.5% Case6 59.2% 73.3% 69.6% 100.0% 100.0% 100.0% Case7 92.1% 86.7% 92.9% 92.9% 95.0% 95.8% Case8 85.0% 85.8% 94.2% 94.2% 95.0% 99.2% Case9 99.2% 99.6% 98.8% 99.6% 100.0% 100.0% Case10 90.8% 90.0% 93.3% 97.5% 100.0% 100.0%average 83.5% 83.5% 87.3% 97.6% 98.5% 99.3%C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 9 = + √ó S h N SA B A B( , ) ( , ) o out(6) Table 1summarizes the calculation strategy for weight design and outlier detection. The dissimilar score is the standard to measure two"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_29", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 29, "text": "ing 142 (2020) 106358 9 = + √ó S h N SA B A B( , ) ( , ) o out(6) Table 1summarizes the calculation strategy for weight design and outlier detection. The dissimilar score is the standard to measure two wafer bin map. Notice that, the smaller the dissimilar score presents two wafer bin maps is more similar. 3.4. Modelevaluation RanktheWBMsbydissimilarscoreinascendantorder.Basedonthe similar and dissimilar result between system predict and actual label, true-positive (TP), false-positive (FP), true-negative (TN), and false- negative (FN) are calculated as shown in Table 2. Sensitivity and Spe- cificity are used to evaluate the model. =+√ó SensitivityTP TP FN100% (7) =+√ó SpecificityTN FP TN100% (8) Theperformanceindex(PI)isdefinedasgeometricaveragebetween Sensitivity and Specificity: = √ó PI Sensitivity Specificity (9) With sensitivity as longitudinal axis and 1-specificity as horizontal axis, we are able to plot the receiver operating characteristic curve (ROC) curve. 4. Empirical study 4.1. Problemstructuring To validate the effectiveness of the proposed framework, but alsoobey the confidential clause with cooperate company, the data is si- mulatedandadjustformrealmanufacturingdata.The"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_30", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 30, "text": ". Problemstructuring To validate the effectiveness of the proposed framework, but alsoobey the confidential clause with cooperate company, the data is si- mulatedandadjustformrealmanufacturingdata.Thedatabaseconsists of1000WBMsand6majorpatternsasshownin Fig.8.Toapproximate the real situation, the database consists of 76% amounts of randompatterns (yield form 60%‚Äì100%), and 24% amounts of symmetric patterns. Since each pattern has different features, the considered factors including different number of defective die, noise degree, pattern density,degreeofpatternshiftandwaferrotation.Thefeaturescanbe described as edge-locate, symmetry, and complex. Consider different level of yield, noise, density, shift and rotation angle, the detail of si- mulation design for compared WBMs is shown in Table 3. Tobeabletofullydemonstrateinfluenceoffactorsforthesimilarity matching between WBMs including pattern size, noise degree, pattern density, pattern shift, and wafer rotation, we generate 10 selected WBMswithtwopatternsizeinhighyieldandlowyield,and10random defective die as shown in Fig. 9. Cases 1 and 2 represent the different patternsize.Thesimilarideaalsousesforcases3and4,cases5and6,cases 7 an"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_31", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 31, "text": "d WBMswithtwopatternsizeinhighyieldandlowyield,and10random defective die as shown in Fig. 9. Cases 1 and 2 represent the different patternsize.Thesimilarideaalsousesforcases3and4,cases5and6,cases 7 and 8. Cases 9 and 10 are used as complex WBMs with two defect patterns on a WBM. 4.2. Modelevaluationwithdifferentsettingsofweightandoutlierscore Fig. 10shows the ROC curves and PI/Rank plots of each selected WBM, the interval is every 10 rank, to evaluate the result form 6 WMHD design as shown in Table 1. According to the curve of PI in different rank, the optimal threshold of similar WBM can be de- termined. Based on the result of ROC curves in these 10 cases, the performanceofWBMsimilaritymatching(i.e.,N-O 0,W1-O0,W2-O0)by using no outlier detection factor Sout are worse than the method using outlier detection factor (N-O 1, W1-O1, W2-O1). According to Table 4, the WMHD which combines with outliner Fig. 11.Similarity matching result of Case 1. Fig. 12.Similarity matching result of Case 3.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 10 detection performs much better than which not detect the outliner. Hence,theoutlinerdetectionisbeneficialinSensitivityandSpecifi"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_32", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 32, "text": ".C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 10 detection performs much better than which not detect the outliner. Hence,theoutlinerdetectionisbeneficialinSensitivityandSpecificity enhancement. Another advantage of combining outliner detection is high ranking consistency. On the other hand, without outliner detec- tion,theperformancedeviatefromdifferenttestingcase,especiallythe case be impact with location change (shift, rotation) factor. Table4showsthemaximumPIvaluethatrevealstheweightdesign have great influence of system performance. Different weight design also results in different system validity. Overall evaluation, the weight design 2 (W 2-O1) is outperform the weight design 1 and no weight. Even though W 2-O1 is not the best on case 5 and 6, the PI still reach 0.95. Therefore, it can concludethat the W 2-O1is the optimal WMHD. The defect area of selected WBM have considering influence of systemperformance.Samepattern,thelargerthedefectarea(lowerthe yield),thebettertheanalysisresult.Thereasonisthespatialdistanceis one of measurement standard of the similarity level. In addition, the defectareaisalsoimpactinthescaleofmountainvalue.Thelargerthe defectare"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_33", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 33, "text": ",thebettertheanalysisresult.Thereasonisthespatialdistanceis one of measurement standard of the similarity level. In addition, the defectareaisalsoimpactinthescaleofmountainvalue.Thelargerthe defectareais,thelargerthedeviationofspatialdistanceandweightis. Thedifferenceoftwowaferbinmapscanbeemphasized.Astheresult, the defect pattern which yield low have better performance. Without outliner detection, the spatial distance dominates the si- milarity score, and have much greater impact than weight. Thus the performance of system is case by case. By combing the outliner detec- tion, the distance can be normalized and the performance of system is relatively stable and consistence. Table 5shows the analysis result of WBM similar matching under fixing the Specificity on 90%, examine the Sensitivity of system, with outlinerdetection,it'sabletoreach90%ofsensitivity. Table6presents theanalysisresultofWBMsimilarmatchingunderfixingtheSensitivityon90%.Table6alsoexaminestheSpecificity,whichtheerrorisunder 5% with outliner detection and weight design 2 (W 2-O1). The results indicates that system can precisely detect 90% of similar WBMs in the Fig. 15.Similarity matching result of Case 10. Fig. 13.S"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_34", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 34, "text": "nder 5% with outliner detection and weight design 2 (W 2-O1). The results indicates that system can precisely detect 90% of similar WBMs in the Fig. 15.Similarity matching result of Case 10. Fig. 13.Similarity matching result of Case 5. Fig. 14.Similarity matching result of Case 7.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 11 database when 10% of false alarm occurs, make under 5% error when the system detect 90% of similar WBMs. 4.3. DiscussionofWBMsimilaritymatching This section demonstrates and discuss the impact of each factor under different level by using visual inspection. We only present the W2-O1analysis result and 5 representative cases (Case1, Case3, Case5, Case7, and Case10) in rank 25. Fig.11showsthesimilaritymatchingresultofCase1.Theproposed method is able to precisely identify the similar WBMs with variouspattern size, pattern density, and noise degree (ex. #1AH01003, #11AH1004,and#22AL02001). Fig.12showsthesimilaritymatching resultofCase3anddemonstratethattheproposedmethodnotonlycan handlenoiseanddensity(ex.#1BH10001and#12BH20011),butalso able to deal with wafer rotation. The no rotation WBMs (i.e., rotation angle is 0¬∞) appeal more similar t"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_35", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 35, "text": "stratethattheproposedmethodnotonlycan handlenoiseanddensity(ex.#1BH10001and#12BH20011),butalso able to deal with wafer rotation. The no rotation WBMs (i.e., rotation angle is 0¬∞) appeal more similar to system than those rotated. The si- milaritymatchingresultofCase5isshownin Fig.13.Itshowsthatthe proposed method can detect not only the shifting defect patterns (ex.#12CH03102 and #22CH30101) but also the large pattern size with the same defect pattern (ex. #24CL03101 and #25CL01101). In parti- cular,thedefectpatternswithnoshiftstillhavesmallerrankthanthose WBMs with shift defect pattern. Fig. 14shows the similarity matching result of Case 7. It demonstrates that the performance of proposed method under the defect pattern with pattern shift and wafer rotate. Thefirst21WBMsin Fig.14aresimilarwithCase7.However,thereis some false-alarm at #22 to #25. The reason is the shape features ofselectedWBM(Case7)andthecomparedWBMs(#22to#25)havethe similarpatternofdefectivediewhicharebothlocatedinthemiddleof wafer.Additionally,theshapeseemslikearoundcircle.Case10isused to evaluate the capability of identifying similar complex patterns. Fig.15showsthattheproposedmethodcanidentifythemostofsimilar WB"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_36", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 36, "text": "iddleof wafer.Additionally,theshapeseemslikearoundcircle.Case10isused to evaluate the capability of identifying similar complex patterns. Fig.15showsthattheproposedmethodcanidentifythemostofsimilar WBMsexceptfor#25AL30004.Sincethecomplexpatterniscomposedby two different defect patterns, which were caused by two kinds of failure causes during the manufacturing process. In root cause identi- ficationbyWBManalysisinpractice,detectingonlyoneofthepatterns still can provide useful information for engineer to find the potential root cause. Simulationresultsdemonstratethattheproposedmodelcanprovide precisely similarity measurement between similar and dissimilar pat- tern. The similarity matching system proposed by this study have fol- lowing features: (1) The proposed WBM similarity matching method is able to identify the similar WBM by considering these five factors (pattern size, noisedegree,patterndensity,patternshift,andwaferrotation).The degreeofpatternsizeandpatternshifthavelargeimpactforWBM similarity matching. The pattern density and noise degree have small impact for similarity matching. (2) Two different patterns which have approximate defect size and location might incorrectly d"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_37", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 37, "text": "rWBM similarity matching. The pattern density and noise degree have small impact for similarity matching. (2) Two different patterns which have approximate defect size and location might incorrectly determine as similar patterns. It might express that the proposed similarity matching method can process considering non-rigid deformation. (3) The proposed WBM similarity matching method is efficiently Fig. 16.Interface of intelligent WBM similarity matching system.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 12 screened out the random patterns while identifying the similar WBM with low false alarm. This study design the database and testing case considering the patterns which are common to fab (Patterns A and C), the patterns which are very rare in amount and have no symmetry appearance (PatternsBandD),andrelativelyrarecomplexpatterns(PatternsEand F). Therefore, the system is capable to analysis most of realistic situa- tions. Furthermore, the proposed WBM similarity matching has been embeddedintoadecisionsupportsystemandhasbeenimplementedin asemiconductorcompanyinTaiwan. Fig.16showstheinterfaceofthe developed system of WBM similarity matching. This decision sup"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_38", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 38, "text": "y matching has been embeddedintoadecisionsupportsystemandhasbeenimplementedin asemiconductorcompanyinTaiwan. Fig.16showstheinterfaceofthe developed system of WBM similarity matching. This decision supportsystem of WBM similarity matching can assist engineers to identify defect patterns efficiently and thus diagnose the root cause of defect pattern effectively to improve quick response for smart production. 5. Conclusion To address the needs to deal with new defect patterns, this study developed an approach of measuring the similarity among wafer bin mapsthatcanaccuratelydeterminethesimilarleveldespitesize,noise, density, shift, and rotation issue. A decision support system embedded with the developed similarity matching algorithms is also constructed to provide an effective method to empower human judgments of the engineers, as proposed in Industry 3.5. Comparing with existing ap- proaches for WBM analysis, the proposed similarity matching can achievehigherperformanceonfailureanalysisthanpatternrecognition and classification, especially in advanced technologies foe semi- conductor manufacturing. Moreover, the developed system does not need to pre-define the pattern categories, nor "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_39", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 39, "text": "hanpatternrecognition and classification, especially in advanced technologies foe semi- conductor manufacturing. Moreover, the developed system does not need to pre-define the pattern categories, nor need to train the model withhugehistoricaldata.Moreover,thesimilarityalsoprovidesaclue to define a newly discovered pattern that may be closer to some ofexisting patterns to support root cause diagnosis. Futureresearchcanbedonetoenforcethedatalinkagebetweenthe developed system and manufacturing process data, increase the effi- ciency and automatic level of failure analysis. Further study should be done to improve the functions and control rules generated from the proposed framework through lessons learned from implementation in real settings. Similar approaches can be done for other problems to empower the engineers for analysis and decision making involved for smart production. CRediT authorship contribution statement Chia-Yu Hsu: Conceptualization, Methodology, Writing - original draft, Writing - review & editing, Resources, Supervision, Project ad- ministration. Wei-JuChen: Investigation,Validation,Writing-original draft.Ju-Chien Chien: Data curation, Visualization, Formal analysis."}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_40", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 40, "text": "Writing - review & editing, Resources, Supervision, Project ad- ministration. Wei-JuChen: Investigation,Validation,Writing-original draft.Ju-Chien Chien: Data curation, Visualization, Formal analysis. Acknowledgements This research is supported by Ministry of Science and Technology, Taiwan ((MOST106-2628-E-027-002-MY3; MOST108-2813-C-027-017- E). References Baly, R., & Hajj, H. (2012). Wafer classification using support vector machines. IEEE TransactionsonSemiconductorManufacturing,25(3), 373‚Äì383. Chao,L.-C.,&Tong,L.-I.(2009).Waferdefectpatternrecognitionbymulti-classsupport vector machines by using a novel defect cluster index. ExpertSystemswith Applications,36(6), 10158‚Äì10167. Chien, C.F.,Dou,R.,&Fu,W.(2018).Strategiccapacityplanningforsmartproduction: Decision modeling under demand uncertainty. AppliedSoftComputing,68, 900‚Äì909. Chien,C.-F.,&Hsu,C.-Y.(2006).Anovelmethodfordeterminingmachinesubgroupsand backups with an empirical study for semiconductor manufacturing. Journalof IntelligentManufacturing,17(4), 429‚Äì439.Chien, C.-F., & Hsu, C.-Y. (2011). UNISON analysis to model and reduce step-and-scan overlay errors forsemiconductor manufacturing. JournalofIntelligentManufacturing, "}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_41", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 41, "text": "gentManufacturing,17(4), 429‚Äì439.Chien, C.-F., & Hsu, C.-Y. (2011). UNISON analysis to model and reduce step-and-scan overlay errors forsemiconductor manufacturing. JournalofIntelligentManufacturing, 22(3), 399‚Äì412. Chien, C.-F., & Hsu, C.-Y. (2014). Data mining for optimizing IC feature designs to en- hance overall wafer effectiveness. IEEETransactionsonSemiconductorManufacturing, 27(1), 71‚Äì82. Chien, C.-F., & Chuang, S.-C. (2014). A framework for root cause detection of sub-batch processing system for semiconductor manufacturing big data analytics. IEEE TransactionsonSemiconductorManufacturing,27(4), 475‚Äì488. Chien, C.-F., Chen, Y.-J., & Peng, J.-T. (2010). Manufacturing intelligence for semi- conductor demand forecast based on technology diffusion and product life cycle. InternationalJournalofProductionEconomics,128(2), 496‚Äì509. Chien, C.-F., Chou, C.-W., & Yu, H.-C. (2016). A Novel route selection and resource al- location approach to improve the efficiency of manual material handling system in200-mm wafer fabs for industry 3.5. IEEETransactionsonAutomationScienceand Engineering,13(4), 1567‚Äì1580. Chien, C.-F., Hong, T.-Y., & Guo, H.-Z. (2017). An empirical study for smart produ"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_42", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 42, "text": "ing system in200-mm wafer fabs for industry 3.5. IEEETransactionsonAutomationScienceand Engineering,13(4), 1567‚Äì1580. Chien, C.-F., Hong, T.-Y., & Guo, H.-Z. (2017). An empirical study for smart production for TFT-LCD to empower Industry 3.5. JournaloftheChineseInstituteofEngineers, 40(7), 552‚Äì561. Chien, C.-F., Hsu, C.-Y., & Hsiao, C. (2012). Manufacturing intelligence to forecast and reduce semiconductor cycle time. JournalofIntelligentManufacturing,23(6), 2281‚Äì2294. Chien, C.-F., Hsu, C.-Y., & Chen, P.-L. (2013). Semiconductor fault detection and classi- fication for yield enhancement and manufacturing intelligence. FlexibleServicesand ManufacturingJournal,25(3), 367‚Äì388. Chien, C.-F., Hsu, S.-C., & Chen, Y.-J. (2013). A system for online detection and classi- ficationofwaferbinmapdefectpatternsformanufacturingintelligence. International JournalofProductionResearch,51(8), 2324‚Äì2338. Chien,C.-F.,Liu,C.-W.,&Chuang,S.-C.(2017).Analysingsemiconductormanufacturing big data for root cause detection of excursion for yield enhancement. International JournalofProductionResearch,55(17), 5095‚Äì5107. Dou, R., Chien, C. F., Kacem, I., & Hsu, C. Y. (2018). Industry applications of computa- tio"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_43", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 43, "text": " detection of excursion for yield enhancement. International JournalofProductionResearch,55(17), 5095‚Äì5107. Dou, R., Chien, C. F., Kacem, I., & Hsu, C. Y. (2018). Industry applications of computa- tionalintelligence:Preface. InternationalJournalofComputationalIntelligenceSystems, 11(1), 803‚Äì804. Dou,R.,He,Z.,&Hsu,C.Y.(2018).Foreword:Smartmanufacturing,innovativeproduct and servicedesignto empowerIndustry4.0. Computers&IndustrialEngineering,125, 514‚Äì516. Hsu, S.-C., & Chien, C.-F. (2007). Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing. International JournalofProductionEconomics,107(1), 88‚Äì103. Huttenlocher, D. P. & Rucklidge, W. J. (1992). A multi-resolution technique for com- paring images using the Hausdorff distance. In: Cornell University. Khakifirooz, M., Chien, C.-F., & Chen, Y.-J. (2018). Bayesian inference for mining semi- conductor manufacturing big data for yield enhancement and smart production to empower industry 4.0. AppliedSoftComputing,68, 990‚Äì999. Kuo, C.-J., Chien, C.-F., & Chen, C.-D. (2011). Manufacturing intelligence to exploit the value of production and tool data to reduce cycle time. IEEETr"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_44", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 44, "text": "industry 4.0. AppliedSoftComputing,68, 990‚Äì999. Kuo, C.-J., Chien, C.-F., & Chen, C.-D. (2011). Manufacturing intelligence to exploit the value of production and tool data to reduce cycle time. IEEETransactionson AutomationScienceandEngineering,8(1), 103‚Äì111. Li, T.-S., & Huang, C.-L. (2009). Defect spatial pattern recognition using a hybrid SOM‚ÄìSVM approach in semiconductor manufacturing. ExpertSystemswith Applications,36(1), 374‚Äì385. Liao, C.-S., Hsieh, T.-J., Huang, Y.-S., & Chien, C.-F. (2014). Similarity searching for defective wafer bin maps in semiconductor manufacturing. IEEETransactionson AutomationScienceandEngineering,11(3), 953‚Äì960. Liu, C.-W., & Chien, C.-F. (2013). An intelligent system for wafer bin map defect diag- nosis: An empirical study for semiconductor manufacturing. EngineeringApplications ofArtificialIntelligence,26(5‚Äì6), 1479‚Äì1486. Liu, S., Chen, F., & Lu, W. (2002). Wafer bin map recognition using a neural network approach.InternationalJournalofProductionResearch,40(10), 2207‚Äì2223. Lu, Y., Tan, C. L., Huang, W., & Fan, L. (2001). An approach to word image matching basedonweightedHausdorffdistance. Proceedingsofsixthinternationalconferenceon documentanalysi"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_45", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 45, "text": "rch,40(10), 2207‚Äì2223. Lu, Y., Tan, C. L., Huang, W., & Fan, L. (2001). An approach to word image matching basedonweightedHausdorffdistance. Proceedingsofsixthinternationalconferenceon documentanalysisandrecognition (pp. 921‚Äì925). IEEE. Nakazawa, T., & Kulkarni, D. V. (2018). Wafer map defect pattern classification and image retrieval using convolutional neural network. IEEETransactionson SemiconductorManufacturing,31(2), 309‚Äì314. Nakazawa, T., & Kulkarni, D. V. (2019). Anomaly detection and segmentation for wafer defect patterns using deep convolutional encoder‚Äìdecoder neural network archi- tectures in semiconductor manufacturing. IEEETransactionsonSemiconductor Manufacturing,32(2), 250‚Äì256. Piao,M., Jin,C.H.,Lee, J.Y.,& Byun,J.Y.(2018).Decision treeensemble-basedwafer map failure pattern recognition based on radon transform-based features. IEEE TransactionsonSemiconductorManufacturing,31(2), 250‚Äì257. Saqlain,M.,Jargalsaikhan,B.,&Lee,J.Y.(2019).Avotingensembleclassifierforwafer mapdefectpatternsidentificationinsemiconductormanufacturing. IEEETransactions onSemiconductorManufacturing,32(2), 171‚Äì182. Taam,W.,&Hamada,M.(1993).Detectingspatialeffectsfromfactorialexperiments:An applica"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_46", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 46, "text": "ectpatternsidentificationinsemiconductormanufacturing. IEEETransactions onSemiconductorManufacturing,32(2), 171‚Äì182. Taam,W.,&Hamada,M.(1993).Detectingspatialeffectsfromfactorialexperiments:An application from integrated-circuit manufacturing. Technometrics,35(2), 149‚Äì160. Wang, C.-H. (2008). Recognition of semiconductor defect patterns using spatial filtering and spectral clustering. ExpertSystemswithApplications,34(3), 1914‚Äì1923. Wang, C.-H., Kuo, W., & Bensmail, H. (2006). Detection and classification of defect patterns on semiconductor wafers. IIETransactions,38(12), 1059‚Äì1068. Wu,M.J.,Jang,J.S.R.,&Chen,J.L.(2015).Wafermapfailurepatternrecognitionand similarity ranking for large-scale data sets. IEEETransactionsonSemiconductor Manufacturing,28(1), 1‚Äì12. Yager,R.R.,&Filev,D.P.(1994).Approximateclusteringviathemountainmethod. IEEE TransactionsonSystems,Man,andCybernetics,24(8), 1279‚Äì1284.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 13 Yang, M.-S., & Wu, K.-L. (2005). A modified mountain clustering algorithm. Pattern AnalysisandApplications,8(1‚Äì2), 125‚Äì138. Yu,J.,&Lu,X.(2016).Wafermapdefectdetectionandrecognitionusingjointlocaland nonlocal linear discriminan"}
{"id": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf::chunk_47", "source": "Similarity matching of wafer bin maps for manufacturing intelligence.pdf", "chunk_index": 47, "text": "2005). A modified mountain clustering algorithm. Pattern AnalysisandApplications,8(1‚Äì2), 125‚Äì138. Yu,J.,&Lu,X.(2016).Wafermapdefectdetectionandrecognitionusingjointlocaland nonlocal linear discriminant analysis. IEEETransactionsonSemiconductor Manufacturing,29(1), 33‚Äì43. Yu, J., Zheng, X., & Liu, J. (2019). Stacked convolutional sparse denoising auto-encoder for identification of defect patterns in semiconductor wafer map. ComputersinIndustry,109, 121‚Äì133. Yuan, T., Bae, S. J., & Park, J. I. (2010). Bayesian spatial defect pattern recognition in semiconductorfabricationusingsupportvectorclustering. TheInternationalJournalof AdvancedManufacturingTechnology,51(5‚Äì8), 671‚Äì683. Yuan, T., Kuo, W., & Bae, S. J. (2011). Detection of spatial defect patterns generated in semiconductor fabrication processes. IEEETransactionsonSemiconductor Manufacturing,24(3), 392‚Äì403.C.-Y.Hsu,etal. Computers & Industrial Engineering 142 (2020) 106358 14"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_0", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 0, "text": "IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 953 [13] N. Brahimi, S. Dauzere-Peres, N. Najid, and A. Nordli, ‚ÄúSingle item lot sizing problems,‚Äù Eur. J. Oper. Res. , vol. 168, pp. 1‚Äì16, 2006. [14] G. Bitran and H. Yanasse, ‚ÄúComputational complexity of the capaci- tated lot size problem,‚Äù Manag. Sci. , vol. 28, pp. 1174‚Äì1186, 1982. [15] A. Akbalik and C. Rapine, ‚ÄúPolynomial time algorithms for the con- stant capacitated single-item lot sizing problem with stepwise produc-tion cost,‚Äù Oper. Res. Lett. , vol. 40, pp. 390‚Äì397, 2012. [16] M. Florian, J. Lenstra, and A. Rinnooy Kan, ‚ÄúDeterministic produc- tion planning: Algorithms and complexity,‚Äù Manag. Sci. , vol. 26, pp. 669‚Äì679, 1980. [17] Y. Pochet and L. Wolsey, ‚ÄúLot-sizing with constant batches: Formula- tions and valid inequalities,‚Äù Math. Oper. Res. , vol. 18, pp. 767‚Äì785, 1993. [18] C. van Hoesel and A. Wagelmans, ‚ÄúAn algorithm for the eco- nomic lotsizing problem with constant capacities,‚Äù Manag. Sci. , vol. 42, pp. 142‚Äì150, 1996. Similarity Searching for De fective Wafer Bin Maps in Semiconductor Manufacturing Chung-Shou Liao ,M e m b e r ,I E E E , Tsung-Jung Hsieh, Yu-Syuan Huang, and Che"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_1", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 1, "text": ". Sci. , vol. 42, pp. 142‚Äì150, 1996. Similarity Searching for De fective Wafer Bin Maps in Semiconductor Manufacturing Chung-Shou Liao ,M e m b e r ,I E E E , Tsung-Jung Hsieh, Yu-Syuan Huang, and Chen-Fu Chien , Member, IEEE Abstract‚Äî Because high-dimensional waf er bin maps (WBMs) cause var- ious features, it is dif Ô¨Åcult to search the similarity among WBMs via con- ventional pattern recognition metho ds. This study develops a novel mor- phology-based support vector machine f or defective wafer detection. The experimental results demonstrate it s usefulness in yield improvements on precision and computation cost. Note to Practitioners ‚ÄîSemiconductor manufacturing in complicated nanotechnology is facing tough cha llenge for quick response to yield excursion for shortening time to market and reducing the cost to maintaincompetitive advantages. Due to the in creasing complexity of nanotech- nology for wafer fabrication, increasingly high inspection costs and yieldloss associated with defective waf ers have become a critical concern of semiconductor manufacturers. Focused on real settings of practicalindustrial experiments, this study provides a novel approach to searchingsimilar WBM"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_2", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 2, "text": "fective waf ers have become a critical concern of semiconductor manufacturers. Focused on real settings of practicalindustrial experiments, this study provides a novel approach to searchingsimilar WBMs from huge wafer spatial data to quickly identify potentialcauses for yield enhancement. This approach was validated in real settingin Taiwan and the results showed its practical viability. Index Terms‚Äî Data mining, morphology, sem iconductor manufacturing, similarity search, support vector machines, wafer bin maps. I. INTRODUCTION With increasingly sophisticated manufacturing processes in the semiconductor industry, the cost to m igrate the required techniques Manuscript received May 02, 2013; a ccepted July 15, 2013. Date of pub- lication August 29, 2013; date of current version June 30, 2014. This paperwas recommended for publication by Associate Editor S. Zhou and Editor H.Ding upon evaluation of the reviewers‚Äô comments. This work was supportedby the Advanced Manufacturing and Ser vice Management Research Center, National Tsing Hua University under Toward World-Class Universities Projects101N2073E1, 101N2074E1 and the National Science Council of Taiwan underGrant NSC100-2221-E-007"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_3", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 3, "text": "e Management Research Center, National Tsing Hua University under Toward World-Class Universities Projects101N2073E1, 101N2074E1 and the National Science Council of Taiwan underGrant NSC100-2221-E-007-108-MY3, Grant NSC100-2628-E-007-017-MY3,and Grant NSC102-2221-E-007-075-MY3. (Corresponding author: C.-S. Liao.) The authors are with the Department of Industrial Engineering and Engineering Management, National Tsing Hua University, Hsinchu 300,Taiwan (e-mail: csliao@ie.nthu.e du.tw; tsungjung.hsieh@gmail.com; s9934519@m99.nthu.edu.tw; cfchien@mx.nthu.edu.tw). Color versions of one or more of the Ô¨Ågures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identi Ô¨Åer 10.1109/TASE.2013.2277603 Fig. 1. An example of defective wafer bin maps: functional bins; defective bins. adds substantially to semiconductor production costs. Indeed, for the semiconductor industry as wafer production and size continues togrow, the volume of in-line and off-line data required to diagnose yield conditions is growing exponentially. Furthermore, high-volume wafer fabrication facilities typically produce thousands of wafersper week, and many of these wafers are inspected and fou"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_4", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 4, "text": " diagnose yield conditions is growing exponentially. Furthermore, high-volume wafer fabrication facilities typically produce thousands of wafersper week, and many of these wafers are inspected and found to be defective [1], [2], [3]. In this scenario, yield improvement is critically important, as is maintaining competitive processes and low die costsfor semiconductor wafers in a fabrication facility. During the Ô¨Ånal process of wafer fabrication, Circuit Probe (CP) test will determine whether the corresponding die is good for packaginginto chip. Spatial patterns of testing results are WBMs that provide crucial information to identify process failures, as illustrated in Fig. 1. These patterns are formed by mark ing the defective wafers, so that manufacturing engineers may use the patterns of WBMs as clues to investigate the causes of failures resulting in yield losses. As there are many WBMs to be evaluated, the judgments in semiconductor manu-facturing thus far still rely on human labor. As a result, the judgments may be inconsistent owing to human factors (e.g., fatigue) because of the substantial workload. In particular, not only should the defective dies be detected before packag"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_5", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 5, "text": ". As a result, the judgments may be inconsistent owing to human factors (e.g., fatigue) because of the substantial workload. In particular, not only should the defective dies be detected before package, but assignable causes should also be attributed to reduce yield and pro Ô¨Åt loss due to scrapped wafers. During the CP test, wafers are inspected by retrieving information about defect patterns [4]. More pre- cisely, WBM patterns can provide information to help better monitor the processes and products. The WBMs , in many cases, contain charac- teristic patterns, or signatures, which provide insight into the Ô¨Åtness of the manufacturing processes. A bin can be conceptualized as a bucket and viewed by mapping the results of these electrical tests onto a 2-Dspace. These defective patterns are usually associated with speci Ô¨Åcm a n - ufacturing problems, and can provi de process and product engineers with important clues regarding the identi Ô¨Åcation of causes and their so- lutions in order to improve yields [5]. Stapper [6] indicated that defects are typically clustered, rather than dispersed randomly over a wafer,and that these clusters become more ev ident as the wafer size increases. I"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_6", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 6, "text": " improve yields [5]. Stapper [6] indicated that defects are typically clustered, rather than dispersed randomly over a wafer,and that these clusters become more ev ident as the wafer size increases. In the literature, the three proposed approaches to solving the pattern recognition problem are stated as: the s tatistical approach, the heuristic approach, and the simulation approach [7]. The statistical approach classi Ô¨Åes patterns based on an extracted feature set, and an underlying statistical model for generating these patterns. The heuristic approach 1545-5955 ¬© 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publi cations/rights/index.ht ml for more information. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. 954 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 utilizes soft computing schemes, such as genetic algorithms andfuzzy sets, to perform pattern recognition pr ocesses. However, genetic sys- tems typically require expensive evaluation processes to a"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_7", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 7, "text": "4 utilizes soft computing schemes, such as genetic algorithms andfuzzy sets, to perform pattern recognition pr ocesses. However, genetic sys- tems typically require expensive evaluation processes to achieve an op- timal solution [8]. Furthermore, a ma jor limitation of the fuzzy logic controller is that it requires that suitable linguistic control rules are gen- erated, as well as the knowledge and experience of human experts [9]. The simulation approach emulates the computational paradigm of a bi-ological system, subsequent ly leading to a class of arti Ô¨Åcial neural sys- tems, termed neural networks [7], [10], [11]. However, the main d raw- back of neural networks is their inability to determine the number of layers and number of neurons per layer [12]. To improve upon this in- sufÔ¨Åciency of neural networks, support vector machines (SVM )w e r e proposed in 1995 [13] and have been widely used for pattern recogni- tion in recent years. Several studies noted that SVM classi Ô¨Åcation was more accurate than previous classi Ô¨Åcation algorit hms [14], [15]. Our Contribution: In this work, we propose a morphology-based SVM (MSVM) similarity searching method to generate wafer samples with c"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_8", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 8, "text": "more accurate than previous classi Ô¨Åcation algorit hms [14], [15]. Our Contribution: In this work, we propose a morphology-based SVM (MSVM) similarity searching method to generate wafer samples with certain degrees of similarity, as compared to the objective target wafer maps . From a practical perspective, the failure patterns of defec- tive wafers are increasingly complex, and possess the characteristics of bin rotation, so traditional pattern rec ognition methods cannot be adapted to address this problem. Nevertheless, we collaborated with the industry, and provide the MSVM as an alternative for achieving high-precision detection, thereby lowe ring costs and saving time. The rest of this paper is organized as follows. Section II describes the problem. Section III presents the central concept of our mor- phology-based SVM approach. Section IV shows experimental results to demonstrate the usefulness of our approach. Finally, we conclude with some discussions and future work in Sections V and VI. II. T HEINVESTIGATED PROBLEM A. Problem Description The similarity search of defective wafer patterns in this work mainly addresses two problems as follows. First, the traditional pa ttern"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_9", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 9, "text": "s V and VI. II. T HEINVESTIGATED PROBLEM A. Problem Description The similarity search of defective wafer patterns in this work mainly addresses two problems as follows. First, the traditional pa ttern recognition or classi Ô¨Åcation methods can not easily recognize complex patterns due to the increasing variety of defective wafers. In particular, a slight change of bins can form a to-tally different defective pattern from its original. Furthermore, as the wafer size increases, the WBMs will extend from both -a n d -axes directions, causing the defective portions to show a square growth aswell. Thus, the problem of complexity grows quadratically, since the bin maps with higher dimensions may have a great deal of variation, and further generate several more complicated wafer maps, such as inthe case of ‚Äúmap group movement,‚Äù which may have a high degree of similarity to the wafer maps. Consequently, owing to the high-dimen- sional bin map, it is extremely dif Ô¨Åcult to capture the variations of each dimension. Second, the problem is that the wafer samples in stock from fab- ricators are costly and limited; besides, the types of defective waferare too numerous to collect. This problem res"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_10", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 10, "text": " of each dimension. Second, the problem is that the wafer samples in stock from fab- ricators are costly and limited; besides, the types of defective waferare too numerous to collect. This problem results in inaccurate deci- sions by such machine learning methods as ART [16], SOM [17], SVM [17], [18], etc., when using insuf Ô¨Åcient training samples. Because more functional wafers possess more prec ise designs, it is vital to consider possible changes in small areas of the wafers. In this case, under the high-dimensional WBMs, a small ch ange may form a completely dif- ferent wafer type, making it dif Ô¨Åcult to discover differences via tradi- tional pattern recognition techniques and classi Ô¨Åcation methods. Thus, in order to reduce the inspection cost for a large volume of productivity,it is necessary to generate representative wafer samples with the orig- inal characteristics. Based on the above reasons, we construct morphological training samples for the SVM learning procedure in suf Ô¨Åcient quantities ef Ô¨Å- Fig. 2. Flowchart of the proposed MSVM. ciently, and avoid excessive expense in sample sources. Also, for the high-dimensional bin maps, a preprocessing scale normalization de- v"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_11", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 11, "text": "ient quantities ef Ô¨Å- Fig. 2. Flowchart of the proposed MSVM. ciently, and avoid excessive expense in sample sources. Also, for the high-dimensional bin maps, a preprocessing scale normalization de- veloped in collaboration with the industry is incorporated into the pro-cedure of wafer generation, so that the size of wafer bin maps in the training phase is consistent. B. Problem Resolving Flowchart The proposed morphology-based support vector machine (MSVM) for similarity searching will generate wafer samples with various cer- tain degrees of similarity, as compared to the objective target wafer maps . The implementation Ô¨Çowchart of the MSVM is illustrated in Fig. 2. First, we obtain a target wafer map as the target that has gone through normalization preprocessing; then, t o directly extract more feature in- formation from the target wafer map, the MSVM tool combines with morphology to generate various wafer patterns. These simulated waferfeatures, based on morphology, provide for several types, including di- lation, erosion, opening, closing, position shift, density change and ro- tation with variations, with respect to the target wafer map, which willbe introduced in more detail"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_12", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 12, "text": "eral types, including di- lation, erosion, opening, closing, position shift, density change and ro- tation with variations, with respect to the target wafer map, which willbe introduced in more detail later. Next, the generated training samples contain both similar and dis- similar wafer maps; the former is a reference based on domain ex-perts, and the latter is derived through a Ô¨Åltering process, which uses One-Class SVM to exclude possible similar samples, so as to ensure a high quality training phase in SVM. Recent research [18] has pre-sented a recognition system using SVM with a defect cluster index to efÔ¨Åciently and accurately recognize wafer defect patterns. The cluster index was designed to transform the information regarding the propor-tion of wafer defects into a numerical expression, and used them as the SVM inputs. However, when more complex and high-dimensional wafer patterns are considered, more aspects for pattern extraction forSVM must be included. Based on the morphological training data from theÔ¨Årst phase, SVM will categorize the testing samples into groups with respect to the given target wafer. In so doing, the proposed sim-ilarity search method employs the SVM "}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_13", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 13, "text": "gical training data from theÔ¨Årst phase, SVM will categorize the testing samples into groups with respect to the given target wafer. In so doing, the proposed sim-ilarity search method employs the SVM trained by morphology gen- erating samples, which can search for defective wafers as well as the corresponding causes of their defects, depending on the process engi-neers‚Äô demands. III. M ETHODOLOGY Each wafer may have fabricated from several hundred to several thousand dies on its surface. A typical WBM usually contains a numberof dies failed in different functional t ests. For visualization and analysis Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 955 Fig. 3. An illustration of morphology-based samples. Fig. 4. The structure element in morphology (a) with respect to a wafer bin (b) inÔ¨Çuential elements. purposes, WBM is usually transfor med into a binary map and binary code, or two different colors are used for representation. This work uses red squares, or 1, to denote defective chips, and yellow squares"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_14", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 14, "text": "ses, WBM is usually transfor med into a binary map and binary code, or two different colors are used for representation. This work uses red squares, or 1, to denote defective chips, and yellow squares,or 0, to denote functional chips. Next, we highlight the methods used in the proposed MSVM, including morphological sample generation, One-Class SVM sample Ô¨Ålter, and a brief description of the training tool, SVM. A. Morphology-Based Sample Generation Morphology was Ô¨Årst proposed by Matheron and Serra [19] in 1968. Originally, morphology was employe d in mathematics; current mor- phology is extended to several aspects in image processing. The con- cept and operations of morphology we used are illustrated in Figs. 3, 5, and 6. In addition to the Ô¨Åve common features, we propose two new morphological methods for sample generation in order to adapt to changeable patterns of complex WBMs. Erosion :E a c hc h i po rb i nc a nb ev i e w e da sa structural element (SE), a ss h o w ni nF i g .4 ( a ) ,w h i c hi sf o r m e db ya3 3 matrix. In the erosion operation, we focus on a speci Ô¨Åc region and locate each considered bin at position P5, which denotes whether conserving P5 (the bin) isdecid"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_15", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 15, "text": "a ) ,w h i c hi sf o r m e db ya3 3 matrix. In the erosion operation, we focus on a speci Ô¨Åc region and locate each considered bin at position P5, which denotes whether conserving P5 (the bin) isdecided by some elements (bins) directly connecting to P5, i.e., , , 4, 6, and 8. These elements are called inÔ¨Çuential elements (IE), as shown in Fig. 4(b). The effect of erosion is to make the image structure thin and sparse (see Fig. 3). Equation (1) shows the erosion operation (1) where denotes the original image, and SEdenotes structural ele- ments. Note that if a defective element is surrounded by defective IE , that element becomes func tional (set as 0). Each bin is subjected to the erosion operation independently, i.e., all elementsmust be viewed under original conditions when erosion is applied. Theparameter can be set by the user in order to apply the effects of slight or heavy erosion. Dilation : The dilation operation is the opposite of the erosion oper- ation, and is described as (2) (2) Similarly, is the original image, and SE refers to the structural ele- ments. An illustration is shown in Fig. 3. According to (2), as long as adefective element is surrounded by at least one d"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_16", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 16, "text": "2) (2) Similarly, is the original image, and SE refers to the structural ele- ments. An illustration is shown in Fig. 3. According to (2), as long as adefective element is surrounded by at least one defective IE, the whole IE becomes defective (set as 1). Again, each chip performs the oper- ation independently; that is, the defective IEs must be viewed underoriginal conditions when the dilation operation is initiated. Opening : The opening operation is designed to make the original pat- tern thinner, connecting or noncontinuous; also, the image could havea smoother contour (see Fig. 3). Opening is realized by Ô¨Årst performing erosion, and then dilation. The opening operation is shown in (3) (3) Closing : The closing operation is opposite to opening. The effect of closing is to Ô¨Åll up or thicken the thinner portions or portions that appear to be noncontinuous. The corresponding column in Fig. 3 shows several connected portions become th icker and are connected after the closing operation. Closing can be realized by performing dilation Ô¨Årst, and then erosion. This is shown in (4) (4) Shift: In order to generate the effect of pattern movement, the shift operation is considered for samp"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_17", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 17, "text": ". Closing can be realized by performing dilation Ô¨Årst, and then erosion. This is shown in (4) (4) Shift: In order to generate the effect of pattern movement, the shift operation is considered for sample generation. According to the ob- servation of domain experts, the patterns of WBMs may exhibit group movement, and this movement will also have high degree of similarityto the original (target) wafer map (i.e., the target wafer map); SVM is likely to have an incorrect judgm ent because it is based on the oppo- site position of two extremely different classes in the sample space, andthen separates the sample points. Ther efore, pattern shift is an essential method of sample generation in the context of using SVM in WBM. In this work, the shift direction is designed for eight positions: right, left,upper, down, upper right, lower right, upper left, and lower left. The shift size is also an adjustable parameter. In this case, the WBMs can move with a preset direction and range. Fig. 3 shows that the innerchips shift down for three steps (bins). In addition, two other morphology-based operations are suggested by domain experts as follows. Rotation : Due to a lack of constant positions o"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_18", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 18, "text": "s that the innerchips shift down for three steps (bins). In addition, two other morphology-based operations are suggested by domain experts as follows. Rotation : Due to a lack of constant positions or directions for wafer placement during the detection process, it is essential to determine the problem with the training error caused by incorrect correspondingplacement. In this case, we use the p rinciple of polar coordinates to generate the training samples with various rotation angles, where all bins rotate around the center in a preset counterclockwise angle within0 to 360 . Fig. 5 shows that each chip rotates 90 counterclockwise around the center. Density change : If we could dictate that one or more speci Ô¨ÅcW B M areas will have different density, it would be convenient to modify the generated samples with many forms. More precisely, we cut the wafer into an grid (here, , depending on users), and the se- lected bins in a speci Ô¨Åc grid have the following three options for den- sity change: increase, decrease a nd random. For example, suppose that equals 9, the degree of density change is 0.3 (this value is within 0 to 1), and we intend to increase/dec rease/randomize the density"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_19", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 19, "text": "change: increase, decrease a nd random. For example, suppose that equals 9, the degree of density change is 0.3 (this value is within 0 to 1), and we intend to increase/dec rease/randomize the density of the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. 956 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 Fig. 5. An illustration of Rotation (a) The original wafer (b) 90 counterclock- wise rotation. Fig. 6. An illustration of density change. center grid (see Fig. 6), then 30% of bins in that grid will set 1/0/ 0‚Äì1 normal distribution. We brie Ô¨Çy summarize that the above seven morphological opera- tions can be divided into two groups. The Ô¨Årst group consists of the common existing methods, erosion, dilation, opening, closing and shift; the remainder includes our novel methods, rotation anddensity change . B. Sample Filtering Utilizing One-Class SVM One-class classi Ô¨Åcation techniques are par ticularly useful in cases of two-class learning problems, whereby one of the classes, referred to as thetarget class , is well-sampled, whereas the other one, referr"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_20", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 20, "text": " classi Ô¨Åcation techniques are par ticularly useful in cases of two-class learning problems, whereby one of the classes, referred to as thetarget class , is well-sampled, whereas the other one, referred to as theoutlier class , is severely undersampled [20]. The small number of examples from the outlier class may result from the fact that samples are too dif Ô¨Åcult to obtain from this class. Therefore, the goal of one- class classi Ô¨Åcation is to construct a decision surface (function) around the examples from the target class in order to distinguish between thetarget objects and the outliers [21]. Indeed, similar training data were generated based on the inputs of domain experts. In addition, the similar part can be distinguished fromthe systematic defect patterns (SDP) by using a one-class classi Ô¨Åca- tion technique with recognized simila r samples, where SDP is a set of the speci Ô¨Åc morphology-based samples provided by the company. The one-class SVM can be applied to obtain the dissimilar training samples that are Ô¨Åltered from SDP. In this work the LIBSVM (version 3.11) was utilized [22] since it is an integrated tool for support vector clas-siÔ¨Åcation and regression, which can han"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_21", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 21, "text": "ilar training samples that are Ô¨Åltered from SDP. In this work the LIBSVM (version 3.11) was utilized [22] since it is an integrated tool for support vector clas-siÔ¨Åcation and regression, which can handle the problem of one-classclassi Ô¨Åcation. We used the standard pa rameters of LIBSVM, chose the number of features (bins) and, by tria l-and-error, selected the appro- priate kernel and its a ppropriate parameters. C. Support Vector Machine (SVM) Similar to the one-class SVM, as a typical supervised learning method, the underlying theme of the SVM is to learn from the data. The difference between them is that the (Two-Class) SVMuses two parties of examples for training. Suppose that there is an input space , an output space , and a training data set ,a n d is the size of the training data. The output space deter- mines the learning type, and leads to a binary classi Ô¨Åcation problem. Geometrically, the basic concept behind SVM is to maximize themargin of separation of the hyperplane in a feature space. SVM‚Äôs creator, Vapnik [23], showed how training an SVM leads to a QP problem with bound constraints and linear equality constraints.This can be solved by constructing a Lagrangian funct"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_22", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 22, "text": "feature space. SVM‚Äôs creator, Vapnik [23], showed how training an SVM leads to a QP problem with bound constraints and linear equality constraints.This can be solved by constructing a Lagrangian function, and trans- forming it into the dual form, as shown in the following equation: (5) where stands for the size of training samples, i.e., the number of sim- ulated samples; is a vector variable with dimen- sion , which denotes the number of wafer features; is the response variable indicating whether a sample is similar to the target wafer. Inaddition, is a feature map, and is an upper bound parameter con- trolling the tradeoff between margin maximization and tolerable clas- siÔ¨Åcation errors. Parameters are the so-called Lagrange multipliers, while the kernel function is de Ô¨Åned as: . The elegance of using the kernel function is evident in dealing with feature spaces of arbitrary dimensionality without having to explicitlycompute the map function. The training was implemented by using the LIBSVM software [22], and the parameters were selected via a forced search process in the LIBSVM, where the parameters settings including and SVM type: c-svc is automatically read in. In addition, af"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_23", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 23, "text": " LIBSVM software [22], and the parameters were selected via a forced search process in the LIBSVM, where the parameters settings including and SVM type: c-svc is automatically read in. In addition, after many trials, the most commonly used kerne l function, the radial basis func- tion (RBF), is also utilized here, and the mathematical formula is shownas (6) (6) where is the kernel parameter. IV. C ASESTUDIES To validate our method, we used real data in industry for compar- ison. The company provided two lots of the target wafer maps, namely, 395-bin and 1742-bin. The effectiveness was tested on these indepen- dent wafer maps from the two lots as well. The goal of this experimentw a st oc l a s s i f yt h et e s t i n gd a t ai n t ot w oc l a s s e s ,b a s e do nt h es i m i l a r i t y degree of training sample generation with respect to the given target wafer maps. We used the domain experts‚Äô judgments (called OfÔ¨Åcial) as the measure standard, and compared the classi Ô¨Åed results with Of- Ô¨Åcial. The experimental results showed that MSVM achieved satisfac- tory performance, even considering the complex target maps. More-over, in terms of the execution time, MSVM saved nearly a qua"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_24", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 24, "text": "h Of- Ô¨Åcial. The experimental results showed that MSVM achieved satisfac- tory performance, even considering the complex target maps. More-over, in terms of the execution time, MSVM saved nearly a quarter of the time taken by the method currently used in the semiconductor in- dustry. A. The Method Used in the Semiconductor Industry For the purpose of complete illustration, we brie Ô¨Çy introduce the main idea of similar search use d in the semiconductor industry, as Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 957 Fig. 7. Work Ô¨Çow of MMA. Fig. 8. Experiment framework for WBMs similar searching. shown in Fig. 7. The work Ô¨Çow in Fig. 7 consists of three core steps: me- dian Ô¨Ålter[24], mountain function [25], and anomaly correlation (called MMA for short). Themedian Ô¨Ålteris often applied to noise reduction on an image or signal, which is a nonlinear digital Ô¨Åltering technique used to remove noise. This step is a typical preprocessing stage intended to improve the results of later processing (e.g ., edge dete"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_25", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 25, "text": " image or signal, which is a nonlinear digital Ô¨Åltering technique used to remove noise. This step is a typical preprocessing stage intended to improve the results of later processing (e.g ., edge detection on an image) [24]. Next, the mountain function computes the density of the foreground pixels around a given point on an image in order to realize the whole distribution map. The de Ô¨Ånition and further details can be found in [25]. Finally, the anomaly correlation is used for the expression of similarity (7), where is the number of testing samples, and ,mean the mountain values of the target and testing wafers, respectively (7) Fig. 9. Scale normalization: (a) original: 395-bin and (b) normalized: 1854-bin. B. Experiment Framework Fig. 8 describes the whole picture of the experimental execution. Ini- tially, suppose the collaborator provides some target wafer maps, i.e., the main defect patterns, and we then have to use MSVM to deal with the subsequent wafer lots to be detected. For the source of (testing ortarget) wafer maps, each lot of wafers may have different scale; in this case, scale normalization is essenti al preprocessing in order to avoid the problem of size adjustment "}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_26", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 26, "text": "he source of (testing ortarget) wafer maps, each lot of wafers may have different scale; in this case, scale normalization is essenti al preprocessing in order to avoid the problem of size adjustment during the training phase. More pre-cisely, scale normalization not only makes a speci Ô¨Åc batch of wafers for a similarity search, but also facilitates the subsequent SVM training phase. Currently, the most adaptive size is 1854-bin, since it is conve-nient for the transformation of both large and small bin-size wafer maps in the industry. As seen from Fig. 9, it is the case that a wafer with a scale of 395-bin transformed into one of 1854-bin. For the process ofscale normalization, for example, when the 395-bin is transformed into 1854-bin, the prototype of 395-bin is divided into a grid with 1854 bins, where the chips in 1854-bin are decided to be red (defective chips) onlywhen the red parts of original 395-bin occupy arbitrary area inside the chips of 1854-bin. For smooth processing, this preprocessing is com- bined with the wafer generation procedure in the industry. Next, we proceed with the generation of morphological training sam- ples with a procedure of characteris tic separat"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_27", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 27, "text": "is preprocessing is com- bined with the wafer generation procedure in the industry. Next, we proceed with the generation of morphological training sam- ples with a procedure of characteris tic separation for similarity con- Ô¨Årmation (based on domain experts‚Äô judgments) and dissimilar sam- ples (One-Class SVM Ô¨Åltering) (see Fig. 10). After the two-class SVM training phase, the normalized testing data are sent for similarity search, in order to classify them into classes 1 (similar to the target) and 2 (dis- similar to the target). To evaluate the classi Ô¨Åcation performance, the Receiver Operating Characteristic (ROC) curve is used to observe the relevance of the catching rate (true positive rate, axis in ROC), and the false-alarm rate (false positive rate, axis in ROC). The formal de Ô¨Ånitions are presented in Fig. 11 and eqs. (8) and (9). An ideal classi Ô¨Åer is required to produce an ROC curve above the diagonal line; furthermore, the area below the ROC curve serves to judge the degree of performance: the larger the better. In addition, from a practical viewpoint in the industry,the catching rate is anticipated to be more than 0.8, and the false-alarm rate under 0.1 (8) (9) C. Resul"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_28", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 28, "text": "of performance: the larger the better. In addition, from a practical viewpoint in the industry,the catching rate is anticipated to be more than 0.8, and the false-alarm rate under 0.1 (8) (9) C. Results This work was accomplished in collaboration with a semiconductor Ô¨Årm in Taiwan, assisting them in dealing with defective wafer detec- tion. The wafer data from the Ô¨Årm has been divided into two main types: simple and complex patterns. The two types contain Ô¨Åve and four pat- terns, respectively. Fig. 12 draws the target wafer maps of those pat- terns and several corresponding trai ning samples. As for the number of Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. 958 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 Fig. 10. An illustration of similar and dissimilar samples. Fig. 11. Confusion matrix. Fig. 12. An illustrations of created samples. training samples, for each pattern the similar part has 234 wafers, and the dissimilar part has nearly 234, because of the Ô¨Åltering process. 1) Simple Patterns: Table I presents the results of simple patterns. The a"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_29", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 29, "text": "s, for each pattern the similar part has 234 wafers, and the dissimilar part has nearly 234, because of the Ô¨Åltering process. 1) Simple Patterns: Table I presents the results of simple patterns. The amount of testing data depends on the stock situation, and we alsoTABLE I RESULTS OF SIMPLE -PATTERNS TABLE II RESULTS OF COMPLEX -PATTERNS TABLE III RESULTS OF AVERAGE CPU T IMECOST provided the ofÔ¨Åcialresults, as judged by the domain experts. The Ô¨Ånd- ings are given as follows. For the Center case, the MSVM reaches ex cellent performance since it is easier to identify the pattern. Edge andC-shape are highly similar, with the only difference being the circular gap. Once the gap is smaller than the semicircle, MSVM may generate a slight false-alarm due to the misjudgment resulting from the higher similarity to Edge .M o r e - over, for the Edge andC-shape cases, the rotation feature needs to be considered because of the placement problem mentioned in rotation , Section III. In general, though, both hav e satisfactory performance, es- pecially C-shape . TheDonut is scarce in stock, and thus has a slightly low catching rate owing to the small number of similar samples compared with other "}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_30", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 30, "text": "gh, both hav e satisfactory performance, es- pecially C-shape . TheDonut is scarce in stock, and thus has a slightly low catching rate owing to the small number of similar samples compared with other pat-terns. The last simple pattern is . Because the strips have various degrees of coarseness and arbitrary distributions, , has many char- acteristics of other simple patterns. We believe that precision could beincreased by offering speci Ô¨Åcd eÔ¨Ånitions of WBM patterns or improved training machines. Thus, , presents a challenging work for future endeavors. The comparison of simple patterns between MSVM and MMA can be referred to the ROC curves (see Fig. 13(a) to (e)) in terms of the area below the curve. Because the MMA cannot perform the experi-ment to detect all the patterns with its current approach, some simple cases ( C-Shape andDonut ) only present the results of MSVM. The main limitation of MMA is that it lack s the rotation features in support of the consideration of different angle aspects that C-Shape andDonut require. As seen from Fig. 13(a) to (e), Edge , MSVM, and MMA have ideal and close performance. For the remaining simple cases, however,MSVM obviously achieves a higher"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_31", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 31, "text": "e aspects that C-Shape andDonut require. As seen from Fig. 13(a) to (e), Edge , MSVM, and MMA have ideal and close performance. For the remaining simple cases, however,MSVM obviously achieves a higher catching rate than does MMA under all false-alarm rates; MSVM h as a lower false-alarm rate under all catching rates. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 959 Fig. 13. The performances in all testing patterns. (a)‚Äì(e) Simple patterns. (f) and (g) Complex patterns. 2) Complex Patterns: With constantly developing manufacturing technology, engineers have to deal with ever larger scales and more di- verse WBMs. Moreover, defective w afer maps may generate complex patterns. We tested our method, MSVM on the two complex patterns that have not been successfully detected by MMA or any other ma- chine learning-based methods. The e xperimental results are presented in Table II and Fig. 13(f) and (g), where they show ROC curves with large areas under the curves, while th e catching rate increases to 1 when th"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_32", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 32, "text": "based methods. The e xperimental results are presented in Table II and Fig. 13(f) and (g), where they show ROC curves with large areas under the curves, while th e catching rate increases to 1 when the false-alarm value is around 0.05. All told, MSVM, on average, ob-tains a high catching rate of nearly 0.95, and a low false-alarm rate of below 0.05. D. Result Summary In the literature, there are few methods contributing to wafer detec- tion using similarity search in the semiconductor industry. Similarity searching must consider variations of many features. This problem is very different from those more commonly related to pattern recogni- tion. In addition, signi Ô¨Åcant CPU time would be expended if thosepattern recognition approaches such as MMA were to take all of the features into consideration. As a result, MMA can only handle fewer simple-pattern cases. Table III presents the average execution time in each step of MMA and MSVM. MMA and MSVM were performed on computer facilities: an Intel E7500, 2.93 GHz PC with 1.96 GB memory, and an Intel (R)Core(TM) i5, 3.20 GHz PC with 4 GB memory, respectively. It can be observed that MSVM saves nearly a quarter of the time taken by MMA; m"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_33", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 33, "text": "n Intel E7500, 2.93 GHz PC with 1.96 GB memory, and an Intel (R)Core(TM) i5, 3.20 GHz PC with 4 GB memory, respectively. It can be observed that MSVM saves nearly a quarter of the time taken by MMA; more importantly, MSVM has a bette r wafer detection performance. V. D ISCUSSIONS In this study, the similarity measurement for evaluating the perfor- mance of the proposed approach was only compared with MMA be- cause of the con Ô¨Ådential reason. There are so me spatial characteris- tics in wafer maps, which have been discussed in the literature [26], [27]. These characteristics such as correlogram may capture defective patterns better than the two-dimension wafer map data [26]. More pre- cisely, spatial statistic can deal with bin-level wafer maps by comparing Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply. 960 IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING, VOL. 11, NO. 3, JULY 2014 the number of functional bins around a defective bin with the number of defective bins around a functional bin. Although the spatial statis- tics performed well in previous work, there are several criti"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_34", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 34, "text": "e number of functional bins around a defective bin with the number of defective bins around a functional bin. Although the spatial statis- tics performed well in previous work, there are several critical issues in similarity measurement when considering complicated wafer featuressuch as rotation and shifts. For example, in terms of rotation, wafers are actually not a perfectly round shape, so some bins need to be in- serted or ignored concerning the rotat ion bins. In this case, the spatial statistic measurement cannot provide an effective similarity measure- ment because of the diversity of wafer maps. The future studies wi ll in- corporate the comments and judgment from the experienced engineers into the tool, and focus on a more general similarity measurement, es- pecially for the complex shapes. VI. C ONCLUSION This work has proposed a novel approach for combining a super- vised SVM classi Ô¨Åer with a morphology-based sample simulation for similarity searching of binary WBM defect patterns for yield enhancement. Owing to the increasing size and variations of def ective wafer patterns, conventional p attern recognition or classi Ô¨Åcation methods have dif Ô¨Åculty in determining the "}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_35", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 35, "text": "atterns for yield enhancement. Owing to the increasing size and variations of def ective wafer patterns, conventional p attern recognition or classi Ô¨Åcation methods have dif Ô¨Åculty in determining the pattern types. According to the original wafer characteristics of the target wafer maps, this study generated wafer samples through morphology-inspired conceptions. This proposed morphology-base d SVM (MSVM) extends to more complex defect patterns (shapes). More precisely, i nstead of tradi- tional methods, the proposed MSVM has been employed to engage in similarity search through a morphological learning process, which is built in scale normalization, samples Ô¨Åltering process, and seven types of similar samples generation approach. The experimental results showed that MSVM not only has great performance in terms of ROC curve (catching and fal se-alarm rates), bu t has faster execution time. REFERENCES [1] Q. Zhou, L. Zeng, and S. Zhou, ‚ÄúStatistical detection of defect patterns using Hough transform,‚Äù IEEE Trans. Semicond. Manuf. , vol. 23, no. (3), pp. 370‚Äì380, Aug. 2010. [2] C. F. Chien, J.-Z Wu, and C.-C. Wu, ‚ÄúA two-stage stochastic program- ming approach for new tape-out allo catio"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_36", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 36, "text": " transform,‚Äù IEEE Trans. Semicond. Manuf. , vol. 23, no. (3), pp. 370‚Äì380, Aug. 2010. [2] C. F. Chien, J.-Z Wu, and C.-C. Wu, ‚ÄúA two-stage stochastic program- ming approach for new tape-out allo cation decisions for demand ful- Ô¨Ållment planning in semiconductor manufacturing,‚Äù Flexible Services Manuf. J. , vol. 25, no. 3, pp. 286‚Äì309, 2013. [3] C. Chien, W. Wang, and J. Cheng, ‚ÄúD ata mining for yield enhancement in semiconductor manufacturing and an empirical study,‚Äù Expert Syst. With Applicat. , vol. 33, no. 1, pp. 1‚Äì7, 2007. [4] J. G. Shanthikumar, S. Ding, and M. T. Cheng, ‚ÄúQueueing theory for semiconductor manufacturing syste ms: A survey and open problems,‚Äù IEEE Trans. Autom. Sci. Eng. , vol. 4, no. 4, pp. 513‚Äì522, Oct. 2007. [5] R. C. Leachman and S. Ding, ‚ÄúExcursion yield loss and cycle time reduction in semiconductor manufacturing,‚Äù IEEE Trans. Autom. Sci. Eng., vol. 8, no. 1, pp. 112‚Äì117, Jan. 2011. [6] C. H. Stapper, ‚ÄúThe effects of wafer to wafer defect density variations on integrated circuit defect and fault distributions,‚Äù IBM J. Res. De- velop. , vol. 29, no. 1, pp. 87‚Äì97, 1985.[7] A. K. Jain, R. P. W. Duin, and J. Mao, ‚ÄúStatistical pattern recognition: Ar e v i e w "}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_37", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 37, "text": " integrated circuit defect and fault distributions,‚Äù IBM J. Res. De- velop. , vol. 29, no. 1, pp. 87‚Äì97, 1985.[7] A. K. Jain, R. P. W. Duin, and J. Mao, ‚ÄúStatistical pattern recognition: Ar e v i e w , ‚Äù IEEE Trans. Pattern Anal. Mach. Intell. , vol. 22, no. 1, pp. 4‚Äì37, Jan. 2000. [8] B. Bhanu, S. Lee, and J. Ming, ‚ÄúAdaptive image segmentation using a genetic algorithm,‚Äù IEEE Trans. Syst. Man Cybern. , vol. 25, no. 12, pp. 1543‚Äì1567, Dec. 1995. [9] P. Farzin, N. Sulaiman, S. Roosta, M. H. Marhaban, and R. Ramli, ‚ÄúDesign a new sliding mode adaptive hybrid fuzzy controller,‚Äù J. Adv. Sci. Eng. Res , vol. 1, pp. 115‚Äì123, 2011. [10] H. Kim, K. Lee, B. Jeon, and C. Song, ‚ÄúQuick wafer alignment using feedforward neural networks,‚Äù IEEE Trans. Autom. Sci. Eng. , vol. 7, no. 2, pp. 377‚Äì382, Apr. 2010. [11] C.-J Kuo, C.-F Chein, and J.-D Chen, ‚ÄúManufacturing intelligence to exploit the value of production and tool data to reduce cycle time,‚ÄùIEEE Trans. Autom. Sci. Eng. ,v o l .8 ,n o .1 ,p p .1 0 3 ‚Äì 1 1 1 ,J a n .2 0 1 1 . [12] J. Wilfredo, Puma-Villanueva, E. P. dos Santos, and F. J. V. Zuben, ‚ÄúA constructive algorithm to synthesize arbitrarily connected feedforwardneural networks,‚Äù Neuroc"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_38", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 38, "text": "0 3 ‚Äì 1 1 1 ,J a n .2 0 1 1 . [12] J. Wilfredo, Puma-Villanueva, E. P. dos Santos, and F. J. V. Zuben, ‚ÄúA constructive algorithm to synthesize arbitrarily connected feedforwardneural networks,‚Äù Neurocomputing , vol. 75, pp. 14‚Äì32, 2012. [13] C. Cortes and V. Vapnik, ‚ÄúSupport vector networks,‚Äù Mach. Learning , vol. 20, no. 3, pp. 273‚Äì297, 1995. [14] M. Farhan, G. Kassem, M. Abdullah, and S. Akbar, ‚ÄúSupport vector machine classi Ô¨Åer for pattern recognition,‚Äù in Proc. 1st Int. Conf. In- format. Comput. Intell. (ICI) , 2011, pp. 272‚Äì277. [15] X. Ji, Y. Li, Z. Wang, F. Wang, and Q. Liu, ‚ÄúPartial discharge pat- tern recognition of XLPE cable connector based on support vectormachine,‚Äù in Proc. Int. Conf. Elect. Control Eng. (ICECE) , 2011, pp. 2422‚Äì2425. [16] S- C. Hsu and C.-F Chien, ‚ÄúHybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor man-ufacturing,‚Äù Int. J. Prod. Economics , vol. 107, pp. 88‚Äì103, 2007. [17] T.-S Li and C.-L. Huang, ‚ÄúDefect sp atial pattern recognition using a hybrid SOM-SVM approach in semiconductor manufacturing,‚Äù Expert Syst. Appl. , vol. 36, pp. 374‚Äì385, 2009. [18] L.-C Chao and L.-I. Tong, ‚ÄúWafer defect pattern r"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_39", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 39, "text": "ct sp atial pattern recognition using a hybrid SOM-SVM approach in semiconductor manufacturing,‚Äù Expert Syst. Appl. , vol. 36, pp. 374‚Äì385, 2009. [18] L.-C Chao and L.-I. Tong, ‚ÄúWafer defect pattern recognition by multi- class support vector machines by using a novel defect cluster index,‚ÄùExpert Syst. Appl. , vol. 36, pp. 10158‚Äì10167, 2009. [19] G. Matheron and J. Serra, ‚ÄúHistory of Mathematical Mor- phology,‚Äù 1968 [Online]. Available: http://cmm.ensmp.fr/~serra/pdf/birth_of_mm.pdf [20] R. Perdisci, G. Gu, and W. Lee, ‚ÄúUsing an ensemble of one-class SVM classi Ô¨Åers to harden payload-based anomaly detection systems,‚Äù inProc. IEEE 6th Int. Conf. Data Mining Location , Hong Kong, 2006, pp. 488‚Äì498. [21] I. F. de Viana, P. J. Abad, J. L. Alvarez, and J. L. Arjona, ‚ÄúToward one class classi Ô¨Åer techniques applied to veri Ô¨Åer information,‚Äù in Proc. 6th Iberian Conf. Inf. Sys t. Technol. (CISTI) , 2011, pp. 1‚Äì7. [22] LIBSVM [Online]. Available: http://www.csie.ntu.edu.tw~cjlin/ libsvm/ [23] V. N. Vapnik , The Nature of Statistical Learning Theory .N e w Y o r k , NY, USA: Springer-Verlag, 1995. [24] J. Principe, N. Euliano, and W. Lefebvre , Neural and Adaptive Sys- tems: Fundamentals Thro"}
{"id": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf::chunk_40", "source": "Similarity Searching for Defective Wafer Bin Maps in Semiconductors.pdf", "chunk_index": 40, "text": " N. Vapnik , The Nature of Statistical Learning Theory .N e w Y o r k , NY, USA: Springer-Verlag, 1995. [24] J. Principe, N. Euliano, and W. Lefebvre , Neural and Adaptive Sys- tems: Fundamentals Through Simulations .N e w Y o r k , N Y , U S A : Wiley, 2000. [25] R. R. Yager and D. P. Filev, ‚ÄúApproximate clustering via the mountain method,‚Äù IEEE Trans. Syst. Man Cybern. , vol. 24, pp. 1279‚Äì1284, Aug. 1994. [26] Y.-S. Jeong, S.-J. Kim, and M. K. Jeong, ‚ÄúAutomatic identi Ô¨Åcation of defect patterns in semiconductor wafer maps using spatial correlogramand dynamic time warping,‚Äù IEEE Trans. Semicond. Manuf. , vol. 21, no. 4, pp. 625‚Äì637, Nov. 2008. [27] T. Yuan, W. Kuo, and S. J. Bae, ‚ÄúDetection of spatial defect patterns generated in semiconductor fabrication processes,‚Äù IEEE Trans. Semi- cond. Manuf. , vol. 24, no. 3, pp. 392‚Äì403, Aug. 2011. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 05:20:29 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_0", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 0, "text": "Computers & Industrial Engineering 185 (2023) 109679 Available online 12 October 2023 0360-8352/¬© 2023 Elsevier Ltd. All rights reserved. Contents lists available at ScienceDirect Computers & Industrial Engineering journal homepage: www.elsevier.com/locate/caie Similarity searching for fault diagnosis of defect patterns in wafer bin maps‚ú© Rui Wanga, Songhao Wangb,‚àó aSchool of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China bSchool of Business, Southern University of Science and Technology, Shenzhen, China A R T I C L E I N F O Keywords: Similarity searching Wafer bin map Defect diagnosis Yield enhancement Semiconductor manufacturingA B S T R A C T Due to the growing complexity of processes in semiconductor manufacturing, high volumes of data are automatically generated, resulting in a greater challenge for fault detection and yield improvement. Wafer bin maps (WBMs), which represent the spatial distribution of defective dies on the wafer, may contain specific defect patterns that offer useful insight into the underlying causes of anomalies in the processes. Hence, the identification of these defect patterns helps the early detection and diagno"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_1", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 1, "text": "ain specific defect patterns that offer useful insight into the underlying causes of anomalies in the processes. Hence, the identification of these defect patterns helps the early detection and diagnosis of the faults. Nowadays, rare and mixed-type defects are more frequently observed, which increases the difficulty for the recognition of defect patterns. In this study, we propose a similarity searching approach for the identification of defect patterns and their potential causes. The comparison of similar patterns provides valuable information to trace the problems in the process history which may narrow the scope of troubleshooting. In particular, the tensor voting algorithm is applied to highlight the structural information in the patterns, and then the weighted best-buddies similarity (WBBS) is proposed to measure the degree of similarity. Experimental results verify the effectiveness of the proposed method in the context of both single and mixed-type defect patterns. 1. Introduction The semiconductor manufacturing is a sophisticated and lengthy process with hundreds of steps, during which errors are inevitable. Yield improvement has become a critical concern to guarantee high-"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_2", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 2, "text": "on The semiconductor manufacturing is a sophisticated and lengthy process with hundreds of steps, during which errors are inevitable. Yield improvement has become a critical concern to guarantee high- quality products and low costs at the same time ( Dou, He, & Hsu , 2018 ). Nowadays, technique advances allow the collection of data that are seen to be of complex structure and increasingly high volume ( Li, Du, Huang, Zhao, & Deng , 2019 ; Li, Du, Wang, Lv, & Deng , 2022 ). With the help of the acquired data, it is possible to extract valuable information to monitor the system quality ( Zhang, Yan, Lee, & Shi , 2018a , 2018b ), detect anomalies ( Zhu, Huang, Shen, & Shen , 2022 ), suggest solu- tions ( Qin et al. , 2020 ) and ultimately improve process yield ( Huang, Du, Li, & Wu , 2017 ). The wafer bin map (WBM), in particular, is a two- dimensional graphic depiction of a wafer where each pixel indicates the functionality of each die. It is produced following the circuit probe (CP) yield test, which evaluates the electrical functionality of each die on the wafer following wafer fabrication. The CP test is an important yield indicator that helps with low yield troubleshooting, failu"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_3", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 3, "text": "ld test, which evaluates the electrical functionality of each die on the wafer following wafer fabrication. The CP test is an important yield indicator that helps with low yield troubleshooting, failure monitoring and diagnosis, and performance enhancement. The quality of the CP test is illustrated with the WBM, which typically contains both random defects that are randomly distributed, as well as systematic defects ‚ú©This work was supported in part by the National Natural Science Foundation (NNSF) of China under Grant 72101065 and Grant 72101106, in part by the Guangdong Basic and Applied Basic Research Foundation under Grant 2021A1515110336, and in part by the Shenzhen Science and Technology Program under Grant RCBS20221008093124063 and Grant RCBS20210609103119020. ‚àóCorresponding author. E-mail addresses: r.wang@hit.edu.cn (R. Wang), wangsh2021@sustech.edu.cn (S. Wang).that exhibit spatial correlations ( Liao, Hsieh, Huang, & Chien , 2014 ). The WBM attracts much attention as the systematic defects may form specific patterns that are caused by assignable failures in the process. The analysis of the patterns allows engineers to trace the problem back in history for fault diagnosis "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_4", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 4, "text": "ematic defects may form specific patterns that are caused by assignable failures in the process. The analysis of the patterns allows engineers to trace the problem back in history for fault diagnosis and root cause detection, which is beneficial for yield enhancement and cost reduction. In practice, the identification and comparison of the patterns are mostly conducted by engineers through visual inspection, and are heavily dependent on domain knowledge and expertise. Such human-eye based judgement may be subjective, time-consuming and lack of consistency ( Kyeong & Kim, 2018 ). To overcome the challenge of high inspection costs and yield loss associated with defective dies, many studies have been conducted for WBM analysis, and they can be divided into two categories: unsu- pervised and supervised approaches. Unsupervised learning is able to group the samples into clusters without pre-determined labels. For example, Hsu and Chien (2007 ) proposed a hybrid data mining ap- proach that integrates spatial statistics and adaptive resonance theory (ART) neural networks to extract patterns from WBMs. Lee, Yu, and Park (2001 ) clustered the chip locations having similar defect features th"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_5", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 5, "text": "ntegrates spatial statistics and adaptive resonance theory (ART) neural networks to extract patterns from WBMs. Lee, Yu, and Park (2001 ) clustered the chip locations having similar defect features through self-organizing map (SOM) neural networks. Hwang and Kim https://doi.org/10.1016/j.cie.2023.109679 Received 24 June 2023; Received in revised form 14 September 2023; Accepted 10 October 2023 Computers & Industrial Engineering 185 (2023) 109679 2R. Wang and S. Wang Fig. 1. Examples of WBMs with mixed-type patterns. (2020 ) performed one-step clustering with a Gaussian mixture model applied to a variational autoencoder (VAE) framework. Supervised learning is able to recognize existing patterns, but cannot identify newly-emerged defect patterns. In recent years, machine learning meth- ods were applied for WBM classification, including support vector machine (SVM) ( Wu, Jang, & Chen , 2014 ), decision tree ( Piao, Jin, Lee, & Byun , 2018 ) and linear discriminant analysis (LDA) ( Yu & Lu , 2015 ). Deep learning-based approaches have received an increased amount of interest recently because of their excellent capability in image processing and applicability in various fields. In Adly "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_6", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 6, "text": " , 2015 ). Deep learning-based approaches have received an increased amount of interest recently because of their excellent capability in image processing and applicability in various fields. In Adly et al. (2015 ), General regression neural network (GRNN) was proposed for the accurate and efficient identification of defect patterns in WBMs. The most popular solution is the convolutional neural networks (CNNs), which is specifically developed for image data, examples of these models are seen in Hsu and Chien (2022 ), Kang and Kang (2021 ), Nakazawa and Kulkarni (2018 ). In modern wafer manufacturing systems, mixed-type defect patterns which contains two or more single pattern in the same WBM, are frequently observed because of the increasing circuits density and wafer design complexity. For mixed-type patterns, several manufactur- ing problems can be found, with each defect pattern having a related root cause ( Yuan & Kuo , 2008 ). Fig. 1 illustrates examples of the same mixed-type defect pattern consisting of ‚Äò‚ÄòScratch‚Äô‚Äô, ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòLoc‚Äô‚Äô patterns. ‚Äò‚ÄòScratch‚Äô‚Äô patterns are generated by machine handling problems, ‚Äò‚ÄòCenter‚Äô‚Äô patterns are caused by uniformity variations in the "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_7", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 7, "text": "ect pattern consisting of ‚Äò‚ÄòScratch‚Äô‚Äô, ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòLoc‚Äô‚Äô patterns. ‚Äò‚ÄòScratch‚Äô‚Äô patterns are generated by machine handling problems, ‚Äò‚ÄòCenter‚Äô‚Äô patterns are caused by uniformity variations in the chemical mechanical process (CMP), while ‚Äò‚ÄòLoc‚Äô‚Äô patterns are gener- ated by non-uniformity or uneven cleaning ( Kim, Lee, & Kim , 2018 ). In Fig. 1, both systematic defects that forms certain patterns, and random defects that are seen as noise to the patterns, are seen in the same WBM. In addition, the combination of sizes and placements of various single patterns may also vary significantly, making it more challenging to recognize mixed-type patterns. For the classification of mixed-type defect patterns in WBMs, a few deep learning based models have been proposed. Kyeong and Kim (2018 ) used a mixture of each pattern‚Äôs distinct CNN-based classification model to recognize mixed- type defect patterns. Wang, Xu, Yang, Zhang, and Li (2020 ) introduced a deformable convolutional network to extract high-quality features for mixed-type pattern recognition. Shin, Kahng, and Kim (2022 ) suggested utilizing samples with single type patterns to train CNNs in WBMs with a Mixup-based strategy for"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_8", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 8, "text": "tract high-quality features for mixed-type pattern recognition. Shin, Kahng, and Kim (2022 ) suggested utilizing samples with single type patterns to train CNNs in WBMs with a Mixup-based strategy for the classification of mixed-type patterns. Existing approaches provide solutions for automatic recognition of defect patterns in both single and mixed-type scenarios. However, these classification based methods may have limitations that they cannot distinguish the similarity of different WBMs regarding a query one, resulting in the misdiagnosis when tracking in the history, if the pat- terns are not significantly similar ( Liao, Hsieh, Huang, & Chien , 2013 ). Furthermore, existing methods cannot give satisfactory results when recognizing a newly or rarely observed pattern. In order to improve the efficiency and effectiveness for the tracking of root causes, similarity measures between two WBMs are considered for the WBM analysis. Similarity searching makes it possible to identify root causes by tracing the process history using similarity as a criterion, which limits the scope of troubleshooting and lowers the risk of misdiagnosis ( Hsu, Chen, &Chien , 2020 ). However, the determinat"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_9", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 9, "text": "uses by tracing the process history using similarity as a criterion, which limits the scope of troubleshooting and lowers the risk of misdiagnosis ( Hsu, Chen, &Chien , 2020 ). However, the determination of similarity measure is chal- lenging because the similarity defined by human experts is intrinsically subjective. In addition, the patterns in the each class may also vary in noise level, pattern location and wafer rotation, etc. These factors need to be carefully considered in the design of the similarity measure. Few studies have focused on WBM similarity searching. The ma- jority of the studies that examines similarity measurement of WBMs involve the training of supervised models, which may not guarantee performance when labels are unknown, as the features for similarity ranking are learned using labeled data ( Liao et al. , 2013 ; Nakazawa & Kulkarni , 2018 ). To address this issue, Wu et al. (2014 ) developed a set of novel rotation- and scale-invariant features without pre-determined pattern labels, and similar WBMs are found based on the Euclidean distance of the extracted features. Hsu et al. (2020 ) proposed a similar- ity ranking method without pattern labels by calcula"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_10", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 10, "text": "rmined pattern labels, and similar WBMs are found based on the Euclidean distance of the extracted features. Hsu et al. (2020 ) proposed a similar- ity ranking method without pattern labels by calculating the Hausdorff distances of enhanced feature maps generated by a mountain clustering algorithm. Lee, Moon, and Oh (2021 ) first used nonparametric Bayesian clustering to find local clusters and then employed hierarchical clus- tering to obtain the global clusters with a weight vector, which are subsequently applied to measure and rank similarity. However, existing methods mainly deal with single type defect patterns, which lacks the adaptability for mixed-type patterns that appears to be complex, which includes patterns varying in different sizes and locations with interac- tions. For mixed-type patterns, however, the root causes corresponding to the isolated single patterns are independent. That is, a WBM may contain multiple patterns, with only one pattern having the same root cause with the query one. In order to provide comparable scores with the same pattern contained in different WBMs, the similarity measure must be properly created. It must also take into account the exact s"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_11", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 11, "text": "with the query one. In order to provide comparable scores with the same pattern contained in different WBMs, the similarity measure must be properly created. It must also take into account the exact similarity when the number of faulty points actually varies. This study proposes a method for WBM similarity searching to support decision making of engineers for root cause detection and yield enhancement. We put forward a similarity measurement model and develop the related similarity indices for the ranking and query of similar patterns. The proposed method is based on the preliminary work in Wang and Wang (2022 ). Tensor voting ( Mordohai & Medioni , 2010 ), a perceptual grouping technique, is initially used to transform the WBMs in order to retrieve structural information. In tensor voting, information about the local structural features is propagated across the neighborhood. As a result, points that belong to the same structure will give coherent structural information, which can then be used to find salient structures ( Du, Yan, Chang, & Shi , 2022 ). We are motivated to use the tensor voting algorithm for feature transformation because of its inherent robustness to noise and cap"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_12", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 12, "text": " be used to find salient structures ( Du, Yan, Chang, & Shi , 2022 ). We are motivated to use the tensor voting algorithm for feature transformation because of its inherent robustness to noise and capacity for handling complex patterns. Then, a weighted best-buddies similarity (WBBS) algorithm is proposed to measure the similarity of mixed-type WBMs. The method is validated with experiments using simulated patterns generated by the method described in Kyeong and Kim (2018 ). The main contributions of this study are summarized as follows: ‚Ä¢The proposed method enables similarity searching in the context of both single and mixed-type patterns. ‚Ä¢The proposed method can be used for WBM identification, while variations in shapes are considered regarding the same type of defect patterns. Computers & Industrial Engineering 185 (2023) 109679 3R. Wang and S. Wang ‚Ä¢The proposed method is able to search for similar patterns with- out model training and the collection of large amount of data. The remainder of this paper is organized as follows. In Section 2, we describe the proposed WBM similarity searching method. The ex- perimental results are analyzed in Section 3. Section 4 presents discus-"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_13", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 13, "text": "emainder of this paper is organized as follows. In Section 2, we describe the proposed WBM similarity searching method. The ex- perimental results are analyzed in Section 3. Section 4 presents discus- sions and possible improvements of the proposed method. Section 5 concludes this paper and highlights future research directions. 2. Methodology In this section, we propose a novel similarity searching approach in WBMs, which can be applied when the defect patterns appear to have mixed types with noise. To obtain structural saliency of the defects, the tensor voting algorithm is first applied to original WBMs. Based on the results of tensor voting, the noisy defects are removed to emphasize the pattern structures and improve the data quality. Then, a similarity measure is proposed to properly evaluate the similarity between WBMs with robustness to background, occlusions and complex deformations. The detailed description of the proposed method is presented in the following subsections. 2.1. Tensor voting based feature transformation The raw WBM is a binary valued image that contains only the functional information of each die. Therefore, it is hard to infer specific patterns directly b"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_14", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 14, "text": ". Tensor voting based feature transformation The raw WBM is a binary valued image that contains only the functional information of each die. Therefore, it is hard to infer specific patterns directly based on the original WBM data. Conventionally, in semiconductor industry, the mountain function (Yager & Filev, 1994) is used to compute the density of the surrounding pixels around a given point on an image in order to obtain the spatial distribution of the patterns (Liao et al., 2014). The mountain clustering method gives the clustering features of the defective dies, but it cannot represent different structures that make up of the WBM such as curves and regions. The tensor voting is a perceptual grouping method which aims to extract salient features from clouds of points without prior knowl- edge (Medioni, Tang, & Lee, 2000). It has shown great power to infer structural information based on good continuation and proximity under the existence of gaps and noise. Specifically, in 2-D, the tensor voting is able to distinguish curves, junctions and regions from corrupted images, which provides a chance to amplify the pattern related features in the WBMs. In the following, we present a br"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_15", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 15, "text": "tensor voting is able to distinguish curves, junctions and regions from corrupted images, which provides a chance to amplify the pattern related features in the WBMs. In the following, we present a brief introduction to a closed- form solution to tensor voting algorithm (Wu, Yeung, Jia, Tang, & Medioni, 2011). The tensor voting proposes that the arrangement of the surrounds, rather than the individual points, determines the structural saliency. In particular, a tensor vote is cast from the voter to the vote receiver subject to proximity and continuity requirements. In Fig. 2, two points ùê±ùëñ‚ààRùëëandùê±ùëó‚ààRùëëare connected by some smooth structure, the unit normal ùêßùëóis the voting tensor, ùê´ùëñùëóis a unit vector at ùê±ùëópointing to ùê±ùëñ, andùêØùëñis the normal vote received at ùê±ùëñderived by the osculating arc between the two points. First, the special case when ùêßùëóis known is considered. The structure- aware tensor ùêäùëñ‚ààRùëë√óRùëëatùê±ùëñcan be calculated in the form of a second-order symmetric tensor, which is equivalent to a ùëë√óùëëmatrix and can be visualized as ellipsoid. ùêäùëñis defined as ùêØùëñùêØùëá ùëñmultiplied by ùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùëó), where ùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùëó) =ùëêùëñùëó(1 ‚àí ( ùê´ùëá ùëñùëóùêßùëó)2), (1) ùëêùëñùëó= exp(‚àí‚Äñ‚Äñ‚Äñùê±ùëñ‚àíùê±ùëó‚Äñ‚Äñ‚Äñ2 ùúéùëë). (2) In (1) and (2), 1 ‚àí (ùê´"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_16", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 16, "text": " to a ùëë√óùëëmatrix and can be visualized as ellipsoid. ùêäùëñis defined as ùêØùëñùêØùëá ùëñmultiplied by ùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùëó), where ùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùëó) =ùëêùëñùëó(1 ‚àí ( ùê´ùëá ùëñùëóùêßùëó)2), (1) ùëêùëñùëó= exp(‚àí‚Äñ‚Äñ‚Äñùê±ùëñ‚àíùê±ùëó‚Äñ‚Äñ‚Äñ2 ùúéùëë). (2) In (1) and (2), 1 ‚àí (ùê´ùëá ùëñùëóùêßùëó)2is a square-sine function which panelizes the curvature,ùúéùëëis the scale parameter which denotes the size of neigh- borhood considered for voting. The definition of ùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùëó)implies that smooth continuation and closeness are preferred in the computation of the structure-aware tensor vote. Fig. 2. Second order vote cast by a stick tensor at ùëÇtoùëÉ. Then, the general case is considered where the normal ùêßùëóatùê±ùëóis unknown. Let ùêäùëóatùê±ùëóbe any second-order symmetric tensor, which is typically initialized as an identity matrix. Then the set of all possible unit normals {ùêßùúÉùëó}associated with the corresponding length {ùùâùúÉùëó}at all possible directions ùúÉofùêäùëóare considered for vote computation. The tensor vote ùêíùëñùëóobtained at ùê±ùëñinduced by ùêäùëólocated at ùê±ùëóis: ùêíùëñùëó=‚à´ùêçùúÉùëó‚ààùúàùêØùúÉ(ùê±ùëñ,ùê±ùëó)(ùê±ùëñ,ùê±ùëó)ùëáùúÇ(ùê±ùëñ,ùê±ùëó,ùêßùúÉùëó)ùëëùêçùúÉùëó, (3) where ùêçùúÉùëó=ùêßùúÉùëóùêßùëá ùúÉùëó, (4) andùúàis the space of all possible ùêçùúÉùëó. Based on the osculating arc connection shown in Fig. 2, we have ùêØùúÉ(ùê±ùëñ,ùê±ùëó) = (ùêßùúÉùëó‚àí 2ùê´ùëñùëó(ùê´ùëá ùëñùëóùêßùúÉùëó))ùùâùúÉùëó. (5) The closed-form solution of "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_17", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 17, "text": "(3) where ùêçùúÉùëó=ùêßùúÉùëóùêßùëá ùúÉùëó, (4) andùúàis the space of all possible ùêçùúÉùëó. Based on the osculating arc connection shown in Fig. 2, we have ùêØùúÉ(ùê±ùëñ,ùê±ùëó) = (ùêßùúÉùëó‚àí 2ùê´ùëñùëó(ùê´ùëá ùëñùëóùêßùúÉùëó))ùùâùúÉùëó. (5) The closed-form solution of the structure-aware tensor ùêäùëñat each site ùê±ùëñ is the accumulation of all the votes cast from the neighborhood, which is given in Wu et al. (2011) as follows: ùêäùëñ=‚àë ùëóùêíùëñùëó, (6) ùêíùëñùëó=ùëêùëñùëóùêëùëñùëóùêäùëó(ùêà‚àí1 2ùê´ùëñùëóùê´ùëá ùëñùëó)ùêëùëá ùëñùëó, (7) with ùêëùëñùëó=ùêà‚àí 2ùê´ùëñùëóùê´ùëá ùëñùëó. (8) In the WBM, a second-order symmetric tensor ùêäùëñis equivalent to a 2√ó2 matrix, which can be decomposed as: ùêäùëñ=ùúÜ1‚Éó ùëí1‚Éó ùëí1ùëá+ùúÜ2‚Éó ùëí2‚Éó ùëí2ùëá, (9) where‚Éó ùëí1and‚Éó ùëí2are the eigenvectors of ùêäùëñwhose corresponding eigen- values areùúÜ1andùúÜ2(ùúÜ1‚â•ùúÜ2). The tensor defined in (9) can be further decomposed into the stick and ball components: ùêäùëñ=ùúÜùë†ùêìùë†+ùúÜùëèùêìùëè, (10) where ùêìùë†=‚Éó ùëí1‚Éó ùëí1ùëáis a stick tensor and ùêìùëè=‚Éó ùëí1‚Éó ùëí1ùëá+‚Éó ùëí2‚Éó ùëí2ùëáis a ball tensor.ùúÜùë†=ùúÜ1‚àíùúÜ2is called stick saliency, which is a measure of the confidence of the encoded direction. ùúÜùëè=ùúÜ2denotes ball saliency, which measures the degree that the point‚Äôs underlying structure is unoriented. The combination of stick and ball saliency gives hints on the structure that the point belongs to. When ùúÜùë†‚âà 0andùúÜùëè>0, the structure indicates"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_18", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 18, "text": "egree that the point‚Äôs underlying structure is unoriented. The combination of stick and ball saliency gives hints on the structure that the point belongs to. When ùúÜùë†‚âà 0andùúÜùëè>0, the structure indicates no orientation preference, so the point may lies in a region or junctions of curves. Similarly, when ùúÜùë†>0andùúÜùëè‚âà 0, the tensor is nearly a stick tensor that shows a direction with the strength ùúÜùë†, indicating a curvature structure. Given that defect patterns in the WBMs mostly consist of curves (such as ‚Äò‚ÄòEdge‚Äô‚Äô and ‚Äò‚ÄòScratch‚Äô‚Äô) and regions (such as ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòDonut‚Äô‚Äô) structures, the application of tensor voting for feature trans- formation is advantageous for the analysis of these defect patterns. The Computers & Industrial Engineering 185 (2023) 109679 4R. Wang and S. Wang Fig. 3. Results of tensor voting based feature transformation. results of tensor voting is also ideal for the removal of isolated defective points, which provide lower saliency values on the map of both ùúÜùë† andùúÜùëèdue to the inconsistent appearance that does not belong to any specific structure. The noisy points are removed with thresholding method when both ùúÜùë†< ùë°‚àó max(ùúÜùë†)andùúÜùëè< ùë°‚àó max(ùúÜùëè), whereùë° denotes the pe"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_19", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 19, "text": "ue to the inconsistent appearance that does not belong to any specific structure. The noisy points are removed with thresholding method when both ùúÜùë†< ùë°‚àó max(ùúÜùë†)andùúÜùëè< ùë°‚àó max(ùúÜùëè), whereùë° denotes the percentage of saliency value that are regarded as noise. Fig. 3 shows examples of the structural and ball saliency computed by tensor voting, as well as the WBMs after noise removal. The first column in Fig. 3 shows the raw WBMs, the second and third columns illustrate the stick and ball saliency, respectively. In color structured points that are a part of a pattern, the stick and ball saliency is darker, therefore the isolated points can be eliminated. The last column is the denoised WBMs based the results of tensor voting. The WBM in the first row contains a ‚Äò‚ÄòDonut‚Äô‚Äô pattern in the middle of the wafer. The stick saliency appears darker only at the region edge, while the ball saliency highlights concentrated area. The ‚Äò‚ÄòScratch‚Äô‚Äô pattern has higher value in the map of stick saliency in the second row. The third row in Fig. 3 is a mixture of patterns, the appearance of the stick and ball saliency map are consistent with that in the single-patterned WBM, demonstrating the capacity of ten"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_20", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 20, "text": " second row. The third row in Fig. 3 is a mixture of patterns, the appearance of the stick and ball saliency map are consistent with that in the single-patterned WBM, demonstrating the capacity of tensor voting to extract structural information that can be used for similarity measurement. 2.2. Similarity measure Based on the information obtained from tensor voting, we attempt to compare the patterns in the WBMs after noise removal. A template matching approach called the best-buddies similarity (BBS) ( Oron, Dekel, Xue, Freeman, & Avidan , 2017 ) is applied to evaluate the similarity between two WBMs. Both the structural saliency and location information of the denoised WBMs are considered for the computation of the similarity measure. BBS is inherently robust to outliers, because it only counts the pair of points that are mutual nearest neighbors, which is also known as best-buddies pairs (BBPs). In addition, BBS has the property that the maximum BBS value reaches only when the two groups of points to be compared are drawn from the same distribution, and the result decreases sharply as the distribution diverge.In the context of WBM similarity searching, BBS is defined to measure t"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_21", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 21, "text": "oups of points to be compared are drawn from the same distribution, and the result decreases sharply as the distribution diverge.In the context of WBM similarity searching, BBS is defined to measure the similarity between the selected template and the WBMs to compare in the history. The two sets of points are denoted as ùëÉ= {ùëùùëñ}ùëÅ ùëñ=1andùëÑ= {ùëùùëñ}ùëÄ ùëñ=1,ùëùùëñ,ùëûùëó‚ààRùëë, respectively. A pair of points is considered a BBP, if for a pair of points {ùëùùëñ‚ààùëÉ,ùëûùëó‚ààùëÑ},ùëùùëñis the nearest neighbor of ùëûùëóinùëÑ, andùëûùëóis the nearest neighbor of ùëùùëñinùëÉ. Then BBP can be formulated as an indicator function, ùëèùëè(ùëùùëñ,ùëûùëó,ùëÉ,ùëÑ ) ={ 1, ùëÅùëÅ (ùëùùëñ,ùëÑ) =ùëûùëó‚àßùëÅùëÅ(ùëûùëó,ùëÉ) =ùëùùëñ 0,otherwise(11) whereùëÅùëÅ(ùëùùëñ,ùëÑ) = arg minùëûùëó‚ààùëÑùëë(ùëùùëñ,ùëûùëó)is the nearest point of ùëûùëóinùëÑ, andùëë(ùëùùëñ,ùëûùëó)is the distance between ùëùùëñandùëûùëó. The function takes value 1 if a BBP is satisfied. Initially, BBS is defined to compare two images of the same size. However, the number of defective points varies in different WBMs, so here a weight is included to compare these patterns. The weight can be divided into two parts: the weight ùë§ùëùfor the number of points in the two sets, and the weight ùë§ùë£for the variations in the number of points to be compared in the history. The distance of the weig"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_22", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 22, "text": "an be divided into two parts: the weight ùë§ùëùfor the number of points in the two sets, and the weight ùë§ùë£for the variations in the number of points to be compared in the history. The distance of the weighted BBS between the point sets ùëÉandùëÑis given by: ùëäùêµùêµùëÜ (ùëÉ,ùëÑ) =ùë§ùëùùë§ùë£‚ãÖùëÅ‚àë ùëñ=1ùëÄ‚àë ùëó=1ùëèùëè(ùëùùëñ,ùëûùëó,ùëÉ,ùëÑ ). (12) Basically, the number of BBPs should be smaller than the minimum number of the points in ùëÉandùëÑ, and the weight ùë§ùëùcan be represented as follows: ùë§ùëù=1 min(ùëÅ,ùëÄ ), (13) so that the similarity satisfies the commutative property ùëäùêµùêµùëÜ (ùëÉ,ùëÑ) =ùëäùêµùêµùëÜ (ùëÑ,ùëÉ). As BBS only considers the number of pairs that have the mutually nearest distance, the BBS will give similar results for both single and mixed-type patterns if they contain the query pattern. To panelize the variation in the number of defective dies on the WBMs, the weight is specially designed as: ùë§ùë£= exp(‚àíùõº|ùëÅ‚àíùëÄ| ùëô), (14) Computers & Industrial Engineering 185 (2023) 109679 5R. Wang and S. Wang Fig. 4. Confusion matrix of similarity searching in mixed-type patterns. whereùëôis the total number of dies on the WBM which is fixed for the same type of the wafer product, and ùõºis the scale parameter that controls the degree of similarity difference for"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_23", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 23, "text": "xed-type patterns. whereùëôis the total number of dies on the WBM which is fixed for the same type of the wafer product, and ùõºis the scale parameter that controls the degree of similarity difference for single or mixed- type patterns. The greater value of ùëäùêµùêµùëÜ indicates higher similarity between template ùëÉand targetùëÑ. Both the structural saliency and the location of defects should be taken into account for the similarity measurement of WBMs. Curves and areas can be separated by structural saliency, while the specific patterns of the defect clusters can be determined by the locations. For example, ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòLoc‚Äô‚Äô patterns show similar results in the ball saliency map, but the ‚Äò‚ÄòCenter‚Äô‚Äô pattern appear much closer to the wafer center. Then the distance measure is defined as a tradeoff between structural and location information: ùëë(ùëùùëñ,ùëûùëó) =‚Äñ‚Äñ‚Äñùëù(ùëÜ) ùëñ‚àíùëû(ùëÜ) ùëó‚Äñ‚Äñ‚Äñ2 2+ùúá‚Äñ‚Äñ‚Äñùëù(ùêø) ùëñ‚àíùëû(ùêø) ùëó‚Äñ‚Äñ‚Äñ2 2, (15) where superscripts ùëÜandùêødenote the descriptor of structural saliency and location, respectively, and ùúáis a parameter that controls the weight of the strength between structure saliency and the location information. The structural descriptor is the stick and ball saliency (ùúÜùë†,ùúÜùëè). The location"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_24", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 24, "text": "ly, and ùúáis a parameter that controls the weight of the strength between structure saliency and the location information. The structural descriptor is the stick and ball saliency (ùúÜùë†,ùúÜùëè). The location information is described by polar coordinates ùúå, defined as ùúå=‚àö ùëé2+ùëè2, (16) whereùúåis the distance from the origin, when the point is located at (ùëé,ùëè)in Cartesian coordinates. Both of the descriptors are normalized to the range [0,1]. 2.3. Model evaluation To evaluate the similarity between two WBMs, we examine the problem of binary classification, i.e., if the WBM contains the query patternùëê, for the identification of mixed-type patterns. If the similarity measure is higher than a certain threshold, the WBM is predicted to include the query pattern ùëê. The combination of actual and predicted classes has four results: true positive (TP), false positive (FP), true negative (TN) and false negative (FN), as shown in Fig. 4. True positive rate (TPR) and false positive rate (FPR) are defined as: TPR =TP TP+FN, (17) FPR=FP FP+TN. (18) The receiver operating characteristic (ROC) curve, which plots TPR vs. FPR at different classification thresholds, is used to evaluate the performance of the pr"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_25", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 25, "text": " TPR =TP TP+FN, (17) FPR=FP FP+TN. (18) The receiver operating characteristic (ROC) curve, which plots TPR vs. FPR at different classification thresholds, is used to evaluate the performance of the proposed method. The precision‚Äìrecall (PR) curve is additionally applied to evaluate the detection performance on imbalanced data, as the ROC curves are overly optimistic when the amount of positive examples is far less than negative ones ( Saito & Rehmsmeier , 2015 ). Specially, the pattern ‚Äò‚ÄòRandom‚Äô‚Äô and ‚Äò‚ÄòNear-full‚Äô‚Äô are single-type patterns and cannot mix with others, showing classes imbalance in the task of binary classification. The precision (Pc) and Recall (Rc) defined at every threshold are: Pc=TP TP+FP, (19)Rc=TP TP+FN. (20) It should be noted that the definition of TPR and Rc is the same, where TPR=Rc in the two curves. For ROC, the Area under the curve (AUC) is used to measure the classification performance. The average precision (AP), which computes the area under the PR curve, is also applied as a numeric metric. Higher values of both indices indicate the effectiveness of the method. 3. Experiments We used the dataset ‚Äò‚ÄòMixedWM38‚Äô‚Äô provided in Wang et al. (2020 ) to evaluat"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_26", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 26, "text": "is also applied as a numeric metric. Higher values of both indices indicate the effectiveness of the method. 3. Experiments We used the dataset ‚Äò‚ÄòMixedWM38‚Äô‚Äô provided in Wang et al. (2020 ) to evaluate the performance of the proposed method. The dataset contains both real-world defect patterns, as well as simulated ones to guarantee class balance. Frequently occurred mixed-type patterns are collected, which are defined as combinations of basic defect patterns. When similarity searching in mixed-type patterns, the pattern ‚Äò‚ÄòEdge- ring‚Äô‚Äô and ‚Äò‚ÄòEdge-Loc‚Äô‚Äô can be regarded as the same pattern as they may overlap each other. Therefore, the two classes are combined together and denoted as ‚Äò‚ÄòEdge‚Äô‚Äô. The typical example of single patterns considered in this dataset is shown in Fig. 5. A total of 25 classes are determined after this pre-processing, and one thousand WBM samples are selected for each class. Among the mixed pattern types, nine of them are mixed with two single types, seven are mixed with three single types, and two mixed-type pattern are composed with four single patterns. The size of each WBM is 52 √ó52. We applied the detailed settings of the tensor voting and noise removal as"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_27", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 27, "text": "d with three single types, and two mixed-type pattern are composed with four single patterns. The size of each WBM is 52 √ó52. We applied the detailed settings of the tensor voting and noise removal as in Wang and Chen (2022 ). Using a thresholding technique based on the tensor voting results, noisy points that are not a part of the patterns are eliminated. The points were removed with threshold ùë°= 0.32. The parameters were set to ùõº= 5 andùúá= 1 based on experiments. The algorithms are coded using Python 3.8 and executed on a computer with a Core i9-10885H CPU@2.40 GHz. The averaged computational time similarity matching is 0.038 s per sample. The original and denoised query samples which are randomly selected for this study is illustrated in Fig. 5. Fig. 6 shows the similarity matching results of query patterns. The first nine patterns according to the rank of the similarity measure are extracted for visualization. The selected single patterns for query are arranged at the first column, and the other WBMs at the right of the black vertical line are queried patterns from the dataset. It is seen that the proposed method is able to retrieve similar patterns considering wafer rotation an"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_28", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 28, "text": "and the other WBMs at the right of the black vertical line are queried patterns from the dataset. It is seen that the proposed method is able to retrieve similar patterns considering wafer rotation and pattern size for all the single patterns, when both single and mixed-type patterns exist in the historical data. The similarity matching results with complex query patterns is shown in Fig. 7. The proposed method can identify most of the similar WBMs for the mixed-type pattern. The first row in Fig. 7 presents the query results of a mixed-type pattern that contains ‚Äò‚ÄòDonut‚Äô‚Äô, ‚Äò‚ÄòEdge‚Äô‚Äô, ‚Äò‚ÄòLoc‚Äô‚Äô and ‚Äò‚ÄòScratch‚Äô‚Äô. All the extracted WBMs contains at least three types of mixed patterns, showing the effectiveness in the similarity searching of mixed-type patterns. The second query pattern is com- posed of two defect patterns ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòLoc‚Äô‚Äô, and most of the extracted patterns are similar except the last one. For complex patterns, the measurement of the similarity is difficult considering the combi- nation of patterns of different shape, size and location. In this case, detecting a portion of the patterns still offers useful information for identifying root causes because the patterns"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_29", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 29, "text": " the combi- nation of patterns of different shape, size and location. In this case, detecting a portion of the patterns still offers useful information for identifying root causes because the patterns are caused by numerous types of production failures that occur independently ( Hsu et al. , 2020 ). Fig. 8 and Fig. 9 illustrate the ROC and PR curves of each query pat- tern, respectively. WBBS denotes the proposed weighted BBS method, and BBS represents the special case when ùõº= 0andùë§ùë£= 1. Our method was compared with the four similarity measures, namely deformable diversity similarity (DDIS) ( Talmi, Mechrez, & Zelnik-Manor , 2017 ), smallest deformation similarity (SDS), weighted smallest deformation Computers & Industrial Engineering 185 (2023) 109679 6R. Wang and S. Wang Fig. 5. Original and denoised samples of single-type query patterns. Fig. 6. Similarity matching results with single-type query patterns. Fig. 7. Similarity matching results with mixed-type query patterns. similarity (WSDS) ( Zhang, Yang, & Gao , 2020 ) and Hausdorff dis- tance ( Huttenlocher, Klanderman, & Rucklidge , 1993 ). The results show superiority of the proposed BBS based method, particularly for WBBS, w"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_30", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 30, "text": " (WSDS) ( Zhang, Yang, & Gao , 2020 ) and Hausdorff dis- tance ( Huttenlocher, Klanderman, & Rucklidge , 1993 ). The results show superiority of the proposed BBS based method, particularly for WBBS, which performs the best in almost all the pattern types. Table 1 shows the corresponding average AUC and AP values for both curves. For AUC, WBBS gives the best result in all selected patterns except ‚Äò‚ÄòDonut‚Äô‚Äô, where the value (0.969) is close to the best one (0.972) in BBS. For AP, WBBS shows better performance for all the selected patterns compared with other methods. The values of AP are all greater than 0.8 except for the pattern ‚Äò‚ÄòRandom‚Äô‚Äô, which has the AP value at 0.473. The relatively low AP is acceptable due to the fact that the ‚Äò‚ÄòRandom‚Äô‚Äô pattern cannot be assigned to a specific problem during the manufacturing process, and they are probably not used for similarity searching in practice.To evaluate the effectiveness of the tensor voting algorithm, we compared it with the mountain function ( Yager & Filev , 1994 ) for feature transformation. WBBS was applied to both of the methods to ensure a fair comparison. In addition, comparisons were also made on whether noise removal was "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_31", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 31, "text": "function ( Yager & Filev , 1994 ) for feature transformation. WBBS was applied to both of the methods to ensure a fair comparison. In addition, comparisons were also made on whether noise removal was conducted for the WBMs. Fig. 10 shows the ROC and AP curves of similarity matching results, and the combinations of the method initials are used for illustration. ‚Äò‚Äòtv_d‚Äô‚Äô and ‚Äò‚Äòtv_o‚Äô‚Äô denote the application of the proposed tensor voting based method with denoised and original samples, respectively. ‚Äò‚Äòmt_d‚Äô‚Äô and ‚Äò‚Äòmt_o‚Äô‚Äô represent the use of the mountain function for similarity computation based on the denoised and original WBMs. In both ROC and AP results, our proposed method outperforms the mountain function, demonstrat- ing its efficacy in extracting structural information. For both of the Computers & Industrial Engineering 185 (2023) 109679 7R. Wang and S. Wang Fig. 8. Comparison of ROC curves for selected WBMs. feature transformation methods, the denoised samples show better performance, which indicates the effectiveness of noise removal. We then examined the influence of the weight parameter ùõºfor sim- ilarity matching. The similarity distance was calculated with differentùõºvalues "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_32", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 32, "text": "ce, which indicates the effectiveness of noise removal. We then examined the influence of the weight parameter ùõºfor sim- ilarity matching. The similarity distance was calculated with differentùõºvalues (0,2,5,10) and the results are shown in Fig. 11. The boxplot in Fig. 11 shows the distribution of similarity distance of the query pattern ‚Äò‚ÄòDonut‚Äô‚Äô, and different colors of the box represent the number of mixed patterns included in the WBMs. For example, ‚Äò‚Äò3‚Äô‚Äô in the Computers & Industrial Engineering 185 (2023) 109679 8R. Wang and S. Wang Fig. 9. Comparison of PR curves for selected WBMs. ùë•-axis means three patterns are contained in the same WBM, with one of them being the query pattern ‚Äò‚ÄòDonut‚Äô‚Äô shown in Fig. 6. Whenùõº= 0, the variation in the number of defective points is not considered, and the similarity distance shows similar distribution for different numberof mixed pattern types, which is consistent with our intuition. When ùõºincreases, the spread of distance distribution gradually becomes separated, indicating the effectiveness of the proposed weight. Higher values ofùõºforce the distance to be smaller if the number of defective Computers & Industrial Engineering 185 (2023) 10967"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_33", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 33, "text": "becomes separated, indicating the effectiveness of the proposed weight. Higher values ofùõºforce the distance to be smaller if the number of defective Computers & Industrial Engineering 185 (2023) 109679 9R. Wang and S. Wang Table 1 Comparison of AUC and AP for selected WBMs. Pattern type AUC AP BBS WBBS DDIS SDS WSDS Hausdorff BBS WBBS DDIS SDS WSDS Hausdorff Center 0.876 0.927 0.754 0.651 0.727 0.848 0.799 0.863 0.605 0.407 0.560 0.671 Donut 0.972 0.969 0.923 0.895 0.902 0.914 0.914 0.934 0.868 0.711 0.824 0.739 Edge 0.960 0.979 0.852 0.922 0.953 0.736 0.975 0.989 0.920 0.950 0.975 0.761 Loc 0.915 0.972 0.939 0.784 0.837 0.756 0.813 0.971 0.953 0.676 0.794 0.669 Random 0.890 0.910 0.368 0.867 0.835 0.746 0.281 0.473 0.029 0.232 0.216 0.070 Scratch 0.843 0.877 0.737 0.658 0.672 0.801 0.761 0.822 0.721 0.601 0.604 0.731 Near-full 1.000 1.000 0.852 0.999 0.997 0.921 0.990 0.996 0.103 0.986 0.973 0.263 Overall 0.922 0.948 0.852 0.825 0.846 0.817 0.790 0.863 0.600 0.652 0.707 0.558 Fig. 10. Effects of feature transformation and noise removal. points is much more than the selected pattern, which improves the query results. The distance parameter ùúáhas to be tuned as well, which affects th"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_34", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 34, "text": " Effects of feature transformation and noise removal. points is much more than the selected pattern, which improves the query results. The distance parameter ùúáhas to be tuned as well, which affects the weight between the structural saliency and location information when calculating the similarity measure. In 12, it is observed that WBBS is not sensitive to ùúáfor most of the patterns including ‚Äò‚ÄòCenter‚Äô‚Äô, ‚Äò‚ÄòDonut‚Äô‚Äô, ‚Äò‚ÄòLoc‚Äô‚Äô and ‚Äò‚ÄòNear-full‚Äô‚Äô. When ùúá= 0, the AUC results of ‚Äò‚ÄòCenter‚Äô‚Äô and ‚Äò‚ÄòScratch‚Äô‚Äô are highly influenced, with the identification dependent on the pattern location. The similarity matching of the ‚Äò‚ÄòRandom‚Äô‚Äôpattern shows significant reliance on the choice of ùúá, so we setùúáto be 1 in this study. 4. Discussion The proposed method can distinguish between comparable pat- terns when both single-type and mixed-type patterns exist in the same dataset. The method is also able to identify similar WBMs considering the effects of pattern size, density and wafer rotation. Moreover, the proposed method can be performed without any pre-defined features or classes, therefore large amount of historical training data is not required. This similarity matching method can help engineers to id"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_35", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 35, "text": "oposed method can be performed without any pre-defined features or classes, therefore large amount of historical training data is not required. This similarity matching method can help engineers to iden- tify defect patterns efficiently by tracking in the history, and therefore support the diagnosis of root causes for smart productions. In this paper, we mainly examine the problem of whether the WBM consists of a particular single pattern, due to the fact that most of the examples collected in real applications consist of only single pattern types. Matching with a single pattern is also easier to consider and produces more accurate results. In addition, a mixed-type pattern can be identified by combining the thresholding results of the related single patterns and the similarity distance with the chosen single pattern, which provides useful information for pattern identification. In this situation, various patterns can be utilized as matching templates to derive similarity indices, which can then be employed as features for the WBM classification task. For WBM similarity searching, the parameters need to be deter- mined are ùõºandùúá.ùõºcontrols the degree of similarity difference for pat"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_36", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 36, "text": "h can then be employed as features for the WBM classification task. For WBM similarity searching, the parameters need to be deter- mined are ùõºandùúá.ùõºcontrols the degree of similarity difference for patterns with different numbers of defective dies. Greater values of ùõºpenalizes this variation, which gives smaller similarity measure when the density of defects in WBMs are significantly different. ùúácontrols the weight of the strength between the structural saliency and the location information. Greater values of ùúáemphasize the importance of pattern location for the determination of the WBM similarity. The weight parameters ùõºand distance parameter ùúáused for similarity calculation can be separated chosen for different patterns, as the effects of these parameters on different patterns may be significantly different. Furthermore, we define ùë§ùëùas the minimum number of defective points in the two sets to be compared because of the range of the similarity distance and the commutative property for computation. It should be noted that ùë§ùëùcan be flexibly defined in different forms based on real-world settings, resulting in different similarity ranking results for mixed-type patterns. As an example"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_37", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 37, "text": "computation. It should be noted that ùë§ùëùcan be flexibly defined in different forms based on real-world settings, resulting in different similarity ranking results for mixed-type patterns. As an example, ùë§ùëù=1 ùëÅmakes the similarity measure of different samples comparable considering a query pattern, whereùëÅis the number of defective points on the query pattern. Then for a selected pattern, the extracted similar patterns will tend to be of mixed-type that consist of at least the query pattern in the WBM, because the BBS distances remain the same for different numbers of mixed pattern types. Similarly, ùë§ùë£can be designed to account for the number difference of defective points. 5. Conclusion In this paper, we propose a novel similarity searching method for WBMs with mixed-type patterns. Using tensor voting, the structural in- formation of the defect patterns is first highlighted. The WBBS method is then proposed to support expert judgments, to find the root causes of the patterns, based on the structural saliency and location information of the defect patterns. The similarity measure are designed to give similar scores with the same pattern contained, while considering the exact similarit"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_38", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 38, "text": "e structural saliency and location information of the defect patterns. The similarity measure are designed to give similar scores with the same pattern contained, while considering the exact similarity when the number of defective points are really different. Experiments show the superiority of the proposed method in the identification of defect patterns when both single and mixed-type patterns are present. For future studies, the parameters used for similarity calculation can be separated chosen for different patterns. Furthermore, the structural Computers & Industrial Engineering 185 (2023) 109679 10R. Wang and S. Wang Fig. 11. The influence of different ùõºfor weight calculation in similarity measure. Fig. 12. Effects of the choice of ùúáon similarity searching results. data produced through tensor voting offers the opportunity for the identification and extraction of single patterns in mixed-type scenarios. This method can be used to resolve other comparable problems, to support the decision making in tasks of fault diagnosis in intelligent manufacturing systems.CRediT authorship contribution statement Rui Wang: Conceptualization, Methodology, Software, Formal anal- ysis, Data cura"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_39", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 39, "text": "cision making in tasks of fault diagnosis in intelligent manufacturing systems.CRediT authorship contribution statement Rui Wang: Conceptualization, Methodology, Software, Formal anal- ysis, Data curation, Writing ‚Äì original draft, Supervision, Funding acquisition. Songhao Wang: Methodology, Validation, Investigation, Resources, Writing ‚Äì review & editing, Visualization, Project adminis- tration, Funding acquisition. Data availability We use public data in this research, which can be found in the reference. References Adly, F., Alhussein, O., Yoo, P. D., Al-Hammadi, Y., Taha, K., Muhaidat, S., et al. (2015). Simplified subspaced regression network for identification of defect patterns in semiconductor wafer maps. IEEE Transactions on Industrial Informatics ,11(6), 1267‚Äì1276. Dou, R., He, Z., & Hsu, C.-Y. (2018). Foreword: Smart manufacturing, innovative prod- uct and service design to empower Industry 4.0. Computer & Industrial Engineering , 125, 514‚Äì516. Du, J., Yan, H., Chang, T.-S., & Shi, J. (2022). A tensor voting-based surface anomaly classification approach by using 3D point cloud data. Journal of Manufacturing Science and Engineering ,144(5), Article 051005. Hsu, C.-Y., Che"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_40", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 40, "text": " & Shi, J. (2022). A tensor voting-based surface anomaly classification approach by using 3D point cloud data. Journal of Manufacturing Science and Engineering ,144(5), Article 051005. Hsu, C.-Y., Chen, W.-J., & Chien, J.-C. (2020). Similarity matching of wafer bin maps for manufacturing intelligence to empower Industry 3.5 for semiconductor manufacturing. Computers & Industrial Engineering ,142, Article 106358. Computers & Industrial Engineering 185 (2023) 109679 11R. Wang and S. Wang Hsu, S.-C., & Chien, C.-F. (2007). Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing. International Journal of Production Economics ,107(1), 88‚Äì103. Hsu, C.-Y., & Chien, J.-C. (2022). Ensemble convolutional neural networks with weighted majority for wafer bin map pattern classification. Journal of Intelligent Manufacturing ,33(3), 831‚Äì844. Huang, D.-L., Du, S.-C., Li, G.-L., & Wu, Z.-Q. (2017). A systematic approach for online minimizing volume difference of multiple chambers in machining processes based on high-definition metrology. ASME Transactions on Manufacturing Science and Engineering ,139(8), Article 081003. Huttenlocher, D. "}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_41", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 41, "text": " volume difference of multiple chambers in machining processes based on high-definition metrology. ASME Transactions on Manufacturing Science and Engineering ,139(8), Article 081003. Huttenlocher, D. P., Klanderman, G. A., & Rucklidge, W. J. (1993). Comparing images using the Hausdorff distance. IEEE Transactions on Pattern Analysis and Machine Intelligence ,15(9), 850‚Äì863. Hwang, J., & Kim, H. (2020). Variational deep clustering of wafer map patterns. IEEE Transactions on Semiconductor Manufacturing ,33(3), 466‚Äì475. Kang, H., & Kang, S. (2021). A stacking ensemble classifier with handcrafted and convolutional features for wafer map pattern classification. Computers in Industry , 129, Article 103450. Kim, J., Lee, Y., & Kim, H. (2018). Detection and clustering of mixed-type defect patterns in wafer bin maps. IISE Transactions ,50(2), 99‚Äì111. Kyeong, K., & Kim, H. (2018). Classification of mixed-type defect patterns in wafer bin maps using convolutional neural networks. IEEE Transactions on Semiconductor Manufacturing ,31(3), 395‚Äì402. Lee, J. H., Moon, I.-C., & Oh, R. (2021). Similarity search on wafer bin map through nonparametric and hierarchical clustering. IEEE Transactions on S"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_42", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 42, "text": "s on Semiconductor Manufacturing ,31(3), 395‚Äì402. Lee, J. H., Moon, I.-C., & Oh, R. (2021). Similarity search on wafer bin map through nonparametric and hierarchical clustering. IEEE Transactions on Semiconductor Manufacturing ,34(4), 464‚Äì474. Lee, J. H., Yu, S. J., & Park, S. C. (2001). Design of intelligent data sampling methodology based on data mining. IEEE Transactions on Robotics and Automation , 17(5), 637‚Äì649. Li, G., Du, S., Huang, D., Zhao, C., & Deng, Y. (2019). Dynamics modeling-based optimization of process parameters in face milling of workpieces with discontinuous surfaces. ASME Transactions on Manufacturing Science and Engineering ,141(10), Article 101009. Li, G., Du, S., Wang, B., Lv, J., & Deng, Y. (2022). High definition metrology- based quality improvement of surface texture in face milling of workpieces with discontinuous surfaces. ASME Transactions on Manufacturing Science and Engineering , 144(3), Article 031001. Liao, C.-S., Hsieh, T.-J., Huang, Y.-S., & Chien, C.-F. (2013). Similarity searching for defective wafer bin maps in semiconductor manufacturing. IEEE Transactions on Automation Science and Engineering ,11(3), 953‚Äì960. Liao, C.-S., Hsieh, T.-J., Huan"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_43", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 43, "text": "C.-F. (2013). Similarity searching for defective wafer bin maps in semiconductor manufacturing. IEEE Transactions on Automation Science and Engineering ,11(3), 953‚Äì960. Liao, C.-S., Hsieh, T.-J., Huang, Y.-S., & Chien, C.-F. (2014). Similarity searching for defective wafer bin maps in semiconductor manufacturing. IEEE Transactions on Automation Science and Engineering ,11(3), 953‚Äì960. Medioni, G., Tang, C.-K., & Lee, M.-S. (2000). Tensor voting: Theory and applications. InProceedings of RFIA, vol. 2000 . Mordohai, P., & Medioni, G. (2010). Dimensionality estimation, manifold learning and function approximation using tensor voting.. Journal of Machine Learning Research , 11(1). Nakazawa, T., & Kulkarni, D. V. (2018). Wafer map defect pattern classification and image retrieval using convolutional neural network. IEEE Transactions on Semiconductor Manufacturing ,31(2), 309‚Äì314.Oron, S., Dekel, T., Xue, T., Freeman, W. T., & Avidan, S. (2017). Best-buddies similarity‚ÄîRobust template matching using mutual nearest neighbors. IEEE Transactions on Pattern Analysis and Machine Intelligence ,40(8), 1799‚Äì1813. Piao, M., Jin, C. H., Lee, J. Y., & Byun, J.-Y. (2018). Decision tree ensemble-base"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_44", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 44, "text": "ng using mutual nearest neighbors. IEEE Transactions on Pattern Analysis and Machine Intelligence ,40(8), 1799‚Äì1813. Piao, M., Jin, C. H., Lee, J. Y., & Byun, J.-Y. (2018). Decision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features. IEEE Transactions on Semiconductor Manufacturing ,31(2), 250‚Äì257. Qin, Y., Zhang, J., Chan, F. T., Chung, S., Niu, B., & Qu, T. (2020). A two-stage opti- mization approach for aircraft hangar maintenance planning and staff assignment problems under MRO outsourcing mode. Computers & Industrial Engineering ,146, Article 106607. Saito, T., & Rehmsmeier, M. (2015). The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PLoS One . Shin, W., Kahng, H., & Kim, S. B. (2022). Mixup-based classification of mixed-type defect patterns wafer bin maps. Computers & Industrial Engineering ,167, Article 107996. Talmi, I., Mechrez, R., & Zelnik-Manor, L. (2017). Template matching with deformable diversity similarity. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 175‚Äì183). Wang, R., & Chen, N. (2022). Detection and rec"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_45", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 45, "text": ". Template matching with deformable diversity similarity. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 175‚Äì183). Wang, R., & Chen, N. (2022). Detection and recognition of mixed-type defect patterns in wafer bin maps via tensor voting. IEEE Transactions on Semiconductor Manufacturing , 35(3), 485‚Äì494. Wang, R., & Wang, S. (2022). Tensor voting based similarity matching of wafer bin maps in semiconductor manufacturing. In 2022 5th international conference on data science and information technology (pp. 1‚Äì6). IEEE. Wang, J., Xu, C., Yang, Z., Zhang, J., & Li, X. (2020). Deformable convolutional networks for efficient mixed-type wafer defect pattern recognition. IEEE Transactions on Semiconductor Manufacturing ,33(4), 587‚Äì596. Wu, M.-J., Jang, J.-S. R., & Chen, J.-L. (2014). Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Transactions on Semiconductor Manufacturing ,28(1), 1‚Äì12. Wu, T.-P., Yeung, S.-K., Jia, J., Tang, C.-K., & Medioni, G. (2011). A closed-form solution to tensor voting: Theory and applications. IEEE Transactions on Pattern Analysis and Machine Intelligence ,34(8), 1482‚Äì1495. Yager, R."}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_46", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 46, "text": "ia, J., Tang, C.-K., & Medioni, G. (2011). A closed-form solution to tensor voting: Theory and applications. IEEE Transactions on Pattern Analysis and Machine Intelligence ,34(8), 1482‚Äì1495. Yager, R., & Filev, D. (1994). Approximate clustering via the mountain method. IEEE Transactions on Systems, Man, and Cybernetics ,24(8), 1279‚Äì1284. Yu, J., & Lu, X. (2015). Wafer map defect detection and recognition using joint local and nonlocal linear discriminant analysis. IEEE Transactions on Semiconductor Manufacturing ,29(1), 33‚Äì43. Yuan, T., & Kuo, W. (2008). Spatial defect pattern recognition on semiconductor wafers using model-based clustering and Bayesian inference. European Journal of Operational Research ,190(1), 228‚Äì240. Zhang, C., Yan, H., Lee, S., & Shi, J. (2018a). Multiple profiles sensor-based monitoring and anomaly detection. Journal of Quality Technology ,50(4), 344‚Äì362. Zhang, C., Yan, H., Lee, S., & Shi, J. (2018b). Weakly correlated profile monitor- ing based on sparse multi-channel functional principal component analysis. IISE Transactions ,50(10), 878‚Äì891. Zhang, Z., Yang, X., & Gao, H. (2020). Weighted smallest deformation similarity for NN-based template matching. IE"}
{"id": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf::chunk_47", "source": "Similarity searching for fault diagnosis of defect patterns in wafer bin maps.pdf", "chunk_index": 47, "text": "-channel functional principal component analysis. IISE Transactions ,50(10), 878‚Äì891. Zhang, Z., Yang, X., & Gao, H. (2020). Weighted smallest deformation similarity for NN-based template matching. IEEE Transactions on Industrial Informatics ,16(11), 6787‚Äì6795. Zhu, J., Huang, C.-G., Shen, C., & Shen, Y. (2022). Cross-domain open-set machinery fault diagnosis based on adversarial network with multiple auxiliary classifiers. IEEE Transactions on Industrial Informatics ,18(11), 8077‚Äì8086."}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_0", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 0, "text": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns Min-Su Kanga, Jin-Su Shinb,c, Dong-Hee Leea,* aDepartment of Industrial Engineering, Sungkyunkwan University, 2066 Seobu-ro, Jangan-gu, Suwon 16419, Republic of Korea bDepartment of Semiconductor and Display Engineering, Sungkyunkwan University, 2066, Seobu-ro, Suwon-si, Gyunggi-do 16419, Republic of Korea cMemory Division, Samsung Electronics Co, Ltd., 1-1 Samsungjeonja-ro Hwaseong-si, Gyeonggi-do 18448, Republic of Korea ARTICLE INFO Keywords: Wafer bin map Similarity searching Semiconductor manufacturing Unsupervised learning Defect patternABSTRACT A wafer bin map (WBM) is a visual representation of the spatial distribution of defective chips on a wafer. WBMs showing specific defect patterns are usually a result of process-assignable causes; thus, it is important to identify them to eliminate assignable causes. With advances in semiconductor manufacturing technology, identifying new defect patterns, and diagnosing their causes have become critical. However, most existing methods for WBM analysis use a supervised learning approach, which only detects previously known def"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_1", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 1, "text": "fying new defect patterns, and diagnosing their causes have become critical. However, most existing methods for WBM analysis use a supervised learning approach, which only detects previously known defect patterns. The similarity- search approach is a suitable alternative for defining new defect patterns. The proposed method uses an unsu- pervised approach to search for similar WBMs by measuring the similarities of three spatial features of defect patterns ‚Äìshape, location, and size‚Äìwhich are useful for defining new defect patterns and diagnosing their causes. These three similarities are achieved using tensor voting and the mountain function for shape similarity, Euclidean distance for location similarity, and a combination of defect count and average radius for size simi- larity. The overall similarity was assessed using the weighted average of the three similarities. The weights are determined by quantifying the uncertainty of each similarity based on information entropy theory to better distinguish between similar patterns. The experimental results demonstrate the effectiveness of the proposed method compared to existing methods and highlight its capability to identify and descr"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_2", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 2, "text": "tter distinguish between similar patterns. The experimental results demonstrate the effectiveness of the proposed method compared to existing methods and highlight its capability to identify and describe the spatial features of defect patterns. 1.Introduction After the intricate process of semiconductor manufacturing, where integrated circuits (ICs) are created on wafers, each chip undergoes an electrical die sorting test using probes to assess its basic functionality. The outcomes of these tests are mapped to corresponding wafer bin numbers. By utilizing these wafer bin numbers, a visualization of in- terest for defective areas is created, forming what is known as a wafer bin map (WBM) (Kyeong & Kim, 2018). The shapes or patterns of the combined chips in this WBM provide insights into process variability, equipment malfunctions, material defects, design flaws, and environ - mental factors. Therefore, accurate detection and comparison of defect patterns in WBM present an opportunity for improvement in semi- conductor manufacturing (Chen & Liu, 2000; Hsu & Chien, 2007 ).WBM analysis can be broadly categorized into two branches: su- pervised and unsupervised. Recent studies have reli"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_3", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 3, "text": "r improvement in semi- conductor manufacturing (Chen & Liu, 2000; Hsu & Chien, 2007 ).WBM analysis can be broadly categorized into two branches: su- pervised and unsupervised. Recent studies have relied predominantly on supervised learning techniques (Gallo & Capozzi, 2020; Kahng & Kim, 2021; Lee & Kim, 2020; Park & You, 2023; Wang & Ni, 2023), which involve pre-existing knowledge of defect patterns, labeled data, and extensive training processes. However, as technology advances rapidly, semiconductor manufacturing processes evolve swiftly, leading to the emergence of new defect patterns in WBM (Kyeong & Kim, 2018; Liao et al., 2014 ). Supervised learning methods are limited to identifying only patterns that are known beforehand, posing a significant constraint in the dynamic environment of semiconductor manufacturing, where new defect patterns frequently emerge (Lee et al., 2023 ). The adoption of similarity search methods is necessary to detect new and unknown defect patterns effectively (Lee et al., 2021 ). These Abbreviations: ICs, integrated circuits ; WBM, wafer bin map; SVM, support vector machine ; CNN, convolutional neural network ; PCA, principal component analysis ; GANs"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_4", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 4, "text": "vely (Lee et al., 2021 ). These Abbreviations: ICs, integrated circuits ; WBM, wafer bin map; SVM, support vector machine ; CNN, convolutional neural network ; PCA, principal component analysis ; GANs, generative adversarial networks ; DPGMM, Dirichlet Process Gaussian Mixture Model ; DCNN, Deep Convolutional Neural Network ; WSCN, WaferSegClassNet . *Corresponding author. E-mail address: dhee@skku.edu (D.-H. Lee). Contents lists available at ScienceDirect Computers & Industrial Engineering u{ÔøΩ~zkw! s{yo|kr o>!√ê√ê√ê1owÔøΩo ÔøΩto~1m{y2w{m kÔøΩo2mkto https://doi.org/10.1016/j.cie.2024.110486 Received 10 March 2024; Received in revised form 26 July 2024; Accepted 13 August 2024 Computers & Industrial Engineering 196 (2024) 110486 Available online 14 August 2024 0360-8352/¬© 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies. approaches involve comparing defect patterns across different wafers, identifying recurring issues and trends that are crucial for rapid di- agnostics, and making efficient process improvements. According to Hwang & Kim (2020) , analyzing the process histories of similar failures within a database can"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_5", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 5, "text": " trends that are crucial for rapid di- agnostics, and making efficient process improvements. According to Hwang & Kim (2020) , analyzing the process histories of similar failures within a database can provide information for defect diagnosis and root cause analysis, even in the absence of predefined classes. Additionally, (Park et al. (2021 ) suggest that using a similarity search on a WBM can help detect new categories of previously unidentified defect patterns. In recent years, several studies using similarity search techniques for WBM analysis have been conducted. Liao et al. (2014) were the first to propose an algorithm that utilizes label information to perform simi- larity searches and rank WBMs based on similarity. Subsequently, methods employing supervised learning, which require label informa - tion, were developed for similarity searching (Kong & Ni, 2022; Naka - zawa & Kulkarni, 2018; Yu et al., 2019 ). The supervised learning approaches used in these studies generally provide excellent perfor - mance. However, they have the limitation of identifying only previously recognized patterns. To overcome this limitation, the use of unsupervised learning for similarity searches"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_6", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 6, "text": "de excellent perfor - mance. However, they have the limitation of identifying only previously recognized patterns. To overcome this limitation, the use of unsupervised learning for similarity searches was proposed (Wu et al., 2015 ). Subsequent research focused on different aspects of defect patterns. For instance, Hsu et al. (2020) focused on capturing the density of defect clusters, while Lee et al. (2021) identified the locations of the defect clusters. Recently, Wang & Wang (2022) emphasized capturing the shapes of the defect clusters. However, existing research on similarity searches fails to sufficiently capture the spatial features. For instance, Hsu et al. (2020) focused on capturing the density of defect clusters, while Lee et al. (2021) identified the locations of the defect clusters of defect patterns, thereby not providing adequate information about defects related to semiconductor manufacturing processes. Fundamentally, the spatial features of the defect patterns can be described in three dimensions: shape, size, and location. For an effective process diagnosis, it is crucial to identify the precise causes of defects and provide detailed information, such as lot or mac"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_7", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 7, "text": "scribed in three dimensions: shape, size, and location. For an effective process diagnosis, it is crucial to identify the precise causes of defects and provide detailed information, such as lot or machine numbers, to better understand the defects. In this context, we believe that a method presenting three spatial aspects of defect patterns offers a higher likelihood of providing more detailed information about defects, along with defect suspicions, compared to considering only one or two aspects. Therefore, it is essential to simultaneously search for WBMs with similar defect patterns in all three aspects. However, the existing methods lack the ability to identify detailed spatial information regarding the shape, size, and location of defect patterns, thereby limiting their effectiveness in diagnosing the causes and improving the occurrence of defect patterns in semiconductor manufacturing processes. For example, during photolithography, patterns are imprinted onto the wafer surface using light (Nguyen et al., 2022), stage movement, or stepper motor errors. These errors are often observed as linear defect patterns in WBMs. Most linear defect patterns are unique because they have di"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_8", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 8, "text": "ing light (Nguyen et al., 2022), stage movement, or stepper motor errors. These errors are often observed as linear defect patterns in WBMs. Most linear defect patterns are unique because they have different locations and sizes, and these differences result from different causes. In such cases, searching for linear defect patterns with similar locations and sizes is useful for tracking and diagnosing the causes. However, the existing methods focus on searching for linear- shaped patterns without considering their size and location. This claim is true not only for linear shapes but also for other shapes such as arcs, donuts, clusters, and rings. Chemical‚Äìmechanical planarization, a major semiconductor manufacturing process, can cause uneven slurry distri - bution, pad wear, and inconsistent pressure (Basim & Moudgil, 2002 ). These failures result in cluster-shaped patterns such as hotspots. Simi- larly, existing methods focus on searching for cluster-shaped patterns without considering their location and size in WBMs. This study proposes a similarity search method that independently measures shape, location, and size similarities. This method can be applied to evaluate and explain t"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_9", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 9, "text": "their location and size in WBMs. This study proposes a similarity search method that independently measures shape, location, and size similarities. This method can be applied to evaluate and explain the detailed features of defect patterns (i.e., shape, location, and size), thereby addressing the limitations of existing methods. Moreover, it enables easy identification of new defect patterns based on these three similarities. We used tensor voting and the mountain function to measure the shape similarity, the Euclidean dis- tance of the defect center between the two WBMs for location similarity, and the variance of the number of defects, in addition to the average radius of the defect cluster for size similarity. The overall similarity was then measured using a weighted average. Each weight was measured based on the uncertainty of its weight similarity using information en- tropy. This method enables a detailed comparison of how each WBM resembles the reference WBM in specific aspects, thus allowing engi- neers to adjust their weights to emphasize the features of interest. Unlike previous studies that failed to adequately consider shape, location, and size, our proposed method inte"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_10", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 10, "text": " thus allowing engi- neers to adjust their weights to emphasize the features of interest. Unlike previous studies that failed to adequately consider shape, location, and size, our proposed method integrates all three dimensions. This study presents the following specific contributions and nov- elties: Firstly, it proposes a similarity search method capable of inde- pendently measuring the similarity in shape, location, and size. This enables more precise analysis of defect patterns within complex WBM (Wafer Bin Map) images. Secondly, it introduces a method that utilizes information entropy to set weights according to the uncertainty of similarity measurements. This contributes to enhancing the accuracy of similarity assessments. Thirdly, by proposing an unsupervised learning- based WBM image classification method, it addresses the limitations associated with labeling and presents the possibility of detecting un- known defect types. This approach is expected to overcome the limita - tions of existing methods and significantly improve the efficiency of defect pattern analysis and detection in semiconductor manufacturing processes. The remainder of this paper is structured as follows:"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_11", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 11, "text": "ns of existing methods and significantly improve the efficiency of defect pattern analysis and detection in semiconductor manufacturing processes. The remainder of this paper is structured as follows: Section 2ex- plores the related literature. Section 3details the proposed method for similarity search. Experiments utilizing different datasets are presented in Section 4. Section 5addresses the potential limitations of our approach and concludes. 2.Literature review Table 1presents a review of various literatures on defect analysis in Wafer Bin Maps (WBM). WBM defect analysis research can be broadly divided into two main categories: one focusing on the accurate class classification of defect patterns, and the other utilizing similarity with target wafer maps to identify more clear and specific causes of defects, thereby aiding in engineering solutions. The existing studies on WBM defect analysis primarily employ supervised learning algorithms (Kim & Behdinan, 2023 ), particularly those studies on defect pattern classifi - cation aim to learn predefined defect type classes to detect them accu- rately and efficiently. However, these studies require pre-labeled data and have the limita"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_12", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 12, "text": "studies on defect pattern classifi - cation aim to learn predefined defect type classes to detect them accu- rately and efficiently. However, these studies require pre-labeled data and have the limitation of potential misclassification when new, un- learned defect types occur. With the miniaturization of semiconductor processes and the introduction of new processes and equipment, there is an increasing demand for methods capable of identifying defect patterns similar to those of interest (typically new patterns). This demand has stimulated research on similarity search methods. The research on similarity comparison can be divided into supervised and unsupervised learning-based studies, with supervised learning methods using labeled data to search for WBMs similar to reference maps. Various studies have been conducted on this approach, highlighting its importance and effectiveness in identifying comparable defect patterns in WBMs. Liao et al. (2014) proposed the concept of similarity search and designed a morphology-based support vector machine (SVM) for simi- larity retrieval that integrates morphological operations and SVM clas- sification to detect defect patterns in WBMs. Morpho"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_13", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 13, "text": "arch and designed a morphology-based support vector machine (SVM) for simi- larity retrieval that integrates morphological operations and SVM clas- sification to detect defect patterns in WBMs. Morphological operations generate synthetic samples that simulate various defect patterns and enrich training datasets. The SVM classifier trained on this synthetic dataset identified the separation hyperplane between the defect classes. Nakazawa & Kulkarni (2018) developed and applied a convolutional neural network (CNN) for the classification and image retrieval of defect patterns in WBM. This method leverages synthetic WBMs to train a CNN, achieving high classification accuracy and demonstrating the ability to M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 2 efficiently retrieve similar defect patterns from a large database. Yu et al. (2019) presented a method for recognizing and searching for defect patterns in WBMs using CNNs and principal component analysis. This study introduces two CNN models, an 8-layer model for the initial inspection of defect patterns on WBMs and a more detailed 13- layer model dedicated to classifying specific defect patterns. For post- c"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_14", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 14, "text": "udy introduces two CNN models, an 8-layer model for the initial inspection of defect patterns on WBMs and a more detailed 13- layer model dedicated to classifying specific defect patterns. For post- classification, the method extracts features using a CNN and then em- ploys principal component analysis (PCA) for dimensionality reduction. In addition, it retrieves similar defect patterns and ranks them according to their similarities. Kong & Ni (2022) proposed a deep CNN-based retrieval method resembling generative adversarial networks (GANs) to identify WBMs with unknown defect patterns by exploring the similarities between the defect patterns in WBMs. This approach is designed to work effectively even with a very limited number of samples for unknown defect pat- terns, addressing a common challenge in WBM defect pattern analysis. Generally, these supervised learning-based methods perform well in searching for WBMs with defect patterns similar to the reference pattern. However, they present practical difficulties because they require a long training time, which can lead to inefficiency in the manufacturing pro- cess. Engineers are also required to manually label the defect patterns"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_15", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 15, "text": "esent practical difficulties because they require a long training time, which can lead to inefficiency in the manufacturing pro- cess. Engineers are also required to manually label the defect patterns. This is time-consuming and labor-intensive, and it presents a major shortcoming in achieving process automation. Moreover, as mentioned in Section 1, they are constrained to identifying only previously known patterns, which is a significant limitation in the dynamic environment of semiconductor manufacturing, where new defect patterns emerge frequently (Lee et al., 2023 ). To overcome these limitations, several studies have been conducted that do not require label information. Wu et al. (2015) proposed a sys- tem that extracts radon/geometry-based features and uses a SVM for classification. In addition, a wafer map similarity ranking based on the Euclidean distance of the extracted features was designed to retrieve defect patterns on WBMs, similar to a given query wafer map, which can assist engineers in identifying the root causes of similar failure patterns. Hsu et al. (2020) employed a modified mountain function for the feature transformation. This method enhances defect features "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_16", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 16, "text": "sist engineers in identifying the root causes of similar failure patterns. Hsu et al. (2020) employed a modified mountain function for the feature transformation. This method enhances defect features based on clustering density. To measure the similarity between defect patterns on WBMs, weighted modified Hausdorff distance was utilized, and metrics for binary classification were used to assess the accuracy of the model in identifying similar and dissimilar defect patterns in WBMs. Lee et al. (2021) applied the polar coordinate transform, Dirichlet Process Gaussian Mixture Model (DPGMM), and the hierarchical clus- tering method to cluster similar defect patterns. In addition, weight vectors with respect to the clusters were derived to serve as reduced representations of the defect patterns in the WBMs. The similarity between the defect patterns was measured using Jensen ‚ÄìShannon divergence based on the derived weight vectors. Wang & Wang (2023) utilized tensor voting to remove noise and highlight structural information. They then used the weighted best- buddies similarity to measure the similarity between the defect pat- terns. The effectiveness of their method was assessed through "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_17", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 17, "text": " highlight structural information. They then used the weighted best- buddies similarity to measure the similarity between the defect pat- terns. The effectiveness of their method was assessed through binary classification to determine whether a WBM contained a specific query pattern. Wang & Wang (2023) addressed the challenges in recognizing rare- and mixed-type defects by proposing a similarity-searching approach. Numerous similarity search studies have been conducted; however, there is a lack of comprehensive consideration of shape, location, and size. While Hsu et al. (2020) focused on density, they did not adequately address the spatial characteristics of defect patterns, leading to analyses that missed essential details regarding defect locations. This oversight is particularly crucial for the accurate evaluation of ring patterns, where understanding the spatial context is crucial for accuracy. Wu et al. (2015) and Lee et al. (2021) considered the geometric features of defect patterns and the positioning of clusters but did not fully explore the shape attributes. Additionally, Wang & Wang (2023) did not thoroughly address the location or size of the defect patterns. This limit"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_18", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 18, "text": "erns and the positioning of clusters but did not fully explore the shape attributes. Additionally, Wang & Wang (2023) did not thoroughly address the location or size of the defect patterns. This limitation is particularly significant for cluster-shaped patterns, defined as circular defect clusters, where the size plays a crucial role in differentiating them from ring-shaped patterns, with variations in size suggesting different root causes. Overall, there is a gap in existing research on the integration of spatial features in similarity search methodologies. The proposed method attempts to independently assess shape, location, and size before synthesizing these dimensions to establish a comprehensive similarity ranking and ensure thorough consideration of spatial characteristics. As highlighted in Section 1, we emphasize the critical need to consider shape, size, and location to distinguish between linear and cluster shapes. Despite the significance of these factors, existing supervised and unsupervised methods have struggled to address them adequately. Our method addresses these gaps by providing a comprehensive approach that integrates shape, location, and size into the similarit"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_19", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 19, "text": "d and unsupervised methods have struggled to address them adequately. Our method addresses these gaps by providing a comprehensive approach that integrates shape, location, and size into the similarity search process, thereby facilitating more precise root cause analysis and similarity assessment. 3.Proposed method The proposed method aims to compute the similarity between the defect patterns of two WBMs. The first corresponds to a reference WBM that typically has a new defect pattern of interest. The other corresponds to the candidate WBM, which is compared with the reference WBM. The reference and candidate WBM are denoted as P and Q, respectively. To Table 1 Literature review. Reference Object Learning type Algorithm Method of Studies (S. Chen et al., 2022 ) Classification Supervised Dual DCNN WBM Defect Pattern class Classification (Xu et al., 2022 ) ResNet 18 (E. S. Kim et al., 2021 ) ResNet50 (J. Yu et al., 2021 ) DenseNet-GCForest (Bae & Kang, 2023 ) Modified VGG16 (Nag et al., 2022 ) WSCN WBM Defect Pattern class Classification & Segmentation (Shinde et al., 2022 ) YOLO V4 WBM Defect Pattern class Classification & Localization Detect (Liao et al., 2014 ) Similarity Search S"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_20", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 20, "text": "2022 ) WSCN WBM Defect Pattern class Classification & Segmentation (Shinde et al., 2022 ) YOLO V4 WBM Defect Pattern class Classification & Localization Detect (Liao et al., 2014 ) Similarity Search Supervised M\u0000SVM SVM trained on set of WBMs constructed by domain experts (Engineer ‚Äôs domain) (Nakazawa & Kulkarni, 2018 )CNN Binary classification (whether similar or not) (N. Yu et al., 2019 ) CNN/PCA Similarity using hamming distance between latent vectors (Kong & Ni, 2022 ) CNN/GAN Similarity using Euclidean Distance between Feature vector (Wu et al., 2015 ) Unsupervised Radon transform/SVM Similarity using Euclidean Distance between Feature vector (C. Y. Hsu et al., 2020 ) Mountain function Similarity using Weighted Modified Hausdorff Distance (J. H. Lee et al., 2021 ) DPGMM/ Hierarchical clustering Similarity using the Jensen ‚ÄìShannon divergence (Wang & Wang, 2023 ) Tensor voting Similarity using best-buddies similarity score Proposed Similarity SearchUnsupervised Mountain function/Tensor votingSimilarity search using shape, location, and sizeM.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 3 compute the similarity between P and Q, three individual similarit"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_21", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 21, "text": "ensor votingSimilarity search using shape, location, and sizeM.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 3 compute the similarity between P and Q, three individual similarities of shape, location, and size between P and Q are computed and then aggregated into the overall similarity. We assume that P and Q have the same number of dies and are denoted by N. The notations associated with P are listed in Table 2. The notation in Table 2is also related to Q if we regard P as Q. The overall flowchart of the proposed method operates as shown in Fig. 1. Initially, noise is filtered through two preprocessing stages of the WBM. Next, shape similarity is assessed using the product of density similarity and stick-ball similarity. The modified mountain function is utilized to determine density similarity, while tensor voting is used to derive stick-ball saliency. Subsequently, location similarity is computed based on the distance between the centroids of the patterns in the two WBMs. Size similarity is determined by the product of the similarity in the number of defects and the radius of the patterns. Finally, overall similarity is derived by summing all individual si"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_22", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 22, "text": "he two WBMs. Size similarity is determined by the product of the similarity in the number of defects and the radius of the patterns. Finally, overall similarity is derived by summing all individual similarities using a weighted average approach. 3.1. Noise filtering The proposed method includes a two-step noise-filtering process that involves the sequential use of c-mean filtering and tensor-voting algo- rithms. This eliminates unnecessary information from the WBMs images and extracts more accurate defect patterns to help the proposed simi- larity searching process focus only on defect patterns and not on noise. In WBMs, some defective chips deviate significantly from the defect patterns; therefore, these cases are considered noise and must be removed to enhance the performance of the proposed method. The effect of noise filtering is directly related to the improvement in algorithm performance, and this two-step noise filtering process differs from that of previous studies. First, c-mean filtering proposed by (Yu et al., 2021 ) was conducted. This filtering method is effective in maintaining linear patterns by specifying the areas surrounding each faulty die, such as scratch pat- t"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_23", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 23, "text": "an filtering proposed by (Yu et al., 2021 ) was conducted. This filtering method is effective in maintaining linear patterns by specifying the areas surrounding each faulty die, such as scratch pat- terns. It specifically targets the area surrounding each defective die, proving to be efficient in maintaining linear patterns, such as scratch patterns. According to (Xu et al., 2022 ), this method prevents edge blurring or the misclassification of normal dies as defective. As listed in Table 2, each defective die has a bin value of two. Based on the following equation, the bin value of each chip was updated: If the updated bin value is 1, the corresponding die is considered noise. Bin Pi¬Ü¬à| ‚®Ü„Äà ‚®Ü‚éú2if1 ‚Ä†ni‚Ä†ÃÇ j‚àÉniBin\u0000 Pj) ‚âΩtc 1othersfori‚àÉPdef Second, noise filtering was conducted through tensor voting, which is a pattern-recognition algorithm (Medioni et al., 2000 ). This method involves gathering votes Sij from nearby pixels to capture spatial char- acteristics, which are represented as a second-order symmetric tensor Ki (T.-P. Wu et al., 2016) as follows: Ki¬àÃÇ jSijforiCj‚àÉPdef Subsequently, the tensor-voting process at point PiCinfluenced by the tensor Kj located at Pj is described by t"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_24", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 24, "text": "econd-order symmetric tensor Ki (T.-P. Wu et al., 2016) as follows: Ki¬àÃÇ jSijforiCj‚àÉPdef Subsequently, the tensor-voting process at point PiCinfluenced by the tensor Kj located at Pj is described by the following formula: Sij¬àcijRijKjRij π Matrix Rij is a rotation matrix that modifies the orientation of a tensor based on the directional relationship between points Pi and Pj, with unit vector rij where Rij¬àI\u00002rijrijT and Rij π¬à I\u00002rijrijT¬ÜRijT. The Rij π¬à I\u0000 2rijrijT¬ÜRijT combines a reflection operation I\u00002rijrijT, with the transpose of Rij to make the final orientation and contribution of Kj to Pi through Sij. Here, I represents the identity matrix and rij is a unit vector pointing from Pj to Pi. cij¬àexp[ \u0000d PiCPj¬Ü œÉd] is the normalization factor with œÉd, the scale parameter which affects how cij decreases with distance. In our approach, Ki initially begins as an identity matrix and is subsequently updated immediately after gathering all tensor votes. After the process of aggregating tensor votes is completed, Ki is decomposed into Ki¬àŒª1e‚Üó 1e‚Üó 1T¬áŒª2e‚Üó 2e‚Üó 2T where e‚Üó 1 and e‚Üó 2 are the eigenvectors of Ki with corresponding ei- genvalues Œª1, Œª2 (Œª1 ‚âΩŒª2). Ki can be further split into st"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_25", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 25, "text": "or votes is completed, Ki is decomposed into Ki¬àŒª1e‚Üó 1e‚Üó 1T¬áŒª2e‚Üó 2e‚Üó 2T where e‚Üó 1 and e‚Üó 2 are the eigenvectors of Ki with corresponding ei- genvalues Œª1, Œª2 (Œª1 ‚âΩŒª2). Ki can be further split into stick and ball components as follows: Ki¬àŒªsTs¬áŒªbTb where Ts¬àe‚Üó 1e‚Üó 1T\u0000e‚Üó 2e‚Üó 2T and Tb¬àe‚Üó 2e‚Üó 2T. Here, Œªs ¬àŒª1 \u0000Œª2 represents stick saliency, indicating the confidence of the direction encoded. Tb ¬àŒª2 reflects ball saliency, measuring the extent to which the point ‚Äôs structure is non-oriented. A higher Œªs value suggests a concen - tration of surrounding points forming a line, while a higher Œªb indicates a clustering of points into a ball shape. By retaining the points satisfying Œªs‚âΩtt√ómax Œªs¬Üand Œªb‚âΩtt√ómax Œªb¬Ü, patterns resembling lines and spheres can be isolated( Wang & Wang, 2023 ). Wang & Wang (2023) demonstrated that conducting tensor voting exclusively on defective dies in WBMs can effectively identify defect patterns. Œªs and Œªb values derived from tensor voting on defective dies provide insights into the patterns formed, which are instrumental for the next phase of similarity measurement.Table 2 List of notations. Symbol Description Value iCj Index of the ith (jth) die on P iCj‚àÉ‚äî1C"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_26", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 26, "text": "e insights into the patterns formed, which are instrumental for the next phase of similarity measurement.Table 2 List of notations. Symbol Description Value iCj Index of the ith (jth) die on P iCj‚àÉ‚äî1C2C‚ãØCN‚äì Pi Coordinate of the ith die on P\u0000 xiCyi)T‚àÉc2F0 Bin Pi¬Ü Bin value of the ith die on P. 0 for background, 1 for normal die, 2 for defective dieBin Pi¬Ü‚àÉ‚äî0C1C2‚äì Pdef Set of defective dies on P Pdef¬à ‚äîi‚Ä†Bin Pi¬Ü¬à2‚äì‚É¶‚É¶Pdef‚É¶‚É¶ Cardinality of Pdef‚É¶‚É¶Pdef‚É¶‚É¶‚àÉc‚âΩ0C‚É¶‚É¶Pdef‚É¶‚É¶‚âºN ni Set of neighbors around Pi ni‚äÇ‚äîP1C‚ãØCPN‚äì tc Threshold for c-mean filtering tc‚àÉZF0 Ki Geometric tensor at Pi Ki‚àÉZ2√ó2 Sij Tensor vote cast by Pj to Pi Sij‚àÉZ2√ó2 cij Weighting coefficient using in tensor voting cij‚àÉZ‚âΩ0 Rij Rotation matrix aligns the tensor vote Rij‚àÉZ2√ó2 Rij πModified rotation matrix aligns the tensor vote Rij π‚àÉZ2√ó2 d PiCPj¬ÜEuclidean distance between Pi and Pj d PiCPj¬Ü‚àÉZ‚âΩ0 œÉd Scale parameter of cij œÉd‚àÉZ‚âΩ0 rij Unit vector pointing from Pj to Pi rij‚àÉZ2 ‚âΩ0 Œª1 Largest eigenvalue of Ki Œª1‚àÉZ Œª2 Second largest eigenvalue of Ki Œª2‚àÉZ e‚Üó 1Eigenvector corresponding to the eigenvalue Œª1 e‚Üó 1‚àÉZ2 ‚âΩ0 e‚Üó 2 Eigenvector corresponding to the eigenvalue Œª2 e‚Üó 2‚àÉZ2‚âΩ0 Œªs Stick saliency of Ki Œªs‚àÉZ‚âΩ0 Œªb Ball saliency of Ki Œªb‚àÉZ‚âΩ0 Ts "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_27", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 27, "text": " of Ki Œª2‚àÉZ e‚Üó 1Eigenvector corresponding to the eigenvalue Œª1 e‚Üó 1‚àÉZ2 ‚âΩ0 e‚Üó 2 Eigenvector corresponding to the eigenvalue Œª2 e‚Üó 2‚àÉZ2‚âΩ0 Œªs Stick saliency of Ki Œªs‚àÉZ‚âΩ0 Œªb Ball saliency of Ki Œªb‚àÉZ‚âΩ0 Ts Stick tensor of Ki Ts‚àÉZ2√ó2 Tb Ball tensor of Ki Tb‚àÉZ2√ó2 tt Threshold for tensor voting filtering tt‚àÉZF0 M Pi¬Ü Mountain value of Pi M Pi¬Ü‚àÉZ‚âΩ0 Œ≤ Normalizing factor for mountain function Œ≤‚àÉZ‚âΩ0 Pcentroid Coordinate of centroid of Pdef Pcentroid‚àÉ‚äîP1C‚ãØC PN‚äì Pcenter Coordinate of center of P Pcenter‚àÉ‚äîP1C‚ãØCPN‚äì ŒªPi Saliencies of Pi ŒªsCŒªb¬ÜT‚àÉZ2‚âΩ0 RP The radius of defect pattern in P RP‚àÉZ‚âΩ0 H Uncertainty derived by informational entropy H‚àÉZ‚âΩ0M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 4 3.2. Shape similarity Density and stick-ball features are essential indicators for describing the shape of defect patterns, with ball-like shapes indicating clustered defects due to contamination and stick-like shapes indicating systematic defects from photolithography or etching processes. Therefore, the shape similarity was calculated as the product of the density similarity and stick-ball similarity as follows: This approach is based on the premise that both the concentration of defect"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_28", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 28, "text": "herefore, the shape similarity was calculated as the product of the density similarity and stick-ball similarity as follows: This approach is based on the premise that both the concentration of defects and the presence of distinct stick-ball patterns are critical for characterizing the shapes of defect clusters. Combining these two measures into a single metric al- lows for a precise evaluation of shape similarity and captures the complexity of defect patterns. shapesimilarity¬àdensitysmilarity√ó stick\u0000ballsimilarity¬ÜB The density similarity was assessed by comparing the defect densities at the centroid of P. We employed a modified mountain function to calculate the density at the centroid, which approximates the probability density function of the feature according to Hsu et al. (2020) . The density similarity is defined as follows: densitysimilarity¬à1\u0000‚É¶‚É¶‚É¶‚É¶‚É¶‚É¶M Pcentroid¬Ü max i‚àÉ‚äî1C‚ãØCN‚äì M Pi¬Ü¬Ü\u0000M Qcentroid¬Ü max i‚àÉ‚äî1C‚ãØCN‚äì M Qi¬Ü¬Ü‚É¶‚É¶‚É¶‚É¶‚É¶‚É¶C where M Pi¬Ü¬à‚ãÉ j‚àÉPdefexp\u0000 \u0000Œ≤‚â°d\u0000 PiCPj)) and Pcentroid¬à1 ‚Ä†Pdef‚Ä†‚ãÉ i‚àÉPdefPi. Here, Œ≤ serves as a normalizing factor for distances, calculated as Œ≤¬à‚åä‚ãÉ jd PjCPcenter¬Ü N‚åã\u00001 BBy normalizing the mountain function value to its maximum within the WBM and calculating"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_29", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 29, "text": "‚Ä†Pdef‚Ä†‚ãÉ i‚àÉPdefPi. Here, Œ≤ serves as a normalizing factor for distances, calculated as Œ≤¬à‚åä‚ãÉ jd PjCPcenter¬Ü N‚åã\u00001 BBy normalizing the mountain function value to its maximum within the WBM and calculating the difference, we normalize and compute the density similarity within the range [0, 1]. The stick-ball Similarity is determined based on the saliency of the stick and ball shapes derived during the tensor-voting process explained in Section 3.1. This was calculated using the following formula: stick\u0000ballsimilarity¬àexp‚é¢ ‚àÆ\u00001‚É¶‚É¶Pdef‚É¶‚É¶‚É¶‚É¶Qdef‚É¶‚É¶ÃÇ i‚àÉPdefÃÇ j‚àÉQdefd( ŒªPiCŒªQj)‚é• ‚®ÄB Here, 1 ‚Ä†Pdef‚Ä†‚Ä†Qdef‚Ä†‚ãÉ i‚àÉPdef‚ãÉ j‚àÉQdefd( ŒªPiCŒªQj) represents the average Euclidean distance between the saliencies of each defective die in two WBMs, with ŒªPi denoting the saliency ŒªsCŒªb¬Üof the ith die on P. This approach causes the stick-ball similarity to fall within the range [0, 1] and decrease rapidly as the differences grow. 3.3. Location similarity Location similarity is calculated by determining the Euclidean dis- tance between the centroids of the defective dies on two WBMs. This distance is then used in an exponential decay function, where the decay constant, denoted by Œ±, influences the rate at which the funct"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_30", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 30, "text": "nce between the centroids of the defective dies on two WBMs. This distance is then used in an exponential decay function, where the decay constant, denoted by Œ±, influences the rate at which the function de- clines. The formula used to calculate location similarity is as follows: locationsimilarity ¬àexp \u0000Œ±√ód PcentroidCQcentroid¬Ü¬ÜBwhere d PcentroidCQcentroid¬Ürepresent the Euclidean distances between the centroids of the defective dies in the two compared WBMs. The constant Œ± is crucial as it dictates how rapidly the similarity value di- minishes with increasing distance. Based on empirical observations, we have chosen an Œ± value of 0.1 to gauge location similarity across WBMs with both similar and dissimilar patterns, adjusting Œ± to refine our un- derstanding of how it affects these comparisons. 3.4. Size similarity The size of a defect pattern within a WBM can be defined by two critical factors: the number of defective dies it encompasses and its average radius. This allows us to differentiate between the sizes of the two defect patterns, even if they contain the same number of defective dies, because the radii of these patterns may vary. Therefore, the size of the pattern is deter"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_31", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 31, "text": "rentiate between the sizes of the two defect patterns, even if they contain the same number of defective dies, because the radii of these patterns may vary. Therefore, the size of the pattern is determined by both the number of defective dies and their average radii. Consequently, we define the size similarity as the product of the defect quantity and radius similarities as follows: sizesimilarity¬àdefect numbers similarity√óradius similarityB Defectnumberssimilarity is computed as follows: defectnumberssimilarity ¬àexp‚åä min\u0000‚É¶‚É¶Pdef‚É¶‚É¶C‚É¶‚É¶Qdef‚É¶‚É¶) max\u0000‚É¶‚É¶Pdef‚É¶‚É¶C‚É¶‚É¶Qdef‚É¶‚É¶)‚åã This calculation involves the ratio of the total number of defective dies in the defect pattern in Q to the defect pattern in P and applying the result within an exponential decay function to gauge the similarity in defect quantity. Radiussimilarity was assessed based on the ratio of the radii of the two patterns: radiussimilarity¬àmin\u0000 RpCRQ) max\u0000 RpCRQ)B where Rp and RQ represent the average distances from each defective die to Pcentroid and Qcentroid , respectively. To represent the radius of a pattern with sporadic width changes, Rp and RQ are computed as follows: RP¬à1‚É¶‚É¶Pdef‚É¶‚É¶ÃÇ i‚àÉPdefd PiCPcentroid¬ÜC RQ¬à1‚É¶‚É¶Qdef‚É¶‚É¶ÃÇ i‚àÉQd"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_32", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 32, "text": " to Pcentroid and Qcentroid , respectively. To represent the radius of a pattern with sporadic width changes, Rp and RQ are computed as follows: RP¬à1‚É¶‚É¶Pdef‚É¶‚É¶ÃÇ i‚àÉPdefd PiCPcentroid¬ÜC RQ¬à1‚É¶‚É¶Qdef‚É¶‚É¶ÃÇ i‚àÉQdefd QiCQcentroid¬ÜB 3.5. Overall similarity To calculate the overall similarity between P and Q, we used a weighted average of the shape, location, and size similarities as follows: Overallsimilarity¬àwshape√óshapesimilarity¬áwloc √ólocationsimilarity¬áwsize√ósizesimilarity B Here, the weights wshapeCwlocation and wsize account for the differing sig- Fig. 1.Overall Flowchart of Proposed Method.M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 5 nificance of each similarity aspect, with the sum of weights equal to 1 (‚ãÉw ¬à1), and each weight being a positive real number (w‚àÉZ¬á). This weighted average allows each type of similarity to contribute according to its importance, with the overall similarity score ranging from 0 to 1, making it easy to compare overall similarities when the reference WBM changes. Engineers can manually set the values of the weights according to their subjective judgment of the importance of the similarities. This is recommended when engineers have pr"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_33", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 33, "text": "the reference WBM changes. Engineers can manually set the values of the weights according to their subjective judgment of the importance of the similarities. This is recommended when engineers have prior knowledge of the defect pat- terns. If this is not the case, we recommend setting the weight based on information entropy theory (Gray, 2011; Pan & Deng, 2020 ) to improve the discrimination between similar patterns. This ultimately leads to a search for Qs that are more similar Qs to a given P. Information entropy is a measure of uncertainty or unpredictability in a dataset, and the weights can be determined based on this uncertainty. In general, in- formation entropy can be represented as H¬à\u0000ÃÇ xp x¬Ülogp x¬Ü In this formula, p x¬Ürepresents the probability of occurrence of x and H denotes the overall uncertainty. A lower value of H indicates higher certainty. In the proposed method, each similarity measure (shape, location, and size) can be interpreted as the likelihood of a given Qs matching P. Suppose there exist U Qs, and each Q is compared to P. Then, each Q has three similarities according to the formulations in Sections 3.2, 3.3, and 3.4. Let us denote the three similarities o"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_34", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 34, "text": "tching P. Suppose there exist U Qs, and each Q is compared to P. Then, each Q has three similarities according to the formulations in Sections 3.2, 3.3, and 3.4. Let us denote the three similarities of the uth Q as shapesimilarityu, locationsimilarityu, and sizesimilarityu for u¬à1C2C‚ãØC U. Then, the likelihood of each similarity for the uth Q is defined as p shapesimilarity u¬Ü¬àshapesimilarityu‚ãÉU ushapesimilarityuC p locationsimilarity u¬Ü¬àlocationsimilarityu‚ãÉU ulocationsimilarityuC p sizesimilarity u¬Ü¬àsizesimilarityu‚ãÉU usizesimilarityuB According to Gray (2011) , the certainty of each similarity can be quantified by calculating its respective entropy, H. Hshape¬à\u0000ÃÇU up shapesimilarity u¬Ü√ólogp shapesimilarity u¬ÜC Hlocation¬à\u0000ÃÇU up locationsimilarity u¬Ü√ólogp locationsimilarity u¬ÜC Hsize¬à\u0000ÃÇU up sizesimilarity u¬Ü√ólogp sizesimilarity u¬ÜB Entropy (H) quantifies the uncertainty associated with each simi- larity. High entropy means that the uncertainty is high; thus, the weight has a small value. For example, suppose that the shape entropy (Hshape) is high. According to the entropy equation, this indicates that the shape likelihood values (i.e., p shapesimilarity u¬Üfor u¬à1C2C‚ãØCU) are likely un"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_35", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 35, "text": "For example, suppose that the shape entropy (Hshape) is high. According to the entropy equation, this indicates that the shape likelihood values (i.e., p shapesimilarity u¬Üfor u¬à1C2C‚ãØCU) are likely uniform. These uniform values imply that the uncertainty is high, and they are not helpful for distinguishing Qs from P. For this reason, we assign a small value to the weight when the entropy is high. For the same reason, a large value is assigned to the weight when the entropy is low. Considering this inverse relationship between H and the weight, the inverse of H is used in the weight calculation. The softmax function was applied to these inverse H values to highlight the differences in certainty between the similarity measures, thereby making the weights more sensitive to changes. The weights were calculated as follows: wshape¬àexp\u0000 \u0000Hshape) exp\u0000 \u0000Hshape) ¬áexp \u0000Hlocation¬Ü¬áexp \u0000Hsize¬ÜCwlocation¬àexp \u0000Hlocation¬Ü exp\u0000 \u0000Hshape) ¬áexp \u0000Hlocation¬Ü¬áexp \u0000Hsize¬ÜC wsize¬àexp \u0000Hsize¬Ü exp\u0000 \u0000Hshape) ¬áexp \u0000Hlocation¬Ü¬áexp \u0000Hsize¬ÜB 4.Experiment This section presents several experiments conducted using the pro- posed method on the WM-811 K dataset. The WM-811 K dataset contains 811,457 WBMs from actual s"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_36", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 36, "text": " \u0000Hlocation¬Ü¬áexp \u0000Hsize¬ÜB 4.Experiment This section presents several experiments conducted using the pro- posed method on the WM-811 K dataset. The WM-811 K dataset contains 811,457 WBMs from actual semiconductor manufacturing processes (M. J. Wu et al., 2015 ). It categorizes WBMs into eight defect pattern types, as listed in Table 3. They are Center, Donut, Edge-local, Edge-Ring, Loc, Random, Scratch, and Near full of 632 different sizes. Among the entire WBM dataset, about 21.3 % are labeled, and the remaining 78.7 % are unlabeled. While previous supervised learning-based studies utilized only the labeled data (21.3 %) for accuracy comparison in classification and similarity measurement, this study conducted similarity measure - ment experiments using the entire WM-811 K dataset, as it employs rule- based unsupervised learning that does not require labeling. Section 4.1illustrates the process of computing the three similarities for P and Q selected from the WM-811 K dataset. Section 4.2reports the results of the similarity search for the eight defect pattern types. A similarity search was conducted without size normalization to avoid distortion of the spatial information of the "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_37", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 37, "text": " 4.2reports the results of the similarity search for the eight defect pattern types. A similarity search was conducted without size normalization to avoid distortion of the spatial information of the WBM. Section 4.3confirms the results of ablation studies to confirm the effectiveness of each sim- ilarity comparison algorithm and uncertainty estimation using entropy. Section 4.4compares the performance of the proposed method with that of an existing similarity-search method. 4.1. Illustration of computing shape, location, and size similarities We selected two WBMs from the WM-811 K dataset ‚Äìone for P and the other for Q, and computed the three similarities. The first step was a two- step noise-filtering process. The first column of Table 4displays P and Q, whose defect pattern types are center and scratch, respectively. The second column shows P and Q after c-mean filtering. The third column shows the saliency map of Œªs and Œªb after applying the tensor voting process. In the saliency map, a brighter color indicates a higher value. As mentioned in Section 3.1, c-mean filtering followed by tensor voting effectively removed most noise while preserving the scratch pattern. The last col"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_38", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 38, "text": "ap, a brighter color indicates a higher value. As mentioned in Section 3.1, c-mean filtering followed by tensor voting effectively removed most noise while preserving the scratch pattern. The last column lists the P and Q values after tensor voting. The edge threshold for c-mean, the sigma value, and saliency threshold for tensor voting were set to tc¬à1B25, œÉd¬à3, tt¬à0B3 respectively, following the same values described inWang & Wang (2023) and Yu et al. (2021) . After filtering, the shape, location, and size similarities were measured. Firstly, the average distance is calculated using the saliency values which were derived by the tensor voting as ‚ãÉ i‚àÉPdef‚ãÉ j‚àÉQdefd( ŒªPiC ŒªQj) ¬à11185, ‚É¶‚É¶Pdef‚É¶‚É¶¬à145, ‚É¶‚É¶Qdef‚É¶‚É¶¬à29. Using these values, the stick- ball similarity is derived as follows: stick\u0000ballsimilarity¬àexp‚é¢ ‚àÆ\u00001‚É¶‚É¶Pdef‚É¶‚É¶‚É¶‚É¶Qdef‚É¶‚É¶ÃÇ i‚àÉPdefÃÇ j‚àÉQdefd( ŒªPiCŒªQj)‚é• ‚®Ä¬à0B12 The density similarity was measured using the normalized mountain value at the WBM centroid. Fig. 2represents the peak values of P and Q and their centroids. The brighter color indicates a larger mountain value, and the green dot represents the centroids of P and Q. Below are the mountain values at the centroids and the maximum "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_39", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 39, "text": " and Q and their centroids. The brighter color indicates a larger mountain value, and the green dot represents the centroids of P and Q. Below are the mountain values at the centroids and the maximum values of P and Q. M Pcentroid¬Ü¬à3B93CM Qcentroid¬Ü¬à2B39 max i‚àÉ‚äî1C‚ãØCN‚äì M Pi¬Ü¬Ü¬à3B93Cmax i‚àÉ‚äî1C‚ãØCN‚äì M Qi¬Ü¬Ü¬à2B84 M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 6 Note that M Pcentroid¬Üand M Qcentroid¬Üare the values indicated by the green dots. Using the above values, the density similarity can be calculated as follows: densitySimilarity¬à1\u0000‚É¶‚É¶‚É¶‚É¶‚É¶‚É¶M Pcentroid¬Ü max i‚àÉ‚äî1C‚ãØCN‚äì M Pi¬Ü¬Ü\u0000M Qcentroid¬Ü max i‚àÉ‚äî1C‚ãØCN‚äì M Qi¬Ü¬Ü‚É¶‚É¶‚É¶‚É¶‚É¶‚É¶¬à0B84 The shape similarity can be calculated by multiplying the density similarity and stick-ball similarity as follows: ‚à¥Shapesimilarity¬àDensitysmilarity√óStickballsimilarity ¬à0B55√ó0B12 ¬à0B07 The location similarity is calculated as the Euclidean distance be- tween two centroids, which is the same as the distance between the two green dots above: d PcentroidCQcentroid¬Ü¬à21B84B As we set the Œ± as 0.1, the location similarity is calculated as: ‚à¥locationsimilarity ¬àexp \u0000Œ±√ód PcentroidCQcentroid¬Ü¬Ü¬à0B11B Size similarity was calculated as the product of the simila"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_40", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 40, "text": "centroid¬Ü¬à21B84B As we set the Œ± as 0.1, the location similarity is calculated as: ‚à¥locationsimilarity ¬àexp \u0000Œ±√ód PcentroidCQcentroid¬Ü¬Ü¬à0B11B Size similarity was calculated as the product of the similarity of the defect numbers and radii. Because we have already calculated the ‚É¶‚É¶Pdef‚É¶‚É¶C‚É¶‚É¶Qdef‚É¶‚É¶, the defect similarity can be derived as defectnumberssimilarity ¬àexp‚åä min\u0000‚É¶‚É¶Pdef‚É¶‚É¶C‚É¶‚É¶Qdef‚É¶‚É¶) max\u0000‚É¶‚É¶Pdef‚É¶‚É¶C‚É¶‚É¶Qdef‚É¶‚É¶)‚åã ¬à0B20B Radius similarity can be derived from the average radius of the centroid. The average radii of P and Q are as follows: RP¬à1‚É¶‚É¶Pdef‚É¶‚É¶ÃÇ i‚àÉPdefd PiCPcentroid¬Ü¬à4B57C RQ¬à1‚É¶‚É¶Qdef‚É¶‚É¶ÃÇ i‚àÉQdefd QiCQcentroid¬Ü¬à6B53C where ‚ãÉ i‚àÉPdefd PiCPcentroid¬Ü¬à662B77 and ‚ãÉ i‚àÉQdefd QiCQcentroid¬Ü¬à 189B30. Using above, radius similarity is calculated as: radiussimilarity¬àmin\u0000 RpCRQ) max\u0000 RpCRQ)¬à0B70 Size similarity was measured by aggregating the defect number similarity and radius similarity by product. ‚à¥Sizesimilarity¬àDefectnumberssimilarity √óRadiusSimilarity ¬à0B20√ó0B70¬à0B14 Briefly, the three similarities were computed as (Shapesimilarity , Table 3 Defect pattern types of WM-811 K. Table 4 A two-step noise filtering process of P and Q. Fig. 2.Mountain values of P and.. QM.-S. Kang et al. Computers"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_41", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 41, "text": "ties were computed as (Shapesimilarity , Table 3 Defect pattern types of WM-811 K. Table 4 A two-step noise filtering process of P and Q. Fig. 2.Mountain values of P and.. QM.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 7 Locationsimilarity , Sizesimilarity ) ¬à(0.07, 0.11, and 0.14). This score was rather low and was expected before computing the similarities, because P and Q were quite different, as shown in Table 4. This result implies that the proposed method performs well. 4.2. Similarity search using WM-811 K By substituting Q with every WBM in the WM-811 K dataset and repeating the process described in Section 4.1, the three similarities of each WBM in the WM-811 K were computed. These similarity values were then used to calculate the weights wshape, wlocation , wsize , which in turn were used to compute the overall similarity and perform the ranking. Fig. 3shows the results of similarity matching. For each defect pattern type listed in Table 3, we selected a single WBM and regarded it as P. The selected P for each defect pattern type is shown in the first row, Fig. 3.Similarity ranking result of single pattern.M.-S. Kang et al. Computers & Industrial "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_42", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 42, "text": "d a single WBM and regarded it as P. The selected P for each defect pattern type is shown in the first row, Fig. 3.Similarity ranking result of single pattern.M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 8 whereas the Qs for each defect pattern type are shown in the second to sixth rows. We show only the top five Qs in order of overall similarity. Overall, the five Qs are similar to P for all eight defect pattern types, implying that the proposed method works well. In addition to the three similarities, the weights of the three simi- larities and the overall similarity for each Q were calculated and pre- sented. The three weights for each defect pattern type are shown in the first row of Fig. 3. These were obtained based on the information en- tropy theory described in Section 3.4. It is noteworthy that the three weights are determined relatively evenly, which implies that the simi- larity search considers these three aspects in a balanced manner. Nevertheless, it is noteworthy that wlocation was the largest among the three weights. This means that the location aspect plays an important role in distinguishing similar patterns to search for Qs that are more"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_43", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 43, "text": ", it is noteworthy that wlocation was the largest among the three weights. This means that the location aspect plays an important role in distinguishing similar patterns to search for Qs that are more similar to a given P. Let us compare two groups: one with small wlocation values and the other with large wlocation values. The center, Random, and Near-full types (first, sixth, and last columns in Fig. 3) had smaller wlocation values, whereas the Edge-local, Edge-Ring, and Scratch types (third, fourth, and seventh columns in Fig. 3) had larger wlocation values. The three defect pattern types of the first group tended to be located at similar positions on the WBM, implying that the location aspect did not play an important role in discriminating between similar patterns. By contrast, the other three defect pattern types can be located at various positions on the WBM; thus, the location aspect plays a critical role in searching for Qs that are more similar Qs to a given P. Table 5presents the results of the computational time taken by the proposed model to compare a single reference WBM with a candidate WBM in this study. The experimental setup was conducted on a server equipped with "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_44", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 44, "text": " the results of the computational time taken by the proposed model to compare a single reference WBM with a candidate WBM in this study. The experimental setup was conducted on a server equipped with an AMD EPYC 3rd generation (16Core/32Thread) Model 7313 at 3.00 GHz, 128 MB, 155 W, under a Linux OS, with Sci-kit Learn and NumPy libraries. The results showed that it took approximately 0.3 s to compare a reference WBM with a candidate WBM. Of this time, the image preprocessing phase occupied about 0.26 s, making up the ma- jority of the time consumed. It was observed that the process of calcu - lating and comparing the similarities in shape, size, and position had a relatively lower computational complexity. Moreover, it was noted that the comparison of size and location similarities required a significantly lower computational time (about 0.0008 s in total), indicating that there is no substantial difference in computation time and complexity when comparing similarities based solely on shape. 4.3. Ablation studies Fig. 4presents the results of visualizing the top 5 WBMs with the highest similarity scores to the reference WBM after measuring simi- larity scores using only a single i"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_45", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 45, "text": " shape. 4.3. Ablation studies Fig. 4presents the results of visualizing the top 5 WBMs with the highest similarity scores to the reference WBM after measuring simi- larity scores using only a single individual similarity to investigate effect of each individual similarity. Fig. 4show the results of similarity com- parison based solely on the shape of defects (a), the location of defects (b), the size of defects (c), and the results of a similarity search method that considers shape, size, and location applying equal weight to the three individual scores (d). In Fig. 4(a), when the reference pattern is Edge Loc, scratch defect patterns with similar curved shapes exhibit high shape similarity scores. This is an expected result since the two patterns share similar shapes. However, it can be observed that the defect loca- tions are not fixed. In Fig. 4(b), scratch defects located at the bottom-left of the reference WBM are often confused with other defect patterns in the same location. This occurs because, when considering only the defect location, different shaped defects occurring at the same location can also have high similarity scores. Similarly, in Fig. 4(c), when only size simil"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_46", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 46, "text": "s occurs because, when considering only the defect location, different shaped defects occurring at the same location can also have high similarity scores. Similarly, in Fig. 4(c), when only size similarity is considered, defect patterns such as Edge-Loc and scratch defects with similar sizes are detected. Finally, in Fig. 4(d), the top five images of the center defect class, which is the same defect class as the reference WBM, are presented. However, it can be observed that the third and fifth candidate WBM images differ from the reference WBM image. On the other hand, when the proposed weighting scheme based on information entropy theory is applied, as shown in Fig. 3, defect types that are often confused, such as Edge-Loc and scratch de- fects, are correctly identified. Additionally, even in the case of center defects that were not appropriately retrieved in Fig. 4(d), it can be confirmed that the proposed method correctly identified similar types of defects up to the fourth image. These results demonstrate the necessity of each module proposed in this study and the importance of a comprehensive approach to similarity measurement and retrieval. Consequently, through Fig. 4, it is"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_47", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 47, "text": "hese results demonstrate the necessity of each module proposed in this study and the importance of a comprehensive approach to similarity measurement and retrieval. Consequently, through Fig. 4, it is confirmed that the shape, location, and size similarity algorithms in the proposed methodology faithfully find candidate WBMs according to the purpose of each similarity mea- surement. This indicates that our methodology operates appropriately. However, considering each similarity comparison method indepen - dently or assigning equal weights to each similarity score to measure a composite score can retrieve similar WBMs that differ from the reference WBM. To prevent this, it is important to apply the uncertainty estima - tion and weight assignment method based on the information entropy theory proposed in the study, using the weighted average of each sim- ilarity score. 4.4. Comparison to existing methods This section compares our method with the conventional similarity search method proposed in Wang & Wang (2022) , which conducts an experiment using a public dataset, MixedWM38K. Fig. 5(a) and (b) respectively show the comparison of similarity search results for Loc and Scratch defect"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_48", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 48, "text": "osed in Wang & Wang (2022) , which conducts an experiment using a public dataset, MixedWM38K. Fig. 5(a) and (b) respectively show the comparison of similarity search results for Loc and Scratch defect patterns between the proposed method and the existing method. In these figures, the top (bottom) shows the results obtained by the existing (proposed) method, and the two most left WBM images are the reference WBM (P), while the rest are the WBMs (Qs) found to have high similarity by the proposed and existing methods. Looking at the results in detail, in the case of the traditional similarity search method, when recommending the top 10 WBM images based on similarity scores, although images from the same defect pattern class as P were presented, they mainly depended on shape. In particular, as can be seen in Fig. 5(a), despite the Loc defect pattern located at the top left of the wafer, the existing study selected a WBM at the top right with different location and size as the most similar image. Moreover, as shown in Fig. 5(a), the fourth and eighth Qs from the left have smaller defect patterns than P, showing significant differences in shape, size, and location with the reference WBM "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_49", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 49, "text": "image. Moreover, as shown in Fig. 5(a), the fourth and eighth Qs from the left have smaller defect patterns than P, showing significant differences in shape, size, and location with the reference WBM in about 6‚Äì8 out of the 10 recommended images. Similarly, the results for the Scratch defect type in Fig. 5(b) also show that all 10 images belong to the same defect class, but there are slight differences in the location and size where the defects occurred. On the other hand, all Qs found using the proposed method show high similarity with the reference WBM in all aspects, such as shape, form, and size. This is because the proposed method independently evaluates similarity regarding shape, location, and size, providing a more precise similarity ranking. Especially, thanks to its ability to Table 5 Computational complexity of proposed method. \u0000 Data Preprocessing Process Similarity & Uncertainty Measurement Process Total time C-Mean Filtering Tensor Voting Shape Similarity Location Similarity Size Similarity Uncertainty Estimation Calculate Time (ms / WBM) 65.5096 191.1688 40.5684 0.725 0.0615 17.8129 315.8462 Total Time 256.6784 59.1678M.-S. Kang et al. Computers & Industrial Engineer"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_50", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 50, "text": "ity Size Similarity Uncertainty Estimation Calculate Time (ms / WBM) 65.5096 191.1688 40.5684 0.725 0.0615 17.8129 315.8462 Total Time 256.6784 59.1678M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 9 precisely identify spatial features, it excels at determining the exact location and size of each pattern. Through this analysis, this study demonstrates that focusing not only on a single element of defect pat- terns but on more detailed and specific defect similarity search can contribute to early detection and cause identification of defects. Fig. 4.Similarity search results using each method. Fig. 5.Comparison of the proposed and existing search methods.M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 10 5.Concluding remarks In this study, we propose a similarity ranking method for WBMs that considers the combined aspects of defect pattern shape, location, and size, which have been overlooked in existing similarity search research. To measure shape similarity, we employ tensor voting and a mountain function, while Euclidean distance of the center of mass between two WBMs is used for location similarity. Additionally, we incorporate the "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_51", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 51, "text": "re shape similarity, we employ tensor voting and a mountain function, while Euclidean distance of the center of mass between two WBMs is used for location similarity. Additionally, we incorporate the average radius of defect clusters and the variance in defect counts for size similarity. The overall similarity is calculated using a weighted average, with each weight determined based on the uncertainty of each similarity score using information entropy. By employing these methods, our proposed approach can independently evaluate shape, location, and size characteristics, automatically identify dominant fea- tures, and derive integrated overall similarity scores. The proposed method does not require predefined labels for defects or a training process, enabling swift and accurate comparison of defects even for previously unknown patterns. Moreover, it effectively detects spatial features, allowing for a more nuanced comparison within the same defect pattern class. These achievements are particularly effective for defects like Edge-Loc and Scratch, where location and size infor- mation are crucial. However, the proposed method faces challenges when dealing with mixed-pattern defects, w"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_52", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 52, "text": "articularly effective for defects like Edge-Loc and Scratch, where location and size infor- mation are crucial. However, the proposed method faces challenges when dealing with mixed-pattern defects, where various shapes and sizes of defects coexist on a single wafer, making comparison difficult due to their combined shapes, locations, and sizes. Additionally, the adoption of two unique preprocessing methods to compare defect shapes, locations, and sizes may increase computational complexity. Therefore, future research should focus on developing efficient pre- processing methods, especially for handling diverse types of mixed de- fects. Furthermore, exploring multimodal learning approaches that integrate defect image and equipment information could enhance con- venience for engineers. CRediT authorship contribution statement Min-Su Kang: Writing ‚Äì original draft, Software, Methodology, Formal analysis. Jin-Su Shin: Writing ‚Äì review & editing, Supervision, Investigation. Dong-Hee Lee: Writing ‚Äì review & editing, Funding acquisition, Conceptualization. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_53", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 53, "text": "iting ‚Äì review & editing, Funding acquisition, Conceptualization. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. Acknowledgement This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. NRF- 2022R1C1C1011743). References Bae, Y., & Kang, S. (2023). Supervised contrastive learning for wafer map pattern classification. Engineering Applications of Artificial Intelligence, 126. https://doi.org/ 10.1016/j.engappai.2023.107154 Basim, G. B., & Moudgil, B. M. (2002). Effect of Soft Agglomerates on CMP Slurry Performance. Journal of Colloid and Interface Science, 256(1), 137‚Äì142. https://doi. org/10.1006/JCIS.2002.8352Chen, F.-L., & Liu, S.-F. (2000). A Neural-Network Approach To Recognize Defect Spatial Pattern In Semiconductor Fabrication. In IEEE Transactions On Semiconductor Manufacturing (Vol. 13, Issue 3). Chen, S., Zhang, Y., Hou, X., Shang, Y., & Yang, P. (2022). Wafer map failure pattern recognition base"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_54", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 54, "text": "emiconductor Fabrication. In IEEE Transactions On Semiconductor Manufacturing (Vol. 13, Issue 3). Chen, S., Zhang, Y., Hou, X., Shang, Y., & Yang, P. (2022). Wafer map failure pattern recognition based on deep convolutional neural network. Expert Systems with Applications, 209. https://doi.org/10.1016/j.eswa.2022.118254 Gray, R. M. (2011). Entropy and Information Theory. Springer Science & Business Media . Hsu, C. Y., Chen, W. J., & Chien, J. C. (2020). Similarity matching of wafer bin maps for manufacturing intelligence to empower Industry 3.5 for semiconductor manufacturing. Computers and Industrial Engineering, 142. https://doi.org/10.1016/j. cie.2020.106358 Hsu, S. C., & Chien, C. F. (2007). Hybrid data mining approach for pattern extraction from wafer bin map to improve yield in semiconductor manufacturing. International Journal of Production Economics, 107(1), 88‚Äì103. https://doi.org/10.1016/j. ijpe.2006.05.015 Hwang, J., & Kim, H. (2020). Variational Deep Clustering of Wafer Map Patterns. IEEE Transactions on Semiconductor Manufacturing, 33(3), 466‚Äì475. https://doi.org/ 10.1109/TSM.2020.3004483 Kim, E. S., Choi, S. H., Lee, D. H., Kim, K. J., Bae, Y. M., & Oh, Y. C. (2021). "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_55", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 55, "text": " Patterns. IEEE Transactions on Semiconductor Manufacturing, 33(3), 466‚Äì475. https://doi.org/ 10.1109/TSM.2020.3004483 Kim, E. S., Choi, S. H., Lee, D. H., Kim, K. J., Bae, Y. M., & Oh, Y. C. (2021). An oversampling method for wafer map defect pattern classification considering small and imbalanced data. Computers and Industrial Engineering, 162. https://doi.org/ 10.1016/j.cie.2021.107767 Kim, T., & Behdinan, K. (2023). Advances in machine learning and deep learning applications towards wafer map defect recognition and classification: a review. Journal of Intelligent Manufacturing, 34(8), 3215‚Äì3247. https://doi.org/10.1007/ s10845-022-01994-1. Springer. Kong, Y., & Ni, D. (2022). A one-shot learning approach for similarity retrieval of wafer bin maps with unknown failure pattern. IEEE Transactions on Semiconductor Manufacturing, 35(1), 40‚Äì49. https://doi.org/10.1109/TSM.2021.3123290 Lee, H., Lee, J., & Kim, H. (2023). Semi-supervised learning for simultaneous location detection and classification of mixed-type defect patterns in wafer bin maps. IEEE Transactions on Semiconductor Manufacturing, 36(2), 220‚Äì230. https://doi.org/ 10.1109/TSM.2023.3264279 Lee, J. H., Moon, I. C., & Oh, "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_56", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 56, "text": "ssification of mixed-type defect patterns in wafer bin maps. IEEE Transactions on Semiconductor Manufacturing, 36(2), 220‚Äì230. https://doi.org/ 10.1109/TSM.2023.3264279 Lee, J. H., Moon, I. C., & Oh, R. (2021). Similarity search on wafer bin map through nonparametric and hierarchical clustering. IEEE Transactions on Semiconductor Manufacturing. https://doi.org/10.1109/TSM.2021.3102679 Liao, C. S., Hsieh, T. J., Huang, Y. S., & Chien, C. F. (2014). Similarity searching for defective wafer bin maps in semiconductor manufacturing. IEEE Transactions on Automation Science and Engineering, 11(3), 953‚Äì960. https://doi.org/10.1109/ TASE.2013.2277603 Nag, S., Makwana, D., Mittal, S., & Mohan, C. K. (2022). WaferSegClassNet - A light- weight network for classification and segmentation of semiconductor wafer defects. Computers in Industry, 142. https://doi.org/10.1016/j.compind.2022.103720 Nakazawa, T., & Kulkarni, D. V. (2018). Wafer map defect pattern classification and image retrieval using convolutional neural network. IEEE Transactions on Semiconductor Manufacturing, 31(2), 309‚Äì314. https://doi.org/10.1109/ TSM.2018.2795466 Pan, L., & Deng, Y. (2020). Probability transform based on the o"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_57", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 57, "text": "nvolutional neural network. IEEE Transactions on Semiconductor Manufacturing, 31(2), 309‚Äì314. https://doi.org/10.1109/ TSM.2018.2795466 Pan, L., & Deng, Y. (2020). Probability transform based on the ordered weighted averaging and entropy difference. International Journal of Computers, Communications and Control, 15(4). https://doi.org/10.15837/IJCCC.2020.4.3743 Park, S., Jang, J., & Kim, C. O. (2021). Discriminative feature learning and cluster-based defect label reconstruction for reducing uncertainty in wafer bin map labels. Journal of Intelligent Manufacturing, 32(1), 251‚Äì263. https://doi.org/10.1007/s10845-020- 01571-4 Shinde, P. P., Pai, P. P., & Adiga, S. P. (2022). Wafer defect localization and classification using deep learning techniques. IEEE Access, 10, 39969‚Äì39974. https://doi.org/ 10.1109/ACCESS.2022.3166512 Medioni, G., Tang, C.-K., & Lee, M.-S. (2000). Tensor Voting: Theory and Applications. In Proceedings of RFIA, 2000. Wang, R., & Wang, S. (2022). Tensor Voting Based Similarity Matching of Wafer Bin Maps in Semiconductor Manufacturing. 2022 5th International Conference on Data Science and Information Technology, DSIT 2022 - Proceedings. https://doi.org/ 10.1109/DSI"}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_58", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 58, "text": "imilarity Matching of Wafer Bin Maps in Semiconductor Manufacturing. 2022 5th International Conference on Data Science and Information Technology, DSIT 2022 - Proceedings. https://doi.org/ 10.1109/DSIT55514.2022.9943882. Wang, R., & Wang, S. (2023). Similarity searching for fault diagnosis of defect patterns in wafer bin maps. Computers & Industrial Engineering, 185, Article 109679. https://doi. org/10.1016/J.CIE.2023.109679 Wu, M. J., Jang, J. S. R., & Chen, J. L. (2015). Wafer map failure pattern recognition and similarity ranking for large-scale data sets. IEEE Transactions on Semiconductor Manufacturing, 28(1), 1‚Äì12. https://doi.org/10.1109/TSM.2014.2364237 Xu, Q., Yu, N., & Essaf, F. (2022). Improved wafer map inspection using attention mechanism and cosine normalization. Machines, 10(2). https://doi.org/10.3390/ machines10020146 Yu, J., Shen, Z., & Wang, S. (2021). Wafer map defect recognition based on deep transfer learning-based densely connected convolutional network and deep forest. Engineering Applications of Artificial Intelligence, 105. https://doi.org/10.1016/j. engappai.2021.104387 Yu, N., Gong, X. Q., Wang, H. L., & Lin, J. (2021). Wafer bin map inspection based on "}
{"id": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf::chunk_59", "source": "Similarity searching for wafer bin maps by measuring shape, location, and size similarities of defect patterns.pdf", "chunk_index": 59, "text": "forest. Engineering Applications of Artificial Intelligence, 105. https://doi.org/10.1016/j. engappai.2021.104387 Yu, N., Gong, X. Q., Wang, H. L., & Lin, J. (2021). Wafer bin map inspection based on DenseNet. Journal of Central South University, 28(8), 2436‚Äì2450. https://doi.org/ 10.1007/s11771-021-4778-7 Yu, N., Xu, Q., & Wang, H. (2019). Wafer defect pattern recognition and analysis based on convolutional neural network. IEEE Transactions on Semiconductor Manufacturing, 32(4), 566‚Äì573. https://doi.org/10.1109/TSM.2019.2937793M.-S. Kang et al. Computers & Industrial Engineering 196 (2024) 110486 11"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_0", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 0, "text": "842 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 SoC Speed Binning Using Machine Learning and On-Chip Slack Sensors Mehdi Sadi, Student Member, IEEE , Sukeshwar Kannan, LeRoy Winemberg, and Mark Tehranipoor, Senior Member, IEEE Abstract ‚ÄîSpeed binning of system-on-chips (SoCs) using conventional Fmax test requires application of complex func- tional test patterns. Functional workload-based speed binningtechniques incur high test-cost in terms of long test-time andcomplexity in functional test generation, and require high-endautomatic test equipment. In this paper, we propose a novelspeed binning Ô¨Çow that uses path timing slacks, extracted withrobust digital embedded sensor IPs, of selected critical/near-critical paths. We apply machine learning techniques to model apredictor considering the extracted slacks and the F max values from a set of randomly tested die during wafer sort. The trainedpredictor is used to obtain the F max for the remaining chips. The proposed Ô¨Çow has been demonstrated in an SoC benchmarkcircuit at 28 nm technology. For sufÔ¨Åcient number of trainingsamples, F max is correctly predicted for 99% of the pr"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_1", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 1, "text": " for the remaining chips. The proposed Ô¨Çow has been demonstrated in an SoC benchmarkcircuit at 28 nm technology. For sufÔ¨Åcient number of trainingsamples, F max is correctly predicted for 99% of the prediction samples. Index Terms ‚ÄîFmaxtest, machine learning, slack sensor, speed- binning. I. I NTRODUCTION WITH aggressive technology scaling the transistor density per unit chip area has increased signiÔ¨Åcantly over the past decade. This paved the way for many-core pro-cessors and highly integrated system-on-chips (SoCs). Theincreased variability in transistor parameters and workload-dependent Ô¨Çuctuations in operating conditions have madeharnessing the full beneÔ¨Åts of scaling a challenging task [ 1]. Variations can be broadly categorized into the following classes. 1) One-time static process variations due to manufactur- ing imperfections that cause transistor and interconnectparameters to drift from their designed values. 2) Run-time dynamic variations‚Äîpower supply noise and temperature Ô¨Çuctuations‚Äîresulting shifts in operatingconditions. Manuscript received February 18, 2016; revised May 24, 2016; accepted August 13, 2016. Date of publication August 25, 2016; date of current versionAp"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_2", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 2, "text": "ctuations‚Äîresulting shifts in operatingconditions. Manuscript received February 18, 2016; revised May 24, 2016; accepted August 13, 2016. Date of publication August 25, 2016; date of current versionApril 19, 2017. This work was supported in part by the National Science Foundation under Grant CCF-1565404, and in part by the Semiconductor Research Corporation under Award 2646. A preliminary version of this paperappeared in Proc. of ACM Great Lakes Symposium on VLSI (GLSVLSI)2015 [ 20]. This paper was recommended by Associate Editor S. Reda. M. Sadi and M. Tehranipoor are with the Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL 32611 USA(e-mail: mehdi.sadi@uÔ¨Ç.edu ;tehranipoor@ece.uÔ¨Ç.edu ). S. Kannan is with GLOBALFOUNDRIES, Malta, NY 12020 USA (e-mail: sukeshwar.kannan@globalfoundries.com ). L. Winemberg is with NXP Semiconductors, Austin, TX 78735 USA (e-mail: leroy.winemberg@nxp.com ). Color versions of one or more of the Ô¨Ågures in this paper are available online at http://ieeexplore .ieee.org. Digital Object IdentiÔ¨Åer 10.1109/TCAD.2016.2602806In terms of spatial locations, the variation can be segmented into die-to-die and within-die compon"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_3", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 3, "text": "e available online at http://ieeexplore .ieee.org. Digital Object IdentiÔ¨Åer 10.1109/TCAD.2016.2602806In terms of spatial locations, the variation can be segmented into die-to-die and within-die components. Variations impact transistor length, width, threshold voltage, oxide thickness,etc., all of which directly contribute to path delay variations.As a result, a certain path may show signiÔ¨Åcant discrepancyin the delay between pre- and post-fabrication stages [ 2], [3] and the actual speed limiting paths might be masked in thesimulation phase [ 4], [5]. As a result of path delay variations, the maximum operating frequency of a chip (e.g., microprocessors, DSPs, micro-controllers, and application speciÔ¨Åed integrated circuits) or theF maxvaries from chip-to-chip and wafer-to-wafer. In order to sustain an acceptable yield rate without compromising perfor-mance, at the production test phase chips are binned accordingto the maximum functional or operating frequency. Chips in the higher bin are faster and sold at a higher proÔ¨Åt. To accurately identify the F maxit is necessary to execute func- tional workloads or benchmarks and excite all the possiblecritical paths at increasingly higher cl"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_4", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 4, "text": "e faster and sold at a higher proÔ¨Åt. To accurately identify the F maxit is necessary to execute func- tional workloads or benchmarks and excite all the possiblecritical paths at increasingly higher clock frequencies untilany of the capture Ô¨Çip-Ô¨Çops fail [ 6]. Execution of functional workload consumes a signiÔ¨Åcant portion of tester time andmemory. Moreover, this Ô¨Çow is required to be repeated at mul- tiple frequencies to identify the actual F max. Additionally, an expensive automated test equipment (ATE) is required that iscapable of running the test workloads at the comparativelyhigher F maxfrequency range. In [ 7], experimental data on test time for server processors were presented to corroborate thefact that a major portion of total test time is associated withspeed binning. Although functional F maxtesting is the most appropriate method to identify the chip operating frequency orFmax, the high cost and memory requirement of the ATE and the long test time associated with workload executionat multiple frequencies have motivated researchers to investi-gate alternative low-cost and faster techniques to identify chipF max[8]‚Äì[11], [14]‚Äì[20]. A. Related Work Structural test patterns‚Äîg"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_5", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 5, "text": "cutionat multiple frequencies have motivated researchers to investi-gate alternative low-cost and faster techniques to identify chipF max[8]‚Äì[11], [14]‚Äì[20]. A. Related Work Structural test patterns‚Äîgenerally transition delay fault (TDF) and path delay fault (PDF) patterns‚Äîarewidely used to test the integrity of circuit paths againstdefects. Since structural patterns are less expensive to gen-erate and offer much higher fault coverage, there have been signiÔ¨Åcant amount of research to utilize structural test results in estimating actual chip F max[8]‚Äì[10]. Cory et al. [8] studied the correlation between the structural and functional Fmax using sample chips, where a linear relation was established. 0278-0070 c/circlecopyrt2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. Seehttp://www.ieee.org/publications_standards/publications/rights/index.html for more information. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 843 Brand et al. [9] demonstrated that structural"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_6", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 6, "text": "ptember 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 843 Brand et al. [9] demonstrated that structural Fmaxbased on complex PDF patterns exhibited correlation to the actualfunctional F max.I n[ 10] and [ 11], data learning techniques were used to build an Fmax predictor from structural test results. However, in order to apply structural delay fault testpatterns, the path under test must be testable. To make all thepaths testable by structural test patterns, extra test points may be required to be inserted which incur area overhead [ 12]. Also structural test‚Äôs correlation (i.e., direct linear correlation)to the functional-test F maxcannot be guaranteed for advanced technology nodes because of process variations [ 11], [19]. Researchers proposed the concept of built-in speed- grading [ 14] and built-in delay-binning [ 15] where the built-in self-test (BIST) hardware and on-chip programmable clock generator were used to apply BIST patterns at different fre- quencies by the chip itself, thus eliminating the need forexpensive ATE and also reducing the test time. However,because of the pseu"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_7", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 7, "text": " clock generator were used to apply BIST patterns at different fre- quencies by the chip itself, thus eliminating the need forexpensive ATE and also reducing the test time. However,because of the pseudo-random nature of BIST patterns, thesepatterns may not excite the critical/near-critical paths [ 13]. As a result, the accuracy of this method in correlating to the chipF maxcannot be proven [ 19]. In [16] and [ 17], on-chip circuits were used to measure the propagation delay of critical paths and then the longestmeasured delay dictated the chip F max. Although direct mea- surement of critical path delays would eliminate the costlyprocedure of repeated application of the functional test at dif-ferent frequencies, the large number of possible critical pathsin modern SoC make it almost impossible to include that many path delay monitoring circuitry. Also, the preselected critical paths may not remain critical in each fabricated chip due tothe increasing levels of process variations [ 3]. In [18] and [ 19],F maxobtained from functional test and data collected from on-chip ring oscillator (RO)-based processmonitors were utilized in training machine learning predic-tors. Next, for rest of"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_8", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 8, "text": "n [18] and [ 19],F maxobtained from functional test and data collected from on-chip ring oscillator (RO)-based processmonitors were utilized in training machine learning predic-tors. Next, for rest of the samples, the RO data were fed to the trained predictors to obtain the F max. The reported speed- binning accuracy ranged from 90% to 93% in [ 18] and 87% to 93% in [ 19] based on silicon data collected from chips fabricated in 55 and 28 nm technology, respectively. For chip timing data extraction, in [ 21], a systematic method to synthesize multiple design dependent RO (DDRO) circuitsusing standard cell gates is presented. Because of the design dependent aspect of the proposed RO, and the use of critical path cluster information in the design, the DDRO offers signif-icant accuracy improvement over conventional inverter-basedRO in delay estimation [ 21]. Since DDRO is a replica type monitor, it offers lower area overhead and design cost com-pared to the in-situ monitors. However, as discussed in [ 21], replica monitors such as DDRO can only capture global varia- tions; whereas in-situ monitors are better suited for capturing local variations in addition to the global variations as "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_9", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 9, "text": "scussed in [ 21], replica monitors such as DDRO can only capture global varia- tions; whereas in-situ monitors are better suited for capturing local variations in addition to the global variations as theyoperate on actual circuit paths. Since our research goal requiresthe capture of timing slacks directly from a set of selectedcritical paths, instead of replica monitors we designed in-situ monitors that can record the slack values. In [ 22], an in-situ technique called SlackProbe was proposed that probes the intermediate nodes of critical paths to detect any impending timing failure within a monitoring window. SlackProbe wasdesigned to detect possible timing failures‚Äîwithout recordingthe actual slack value‚Äîon the critical paths for the purpose of activating remedial countermeasures, whereas the goal ofour designed slack sensor is to measure and record the timingslack of critical/near-critical paths for F maxestimation. B. Our Contributions and Novelties One of the primary objectives of this paper is to reduce the test time and cost associated with speed binning. With the aim of test cost and time reduction, we evaluate the appli-cation of machine learning-based predictive methodolo"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_10", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 10, "text": " this paper is to reduce the test time and cost associated with speed binning. With the aim of test cost and time reduction, we evaluate the appli-cation of machine learning-based predictive methodology inspeed binning using extracted path slack. In our proposedÔ¨Çow, instead of testing testable paths with patterns whichalso require clock sweeping, we take a completely differentapproach‚Äîwe measure the timing slack of selected number of possibly critical/near-critical paths with embedded sensors to estimate what F maxis. Contrary to [ 18] and [ 19], where stan- dalone ROs are placed randomly at multiple locations insidethe chip, our approach methodically places timing slack sen-sors on actual circuit paths spread across the chip layout thatare potentially critical or near-critical paths. In addition tocapturing slacks from actual critical/near-critical paths‚Äîwhich strongly inÔ¨Çuence the F max, the multiple number of embedded slack sensors also act as process monitors. In the experimen-tal work of [ 9] that analyzed data from large number of test chips, it was reported that the use of process monitor sen-sors, such as ROs, substantially improved the F maxprediction accuracy. The use of "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_11", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 11, "text": "work of [ 9] that analyzed data from large number of test chips, it was reported that the use of process monitor sen-sors, such as ROs, substantially improved the F maxprediction accuracy. The use of sensors may slightly increase the designeffort, but signiÔ¨Åcantly reduces the F maxtest cost and time as explained in the later sections. The design effort is not sig- niÔ¨Åcant as we insert our slack sensors on selected numberof critical/near-critical paths inside the gate-level netlist andthen use the conventional physical design Ô¨Çow. The selectedpaths are not necessarily the exact critical paths, making theÔ¨Çow more realistic to modern SoC designs at lower technol-ogy nodes. The use of sensors also allow measuring F maxin the Ô¨Åeld during functional mode and in-Ô¨Åeld BIST mode in addition to the manufacturing test mode. In summary, our contributions and novelties in this paper are as follows. 1) A novel Fmax prediction framework is presented to eliminate the long test time and cost associated withfunctional F maxtesting. For the development of accurate machine learning predictors, the timing slacks extracted from actual critical/near-critical paths‚Äîinstead of datafrom path replica or RO m"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_12", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 12, "text": " withfunctional F maxtesting. For the development of accurate machine learning predictors, the timing slacks extracted from actual critical/near-critical paths‚Äîinstead of datafrom path replica or RO monitors‚Äîare used as fea-tures. To identify the most accurate predictor for thisframework, we tested Ô¨Åve different machine learningtechniques. 2) For the purpose of in-situ timing slack data extraction, a novel timing slack sensor IP has been designed that can monitor and record the timing slack of critical/near-critical capture Ô¨Çip-Ô¨Çops. 3) In order to ensure that the features of the machine learn- ing tools‚Äîthe path slacks‚Äîcapture spatial variation andworkload proÔ¨Åle, a novel layout and gate-overlap awarealgorithm has been proposed for the selection of the optimum set of critical/near-critical Ô¨Çip-Ô¨Çops. The algo- rithm ensures that the selected capture Ô¨Çip-Ô¨Çops (and thecorresponding sensors) are physically spread across the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 844 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 layout. Moreo"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_13", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 13, "text": "ded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 844 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 layout. Moreover, to minimize the extra design efforts, a netlist-level automated sensor insertion technique hasbeen developed to insert the sensor IPs in the synthesizedgate-level netlist of the SoC. The rest of this paper is organized as follows. Section II describes our proposed F max framework. The architecture of slack extraction sensor IP is presented in Section III. Sensor insertion algorithm is provided in Section IV . Different machine learning classiÔ¨Åcation techniques are discussed inSection V . Simulation results and analysis are presented inSection VI, followed by the conclusions in Section VII. II. P ROPOSED SPEED BINNING FLOW The chip Fmaxis limited by the path delay of the most critical path. Because of process variations, the exact critical path cannot be identiÔ¨Åed at the prefabrication stage [ 5]. As a result any of the critical or near-critical paths‚ÄîidentiÔ¨Åed fromthe static timing analysis (STA) or statistical STA‚Äîcan be thespeed-limiting most critical path for a certain chip dep"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_14", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 14, "text": " stage [ 5]. As a result any of the critical or near-critical paths‚ÄîidentiÔ¨Åed fromthe static timing analysis (STA) or statistical STA‚Äîcan be thespeed-limiting most critical path for a certain chip dependingon the chip-to-chip process variations. Without loss of gener-ality, path slack, and F maxdistributions are correlated [ 8], [9]. As a result, if the impact of process variations on path slack distribution is known, using the slack‚Äôs correlation with Fmax, one would be able to predict the distribution of Fmaxwith pro- cess variations at the production test stage. In order for thisapproach to be practical, we would require a simpler methodto extract path slack in-situ from fabricated chips. Toward this goal, we have designed an all digital sensor IP which is con-nected to a capture Ô¨Çip-Ô¨Çop, and records the worst-case slack of all the paths that terminate at that capture Ô¨Çip-Ô¨Çop. The use of slack sensors eliminates the frequency sweep step associ-ated with speed binning. Structural test patterns are used toexcite those critical/near-critical paths monitored by the slacksensors attached to the respective path-ending capture Ô¨Çip-Ô¨Çops. Using modern ATPG tools (e.g., Synopsys Tetramax)"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_15", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 15, "text": "t patterns are used toexcite those critical/near-critical paths monitored by the slacksensors attached to the respective path-ending capture Ô¨Çip-Ô¨Çops. Using modern ATPG tools (e.g., Synopsys Tetramax)those speciÔ¨Åc paths or capture Ô¨Çip-Ô¨Çops can be easily excited by PDF or TDF patterns, without the requirement of exe- cuting exhaustive functional patterns. Application of thesetest patterns and corresponding response extraction can beaccomplished by the ATE tool through the chip‚Äôs JTAG ports. Before proceeding with the proposed speed binning Ô¨Çow, it is necessary to make sure all the chip samples are freefrom all possible manufacturing defects such as stuck-at fault, path/TDF, etc. [ 13]. This is to ensure that no defective chip escapes from the initial stage of chip test [ 13]. Highly unreli- able trained predictor may result if gross timing defects are notscreened out in advance. Also predicted F maxresponse from defective samples will be erroneous. Our proposed Fmaxprediction methodology is depicted in Fig. 1. The essence of this approach is to train a machine learning classiÔ¨Åer with sufÔ¨Åcient training data obtained from chips under test and training (CTT) [Fig. 1(a)] and later use "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_16", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 16, "text": "y is depicted in Fig. 1. The essence of this approach is to train a machine learning classiÔ¨Åer with sufÔ¨Åcient training data obtained from chips under test and training (CTT) [Fig. 1(a)] and later use this trained predictor to estimate Fmaxfor new chips under test (CUT) [Fig. 1(b)]. The required number of CTTs [marked as black dots on the wafer in Fig. 1(a)] ndepends on the characteristics of the data and generally n<< k, where kis the number of remaining CUTs [marked as red dots on the wafer in Fig. 1(b)]. Let us assume { Si1...Sim} represents the slacks from msensors of the ith chip. The matrix Xtrcontains Fig. 1. (a) Fmaxpredictor development from CTTs. (b) Fmaxprediction of CUTs using the developed predictor. slack data of msensors from each of the ndifferent training samples. The column vector ytrcontains the Fmaxof each of thentraining chips. The slack data collected from kprediction samples in matrix Xprare fed to the trained classiÔ¨Åer to obtain the predicted Fmaxfor these samples Xtr=‚é° ‚é¢‚é£S11¬∑¬∑¬∑ S1m ......... S n1¬∑¬∑¬∑ Snm‚é§ ‚é•‚é¶ytr=‚é° ‚é¢‚é£F1 ... Fn‚é§ ‚é•‚é¶ Xpr=‚é° ‚é¢‚é£S11¬∑¬∑¬∑ S1m ......... S k1¬∑¬∑¬∑ Snm‚é§ ‚é•‚é¶. During training phase both functional Fmaxtest and sensor data extraction is done. The"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_17", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 17, "text": "s Xtr=‚é° ‚é¢‚é£S11¬∑¬∑¬∑ S1m ......... S n1¬∑¬∑¬∑ Snm‚é§ ‚é•‚é¶ytr=‚é° ‚é¢‚é£F1 ... Fn‚é§ ‚é•‚é¶ Xpr=‚é° ‚é¢‚é£S11¬∑¬∑¬∑ S1m ......... S k1¬∑¬∑¬∑ Snm‚é§ ‚é•‚é¶. During training phase both functional Fmaxtest and sensor data extraction is done. The Fmaxfrom functional test and the extracted sensor responses are fed to the machine learningsoftware running at the ATE‚Äôs computer and a trained predictoris obtained. In the training process, if there are Ndiscrete F max classes in the training data or Nbins, an N-level classiÔ¨Åer is trained with the training data. Sensor data extraction involvesthree steps: 1) activation of the sensor monitored paths by shifting in the appropriate test patterns through JTAG port; 2) shifting out the sensor responses through JTAG port; and3) storage of the responses in a log Ô¨Åle for feeding into theATE‚Äôs computer. After the machine learning tools are trained with sufÔ¨Åcient number of CTTs, for CUTs, the expensive procedure of func-tional F maxtesting is omitted and only slacks are measured using the embedded sensors. At prediction phase, the three steps of the above mentioned sensor data processing are com-pleted followed by step 4) execution of the trained machinelearning program in ATE‚Äôs computer to ge"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_18", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 18, "text": " sensors. At prediction phase, the three steps of the above mentioned sensor data processing are com-pleted followed by step 4) execution of the trained machinelearning program in ATE‚Äôs computer to get the predictedF max.T h e Fmaxprediction time can be obtained by summing the times spent in each of the above four steps involved inthe prediction phase. Silicon results presented in [ 19]‚Äîwhich used randomly placed ROs as sensors and Bayesian regression for machine learning‚Äîreported 2780 √óreduction in F maxtest Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 845 Fig. 2. Slack sensor architecture for rising transition. time for a four bin search space over the conventional func- tional Fmaxtesting for ARM-CA9 SoCs fabricated in 28 nm technology. III. P ATH SLACK SENSOR An important component of the Ô¨Çow presented in Fig. 1 is a low-cost embedded sensor to accurately measure slack ofthe selected number of critical/near-critical paths. The circuitdiagram of the used slack sensor IP is shown in Fig. 2. When activat"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_19", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 19, "text": " Fig. 1 is a low-cost embedded sensor to accurately measure slack ofthe selected number of critical/near-critical paths. The circuitdiagram of the used slack sensor IP is shown in Fig. 2. When activated, the sensor monitors and records the worst-case tim-ing slack at the capture Ô¨Çip-Ô¨Çop for all the paths terminating atthat particular capture Ô¨Çip-Ô¨Çop. The sensor probes path ending capture Ô¨Çip-Ô¨Çop‚Äôs D port through a minimum size clock gating cell ensuring that small amount of load capacitance is addedto the main circuit path. In Fig. 2, the architecture of rising transition detector sensor is shown. To make a falling transi-tion detection sensor the M0‚ÄìM6 bits are simply required to be connected to the ¬ØQoutputs (instead of Q) of the Ô¨Çip-Ô¨Çops of the monitor unit (MU). The different modules of the sensor and their functions are brieÔ¨Çy described below. A. Clock Gating Unit The sensor IP is clock gated with the Enable input to turn it on only during the timing slack measurement interval as s h o w ni nF i g . 2. The gated clock signal CLK_ Encontrols all the local Ô¨Çip-Ô¨Çops in the sensor. To preserve the relativetiming relationship between the actual clock (CLK) and inputdata ( D_in), th"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_20", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 20, "text": "s h o w ni nF i g . 2. The gated clock signal CLK_ Encontrols all the local Ô¨Çip-Ô¨Çops in the sensor. To preserve the relativetiming relationship between the actual clock (CLK) and inputdata ( D_in), the clock gating cell was placed with both the incoming data ( D_in) and clock (CLK) inputs. As a result CLK_ EnandD_Enwere synchronized similarly to their non clock-gated counterparts. The clock gating mechanism also minimizes power dissipation during the sensor OFF stage by cutting the dynamic power dissipation.B. Delay Line The delay line consists of a chain of unit size buffers from the standard cell library. The buffers quantize the total slack according to the propagation delay of the used buffer. Thenumber of required buffer stages in the delay line dependson the desired slack detection range and the delay of a unitsize buffer. Use of the unit size buffer from the standardcell library ensures that the slack detection resolution is theoptimum. C. Monitor Unit A Ô¨Çip-Ô¨Çop is attached at the end of each buffer to capture the states in bits M0‚ÄìM6 at the active clock edge. The com- bination of delay line and the Ô¨Çip-Ô¨Çops in the MU convertthe timing slack into a corresponding digital data"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_21", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 21, "text": "he end of each buffer to capture the states in bits M0‚ÄìM6 at the active clock edge. The com- bination of delay line and the Ô¨Çip-Ô¨Çops in the MU convertthe timing slack into a corresponding digital data. The Ô¨Årst bit,M0, of MU is inverted to get the State signal. This State signal indicates if the desired (rising or falling, depending onsensor conÔ¨Åguration) transition is occurring in the incomingdata D_in. D. Capture and Result Storage Unit The capture and result storage unit (CRSU) is constructed of storage cells connected in a scan chain. Each storage cellconsists of an OR-AND gate and a scan Ô¨Çip-Ô¨Çop as shownin Fig. 2. Each Ô¨Çip-Ô¨Çop in the scan chain samples the corre- sponding MU Ô¨Çip-Ô¨Çop‚Äôs output. The AND gate connected tothe scan Ô¨Çip-Ô¨Çop inside the storage cell makes it sticky, in thesense that if the Ô¨Çip-Ô¨Çop ever records a zero, it will hold on to the zero until reset or it is scan-loaded with a logic one. The State signal makes the OR gate transparent to the outputs of MU Ô¨Çip-Ô¨Çops only for the desired transitions. At the initial-ization stage all the scan Ô¨Çip-Ô¨Çops are set to logic one. Duringthe slack evaluation phase, SEis set to zero and the Ô¨Çip-Ô¨Çops inside CRSU record the wor"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_22", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 22, "text": "nly for the desired transitions. At the initial-ization stage all the scan Ô¨Çip-Ô¨Çops are set to logic one. Duringthe slack evaluation phase, SEis set to zero and the Ô¨Çip-Ô¨Çops inside CRSU record the worst-case slack observed at the mon-itored capture Ô¨Çip-Ô¨Çop. The sensor data extraction process is initiated by setting SEpin to logic high which connects the Ô¨Çip-Ô¨Çops in a scan chain clocked by the main clock and Ô¨Ånallythe stored slack data is extracted through the Senor _SOpin. For multiple number of sensors, their CRSU are connectedby a scan chain for data extraction. The meta-stability issuemay occur in at most one of the Ô¨Çip-Ô¨Çops of the MU blockif the output from the buffer of the delay line arrives late in the Ô¨Çip-Ô¨Çop‚Äôs setup time window. Any such meta-stability is automatically resolved in our architecture as we are using twoÔ¨Çip-Ô¨Çops in series‚Äîforming a synchronizer circuit [ 23]‚Äîwith the output of each buffer in the delay line. Since Ô¨Çip-Ô¨Çops in both MU and CRSU are operated by the same clock, the valuesthat were latched by MU Ô¨Çip-Ô¨Çops are sampled again in thenext clock cycle by the CRSU Ô¨Çip-Ô¨Çops. This latency of one clock cycle between successive sampling is utilized to resolve t"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_23", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 23, "text": "me clock, the valuesthat were latched by MU Ô¨Çip-Ô¨Çops are sampled again in thenext clock cycle by the CRSU Ô¨Çip-Ô¨Çops. This latency of one clock cycle between successive sampling is utilized to resolve the meta-stability in the output of MU Ô¨Çip-Ô¨Çops, if any. As aresult, even if there occurs a meta-stability in the MU block,the Ô¨Çip-Ô¨Çops of the CRSU will practically be meta-stabilityresolved because of the high mean time between failure of asynchronizer circuit [ 23] and the designed sticky feature of the CRSU Ô¨Çip-Ô¨Çops. In addition to its application in speed binning, the sensor IP can be also used for in-Ô¨Åeld reliability observation. When Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 846 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 Fig. 3. Sensor insertion Ô¨Çow. necessary, instances of this sensor embedded into the SoC can be activated to monitor and record the delay degradation on the critical/near-critical paths because of noise, aging, and otherwear-out. For this paper, we only analyze the application ofthe sensor IP in speed bin"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_24", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 24, "text": "to monitor and record the delay degradation on the critical/near-critical paths because of noise, aging, and otherwear-out. For this paper, we only analyze the application ofthe sensor IP in speed binning at time 0. IV . S ENSOR INSERTION FLOW In this section, we develop a gate-netlist level and layout- aware algorithm to select path-ending capture Ô¨Çip-Ô¨Çops to be monitored by sensors. The sensors act as features in our machine learning tool. The candidate capture Ô¨Çip-Ô¨Çops for sen-sor placement should be selected based on two main criteria:1) the sensors target the critical/near-critical paths and 2) thesensors or features of the machine learning tool should be agood representative of the trend of the modeling data to incor-porate the chip-to-chip PVT variations [ 25]. Our proposed sensor insertion Ô¨Çow along with the capture Ô¨Çip-Ô¨Çop selection algorithm, shown in Fig. 3, addresses these criteria. For the Ô¨Årst condition, it is not practical to place sensors at the end ofeach of the critical/near-critical paths, as the number of suchpaths are extensive in modern SoCs. Hence, the number of sen-sors to place are decided by the area-overhead budget. For thesecond criterion, the proposed a"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_25", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 25, "text": "al/near-critical paths, as the number of suchpaths are extensive in modern SoCs. Hence, the number of sen-sors to place are decided by the area-overhead budget. For thesecond criterion, the proposed algorithm ensures that the sen- sors cover a wide range of diverse or distinct paths and those paths are spatially distributed across the layout. Spatial distri-bution of the sensors allow monitoring PVT variation effectson the timing critical paths. The Ô¨Çow begins with the synthe-sis of hardware from RTL to the gate-level netlist as depictedin Fig. 3. At this stage, based on the standard cell library used in synthesis and the gate-level netlist, an estimate of the layout area is obtained from the synthesis CAD tool. After that, STA is performed on the synthesized netlist, and critical/near-critical paths (considering both single and multicycle paths)are sorted in order of their respective path slacks. Next the cap-ture Ô¨Çip-Ô¨Çop selection algorithm presented in Algorithm 1is executed. The algorithm is composed of three main proceduresas described in the following. The Ô¨Årst procedure netlist parser (lines 1‚Äì11) takes as input the gate-level netlist of the design, list of logical modulesAl"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_26", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 26, "text": "gorithm is composed of three main proceduresas described in the following. The Ô¨Årst procedure netlist parser (lines 1‚Äì11) takes as input the gate-level netlist of the design, list of logical modulesAlgorithm 1 Proposed Capture Flip-Flop Selection Algorithm 1:procedure NETLIST PARSER 2:Input: Gate-level netlist of the main design 3:Input: Number of logical modules in design netlist, Nmodule 4:Input: Static timing analysis report with capture Ô¨Çip-Ô¨Çops and slack data 5:Input: Cut-off timing slack, Scut 6:Output: For each logical module k, a list of unique capture Ô¨Çip-Ô¨Çops sorted in ascending order of slack, Dk={d1k,d2k,d3k,...dnk} 7: CFF‚Üêset of all unique capture Ô¨Çip-Ô¨Çops in design netlist with slack below Scut 8: for k=1to number of logical modules Nmodule do 9: Dk‚Üêlist of capture Ô¨Çip-Ô¨Çops ( Dk‚äÇCFF) in logical module k 10: end for 11: end procedure 12: 13: procedure GATE-OVERLAP AWARE FLIP-FLOP SORTER 14: Input: Logical module based capture Ô¨Çip-Ô¨Çop list Dkfrom previous procedure 15: Input: Gate-overlap threshold, Œ¥OV 16: Input: Number of logical modules in design netlist, Nmodule 17: Output: Gate-overlap aware list of capture Ô¨Çip-Ô¨Çops (sorted in ascending order of slack) for each log"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_27", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 27, "text": "t: Gate-overlap threshold, Œ¥OV 16: Input: Number of logical modules in design netlist, Nmodule 17: Output: Gate-overlap aware list of capture Ô¨Çip-Ô¨Çops (sorted in ascending order of slack) for each logical module k,Lk 18: 19: fork=1to number of logical modules Nmodule do 20: fori=1to number of Ô¨Çip-Ô¨Çops in Dkdo 21: Gik‚Üêlist of on-path (critical/near-critical) gates for Ô¨Çip-Ô¨Çop dik‚ààDk 22: end for 23: end for 24: Initialization: Tk={G1k}fork=1 to Nmodule 25: Initialization: Lk={d1k}fork=1 to Nmodule 26: fork=1to number of logical modules Nmodule do 27: fori=2to number of Ô¨Çip-Ô¨Çops in Dkdo 28: Œ¥= percentage gate-overlap between TkandGik 29: if(Œ¥<Œ¥ OV)then 30: Tk=Tk‚à™Gik 31: Lk=Lk‚à™dik 32: end if 33: end for 34: end for 35: end procedure 36: 37: procedure IDENTIFICATION OF SENSOR INSERTION POINTS 38: Input: Area of the sensor module, Area Sensor 39: Input: Estimated total area of the main design, Area main.design 40: Input: Area-overhead budget, Area Overhead 41: Input: Optimized list of unique capture Ô¨Çip-Ô¨Çops in each logical module k,Lk 42: Output: Set of target capture Ô¨Çip-Ô¨Çops for sensor insertion in each module k,FFk 43: Total Sensor =(Area main.design ‚àóArea Overhead )/Area Sensor 44: "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_28", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 28, "text": " capture Ô¨Çip-Ô¨Çops in each logical module k,Lk 42: Output: Set of target capture Ô¨Çip-Ô¨Çops for sensor insertion in each module k,FFk 43: Total Sensor =(Area main.design ‚àóArea Overhead )/Area Sensor 44: fork=1to number of logical modules Nmodule do 45: Nk=number of capture Ô¨Çip-Ô¨Çops in list Lk 46: end for 47:/summationtextNk=total number of capture Ô¨Çip-Ô¨Çops in all of the kmodules 48: fork=1to number of logical modules Nmodule do 49: Pk=Nk/summationtextNk; module k‚Äôs contribution to the total number of candidate Ô¨Çip- Ô¨Çops 50: Sk=Pk‚àóTotal Sensor ; Allotted number of sensors for logical module k 51: FFk‚Üêselect top Skcapture Ô¨Çip-Ô¨Çops from list Lk 52: end for 53: end procedure inside the design, timing slack data for each capture Ô¨Çip-Ô¨Çop obtained from STA, and a cut-off slack margin. This proce- dure outputs the sorted list ( Dk) of capture Ô¨Çip-Ô¨Çops grouped according to the logical modules where those belong to. Thelogical module and slack-based sorting of capture Ô¨Çip-Ô¨Çopsis accomplished by looping over all of the capture Ô¨Çip-Ô¨Çopinstances above the target cut-off slack, followed by parsingof the gate-level netlist to identify the Ô¨Çip-Ô¨Çop‚Äôs location in the logical hierarchy and putting it in"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_29", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 29, "text": "ping over all of the capture Ô¨Çip-Ô¨Çopinstances above the target cut-off slack, followed by parsingof the gate-level netlist to identify the Ô¨Çip-Ô¨Çop‚Äôs location in the logical hierarchy and putting it in the appropriate list as shown in lines 8‚Äì10. The second procedure gate-overlap aware Ô¨Çip-Ô¨Çop sorter (lines 13‚Äì35) outputs a reduced list L kof capture Ô¨Çip-Ô¨Çops obtained by narrowing down the selection to include pathswith diverse or distinct logic gates. The distinctness of theselected capture Ô¨Çip-Ô¨Çops is achieved by reducing the num- ber of overlapping logic gates among the critical/near-critical paths terminating at those capture Ô¨Çip-Ô¨Çops. The inputs to this Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 847 procedure are the Ô¨Çip-Ô¨Çop list Dkfrom the previous procedure, a target gate-overlap threshold Œ¥OVand the list of logical mod- ules. In the Ô¨Årst stage of this procedure, the lists Gik‚Äîof all on-path logic gates for the critical/near-critical paths terminat-ing at each capture Ô¨Çip-Ô¨Çop iof each logical modu"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_30", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 30, "text": "list of logical mod- ules. In the Ô¨Årst stage of this procedure, the lists Gik‚Äîof all on-path logic gates for the critical/near-critical paths terminat-ing at each capture Ô¨Çip-Ô¨Çop iof each logical module k‚Äîare generated as shown in lines 19‚Äì23. Next, for each hierarchi-cal logical module k, we create two arrays T kandLkto hold the on-path logic gates and capture Ô¨Çip-Ô¨Çops, respectively. We initialize Lkwith the Ô¨Årst capture Ô¨Çip-Ô¨Çop d1kfrom the list Dk andTkwith the corresponding on-path logical gates as demon- strated in lines 24 and 25. Next, for each logical module, weiterate over the rest of the capture Ô¨Çip-Ô¨Çops and include a cap-ture Ô¨Çip-Ô¨Çop in the list L kif the gate-overlap threshold between this particular Ô¨Çip-Ô¨Çop‚Äôs on-path logic gates and the existing gates in the list Tkis less than the preselected threshold Œ¥OV (lines 26‚Äì34). The Ô¨Ånal procedure IdentiÔ¨Åcation of Sensor Insertion Points generates the list FFkof target capture Ô¨Çip-Ô¨Çops in module k for sensor insertion. The inputs to this procedure are the area ofthe main design, area of each sensor, area-overhead budget andthe optimized Ô¨Çip-Ô¨Çop list L kfrom the previous procedure. In line 43, the total number of available sens"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_31", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 31, "text": "to this procedure are the area ofthe main design, area of each sensor, area-overhead budget andthe optimized Ô¨Çip-Ô¨Çop list L kfrom the previous procedure. In line 43, the total number of available sensors is calculated from the area-overhead budget. Next, in lines 44‚Äì46, Nknumber of Ô¨Çip-Ô¨Çops in list Lkare identiÔ¨Åed for each module k. In lines 49 and 50, available sensor quota Skfor each logical module kis calculated. This quota for a module is decided by the module‚Äôs share in the cumulative number of total capture Ô¨Çip-Ô¨Çops. Lastly, in line 51, the Ô¨Ånal capture Ô¨Çip-Ô¨Çop list FF kfor each module kis reported by selecting top SkÔ¨Çip-Ô¨Çops from the list Lkfor sensor insertion. After Ô¨Ånalizing the sensor insertion points or the capture Ô¨Çip-Ô¨Çops, the sensor instances are added inside the synthesizednetlist of the SoC at those identiÔ¨Åed insertion points usingcustom scripts and the physical design is completed. V. M ACHINE LEARNING In developing our speed binning model, we explored Ô¨Åve major multiclass machine learning classiÔ¨Åers [ 33]: 1) multino- mial logistic regression; 2) multiclass support vector machine;3) bootstrap aggregation (bagging) decision tree; 4) randomforest decision tree; and"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_32", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 32, "text": "class machine learning classiÔ¨Åers [ 33]: 1) multino- mial logistic regression; 2) multiclass support vector machine;3) bootstrap aggregation (bagging) decision tree; 4) randomforest decision tree; and 5) adaptive boosting (AdaBoost).Brief descriptions on each of these techniques are given below. A. Multinomial Logistic Regression Multinomial logistic regression is a supervised machine learning technique, where a linear combination of the observedfeatures are used to predict the class label [ 26]. In this regres- sion model the log-odds of the outcomes are modeled as alinear combination of the predictor variables. Contrary to lin-ear regression, where the dependent variable or the outcome is continuous, in logistic regression it is categorical, i.e., discrete. The training set of mtraining samples is represented in the form {(x (1),y(1)),(x(2),y(2)),...,( x(m),y(m))}. The input data sample x(i)‚ààRN, where Nis the total number of features. For Kpossible classes, the class labels y(i)‚àà {1,2,..., K}. The weight parameters, corresponding to the class labels, are Œ∏(1),Œ∏(2),...,Œ∏(K)‚ààRN. By concatenat- ing the columns Œ∏(1),Œ∏(2),...,Œ∏(K)anN-by-Kmatrix Œ∏= [Œ∏(1)Œ∏(2)... Œ∏(K)]i sf o r m e d[ 26]"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_33", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 33, "text": "2,..., K}. The weight parameters, corresponding to the class labels, are Œ∏(1),Œ∏(2),...,Œ∏(K)‚ààRN. By concatenat- ing the columns Œ∏(1),Œ∏(2),...,Œ∏(K)anN-by-Kmatrix Œ∏= [Œ∏(1)Œ∏(2)... Œ∏(K)]i sf o r m e d[ 26].During supervised training stage, using the training data the matrix Œ∏is obtained for which the following cost function J(Œ∏)is minimum. Iterative optimization algorithm is used for obtaining the solution [ 26] J(Œ∏)=‚àím/summationdisplay i=1K/summationdisplay k=11/braceleftBig y(i)=k/bracerightBig logexp/parenleftBig Œ∏(k)Tx(i)/parenrightBig /summationtextK j=1exp/parenleftBig Œ∏(j)Tx(i)/parenrightBig. During prediction, for any test input x, a hypothesis is required to estimate the probability that P(y=k|x)for each k‚àà{1,2,...K}. This hypothesis outputs a vector of length K representing the probabilities. The hypothesis hŒ∏(x)is [26] hŒ∏(x)=‚é° ‚é¢‚é¢‚é¢‚é£P(y=1|x;Œ∏) P(y=2|x;Œ∏) ... P(y=K|x;Œ∏)‚é§ ‚é•‚é•‚é•‚é¶ =1 /summationtextK j=1exp/parenleftbig Œ∏(j)Tx/parenrightbig‚é° ‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£exp/parenleftBig Œ∏ (1)Tx/parenrightBig exp/parenleftBig Œ∏(2)Tx/parenrightBig ... exp/parenleftBig Œ∏(K)Tx/parenrightBig‚é§ ‚é•‚é•‚é•‚é•‚é•‚é•‚é¶. Inh Œ∏(x)the class label for which the probability is maxi- mum is taken as the predicted class for the test dat"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_34", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 34, "text": "xp/parenleftBig Œ∏(2)Tx/parenrightBig ... exp/parenleftBig Œ∏(K)Tx/parenrightBig‚é§ ‚é•‚é•‚é•‚é•‚é•‚é•‚é¶. Inh Œ∏(x)the class label for which the probability is maxi- mum is taken as the predicted class for the test data x. B. Multiclass Support Vector Machine The support vector machine (SVM) classiÔ¨Åer is inherently a binary classiÔ¨Åer that distinguishes between two classes [ 27]. To apply SVM technique to multiclass classiÔ¨Åcation, the mul- ticlass problem is Ô¨Årst reduced to multiple binary classiÔ¨Åcation problems that can be solved separately [ 28], [29]. For a multiclass classiÔ¨Åcation scenario with Knumber of classes, one-against-one or all-pairs comparison would require/parenleftbigK 2/parenrightbig or K(K‚àí1)/2 binary classiÔ¨Åers. The/parenleftbigK 2/parenrightbig hypotheses that are generated by this process are next combined to get the Ô¨Ånal predicted class [ 28]. To combine multiple binary SVMs for multiclass classiÔ¨Åcation problems, the error correcting outputcode (ECOC) multiclass model has been proposed to achievea very high prediction accuracy [ 28]. The ECOC model reduces the problem of classiÔ¨Åcation with three or more classes to a set of binary SVM classiÔ¨Åers by using a coding matrix M C, wher"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_35", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 35, "text": "sed to achievea very high prediction accuracy [ 28]. The ECOC model reduces the problem of classiÔ¨Åcation with three or more classes to a set of binary SVM classiÔ¨Åers by using a coding matrix M C, where the elements of MCare from the set {‚àí1,0,+1}[29]. For the all-pairs approach and Knumber of classes, the coding matrix MChasKrows and/parenleftbigK 2/parenrightbig columns. Each row of the coding matrix corresponds to a distinct class. The SVM of each column of MCcorresponds to a distinct pair (rp,rq), where (rp,rq)is one of the/parenleftbigK 2/parenrightbig possible pairs. In the column corresponding to the SVM for the pair (rp,rq),+1 (to indicate positive class) is assigned for the row rp,‚àí1 (to indicate negative class) is assigned for row rqand zeros (ignore) are assigned for all other rows [ 29]. During training phase, all the/parenleftbigK 2/parenrightbig binary SVMs‚Äî corresponding to the columns of MC‚Äîare trained using conventional SVM methods [ 27]‚Äì[29]. After training is complete, for a new observation Xall the trained N=/parenleftbigK 2/parenrightbig binary SVMs are executed. The vec- tor of predictions by the individual SVMs are, f(X)= Authorized licensed use limited to: Ho"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_36", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 36, "text": ", for a new observation Xall the trained N=/parenleftbigK 2/parenrightbig binary SVMs are executed. The vec- tor of predictions by the individual SVMs are, f(X)= Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 848 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 Algorithm 2 Bagging Machine Learning ClassiÔ¨Åcation 1:procedure TRAINING PHASE 2:Input: Training data set Z={XTr,yTr}; Matrix XTris of the form [x1;x2;...;xm]T where each xiis a row vector ( i=1tom)a n d yTris a melement column vector consisting of class labels for each row of matrix XTr 3:Input: Number of classiÔ¨Åers to train, N 4:Output: A set of trained classiÔ¨Åers T={D1,D2,D3,...DN} 5: Initialization: T={} 6: for k=1to number of classiÔ¨Åers Ndo 7: Sk‚Üêgenerated bootstrap sample with replacement from training data set Z 8: Dk‚Üêbuilt and trained decision-tree classiÔ¨Åer using Skas the training data 9: T=T‚à™Dk 10: end for 11: end procedure 12: 13: procedure PREDICTION PHASE 14: Input: A set of trained classiÔ¨Åers, T={D1,D2,D3,...DN} 15: Input: New data for classiÔ¨Åcation, xC 16: Outpu"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_37", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 37, "text": " training data 9: T=T‚à™Dk 10: end for 11: end procedure 12: 13: procedure PREDICTION PHASE 14: Input: A set of trained classiÔ¨Åers, T={D1,D2,D3,...DN} 15: Input: New data for classiÔ¨Åcation, xC 16: Output: Predicted class or label, yC, corresponding to the input data xC 17: 18: for k=1to number of classiÔ¨Åers Ndo 19: rk‚Üêresponse obtained from execution of trained classiÔ¨Åer Dk‚ààTonxC 20: end for 21: yC‚ÜêMajority vote {r1,r2,...rk} 22: end procedure [f1(X) ,..., fN(X)]. As the Ô¨Ånal predicted class label, ÀÜyis chosen such that ÀÜy=argmin r‚ààYN/summationdisplay s=1L(MC(r,s)fs(X)) where Lis the loss function, Yis the set of Kclass labels [ 29]. C. Bootstrap Aggregating Bagging is an ensemble meta-algorithm that improves the stability and accuracy of machine learning classiÔ¨Åers [ 30]. The essence of bagging is to Ô¨Åt many large decision treesto bootstrap-resampled versions of the training data, and clas-sify the Ô¨Ånal label by majority vote. Bagging averages a givenprocedure over many samples, to reduce its variance. As bag-ging algorithm performs averaging on bootstrap samples, the error from variance can be suppressed even for the regres- sion or classiÔ¨Åcation procedures that are not very stable"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_38", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 38, "text": "ce its variance. As bag-ging algorithm performs averaging on bootstrap samples, the error from variance can be suppressed even for the regres- sion or classiÔ¨Åcation procedures that are not very stable [ 30]. In situations for which the predictor has a relatively largevariance, bagging can appreciably reduce the mean squaredprediction error, provided that the learning sample is suf-Ô¨Åciently large. The bagging machine learning Ô¨Çow [ 30]i s presented in Algorithm 2. In the training phase (lines 1‚Äì11), the inputs to the algorithm are the training samples along with their respective class labels and the targeted number of clas-siÔ¨Åers to train. The mbyfmatrix X Trconsists of mtraining samples with fnumber of features. The corresponding class labels are included in the column vector yTr. The output T is a set of trained classiÔ¨Åers on the bootstrap samples. Asdepicted in lines 6‚Äì10, on each iteration a bootstrap sample S kis drawn from the training data set, a decision-tree classiÔ¨Åer Dkis obtained with this sample and included in the classiÔ¨Åer ensemble T. In the subsequent prediction phase (lines 13‚Äì22), the trained ensemble Tand new data for classiÔ¨Åcation xCare fed, and the predicted clas"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_39", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 39, "text": "ined with this sample and included in the classiÔ¨Åer ensemble T. In the subsequent prediction phase (lines 13‚Äì22), the trained ensemble Tand new data for classiÔ¨Åcation xCare fed, and the predicted class label yCis obtained. Each classi- Ô¨ÅerDkin the ensemble Treports a predicted class label rkas shown in line 19. Finally in line 21, a majority vote is taken on the individually predicted labels and the winner is the Ô¨Ånal class label yC.Algorithm 3 AdaBoost.M2 Machine Learning ClassiÔ¨Åcation 1:procedure TRAINING PHASE 2:Input: Set of unique class labels Y, where number of class labels is L 3:Input: Training data set Z={XTr,yTr}; Matrix XTris of the form [x1;x2;...;xm]T where each xiis a row vector ( i=1tom)a n d yTrconsists of class labels for each row of matrix XTr.yTris of the form [y1y2...ym]Twhere yi‚ààY(i=1tom) 4:Input: Weak learning algorithm WeakLearn 5:Input: Number of iterations or boosting rounds, N 6:Output: The Ô¨Ånal classiÔ¨Åer hÔ¨Ån 7: LetB={(i,y):i‚àà{1,..., m},y/negationslash=yi}, so length of B, |B|=m(L‚àí1) 8: Initialization: D1(i,y)=1 |B|=1 m(L‚àí1)for(i,y)‚ààB 9: for k=1to number of iterations Ndo 10: hk‚Üêhypothesis returned by WeakLearn called with mislabel distribution Dk 11: Œµk=1"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_40", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 40, "text": " length of B, |B|=m(L‚àí1) 8: Initialization: D1(i,y)=1 |B|=1 m(L‚àí1)for(i,y)‚ààB 9: for k=1to number of iterations Ndo 10: hk‚Üêhypothesis returned by WeakLearn called with mislabel distribution Dk 11: Œµk=1 2‚àó/summationtext (i,y)‚ààB[Dk(i,y)]‚àó[1‚àíhk(xi,yi)+hk(xi,y)]= pseudo-loss of hk 12: Œ≤k=Œµk/(1‚àíŒµk) 13: Dk+1(i,y)=Dk(i,y) Zk‚àóŒ≤0.5‚àó[1+hk(xi,yi)‚àíhk(xi,y)] k;Zkis normalization constant 14: end for 15: hÔ¨Ån(x)=argmax y‚ààYk=N/summationdisplay k=1log(1 Œ≤k)‚àóhk(x,y) 16: end procedure 17: 18: procedure PREDICTION PHASE 19: Input: The Ô¨Ånal classiÔ¨Åer hÔ¨Ån 20: Input: New data for classiÔ¨Åcation, xC 21: Output: Predicted class or label, yC, corresponding to the input data xC 22: yC=hÔ¨Ån(xC)=argmax y‚ààYk=N/summationdisplay k=1log(1 Œ≤k)‚àóhk(xC,y) 23: end procedure D. Random Forest The random forest algorithm strives to improve the efÔ¨Åcacy of the bootstrap aggregating technique by decorrelating thetrees [ 31]. The random forest technique is similar to the bag- ging Ô¨Çow presented in Algorithm 2, with the only exception that at each tree split a random sample of qfeatures are drawn, and only those features are considered for splitting in the deci- sion tree. Generally q=‚àö f, where fis the total number of features. "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_41", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 41, "text": "n that at each tree split a random sample of qfeatures are drawn, and only those features are considered for splitting in the deci- sion tree. Generally q=‚àö f, where fis the total number of features. The overall effect is that the variance is reduced whenwe average the trees. In other words, random forest curbs theover-Ô¨Åtting of the training data set [ 30], [31]. E. Adaptive Boosting AdaBoost is a machine learning meta-algorithm [ 32], where the training Ô¨Çow starts with the execution of the Ô¨Årst classi- Ô¨Åer supplied with equally weighted training data. Based on the accuracy of the Ô¨Årst classiÔ¨Åer, weights on misclassiÔ¨Åeddata are increased for the second classiÔ¨Åer. This procedure ofgiving emphasis on misclassiÔ¨Åed data is repeated until all theclassiÔ¨Åers are trained. The AdaBoost.M2 algorithm [ 32], pre- sented in Algorithm 3, takes as input the set of unique class labels Y, the training data set ( X Tr,yTr), a choice of a basic classiÔ¨Åer called WeakLearn , the number of iterations N, and outputs the Ô¨Ånal optimized classiÔ¨Åer hÔ¨Ån. The mislabel weight distribution function D1is initialized to a uniform distribution. Next the algorithm calls the basic classiÔ¨Åer WeakLearn ‚Äî generally a tr"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_42", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 42, "text": " outputs the Ô¨Ånal optimized classiÔ¨Åer hÔ¨Ån. The mislabel weight distribution function D1is initialized to a uniform distribution. Next the algorithm calls the basic classiÔ¨Åer WeakLearn ‚Äî generally a tree classiÔ¨Åer‚Äîrepeatedly in a series of iterations.On iteration k, the booster provides WeakLearn with a mis- label distribution D kover the training data set. As shown in line 10, the response of WeakLearn is a classiÔ¨Åer or hypoth- esis hk, which is able to correctly classify a portion of the Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 849 training set that has higher probability with respect to the dis- tribution Dk. The weak learner‚Äôs goal is to Ô¨Ånd a hypothesis which minimizes the training error Œµk(line 11) with respect to the distribution Dkthat was provided to the weak learner. To indicate the degree of credibility, each weak hypothesish koutputs a vector with values in the range of 0‚Äì1 corre- sponding to the class labels, where the objects with values close to 0 or 1 are considered to be implausible or"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_43", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 43, "text": "dibility, each weak hypothesish koutputs a vector with values in the range of 0‚Äì1 corre- sponding to the class labels, where the objects with values close to 0 or 1 are considered to be implausible or plausible, respectively. In line 11 of Algorithm 3,i fhk(xi,yi)=1 and hk(xi,y)=0, then hkhas predicted that xi‚Äôs class label is yi, noty, which is the correct prediction. On the other hand, if hk(xi,yi)=0 and hk(xi,y)=1, then hkhas incorrectly made the opposite prediction. hk(xi,yi)=hk(xi,y)implies random guess [ 32]. The quality of a trained hypothesis hkis judged with the pseudo-loss factor /epsilon1k. Pseudo-loss is used to instruct the algorithm to concentrate on the labels that are hardest todifferentiate. Pseudo-loss /epsilon1 kis computed with respect to a dis- tribution Dkover the set of all pairs of examples and incorrect labels as shown in line 11. In line 13, mislabel weight distri-bution for next iteration is updated according to the trainingerror, and this enables the boosting algorithm to force the WeakLearn to focus not only on harder-to-classify samples, but more particularly, on the incorrect labels that are hardestto differentiate. Finally, after Niterations, the boo"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_44", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 44, "text": "g algorithm to force the WeakLearn to focus not only on harder-to-classify samples, but more particularly, on the incorrect labels that are hardestto differentiate. Finally, after Niterations, the booster com- bines the weak hypotheses h 1,h2,..., hkinto a single Ô¨Ånal hypothesis hÔ¨Ånas reported in line 15. Later in the prediction stage, new test data xCis supplied to the trained classiÔ¨Åer hÔ¨Ånto get the predicted class label yCas shown in line 22 of Algorithm 3. VI. S IMULATION RESULTS AND ANALYSIS The Ô¨Årst step in extracting the path slacks for speed binning using embedded sensors, is to design the sensor IP with appro-priate slack detection range. The detection resolution is limitedby the delay of a unit buffer. The nominal resolution at typical-typical corner for our selected 28 nm standard cell library is 20 ps [ 38]. The expected resolution at 14 and 22 nm nodes are 10 and 6 ps, respectively, considering minimum size buffersat nominal conditions [ 39]. The resolution also sets the max- imum round-off error limit of slack measurement. The slackdetection range is set to 15% of the nominal clock period ofthe SoC in which the sensors would be embedded. With anominal clock period of "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_45", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 45, "text": "ax- imum round-off error limit of slack measurement. The slackdetection range is set to 15% of the nominal clock period ofthe SoC in which the sensors would be embedded. With anominal clock period of 833 ps (based on path-delay anal- ysis of possible critical paths) for our benchmark circuit, at the sensor nominal resolution of 20 ps for the selected stan-dard cell library, 7 buffers are required to cover a 15% slackmargin‚Äîwhich is about 140 ps. After deciding the number of required buffers in the delay line, the slack sensor IP was written in gate-level Verilog andsynthesized with design compiler using Synopsys 28 nm stan- dard cell library [ 38]. During creation of the layout of the sensor soft macro, the buffers were placed in the same rowadjacent to one another to ensure delay consistency amongthe buffers. The Ô¨Çip-Ô¨Çops inside a sensor were also placedadjacently in a row. Each sensor occupied a layout area of164Œºm 2and dissipated 26 ŒºW power while activated. A post layout SPICE netlist was extracted and simulated with HSPICE [ 38]. Timing diagrams from post-layout SPICE sim- ulations are given in Fig. 4, where the timing slack simulated Fig. 4. Wave-shapes of sensor response fro"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_46", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 46, "text": "ist was extracted and simulated with HSPICE [ 38]. Timing diagrams from post-layout SPICE sim- ulations are given in Fig. 4, where the timing slack simulated Fig. 4. Wave-shapes of sensor response from SPICE simulation. is 100 ps. The active zero State signal transitions to zero after the rising clock edge at 2 ns. The Ô¨Çip-Ô¨Çops of MU recordthis slack data into bits M0‚ÄìM6 as shown in the respective wave-shapes in Fig. 4. Wave-shapes S0‚ÄìS6 capture the worst- case slack information for the case of a rising transition of theData _Ensignal. In Fig. 4, the timing slack corresponding to the clock edge at 2 ns is recorded in storage bits S0‚ÄìS6a f t e r a latency of one clock cycle at the clock edge at 3 ns to avoid meta-stability as discussed in Section III. The sensor calibration results for 28 nm standard cell library are given in Table I, where column 1 reports the slack obtained by subtracting the Ô¨Çip-Ô¨Çop setup time from the delay betweenthe data arrival time and the active clock edge. Column 2shows the effects of temperature variations on the sensor responses at nominal VDD. Since only seven buffers were used in the delay line, it was observed‚Äîfor the selected 28 nmlibrary‚Äîthat the se"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_47", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 47, "text": "umn 2shows the effects of temperature variations on the sensor responses at nominal VDD. Since only seven buffers were used in the delay line, it was observed‚Äîfor the selected 28 nmlibrary‚Äîthat the sensor responses were invariant of any shiftin temperature within 20 ‚ó¶C‚Äì80‚ó¶C, the typical temperature in IC test environment. A similar calibration table can beobtained for other temperatures. We assume that the chip tem-perature would be available from the typical thermal sensors used in SoCs [ 36]. As mentioned in Section III, for a rising transition detection, the sensors are initialized with a sensorreading of 1111111, before the path slack measurements com-mence. At the upper detection limit the sensor code is 1111111and as the slack decreases, the sensor code changes from1111111 to 1111110, then to 1111100 and eventually to thelower detection limit at 1000000, where each zero represents slack reduction by an amount equal to the delay of a buffer. Hence, the sensor reading of 1111111 indicates slack is at least140 ps and 0000000 interprets that the monitored slack wasnegative. Other states not mentioned in the calibration tableindicate that the current slack is beyond the detection "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_48", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 48, "text": "dicates slack is at least140 ps and 0000000 interprets that the monitored slack wasnegative. Other states not mentioned in the calibration tableindicate that the current slack is beyond the detection rangeof the sensor. Since the speed of the buffers used in the delayline is sensitive to power supply noise and voltage droop, we analyzed the power supply variation sensitivity of the sensor IP and tabulated the results in Table I. The effect of voltage Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 850 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 TABLE I SENSOR CALIBRATION RESULTS FOR 28 nm S TANDARD CELLLIBRARY Fig. 5. Monte Carlo process variation simulation results on sensor IP atnominal VDD. droop‚Äîslowing down of the sensor as shown for the 90% VDD case in column 3‚Äîcan be easily decoupled from slack data with the aid of power supply noise sensors [ 37]. To assess the impact of process variations on the sensitivity of the sensor, we conducted a 150 sample Monte Carlo simu-lation on the sensor IP. The selected parameters to vary"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_49", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 49, "text": "ly noise sensors [ 37]. To assess the impact of process variations on the sensitivity of the sensor, we conducted a 150 sample Monte Carlo simu-lation on the sensor IP. The selected parameters to vary fromnominal were transistor length ( L), width ( W), and threshold voltage ( V th) each by 15%, and oxide thickness ( tox)b y4 % . All simulations were done within the statistical range of 3 standard deviations (3 œÉ). The results are depicted in the pie charts of Fig. 5, where it can be observed that in all the cases about 95% of the responses matched the expected calibrationresults of Table I, in the rest of the cases the sensor response was either slower or faster by a unit buffer delay. These resultsimply that worst-case observation error is limited to one bufferdelay. Next, we implemented our proposed sensor insertion Ô¨Çow and the capture Ô¨Çip-Ô¨Çop selection algorithm described inSection IVfor speed binning. We selected the Ô¨Çoating point and graphics unit (FGU) circuit from the OpenSPARCT2SoC‚Äôs SPARC core [ 40]. The circuits were synthesized to gate-level netlist with 28 nm standard cell library using designcompiler [ 38]. For the FGU circuit, from an initial post syn- thesis timing "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_50", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 50, "text": "T2SoC‚Äôs SPARC core [ 40]. The circuits were synthesized to gate-level netlist with 28 nm standard cell library using designcompiler [ 38]. For the FGU circuit, from an initial post syn- thesis timing analysis with PrimeTime [ 38], the list of all the timing paths sorted in the descending order of nominaldelay were obtained. The layout area of FGU was estimatedfrom the synthesis tool design compiler [ 38]. The statistics from the sensor insertion Ô¨Çow are shown in Table II. For an area-overhead budget of 2%, the corresponding number of cap-ture Ô¨Çip-Ô¨Çops to be monitored by sensors were around 25 as reported in column 5 in Table II. Here, the area-overhead of 2% is a conservative estimate as we have considered only theTABLE II LAYOUT STATISTICS AND SENSOR AREA OVERHEAD FOR FGU Fig. 6. Sensor loading effect on path delay. TABLE III SENSOR LOADING EFFECT ON PATH DELAY standard cell area. If we also include the area of the register Ô¨Åle macro in calculating the overhead, the overall area-overheadis only 0.39%. Fig. 6shows the diagram of an actual critical/near-critical path from FGU, which was used to analyze the sensor‚Äôs load-ing impact on the critical/near-critical path‚Äôs delay. In Table"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_51", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 51, "text": "eadis only 0.39%. Fig. 6shows the diagram of an actual critical/near-critical path from FGU, which was used to analyze the sensor‚Äôs load-ing impact on the critical/near-critical path‚Äôs delay. In Table III, the pin capacitance values and cell‚Äôs load drive capacity fac- tor are reported from the NLDM/CCS liberty [ 38] library Ô¨Åle and design manual, respectively, available with the 28 nmstandard cell library. We also performed a detailed SPICE sim-ulation on the path with and without the sensor. As shown inrows 4 and 5 of Table III, because of the sensor insertion the path delay increased to 769 ps from 762 ps, which is less than1% increase. Column 1 in Table IVreports the different logical mod- ules of the FGU circuit and column 2 reports the number ofunique capture Ô¨Çip-Ô¨Çops in each logical module. The slack cut-off range for identifying critical/near-critical capture Ô¨Çip-Ô¨Çopswas set as 15% of the nominal clock period. While selectingthe critical/near-critical paths to monitor with sensors, we ana-lyzed if the path‚Äôs output node was rare. A rare node is deÔ¨Åned as a node where the switching activity is very low. To obtain the switching activity, it is required to run dedicated test pr"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_52", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 52, "text": "rs, we ana-lyzed if the path‚Äôs output node was rare. A rare node is deÔ¨Åned as a node where the switching activity is very low. To obtain the switching activity, it is required to run dedicated test pro-grams that represent the actual workload, and then monitor theswitching proÔ¨Åle at the node of interest. Since, for FGU cir-cuit module we did not have dedicated workload programs, wehave used the Sandia controllability/observability analysis pro-gram (SCOAP)-based technique [ 34] to identify the switching proÔ¨Åle at a node. This technique is based on the observation that the probability of a node being rare is directly correlated to Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 851 TABLE IV SENSOR DISTRIBUTION IN FGU OFOPENSPARCT2 the node‚Äôs controllability [ 34]. A node with very low controlla- bility implies the logic transition on that node is a scarce event.The SCOAP [ 35] technique can calculate ‚Äúcontrollability to 0‚Äù and ‚Äúcontrollability to 1‚Äù for each node in the circuit, where higher values indicate l"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_53", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 53, "text": "e logic transition on that node is a scarce event.The SCOAP [ 35] technique can calculate ‚Äúcontrollability to 0‚Äù and ‚Äúcontrollability to 1‚Äù for each node in the circuit, where higher values indicate lower controllability. For our switching analysis, we take the ratio, R T=minimum (controllability to 0, controllability to 1)/ maximum (controllability to 0, control- lability to 1). 0 <RT‚â§1; and the closer the value of RT to 0, the lower is the probability of a switching event on that node. We used the SCOAP function available with SynopsysTetramax tool [ 38] to evaluate the R Tparameter at the output node (which connects to the Dpin of capture Ô¨Çip-Ô¨Çop) of each critical/near-critical path. For the critical/near-critical paths ofFGU circuit, the R Tvalue ranged from 0.44 to 0.95. Since these values are not low enough to indicate signiÔ¨Åcantly lowswitching activity node, we did not eliminate any critical/near-critical path because of lower probability of switching proÔ¨Åle.The results are also intuitive because many gates are con- nected in-series in a long path, as a result output node of a critical/near-critical path is hardly rare (i.e., low switchingevent). To identify the critical/nea"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_54", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 54, "text": " intuitive because many gates are con- nected in-series in a long path, as a result output node of a critical/near-critical path is hardly rare (i.e., low switchingevent). To identify the critical/near-critical paths of FGU, and to sort them according to the logical modules where they ter-minate, the STA was performed in three steps: 1) the STAwas run on the full FGU module, and the list of critical/near- critical capture Ô¨Çip-Ô¨Çops obtained; 2) those capture Ô¨Çip-Ô¨Çops (along with their corresponding paths) were grouped accordingto their logical module location; and 3) the STA was again runindividually for each logical module with only the path groupof that module. The results of STA are shown in columns3 and 4 of Table IV. The gate-overlap aware Ô¨Çip-Ô¨Çop sort- ing algorithm (Algorithm 1in Section IV) was executed with a gate-overlap factor of 30%. The Ô¨Çip-Ô¨Çop reduction results form gate-overlap analysis are given in column 4 in Table IV. Each logical module‚Äôs percentage share in the candidate Ô¨Çip-Ô¨Çop list are given in column 5. According to each module‚Äôsrespective share, the slack sensors were allotted into thoselogical modules. An effort was made to include at least onesensor in each"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_55", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 55, "text": "date Ô¨Çip-Ô¨Çop list are given in column 5. According to each module‚Äôsrespective share, the slack sensors were allotted into thoselogical modules. An effort was made to include at least onesensor in each logical module. After Ô¨Ånalizing the candidate capture Ô¨Çip-Ô¨Çops for sensor insertion following the proposed Ô¨Çow, the sensor instance was added to those points inside the Fig. 7. (a) Layout of FGU with embedded sensor network. (b) Cells of sensor modules are highlighted. TABLE V PROCESS VARIATION PROFILE FOR MONTE CARLO SIMULATIONS synthesized gate-level netlist of the FGU. The different steps of our proposed sensor insertion methodology were completedby using Synopsys CAD tools [ 38], and custom scripts writ- ten in Perl, Shell, and Tcl. Finally, the full physical designof the FGU, with embedded sensor network, was completedwith IC compiler [ 38]. Fig. 7(a) shows layout of FGU with 25 embedded sensors. From Fig. 7(b), it can be observed that the sensor blocks are distributed across the layout as those wereplaced inside the different logical modules of the main netlistaccording to our proposed Ô¨Çow. The detailed transistor level circuit netlist of the 25 sensors along with their correspo"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_56", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 56, "text": "out as those wereplaced inside the different logical modules of the main netlistaccording to our proposed Ô¨Çow. The detailed transistor level circuit netlist of the 25 sensors along with their corresponding monitored paths were extractedfrom the layout using Synopsys tools [ 38]. Also, the transis- tor level netlist of the top 10% critical/near-critical paths‚Äî identiÔ¨Åed from post layout timing analysis‚Äîwere extractedforF maxidentiÔ¨Åcation. Any of these top 10% paths can be the most critical path, deciding the Fmax. While identifying the possible critical paths, both single cycle and multicycle pathswere considered. For multicycle paths, the slacks were normal-ized according to the cycle count. Because of post-fabrication process variations, it is expected that the delays of these iden- tiÔ¨Åed critical paths will vary from chip-to-chip. To simulatethe effect of post-fabrication process variations, we performeda 300 point Monte Carlo simulation on the extracted criticalpaths as well as the sensor-path pairs using HSPICE [ 38]. For Monte Carlo simulation two process variation scenarios wereconsidered as reported in Table V. For case 1, the selected parameters to vary from nominal were tr"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_57", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 57, "text": "sensor-path pairs using HSPICE [ 38]. For Monte Carlo simulation two process variation scenarios wereconsidered as reported in Table V. For case 1, the selected parameters to vary from nominal were transistor length ( L), width ( W), and threshold voltage ( V th) each by 10%, and oxide thickness ( tox) by 3%. For case 2, these parameters were var- i e db y1 5 %f o r L,W,Vth, and 4% for tox. All simulations were done within the statistical range of 3 standard deviations (3 œÉ). The simulation time was approximately 25 h on a system withan Intel Xeon processor with 8 cores and 96 GB RAM. The path slacks were extracted from the simulations of the sensor- path pairs by exciting them with appropriate stimulus functions Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 852 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 (a) (b) Fig. 8. Fmaxdistribution in Monte Carlo samples in (a) case 1 and (b) case 2. generated by Synopsys tools [ 38]. From detailed SPICE sim- ulations of all of the top 10% paths of the circuit, the longest path delay was"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_58", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 58, "text": "ibution in Monte Carlo samples in (a) case 1 and (b) case 2. generated by Synopsys tools [ 38]. From detailed SPICE sim- ulations of all of the top 10% paths of the circuit, the longest path delay was identiÔ¨Åed. After adding 10% margin with this delay as a guard-band against aging and noise, the minimumclock cycle and the F maxwas estimated for each sample. In order to quantize the continuous Fmaxvalues we chose 50 MHz as the grid size or bin width. The distribution of Fmaxin Monte Carlo samples for the two variation scenarios are shown inFig. 8. For comparatively lower process variation scenario of case 1 [Fig. 8(a)], the F maxdistribution spreads from 1100 to 1300 MHz with a std. deviation of 46 MHz. On the other hand,for comparatively higher process variation scenario of case 2[Fig. 8(b)], F maxdistribution ranges from 1100 to 1350 MHz with std. deviation of 62 MHz. Comparison of these two Ô¨Åg-ures reveal the degree of F maxspread with the magnitude of process variations. The 300 data samples obtained from Monte Carlo simu- lations were partitioned into a training set and a validationset. The validation data set contained 100 samples and threecases of training set‚Äîconsisting of 1"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_59", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 59, "text": "a samples obtained from Monte Carlo simu- lations were partitioned into a training set and a validationset. The validation data set contained 100 samples and threecases of training set‚Äîconsisting of 100, 150, and 200 samples,respectively‚Äîwere considered. Each of the 25 slacks obtainedby the sensors act as a feature in our machine learning-based speed binning Ô¨Çow. The machine learning capabilities of MATLAB [ 41] were used to implement and train the Ô¨Åve classiÔ¨Åers‚ÄîECOC SVM, logistic regression, bagging, randomforest, and AdaBoost.M2‚Äîdescribed in Section V.T h er e l - ative importance of the 25 features in training the randomforest predictor is shown in Fig. 9. After the classiÔ¨Åers were all trained with the training data set, the 100 sample validationdata set were applied to the trained classiÔ¨Åers and the corre- sponding predicted F maxwere obtained. These predicted Fmax values were later compared with actual Fmaxto identify the misbinning rate. In Fig. 10, prediction mismatch for each of the 100 validation samples are shown for the different machinelearning algorithms and variation proÔ¨Åles for 100 sample train-ing data set. Fig. 10(a)‚Äì(e) is for the variation proÔ¨Åle of case 1 and F"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_60", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 60, "text": "of the 100 validation samples are shown for the different machinelearning algorithms and variation proÔ¨Åles for 100 sample train-ing data set. Fig. 10(a)‚Äì(e) is for the variation proÔ¨Åle of case 1 and Fig. 10(f)‚Äì(j) is for variation proÔ¨Åle of case 2. It can be observed that for the comparatively lower process variation of case 1, 96%, 98%, 90%, 98%, and 84% prediction accu-racy are obtained for bagging, random forest, AdaBoost.M2,ECOC SVM, and logistic regression, respectively. On the otherhand, for case 2, the prediction accuracy deteriorated to 91%,93%, 89%, 94%, and 78%, respectively. In all cases exceptlogistic regression the worst-case misprediction is 50 MHz or one bin. The degraded prediction accuracy for case 2 can be explained with the F maxdistribution in the training data setFig. 9. Importance of each feature (sensor) in developing the random forest predictor. as shown in Fig. 8, where case 2 has 6 bins compared to 5 for case 1. The effect of number of training samples on prediction accu- racy is shown in Fig. 11. For the variation proÔ¨Åle of case 1, as we increased the training sample size, the prediction accuracyimproved signiÔ¨Åcantly reaching 99% for random forest, ECOCSV"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_61", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 61, "text": "iction accu- racy is shown in Fig. 11. For the variation proÔ¨Åle of case 1, as we increased the training sample size, the prediction accuracyimproved signiÔ¨Åcantly reaching 99% for random forest, ECOCSVM, and Bagging for training set sizes of 150 and beyond.For case 2 [Fig. 11(b)], 200 training samples were required to achieve 99% accuracy for random forest, ECOC SVM, and bagging. From a comparative analysis of the results from Ô¨Åvedifferent machine learning techniques in Figs. 10 and 11, it isobserved that random forest and ECOC multiclass SVM offerthe best prediction accuracy. On the other hand, linear logisticregression performed poorly; indicating a weak direct linearcorrelation between sensor responses and functional F max.T h e lower accuracy of AdaBoost.M2 can be explained by the fact that this algorithm emphasizes on the hard to predict sam-ples, and as a result might suffer from over-emphasizing if asmall number of samples are included in a particular class inthe training data set. This is indeed the case as is evident intheF maxdistribution plots in Fig. 8, where only 5% and 4% samples are in the 1100 and 1300 MHz bins, respectively, for case 1 [Fig. 8(a)]. For case 2 [Fig. "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_62", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 62, "text": "t. This is indeed the case as is evident intheF maxdistribution plots in Fig. 8, where only 5% and 4% samples are in the 1100 and 1300 MHz bins, respectively, for case 1 [Fig. 8(a)]. For case 2 [Fig. 8(b)], only 5% samples are in the 1350 MHz bin. The ranking of the observed accuracyof these 5 machine learning techniques in developing a F max predictor is consistent with the Ô¨Åndings of [ 33]. In the scenario that the chips are sold with the Fmaxlabels predicted by the trained classiÔ¨Åer, there is a chance that evenfor a classiÔ¨Åer that was trained with sufÔ¨Åcient number of training samples, 1% of the predicted chips might exhibit mispredicted F max. The worst-case misprediction is one bin faster or slower than the actual Fmax. For a faster chip binned in the slower bin, the customer will not complain. However,a slower chip shipped as a faster one may cause customerreturn. Depending on the tradeoff between beneÔ¨Åts gained‚Äîfrom test time reduction and tester cost savings from F max prediction‚Äîand the cost that will be incurred from dealing with the customer returns of the worst-case 1% shipped sam-ples, the chip vendor can decide if they will sell the chipswith the predicted F maxlabels "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_63", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 63, "text": "n‚Äîand the cost that will be incurred from dealing with the customer returns of the worst-case 1% shipped sam-ples, the chip vendor can decide if they will sell the chipswith the predicted F maxlabels or perform a second stage of expedited functional Fmaxtesting at the predicted Fmaxfre- quency to eliminate customer returns. If the chip passes thisfunctional test, the correct F maxwas predicted. If it fails, then the functional Fmaxtest is done again at the frequency of the immediate lower bin, where a match is expected. In this way Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. SADI et al. : SoC SPEED BINNING USING MACHINE LEARNING AND ON-CHIP SLACK SENSORS 853 (a) (f)(b) (g)(c) (h)(d) (i)(e) (j) Fig. 10. Prediction results for each of the 100 validation samples for 100 sample training data. Case 1‚Äî(a) bagging, (b) random forest, (c) AdaBoost.M 2, (d) ECOC SVM, and (e) logistic regression. Case 2‚Äî(f) bagging, (g) random forest, (h) AdaBoost.M2, (i) ECOC SVM, and (j) logistic regression. (a) (b) Fig. 11. Improvement of prediction accuracy with increasing number of training samples for va"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_64", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 64, "text": "Case 2‚Äî(f) bagging, (g) random forest, (h) AdaBoost.M2, (i) ECOC SVM, and (j) logistic regression. (a) (b) Fig. 11. Improvement of prediction accuracy with increasing number of training samples for variation proÔ¨Åle of (a) case 1 and (b) case 2. there are at most two functional tests that will give the correct Fmaxfor all chips shipped to the customer, as opposed to the test with frequency sweep performed over the possible Fmax labels in the conventional Ô¨Çow. VII. C ONCLUSION We have proposed an innovative speed-binning Ô¨Çow that utilizes machine learning and the path slacks extracted withon-chip sensors. A novel layout-aware and gate-netlist level sensor insertion algorithm places the sensors uniformly in the layout across the critical/near-critical capture Ô¨Çip-Ô¨Çops. Thesensor-extracted path slacks are used as features in modelingand training machine learning software running in the ATE.For a sufÔ¨Åcient number of training samples, the worst-casemismatch between predicted and actual F maxis one bin and occurs for 1% of the predicted samples. The proposed frame- work has the potential to eliminate the high cost associated with conventional functional test-based speed-binning Ô¨Çows.REFER"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_65", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 65, "text": "is one bin and occurs for 1% of the predicted samples. The proposed frame- work has the potential to eliminate the high cost associated with conventional functional test-based speed-binning Ô¨Çows.REFERENCES [1] S. S. Sapatnekar, ‚ÄúOvercoming variations in nanometer-scale technolo- gies,‚Äù IEEE J. Emerg. Sel. Topic Circuits Syst. , vol. 1, no. 1, pp. 5‚Äì18, Mar. 2011. [2] P. Das and S. K. Gupta, ‚ÄúExtending pre-silicon delay models for post- silicon tasks: Validation, diagnosis, delay testing, and speed binning,‚ÄùinProc. 31st IEEE VLSI Test Symp. (VTS) , Berkeley, CA, USA, 2013, pp. 1‚Äì6. [3] J. Zeng, R. Guo, W.-T. Cheng, M. A. Mateja, and J. Wang, ‚ÄúScan- based speed-path debug for a microprocessor,‚Äù IEEE Des. Test Comput. , vol. 29, no. 4, pp. 92‚Äì99, Aug. 2012. [4] E. J. Jang, A. Gattiker, S. Nassif, and J. A. Abraham, ‚ÄúEfÔ¨Åcient and product-representative timing model validation,‚Äù in Proc. 29th IEEE VLSI Test Symp. (VTS) , 2011, pp. 90‚Äì95. [5] J. Zeng, J. Wang, C.-Y . Chen, M. Mateja, and L.-C. Wang, ‚ÄúOn eval- uating speed path detection of structural tests,‚Äù in Proc. 11th Int. Symp. Qual. Electron. Design (ISQED) , San Jose, CA, USA, 2010, pp. 570‚Äì576. [6] C. K. H. Suresh, E. Yilmaz, S. "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_66", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 66, "text": "C. Wang, ‚ÄúOn eval- uating speed path detection of structural tests,‚Äù in Proc. 11th Int. Symp. Qual. Electron. Design (ISQED) , San Jose, CA, USA, 2010, pp. 570‚Äì576. [6] C. K. H. Suresh, E. Yilmaz, S. Ozev, and O. Sinanoglu, ‚ÄúAdaptive reduc- tion of the frequency search space for multi-vdd digital circuits,‚Äù in Proc. Design Autom. Test Europe Conf. Exhibit. (DATE) , 2013, pp. 292‚Äì295. [7] E. Dimaandal and M. Padilla, ‚ÄúTest-time reduction methodology: Innovative ways to reduce test time for server products,‚Äù in Proc. 15th IEEE Electron. Packag. Technol. Conf. , Singapore, 2013, pp. 718‚Äì722. [8] B. D. Cory, R. Kapur, and B. Underwood, ‚ÄúSpeed binning with path delay test in 150-nm technology,‚Äù IEEE Des. Test Comput. , vol. 20, no. 5, pp. 41‚Äì45, Sep./Oct. 2003. [9] K. A. Brand, S. Mitra, E. V olkerink, and E. J. McCluskey, ‚ÄúSpeed clustering of integrated circuits,‚Äù in Proc. Int. Test Conf. (ITC) , 2004, pp. 1128‚Äì1137. [10] J. Chen, J. Zeng, L.-C. Wang, J. Rearick, and M. Mateja, ‚ÄúSelecting the most relevant structural Fmax for system Fmax correlation,‚Äù inProc. 28th IEEE VLSI Test Symp. (VTS) , Santa Cruz, CA, USA, 2010, pp. 99‚Äì104. [11] J. Chen et al. , ‚ÄúData learning techniques and met"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_67", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 67, "text": "the most relevant structural Fmax for system Fmax correlation,‚Äù inProc. 28th IEEE VLSI Test Symp. (VTS) , Santa Cruz, CA, USA, 2010, pp. 99‚Äì104. [11] J. Chen et al. , ‚ÄúData learning techniques and methodology for Fmax prediction,‚Äù in Proc. Int. Test Conf. (ITC) , Austin, TX, USA, 2009, pp. 1‚Äì10. [12] J. Rearick, ‚ÄúToo much delay fault coverage is a bad thing,‚Äù in Proc. Int. Test Conf. (ITC) , Baltimore, MD, USA, 2001, pp. 624‚Äì633. [13] M. Bushnell and V . Agrawal, Essentials of Electronic Testing for Digital, Memory and Mixed-Signal VLSI Circuits . New York, NY , USA: Springer, 2006. [14] H.-J. Hsu, C.-C. Tu, and S.-Y . Huang, ‚ÄúBuilt-in speed grading with a process-tolerant ADPLL,‚Äù in Proc. 16th Asian Test Symp. (ATS) , Beijing, China, 2007, pp. 384‚Äì392. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply. 854 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 36, NO. 5, MAY 2017 [15] C.-I. Chung, J.-S. Jhou, C.-H. Cheng, and S.-Y . Li, ‚ÄúFunctional built- in delay binning and calibration mechanism for on-chip at-speed selftest,‚Äù in Proc. 18th Asian Test Symp. ("}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_68", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 68, "text": "NO. 5, MAY 2017 [15] C.-I. Chung, J.-S. Jhou, C.-H. Cheng, and S.-Y . Li, ‚ÄúFunctional built- in delay binning and calibration mechanism for on-chip at-speed selftest,‚Äù in Proc. 18th Asian Test Symp. (ATS) , Taichung, Taiwan, 2009, pp. 163‚Äì168. [16] A. Raychowdhury, S. Ghosh, and K. Roy, ‚ÄúA novel on-chip delay mea- surement hardware for efÔ¨Åcient speed-binning,‚Äù in Proc. On-Line Testing Symp. (IOLTS) , 2005, pp. 287‚Äì292. [17] X. Wang, M. Tehranipoor, S. George, D. Tran, and L. Winemberg, ‚ÄúDesign and analysis of a delay sensor applicable to pro- cess/environmental variations and aging measurements,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 20, no. 8, pp. 1405‚Äì1418, Aug. 2012. [18] Q. Shi, M. Tehranipoor, X. Wang, and L. Winemberg, ‚ÄúOn-chip sen- sor selection for effective speed-binning,‚Äù in Proc. 57th IEEE Int. Midwest Symp. Circuits Syst. , College Station, TX, USA, Aug. 2014, pp. 1073‚Äì1076. [19] S.-P. Mu, M. C.-T. Chao, S.-H. Chen, and Y .-M. Wang, ‚ÄúStatistical framework and built-in self-speed-binning system for speed bin-ning using on-chip ring oscillators,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 24, no. 5, pp. 1675‚Äì1687, May 2016. [20] M. Sadi, M"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_69", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 69, "text": " and built-in self-speed-binning system for speed bin-ning using on-chip ring oscillators,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 24, no. 5, pp. 1675‚Äì1687, May 2016. [20] M. Sadi, M. Tehranipoor, X. Wang, and L. Winemberg, ‚ÄúSpeed bin- ning using machine learning and on-chip slack sensors,‚Äù in Proc. 25th Ed. ACM Great Lakes Symp. VLSI (GLSVLSI) , Pittsburgh, PA, USA, May 2015, pp. 155‚Äì160. [21] T.-B. Chan, P. Gupta, A. B. Kahng, and L. Lai, ‚ÄúSynthesis and analy- sis of design-dependent ring oscillator (DDRO) performance monitors,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 22, no. 10, pp. 2117‚Äì2130, Oct. 2014. [22] L. Lai, V . Chandra, R. C. Aitken, and P. Gupta, ‚ÄúSlackProbe: A Ô¨Çexi- ble and efÔ¨Åcient in situ timing slack monitoring methodology,‚Äù IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. , vol. 33, no. 8, pp. 1168‚Äì1179, Aug. 2014. [23] R. Ginosar, ‚ÄúMetastability and synchronizers: A tutorial,‚Äù IEEE Des. Test Comput. , vol. 28, no. 5, pp. 23‚Äì35, Sep./Oct. 2011. [24] M. Sadi et al. , ‚ÄúBIST-RM: BIST-assisted reliability management of SoCs using on-chip clock sweeping and machine learning,‚Äù in Proc. IEEE Int. Test Conf. (ITC) , 2016, pp. 1‚Äì1"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_70", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 70, "text": "35, Sep./Oct. 2011. [24] M. Sadi et al. , ‚ÄúBIST-RM: BIST-assisted reliability management of SoCs using on-chip clock sweeping and machine learning,‚Äù in Proc. IEEE Int. Test Conf. (ITC) , 2016, pp. 1‚Äì10. [25] I. Guyon and A. Elisseeff, ‚ÄúAn introduction to variable and feature selection,‚Äù J. Mach. Learn. Res. , vol. 3, pp. 1157‚Äì1182, 2003. [26] (May 2016). [Online]. Available: http://uÔ¨Çdl.stanford.edu/tutorial/ supervised/SoftmaxRegression/ [27] C. Hsu, C. Chang, and C. Lin, ‚ÄúA practical guide to support vector clas- siÔ¨Åcation,‚Äù Ph.D. dissertation, Dept. Comput. Sci., Nat. Taiwan Univ.,Taipei, Taiwan, 2003. [28] T. G. Dietterich and G. Bakiri, ‚ÄúSolving multiclass learning problems via error-correcting output codes,‚Äù J. Artif. Intell. Res. , vol. 2, no. 1, pp. 263‚Äì286, 1995. [29] E. L. Allwein, R. E. Schapire, and Y . Singer, ‚ÄúReducing multiclass to binary: A unifying approach for margin classiÔ¨Åers,‚Äù J. Mach. Learn. Res., vol. 1, pp. 113‚Äì141, Dec. 2001. [30] L. Breiman, ‚ÄúBagging predictors,‚Äù Mach. Learn. , vol. 24, no. 2, pp. 123‚Äì140, 1996. [31] L. Breiman, ‚ÄúRandom forests,‚Äù Mach. Learn. , vol. 45, no. 1, pp. 5‚Äì32, 2001. [32] Y . Freund and R. E. Schapire, ‚ÄúExperiments with a new boos"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_71", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 71, "text": "s,‚Äù Mach. Learn. , vol. 24, no. 2, pp. 123‚Äì140, 1996. [31] L. Breiman, ‚ÄúRandom forests,‚Äù Mach. Learn. , vol. 45, no. 1, pp. 5‚Äì32, 2001. [32] Y . Freund and R. E. Schapire, ‚ÄúExperiments with a new boosting algorithm,‚Äù in Proc. 13th Int. Conf. Mach. Learn. , Bari, Italy, 1996, pp. 148‚Äì156. [33] M. Fern√°ndez-Delgado, E. Cernadas, S. Barro, and D. Amorim, ‚ÄúDo we need hundreds of classiÔ¨Åers to solve real world classiÔ¨Åcation problems?‚ÄùJ. Mach. Learn. Res. , vol. 15, no. 1, pp. 3133‚Äì3181, 2014. [34] M. Tehranipoor and C. Wang, Introduction to Hardware Security and Trust . New York, NY , USA: Springer, 2011. [35] L. H. Goldstein and E. L. Thigpen, ‚ÄúSCOAP: Sandia controllabil- ity/observability analysis program,‚Äù in Proc. 17th Conf. Design Autom. , 1980, pp. 190‚Äì196. [36] S. Paek et al. , ‚ÄúHybrid temperature sensor network for area-efÔ¨Åcient on- chip thermal map sensing,‚Äù IEEE J. Solid-State Circuits , vol. 50, no. 2, pp. 610‚Äì618, Feb. 2015. [37] M. Sadi and M. Tehranipoor, ‚ÄúDesign of a network of digital sensor macros for extracting power supply noise proÔ¨Åle in SoCs,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 24, no. 5, pp. 1702‚Äì1714, May 2016. [38] (Nov. 2015). [Online]. Ava"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_72", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 72, "text": "of digital sensor macros for extracting power supply noise proÔ¨Åle in SoCs,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 24, no. 5, pp. 1702‚Äì1714, May 2016. [38] (Nov. 2015). [Online]. Available: http://www .synopsys .com/ [39] (Nov. 2015). [Online]. Available: http://ptm .asu.edu/ [40] (Nov. 2014). [Online]. Available: http://www .oracle.com/ [41] (Dec. 2015). http://www .mathworks .com/products/matlab/ Mehdi Sadi (S‚Äô12) received the B.S. degree in elec- trical engineering from the Bangladesh University ofEngineering and Technology, Dhaka, Bangladesh, in2009, and the M.S. degree in electrical engineer- ing from the University of California at Riverside, Riverside, CA, USA, in 2011. He is currently pur-suing the Ph.D. degree with the Electrical andComputer Engineering Department, University of Florida, Gainesville, FL, USA. His Ph.D. studies are funded by Semiconductor Research Corporation and NSF. He was a Research Intern with GLOBALFOUNDRIES, Malta, NY , USA and NXP, Austin, TX, USA. His current research interests include digital very large scale integrationdesign, design for test, computer architecture, and circuit design. Sukeshwar Kannan received the B.E. degree in"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_73", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 73, "text": "in, TX, USA. His current research interests include digital very large scale integrationdesign, design for test, computer architecture, and circuit design. Sukeshwar Kannan received the B.E. degree in electrical and electronics engineering fromVisvesvaraya Technological University, Belgaum, India, in 2007, and the M.S. and Ph.D. degrees in electrical engineering from the University ofAlabama, Tuscaloosa, AL, USA, in 2010 and 2013,respectively. He is a Principal Engineer with the Technology and Integration for the Advanced Silicon PackagingDevelopment Group, GLOBALFOUNDRIES U.S. Inc., Malta, NY , USA. His current research interests include 3-D IC characterization, reliability, design-for-test, manufacturingdevelopment, analog mixed-signal, high-voltage, and RF semiconductor test. LeRoy Winemberg received the B.S.E.E. degree from the University of Notre Dame, Notre Dame,IN, USA, and the M.S.E.E. degree with the University of California at Berkeley, Berkeley, CA, USA. He is the DFT Manager with NXP‚Äôs Automotive Microcontroller and Processor, BU‚Äôs Austin Research and Development Group focusing onzero defect test and methodology. He was theDFT Manager for both Freescale‚Äôs Automotive Mic"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_74", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 74, "text": "r with NXP‚Äôs Automotive Microcontroller and Processor, BU‚Äôs Austin Research and Development Group focusing onzero defect test and methodology. He was theDFT Manager for both Freescale‚Äôs Automotive Microcontroller Products Group and TI‚Äôs ASIC Division. He has also held various positions with Agilent, Santa Clara, CA,USA, HP, Palo Alto, CA, USA, Actel, Aliso Viejo, CA, USA, and LSILogic, San Jose, CA, USA. Mark Tehranipoor (S‚Äô02‚ÄìM‚Äô04‚ÄìSM‚Äô07) received the Ph.D. degree from the University of Texas at Dallas, Richardson, TX, USA, in 2004. He is currently the Intel Charles E. Young Professor with Cybersecurity, University of Florida, Gainesville, FL, USA. He has published over 300 journal articles and refereed conference papers andhas given over 150 invited talks and keynoteaddresses. He has published six books and eleven book chapters. His current research interests include hardware security and trust, supply chain security, and very large scale integration (VLSI) design, test, and reliability. Dr. Tehranipoor was a recipient of several best paper awards as well as the 2008 IEEE Computer Society (CS) Meritorious Service Award, the 2012 IEEE CS Outstanding Contribution, the 2009 NSF CAREE"}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_75", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 75, "text": "ty. Dr. Tehranipoor was a recipient of several best paper awards as well as the 2008 IEEE Computer Society (CS) Meritorious Service Award, the 2012 IEEE CS Outstanding Contribution, the 2009 NSF CAREER Award, and the2014 MURI Award. He serves on the program committee of over a dozen ofleading conferences and workshops. He served as the Program Chair of the 2007 IEEE Defect-Based Testing Workshop, the Program Chair of the 2008 IEEE Defect and Data Driven Testing (D3T) Workshop, the Co-Program Chairof the 2008 International Symposium on Defect and Fault Tolerance in VLSI Systems (DFTS), the General Chair for D3T-2009 and DFTS-2009, and the Vice-General Chair for NATW-2011. He co-founded the IEEE InternationalSymposium on Hardware-Oriented Security and Trust (HOST) and served asthe HOST-2008 and HOST-2009 General Chair. He is currently serving as an Associate Editor for JETTA, JOLPE, the IEEE T RANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) S YSTEMS , and ACM TODAES. He served as the Founding Director for CHASE and CSI Centers, University ofConnecticut. He is a Golden Core Member of IEEE, and a member of ACM and ACM SIGDA. Authorized licensed use limited to: Hochschule Heilbronn. "}
{"id": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf::chunk_76", "source": "SoC_Speed_Binning_Using_Machine_Learning_and_On-Chip_Slack_Sensors.pdf", "chunk_index": 76, "text": "Founding Director for CHASE and CSI Centers, University ofConnecticut. He is a Golden Core Member of IEEE, and a member of ACM and ACM SIGDA. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:30:09 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_0", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 0, "text": "Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 https://doi.org/10.1007/s10845-024-02377-4 Sparse deep encoded features with enhanced sinogramic red deer optimization for fault inspection in wafer maps Doaa A. Altantawy1¬∑Mohamed A. Yakout1 Received: 21 September 2023 / Accepted: 17 March 2024 / Published online: 20 May 2024 ¬© The Author(s) 2024 Abstract Due to the complexity and dynamics of the semiconductor manufacturing processes, wafer bin maps (WBM) present variousdefect patterns caused by various process faults. The defect type detection on wafer maps provides information about the process and equipment in which the defect occurred. Recently, automatic inspection has played a vital role in meeting the high-throughput demand, especially with deep convolutional neural networks (DCNN) which shows promising efÔ¨Åciency. Atthe same time, the need for a large amount of labeled and balanced datasets limits the performance of such approaches. Inaddition, complex DCNN in recognition tasks can provide redundant features that cause overÔ¨Åtting and reduce interpretability. In this paper, a new hybrid deep model for wafer map fault detection to get over these challenges is proposed. "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_1", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 1, "text": " tasks can provide redundant features that cause overÔ¨Åtting and reduce interpretability. In this paper, a new hybrid deep model for wafer map fault detection to get over these challenges is proposed. Firstly, a new convolutional autoencoder (CAE) is employed as a synthetization model to Ô¨Åx the high imbalance problem of the dataset.Secondly, for efÔ¨Åcient dimensionality reduction, an embedding procedure is applied to the synthesized maps to get sparse encoded wafer maps by reinforcing a sparsity regularization in an encoder-decoder network to form a sparsity-boosted autoencoder (SBAE). The sparse embedding of wafer maps guarantees more discriminative features with 50% reduction inspatial size compared to the original wafer maps. Then, the 2D encoded sparse maps are converted to 1D sinograms to be fed later into another aggressive feature reduction stage using a new modiÔ¨Åed red deer algorithm with a new tinkering strategy. The resultant feature pool is reduced to ~ 25 1D feature bases, i.e., ~ 1.5% of the initial size of the 2D wafer maps. Finally, forthe prediction stage, a simple 1DCNN model is introduced. The proposed inspection model is tested via different experimentson real-worl"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_2", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 2, "text": "e., ~ 1.5% of the initial size of the 2D wafer maps. Finally, forthe prediction stage, a simple 1DCNN model is introduced. The proposed inspection model is tested via different experimentson real-world wafer map dataset (WM-811K). Compared to state-of-the-art techniques, the proposed model outperforms their performance even with small-sized 1D feature pool. The average testing accuracy are 98.77% and 98.8% for 9 and 8 types of faults, respectively. Keywords Wafer maps ¬∑WM-811K ¬∑Autoencoders ¬∑Sparse encoding ¬∑1DCNN ¬∑Red deer optimization Introduction In semiconductor manufacturing, wafer is an important fun- damental component in integrated circuits (IC). A singlewafer can involve several hundred integrated circuits (ICs) after hundreds of sophisticated processes (Alam & Kehtar- navaz, 2022 ). Any abnormality in these production processes B Doaa A. Altantawy doaa1adel@mans.edu.eg Mohamed A. Yakout myakout@mans.edu.eg 1Electronics and Communications Engineering Department,Faculty of Engineering, Mansoura University, 60El-Gomhoria Street, Mansoura, Egyptmay lead to the generation of defects in the wafer map. Hence, due to the complexity of these processes, it is impossible to produce "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_3", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 3, "text": "neering, Mansoura University, 60El-Gomhoria Street, Mansoura, Egyptmay lead to the generation of defects in the wafer map. Hence, due to the complexity of these processes, it is impossible to produce wafers without any defects (Jin et al., 2019 ;L i u& Chien, 2013 ). After completing the wafer fabrication processes, every wafer undergoes a testing procedure including a series of multiple electrical tests to determine whether each individ-ual chip (or die) meets its product speciÔ¨Åcations. SpeciÔ¨Åcally,a probe test bench is utilized to detect the electrical character- istics of the chip dies (Cheng et al., 2021 ). Then, according to the quality level, the chip dies are marked in different col-ors on the wafer map. Typically, the captured defect patterns are divided into two types: global random defects and local systematic defects. In the global ones, defects are distributedrandomly across the wafer without any spatial arrangement, 123 3360 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 even in normal production conditions. In contrast, in the local ones, spatial correlations are observed in speciÔ¨Åc regions of awafer, resulting in patterns such as center circles, edge rings,"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_4", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 4, "text": "359‚Äì3397 even in normal production conditions. In contrast, in the local ones, spatial correlations are observed in speciÔ¨Åc regions of awafer, resulting in patterns such as center circles, edge rings, local zones, and scratches (Wu et al., 2014 ). Integrated circuits manufacturing requires high invest- ment, precise technology, and a complex manufacturingprocess. Thus, an analysis of the wafer map is essential to improve the yield, quality, and reliability of the IC manufac- turing process. Even so, manually annotating wafer mapswith their defect types is time-consuming and expensive, especially with large production lines (Shankar & Zhong, 2005 ). Moreover, engineers judge the defect types of wafer map based on their professional knowledge and work long hours which can be exposed to visual fatigue and raises the risk of erroneous classiÔ¨Åcation. Hence, automatic inspectionof the wafer map defect is a necessary step which can reducethe time and cost. With the advancements of machine learning and deep learning algorithms, building an effective automatic faultdetection model has become a hot topic in the research com- munity (Kim & Behdinan, 2023 ; Theodosiou et al., 2023 ). These waf"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_5", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 5, "text": "rning and deep learning algorithms, building an effective automatic faultdetection model has become a hot topic in the research com- munity (Kim & Behdinan, 2023 ; Theodosiou et al., 2023 ). These wafer fault detection models can be categorized intosegmentation models (Cheng et al., 2021 ; Chu et al., 2022 ; Jin et al., 2019 ; Kim & Kang, 2021 ; Lee et al., 2010 ;N a g et al., 2022 ; Yan et al., 2023 ) and classiÔ¨Åcation models (Baly & Hajj, 2012 ; Kyeong & Kim, 2018 ; Saqlain et al., 2019 ; Y u et al., 2019 ; Jin et al., 2020 ; Chen et al., 2021 , Chen et al., 2022 ; Kang & Kang, 2021 ; Kim et al., 2021 ; Wang et al., 2021 , Wang et al., 2022 ; Y u et al., 2021a ,b, c; Zheng et al., 2021 ; Shin et al., 2022 ; Xuen et al., 2022 ; Y oon & Kang, 2022 ; Y u et al., 2022 ; Zhang et al., 2022 ; Alqudah et al., 2023 ). The classical supervised recogniz- ers have achieved some good results in wafer map defect recognition (Alqudah et al., 2023 ; Baly & Hajj, 2012 ; Cheng et al., 2021 ; Saqlain et al., 2019 ). Nevertheless, their perfor- mances relied on the effectiveness of the feature extractionstep. In addition, the spatial resolution and noise of the wafer maps signiÔ¨Åcantly affect the pe"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_6", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 6, "text": "et al., 2019 ). Nevertheless, their perfor- mances relied on the effectiveness of the feature extractionstep. In addition, the spatial resolution and noise of the wafer maps signiÔ¨Åcantly affect the performance of such tech- niques. Accordingly in recent times, deep feature learningand extraction has been widely applied in the Ô¨Åeld of wafer defect recognition (Kyeong & Kim, 2018 ; Y u et al., 2019 , 2022 ; Jin et al., 2020 ; Chen et al., 2021 , Chen et al., 2022 ;; Kang & Kang, 2021 ; Kim et al., 2021 ; Wang et al., 2021 , Wang et al., 2022 ;Y ue ta l . , 2021a ,b,c; Zheng et al., 2021 ; Shin et al., 2022 ; Xuen et al., 2022 ; Y oon & Kang, 2022 ; Zhang et al., 2022 ; Xu et al., 2023 ). However, employing the traditional 2D convolutional neural network (CNN) in the direct classiÔ¨Åcation of defects can easily lead to instabil- ity in the classiÔ¨Åcation results (Xu et al., 2023 ), especially with very small image resolution, like the employed WM- 811K wafer map dataset. This instability occurs because of the lack of spatial information to learn features and makeproper predictions. In addition, 2DCNNs generally releaseshigh dimensional features that may contain many redundant information"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_7", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 7, "text": "urs because of the lack of spatial information to learn features and makeproper predictions. In addition, 2DCNNs generally releaseshigh dimensional features that may contain many redundant information, which brings some challenges at the Ô¨Ånal classi-Ô¨Åcation stage, like increasing the computational complexity, reducing memory efÔ¨Åciency, and increasing the chance of overÔ¨Åtting (Y u et al., 2019 ; Jin et al., 2020 ; Chen et al., 2021 , Chen et al., 2022 ; Kang & Kang, 2021 ; Wang et al., 2021 , Wang et al., 2022 ;Y ue ta l . , 2021a ,b; Zheng et al., 2021 ; Xuen et al., 2022 ; Y oon & Kang, 2022 ; Y u et al., 2022 ; Zhang et al., 2022 ). Many studies have tried different feature engineering steps with deep models to get over these challenges in (Jin et al., 2020 ; Y u et al., 2021b ; Zheng et al., 2021 ). Table 1 summarizes the most recent studies that employ deep mod-els, indicating the main procedure, strengths, and issues in each one. Accordingly, the main target in this work is how to build a deep recognition system that can provide precise salientfeatures, despite the very low-resolution of wafer maps, with the highest recognition performance. In addition, this recog- nition syst"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_8", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 8, "text": " build a deep recognition system that can provide precise salientfeatures, despite the very low-resolution of wafer maps, with the highest recognition performance. In addition, this recog- nition system can avoid redundant information that leads toinstability and bad interpretability. Thus, we go for convert- ing the 2D wafer map fault detection problem to 1D detection one to get the most salient features with the least dimension- ality. Therefore, the redundancy and the high dimensionality of features can be reduced. Nonetheless, new challenges are raised, such as how to assign suitable embedding that keptthe 2D spatial information in 1D representation, proper 1Dfeature ranking, and suitable 1DCNN classiÔ¨Åer. Accordingly, the main contributions of the proposed wafer map defect clas- siÔ¨Åcation model can be summarized as follows. (1) We have exploited the importance of encoder-decoder networks, i.e., autoencoders (AE), in two ways. First,AE is employed as a new convolutional synthetization model to get over the high imbalance problem in the employed wafer map dataset. This model proves efÔ¨Å-ciency by reconstructing the original wafer maps with a total loss of 0.0011. Second, AE is int"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_9", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 9, "text": "on model to get over the high imbalance problem in the employed wafer map dataset. This model proves efÔ¨Å-ciency by reconstructing the original wafer maps with a total loss of 0.0011. Second, AE is introduced in a new structure as an embedding representation step withdimensionality reduction behavior, named as sparsity- boosted autoencoder (SBAE). The resultant encoded sparse maps from SBAE guarantee more discrimina-tive features with a 50% reduction in size compared tothe original wafer maps. Despite this reduction in size, inspection accuracy of 99.48% can be obtained while working with initial wafer map resolution of 27 √ó25. (2) An enhanced red deer optimization (ERD) with a new tinkering strategy is proposed. ERD is applied to 1D squeezed sinograms of the previous sparse maps. TheERD algorithm results in a Ô¨Ånal average feature pool of ~ 15 bases, i.e., ~ 1.5% of the initial wafer map size which has resolution of 33 √ó29. The performance of ERD is compared, in an ablation behavior, to other different 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3361 Table 1 Summary of the state-of-the-art techniques in wafer map fault detection following hybrid methods in inspectio"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_10", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 10, "text": " other different 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3361 Table 1 Summary of the state-of-the-art techniques in wafer map fault detection following hybrid methods in inspection Method Main procedure Strengths Issues Jin et al. ( 2020 ) They utilized convolutional neural network to extract high-levelfeatures and then features were fedto combination of error-correctingoutput codes (ECOC)and supportvector machines (SVM)They employed different traditional classiÔ¨Åers with CNN and ECOC inablation study. They achieved overallclassiÔ¨Åcation accuracy of up to98.43% via 10-fold cross validationThe computation effort is large to extract high-level features fromCNN, besides adjusting thehyperparameters of CNN andECOC is difÔ¨Åcult Y u et al. ( 2021b ) They extracted high-dimensional features using a pretrainedDenseNet, and for the classiÔ¨Åcationstage, they have assigned deep forestThey got over the redundancy and the high dimensionality of the extractedfeatures through employingMulti-grained cascade forest(GCForest). They achieved achievesa correct recognition rate of 96.2%on the testing datasetGCForest is a computationally expensive algorithm to train anduse. It is highly"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_11", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 11, "text": "ngMulti-grained cascade forest(GCForest). They achieved achievesa correct recognition rate of 96.2%on the testing datasetGCForest is a computationally expensive algorithm to train anduse. It is highly dependent on thequality of the training data. If thetraining data is noisy orincomplete, GCForest may notperform well Zheng et al. ( 2021 ) They developed their own deep convolutional modelIt is a simple deep learning model. They compared their model to othermachine learning models. Theygained a maximum accuracy of 93.75%Building a CNN from scratch requires a signiÔ¨Åcant amount oftime and effort. There are manyparameters and hyperparameters that need to be tuned carefully to achieve optimal performance Chen et al. (2020) They extracted multi-source features from two different dual-channeldeep networks (DCNN). Thesefeatures were fed into ECOC‚ÄìSVMclassiÔ¨Åcation modelApplying two parallel channels, DCNNs can simultaneously extractboth local and global features fromthe input data, which enhances thequality of features, and theirrobustness to noise. ECOC‚ÄìSVM isa multi-class classiÔ¨Åcation algorithmthat combines the strengths ofsupport vector machines (SVMs)and error-correcting output codes(EC"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_12", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 12, "text": "s thequality of features, and theirrobustness to noise. ECOC‚ÄìSVM isa multi-class classiÔ¨Åcation algorithmthat combines the strengths ofsupport vector machines (SVMs)and error-correcting output codes(ECOC). They declared accuracy of96.4%DCNNs are complex with a large number of parameters.ECOC‚ÄìSVM can be morecomputationally complex thanother multi-class classiÔ¨Åcationalgorithms, especially for largedatasets with many classes. It isalso sensitive to imbalanceddatasets Kang and Kang (2021 )They used CNN with ML models to extract handcrafted andconvolutional features. Thesefeatures are fed into multi-responselinear regression (MLR) asmeta-classiÔ¨Åer for the Ô¨Ånalprediction stageThey can extract salient features through their stacking ensembleThey extracted manually handcrafted features to feed boththe CNN and ML modelsMLR assumes that therelationship between thepredictors and the outcomes islinearOutliers can distort the results ofMLR, leading to inaccuratepredictions Chen et al. ( 2022 ) They built a dual-source DCNN structure which is fed with theoriginal wafer maps and thepreprocessed ones. Then, aninformation entropy fusion wasperformed to the resultantdual-source probability to get the"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_13", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 13, "text": "built a dual-source DCNN structure which is fed with theoriginal wafer maps and thepreprocessed ones. Then, aninformation entropy fusion wasperformed to the resultantdual-source probability to get theÔ¨Ånal predictionThe fusion procedure using information entropy from twosources help to extract more salientfeatures. They declared accuracy of98.34%Having two networks means higher computational cost because of thenumber of trainable parameters Y u et al. ( 2019 ) They developed stacked convolutional sparse denoising auto-encoder (SCSDAE) to generate effectivesalient features from wafer maps.These features were fed into SVMclassiÔ¨Åer to predict the defect labelThey produced salient features with high robustness to noise. They declared a maximum accuracy of95.13%Training SVMs can be computationally expensive, especially with large datasetswith many features. The choiceof kernel function signiÔ¨Åcantlyimpacts the performance of theSVM. Selecting the appropriatekernel function can bechallenging and requiresexperimentation 123 3362 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Table 1 (continued) Method Main procedure Strengths Issues Wang et al. ( 2021 ) They used a variational aut"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_14", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 14, "text": "nd requiresexperimentation 123 3362 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Table 1 (continued) Method Main procedure Strengths Issues Wang et al. ( 2021 ) They used a variational autoencoder (V AE) and decoders to generatesimilar wafer defect maps and areÔ¨Åned deep convolutional neuralnetwork (CNN) for feature learningThe V AE guarantees effective embedding of features to be fed laterinto a deep CNN model. Theydeclared accuracy of 99.16% for thesynthesized data versus 96.20% forthe original oneV AEs often require a high-dimensional latent space tocapture the complexity of thedata. Training V AEs can becomputationally expensive,especially for large datasets withhigh-dimensional latent spaces.This is because V AEs requireoptimizing both the encoder anddecoder networks, as well as thevariational loss function Wang et al. ( 2022 ) They assigned a convolutional autoencoder for balancing data,then, for the classiÔ¨Åcation stage theyemployed a deep CNN network withresidual blockEmploying residual block helps to increase the model depth, henceeffective feature representations canbe obtained. They achieved anaccuracy of 99.9%Residual blocks increase the model size by adding m"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_15", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 15, "text": "kEmploying residual block helps to increase the model depth, henceeffective feature representations canbe obtained. They achieved anaccuracy of 99.9%Residual blocks increase the model size by adding more additionalparameters compared totraditional convolutional blocks.In addition, residual blocks canmake networks more prone tooverÔ¨Åtting Y u et al. ( 2021a ) They developed a deep transfer Wasserstein adversarial network(DTW AN) with multi-stageoptimizationThey have shown superiority to typical transfer learning algorithms in waferinspection through employinggenerative adversarial algorithm toguide the model to extract generalfeatures from source and targetdomain. They declared recognitionrate from 0.7 to 0.98Training W ANs is more computationally expensive thantraditional networks. They arevery sensitive to noise and thechoice of hyperparameters Zhang et al. ( 2022 ) They utilized a binarized neural network (BNN) to reduce runtimeand memory consumption whileachieving high accuracy in therecognition of wafer defectCompared to the CNN model with the same architecture, Their BNN modelachieved 1.66 √óspeedup and 29.70 √ómemory reduction. They declared accuracy of 94.63%Replacing real-valu"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_16", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 16, "text": "erecognition of wafer defectCompared to the CNN model with the same architecture, Their BNN modelachieved 1.66 √óspeedup and 29.70 √ómemory reduction. They declared accuracy of 94.63%Replacing real-valued weights and activations with binary values inBNN inevitably leads to a loss ofprecision, which can negativelyimpact the accuracy of the network Y oon and Kang (2022 )They developed a semi-automatic procedure for the defect recognitionby using uncertainty quantiÔ¨Åcation.Hence, it was decided whether touse manual recognition orCNN-based recognition for theinserted wafer mapIt is the Ô¨Årst work to adopt an uncertainty-based reject option toselectively utilize CNN. Instead ofusing CNN only, the proposedmethod obtained assistance from aprocess engineer to fulÔ¨Åll thenear-perfect accuracy requirement.They declared accuracy of 96.73%with 100% coverage of CNNUncertainty quantiÔ¨Åcation can introduce additionalcomputational overheadcompared to traditional CNNs. Inaddition, it may lead to a slightdecrease in prediction accuracycompared to unquantiÔ¨Åed CNNs metaheuristic algorithms, such as Genetic (GA), Equi- librium (EO), Grey Wolf (GWO), Sine cosine (SCA), and particle swarm algorithms (PSO). The"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_17", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 17, "text": "ease in prediction accuracycompared to unquantiÔ¨Åed CNNs metaheuristic algorithms, such as Genetic (GA), Equi- librium (EO), Grey Wolf (GWO), Sine cosine (SCA), and particle swarm algorithms (PSO). The proposed ERD achieves the least feature pool size with approx-imately the same accuracy as its alternatives, because of the proposed tinkering strategy that makes the ERD algorithm reaches the global optimum solution with theleast number of discriminative features to avoid any pos- sible redundant information. (3) Intensive experiments, with a new predictive 1DCNN model, are performed on different resolutions of wafermaps in 8- and 9-fault type prediction. An averageaccuracy of 95.2% is achieved for unseen 62% test- ing part of the dataset, while an average accuracy of 98.1% is achieved for unseen 20% testing part of the dataset of in a train‚Äìtest‚Äìvalidation evaluation. Despitethe aggressive dimensionality reduction, the proposed inspection model proves efÔ¨Åcient generalization. In addition, the proposed 1DCNN network proves a greatbalance between the number of parameters and the tar- geted accuracy in fault detection compared to other common 1DCNNs, such as 1D-VGG16, 1D-ResNet50,1D-Le"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_18", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 18, "text": "n, the proposed 1DCNN network proves a greatbalance between the number of parameters and the tar- geted accuracy in fault detection compared to other common 1DCNNs, such as 1D-VGG16, 1D-ResNet50,1D-LeNet-5, and 1D-Inception. 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3363 Fig. 1 Labeling and categories distribution of WM-811K dataset The rest of the paper is organized as follows. Details about the targeted wafer map dataset are demonstrated in \" Wafer map dataset \" section. \" Methodology \" section describes the details of the proposed methodology of wafer map fault detection. \" Experimental results and discussion \" section indicated the performed experiments with its results. Finally,the conclusion is offered in \" Conclusion \" section. Wafer map dataset The WM-811K (Wu et al., 2014 ) is the employed wafer map dataset and it is publicly available at Kaggle website(WM-811K, 2014 ) It contains 811,457 instances collected from 46,293 lots during the semiconductor fabrication pro- cess (Wu et al., 2014 ). Only a subset of 21.3% (172,950) is labeled by professionals with one of the following nine cate- gories: Center, Donut, Edge-Loc, Edge-Ring, Loc, Random, Scratch, Ne"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_19", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 19, "text": "ion pro- cess (Wu et al., 2014 ). Only a subset of 21.3% (172,950) is labeled by professionals with one of the following nine cate- gories: Center, Donut, Edge-Loc, Edge-Ring, Loc, Random, Scratch, Near-Full, and None, while the rest of the group isstill unlabeled, check Fig. 1. As indicated from Fig. 1,t h edataset is mostly unlabeled and most of the labeled part is free of fault ‚ÄúNone‚Äù and the faulty part is very imbalanced.In Table 2, the distribution and the main cause of different defects are pointed out. This dataset provide a single-type defect in a single wafer map (Baly & Hajj, 2012 ; Saqlain et al., 2019 ; Y u et al., 2019 ,2022 ; Jin et al., 2020 ; Chen et al., 2021 ; Kang & Kang, 2021 ; Wang et al., 2021 , Wang et al., 2022 ;Y ue ta l . , 2021a ,b; Zheng et al., 2021 ; Chen et al., 2022 ; Xuen et al., 2022 ; Y oon & Kang, 2022 ; Zhang et al., 2022 ; Alqudah et al., 2023 ), but there are multiple studies that target mixed-type defect patterns in their inspection models, such as the ones in Kyeong et al. (2018), Kim et al. ( 2021 ), Sin et al. (2022), Y u et al. ( 2022 ), and Xu et al. ( 2023 ). Methodology The main steps of the proposed model for wafer map fault detectio"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_20", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 20, "text": " as the ones in Kyeong et al. (2018), Kim et al. ( 2021 ), Sin et al. (2022), Y u et al. ( 2022 ), and Xu et al. ( 2023 ). Methodology The main steps of the proposed model for wafer map fault detection are shown in the graphical abstract of Fig. 2, which combines a Ô¨Çow chart with a design purpose for each block. 123 3364 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Table 2 The observed defect patterns in WM-811K with counts and causes DefectpatternWafer map exampleCount (Proportionwith respect to the labelledgroup)The cause of the defect Center 4294 (2.48%)It is caused by abnormaldeposition,Ô¨Çuid Ô¨Çow,or pressureprocess Donut 555 (0.32%) It is caused by theprecipitationof thedissolvedphotoresistsolids on thewafersurface Edge-loc 5189 (3%) It is caused by abnormalÔ¨Ålmdeposition Edge-Ring 9680 (5.6%) It is caused by abnormaltemperatureduringannealing Loc 3593 (2.08%)It is local error causedby excessivemachinevibration Random 866 (0.5%) It is caused by airbornedustinterference Scratch 1193 (0.69%)It is a mechanical damage happeningduringhandling orcutting Near full 149 (0.09%) It is caused by HumanerrorTable 2 (continued) Defect patternWafer map exampleCount (Proportionwith r"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_21", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 21, "text": "ratch 1193 (0.69%)It is a mechanical damage happeningduringhandling orcutting Near full 149 (0.09%) It is caused by HumanerrorTable 2 (continued) Defect patternWafer map exampleCount (Proportionwith respectto the labelled group)The cause of the defect None 147,431 (85.25%)It is a normal wafer mapwith somenoise These steps are detailed in the following subsections. Algo- rithm 1 summarizes a pseudo code for the whole proposed wafer fault detection model. Wafer data synthetization model As presented in Table 2and Fig. 1, WM-811K is a highly imbalanced dataset. Each wafer map consists only of threetypes of pixels: 0 for the background, 1 for the normal pix-els and 2 for the defected ones. Consequently, two main preprocessing steps are performed. The Ô¨Årst is one-hot encod- ing to convert the grey wafer maps X(m,n) to colored ones XX(m,n,c), where c is the number of channels, as xx/parenleftbig m,n,c i/equal1x(m,n)/parenrightbig /equal11,where i ‚àà{0, 1, 2 },x(m,n) and xx(m,n,c) denotes the grey and colored pixel value. RGB wafer maps help to extract multi-scale features in the upcoming procedures. The second preprocessing step is a synthetization (augmentation or balancing) model. In th"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_22", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 22, "text": "grey and colored pixel value. RGB wafer maps help to extract multi-scale features in the upcoming procedures. The second preprocessing step is a synthetization (augmentation or balancing) model. In thiswork, an autoencoder-based synthesizing model is used fordata augmentation. An autoencoder (AE; Li et al., 2023 ) is a type of ANN that learns efÔ¨Åcient mappings or codings of unlabeled data inan unsupervised manner. AE extracts output data to recon- struct input data and compare it with original input data. After numerous times of iterations, the value of cost functionreaches its optimality, which means that the reconstructed input data is able to approximate the original input data to a maximum extent. The introduced convolutional autoencoder(CAE) shows superiority to the traditional AE by incorpo-rating convolutional layers which preserves the local image structures by incorporating spatial relationships between pix- els in images. The introduced CAE consists mainly of two parts: encoder and decoder, see Fig. 3. The encoder converts the input map to a bottleneck low dimensional feature map, while the decoderperforms deconvolution operations to expand the latent fea- ture map to rec"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_23", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 23, "text": "er and decoder, see Fig. 3. The encoder converts the input map to a bottleneck low dimensional feature map, while the decoderperforms deconvolution operations to expand the latent fea- ture map to reconstruct the original wafer map. The encoder in the proposed architecture consists of one 2D convolutionallayer with 64 Ô¨Ålters with a kernel weight of (3√ó3), and a 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3365 Fig. 2 Graphical abstract of the proposed fault type prediction in wafer maps MaxPooling layer. The extracted feature maps from the con- volutional layer of the encoder are represented as H/equal1A(XX‚àóW+B),( 1 ) where Ais the activation function which is employed as ReLU. XX is the encoded colored wafer maps. Wand Bare the weights (convolutional kernel) and the bias, respectively. The extracted feature maps from the convolutional layer is fed into a MaxPooling layer to provide the targeted bottlenecklow dimensional feature map Hc,a s Hc/equal1 max i/equal10,...,‚àá‚àí1,j/equal10,...,‚àá‚àí1H/parenleftbig x/prime+i,y/prime+j/parenrightbig ,( 2 ) where ‚àáis the MaxPooling operator. x/prime,andy/primeare the pixels coordinates. At this point, random Gaussian noise ( Œº/equ"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_24", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 24, "text": "1,j/equal10,...,‚àá‚àí1H/parenleftbig x/prime+i,y/prime+j/parenrightbig ,( 2 ) where ‚àáis the MaxPooling operator. x/prime,andy/primeare the pixels coordinates. At this point, random Gaussian noise ( Œº/equal10, œÉ/equal10.1) is added at the bottleneck embedded map Hcto provide more robustness to the synthetization model. Now,the decoder network tries to construct the input maps XX 123 3366 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 3 The CAE-based synthetization model for wafer maps augmentation Fig. 4 The performance of the proposed CAE-based synthetization model‚ÄîSample wafer map with its synthesized one and the training recon- struction error over epochs through employing two transposing convolution (deconvo- lutional) layers and UpSampling layer, revise Fig. 3.T h e output of decoder is the restored feature maps of Hcas X/equal1A(Hc‚àó/‚àóW+B),( 3 ) where ‚àó/‚àóis the deconvolution (Conv2DTranspose) oper- ator. The Ô¨Årst Conv2DTranspose (TConv2D) layer in thedecoder network employs 64 Ô¨Ålters with a kernel weight of(3√ó3)and activation function Aas ReLU. The second one employs three Ô¨Ålters with a kernel weight of (3√ó3) and activation function Aas Sigmoid. The proposed CAE is "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_25", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 25, "text": "loys 64 Ô¨Ålters with a kernel weight of(3√ó3)and activation function Aas ReLU. The second one employs three Ô¨Ålters with a kernel weight of (3√ó3) and activation function Aas Sigmoid. The proposed CAE is trained over certain epochs to minimize the reconstruction error between the original wafer maps and the synthesizedones, in terms of the mean squared error asMSE /equal11 NN/summationdisplay i/equal11(XX i‚àíXi)2, (4) where X/equal1/equal1/hatwideXX is the new synthesized wafer maps and N is the number of the inserted wafer maps. Figure 4indicates a sample wafer map and its corresponding synthesized one. As indicated, they look very similar in the indicated zoomed-upversions of maps. In addition, in the same Ô¨Ågure, the recon- struction error over the training epochs is shown with a Ô¨Ånal loss 0.0011at epoch 30. 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3367 Sparse feature learning and encoding At this stage, as low-dimensional 2D wafer maps are targeted, a new sparse autoencoder model is introduced. Sparsity is the property of being sparse or having a lot of zero entries (Sunet al., 2022 ). In the context of machine learning, sparsity is often used to refer to the numb"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_26", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 26, "text": "ncoder model is introduced. Sparsity is the property of being sparse or having a lot of zero entries (Sunet al., 2022 ). In the context of machine learning, sparsity is often used to refer to the number of zero weights in a neu- ral network. An autoencoder is called sparse when its hidden layer activations are encouraged to be sparse (Ng, 2011 ). The sparsity constraint is added to the loss function of the tradi- tional convolutional autoencoder. The sparsity constraint can be based on the L 1norm of the hidden layer activations or on the KL divergence between the distribution of activations in the hidden layer and a target distribution that is sparse. For the main difference between the traditional autoencoder andthe sparse one, check Fig. 5. Algorithm 1. The proposed wafer map fault detectionIn the proposed sparsity-boosted autoencoder (SBAE), a sparsity-reinforced layer is added to the last layer of theencoding phase. Therefore, the network is encouraged to learn an encoding by activating only a small number of nodes. The cost function of the proposed SBAE utilizes three terms:a reconstruction term combined with other two regularizers,i.e., a weight decay term and another sparsi"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_27", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 27, "text": "vating only a small number of nodes. The cost function of the proposed SBAE utilizes three terms:a reconstruction term combined with other two regularizers,i.e., a weight decay term and another sparsity-boosting term. The reconstruction term is similar to the previous CAE. The weight decay term helps to decrease the magnitude of theweights and prevent overÔ¨Åtting. The sparsity-boosting term induces a sparsity penalty in the training criterion. For the conÔ¨Åguration of the proposed SBAE, check Table 3. Assume the synthesized wafer maps of Nsamples (X 1,X2,...,XN), where xirepresents the ithinput of sam- pleXi. The cost function considering only the reconstruction term with the weight decay term can be expressed as 123 3368 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 5 Visual comparison between the traditional autoencoder in aand the sparsity-induced autoencoder in b. The dark green nodes are Ô¨Åring whereas the red nodes are constrained, i.e., we are in effect reducing the number of Ô¨Åring neurons Table 3 Detailed conÔ¨Åguration of the proposed SBAE Task Layer Filter size Output Encoder network Conv2d_1 + SeLU activation 3 √ó3√ó12 m√ón√ó12 Conv2d_2 + SeLU activation 3 √ó3√ó6 m√ó"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_28", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 28, "text": " number of Ô¨Åring neurons Table 3 Detailed conÔ¨Åguration of the proposed SBAE Task Layer Filter size Output Encoder network Conv2d_1 + SeLU activation 3 √ó3√ó12 m√ón√ó12 Conv2d_2 + SeLU activation 3 √ó3√ó6 m√ón√ó6 Conv2d_3 + SeLU activation 3 √ó3√ó3 m√ón√ó3 Bottleneck Sparsity regularization The sparsity parameter P, the weight decay ,a n d the sparse penalty term Œ≥were chosen to be 0.05, 0.0001, and 1 MaxPooling2D (2 √ó2)m 2√ón 2√ó3 Decoder network Conv2DTranspose_1 + SeLU activation 3 √ó3√ó3m 2√ón 2√ó3 Conv2DTranspose_2 + SeLU activation 3 √ó3√ó6m 2√ón 2√ó6 Conv2DTranspose_3 + SeLU activation 3 √ó3√ó12m 2√ón 2√ó12 UpSampling2D 2 √ó2 m√ón√ó12 Conv2D_4 (Output) + Sigmoid activation 4 √ó4√ó3 m√ón√ó3 (5) where AW,B/parenleftbig Xi/parenrightbig /equal1A/parenleftbig W‚àóXi+B/parenrightbig is the activation or mapping of the input Xiat layer l.nldenotes the number of layers lin the targeted network. olis the number of nodes or units in layer l.adjusts the weight of the decaying term; large can cause overÔ¨Åtting, while small values may causeunderÔ¨Åtting. In the proposed SBAE conÔ¨Åguration, the value of adjusted empirically via multiple experiments. For the sparsity-boosted term, the following term K/parenleftbig P/bardbl/hatw"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_29", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 29, "text": "lues may causeunderÔ¨Åtting. In the proposed SBAE conÔ¨Åguration, the value of adjusted empirically via multiple experiments. For the sparsity-boosted term, the following term K/parenleftbig P/bardbl/hatwideP/parenrightbig is inserted in the cost function in Eq. 5to be refor- mulated as 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3369 (6) K/parenleftbig P/bardbl/hatwidePj/parenrightbig /equal1PlogP /hatwidePj+(1‚àíP)log1‚àíP 1‚àí/hatwidePj,( 7 ) where K/parenleftbig P/bardbl/hatwideP/parenrightbig is Kullback‚ÄìLeibler divergence which seeks to reduce the deviation between /hatwidePandP.Pdenotes the targeted sparsity parameter, typically a small value close tozero./hatwidePis the average output of all hidden neurons, /hatwideP j/equal1 1/N/summationtext iAW,B/parenleftbig Xi/parenrightbig .Œ≥is the sparse penalty coefÔ¨Åcient. Using the introduced SBAE, the wafer map of size ( m√ó n√óc) is converted to a sparse encoded wafer map Xsof sizem 2√ón 2√óc, which means the encoded map spatial size is reduced to the half. The encoded map Xsis obtained from the bottleneck layer of SBAE. To visualize the clus- tering performance of the resultant encoded maps, T-SNE (V an der Maaten & Hinton, 2"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_30", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 30, "text": "ize is reduced to the half. The encoded map Xsis obtained from the bottleneck layer of SBAE. To visualize the clus- tering performance of the resultant encoded maps, T-SNE (V an der Maaten & Hinton, 2008 ) is used, see Fig. 6. It helps to visualize the high-dimensional data by mapping the clus-tered features into low-dimensional space. As indicated, the encoded feature maps show better clustering performance compared to the original maps.A new sinogramic red deer feature ranking The main target of feature engineering steps is to reduce the feature dimensionality while keeping the best performance. At this stage, we intend to convert the sparse encoded wafermapsX sto 1D signal without losing the spatial information of the 2D maps. Wherefore, the sparse encoded feature maps Xsare converted to sinograms by employing Radon transfor- mation (Leavers, 1992 ). After that, each sinogram now can be converted to 1D signal ysof size/parenleftbig 1√ómnc 4/parenrightbig ,s of o r Nsam- ples, we have 1D feature pool Ysof size/parenleftbig N√ómnc 4/parenrightbig . Then, the proposed enhanced red deer (ERD) algorithm is appliedto the resultant sinograms to assign the optimal reduced fea- tures. The "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_31", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 31, "text": " 1D feature pool Ysof size/parenleftbig N√ómnc 4/parenrightbig . Then, the proposed enhanced red deer (ERD) algorithm is appliedto the resultant sinograms to assign the optimal reduced fea- tures. The conventional red deer algorithm Red deer (RD) algorithm is a new nature-inspired optimiza- tion technique (Fathollahi-Fard et al., 2020 ). It belongs to the family of population-based metaheuristics algorithms. The main advantage of RD algorithm is that it equally maintains Fig. 6 t-SNE comparison before ( a)a n da f t e r( b) the sparse encoding by SBAE 123 3370 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 7 Flow chart of the main Red Deer algorithm for sinogramic feature selection the exploitation and exploration phases, which helps to assign the salient features with low complexity. Red deer is male or female (hinds). A group of hinds is called a harem. Each harem is assigned a male com-mander. A competition is set among male RDs to get the harem with more hinds via roaring and Ô¨Åghting. According to the strength of the roaring phase, male RDs are catego-rized into commanders and stags. Only the strongest male after a Ô¨Åerce Ô¨Åght with the other males will be the com- "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_32", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 32, "text": "ring and Ô¨Åghting. According to the strength of the roaring phase, male RDs are catego-rized into commanders and stags. Only the strongest male after a Ô¨Åerce Ô¨Åght with the other males will be the com- mander of the harem. Here, the/parenleftbig mnc 4/parenrightbigthsparse encoded 1D features in , where of size (N, 1) is the feature vector, are considered as a group of RDs. Figure 7indicates a Ô¨Çow chart of the RD algorithm. The main objective of optimization problem concentrates on the deter-mination of near global or optimal solution evaluated with respect to the variables associated with the problem. Stage 1: Initialize the population At this stage, an sparse sinogramic features to initialize red deers as, . Among this population, are chosen as the male red deer features, Gmale , while the rest are the hind group, Ghind. The best features in the selected population are selected as males according to their Ô¨Åtness value. The proposed objectiveor Ô¨Åtness function is a collaboration between the classiÔ¨Åca-tion accuracy, based on KNN classiÔ¨Åer, and the proportionof the selected number of red deers through a weighted sum as f/equal1œâ.acc +(1‚àíœâ)œë /Gamma1,( 8 ) where acc denotes the classiÔ¨Åc"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_33", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 33, "text": " the classiÔ¨Åca-tion accuracy, based on KNN classiÔ¨Åer, and the proportionof the selected number of red deers through a weighted sum as f/equal1œâ.acc +(1‚àíœâ)œë /Gamma1,( 8 ) where acc denotes the classiÔ¨Åcation accuracy of the currently selected red deers or features. œërepresents the number of the currently selected red deers, while /Gamma1is the total number of features in the targeted feature pool. œâis a weighting coefÔ¨Å- cient in the range of [0, 1]. Stage 2: Roaring phase The male agents are currently the superior solutions. Roaring is a local search for other neigh-boring best features. The updating rule is as follows. RD new male /equal1/braceleftBigg RDold male+Œ±1√ó((u‚àí/lscript)‚àóŒ±2+/lscript),ifŒ±3‚â•0.5, RDold male‚àíŒ±1√ó((u‚àí/lscript)‚àóŒ±2+/lscript),ifŒ±3<0.5, (9) where RDnew maleand RDold maleare the current and the previous positions of male red deer solutions. /intersectionsqand/lscriptare the upper and lower limits of local search of neighboring solutions. Œ±1,Œ±2, andŒ±3are randomly generated coefÔ¨Åcients from a uniform distribution that ranges from 0 to 1. Then, the male red deer solutions are categorized into commander and stage red deer solutions. The 123 Journal of Intelligent Manufact"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_34", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 34, "text": " coefÔ¨Åcients from a uniform distribution that ranges from 0 to 1. Then, the male red deer solutions are categorized into commander and stage red deer solutions. The 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3371 number of male commanders, is considered as , where Œ¥is a random value in a range from 0 to 1. The number of stags can be expressed as Stage 3: The Ô¨Åghting phase between stags and commanders Here, every commander is allowed to Ô¨Åght with random stags. According to the solution space, we let the group solution of commanders Gcom approaches that of stags Gstag. Accord- ingly, two new group of solutions are generated as Gnew1/equal1Gcom+Gstag 2+Œ≤1√ó((u‚àí/lscript)‚àóŒ≤2+/lscript),( 1 0 ) Gnew2/equal1Gcom+Gstag 2‚àíŒ≤1√ó((u‚àí/lscript)‚àóŒ≤2+/lscript), (11) where Gnew1andGnew2denote the new generated solutions due to the Ô¨Åghting process. uand/lscriptare the limits of the search space. Œ≤1andŒ≤2are randomly generated coefÔ¨Åcients from a uniform distribution that ranges from 0 to 1. Now, we have four solutions, i.e., Gcom,Gstag,Gnew1, and Gnew2,t h e solution with the best cost function Fwill be selected as the Ô¨Ånal commander. Stage 4: Forming harems Here, the assigned new comman"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_35", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 35, "text": "Now, we have four solutions, i.e., Gcom,Gstag,Gnew1, and Gnew2,t h e solution with the best cost function Fwill be selected as the Ô¨Ånal commander. Stage 4: Forming harems Here, the assigned new comman- der is responsible for forming harems. A harem consists ofa male commander and a group of female deer (hinds). Thehinds are distributed into separate harems in a random man- ner, based on the power of the commander in roaring andÔ¨Åghting, i.e., it‚Äôs Ô¨Åtting value. Hence, the number of hinds in a harem i, , is calculated as (12) where fidenotes the normalized power, Ô¨Åtting value, of the commander. Stage 5: Mating phase After forming harems, there are three possibilities of mating. The Ô¨Årst is that the commander ofharem imates with œÅof its harem‚Äôs hinds, and the second occurs when the commander mates with œëof hinds of other harems. Commanders attack another harem to expand his command area. The third possibility is that each stag mateswith the closest hind, regardless of harem restrictions. Due to the mating phase, new offspring RDs, G OS, i.e., solutions, are generated as GOS/equal1Gcom+Ghind 2+Œ∏√ó(u‚àí/lscript), (13) where Gcom, and Ghind are the group of solutions that repre- sent comman"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_36", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 36, "text": "Due to the mating phase, new offspring RDs, G OS, i.e., solutions, are generated as GOS/equal1Gcom+Ghind 2+Œ∏√ó(u‚àí/lscript), (13) where Gcom, and Ghind are the group of solutions that repre- sent commanders and hinds. Œ∏is a random number between 0 and 1. In the third possibility of mating Gcom is replaced by the stag solutions Gstag. 123 3372 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Algorithm 2. Detailed steps about the proposed enhanced red deer algorithm (ERD) Finally, the next generation is assigned from all the best commanders (a certain percentage of the best solutions), and the best hinds from all hinds and offspring, via the useof a roulette wheel. These previous stages are performed repeatedly until the maximum number of iterations (Max- iter) reached and the optimal features are deÔ¨Åned.The proposed enhanced red deer optimizer (ERD) The main idea in the proposed ERD is a tinkering strategy that enhances the traditional mating phase in the conventional red deer optimizer represented in Eq. 13. The tinkering strat- egy is about adding members from the worst harems, i.e., 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3373 with the worst Ô¨Åtting valu"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_37", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 37, "text": "imizer represented in Eq. 13. The tinkering strat- egy is about adding members from the worst harems, i.e., 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3373 with the worst Ô¨Åtting values, toward the ‚Äúbest-so-far‚Äù harems which have the best Ô¨Åtting value. This tinkering strategy isperformed based on the degree of diversity among harems. The tinkering strategy For the tinkering strategy, we need to deÔ¨Åne the best harems and the worst harems, according to the Ô¨Åtting value, while keep- ing . The worst of the worst hinds of the Ugroup will tinker the best harems Q, i.e., they join the original hinds. However, this tinkering strategy may lead to local minima entrapment. Accordingly, we need to control the targeted number of worst harems, , as follows. (14) where is the total number of constructed harems. Fworst harem, and Fbest haremdenote the whole worst and best Ô¨Åtting value, respectively. √è is the current iteration number corre-sponding to the maximum assigned number of iterations, maxiter .n ÀÜis a Ô¨Åxed number of harems to be updated within each iteration. After determining the worst harems, the best harems are assigned as . Then, the number of hinds from the worst hare"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_38", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 38, "text": "rations, maxiter .n ÀÜis a Ô¨Åxed number of harems to be updated within each iteration. After determining the worst harems, the best harems are assigned as . Then, the number of hinds from the worst harems are distributed equally, in num-ber, between the best harems, while the best of the best harems assigned the worst hinds in Ô¨Åtting simulating the effect of mutation in metaheuristic algorithms. Now, theharems are reformulated according to the tinkering strategy. According to the mating phase, the new offspring RDs, G OS, are generated as GOS/equal1/braceleftBigg Gcom+Ghind 2+Œ∏√ó(u‚àí/lscript),ifv>Œ∂ , Gcom+Ghind +Gtink 3+Œ∏√ó(u‚àí/lscript),otherwise, (15) where Gtink is the Œæ% of the new tinkering hinds. vis the diversity in Ô¨Åtting between the tinkered harem and the tin- kering harem, as it is deÔ¨Åned as (16) where fharem iis the whole Ô¨Åtting values of hinds in harem i. Algorithm 2 summarizes the main steps of the proposed ERD.The proposed 1DCNN classification model For the Ô¨Ånal prediction stage to differentiate between the different types of faults in the wafer map, we propose a new 1DCNN-based network which receive the resultant featurepool from the proposed ERA algorithm. 1DCNN is a speci"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_39", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 39, "text": " to differentiate between the different types of faults in the wafer map, we propose a new 1DCNN-based network which receive the resultant featurepool from the proposed ERA algorithm. 1DCNN is a speciÔ¨Åctype of CNN that is designed to basically operate on one- dimensional signal. Therefore, it employs one-dimensional convolutions and sub-sampling layers for feature mappingand extraction. Following the optimum majority of CNNs, an input layer, CNN layer group (a convolution layer and a pooling layer), a fully connected layer and output layer form abasic 1DCNN. The resultant vector from each convolutional layer, activation layer, or pooling layer can be considered as a one-dimensional ‚Äúfeature vector‚Äù, that can be used somehow in the 1D targeted task. For the conÔ¨Åguration of the proposed 1DCNN network, check Fig. 8. Experimental results and discussion In this section, different experiments have been performed to test the performance of the proposed model of wafer mapfault detection. Intensive visual and computitative compar- isons are introduced with an ablation study to indicate the impact of the different steps in the introduced model. Fig. 8 The proposed 1DCNN for the Ô¨Ånal classiÔ¨Åc"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_40", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 40, "text": "sive visual and computitative compar- isons are introduced with an ablation study to indicate the impact of the different steps in the introduced model. Fig. 8 The proposed 1DCNN for the Ô¨Ånal classiÔ¨Åcation stage of wafer map fault types 123 3374 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 9 The employed metrics in the evaluation process of fault detection Experimental setup all experiments were performed on the Colab Pro environment of Google using different Python libraries, such as Keras, NumPy, TensorÔ¨Çow, and Sklearn. Forthe feature reduction stages: check Table 3for the conÔ¨Ågura- tion of SBAE and Algorithm 2 for the parameters of proposed tinkered red deer optimization (ERD). For the Ô¨Ånal prediction stage, we used the advanced optimization algorithm Adamwith its default parameters to exploit the optimum weighting coefÔ¨Åcients. We set the learning rate parameter to 0.0001.The 1DCNN is trained with batches of 32 due to memory limita-tions. For the model assessment, see Fig. 9, different metrices are introduced, such as accuracy, precision, recall, and F1- score. Comparison to the state of the art In Table 4, a comparison is set among different methods in wafer ma"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_41", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 41, "text": "ee Fig. 9, different metrices are introduced, such as accuracy, precision, recall, and F1- score. Comparison to the state of the art In Table 4, a comparison is set among different methods in wafer map fault detection (Jin et al., 2020 ; Chen et al., 2021 ; Y u et al., 2021a ), DenseNet-GCF (Y u and Chen et al., 2022 ; Wang et al., 2021 ,2022 ; Zheng et al., 2021 ), WDP-BNN (Alqudah et al., 2023 ; Zhang et al., 2022 ), and the pro- posed method. All the prementioned competitors are based on deep neural networks with supportive modules to enhance the detection performance. Most of them employ a cross-validation evaluation (Jin et al., 2020 ; Y u et al., 2021b , Chen et al., 2022 ) or just a train‚Äìtest evaluation (Chen et al., 2021 ; Y u et al., 2021a ; Xuen et al., 2022 ; Wang et al., 2022 ; Zhang et al., 2022 ). Following the cross-validation evaluation, Chenet al. ( 2022 ) achieved high accuracy of 98.34% for nine fault classes but with a very complicated model of two 2DCNNs employing more than 53,000 sample. On the other hand, Jinet al. ( 2020 ) declared 98.43% accuracy but with 8 fault types employing hybrid model of 2DCNN with error-correcting output codes and support vector ma"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_42", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 42, "text": " more than 53,000 sample. On the other hand, Jinet al. ( 2020 ) declared 98.43% accuracy but with 8 fault types employing hybrid model of 2DCNN with error-correcting output codes and support vector machines for classiÔ¨Åcation with 20,000 samples. For the other types of evaluation, i.e., train‚Äìvalid evalua- tion, it is a fragile evaluation because it can simply lead to overÔ¨Åtting and doesn‚Äôt guarantee that the model will performwell on other unseen data from the same distribution. Wang et al. ( 2022 ) with 95:5 evaluation, for 9 fault types within 13,435 samples, declared 98.35% accuracy but with com-plicated model of 2DCNN and residual blocks. In addition,residual blocks can make networks more prone to overÔ¨Åtting. Chen et al. ( 2022 ) with 80:20 evaluation, for 8 fault types within 33,256 samples, gained 96% accuracy employing verycomplicated model of two 2DCNNs with error-correcting output codes and support vector machines for classiÔ¨Åcation. In Table 4, two methods, i.e., Zheng et al. ( 2021 ) and Alqudah et al. ( 2023 ), have targeted the same evaluation and feature reduction concepts as ours. Zheng et al. ( 2021 ) follows a train‚Äìvalidation‚Äìtest evaluation (60:20:20). Theydeclare"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_43", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 43, "text": "( 2021 ) and Alqudah et al. ( 2023 ), have targeted the same evaluation and feature reduction concepts as ours. Zheng et al. ( 2021 ) follows a train‚Äìvalidation‚Äìtest evaluation (60:20:20). Theydeclared accuracy of 93.8 with 4000 sample size for 9 faulttypes. Zheng et al. ( 2021 ) build their own 2DCNN for classi- Ô¨Åcation. Their obtained accuracy is adequate with the limited sample size and the lack of preprocessing steps. The proposedmodel achieves 98.77% and 99.24% accuracy for 9 and 8 fault 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3375Table 4 Computitative comparison between the state-of-the-art methods with proposed detection method Study Basic techniques Acc Pre Sen F1-score Sample size Fault classes Train‚Äìvalidation‚Äìtest Jin et al. ( 2020 ) 2DCNN‚ÄìECOC‚ÄìSVM 98.43 98.2 98.3 98.2 20,000 8 10-Fold cross validation Y u et al. ( 2021b ) DenseNet + GCForest 97.4 ‚Äì 97.4 97.4 9112 9 5-Fold cross-validation Chen et al. ( 2021 ) Dual-channel 2DCNN + ECOC‚ÄìSVM 96.4 96.4 96.2 96.3 33,256 8 80:20 Zheng et al. ( 2021 ) 2D-DCNN 93.8 93.8 93.8 93.8 4000 9 60:20:20 Y u et al., ( 2021a ) Wasserstein adversarial network 87.32 89.74 86.50 87.33 1800 9 90:10 Chen et al. ( 2022 ) A"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_44", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 44, "text": " 96.3 33,256 8 80:20 Zheng et al. ( 2021 ) 2D-DCNN 93.8 93.8 93.8 93.8 4000 9 60:20:20 Y u et al., ( 2021a ) Wasserstein adversarial network 87.32 89.74 86.50 87.33 1800 9 90:10 Chen et al. ( 2022 ) A dual-source 2D-DCNN + information entropy 98.34 93.30 89.10 90.71 53,925 9 10-Fold cross validation Wang et al. ( 2022 ) 2D-CNN + residual blocks 98.35 98.32 98.32 98.31 13,435 9 95:5 Zhang et al. ( 2022 ) 2D BNN 98.68 92.53 94.00 93.23 31,500 9 90:10 Alqudah et al. ( 2023 ) 59 Features + SVM 82.7 83.7 84.4 84.1 29,043 8 75:25 Ours1 SBAE + ERD (15 features) + 1DCNN 98.77 98.78 98.89 98.89 18,736 9 60:20:20 Ours2 98.60 98.67 98.78 98.8 36:15:49 Ours3 98.50 98.56 98.56 98.44 23:15:62 Ours1 SBAE + ERD (19 features) + 1DCNN 99.24 99.25 99.25 99.38 16,397 8 60:20:20 Ours2 98.66 0.99 98.75 98.75 36:15:49 Ours3 98.61 98.75 98.63 98.63 23:15:62 Bold font is used to emphasize the best results 123 3376 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 10 The confusion matrices of the proposed wafer map fault detection model for 60:20:20 evaluation (ours1) in a, 36:15:49 evaluation (ours2) inb, and 23:15:62 evaluation (ours3) in c types, respectively, with 60:20:20 evaluation within "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_45", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 45, "text": "oposed wafer map fault detection model for 60:20:20 evaluation (ours1) in a, 36:15:49 evaluation (ours2) inb, and 23:15:62 evaluation (ours3) in c types, respectively, with 60:20:20 evaluation within around 16,000:18,000 samples. Alqudah et al. ( 2023 ) have followed the concept of fea- ture reduction. Their features are extracted from the 2D wafer maps contrary to the proposed method which arefrom 1D sinograms. Alqudah et al. ( 2023 ) have utilized 59 feature bases in total (Density, radon, and geometry-based features). They declared accuracy of 82.7%, despite using around 29,000 sample, because they have employed a sim-ple SVM classiÔ¨Åer. In the proposed fault detection method, three different Train‚Äìvalidation‚Äìtest evaluations have been introduced, i.e., 60:20:20, 36:15:49, and 23:15:62. We havegot a minimum accuracy of 98.5% when the detection model is tested with 62% unseen data for 9 fault types within around 18,000 sample and 15 features. On the other side,we have gained accuracy 98.61% for 62% unseen part for 8fault types within around 16,000 sample and 19 features. In addition, with the proposed method, the accuracy justchanged from 98.77 to 98.50% and from 99.24 to 98.61% w"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_46", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 46, "text": "98.61% for 62% unseen part for 8fault types within around 16,000 sample and 19 features. In addition, with the proposed method, the accuracy justchanged from 98.77 to 98.50% and from 99.24 to 98.61% when the unseen testing data part changed from 20 to 62%for 9 and 8 fault types, respectively. This very small change proves that the proposed model generalized well by exploit- ing the most suitable discriminative features by the assignedfeature engineering steps (SBAE and ERD). For detailedclassiÔ¨Åcation reports, confusion matrices, and train‚Äìvalida- tion performance of the proposed detection method for 9 fault types, check Figs .10,11, and 12. From Figs. 10and 11we can see that the ‚Äúnone‚Äù fault type has the least metrics. It is the most confusing class. It shares similar structures (fea- tures) with other faults, check the fault images in Table 2.I n addition, ‚Äúnone‚Äù fault is totally unbalanced with other faults, so many studies (Alqudah et al., 2023 ; Chen et al., 2021 ; Jin et al., 2020 ) have ignored this fault to avoid additional preprocessing steps. Figure 12indicates the train‚Äìvalidation performance which shows semi-identical performance that refuting the chance of overÔ¨Åtting. 1"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_47", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 47, "text": " ) have ignored this fault to avoid additional preprocessing steps. Figure 12indicates the train‚Äìvalidation performance which shows semi-identical performance that refuting the chance of overÔ¨Åtting. 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3377 Fig. 11 The corresponding classiÔ¨Åcation reports of the confusion matrices in Fig. 10of the proposed wafer map fault detection model for 60:20:20 evaluation (ours1) in a, 36:15:49 evaluation (ours2) in b, and 23:15:62 evaluation (ours3) in c The impact of wafer map resolution in performance WM-811K dataset originally has different sizes of wafer maps, 632 in total, and varies in resolution from 6 √ó21 to 300√ó202. Figure 13indicates the resolution distribution in terms of the number of wafer maps. There are 5 resolutions only with more than 10,000 samples. The largest resolution among them 39 √ó37. As the wafer maps are not rich in color, i.e., each map contains only three colors, the initial prepro- cessing steps to adjust the size can simply affect the fault type. Hence, different experiments have been performed onthe resolutions that have more than 8000 samples and they are only 7 different resolutions. These samples for e"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_48", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 48, "text": "ize can simply affect the fault type. Hence, different experiments have been performed onthe resolutions that have more than 8000 samples and they are only 7 different resolutions. These samples for each reso- lution are indicated in Table 5before and after (W/O and W/) the CAE-based synthetization model as a balancing model.The ‚ÄúAll‚Äù wafer map set groups the seven other sets and mapped them to resolution 26 √ó26. As shown, in Table 5, the ‚Äúnone‚Äù fault type has the largest number of maps in eachresolution. In addition, the resolution 33 √ó29 is the mostchallenging as it has the least number of samples in each fault type. Having different resolutions affect the structure of the fault types, and accordingly affect the discriminative fea-tures that affect the recognition rate of each class and thusaffect the Ô¨Ånal metrics. Table 6indicates the performance of different resolutions under different split ratios. As demon- strated, there are two resolutions that have only 8 fault typesor classes, i.e., 25 √ó27 and 27 √ó25, but they don‚Äôt have the same types of faults. The resolution 25 √ó27 misses the fault ‚Äúdonut‚Äù, while the resolution 27 √ó25 misses the fault ‚ÄúEdge-ring‚Äù, revise Table 4. The o"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_49", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 49, "text": ", i.e., 25 √ó27 and 27 √ó25, but they don‚Äôt have the same types of faults. The resolution 25 √ó27 misses the fault ‚Äúdonut‚Äù, while the resolution 27 √ó25 misses the fault ‚ÄúEdge-ring‚Äù, revise Table 4. The other resolutions have 9 fault types. For the category of 8 classes, the resolution 27 √ó25 shows better performance than 25 √ó27. With only 19 fea- tures, the resolution 27 √ó25 provides 99.24% accuracy with 20% testing and 98.61% accuracy with 62% testing corre- sponding to 98.36% and 94.82% for 25 √ó27 resolution with 22 features. We can see that the accuracy changed slightlyfrom 99.24 to 98.61% (very good generalization) in 27 √ó25 123 3378 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 12 Train‚Äìvalidation performance over epochs of the proposed wafer map fault detection in terms of accuracy and losses for 60:20:20 evaluation (ours1) in a, 36:15:49 evaluation (ours2) in b, and 23:15:62 evaluation (ours3) in c 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3379 Fig. 13 the maps resolution distribution in WM-811K and aggressively from 98.36 to 94.82% (good generaliza- tion) in 25 √ó27 by changing the unseen part from 20 to 62%. As indicated from the classiÔ¨Åcatio"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_50", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 50, "text": "g. 13 the maps resolution distribution in WM-811K and aggressively from 98.36 to 94.82% (good generaliza- tion) in 25 √ó27 by changing the unseen part from 20 to 62%. As indicated from the classiÔ¨Åcation reports in Fig. 14,t h e recognition metrics of ‚ÄúLoc‚Äù and ‚Äúnone‚Äù classes degrade a little at resolution 27 √ó25. At the other side, at resolution 25√ó27, the recognition metrics of three classes degrades aggressively, i.e., ‚Äúnone‚Äù, ‚Äúloc‚Äù, and ‚ÄúEdge-Loc‚Äù, while the recognition of the ‚Äúcenter‚Äù degrades slightly. The main causebehind a degradation in recognition metrics, which affectsthe grouped performance, is that the extracted discriminative feature fails to recognize this class effectively like the other classes because of sharing similar structures. Check Fig. 15 for samples of wafers for ‚Äúnone‚Äù, ‚Äúloc‚Äù, ‚ÄúEdge-Loc‚Äù, and ‚Äúcenter‚Äù. For the resolution sets that have 9 fault types, as presented in Table 6, the resolution 33 √ó29 comes at the Ô¨Årst place with the minimum feature size (15), and with the best per- formance in terms of the recognition metrices, despite thevariety of the split ratio. It proves a good generalization bychanging the unseen part from 20 to 62%. The resolution 39√ó37 "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_51", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 51, "text": "ith the best per- formance in terms of the recognition metrices, despite thevariety of the split ratio. It proves a good generalization bychanging the unseen part from 20 to 62%. The resolution 39√ó37 is the worst with the largest feature size (27), the least metrices, and the least generalization. Figure 16indi- cates the classiÔ¨Åcation reports of the resolutions 33 √ó29 and 39√ó37 at different unseen part percentages, i.e., 20% and 62%. As demonstrated, the recognition metrics of ‚Äúnone‚Äù,‚ÄúLoc‚Äù, and ‚ÄúEdge-Loc‚Äù at the resolution set 33 √ó29 are high which means that the faults shapes discriminatively differ from each other, on contrary to what we have with the reso-lution set 39 √ó37. This means the recognition rate of the faulttype is independent of higher-resolution maps, but the fault type structure. In other words, the resolution set 39 √ó37 has more complicated and indiscriminative fault types that are not efÔ¨Åciently recognizable, like the resolution set 33 √ó29. For more results of other resolution sets, see Table 10in ‚ÄúAppendix ‚Äù. The impact of feature engineering steps In the proposed fault detection method, two main tech- niques have been used for feature engineering after the data"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_52", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 52, "text": "resolution sets, see Table 10in ‚ÄúAppendix ‚Äù. The impact of feature engineering steps In the proposed fault detection method, two main tech- niques have been used for feature engineering after the databalancing step. The Ô¨Årst is a sparse feature learning and encoding by the proposed SBAE, where the resultant sparse encoded feature maps are extracted from the bottleneck ofSBAE. Inducing sparse regularization in a traditional con- volutional autoencoder enhances the reconstruction process and accordingly efÔ¨Åcient sparse embedding can be gainedat the bottleneck of SBAE. In Fig. 17a comparison is made between the performance of SBAE and the traditional convolutional AE (CAE) that have the same conÔ¨Åguration excluding the sparsity regularization. As shown, without theinduced sparsity, the reconstructed wafer maps at CAE are blurry without any Ô¨Åne details contrary to SBAE. The second feature engineering step is applying the proposed tinkeredred deer feature ranking (ERD) to 1D sinograms of the resul- tant sparse encoded features from the bottleneck of SBAE. Figure 18indicates visual comparison for the convergence of Ô¨Åtness over iterations between the conventional red deer 123 3380 Journal "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_53", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 53, "text": " resul- tant sparse encoded features from the bottleneck of SBAE. Figure 18indicates visual comparison for the convergence of Ô¨Åtness over iterations between the conventional red deer 123 3380 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397Table 5 The number of samples under each employed wafer map resolution, from the labeled maps, before and after the CAE-based synthetization model Fault type 26 √ó26 25 √ó27 29 √ó26 27 √ó25 30 √ó34 39 √ó37 33 √ó29 All W/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAEW/O CAEW/ CAE Center 90 2160 2251 2251 50 2100 23 2024 58 2088 173 2249 20 2040 2665 3475 Donut 1 2002 ‚Äì ‚Äì 2 2004 6 2010 4 2008 22 2024 2 2004 37 3524 Edge-Loc 296 2368 355 2485 233 2330 96 2112 306 2448 473 2838 130 2210 1889 3563 Edge-Ring 31 2046 25 2050 64 2112 ‚Äì ‚Äì 9 2016 15 2025 55 2090 199 3480 Loc 297 2376 172 2236 117 2223 104 2184 241 2410 222 2442 107 2140 1260 3679 Near-full 16 2032 21 2037 5 2010 11 2013 5 2010 15 2025 28 2044 101 3612 Random 74 2146 53 2067 4 2008 10 2020 18 2034 35 2065 12 2016 206 3662 Scratch 72 2088 23 2024 80 2160 7 2009 69 2070 60 2100 27 2068 358 3873 None 13,489 2489 15,881 2181 11,196 2196 10,425 2025 11"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_54", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 54, "text": "2 Random 74 2146 53 2067 4 2008 10 2020 18 2034 35 2065 12 2016 206 3662 Scratch 72 2088 23 2024 80 2160 7 2009 69 2070 60 2100 27 2068 358 3873 None 13,489 2489 15,881 2181 11,196 2196 10,425 2025 11,690 2090 9158 2158 7724 2124 79,563 3604 /summationtext14,366 19,707 18,781 17,331 11,751 19,143 10,682 16,397 12,400 19,174 10,173 19,926 8105 18,736 86,278 32,472 Bold font is used to emphasize the best results 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3381Table 6 Computitative comparison between the performance of different resolutions of wafer maps at different split ratio Wafer map resolution Final feature size/classes Acc Pre Sen F1-score Sample size Train‚Äìvalid‚Äìtest 25√ó27 22/8 98.36 98.37 98.37 98.5 17,331 60:20:20 96.83 96.88 96.88 97 36:15:4994.82 95.25 94.88 94.88 23:15:62 27√ó25 19/8 99.24 99.25 99.25 99.38 16,397 60:20:20 98.66 0.99 98.75 98.75 36:15:49 98.61 98.75 98.63 98.63 23:15:62 39√ó37 27/9 97.37 97.89 97.22 97.33 19,926 60:20:20 96.17 96.56 96.22 96.33 36:15:49 93.07 93.33 93.56 93.22 23:15:62 33√ó29 15/9 98.77 98.78 98.89 98.89 18,736 60:20:20 98.60 98.67 98.78 98.8 36:15:49 98.50 98.56 98.56 98.44 23:15:62 Bold font is used to emphasize the best r"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_55", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 55, "text": " 36:15:49 93.07 93.33 93.56 93.22 23:15:62 33√ó29 15/9 98.77 98.78 98.89 98.89 18,736 60:20:20 98.60 98.67 98.78 98.8 36:15:49 98.50 98.56 98.56 98.44 23:15:62 Bold font is used to emphasize the best results 123 3382 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 14 Visual comparison between different resolutions of wafer maps in terms of the classiÔ¨Åcation report, 27 √ó25 (8 classes) in the Ô¨Årst row and 25√ó27 (8 classes) in the second row. The Ô¨Årst column at 60:20:20 while the second at 23:15:62 (train‚Äìvalidation‚Äìtest) evaluation optimization and the proposed ERD. Better convergence and higher Ô¨Åtness belongs to the proposed ERD. The impact of these prementioned feature engineering steps on performance can be checked through four condi-tions: the Ô¨Årst is without any feature engineering steps, thesecond and the third adopt only one feature engineering step, i.e., SBAE or ERD, the fourth is about applying both feature engineering steps. These conditions are presented in Table 7 as computitative comparison. As shown, the worst perfor- mance belongs to the Ô¨Årst condition (W/O ERD, W/O SBAE), despite owning the largest 1D feature pool. The redundantinformation in this large "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_56", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 56, "text": " 7 as computitative comparison. As shown, the worst perfor- mance belongs to the Ô¨Årst condition (W/O ERD, W/O SBAE), despite owning the largest 1D feature pool. The redundantinformation in this large pool limits the performance of the proposed classiÔ¨Åer 1DCNN. We can see that the most wafer maps affected by the absence of the feature engineering stepsare the set of ‚Äú33 √ó29‚Äù, while the least affected are the setof ‚Äú30 √ó34‚Äù. This means that the structure of fault types in the set 33 √ó29 offer more redundant information than that of the set ‚Äú30 √ó34‚Äù. For the second and the third condition of applying one feature engineering step, i.e., (W/ ERD, W/OSBAE) and (W/O ERD, W/ SBAE), respectively, better per-formance than the Ô¨Årst condition is gained with smaller 1D feature pool. As pointed out, in (W/ ERD, W/O SBAE), considering the original features without the sparse learning by SBAE increases the number of features selected by the proposed ERD algorithm seeking the global optimum feature ranking.The set ‚Äú30 √ó34‚Äù has the largest feature pool but with high accuracy, while the set ‚Äú33 √ó29‚Äù has the smallest feature pool but with low accuracy. On the other hand, depending on thesparse boosted"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_57", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 57, "text": "king.The set ‚Äú30 √ó34‚Äù has the largest feature pool but with high accuracy, while the set ‚Äú33 √ó29‚Äù has the smallest feature pool but with low accuracy. On the other hand, depending on thesparse boosted features from the bottleneck of SBAE without 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3383 Fig. 15 Samples of wafer maps from fault types: ‚Äúnone‚Äù, ‚ÄúLoc‚Äù, ‚ÄúEdge-Loc‚Äù, and ‚ÄúCenter‚Äù employing ERD at the third condition (W/O ERD, W/ SBAE) provides a Ô¨Åxed size 1D feature pool which shows adequate performance with some sets, like 27 √ó25 and 33 √ó29, but fails with other sets, like 26 √ó26, 30 √ó34. The adequate performance means that the extracted features guarantees a suitable discrimination between classes while failing means that features are not discriminative enough. Finally, at thefourth condition (W/ ERD, W/ SBAE), as signiÔ¨Åed, the least 1D feature pool sizes with the best performance is achieved. The sparsity induced in SBAE allows to get more sparseÔ¨Åne details that simpliÔ¨Åes the mission of ERD to Ô¨Ånd the global optimum with the least number of features. For more computitative results of the four conditions at other differentresolutions, see Table 11in ‚ÄúAppendix ‚Äù. "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_58", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 58, "text": "pliÔ¨Åes the mission of ERD to Ô¨Ånd the global optimum with the least number of features. For more computitative results of the four conditions at other differentresolutions, see Table 11in ‚ÄúAppendix ‚Äù. Figure 19presents the classiÔ¨Åcation reports of the map set ‚Äú26 √ó26‚Äù at the previous four conditions. In addition, Fig. 20indicates the train‚Äìvalidation performance over epochs. The small gapbetween train and valid means good generalization while large gap means bad generalization. 123 3384 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 16 Visual comparison between different resolutions of wafer maps in terms of the classiÔ¨Åcation report, 33 √ó29 (9 classes, 15 features) in the Ô¨Årst row and 39 √ó37 (9 classes, 27 features) in the second row. The Ô¨Årstcolumn at 60:20:20 while the second at 23:15:62 (train‚Äìvalidation‚Äìtest) evaluation The impact of the proposed ERD compared to other metaheuristic algorithms. Here, the impact of the enhanced tinkered red deer algo- rithm (ERD) is discussed. A comparison is set in Table 8 between different metaheuristics algorithms compared to the proposed ERD. A metaheuristic algorithm (Abdel-Basset et al., 2018 ) is a high-level procedure or heu"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_59", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 59, "text": "cussed. A comparison is set in Table 8 between different metaheuristics algorithms compared to the proposed ERD. A metaheuristic algorithm (Abdel-Basset et al., 2018 ) is a high-level procedure or heuristic designed to Ô¨Ånd, generate, tune, or select a heuristic (partial search algorithm) that may provide a sufÔ¨Åciently good solution to an optimization problem. In the prementioned comparison,Genetic (GA; Sohail, 2023 ), Equilibrium (EO; Altantawy & Kishk, 2023 ; Houssein et al., 2022 ), Grey Wolf (GWO;Faris et al., 2018 ), Sine cosine (SCA; Zhou et al., 2022 ), and particle swarm algorithms (PSO; Shami et al., 2022 )h a v e been utilized. As demonstrated from Table 8, all assigned metaheuristic algorithms provide a superior performance in the fault type prediction, but the proposed ERD providesthe absolute least feature pool size with the same accuracy, approximately. For the 8-fault type detection problem, the average drop in accuracy from the best performer is 0.63%,while in 9-fault type problem, the average drop in accuracy is 1.22%. In the set of ‚ÄúAll‚Äù, it is noticed that the accuracy degraded a little bit compared to other sets, because of theresizing process of wafer map to a Ô¨Å"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_60", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 60, "text": "pe problem, the average drop in accuracy is 1.22%. In the set of ‚ÄúAll‚Äù, it is noticed that the accuracy degraded a little bit compared to other sets, because of theresizing process of wafer map to a Ô¨Åxed common size whichaffects the shape of fault patterns. Table 8indicates the results 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3385 Fig. 17 Comparison between the performance of SBAE and CAE for the resolution sets: 26 √ó26, 27 √ó25, and All. For more results of other resolution sets, see Table 12in ‚ÄúAppendix ‚Äù. For fair comparison in Tables 8and 12, we have utilized the same population size and seek the parameters that keep the most possible Ô¨Åtting score on all employed metaheuristicalgorithms. The main cause that the proposed ERD selects a smaller number of features is generally the tendency to focus moreon exploitation than other metaheuristic algorithms, such asGA, PSO, EO, GWO, and SCA. The tendency of emphasiz- ing on exploitation rises from the mating behavior of red deer,where the dominant stag (leader) mates with the most fertile hinds. This mechanism symbolizes the selection of featureswith higher Ô¨Åtness, driving the algorithm towards reÔ¨Åning a smaller set "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_61", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 61, "text": "red deer,where the dominant stag (leader) mates with the most fertile hinds. This mechanism symbolizes the selection of featureswith higher Ô¨Åtness, driving the algorithm towards reÔ¨Åning a smaller set of relevant features. In contrast, algorithms like GA and PSO tend to explore the search space more exten-sively, potentially leading to the selection of a larger number of features. This is because their mechanisms encourage the exploration of diverse solutions and the recombination offeatures, which can sometimes introduce less relevant fea-tures into the selected set. While ERD focus on exploitation can be beneÔ¨Åcial in reducing the risk of overÔ¨Åtting, it may 123 3386 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 18 The convergence of Ô¨Åtness over iterations for the traditional red deer in aand the tinkered version in b Table 7 Comparison between the different cases of applying the adopted feature engineering steps, i.e., ERD and SBAE Tested condition Resolution Final feature size/classesAcc Pre Sen F1-score W/O ERD W/O SBAE26√ó26 676/9 76.59 84.67 75.78 75.11 27√ó25 675/8 85.49 80.25 86.87 82.62 30√ó34 1020/9 95.57 96.22 95.67 96 33√ó29 957/9 73.23 0.78 73.33 0.71 W/ ERD "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_62", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 62, "text": "ure size/classesAcc Pre Sen F1-score W/O ERD W/O SBAE26√ó26 676/9 76.59 84.67 75.78 75.11 27√ó25 675/8 85.49 80.25 86.87 82.62 30√ó34 1020/9 95.57 96.22 95.67 96 33√ó29 957/9 73.23 0.78 73.33 0.71 W/ ERD W/O SBAE26√ó26 73/9 98.05 98.22 98.22 98.22 27√ó25 37/8 99.12 99.25 99.13 99.25 30√ó34 280/9 97.57 97.67 97.78 97.67 33√ó29 28/9 94.98 0.95 94.89 94.89 W/O ERD W/ SBAE26√ó26 169/9 93.61 95.33 94.33 94.11 27√ó25 169/8 99.48 99.63 99.38 99.5 30√ó34 169/9 90.33 91.78 90.22 90.22 33√ó29 169/9 99.04 99.11 99.11 99.11 W/ ERD W/ SBAE26√ó26 22/9 98.71 98.78 98.89 98.89 27√ó25 19/8 99.24 99.25 99.25 99.38 30√ó34 23/9 98.17 98.44 98.11 98.11 33√ó29 15/9 98.78 98.89 98.89 98.77 Bold font is used to emphasize the best results also limit the algorithm‚Äôs ability to capture complex rela- tionships between features. This could potentially affect its performance on datasets where such relationships are crucial for accurate prediction or classiÔ¨Åcation. The impact of the classification stage For the prediction stage, different common 1D deep networks(Kiranyaz et al., 2021 ) have been tested, like 1D-VGG16,1D-ResNet50, 1D-LeNet-5, and 1D-Inception, against the proposed 1DCNN. A comparison is set at Table 9between the"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_63", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 63, "text": "fferent common 1D deep networks(Kiranyaz et al., 2021 ) have been tested, like 1D-VGG16,1D-ResNet50, 1D-LeNet-5, and 1D-Inception, against the proposed 1DCNN. A comparison is set at Table 9between these networks. As demonstrated, the 1D-VGG16 provides the best average accuracy of 98.27%, but with larger param-eters which are three times the parameters of the proposed1DCNN which comes in the second place with average accu- racy of 98.08%. The largest parameters and the worst perfor- mance belong to 1D-ResNet50 (16 M, 96.68%). The smallestnumber of parameters, 16 K, belongs to 1D-Inception with 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3387 Fig. 19 Visual classiÔ¨Åcation reports comparison of different conditions of applying the feature engineering steps, i.e., SBAE and ERD, to wafermaps of size 26 √ó26; aW/O ERD and W/O SBAE (676 features), bW/ERD and W/O SBAE (73 features), cW/O ERD and W/ SBAE (169 features), and dW/ ERD and W/ SBAE (22 features) an average accuracy of 97.23%. The introduced 1D-LeNet-5 shows an average accuracy of 97.96% with 240 K numberof parameters. For more computitative results, see Table 13 in ‚Äú Appendix ‚Äù. Figure 21introduces a visual compar"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_64", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 64, "text": " 97.23%. The introduced 1D-LeNet-5 shows an average accuracy of 97.96% with 240 K numberof parameters. For more computitative results, see Table 13 in ‚Äú Appendix ‚Äù. Figure 21introduces a visual comparison between the prementioned classiÔ¨Åer in terms of the classiÔ¨Å- cation report. The main difference between classiÔ¨Åers thataffect the total performance is the recognition metrics of ‚Äúnone‚Äù, ‚Äúloc‚Äù, and ‚Äúedge-loc‚Äù, as the main difÔ¨Åcult fault types in recognition. In Fig. 22, the training and validation losses are indicated over epochs. As shown, the proposed 1DCNN and 1D-LeNet-5 demonstrate the least losses and the small- est gap between validation and training which provides goodgeneralization.Conclusion In this paper, a hybrid deep model for fault type predictionin wafer maps is proposed. The proposed model has tar- geted three objectives. The Ô¨Årst is getting over the highly imbalanced dataset. The second targets obtaining more dis-criminative reduced features in 1D form instead of the 2D form of the original wafer maps. The Ô¨Ånal is an effective classiÔ¨Åer that achieves adequate balance between accuracyand complexity. For the Ô¨Årst objective, a new unsupervised synthetization model as a "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_65", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 65, "text": "form of the original wafer maps. The Ô¨Ånal is an effective classiÔ¨Åer that achieves adequate balance between accuracyand complexity. For the Ô¨Årst objective, a new unsupervised synthetization model as a CAE is proposed which succeeded in reconstructing the inserted wafer maps with a very low lossof 0.0011. For achieving more discriminative features, as the 123 3388 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 20 Train‚Äìvalidation performance of different conditions of apply- ing the feature engineering steps, i.e., SBAE and ERD, to wafer mapsof size 26 √ó26; aW/O ERD and W/O SBAE (676 features), bW/ERD and W/O SBAE (73 features), cW/O ERD and W/ SBAE (169 features), and dW/ ERD and W/ SBAE (22 features) second objective, Ô¨Årstly, a new sparsity-boosted autoencoder (SBAE) is proposed to get sparse encoded maps with 50% reduction in spatial size compared to the original maps. Sec-ondly, an enhanced tinkered red deer optimization (ERD) isapplied to 1D sinograms of the previously obtained sparse maps to get an average Ô¨Ånal 1D feature pool of ~ 25 fea- ture bases (~ 1.5% of the original maps). In an ablationstudy, the adopted feature engineering steps prove efÔ¨Åciency in getti"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_66", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 66, "text": "y obtained sparse maps to get an average Ô¨Ånal 1D feature pool of ~ 25 fea- ture bases (~ 1.5% of the original maps). In an ablationstudy, the adopted feature engineering steps prove efÔ¨Åciency in getting the least possible feature bases with high accu- racy, especially when it is compared to other metaheuristicalgorithms, such as Genetic (GA), Equilibrium (EO), Grey Wolf (GWO), Sine cosine (SCA), and particle swarm (PSO) algorithms. For the third objective, a new 1DCNN modelis proposed for the 9- and 8-fault type prediction, which achieves an average accuracy of 98.1% with 180 K of train- able parameters. The proposed 1DCNN is compared to othercommon 1DCNNs, such as 1D-VGG16 (98.26%, 590 K),1D-ResNet50 (96.7%, 16 M), 1D-LeNet-5 (98%, 240 K), and 1D-Inception (97.23%, 16 K). Despite the achievements of the proposed wafer map inspection model, being a hybriddeep model still increases the computational cost of the inspection procedure. Accordingly, as a future work, we intend to work on the feature engineering steps to reduceits complexity. We will try to extend the proposed detection model to other classiÔ¨Åcation problems in wafer maps and other datasets, as well. 123 Journal of Intell"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_67", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 67, "text": "e feature engineering steps to reduceits complexity. We will try to extend the proposed detection model to other classiÔ¨Åcation problems in wafer maps and other datasets, as well. 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3389 Table 8 Comparison of different common metaheuristic algorithms for the proposed fault detection in wafer maps Wafer map resolution Final feature size/classes Metaheuristic algorithm Acc Pre Sen F1-score 26√ó26 179/9 GA 99.24 99.33 99.33 99.44 229/9 EO 99.32 99.44 99.44 99.56 155/9 SCA 99.21 99.22 99.33 99.33 152/9 GWO 99.16 99.22 99.22 99.22 174/9 PSO 99.11 99.11 99.22 99.11 22/9 ERD 98.71 98.78 98.89 98.89 27√ó25 152/8 GA 99.66 99.75 99.63 99.63 201/8 EO 99.70 99.63 99.75 99.88 190/8 SCA 99.70 99.75 99.75 99.75 154/8 GWO 99.70 99.75 99.75 99.75 157/8 PSO 99.73 99.75 99.75 99.75 19/8 ERD 99.24 99.25 99.25 99.38 All (26 √ó26) 199/9 GA 97.20 97.22 97.22 97.22 245/9 EO 97.29 97.44 97.33 97.22299/9 SCA 97.43 97.78 97.33 97.44 200/9 GWO 97.21 97.33 97.22 97.22 225/9 PSO 97.81 97.67 97.89 97.89 45/9 ERD 95.15 95.11 95.11 95 Bold font is used to emphasize the best results Table 9 Comparison of different common 1D CNNs for the proposed fault detection"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_68", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 68, "text": "22 97.22 225/9 PSO 97.81 97.67 97.89 97.89 45/9 ERD 95.15 95.11 95.11 95 Bold font is used to emphasize the best results Table 9 Comparison of different common 1D CNNs for the proposed fault detection in wafer maps Wafer map resolution Final feature size/classes ClassiÔ¨Åcation technique Acc Pre Sen F1-score No of parameters 26√ó26 22/9 1D-VGG16 98.86 98.89 99 99 594 K 1D-ResNet50 97.84 97.89 98.11 98 16 M 1D-LeNet-5 98.48 98.67 98.67 98.67 244 K 1D-Inception 98.20 98.33 98.56 98.33 15 K Our 1DCNN 98.71 98.78 98.89 98.89 175 K 27√ó25 19/8 1D-VGG16 98.96 99.22 99 99 561 K 1D-ResNet50 97.93 98 98 98 16 M 1D-LeNet-5 98.87 99 98.88 98.88 211 K 1D-Inception 99.18 99.25 99.25 99.25 15 K Our 1DCNN 99.24 99.25 99.25 99.38 175 K 30√ó34 23/9 1D-VGG16 98.36 98.56 98.33 98.33 594 K 1D-ResNet50 97.31 97.78 97.33 97.11 16 M 1D-LeNet-5 97.97 98.22 97.89 97.78 244 K 1D-Inception 97.91 98.11 97.89 97.89 16 K Our 1DCNN 98.17 98.44 98.11 98.11 176 K Bold font is used to emphasize the best results 123 3390 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 21 Visual classiÔ¨Åcation reports of different 1D deep classiÔ¨Åer for the prediction of fault type in wafer maps with resolution of 26 √ó26. a1D-"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_69", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 69, "text": "rnal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Fig. 21 Visual classiÔ¨Åcation reports of different 1D deep classiÔ¨Åer for the prediction of fault type in wafer maps with resolution of 26 √ó26. a1D-VGG-16, b1D-ResNet50, c1D-LeNet-5, d1D-Inception, and ethe proposed 1DCNN 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3391 Fig. 22 Visual classiÔ¨Åcation reports of different 1D deep classiÔ¨Åer for the prediction of fault type in wafer maps with resolution of 26 √ó26. a1D-VGG-16, b1D-ResNet50, c1D-LeNet-5, d1D-Inception, and ethe proposed 1DCNN 123 3392 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adap-tation, distribution and reproduction in any medium or format, aslong as you give appropriate credit to the original author(s) and thesource, provide a link to the Creative Commons licence, and indi-cate if changes were made. The images or other third party materialin this article are included in the article‚Äôs Creative Commons licence,unless indicated otherwise in a credit line to the material. If materialis not included in the article‚Äô"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_70", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 70, "text": "other third party materialin this article are included in the article‚Äôs Creative Commons licence,unless indicated otherwise in a credit line to the material. If materialis not included in the article‚Äôs Creative Commons licence and yourintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copy-right holder. To view a copy of this licence, visit http://creativecomm ons.org/licenses/by/4.0/ . Table 10 Computitative comparison between the performance of different resolutions of wafer maps at different split ratio Wafer map resolution Final feature size/classes Acc Pre Sen F1-score Sample size Train‚Äìvalid‚Äìtest 26√ó26 22/9 98.71 98.78 98.89 98.89 19,707 60:20:20 96.68 96.88 97 96.78 36:15:49 94.32 94.56 94.78 94.56 23:15:62 29√ó26 22/9 98.85 98.89 98.89 99 19,143 60:20:20 98.37 98.44 98.56 98.33 36:15:49 97.19 97.22 97.33 97.22 23:15:62 30√ó34 23/9 98.17 98.44 98.11 98.11 19,174 60:20:20 97.93 98.11 98 98.22 36:15:49 95.39 95.78 95.56 95.56 23:15:62 All (26 √ó26) 45/9 95.15 95.11 95.11 95 32,472 60:20:20 92.80 92.88 92.88 92.78 36:15:49 89.70 89.78 89.67 89.56 23:15:62 Bold font is used to emphasize the best r"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_71", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 71, "text": "5:49 95.39 95.78 95.56 95.56 23:15:62 All (26 √ó26) 45/9 95.15 95.11 95.11 95 32,472 60:20:20 92.80 92.88 92.88 92.78 36:15:49 89.70 89.78 89.67 89.56 23:15:62 Bold font is used to emphasize the best results Table 11 Comparison between the different cases of applying the adopted feature engineering steps, i.e., ERD and SBAE Tested condition Resolution Final feature size/classes Acc Pre Sen F1-score W/O ERD W/O SBAE29√ó26 754/9 87.26 81.55 87 83.22 27√ó25 675/8 85.49 80.25 86.87 82.62 39√ó37 1443/9 85.45 79.78 85.56 81.89 All 676/9 80.17 82.89 79.78 80.11 W/ ERD W/O SBAE29√ó26 104/9 98.49 98.59 98.69 98.56 27√ó25 37/8 99.12 99.25 99.13 99.25 39√ó37 256/9 97.01 97.33 97.11 97.22 All 76/9 92.32 92.44 92.11 92.11 W/O ERD W/ SBAE29√ó26 169/9 97.83 98.11 98.33 98.33 27√ó25 169/8 99.48 99.63 99.38 99.5 39√ó37 169/9 92.80 94.11 92.89 92.89 All 169/9 93.49 94.11 93.56 93.67 W/ ERD W/ SBAE29√ó26 22/9 98.85 98.89 98.89 99 27√ó25 19/8 99.24 99.25 99.25 99.38 39√ó37 27/9 97.37 97.89 97.22 97.33 All 45/9 95.15 95.11 95.11 95 Bold font is used to emphasize the best results 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3393 Table 12 Comparison of different common metaheuristic algorithms for the"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_72", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 72, "text": "5.11 95.11 95 Bold font is used to emphasize the best results 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3393 Table 12 Comparison of different common metaheuristic algorithms for the proposed fault detection in wafer maps Wafer map resolution Final feature size/classes Metaheuristic algorithm Acc Pre Sen F1-score 25√ó27 168/8 GA 99.22 99.25 99.25 99.25 216/8 EO 99.19 99.38 99.25 99.13 162/8 SCA 99.31 99.38 99.25 99.25 223/8 GWO 99.16 99.25 99.25 99.25 174/8 PSO 99.19 99.25 99.25 99.25 22/8 ERD 98.36 98.37 98.37 98.5 29√ó26 152/9 GA 99.53 99.67 99.56 99.67 215/9 EO 99.58 99.67 99.67 99.67 165/9 SCA 99.63 99.67 99.67 99.67 167/9 GWO 99.61 99.67 99.67 99.56 175/9 PSO 99.61 99.67 99.67 99.67 22/9 ERD 98.85 98.89 98.89 99 30√ó34 164/9 GA 99.30 99.33 99.22 99.44 219/9 EO 99.40 99.44 99.44 99.44181/9 SCA 99.19 99.22 99.22 99.22 185/9 GWO 99.22 99.33 99.22 99.22 175/9 PSO 99.37 99.44 99.44 99.44 23/9 ERD 98.17 98.44 98.11 98.11 39√ó37 211/9 GA 98.42 98.78 98.56 98.44 221/9 EO 98.27 98.67 98.22 98.44 180/9 SCA 98.54 98.78 98.56 98.67 197/9 GWO 98.04 98.33 98.11 98.11 191/9 PSO 98.19 98.44 98.22 98.33 27/9 ERD 97.37 97.89 97.22 97.33 33√ó29 164/9 GA 99.68 99.78 99.78 99.78 217/9"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_73", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 73, "text": "27 98.67 98.22 98.44 180/9 SCA 98.54 98.78 98.56 98.67 197/9 GWO 98.04 98.33 98.11 98.11 191/9 PSO 98.19 98.44 98.22 98.33 27/9 ERD 97.37 97.89 97.22 97.33 33√ó29 164/9 GA 99.68 99.78 99.78 99.78 217/9 EO 99.41 99.44 99.44 99.56 153/9 SCA 99.47 99.56 99.44 99.44 152/9 GWO 99.39 99.44 99.44 99.33 166/9 PSO 99.39 99.33 99.44 99.44 15/9 ERD 98.78 98.89 98.89 98.77 Bold font is used to emphasize the best results Appendix Tables 10,11,12, and 13corresponds the Tables 6,7,8, and 9. They just show results at different other resolutions rather than those employed in Tables 6,7,8, and 9in the main text. Table 10indicates computitative comparison between the performance of different resolutions of wafer maps (26 √ó 26, 29 √ó26, 30 √ó34, and All) at different split ratios through the proposed inspection model. Table 11demonstrates com- parison between the different cases of applying the adoptedfeature engineering steps, i.e., ERD and SBAE, at resolutions (29√ó26, 27 √ó25, 39 √ó37, All). Table 12introduces com- parison of different common metaheuristic algorithms for theproposed fault detection in wafer maps, for resolutions (25√ó27, 29 √ó26, 30 √ó34, 39 √ó37, and 33 √ó29). Table 13 presents Comparison of"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_74", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 74, "text": "es com- parison of different common metaheuristic algorithms for theproposed fault detection in wafer maps, for resolutions (25√ó27, 29 √ó26, 30 √ó34, 39 √ó37, and 33 √ó29). Table 13 presents Comparison of different common 1D CNNs for the proposed fault detection in wafer maps, at resolutions (25 √ó 27, 29 √ó26, 39 √ó37, 33 √ó29, and All). Table 10,11,12, and 13resemble/correspond the set of Tables 6,7,8, and 123 3394 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 Table 13 Comparison of different common 1D CNNs for the proposed fault detection in wafer maps Wafer map resolution Final feature size/classes ClassiÔ¨Åcation technique Acc Pre Sen F1-score No of parameters 25√ó27 22/8 1D-VGG16 98.38 98.5 98.5 98.5 594 K 1D-ResNet50 96.36 96.5 96.38 96.38 16 M 1D-LeNet-5 97.66 97.88 97.75 97.63 244 K 1D-Inception 97.03 97 97.13 97.13 15 K Our 1DCNN 98.36 98.37 98.37 98.5 175 K 29√ó26 22/9 1D-VGG16 99.16 99.22 99.22 99.22 594 K 1D-ResNet50 97.26 97.67 97.44 97.33 16 M 1D-LeNet-5 98.56 98.78 98.67 98.56 244 K 1D-Inception 97.73 97.78 97.78 97.78 16 K Our 1DCNN 98.85 98.89 98.89 99 176 K 39√ó37 27/9 1D-VGG16 96.86 97.67 96.78 96.78 626 K 1D-ResNet50 96.34 97 96.22 97.22 16 M 1D-LeNet-5 97.01 97."}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_75", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 75, "text": " 98.56 244 K 1D-Inception 97.73 97.78 97.78 97.78 16 K Our 1DCNN 98.85 98.89 98.89 99 176 K 39√ó37 27/9 1D-VGG16 96.86 97.67 96.78 96.78 626 K 1D-ResNet50 96.34 97 96.22 97.22 16 M 1D-LeNet-5 97.01 97.56 96.89 97 277 K 1D-Inception 96.76 97.22 96.67 96.67 16 KOur 1DCNN 97.37 97.89 97.22 97.33 208 K 33√ó29 15/9 1D-VGG16 99.04 99.11 99 99.11 528 K 1D-ResNet50 97.01 97.11 97.11 97.11 16 M 1D-LeNet-5 98.88 98.78 99 98.89 178 K 1D-Inception 98.08 0.98 98.22 98.33 16 K Our 1DCNN 98.78 98.89 98.89 98.77 176 K All (26 √ó26) 45/9 1D-VGG16 96.51 96.67 96.56 96.44 626 K 1D-ResNet50 93.41 93.44 93.22 93.33 16 M 1D-LeNet-5 96.21 96.22 96.11 96.11 277 K 1D-Inception 92.95 93.22 92.89 92.78 16 K Our 1DCNN 95.15 95.11 95.11 95 176 K Bold font is used to emphasize the best results 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3395 Table 14 Glossary of the main variables/functions/parameters in this paper V ariable Annotation V ariable Annotation X The original grey wafer map respectively of size (m,n)XsAre the resultant encoded sparse maps from SBAE XX The one-hot encoded colored wafer map of size (m,n,c)ys,Ysysof size of size/parenleftbig 1√ómnc 4/parenrightbig is 1D sinogram of the pre"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_76", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 76, "text": " size (m,n)XsAre the resultant encoded sparse maps from SBAE XX The one-hot encoded colored wafer map of size (m,n,c)ys,Ysysof size of size/parenleftbig 1√ómnc 4/parenrightbig is 1D sinogram of the previous 2D sparse map Xs,s of o r N samples, we have sinogramic feature pool Ys of size/parenleftbig N√ómnc 4/parenrightbig X The synthesized wafer map after Ô¨Åxing the imbalance problem of size ( m,n,c)Is a group of vertical features from Ys. Ys/equal1/bracketleftBig y1,y2,...,ymnc 4/bracketrightBig . Ys/equal1/bracketleftbig ys 1,ys 2,...,ys N/bracketrightbigT.ys iis a sparse encoded sample. yiis a sparse encoded feature vector H The convolutional output of a hidden layer f Is the employed Ô¨Åtness function in ERD algorithm Hc The convolutional output of a hidden layer after MaxPooling ‚Äúdown sampling‚Äù operationuand/lscript Are the upper and lower limits of local search of neighboring solutions in ERD W,B,A The employed weights, bias, and activation function(Œ±1,Œ±2,Œ±3,Œ¥); (Œ≤1, Œ≤2)Are randomly generated coefÔ¨Åcients from a uniform distribution that ranges from 0 to 1 inthe roaring and Ô¨Åghting phases respectively N The total number of wafer maps after synthetization Is the number of selected fe"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_77", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 77, "text": "nerated coefÔ¨Åcients from a uniform distribution that ranges from 0 to 1 inthe roaring and Ô¨Åghting phases respectively N The total number of wafer maps after synthetization Is the number of selected features under the category i‚àà{stag ,com ,hind ,male} C(W,B) Is the cost function of Sparsity-boosted autoencoder (SBAE)Gi Is the grouped features under the category i‚àà{stag ,com ,hind ,OS,tink} K/parenleftbig P/bardbl/hatwideP/parenrightbig is Kullback‚ÄìLeibler divergence v Is the diversity in Ô¨Åtting between the tinkered harem and the tinkering harem and itsthreshold value Œ∂is used to check how the new offspring RDs, G OS, are generated P,/hatwidePP is the targeted or assigned sparsity, while /hatwidePis average output of all hidden neurons (the actualresultant sparsity amount)n ÀÜIs a Ô¨Åxed number of harems to be updated within each iteration K,Œ≥ Are weighting coefÔ¨Åcients in C(W,B) Œ∏ Is a random number between 0 and 1 in the mating phase 9. Table 10,11,12, and 13just shows results at different resolutions rather than those mentioned in the main text in Tables 6,7,8, and 9. Table 14indicates summary of the main variables/parameters/functions mentioned in this paper. Author contributions Al"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_78", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 78, "text": "t resolutions rather than those mentioned in the main text in Tables 6,7,8, and 9. Table 14indicates summary of the main variables/parameters/functions mentioned in this paper. Author contributions All persons who meet authorship criteria are listed as authors, and all authors certify that they have participated sufÔ¨Å-ciently in the work to take public responsibility for the content, includingparticipation in the concept, design, analysis, writing, or revision of themanuscript. Funding Open access funding provided by The Science, Technology & Innovation Funding Authority (STDF) in cooperation with The Egyp-tian Knowledge Bank (EKB). Data availability All employed datasets are open source and have been cited in this paper.Declarations ConÔ¨Çict of interest The authors declare that they have no known com- peting Ô¨Ånancial interests or personal relationships that could haveappeared to inÔ¨Çuence the work reported in this paper. Ethical approval This article does not contain any studies with human participants or animals performed by any of the authors. 123 3396 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 References Abdel-Basset, M., Abdel-Fatah, L., & Sangaiah, A. K. (2018). Me"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_79", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 79, "text": "an participants or animals performed by any of the authors. 123 3396 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 References Abdel-Basset, M., Abdel-Fatah, L., & Sangaiah, A. K. (2018). Meta- heuristic algorithms: A comprehensive review. In Computational intelligence for multimedia big data on the cloud with engineer-ing applications (pp. 185‚Äì231). https://doi.org/10.1016/b978-0- 12-813314-9.00010-4 Alam, L., & Kehtarnavaz, N. (2022). A survey of detection methods for die attachment and wire bonding defects in integrated circuitmanufacturing. IEEE Access, 10 , 83826‚Äì83840. https://doi.org/ 10.1109/access.2022.3197624 Alqudah, R., Al-Mousa, A. A., Hashyeh, Y . A., & Alzaibaq, O. Z. (2023). A systemic comparison between using augmented dataand synthetic data as means of enhancing wafer map defect clas-siÔ¨Åcation. Computers in Industry, 145 , 103809. https://doi.org/10. 1016/j.compind.2022.103809 Altantawy, D. A., & Kishk, S. S. (2023). Equilibrium-based COVID- 19 diagnosis from routine blood tests: A sparse deep convolutionalmodel. Expert Systems with Applications, 213 , 118935. https://doi. org/10.1016/j.eswa.2022.118935 Baly, R., & Hajj, H. (2012). Wafer classiÔ¨Åcation us"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_80", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 80, "text": "m routine blood tests: A sparse deep convolutionalmodel. Expert Systems with Applications, 213 , 118935. https://doi. org/10.1016/j.eswa.2022.118935 Baly, R., & Hajj, H. (2012). Wafer classiÔ¨Åcation using support vector machines. IEEE Transactions on Semiconductor Manufacturing, 25(3), 373‚Äì383. https://doi.org/10.1109/tsm.2012.2196058 Chen, S., Zhang, Y ., Hou, X., Shang, Y ., & Yang, P . (2022). Wafer map failure pattern recognition based on deep convolutional neuralnetwork. Expert Systems with Applications, 209 , 118254. https:// doi.org/10.1016/j.eswa.2022.118254 Chen, S., Zhang, Y ., Yi, M., Shang, Y ., & Yang, P . (2021). AI clas- siÔ¨Åcation of wafer map defect patterns by using dual-channelconvolutional neural network. Engineering Failure Analysis, 130 , 105756. https://doi.org/10.1016/j.engfailanal.2021.105756 Cheng, K. C. C., Chen, L. L. Y ., Li, J. W., Li, K. S. M., Tsai, N. C. Y ., Wang, S. J., Huang, A. Y . A., Chou, L., Lee, C. S., Chen, J. E.,& Liang, H. C. (2021). Machine learning-based detection methodfor wafer test induced defects. IEEE Transactions on Semiconduc- tor Manufacturing, 34 (2), 161‚Äì167. https://doi.org/10.1109/tsm. 2021.3065405 Chu, M., Park, S., Jeong, J"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_81", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 81, "text": "earning-based detection methodfor wafer test induced defects. IEEE Transactions on Semiconduc- tor Manufacturing, 34 (2), 161‚Äì167. https://doi.org/10.1109/tsm. 2021.3065405 Chu, M., Park, S., Jeong, J., Joo, K., Lee, Y ., & Kang, J. (2022). Recognition of unknown wafer defect via optimal bin embeddingtechnique. The International Journal of Advanced Manufactur- ing Technology, 121 (5‚Äì6), 3439‚Äì3451. https://doi.org/10.1007/ s00170-022-09447-y Faris, H., Aljarah, I., Al-Betar, M. A., & Mirjalili, S. (2018). Grey wolf optimizer: A review of recent variants and applications. Neu- ral Computing and Applications, 30 , 413‚Äì435. https://doi.org/10. 1007/s00521-017-3272-5 Fathollahi-Fard, A. M., Hajiaghaei-Keshteli, M., & Tavakkoli- Moghaddam, R. (2020). Red deer algorithm (RDA): A newnature-inspired meta-heuristic. Soft Computing, 24 , 14637‚Äì14665. https://doi.org/10.1007/s00500-020-04812-z Houssein, E. H., √áelik, E., Mahdy, M. A., & Ghoniem, R. M. (2022). Self-adaptive Equilibrium Optimizer for solving global, combina-torial, engineering, and Multi-Objective problems. Expert Systems with Applications, 195 , 116552. https://doi.org/10.1016/j.eswa. 2022.116552 Jin, C. H., Kim, H. J., Piao, Y"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_82", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 82, "text": "r solving global, combina-torial, engineering, and Multi-Objective problems. Expert Systems with Applications, 195 , 116552. https://doi.org/10.1016/j.eswa. 2022.116552 Jin, C. H., Kim, H. J., Piao, Y ., Li, M., & Piao, M. (2020). Wafer map defect pattern classiÔ¨Åcation based on convolutional neuralnetwork features and error-correcting output codes. Journal of Intelligent Manufacturing, 31 (8), 1861‚Äì1875. https://doi.org/10. 1007/s10845-020-01540-x Jin, C. H., Na, H. J., Piao, M., Pok, G., & Ryu, K. H. (2019). A novel DBSCAN-based defect pattern detection and classiÔ¨Åcationframework for wafer bin map. IEEE Transactions on Semiconduc- tor Manufacturing, 32 (3), 286‚Äì292. https://doi.org/10.1109/tsm. 2019.2916835Kang, H., & Kang, S. (2021). A stacking ensemble classiÔ¨Åer with handcrafted and convolutional features for wafer map pattern clas-siÔ¨Åcation. Computers in Industry, 129 , 103450. https://doi.org/10. 1016/j.compind.2021.103450 Kim, D., & Kang, P . (2021). Dynamic clustering for wafer map patterns using self-supervised learning on convolutional autoen-coders. IEEE Transactions on Semiconductor Manufacturing, 34(4), 444‚Äì454. https://doi.org/10.1109/tsm.2021.3107720 Kim, T., & Behdin"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_83", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 83, "text": "map patterns using self-supervised learning on convolutional autoen-coders. IEEE Transactions on Semiconductor Manufacturing, 34(4), 444‚Äì454. https://doi.org/10.1109/tsm.2021.3107720 Kim, T., & Behdinan, K. (2023). Advances in machine learning and deep learning applications towards wafer map defect recognitionand classiÔ¨Åcation: A review. Journal of Intelligent Manufacturing . https://doi.org/10.1007/s10845-022-01994-1 Kim, T. S., Lee, J. W., Lee, W. K., & Sohn, S. Y . (2021). Novel method for detection of mixed-type defect patterns in wafer maps basedon a single shot detector algorithm. Journal of Intelligent Manu- facturing .https://doi.org/10.1007/s10845-021-01755-6 Kiranyaz, S., Avci, O., Abdeljaber, O., Ince, T., Gabbouj, M., & Inman, D. J. (2021). 1D convolutional neural networks and applications: Asurvey. Mechanical Systems and Signal Processing, 151 , 107398. https://doi.org/10.1016/j.ymssp.2020.107398 Kyeong, K., & Kim, H. (2018). ClassiÔ¨Åcation of mixed-type defect pat- terns in wafer bin maps using convolutional neural networks. IEEE Transactions on Semiconductor Manufacturing, 31 (3), 395‚Äì402. https://doi.org/10.1109/tsm.2018.2841416 Leavers, V . F. (1992). Use of the Rad"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_84", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 84, "text": "n wafer bin maps using convolutional neural networks. IEEE Transactions on Semiconductor Manufacturing, 31 (3), 395‚Äì402. https://doi.org/10.1109/tsm.2018.2841416 Leavers, V . F. (1992). Use of the Radon transform as a method of extracting information about shape in two dimensions. Image and Vision Computing, 10 (2), 99‚Äì107. https://doi.org/10.1016/0262- 8856(92)90004-m Lee, S. H., Koo, H. I., & Cho, N. I. (2010). New automatic defect clas- siÔ¨Åcation algorithm based on a classiÔ¨Åcation-after-segmentationframework. Journal of Electronic Imaging, 19 (2), 020502. https:// doi.org/10.1117/1.3429116 Li, P ., Pei, Y ., & Li, J. (2023). A comprehensive survey on design and application of autoencoder in deep learning. Applied Soft Comput- ing.https://doi.org/10.1016/j.asoc.2023.110176 Liu, C. W., & Chien, C. F. (2013). An intelligent system for wafer bin map defect diagnosis: An empirical study for semiconduc-tor manufacturing. Engineering Applications of ArtiÔ¨Åcial Intel- ligence, 26 (5‚Äì6), 1479‚Äì1486. https://doi.org/10.1016/j.engappai. 2012.11.009 Nag, S., Makwana, D., Mittal, S., & Mohan, C. K. (2022). WaferSeg- ClassNet‚ÄîA light-weight network for classiÔ¨Åcation and segmen-tation of semicon"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_85", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 85, "text": "‚Äì1486. https://doi.org/10.1016/j.engappai. 2012.11.009 Nag, S., Makwana, D., Mittal, S., & Mohan, C. K. (2022). WaferSeg- ClassNet‚ÄîA light-weight network for classiÔ¨Åcation and segmen-tation of semiconductor wafer defects. Computers in Industry, 142 , 103720. https://doi.org/10.1016/j.compind.2022.103720 Ng, A. (2011). Sparse autoencoder. CS294A Lecture Notes , 72, 1‚Äì19. https://graphics.stanford.edu/courses/cs233-21-spring/ ReferencedPapers/SAE.pdf Saqlain, M., Jargalsaikhan, B., & Lee, J. Y . (2019). A voting ensem- ble classiÔ¨Åer for wafer map defect patterns identiÔ¨Åcation insemiconductor manufacturing. IEEE Transactions on Semicon- ductor Manufacturing, 32 (2), 171‚Äì182. https://doi.org/10.1109/ tsm.2019.2904306 Shami, T. M., El-Saleh, A. A., Alswaitti, M., Al-Tashi, Q., Summakieh, M. A., & Mirjalili, S. (2022). Particle swarm optimization: A com-prehensive survey. IEEE Access, 10 , 10031‚Äì10061. https://doi.org/ 10.1109/access.2022.3142859 Shankar, N. G., & Zhong, Z. W. (2005). Defect detection on semi- conductor wafer surfaces. Microelectronic Engineering, 77 (3‚Äì4), 337‚Äì346. https://doi.org/10.1016/j.mee.2004.12.003 Shin, W., Kahng, H., & Kim, S. B. (2022). Mixup-based classiÔ¨Åca-"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_86", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 86, "text": " detection on semi- conductor wafer surfaces. Microelectronic Engineering, 77 (3‚Äì4), 337‚Äì346. https://doi.org/10.1016/j.mee.2004.12.003 Shin, W., Kahng, H., & Kim, S. B. (2022). Mixup-based classiÔ¨Åca- tion of mixed-type defect patterns in wafer bin maps. Computers and Industrial Engineering, 167 , 107996. https://doi.org/10.1016/ j.cie.2022.107996 Sohail, A. (2023). Genetic algorithms in the Ô¨Åelds of artiÔ¨Åcial intelligence and data sciences. Annals of Data Science, 10 (4), 1007‚Äì1018. https://doi.org/10.1007/s40745-021-00354-9 123 Journal of Intelligent Manufacturing (2025) 36:3359‚Äì3397 3397 Sun, Y ., Song, Q., & Liang, F. (2022). Consistent sparse deep learning: Theory and computation. Journal of the American Statistical Asso- ciation, 117 (540), 1981‚Äì1995. https://doi.org/10.1080/01621459. 2021.1895175 Theodosiou, T., Rapti, A., Papageorgiou, K., Tziolas, T., Papageorgiou, E., Dimitriou, N., Margetis, G., & Tzovaras, D. (2023). A reviewstudy on ML-based methods for defect-pattern recognition in wafermaps. Procedia Computer Science, 217 , 570‚Äì583. https://doi.org/ 10.1016/j.procs.2022.12.253 V an der Maaten, L., & Hinton, G. (2008). Visualizing data using t- SNE. Journal of Machine"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_87", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 87, "text": "gnition in wafermaps. Procedia Computer Science, 217 , 570‚Äì583. https://doi.org/ 10.1016/j.procs.2022.12.253 V an der Maaten, L., & Hinton, G. (2008). Visualizing data using t- SNE. Journal of Machine Learning Research, 9 (11). http://jmlr. org/papers/v9/vandermaaten08a.html Wang, F. K., Chou, J. H., & Amogne, Z. E. (2022). A deep convolu- tional neural network with residual blocks for wafer map defectpattern recognition. Quality and Reliability Engineering Interna- tional, 38 (1), 343‚Äì357. https://doi.org/10.1002/qre.2983 Wang, S., Zhong, Z., Zhao, Y ., & Zuo, L. (2021). A variational autoen- coder enhanced deep learning model for wafer defect imbalancedclassiÔ¨Åcation. IEEE Transactions on Components, Packaging and Manufacturing Technology, 11 (12), 2055‚Äì2060. https://doi.org/ 10.1109/tcpmt.2021.3126083 WM-811K (2014). Retrieved March 15, 2014, from https://www. kaggle.com/datasets/qingyi/wm811k-wafer-map Wu, M. J., Jang, J. S. R., & Chen, J. L. (2014). Wafer map failure pattern recognition and similarity ranking for large-scale data sets.IEEE Transactions on Semiconductor Manufacturing, 28 (1), 1‚Äì12. https://doi.org/10.1109/tsm.2014.2364237 Xu, Q., Y u, N., & Hasan, M. M. (2023). "}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_88", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 88, "text": "ition and similarity ranking for large-scale data sets.IEEE Transactions on Semiconductor Manufacturing, 28 (1), 1‚Äì12. https://doi.org/10.1109/tsm.2014.2364237 Xu, Q., Y u, N., & Hasan, M. M. (2023). Evolutionary computation- based reliability quantiÔ¨Åcation and its application in big dataanalysis on semiconductor manufacturing. Applied Soft Comput- ing, 136 , 110080. https://doi.org/10.1016/j.asoc.2023.110080 Xuen, L. S., Mohd Khairuddin, I., Mohd Razman, M. A., Mat Jizat, J. A., Y uen, E., Jiang, H., Yap, E. H., & Abdul Majeed, P . P . A.(2022, December). The classiÔ¨Åcation of wafer defects: A supportvector machine with different DenseNet transfer learning modelsevaluation. In International conference on robot intelligence tech- nology and applications (pp. 304‚Äì309). Springer. https://doi.org/ 10.1007/978-3-031-26889-2_27 Yan, J., Sheng, Y ., & Piao, M. (2023). Semantic segmentation based wafer map mixed-type defect pattern recognition. IEEE Trans- actions on Computer-Aided Design of Integrated Circuits andSystems .https://doi.org/10.1109/tcad.2023.3274958 Y oon, S., & Kang, S. (2022). Semi-automatic wafer map pattern clas- siÔ¨Åcation with convolutional neural networks. Computers an"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_89", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 89, "text": "ntegrated Circuits andSystems .https://doi.org/10.1109/tcad.2023.3274958 Y oon, S., & Kang, S. (2022). Semi-automatic wafer map pattern clas- siÔ¨Åcation with convolutional neural networks. Computers and Industrial Engineering, 166 , 107977. https://doi.org/10.1016/j. cie.2022.107977Y u, J., Shen, Z., & Wang, S. (2021b). Wafer map defect recogni- tion based on deep transfer learning-based densely connectedconvolutional network and deep forest. Engineering Applications of ArtiÔ¨Åcial Intelligence, 105 , 104387. https://doi.org/10.1016/j. engappai.2021.104387 Y u, J., Li, S., Shen, Z., Wang, S., Liu, C., & Li, Q. (2021a). Deep transfer Wasserstein adversarial network for wafer map defect recognition.Computers and Industrial Engineering, 161 , 107679. https://doi. org/10.1016/j.cie.2021.107679 Y u, J., Zheng, X., & Liu, J. (2019). Stacked convolutional sparse denoising auto-encoder for identiÔ¨Åcation of defect patterns insemiconductor wafer map. Computers in Industry, 109 , 121‚Äì133. https://doi.org/10.1016/j.compind.2019.04.015 Y u, N., Chen, H., Xu, Q., Hasan, M. M., & Sie, O. (2022). Wafer map defect patterns classiÔ¨Åcation based on a lightweight network anddata augmentation. CAAI Transac"}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_90", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 90, "text": "i.org/10.1016/j.compind.2019.04.015 Y u, N., Chen, H., Xu, Q., Hasan, M. M., & Sie, O. (2022). Wafer map defect patterns classiÔ¨Åcation based on a lightweight network anddata augmentation. CAAI Transactions on Intelligence Technology . https://doi.org/10.1049/cit2.12126 Y u, N. G., Xu, Q., Wang, H. L., & Lin, J. (2021c). Wafer bin map inspec- tion based on DenseNet. Journal of Central South University, 28(8), 2436‚Äì2450. https://doi.org/10.1007/s11771-021-4778-7 Zhang, Q., Zhang, Y ., Li, J., & Li, Y . (2022). WDP-BNN: EfÔ¨Åcient wafer defect pattern classiÔ¨Åcation via binarized neural network. Integration, 85 , 76‚Äì86. https://doi.org/10.1016/j.vlsi.2022.04.003 Zheng, H., Sherazi, S. W. A., Son, S. H., & Lee, J. Y . (2021). A deep convolutional neural network-based multi-class image classiÔ¨Åca-tion for automatic wafer map failure recognition in semiconductormanufacturing. Applied Sciences, 11 (20), 9769. https://doi.org/10. 3390/app11209769 Zhou, W., Wang, P ., Heidari, A. A., Zhao, X., & Chen, H. (2022). Spiral Gaussian mutation sine cosine algorithm: Framework andcomprehensive performance optimization. Expert Systems with Applications, 209 , 118372. https://doi.org/10.1016/j.eswa.2022."}
{"id": "Sparse deep encoded features with enhanced sinogramic red deer.pdf::chunk_91", "source": "Sparse deep encoded features with enhanced sinogramic red deer.pdf", "chunk_index": 91, "text": "en, H. (2022). Spiral Gaussian mutation sine cosine algorithm: Framework andcomprehensive performance optimization. Expert Systems with Applications, 209 , 118372. https://doi.org/10.1016/j.eswa.2022. 118372 Publisher‚Äôs Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional afÔ¨Åliations. 123"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_0", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 0, "text": "1Speed Binning Aware Design Methodology to Improve Profit under Parameter Variations * Animesh Datta, Swarup Bhunia1, Jung Hwan Choi, Saibal Mukhopadhyay, and Kaushik Roy School of ECE, Purdue University, IN 47907, USA, <adatta, choi56, sm, kaushik> @ecn.purdue.edu Dept EECS, Case Western Reserve University, Cleveland, OH 44106, USA, Swarup.Bhunia@case.edu Abstract ‚ÄîDesigning high-performance systems with high yield under parameter variations has raised serious design challenges in nanometer technologies. In this paper, we propose a profit-aware yield model, based on which we present a statistical design methodology to improve profit of a design considering frequency binning and product price profile. A low-complexity sensitivity-based gate sizing algorithm is developed to improve the profitability of design over an initial yield-optimized design. We also propose an algorithm to determine optimal bin boundaries for maximizing profit with frequency binning. Finally, we present an integrated design methodology for simultaneous sizing and bin placement to enhance profit under an area constraint. Experiments on a set of ISCAS85 benchmarks show up to 26% (36%) improvement in profit for "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_1", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 1, "text": "ated design methodology for simultaneous sizing and bin placement to enhance profit under an area constraint. Experiments on a set of ISCAS85 benchmarks show up to 26% (36%) improvement in profit for fixed bin (for simultaneous sizing and bin placement) with three frequency bins considering both leakage and delay bounds compared to a design optimized for 90% yield at iso-area. 1. INTRODUCTION Aggressive technology scaling has led to large uncertainties in device and interconnects characteristics for nano-scaled circuits [1]. Increasing variations (both inter-die and intra-die) in device parameters (channel length, gate width, oxide thickness, device threshold voltage etc.) produce large spread in the speed and leakage power consumption of integrated circuits (ICs) [1, 3]. Fig. 1 shows the distribution of operating frequency and leakage current over a large number of high-end micro-processor chips [3]. From the figure, it can be observed that a mature silicon technology like 130nm suffers from about 30 % variation in maximum allowable frequency of operation and about 5 X variation in leakage power .For newer technologies, the variations are reported to be much higher with about 20 X"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_2", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 2, "text": "rs from about 30 % variation in maximum allowable frequency of operation and about 5 X variation in leakage power .For newer technologies, the variations are reported to be much higher with about 20 X variation in leakage power for 90nm technology [3]. Consequently, parametric yield of a circuit (probability to meet the desired performance or power specification) is expected to suffer considerably, unless an overly pessimistic worst-case design approach is followed. Therefore, design of high-performance circuits maintaining or enhancing yield under parameter variations has emerged as a major challenge in nano-scaled technologies [3]. In recent years, statistical analysis of timing and power has been extensively explored [2, 5, 8]. Several parametric yield models have been proposed to consider impact of different sources of variations on circuit delay and power [5, 6]. At the same time, multiple efforts have been made to develop statistical design methodology that either ensures or enhances parametric yield (e.g. with respect to delay or power) under specific design constraint (e.g. on area or power) [6, 10, 13]. Profitability of a design is conventionally equated with yield [1, 3]."}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_3", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 3, "text": "nces parametric yield (e.g. with respect to delay or power) under specific design constraint (e.g. on area or power) [6, 10, 13]. Profitability of a design is conventionally equated with yield [1, 3]. However, large spread in the frequency distribution due to increasing uncertainties has led to the concept of speed-binning to improve the design profit [4]. Presently, speed-binning is widely used during manufacturing test to qualitatively sort the working (i.e. free from manufacturing defects) ICs based on their highest permissible frequency of operation. During the speed-binning process, functional or structural tests are run at multiple frequencies and parts are binned according to the highest speed test they pass. Working ICs are then priced based on their respective frequency bins [4]. Since high-frequency ICs correspond to higher price points, maintaining yield at a target circuit delay (i.e. frequency) under statistical delay distribution does not ensure high profit. Here, profit refers to the cumulative sum of price-weighted yield of the ICs across all frequency bins. Hence, there is a need to develop design methodology that can either maintain or improve the design profit (i"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_4", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 4, "text": "refers to the cumulative sum of price-weighted yield of the ICs across all frequency bins. Hence, there is a need to develop design methodology that can either maintain or improve the design profit (instead of yield at a target delay) under statistical delay variations. In [10] authors have used a linear profit function to capture the performance levels of different ICs. However, they did not consider the impact of design choices or delay distribution change on the profit function.To the best of our knowledge, there is no design technique addressing optimization of design profit (instead of parametric yield at a fixed target delay), considering frequency bins and product price profile. In particular, this paper makes the following contributions: ‚Ä¢ A weighted yield model to represent profit that considers price of ICs running at different frequencies and satisfying specific power dissipation requirement. ‚Ä¢ A statistical design methodology to improve profitability of a design using a sensitivity-based low-complexity gate sizing under both delay and power bounds. ‚Ä¢ An algorithm to determine optimal bin boundaries for a design to maximize profit for a given price profile and design spe"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_5", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 5, "text": "sitivity-based low-complexity gate sizing under both delay and power bounds. ‚Ä¢ An algorithm to determine optimal bin boundaries for a design to maximize profit for a given price profile and design specification. ‚Ä¢ An integrated design flow for simultaneous gate sizing and optimal bin boundary placement to improve design profit for a given price profile with a constraint on area. 2. BACKGROUND AND MOTIVATION In this section, we describe a parametric yield model of a design based on a target delay and leakage power constraint. 2.1 Modeling Yield with respect to a Target Delay Under parameter variations, circuit delay is the maximum of all path delays in the circuit [1]. The overall circuit delay, Tckt thus follows a distribution and can be modeled as a random variable with mean ¬µ and standard deviation (STD) œÉ (i.e. Tckt ~N(¬µ,œÉ)) [1]. Hence, for a given target delay, the circuit will have a certain Figure 1: Leakage and frequency variations in 130nm technology ( source: Intel ) * The work is sponsored in part by Marco Gigascale Systems Research Center (GSRC) and Semiconductor Research Corp.~1000 samples 30% 5X 0.91.0 1.11.21.31.4 1 2 34 Normalized Leakage (Isb) Normalized Frequency 5"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_6", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 6, "text": "k is sponsored in part by Marco Gigascale Systems Research Center (GSRC) and Semiconductor Research Corp.~1000 samples 30% 5X 0.91.0 1.11.21.31.4 1 2 34 Normalized Leakage (Isb) Normalized Frequency 5 2probability to meet it depending on its delay distribution parameters. Conventionally, yield of a design is defined as its probability to meet the target delay ( TD) [6]: Pr{ ( , ) }D ckt D YP T T ¬µœÉ == ‚â§ (1) However, in nano-scaled circuits, power consumption of the system also varies from chip to chip along with performance due to variations in transistor threshold voltage ,channel length, gate width and gate oxide thickness, resulting in parametric yield loss. The yield loss occurs due to the fact that devices with lower V t (and/or lower channel length) suffer from an exponential increase in sub-threshold leakage. Therefore, there exists a strong correlation among the maximum operating frequency and leakage power of a system. In [5], authors show that when both power and performance constraints are considered, maximum yield loss occurs in the highest frequency bin, while negligible yield loss occurs in other frequency bins. Hence, we can effectively use a minimum delay T leakage "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_7", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 7, "text": "constraints are considered, maximum yield loss occurs in the highest frequency bin, while negligible yield loss occurs in other frequency bins. Hence, we can effectively use a minimum delay T leakage (or maximum operating frequency) value as a bound on the leakage power dissipation of the design. Mathematically, when Tleakage bound is used together with TD bound in (1), effective yield of a design can be given by: 2.2 Motivation Fig. 2 shows two possible circuit delay distributions (Gaussian) with the corresponding three frequency bin boundaries for a small test circuit. In this figure, Yield optimized distribution corresponds to a design obtained by optimizing for certain yield constraint at a target delay, T D. The other distribution (Profit optimized ) corresponds to a design where the distribution is changed (by properly sizing the netlist) to improve profit with respect to an exponential price profile (i.e. price point of ICs have exponential dependence on their operating frequency). Fig 2(a) shows that although both distributions meet the yield constraint at T D, the process of improving profit deterministically changes the distribution (¬µ increases, while œÉ decreases) in a w"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_8", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 8, "text": "y). Fig 2(a) shows that although both distributions meet the yield constraint at T D, the process of improving profit deterministically changes the distribution (¬µ increases, while œÉ decreases) in a way that increases the profit with respect to the given price-profile. In this case, yield loss suffered by profit-optimized design in the highest frequency bin, is easily amortized by significant gain in yields at the other two lower frequency bins. In Fig. 2(b), interestingly, yield degrades due to increase in œÉ though profit increases due to adequate increase in the number of highest frequency ICs (that more than offsets yield loss at the two lower frequency bins). Thus, instead of modeling and optimizing yield at a target delay, it is important to consider modeling of profit and to explore design space to optimize profit for high performance systems, which employ frequency binning. 3. PROFIT-AWARE YIELD MODEL We propose a new profit-aware yield model that represents product profitability considering both frequency binning and product price profile. 3.1 Yield Model Considering Frequency binning and Price Profile Fig. 3(a) shows a normalized price vs. frequency specification of two re"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_9", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 9, "text": "y considering both frequency binning and product price profile. 3.1 Yield Model Considering Frequency binning and Price Profile Fig. 3(a) shows a normalized price vs. frequency specification of two recent high-end processors [14]. We observe that for both products, price of the highest frequency part is about three times higher than that of the lowest frequency parts. Hence, to capture the quality of different chips in the design objective function, we model design profit as a price-weighted cumulative sum of yields at different frequency bins. Thus, considering N frequency bins, the profit-aware design yield can be expressed as: where, weighing parameter w i = C (T i) is the price of a chip in the ith frequency bin. It can be noted that the weighted yield YP directly represents the profitability of the design. Fig. 3(b) shows delay distribution vs. exponential product price profile with three frequency bins (i.e. N = 3) for an ISCAS85 benchmark circuit (c499) realized in 70nm BPTM technology [9]. The delay distribution is computed considering both systematic and random variations in threshold voltage. Since all the ICs in a particular frequency bin are sold at the same price, prod"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_10", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 10, "text": "hnology [9]. The delay distribution is computed considering both systematic and random variations in threshold voltage. Since all the ICs in a particular frequency bin are sold at the same price, product price profile becomes a stair-case function of delay (or frequency) irrespective of the nature of the price function (Fig. 3(b)). As different circuits have different delay distribution parameters (¬µ, œÉ), for a given circuit, we choose price weights ( w i) in such a way that the ratio of the prices at the highest and lowest frequencies is constant for all circuits. Mathematically this can be represented as: Four delay specifications ( T leakage , T1, T2, TD) are used to consider three frequency bins (Fig. 3(b)). Yield of a frequency bin is defined as the fraction of the chips that lies within a specified 0.8 1 1.2 1.4 1.6 1.8 2 2.2 x 10‚àí10020040060080010001200 Circuit delay (s)pdf of circuit delayYieldoptimized Profitoptimized TleakageT1TDT2Yloss due to leakage 0.8 1 1.2 1.4 1.6 1.8 2 2.2 x 10‚àí10020040060080010001200 Circuit delay (s)pdf of circuit delayYieldoptimized Profitoptimized TleakageT1T2TDYloss (a) (b) Figure 2: Circuit delay distributions for yield- and profit- optimized "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_11", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 11, "text": "2.2 x 10‚àí10020040060080010001200 Circuit delay (s)pdf of circuit delayYieldoptimized Profitoptimized TleakageT1T2TDYloss (a) (b) Figure 2: Circuit delay distributions for yield- and profit- optimized design with a) iso-yield at the target delay, and b) profit-optimized design of smaller yield 1.5 2 2.5 3 3.5 401234567 Frequency (GHz)PriceIntel Prescott AMD64 Venice 2.5 3 3.5 4 4.5 5 x 10‚àí10050010001500 Circuit Delay (s)No. of chipsdelay pdf cost profile Tleakage T1T2TDW1 W2 W3Cost 2 2.5 3 3.5050010001500No. of chips Frequency (GHz)2 2.5 3 3.502040 Costfreq. pdf lin cost quad cost exp cost f3f1f2 (a) (b) (c) Figure 3: (a) Price and frequency comparisons of two recent high-end processors; (b) Exponential price profile vs. delay distribution for benchmark c499 and (c) Frequency distribution vs. different cost profile Pr{ ( , ) }effective D ckt leakageYT T T ¬µœÉ =‚â• ‚â• (2) ND 1 i 1( ) ; where T = T Target design delay ; where w ( )iN Pi b i n i N Pi i i iYC T Y Yw Y C T= === ==¬¶ ¬¶(3) max price_profile min min max max max = Constant = 11 where ( ), ; ( ), min min D leakagewRw wC f f w C f fTT== ==(4) 3delay (frequency) range. Assuming a Gaussian circuit delay distribution with mean ( ¬µ) an"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_12", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 12, "text": "e_profile min min max max max = Constant = 11 where ( ), ; ( ), min min D leakagewRw wC f f w C f fTT== ==(4) 3delay (frequency) range. Assuming a Gaussian circuit delay distribution with mean ( ¬µ) and standard deviation ( œÉ), yields of different bins can be expressed as: where, Œ¶ is the Cumulative Distribution Function of circuit delay. In (3) and (4), price function ‚Äò C‚Äô can represent any price profile depending on the specific product. In our experiments, we have considered a variety of price profiles with linear, quadratic, exponential dependence on operating frequency. Any other price profiles and even discrete bin prices can also be modeled in the similar manner to compute the profit. Typical example of an exponential price profile vs. delay distribution for an ISCAS85 benchmark c499 is shown in Fig. 3(b). Fig. 3(c) shows different price profiles vs. operating frequency for this circuit. The profit-aware yield model (3) can help us to design high-performance circuits under variations such that design profit is maximized instead of the yield at a specific target delay. Using (3), profit optimization problem with respect to a given price profile and the number of frequency bins"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_13", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 13, "text": "ions such that design profit is maximized instead of the yield at a specific target delay. Using (3), profit optimization problem with respect to a given price profile and the number of frequency bins N can be formulated as: 3.2 Statistical Delay Model To compute the delay distribution of a circuit based on the information of parameter variations, we have employed the statistical static timing analysis (SSTA) algorithm proposed in [8], where delay distribution of a circuit is calculated using Levelized Covariance Propagation (LCP). It was shown in [8] that, using this technique, the effect of both inter-die and intra-die variations can be taken into account. The simulation results on several ISCAS85 benchmarks show average error of 0.21% and 1.07% compared to the Monte-Carlo analysis for mean and standard deviation of delay, respectively. Gate delays are modeled with 70nm BPTM [9] parameters using analytical expression as in Sakurai et al. [11]. For simplicity, we ignore interconnect delays and assume a constant capacitive load for each net. However, our algorithm can be easily extended to incorporate interconnect delays using conventional œÄ-type RC model as used in [7]. 4. PROFIT-"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_14", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 14, "text": "elays and assume a constant capacitive load for each net. However, our algorithm can be easily extended to incorporate interconnect delays using conventional œÄ-type RC model as used in [7]. 4. PROFIT-AWARE DESIGN OPTIMIZATION Using our profit-aware yield model presented in section 3.1, we propose a statistical design flow for profit optimization under an area constraint. 4.1 Yield Optimization using Gate Sizing Gate sizing is conventionally used in different circuit synthesis tools for area/power optimizations while meeting the desired timing constraint, or for minimizing the maximum delay under constraint on area/power [6, 7, 10, 13]. Mathematically, gate sizing problem for achieving mean delay A 0with minimum active area can be formulated as [7]: where, Ui,Li, are the bounds of maximum and minimum gate size, respectively, the value of A0 depends upon the target yield (YT), target delay T D, and ( ¬µ, œÉ) of the delay distribution. In [7], a solution for convex gate-level sizing problem is proposed to minimize maximum delay under an area constraint. Starting from the minimum-sized netlist, we iteratively use the Lagrangian Relaxation (LR) based sizing algorithm [7] in conjunction wi"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_15", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 15, "text": " is proposed to minimize maximum delay under an area constraint. Starting from the minimum-sized netlist, we iteratively use the Lagrangian Relaxation (LR) based sizing algorithm [7] in conjunction with the statistical timing analysis to achieve the yield target with minimum area. In the m th iteration mean target delay is set to ¬µm and at the next iteration we update the target delay by small steps to¬µm+1 as: where, œÉm+1 is the STD of the circuit delay after sizing in the next iteration, œÉm is STD of circuit delay with current sizes and k < 1 is a constant. The solution in [7] provides a globally optimal solution for the problem of area minimization under a static delay constraint. We have observed that with up/down sizing of a logic gate, the mean and standard deviation of the circuit delay shift in the same direction. Based on this observation, we obtain a yield optimized initial design with the minimum area. 4.2 Profit-Aware Gate Sizing In this section, we propose a sensitivity-based profit-aware gate sizing methodology for the optimization problem proposed in (6). Fig. 4 shows principal steps of the proposed profit-aware sizing methodology. Step 1 has been detailed in section "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_16", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 16, "text": "ed profit-aware gate sizing methodology for the optimization problem proposed in (6). Fig. 4 shows principal steps of the proposed profit-aware sizing methodology. Step 1 has been detailed in section 4.1. Once the design is optimized for a target yield with minimum area, we perform SSTA to determine the delay distribution parameters (step 2a). We define leakage bound based on delay distribution parameters (¬µ, œÉ) of the design as: Since the delay parameters (¬µ, œÉ) vary with sizing, the leakage bound also changes with sizing. We define the fixed bin boundaries based on these delay parameters so that Y effective (effective yield between the highest and lowest permissible frequencies) is equally distributed among N frequency bins as: Then we compute initial design profit P old(using (3)), initial design area Aold (computed as active area). In step 3, we compute 1 11 21 2 2 3() - = ; leakage leakage DT TYY T Y TT T TYY¬µ ¬µ œÉœÉ ¬µ ¬µ¬µ ¬µ œÉœÉ œÉ œÉ‚àí ¬ß¬∑ ‚àí¬ß¬∑=‚àí = Œ¶ Œ¶ ¬®¬∏ ¬®¬∏ ¬®¬∏¬©¬π ¬©¬π ‚àí‚àí ‚àí ‚àí¬ß¬∑ ¬ß¬∑ ¬ß¬∑ ¬ß¬∑Œ¶‚àí Œ¶ = Œ¶ ‚àí Œ¶¬®¬∏ ¬®¬∏ ¬®¬∏ ¬®¬∏¬©¬π ¬©¬π ¬©¬π ¬©¬π(5)Input: Netlist (G), target yield (YT), delay bound (TD), price profile 1. Size netlist G using LR gate sizing algorithm for YT at TD 3. Profit-aware up/down sizing2a. R"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_17", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 17, "text": "= Œ¶ ‚àí Œ¶¬®¬∏ ¬®¬∏ ¬®¬∏ ¬®¬∏¬©¬π ¬©¬π ¬©¬π ¬©¬π(5)Input: Netlist (G), target yield (YT), delay bound (TD), price profile 1. Size netlist G using LR gate sizing algorithm for YT at TD 3. Profit-aware up/down sizing2a. Run SSTA and obtain ( ¬µ,ƒ±) 2b. Initialize Tleakage, bin boundaries (Ti), node colors 2c. Compute initial profit Pold, initial area Aold Outut: Profit-aware sized netlist (G)dA <= Ath or dP > 0 NoYes Figure 4: Profit-aware statistic al gate sizing algorithm 1 n i=1 th1 Maximize ( ) , where and are defined in (3) Subject to : = = const, where = total area of circuit; size for the i gate; = total number of gatesN Ri i i ii i iYC Y Y TT Ax A xn== =¬¶ ¬¶(6) 1 0Minimize where , for 1, ... , Subject to: mean( ) , set of Paths, Yield ; where ( )n ii i i i i ip D TxL x U i n DA p TYY Y¬µ œÉ= ‚àà‚â§‚â§ = ‚â§‚àÄ ‚àà ‚àí‚â•= Œ¶¬¶ ¬¶ (7) 1 1 11 1() ( ) ; w h e r e Dm Tm D m T m m mTYT k Y k¬µ¬µ œÉœÉ œÉœÉ‚àí + ++ +‚àíŒ¶‚â• ¬ü ‚â§‚àí Œ¶ = (8) ( , ) ( * ); where, =constantleakageTf l l ¬µœÉ ¬µ œÉ== ‚àí (9) 1 1(, , ) ; (( * ), , ), i = 1, ..., NTl e a k a g e D TD T b i n i leakage binYY TYT Y YN TY i Y¬µ¬µœÉœÉ ¬µœÉ‚àí ‚àí‚àí ‚àí¬ß¬∑=Œ¶ ¬ü =Œ¶ = ¬®¬∏¬©¬π ¬ü =Œ¶ + ‚àÄ(10) 4sensitivity of logic gates with respect to profit ( dP/dx ) for up and down sizing. Next, starting from th"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_18", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 18, "text": "a g e D TD T b i n i leakage binYY TYT Y YN TY i Y¬µ¬µœÉœÉ ¬µœÉ‚àí ‚àí‚àí ‚àí¬ß¬∑=Œ¶ ¬ü =Œ¶ = ¬®¬∏¬©¬π ¬ü =Œ¶ + ‚àÄ(10) 4sensitivity of logic gates with respect to profit ( dP/dx ) for up and down sizing. Next, starting from the most sensitive gate, we perform up/down sizing of logic gates to improve the overall profit of the circuits. This process is performed iteratively until there is no improvement in profit ( dP‚â§ 0) or the area constraint cannot be satisfied ( dA >A th) for further improvement in profit. Fig. 5 shows pseudo-code for our sensitivity-based up/down sizing routine. We apply sizing step (satisfying the bounds on maximum and minimum gate size) to these nodes and perform SSTA to re-compute the delay distribution. A node with higher sensitivity is sized before the node with lower sensitivity. The runtime complexity of the routine depends on the number of SSTA calls in sensitivity analysis during an up/down sizing iteration. We have employed three optimization techniques to improve the runtime of the proposed gate sizing method. 1. Considering the fact that gates lying in the critical path are most sensitive in terms of delay variation and hence, change in profit, we select a set of gates { S C}"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_19", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 19, "text": "e proposed gate sizing method. 1. Considering the fact that gates lying in the critical path are most sensitive in terms of delay variation and hence, change in profit, we select a set of gates { S C} on the critical paths. After the SSTA run, we choose a fixed number of critical paths (10,000 in our case) and compute their delay failure probabilities (with respect to T D) from the path delay parameters (mean and STD). Next, we compute the worst-case delay failure probability for each gate based on the paths crossing it. Gates with high delay failure probability are chosen in an iteration to improve profit (line 1, Fig. 5). 2. We determine profit sensitivity ( S P) of all gates in { SC} by changing one gate size at a time, with a small step ( dx) and computing the corresponding change in profit (i.e. SP = dP/dx ). The sensitivity analysis is performed for both sizing directions (i.e. up and down). If a logic gate has unacceptable profit sensitivities (i.e. profit drops with upsizing or degrades too much with down sizing) in an iteration, we remove it from { S C} in the subsequent calls of up/down sizing (line 3, Fig. 5). 3. Multiple up/down sizing steps are performed after each sen"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_20", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 20, "text": " degrades too much with down sizing) in an iteration, we remove it from { S C} in the subsequent calls of up/down sizing (line 3, Fig. 5). 3. Multiple up/down sizing steps are performed after each sensitivity analysis by selecting successive gates not lying in the fan-in and fan-out logic cone of the previously sized gates. In each iteration, we color the fan-in and fan-out cone of a sized logic gate in the graph ( G) (line 8, Fig. 5). The colored nodes are not considered for sizing in that iteration. When no suitable uncolored gate exists in { S C}, the iteration terminates. We then mark all gates uncolored and perform a SSTA to update the increment of profit ( dP) and area ( dA) values of the given circuit (line 10-15, Fig. 5). These three techniques reduce the number of gates used to compute profit sensitivity in an iteration with negligible degradation ( < 1%) in the over-all profit improvement compared to a case where sensitivity analysis is performed for all gates. It is important to note that, we perform downsizing of least profit sensitive (by assigning higher weight to the downsizing sensitivity) gates to recover from the area overhead incurred during upsizing phase and to"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_21", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 21, "text": "t to note that, we perform downsizing of least profit sensitive (by assigning higher weight to the downsizing sensitivity) gates to recover from the area overhead incurred during upsizing phase and to satisfy area overhead constraint A th. Note that the proposed profit-aware sizing methodology (up/down sizing as described in Fig. 5) can be used to improve the profit independent of initial sizing of the design. For example, profit optimization can be performed starting from a minimum-sized design instead of a yield optimized design (Section 4.1). 4.3 Experimental Results We have applied the proposed profit-aware statistical design on several ISCAS85 benchmarks for different number of frequency bins. We have considered design profit improvement for three different price profiles with different price ratios as defined in (4) (e.g. R lin = 3, Rquad = 5, Rexpo = 10). The final product profit ( YP) is then computed using (3). The area overhead threshold ( Ath) is taken to be a very small value (0.3%) to observe the scope of profit optimization at iso-area over a yield-optimized design. In Table I columns 3 to 5 present profit improvement for different price profiles as a percentage of pr"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_22", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 22, "text": "ue (0.3%) to observe the scope of profit optimization at iso-area over a yield-optimized design. In Table I columns 3 to 5 present profit improvement for different price profiles as a percentage of profit for a 90% yield-optimized design with T leakage = ¬µ - 2.5* œÉ. Using the proposed method, we obtain up to 26 % profit improvement (for c3540). On average, we observe profit improvements of 10.4% for the linear, 9.9% for the quadratic, and 14.2% for the exponential price profile at iso-area (Table I). Smaller slope of quadratic price function than the linear one (Fig 3(c)) for lower frequency bins is responsible for smaller profit improvement under quadratic price profile over linear one, considering equal yield bin boundaries. However, profit improvement for a particular price profile varies widely across the benchmarks and it largely depends on the design specifications as well as on the circuit topology (Table I). Profit improvement at the iso-area comes from the proper distribution of the right amount of yield in the right frequency bin (depending on the price profile). Average runtimes of a sizing iteration considering linear price profile are reported in column 6. Similar runt"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_23", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 23, "text": "of the right amount of yield in the right frequency bin (depending on the price profile). Average runtimes of a sizing iteration considering linear price profile are reported in column 6. Similar runtimes are observed for the other price profiles since they are dominated by the number of calls to the SSTA routine. The number of sizing iterations required by the proposed sizing scheme varies from 3 to 21. Fig. 6(a) plots the delay distributions for c2670 circuit after initial yield optimized design and profit-aware sizing along with its exponential price profile. Note that considerable profit Table I: Profit-aware design results compared to 90% yield- optimized design (N = 3) Profit improvement (%) Circuit Target Delay TD (ps) RLin R Quad R ExpRuntime (sec) c432 520 9.53 9.20 12.80 1.12 c499 440 7.75 8.58 9.66 15.5 c880 400 16.28 15.16 20.89 11.88 c1908 520 7.02 6.50 9.07 51.69 c2670 425 8.11 7.15 10.32 9.91 c3540 640 18.78 18.04 26.18 56.71 c6288 1725 12.98 12.04 17.89 55.74 c74181 200 7.27 6.49 9.28 0.24 c74L85 150 13.83 13.29 19.06 0.04 c74283 170 2.77 2.57 3.53 0.08 Avg. 10.43 9.92 14.15 18.45 up-downSizing ( ) Input: Netlist (G) Output: Sized netlist (G) after one sizing iterat"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_24", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 24, "text": " 7.27 6.49 9.28 0.24 c74L85 150 13.83 13.29 19.06 0.04 c74283 170 2.77 2.57 3.53 0.08 Avg. 10.43 9.92 14.15 18.45 up-downSizing ( ) Input: Netlist (G) Output: Sized netlist (G) after one sizing iteration Direction: down = 0; up = 1 1. Select gates {SC} from critical set of paths with high failure probability; 2. Compute profit sensitivity of all gates {SC} for up/down sizing; 3. Remove the gates with unacceptable profit sensitivity form {SC}; 4. Sort gates of set {SC} in the descending order of profit sensitivity; 5. while (not all gates are colored) 6. Choose the most sensitive uncolored gate;7. Size the gate by dx in proper direction; 8. Color its fan-in and fan-out logic cone; 9. end //while 10. Reset color of all gates; 11. Perform SSTA (G) to obtain ¬µ‚Äô,ƒ±‚Äô; 12. P new = P (T0 , T1, ‚Ä¶, TN,¬µ‚Äô,ƒ±‚Äô); 13. dP = Pnew- Pold; 14. Pold = Pnew; 15. dA = Area(G) - Aold; Figure 5: Pseudo code for up/down sizing 5improvement (10.3%) is achieved for increased high frequency bin yield (due to reduction in mean). Figure 6(b) shows profit improvements of the various benchmarks as the number of frequency bins is varied under an exponential price profile. Note that we have not considered the smaller"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_25", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 25, "text": "ion in mean). Figure 6(b) shows profit improvements of the various benchmarks as the number of frequency bins is varied under an exponential price profile. Note that we have not considered the smaller benchmarks (i.e. c74 series) in this plot because they have small delay spread (Table I). The trend of increasing profit improvement with number of bins can be attributed to the fact that with fine-grained frequency binning, the high frequency bin prices (and the average bin price) increase considerably under a given price profile. We have obtained three sets of average profit improvement results for three different target yields ( Y T), while keeping other design specifications ( Tleakage ,TD,N) unchanged (Fig. 7(a)). We observe that profit improvement decreases with the increase in YT (Fig. 7(a)). This is due to the fact that with low initial yield, design profit is usually low for the specific price profile, thus has good scope of improvement. Fig. 7(b) shows the profit improvement trend with different leakage bounds. We observe that when we change the leakage bound ( T leakage ) from ¬µ - 2* œÉ to ¬µ ‚Äì 3* œÉfor N = 3, average profit improvement increases for all the cost functions. Th"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_26", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 26, "text": "nd with different leakage bounds. We observe that when we change the leakage bound ( T leakage ) from ¬µ - 2* œÉ to ¬µ ‚Äì 3* œÉfor N = 3, average profit improvement increases for all the cost functions. This happens because scope of change in high frequency bin yields and thus scope of profit improvement for a given price profile increase with the smaller leakage bounds. 4.4 Complexity of Profit-Awa re Sizing Algorithm In our proposed sensitivity-based gate sizing approach, we run SSTA multiple times during sensitivity computation of different gates. The complexity of the SSTA is O(m) [7], where m is the maximum number of gates in any level in the levelized netlist of the given circuit. It is shown that even for a very large circuit this number grows very slowly [7]. The complexity of a LR sizing run isO(n a),w h e r e n is the number of gates in the circuit and a‚âà1.7 [8]. Moreover, since after the 1st iteration of up/down sizing, the subsequent sizing steps start with a reduced set of gates, the effective runtime of the subsequent up/down sizing iteration reduces. Hence, the over-all complexity of the design flow is dominated by the runtime complexity of the LR-based sizing (section 4."}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_27", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 27, "text": "s, the effective runtime of the subsequent up/down sizing iteration reduces. Hence, the over-all complexity of the design flow is dominated by the runtime complexity of the LR-based sizing (section 4.1) and SSTA routine. Let us assume that the LR-sizing routine is called r times and the number of iterations for profit improvement is s. Hence, the total runtime complexity can be given by ()aOr n r m s m l‚àó+ ‚àó + ‚àó ‚àó for a design with average number of sensitive gates in set { SC} equal to l. The complete profit-aware design flow takes 0.12 second for the smallest benchmark (c741L85, 33 gates) and 15 minutes for the largest benchmark (c6288, 2503 gates). All the simulations have been run on a Linux server with 3.06 GHz Pentium Xeon processor and 2 GB RAM. Hence, this sensitivity-based profit- aware gate sizing can be efficiently applied to improve design profit of large scale industrial circuits containing large number of gates. Note that we can apply incremental timing analysis (realized by incremental timing refinement considering only the gates with modified size) [2] for a large number of SSTA runs to further improve the runtime. 5.SIMULTANEOUS GATE SIZING AND OPTIMAL BIN PLACEMEN"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_28", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 28, "text": " by incremental timing refinement considering only the gates with modified size) [2] for a large number of SSTA runs to further improve the runtime. 5.SIMULTANEOUS GATE SIZING AND OPTIMAL BIN PLACEMENT In this section we present key observations on how the choice of frequency bin boundaries affects design profitability under process parameter variations. Next, we propose a design method, which maximizes design profit by simultaneous gate sizing and optimal bin-boundary placement. 5.1 Optimal bin placement In case the bin boundaries are not available or designers are allowed to change it, they can be chosen appropriately such that the profit metric is optimized for a given price profile. Assuming fixed number of frequency bins (say N), given a delay distribution D ~ N( ¬µ,œÉ ) and price profile C, the problem of finding optimal bin boundaries can be expressed as: 1Maximize ( ) ( ), Subject to : , for = 1 to N ii i leakage i DYC T Y T TT Ti N== ‚â§‚â§¬¶(11) In order to solve the problem of optimal bin boundary determination (11), we start with equal yield bin boundaries as defined in (10). We employ a greedy approach and at a time we search for one bin boundary that optimizes the design pro"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_29", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 29, "text": "mal bin boundary determination (11), we start with equal yield bin boundaries as defined in (10). We employ a greedy approach and at a time we search for one bin boundary that optimizes the design profit keeping other boundaries fixed. First, we search the optimal boundary for the highest allowable frequency bin. We repeatedly perform such optimization for all other bins in descending order of bin frequencies. At the end, we obtain modified bin boundaries 3 3.5 4 x 10‚àí1002004006008001000 Circuit delay (s)pdf of circuit delayYieldoptimized Profitoptimized price profile Tleakage TDT1T2 c432 c499 c880 c1908 c2670 c3540 c6288051015202530 CircuitsProfit improvement (%)n=2 n=3 n=4 n=5 (a) (b) Figure 6: (a) Delay distributions change for c2670 with an exponential price profile. (b) Profit improvement of different number of bins for fixed bin boundaries 85 90 95024681012141618 Initial yield (%)Average profit improvement (%)Lin Quad Expo ‚àí2 ‚àí2.5 ‚àí302468101214161820 Leakage bound from ¬µAverage profit improvement (%)Lin Quad Expo œÉ œÉ œÉ (a) (b) Figure 7: Average profit improvement for different (a) initial yield targets and (b) leakage bounds for (N = 3)findOptBinBoundary ( ) Input: Number of "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_30", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 30, "text": "rofit improvement (%)Lin Quad Expo œÉ œÉ œÉ (a) (b) Figure 7: Average profit improvement for different (a) initial yield targets and (b) leakage bounds for (N = 3)findOptBinBoundary ( ) Input: Number of bins (N), delay params: ¬µ , ƒ± Output: Optimal bin boundaries (T0, ‚Ä¶ , TN = TD) 1. Find equal yield bin boundaries (T0, T1 ‚Ä¶, TN) for N bins 2. Pold = P (T0, T1 ‚Ä¶, TN, ¬µ, ƒ±) 3. while (no change in Ti ) 4. for each Ti (0 < i < N) 5. Pnew+ = P ( ..., Ti+ dT,‚Ä¶, TN, ¬µ, ƒ±); 6. dP+ = Pnew+- Pold; 7. Pnew- = P ( ..., Ti- dT,‚Ä¶, TN, ¬µ, ƒ±); 8. dP- = Pnew- - Pold; 9. if (dP+ > 0) 10. Ti = Ti+ dT; Pold = Pnew+; 11. else if (dP- > 0) 12. Ti = Ti- dT; Pold = Pnew-; 13. end //if 14. end //for15. end //while Figure 8: Pseudo-code to find optimal bin boundaries 6for all the bins that locally optimize the profit. The pseudo-code for optimal bin boundary determination is given in Fig. 8. Results obtained from this algorithm match very closely with optimal bin placement results obtained from an exhaustive search using an implementation in MATLAB. It is important to note that this technique does not have any design overhead. It only requires an extra design step to be incorporated after the final up/down si"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_31", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 31, "text": "ch using an implementation in MATLAB. It is important to note that this technique does not have any design overhead. It only requires an extra design step to be incorporated after the final up/down sizing routine (Fig. 4). 5.2 Simultaneous Sizing and Optimal Bin Placement Finally, we integrate optimal bin placement procedure (section 5.1) and our profit-aware design flow (section 4.2) to develop an integrated design methodology that simultaneously perform gate sizing as well as optimal bin placement. Basic steps of the design flow are similar to that shown in Fig. 4, except that now we use optimal bin placement routine for profit computation during sensitivity analysis in each up/down sizing routine (step 2, Fig. 5). This means that after obtaining ¬µ andœÉ corresponding to sizing of a logic gate we perform optimal bin placement to compute the profit sensitivity of the gate. This method when employed to different ISCAS85 benchmarks shows up to 36% profit improvement with three frequency bins (Table II), considering a leakage bound of ¬µ - 2.5* œÉ for an 90% yield-optimized design at equal area. For all price profiles, additional improvements in profit with simultaneous sizing and bin p"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_32", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 32, "text": "bins (Table II), considering a leakage bound of ¬µ - 2.5* œÉ for an 90% yield-optimized design at equal area. For all price profiles, additional improvements in profit with simultaneous sizing and bin placement over fixed bin boundaries are also shown in Table II under the columns labeled Imp. We observe that using integrated approach up to 10.1% (c3540) more improvement in profit over fixed bin boundaries can be achieved for exponential price profile. Note that profit improvements do not change much with optimal bin-placement for a linear price profile, since linear price profile has the smallest bin price ratio (i.e. R Lin<R Quad<R Expo). However, the integrated approach shows significant average profit improvement compared to fixed bin boundary results for both quadratic (from 10% to 16.7%) and exponential price profiles (from 14.1% to 18.8%) for a set of ISCAS85 benchmarks (Table I, and II). Fig. 9(a) shows effectiveness of two proposed profit-aware sizing methodologies (i.e. fixed bin and simultaneous sizing and optimal bin placement) for different price functions with N = 3 and T leakage = ¬µ - 2.5* œÉ. Fig. 9(b) shows a consistent increasing trend in average profit improvements "}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_33", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 33, "text": "in and simultaneous sizing and optimal bin placement) for different price functions with N = 3 and T leakage = ¬µ - 2.5* œÉ. Fig. 9(b) shows a consistent increasing trend in average profit improvements for both the methods under an exponential price profile as the number of bins is increased. Note that the runtime of the simultaneous sizing and optimal bin placement algorithm is almost indistinguishable from the runtime of profit optimization with fixed bin boundaries (Table I). This is because optimal bin placement routine has negligible impact on overall runtime, which is dominated by the number of SSTA runs. It is worth noting that although our delay models follow Gaussian (normal) distribution, the proposed methods can be easily extended to a recently-proposed non-normal delay distribution [12], which is reported to have higher accuracy in representing delay variations. With non-normal distribution, the steps on making sizing decision using profit sensitivity do not change. However, computation of effective yield in each frequency bin needs to be modified based on the nature of the distribution. Determination of optimal bin boundaries using the greedy approach section 5.1) also r"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_34", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 34, "text": "computation of effective yield in each frequency bin needs to be modified based on the nature of the distribution. Determination of optimal bin boundaries using the greedy approach section 5.1) also remains valid for non-normal delay distributions. 6. CONCLUSIONS We have proposed a profit-aware yield model and a statistical design methodology to optimize design profit for a given price profile under an area constraint. The methodology can be applied to any price profile and any delay distribution models (normal/non-normal). We have demonstrated that optimal bin- boundary determination can be used to increase the design profit. Experimental results on ISCAS85 benchmarks show that the proposed profit-aware design flow that incorporates information on price profile and frequency binning during the design phase can be very effective to improve design profit under parameter variations. REFERENCES [1] K. A. Bowman et al., ‚ÄúImpact of Die-to-Die and Within-Die Parameter Fluctuations on the Maximum Clock Frequency Distribution for Gigascale Integration‚Äù, JSSC, 2002, pp. 183-190. [2] L.-C. Chen et al., ‚ÄúA New Framework for Static Timing Analysis, Incremental Timing Refinement, and Timing Sim"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_35", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 35, "text": "imum Clock Frequency Distribution for Gigascale Integration‚Äù, JSSC, 2002, pp. 183-190. [2] L.-C. Chen et al., ‚ÄúA New Framework for Static Timing Analysis, Incremental Timing Refinement, and Timing Simulation‚Äù, ATS, 2000, pp. 102-107. [3] S. Borkar et al., ‚ÄúParameter Variations and Impact on Circuits and Micro-architecture‚Äù, DAC, 2003, pp. 338-342. [4] B. Cory et al., ‚ÄúSpeed binning with path delay test in 150-nm technology‚Äù, IEEE Design and Test of Computers , 2003, pp. 41-45. [5] R. R. Rao et al., ‚ÄúParametric Yield Estimation Considering Leakage variability‚Äù, DAC, 20 04, pp. 442-447. [6] S. Choi et al., ‚ÄúNovel Sizing Algorithm for Yield Improvement under Process Variation in Nanometer Technology‚Äù, DAC, 20 04, pp. 454- 459. [7] C. P. Chen et al., ‚ÄúFast and Exact Simultaneous Gate and Wire Sizing by Lagrangian Relaxation,\" IEEE TCAD , 1999, pp. 1014-1025. [8] K. Kang et al., ‚ÄúStatistical Timing Analysis using Levelized Covariance Propagation‚Äù, DATE, 2005, pp. 764-769. [9] ‚ÄúTechnology Models‚Äù, http://www-device.eecs.berkeley.edu/~ptm. [10] A. Agarwal et al., ‚ÄúCircuit Optimization using Statistical Timing Analysis‚Äù, DAC, 2005, pp. 321-324. [11] T. Sakurai et al., ‚ÄúDelay Analysis of Se"}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_36", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 36, "text": "dels‚Äù, http://www-device.eecs.berkeley.edu/~ptm. [10] A. Agarwal et al., ‚ÄúCircuit Optimization using Statistical Timing Analysis‚Äù, DAC, 2005, pp. 321-324. [11] T. Sakurai et al., ‚ÄúDelay Analysis of Series-connected MOSFET Circuits‚Äù, IEEE JSSC , vol. 26, no. 2, 1991, pp. 122-131. [12] X. Li et al., ‚ÄúAsymptotic Probability Extraction for Non-Normal Distributions of Circuit Performance‚Äù, ICCAD, 2004, pp. 2-9. [13] X. Bai et al., ‚ÄúUncertainty-Aware Circuit Optimization‚Äù, DAC, 2002, pp. 58-63. [14] ‚ÄúProcessor Retail prices‚Äù , http://www.newegg.com.Linear Quadratic Exponential02468101214161820 Price functionsAverage profit improvement (%)Fixed Simul 2 3 4 5051015202530 Number of binsAverage profit improvement (%)Fixed Simul (a) (b) Figure 9: Average profit improvements in different methods (a) for different price functions by (N=3), and (b) for different N (exponential price profile) Table II: Simultaneous profit-aware sizing and optimal bin placement compared to 90% yield-optimized design (N = 3) Profit improvement (%)Circuit RLin Imp. R Quad Imp. R Exp Imp. c432 9.98 0.33 15.58 6.38 17.98 5.18 c499 8.01 0.26 14.58 6.00 13.13 3.47 c880 17.01 0.73 22.63 7.47 27.17 6.28 c1908 7.13 0.11 8."}
{"id": "Speed Binning Aware Design Methodology to Improve Profit.pdf::chunk_37", "source": "Speed Binning Aware Design Methodology to Improve Profit.pdf", "chunk_index": 37, "text": "N = 3) Profit improvement (%)Circuit RLin Imp. R Quad Imp. R Exp Imp. c432 9.98 0.33 15.58 6.38 17.98 5.18 c499 8.01 0.26 14.58 6.00 13.13 3.47 c880 17.01 0.73 22.63 7.47 27.17 6.28 c1908 7.13 0.11 8.32 1.82 9.52 0.45 c2670 8.59 0.48 13.17 6.02 14.68 4.36 c3540 20.97 2.19 30.00 11.96 36.31 10.13 c6288 14.02 1.04 20.69 8.65 26.07 8.18 c74181 7.66 0.39 11.93 5.44 13.30 4.02 c74L85 14.85 1.02 22.48 9.19 27.60 8.54 c74283 2.93 0.16 6.59 4.02 6.06 2.53 Avg. 11.11 0.67 16.70 6.70 18.78 5.31"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_0", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 0, "text": "Surface Defect Classification in Silicon Wafer Manufacturing Using the Linear -Based Channel ing and Rule -Based Binning Algorithms Hao Hu1,a*, Kari Ullak ko1,b, Mingming Chao2,c , Xin Lai2,d 1Lappeenranta- Lahti University of Technology, Finland 2Advanced Silicon Technology Co., Ltd. China ahuha0002@e.ntu.edu.sg, bkari.ullakko@lut.fi , cmmchao@ast.com.cn, dxlai@ast.com.cn Keywords: Process -induced defects, Surface -adhered foreign particles, Crystal -originated pits, Scanning surface inspection system s, Defect classification , Localized light scatterers Abstract. Developing an accurate means of classifying defect s, such as crystal -originated pits , surface -adhered foreign particles , and proce ss-induced defects , using scanning surface inspection system s (SSIS) is of paramount importance because i t provide s the opportunity to determine the root cause s of defects , which is valuable for yield enhancement. This report present s a novel defect classification approach developed by optimizing the linear -based channel ing (LBC ) and rule -based binning (RBB) algorithms that are applie d to a commercially available SSIS (KLA -SP5) , in combination with test sample selection in"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_1", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 1, "text": "by optimizing the linear -based channel ing (LBC ) and rule -based binning (RBB) algorithms that are applie d to a commercially available SSIS (KLA -SP5) , in combination with test sample selection including the signature defect patterns associated with the typical crystal grow th process. The experimental results demonstrate that defect classification is possible with an accuracy and purity above 80% using the LBC algorithm and 90% using the RBB algorithm . Abbreviations Scanning surface inspection system (SSIS) Crystal -originated pits (COP) Surface -adher ed foreign particle s (SFP) Process -induced defect s (PID) Linear -based channeling (LBC) Rule -based binning (RBB) Light point defects (LPD) Non-cleanable light point defects (LPDN) Localized light scatterer (LLS) 1. Introduction Highly pure crystalline s ilicon (Si) wafers are used in the semiconductor industry as the basis for manufacturing electronic devices, owing to silicon‚Äôs beneficial structure , satisfactory mechanical strength, and favorable chemical and electrical properti es. Defects on the surface of suc h wafers may be generated during the various manufacturing steps . These surface defects are generally classifi"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_2", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 2, "text": "rength, and favorable chemical and electrical properti es. Defects on the surface of suc h wafers may be generated during the various manufacturing steps . These surface defects are generally classified into three categories , according to their source during the silicon wafer manufacturing process [1,2] , ‚Ä¢ Crystal grown- in defect s, such as crystal -originated pits (COP ): These are voids in the bulk crystal that are delineated as pits on the wafer surface. They are captured as non- cleanable light point defects ( LPDN) on the wafer surface by the scanning surface inspection s ystems ( SSIS) . These defects have the greatest negative impact on the device performanc e - for example , they lead to gate- oxide -integrity failure [3‚Äì5]. ‚Ä¢ Surface -adhe red foreign partic les ( SFP): These are organic par ticles or metal contaminants generated by human activities , fab rication facilities , equipment, and process es [6‚Äì8]. The contemporary silicon wafer manufacturing process has been carefully designed to control the Advanced Materials Research Submitted: 2021-07-07 ISSN: 1662-8985, Vol. 1170, pp 1-10 Revised: 2021-12-08 doi:10.4028/p-0612s4 Accepted: 2021-12-14 ¬© 2022 The Author(s)."}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_3", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 3, "text": "efully designed to control the Advanced Materials Research Submitted: 2021-07-07 ISSN: 1662-8985, Vol. 1170, pp 1-10 Revised: 2021-12-08 doi:10.4028/p-0612s4 Accepted: 2021-12-14 ¬© 2022 The Author(s). Published by Trans Tech Publications Ltd, Switzerland. Online: 2022-04-19 This article is an open access article under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0) deposition of organic particles and metal contaminants , for eliminating their impact on the devic e performance. SFP are often captu red as light point defects ( LPD ) by SSIS . ‚Ä¢ Process -induced defects ( PID): These are also called polishing- induced defects . These include all the unwanted imperfections generated from the manufacturing process es, particularly during polishing, such as residues, stains, dimple s, scrat ches, and surface particles . PID are responsible for gate dielectric failures during the device fabrication process and are observed as either LPD or LPDN by SSIS [9‚Äì11]. These surface defects are detrimental for the electronic devices made on the Si wafers. Therefore , Si wafer manufacturing requires tight defect control . Th"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_4", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 4, "text": "rved as either LPD or LPDN by SSIS [9‚Äì11]. These surface defects are detrimental for the electronic devices made on the Si wafers. Therefore , Si wafer manufacturing requires tight defect control . This is achieved by using highly sensitive metrology tool s for detecting the surface defects [12,13] and elaborate algorithms for classifying them . Effectively using the line ar-based channeling (LBC) and rule-based binning (RBB) algorithms applied to commercial ly available SSIS such as the KLA -SP5 [14], will enable the appropriate categorization of defects during the defect classification process. In the system, two darkfield angles of incidence (oblique and normal) and two darkfield collectors (wide and narrow), in addition to a brightfield subsystem (differential interference contrast) comprise the data channels for collecting surface defect information [15] . As illustrated in F igure 1, there are several defect characteristics such as the size information of the darkfield wide (DW) and darkfield narrow (DN) channels, size information of the normal DW and DN channels, signal to noise ratio (SNR), and positions of the oblique and normal light incidences. The LBC algorithm uses the"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_5", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 5, "text": "and darkfield narrow (DN) channels, size information of the normal DW and DN channels, signal to noise ratio (SNR), and positions of the oblique and normal light incidences. The LBC algorithm uses the result of the cross -channel ratio for discriminating particles and defects on silicon wafers [16] . The RBB algorithm does not simply apply the ratios of defect sizing by various channels. It is a combination of defect characteristics including the information for the LBC algorithm, the attributes for differential interference contrast (DIC) such as size, p olarity, defect location (x -y positions), and other general information including the aspect ratio, length, and area. [17]. The present paper presents a report about an investigation about the effective of such algorithms provided by a commercially available SSIS. Experimental details are presented in section 2 and the results are discussed in section 3 before the report is closed by a section with a summary and conclusions. Fig. 1 Surface defect characteristics that applied in the LBC and RBB algorithm s. 2. Experimental Detail s 2.1 Defect E ngineering F low and Preliminary Investigations There are five steps involved during pr"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_6", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 6, "text": "urface defect characteristics that applied in the LBC and RBB algorithm s. 2. Experimental Detail s 2.1 Defect E ngineering F low and Preliminary Investigations There are five steps involved during process control and defect engineering, for which corresponding surface defect metrology is selected (Figure 2). 2 Advanced Materials Research Vol. 1170 Fig. 2 Overview of the defect engineering flow for detecting and identifying the surface defect s - from ‚Äúdefect detection & sizing ‚Äù to ‚Äúyield enhancement ‚Äù. Defe ct detection and sizing involve the use of a n SSIS. In such a system a focused laser beam spot is scanned across the wafer surface and the scattered light is collected by an optical system and fed into one or more detectors. The detect or(s) signal(s) are rec orded as a function of the spot position on the wafer surface. Any signal above a threshold close to the background, which is generated by the overall surface roughness, is considered to result from a surface defect, called in general LLS (localized light scatterer). In the current investigation an SSIS provided from KLA is used, the KLA -SP5 (Figure 3). This tool is equipped with tw o collectors or channels DN and DW . "}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_7", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 7, "text": "in general LLS (localized light scatterer). In the current investigation an SSIS provided from KLA is used, the KLA -SP5 (Figure 3). This tool is equipped with tw o collectors or channels DN and DW . The channel DN collects light scattered close to the surface normal whereas the channel DW covers a large solid angle of scattered light. The intensity of the light scattered by an LLS depends on the refractive index , shape , and size of the LLS. An equivalent size expressed as umLSE or nmLSE is assigned to the LLSs by cali brating the SSIS with p olystyrene latex spheres of different diameters, deposited on a reference silicon wafer surface [18 ‚Äì20]. The acronym ‚ÄúLSE‚Äù (latex sphere equivalent or light scattering equivalent) [21] added to the length unit indicates that the size reported by the SSIS is a metric for the light scattering cross section of the LLS and not for the true geometrical size. In addition, SP5 provides the option of different i ncidence angles of the laser beam. The user of the SP5 may choose between incidence perpendicular to the wafer surface (normal incidence) or incidence under an angle of 5¬∞, 20¬∞Ôºå25¬∞ or 72¬∞( oblique incidence). A brightfield subsystem based o"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_8", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 8, "text": "ser of the SP5 may choose between incidence perpendicular to the wafer surface (normal incidence) or incidence under an angle of 5¬∞, 20¬∞Ôºå25¬∞ or 72¬∞( oblique incidence). A brightfield subsystem based on DIC comprise th e data channels for collecting surface defect information [15] . Fig. 3 Schematic overview of the KLA -SP5 s urface scanning counter -dark-field inspection based on light scattering technology (oblique and normal incidence beam, oblique and normal specular beam, and a wide and narrow detector) . Advanced Materials Research Vol. 1170 3 Defect classification , which is the key focus of this study, is a crucial step in defect engineering flow. The o utput of the various channels and illumination options is the basic for the algorithms used for classifying the surface defects (Fig. 1). LBC and RBB are eff icient defect classification algorithms that are used by SSIS . LBC uses the cross -channel size ratio n (Equation 1) , where DN denote s equivalent size of a defect as captured by the narrow channel , whereas DW denote s the size of the same defect as measured by the wide channel . Using LBC , surface defects are classified into LPD and LPDN based on the cross channel r"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_9", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 9, "text": "ured by the narrow channel , whereas DW denote s the size of the same defect as measured by the wide channel . Using LBC , surface defects are classified into LPD and LPDN based on the cross channel ratio n where LPDN typically display an n > 1. R BB also applies the concept of the cross -channel size ratio, however, it cascades the classification process to introduce multi -level channeling. Particularly , it allow s the area feature (radial or b ox) ‚Äì to be positioned for predefining defects of interest (DOI). (1) For being able to correctly cl assify LLS by L BC and RBB it is necessary to set up the parameters of these algorithms appropriately. This is achieved by r eview ing the LLS with scanning electron microscopy (SEM), which is a labor intensive and time-consuming method that is only suitable as a verific ation process for DOI with known x- y coordinates on the sample wafer. In addition, SEM is a destructive method. C lassification and reviewing of defects are often iterative process es that optimize the defect classification results . The LLS captured by the SSIS comprising LPD (e.g., particles, flakes, residue s, stain s, and sphere s) and LPDN (e.g., COP , embedded defec"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_10", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 10, "text": "rocess es that optimize the defect classification results . The LLS captured by the SSIS comprising LPD (e.g., particles, flakes, residue s, stain s, and sphere s) and LPDN (e.g., COP , embedded defects, bumps, pits/dents , dimple s, scratches , faint lines, and gouge s), were reviewed using SEM KLA-eDR7380 in the current investigation, examples are displayed in Fig ure 4. Review ing defects to identify DOI is an effective step to ward determining the root causes of defect s. Fig. 4 LPD and LPDN high-resolution 2D images captured by SEM. Defect analysis includes SEM studies for reviewing defect topographies , EDX studies for elemental analysis of particles , and a root cause analysi s for the inline manufacturing processes. B y identifying the root cause of the surface defects, process engineer s can understand and reduce P ID for continuous process improvement. Yield enhancement is an important goal of defect engineering, which is realized by improving individual processes as well as the overall operation [13,21,22]. 4 Advanced Materials Research Vol. 1170 2.2 Challenges and the goal of defect classification Surface defects are captured as LLS and classified as LPD and LPDN when u"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_11", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 11, "text": "the overall operation [13,21,22]. 4 Advanced Materials Research Vol. 1170 2.2 Challenges and the goal of defect classification Surface defects are captured as LLS and classified as LPD and LPDN when using the LBC algorithm applied in the SSIS, with a typical setting of a cross -channel ratio threshold rth for n with 1.10 < rth < 1.30 by which LPD and LPDN are distinguished. The situation is shown schematically in Figure 5. Based on the LBC algorithm, the defects may be classified into two groups: One group consists of SFP and PID , and the other group of COP . Therefore, the LBC algorithm with the single -level channeling is not expected to efficiently distinguishing the SFP and PID. In contrast , the R BB algorithm is expected to classify the SFP, PID, and COP efficiently using the mult iple- level channeling that in volves defect characteristics such as the defect location, DIC information, the aspect ratio, length, a nd area. T he blank area s in Figure 5, where the circles overlap, indicate the uncertain defect classification among the thre e defect sources. The task for being able to apply the algorithms in a wafer production line is to minimize the uncertain sectors by tuning"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_12", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 12, "text": " indicate the uncertain defect classification among the thre e defect sources. The task for being able to apply the algorithms in a wafer production line is to minimize the uncertain sectors by tuning the parameters of these algorithms. The next section describes how this was successfully achieved. Fig. 5 Schematic vie w of defect classification implemented using the LBC and RBB algori thms ‚Äì Categorization into SFP, COP , and PID is based on the source of defects; categorization into LPD and LPDN is according to the SSIS equipment (KLA -SP5). 3 Results and Discussi on The investigation regarding to the classification accuracy and purity was performed in two steps. In the first step specifically selected wafers were used for determining the appropriate parameters for the LBC and RBB algorithms. In the second step, subsequently then a set of production wafers was measured and analyzed with the such defined parameters. In both steps the results of the SSIS measurement were cross -checked with SEM investigation of the defects found. In the first step two groups (5 wafers each ) of p-type, lightly doped, and mirror- polished silicon wafers with a 300 mm diameter , (100) crystal orienta"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_13", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 13, "text": " with SEM investigation of the defects found. In the first step two groups (5 wafers each ) of p-type, lightly doped, and mirror- polished silicon wafers with a 300 mm diameter , (100) crystal orientation , and 775¬± 5 ¬µm thickness were selected for the experiment s. In particular, the COP density and distribution of the two groups of wafers were analyzed to investig ate the result s obtained us ing LBC and RBB . Group 1 (5 wafers) consisted of COP -free wafers, in which the defe ct type of LPD dominate d according to the SSIS used with n < rth . Therefore , the LLS on the wafer surface, which were classifi ed as LPD by the KLA -SP5, primarily contribute to the defect count s. Group 2 (5 wafers ) consisted of COP -dominated/COP -rich wafers which exhibited the characteristic disk and ring pattern of COP [23,24] . By this it is possible to apply RBB (radial positioning) to optimize the accuracy of defect class ification [6,25] . The LBC algorithm was applied to both groups of wafers in order to tune the cross -channel ratio according to the DN and DW signals from the oblique and normal incident lights. Subsequently, the RBB Advanced Materials Research Vol. 1170 5 algorithm was applie"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_14", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 14, "text": "rder to tune the cross -channel ratio according to the DN and DW signals from the oblique and normal incident lights. Subsequently, the RBB Advanced Materials Research Vol. 1170 5 algorithm was applied to wafer group 2 with respect to the information regarding the defect location, aspect ratio, size, polarity of the DIC signal, length, and defec t area. Following the experiments, we selected one premium production lot (25 wafers) and ran through it using the qualified KLA -SP5 system . The defect classification r esult was verified by SEM (KLA - eDR7380) using the confusion matrix techniqu e [11]. The accuracy and purity were repor ted accordingly. The surface defects captured by the surface scanning counter are randomly distributed on the Group 1 wafers , as shown in Figure 6. Most of the LPD detected by KLA- SP5 and reviewed by the SEM are process -induced. Moreover, some SFP are also accurately classified as LPD . Notably, crystal grown -in defect pattern s, in terms of defect si zing, density, and distribution, were not observed. The distribution of point defects varies from 30 to 145 mm across the radial direction of the wafer , as shown in Figure 7 (defect count versus r adiu"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_15", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 15, "text": "ng, density, and distribution, were not observed. The distribution of point defects varies from 30 to 145 mm across the radial direction of the wafer , as shown in Figure 7 (defect count versus r adius) . Under th is scenario, we can apply the LBC algorithm in the defect classification pr ocess because zero grown -in defects were observed in the prime grade of COP -free single crystalline silicon. Therefore, the ke y focus of the surface defects is LLS that are generat ed by PID and SFP during silicon wafer manufacturing. Fig. 6 Defect classification using LBC for COP -free s ingle crystal silicon wafer. There is no specific pattern of defect distribution. PID dom inated the defect map. Fig. 7 Size and density distribution of defects in the COP -free wafers . The results of Group 2 wafers, silicon wafer s with the signature COP defect distribution s (disk and ring pattern s at the center and edges, respectively ), are shown in Figure 8 and 9. The radially varying COP distribution is aligned to the radia l dependence of the vacancy concentration [23]. Based on this observat ion, the COP are distributed at the central area from 0 to 50 mm and close to 6 Advanced Materials Research Vo"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_16", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 16, "text": "igned to the radia l dependence of the vacancy concentration [23]. Based on this observat ion, the COP are distributed at the central area from 0 to 50 mm and close to 6 Advanced Materials Research Vol. 1170 the edge of the wafer at radii from 105 to 145mm . The COP size distribution also indicates the radial p osition . This indicates that smaller size d COP (<0.026 ¬µmLSE) display higher densit ies at the edge area, wh ereas larger COP (>0.032 ¬µmLSE) show lower densit ies at the central area of the wafer (0 to 50 mm) . In contrast to other studies on surface defect cl assification [9,26] , we defined two areas with COP - one was the disk- shaped center area (within the 0 - 50 mm radius) and the other wa s the ring -shaped ed ge area (within the 105 - 145 mm radius) . The defects in these areas are thus classif ied as LPDN based on the distribution of the crystal grown- in defects . In contrast, the PID and SFP are captured as LPD in the exclusion area of the DOI. In this experiment, limited LPD were observed based on the detection limit (DL) of 0.022 ¬µmLSE. Fig. 8 Defect classification using RBB for the signature COP single crystal silicon wafer. Applying defect characteristics su"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_17", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 17, "text": "imited LPD were observed based on the detection limit (DL) of 0.022 ¬µmLSE. Fig. 8 Defect classification using RBB for the signature COP single crystal silicon wafer. Applying defect characteristics such as position, aspect ratio, and area for discriminating surface defects. Fig. 9 Size and density distribution of defects in the signature COP sample for the second experiment . In the second step, in order t o evaluate the defect classification performance o f the KLA -SP5 using the LBC and RBB algorithm s, a premium production lot of 25 wafers was measur ed and reviewed . Com parin g the result of the KLA- SP5 and the KLA -eDR7380, the accuracy and purity of the classification are calculated based on the E quation 2 a nd 3 using the confusion matrix technique [11]. The results are repor ted in Table 1 and 2. Table 1 lists the results where only the LBC algorithm was applied and the accuracy and purity were above 80% . However, it is reasonably accepted , that this approach is usually not able to distin guish the SFP and PID efficiently (grouping Advanced Materials Research Vol. 1170 7 the SFP and PID as one). As shown in Table 2, using the RBB algorithm the def ects are efficiently "}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_18", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 18, "text": "t able to distin guish the SFP and PID efficiently (grouping Advanced Materials Research Vol. 1170 7 the SFP and PID as one). As shown in Table 2, using the RBB algorithm the def ects are efficiently classified as SFP, PID, and COP and the accuracy and purity are above 90% . This is sufficient to capture excursion wafers based on practical experience [11]. Accuracy (%) = Total correctly classified by SSIS/ Total classifi ed by SEM (2) Purity (%) = Total corre ctly classified by SSIS/ T otal classified by SSIS (3) Table 1 Results of defect classification using LBC only based on a confusion matrix (accuracy and purity). SEM R eview SFP+PID COP Purity SSIS SFP+PID 500 56 89.9% COP 34 248 87.9% Accu racy 93.6% 81.6% Table 2 Results of defect classification using RBB based on a confusion matrix (accuracy and purity) . SEM Review SFP COP PID Purity SSIS SFP 140 6 8 90.9% COP 8 260 14 92.2% PID 7 12 255 93.1% Accuracy 90.3% 93.5% 92.1% Therefore , in this study, the LBC and RBB algorithms were quantitatively evaluat ed considering one specific scenario . Other scenarios might be worth studying, including cases where only disk - shaped or ring- shaped defect patterns are observed at the ce"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_19", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 19, "text": "e quantitatively evaluat ed considering one specific scenario . Other scenarios might be worth studying, including cases where only disk - shaped or ring- shaped defect patterns are observed at the center or the edge s, respectively , for efficient ly streamlin ing the troubleshooting proces s. Designing suitable scenarios for such studies requires a proper understanding of the silicon crystal growth conditions , such as the interface shape of crystal -melt, pulling speed, and temperature gradient [27] . Characterizing the silicon crystal in terms of crystal ty pe, defect density, and size distribution prior to defect classification is a preliminary requirement [28,29] . This novel method work s wel l in silicon wafer manufacturing , specifically for manufacturing large wafer s. 4 Summary and Conclusion s It was demonstrated that LBC and RBB algorithms are able to distinguish COP, SFP and PID with a high success rate by using a commercially available SSIS, provided the algorithms are appropriately set up. For establishing appropriate parameter settings for the algorithms two sets of specifically selected wafers were used. T he result s show that it is essential to obtain grown- in "}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_20", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 20, "text": "ppropriately set up. For establishing appropriate parameter settings for the algorithms two sets of specifically selected wafers were used. T he result s show that it is essential to obtain grown- in defect information and to select the appropriate samples for the LBC and RBB setup in the SSIS . In addition, this approach is applicable for acquiring defect information during the manufacturing 8 Advanced Materials Research Vol. 1170 processes , such as special process -induced patterns on the surfaces and edge s of the wafers, thus opening opportunit ies for future studies. CRediT authorship contribution statement Hao Hu : Investigation, Writing, Project administration. Kari Ullak ko: Writin g-Review, Supervision. Mingming Chao: Investigation. Xin Lai : Investigation. Refe rences [1] R.F. Reinhardt, K.A., Reidy, Handbook of Cleaning for Semiconductor Manufacturing, John Wiley and Sons, New Jersey, 2011. [2] V. Lindroos, M. Tilli, A. Lehto, T. Motooka, Handbook of Silicon Based M EMS Materials and Technologies (Micro and Nano Technologies), William Andrew, 2010. [3] J. Park, K. Kwack, Crystal Originated Particle Induced Oxide Breakdown in Czochralski Silicon Wafer, J. Korean Phys. So"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_21", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 21, "text": "erials and Technologies (Micro and Nano Technologies), William Andrew, 2010. [3] J. Park, K. Kwack, Crystal Originated Particle Induced Oxide Breakdown in Czochralski Silicon Wafer, J. Korean Phys. Soc. 38 (2001) 356‚Äì365. [4] M. Hourai, E. Asayama, H. Nishikawa, M. Nishimoto, T. Ono, M. Okui, Recognition and Imaging of Point Defect Diffusion, Recombination, and Reaction During Growth of Czochralski -Silicon Crystals, J. E lectron. Mater. 49 (2020) 5110‚Äì5119. https://doi.org/10.1007/s11664- 020-08203- w. [5] G. Kissinger, J. Dabrowski, T. Sinno, Y. Yang, D. Kot, A. Sattler, Ab initio calculations and rate equation simulations for vacancy and vacancy- oxygen clustering in silicon, J. Cryst. Growth. 468 (2017) 424‚Äì 432. https://doi.org/10.1016/j.jcrysgro.2016.10.073. [6] B. Jean -Luc, D. Bruno, Contamination Monitoring and Analysis in Semiconductor Manufacturing, in: Semicond. Technol., Semiconductor Technologies, 2010: pp. 57‚Äì78. https://doi.org/10.5772/8561. [7] A. Nutsch, B. Beckhof, G. Bedana, G. Borionetti, D. Codegoni, S. Grasso, G. Guerinoni, A. Leibold, M. M√ºller, M. Otto, L. Pfitzner, M.L. Polignano, D. De Simone, L. Frey, Characterization of organic contamination in semicond"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_22", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 22, "text": ". Bedana, G. Borionetti, D. Codegoni, S. Grasso, G. Guerinoni, A. Leibold, M. M√ºller, M. Otto, L. Pfitzner, M.L. Polignano, D. De Simone, L. Frey, Characterization of organic contamination in semiconductor manufacturing processes, AIP Conf. Proc. 1173 (2009) 23‚Äì28. https://doi.or g/10.1063/1.3251227. [8] K. Reinhardt, W. Kern, Handbook of Silicon Wafer Cleaning Technology, William Andrew, 2018. [9] H. Ohta, S.M. Byeong, G.P. Jea, H.L. Sang, H.A. Jeong, H. Kwon, T. Watanabe, K. Ichinose, K. Nemoto, K.P. Sung, Quantifying yield impac t of polishing induced defect on the silicon surface, ASMC (Advanced Semicond. Manuf. Conf. Proc. (2009) 41‚Äì45. https://doi.org/10.1109/ ASMC.2009.5155950. [10] R. Vos, K. Xu, M. Lux, W. Fyen, R. Singh, Z. Chen, P. Mertens, Z. Hatcher, M. Heyns, Use of surf actants for improved particle performance of dHF -based cleaning recipes, Solid State Phenom. 76‚Äì77 (2001) 263‚Äì266. https://doi.org/10.4028/www.scientific.net/SSP.76- 77.263. [11] Y.Y. Lin, F.S. Tsai, L.C. Hsu, H.K. Hsu, C.Y. Li, Y.Y. Ke, C.W. Huang, J.M. Chen, S.J. Chang, T.Y. Lee, E. Chen, C.Y. Cheng, Fast and accurate defect classification for CMP process monitoring, ASMC (Advanced Semicond. Manuf."}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_23", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 23, "text": ". Hsu, H.K. Hsu, C.Y. Li, Y.Y. Ke, C.W. Huang, J.M. Chen, S.J. Chang, T.Y. Lee, E. Chen, C.Y. Cheng, Fast and accurate defect classification for CMP process monitoring, ASMC (Advanced Semicond. Manuf. Conf. Proc. 2019- May (2019) 224‚Äì 228. https://doi.org/10.1109/ASMC.2019.8791750. [12] P. Wagner, Metrology of 300 mm silicon wafers: Challenges and results, 1998 Int. Conf. Charact. Metrol. ULSI Technol. 153 (1998) 153‚Äì 160. https://doi.org/10.1063/1.56790. [13] A. Zandiatashbar, B. Ki m, Y. Yoo, K. Lee, A. Jo, J.S. Lee, S.- J. Cho, S. Park, High- throughput automatic defect review for 300mm blank wafers with atomic force microscope, 9424 (2015) 94241X. https://doi.org/10.1117/12.2086042. Advanced Materials Research Vol. 1170 9 [14] M. Akbulut, H. Lihn, M. Vaez -irvani, S. Stok, G. Zhao, W. Inspection, COPs / Particles Discrimination With a Surface Scanning I nspection System, Semicond. Int. (1999) 1‚Äì8. [15] B. Pinto, J. Saito, W. Shen, L. Cheung, A.W.K. Corporation, New Inspection Technology for 45nm Wafers, Yield Manag. Solut. (2007) 28‚Äì32. [16] F. Passek, R. Schmolke, H. Piontek, A. Luger, P. Wagner, Discrim ination of particles and defects on silicon wafers, Microelectron. Eng. 4"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_24", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 24, "text": "ology for 45nm Wafers, Yield Manag. Solut. (2007) 28‚Äì32. [16] F. Passek, R. Schmolke, H. Piontek, A. Luger, P. Wagner, Discrim ination of particles and defects on silicon wafers, Microelectron. Eng. 45 (1999) 191‚Äì196. https://doi.org/10.1016/S0167- 9317(99)00145- 8. [17] Y. Liu, T. Wei, M. Li, Z. Li, Z. Xue, X. Wei, Characterization of grown- in defects in Si wafers by gas decoration, Mater. Sci. Semicond. Process. 130 (2021) 105822. https://doi.org/10.1016/j.mssp.2021.105822. [18] K. Xu, R. Vos, G. Vereecke, M. Lux, W. Fyen, F. Holsteyns, K. Kenis, P.W. Mertens, M.M. Heyns, C. Vinckier, Relation between particle density and haze on a wafer: A new approach to measuring nano -sized particles, Solid State Phenom. 92 (2003) 161‚Äì164. https://doi.org/10.4028/www.scientific.net/ssp.92.161. [19] C.R. Brundle, Full wafer particle defect characterization, in: AIP Conf. Proc., AIP, 2001: pp. 285‚Äì291. https://doi.org/10.1063/1.1354412. [20] P. Huang, Defect mapping accuracy of KLA -Tencor Surfscan 6200, 6400, and SP1, in: AIP Conf. Proc., AIP, 2001: pp. 317‚Äì321. https:/ /doi.org/10.1063/1.1354418. [21] SEMI, SEMI M52 -0214 Guide For Specifying Scanning Surface Inspection Systems For Silicon W"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_25", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 25, "text": "n 6200, 6400, and SP1, in: AIP Conf. Proc., AIP, 2001: pp. 317‚Äì321. https:/ /doi.org/10.1063/1.1354418. [21] SEMI, SEMI M52 -0214 Guide For Specifying Scanning Surface Inspection Systems For Silicon Wafers For The 130 nm To 11 nm, 2014. [22] C. Kupfer, H. Roth, H. Dietrich, Defect requirements for advanced 300 mm DRAM substrates, M ater. Sci. Semicond. Process. 5 (2002) 381‚Äì386. https://doi.org/10.1016/S1369- 8001(02)00137- 3. [23] R.. Brown, F. Dupret, E. Dornberger, T. Sinno, W. von Ammon, Defect engineering of Czochralski single -crystal silicon, Mater. Sci. Eng. R Reports. 28 (2002) 149‚Äì198. https://doi.org/10.1016/s0927- 796x(00)00015- 2. [24] Z. Zheng, T. Seto, S. Kim, M. Kano, T. Fujiwara, M. Mizuta, S. Hasebe, A first -principle model of 300 mm Czochralski single -crystal Si production process for predicting crystal radius and crystal growth rate, J. Cryst. Growth. 492 (2018) 105‚Äì113. https://doi.org/10.1016/j.jc rysgro.2018.03.013. [25] A. Zandiatashbar, P.A. Taylor, B. Kim, Y. Yoo, K. Lee, A. Jo, J.S. Lee, S.- J. Cho, S. Park, Studying post -etching silicon crystal defects on 300mm wafer by automatic defect review AFM, (2016) 97782P. https://doi.org/10.1117/12.2220369. [2"}
{"id": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf::chunk_26", "source": "Surface Defect Classification in Silicon Wafer Manufacturing Using the.pdf", "chunk_index": 26, "text": ". Yoo, K. Lee, A. Jo, J.S. Lee, S.- J. Cho, S. Park, Studying post -etching silicon crystal defects on 300mm wafer by automatic defect review AFM, (2016) 97782P. https://doi.org/10.1117/12.2220369. [26] K.M. Saga, US10718720B2- Semiconductor wafer evaluation method and semiconductor wafer -2020.pdf, US010718720B2, 2020. [27] J. Vanhellemont, S. Senkader, G. Kissinger, V. Higgs, M. T, Measurement , modelling and simulation of defects in as -grown Cz ochralski silicon, 180 (1997) 353‚Äì362. [28] S.H. Lee, D.W. Song, H.J. Oh, D.H. Kim, Modeling of defects generation in 300mm silicon monocrystals during czochralski growth, Jpn. J. Appl. Phys. 49 (2010). https://doi.org/10.1143/JJAP.49.121303. [29] M.S. Kul karni, A selec tive review of the quantification of defect dynamics in growing Czochralski silicon crystals, Ind. Eng. Chem. Res. 44 (2005) 6246‚Äì6263. https://doi.org/10.1021/ie0500422. 10 Advanced Materials Research Vol. 1170"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_0", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 0, "text": "IFAC PapersOnLine 58-4 (2024) 174‚Äì179 ScienceDirect Available online at www.sciencedirect.com 2405-8963 Copyright ¬© 2024 The Authors. This is an open access article under the CC BY-NC-ND license . Peer review under responsibility of International Federation of Automatic Control. 10.1016/j.ifacol.2024.07.213 10.1016/j.ifacol.2024.07.213 2405-8963Copyright ¬© 2024 The Authors. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/ )Sustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. Thi"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_1", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 1, "text": "s facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated cal"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_2", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 2, "text": "the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_3", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 3, "text": "rap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the co"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_4", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 4, "text": "nergy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_5", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 5, "text": " PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines,"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_6", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 6, "text": "itachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is nowpossible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibrati"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_7", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 7, "text": "M) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constantimprovement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwas"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_8", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 8, "text": "ustries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from diffe"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_9", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 9, "text": "and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_10", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 10, "text": "iallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_11", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 11, "text": "a.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is nowpossible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_12", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 12, "text": "g on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constantimprovement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsdu"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_13", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 13, "text": " (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_14", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 14, "text": "chi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the product"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_15", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 15, "text": "ailable,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aa"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_16", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 16, "text": "IV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is nowpossible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead a"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_17", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 17, "text": "yof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_18", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 18, "text": "ay for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Sw"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_19", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 19, "text": "PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing proce"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_20", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 20, "text": "uction stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Iki"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_21", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 21, "text": " via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is nowpossible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawb"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_22", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 22, "text": "nd, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_23", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 23, "text": "ta collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digit"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_24", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 24, "text": "his research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from an"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_25", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 25, "text": "22b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_26", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 26, "text": "semble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is nowpossible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the p"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_27", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 27, "text": "y Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufactu"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_28", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 28, "text": "ficant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Gr"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_29", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 29, "text": "workstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data a"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_30", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 30, "text": " performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approach Kiavash"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_31", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 31, "text": "est PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approach Kiavash Fathi et al. / IF AC PapersOnLine 58-4 (2024) 174‚Äì179 175 Copyright ¬© 2024 The Authors. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/ )Sustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemicon"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_32", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 32, "text": " now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP re"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_33", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 33, "text": "thods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the indu"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_34", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 34, "text": "nd energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). H"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_35", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 35, "text": " production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_36", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 36, "text": "l (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_37", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 37, "text": "ne of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reducti"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_38", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 38, "text": "e accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_39", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 39, "text": "ng production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm da"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_40", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 40, "text": "064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_41", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 41, "text": "n line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous m"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_42", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 42, "text": "en.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further,"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_43", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 43, "text": " interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable pr"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_44", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 44, "text": ". In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.ava"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_45", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 45, "text": "tzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_46", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 46, "text": "s are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustaina"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_47", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 47, "text": "vash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues,"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_48", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 48, "text": "acks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_49", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 49, "text": "Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Te"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_50", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 50, "text": "al Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accu"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_51", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 51, "text": "y (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IV"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_52", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 52, "text": "Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs predictio"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_53", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 53, "text": "production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predi"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_54", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 54, "text": "uring. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Ap"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_55", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 55, "text": "rant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test un"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_56", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 56, "text": "accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachSustainability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_57", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 57, "text": "ability in Semiconductor Production via Interpretable and Reliable Predictions‚ãÜ Kiavash FathiI,1,2Maria StramagliaII,3Marko RistinIII ,1 Marcin SadurskiIV ,1Tobias KleinertV,2 Robert Sch¬® onfelderVI ,3Hans Wernher van de VennVII, 1 Ikiavash.fathi@rwth-aachen.de,IImaria.stramaglia@hitachienergy.com IIIrist@zhaw.ch ,IVsadu@zhaw.ch,Vkleinert@plt.rwth-aachen.de, VIrobert.schoenfelder@hitachienergy.com ,VIIvhns@zhaw.ch Abstract: Sustainability in production stands out as one of the foremost achievements facilitated by Industry 4.0. With the continuous monitoring of production lines, it is now possible to detect quality deviations at their earliest occurrence and reduce the scrap productionrate. This paper studies the sustainability in context of a partially monitored multistagesemiconductor production line with multiple test units. Our goal is to provide a foundationfor interpretable and reliable Product Quality Prediction (PQP) in industrial use cases withnoisy quality check results and missing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners."}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_58", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 58, "text": "ssing process information. To that end, we examine how theaccumulated process information from different steps of the production line impacts the accuracyof the PQP models used later as base learners. Furthermore, we highlight the drawbacks ofconventional model stacking on the accuracy due to base learner‚Äôs prediction quantization. Wepropose instead an interpretable stacked model (SM) from base learners‚Äô predicted probabilityvalues, and demonstrate how it increases the accuracy and reliability of the predictions. Toimprove the results even further, we analyze different calibration methods both for base learnersand the SM. Our final model leads to a 19 .49% reduction in the binary estimated calibration error compared to the conventional models, and thus allows for increased PQP reliability. Keywords: Model reliability, Interpretable AI, Quality prediction, Industry 4.0. 1. INTRODUCTION One of the most significant impacts of Industry 4.0, i.e.the digitalization of the industrial processes, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transf"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_59", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 59, "text": "s, is the constant improvement in data collection from different processesand production assets in industrial manufacturing. Thegathered data paves the way for sustainability and tech-nological transformations in numerous areas such as Prod- uct Quality Prediction (PQP) (Lieber et al., 2013), and preventive and predictive maintenance (Bai et al., 2020). In the domain of PQP, many industries opt for continu- ous quality monitoring to detect early quality deviationsduring production to reduce the scrap rate. This, in turn,leads to more sustainable production due to less materialwaste and energy consumption (Schulze Struchtrup et al.,2020). In particular, one of the industries heavily invest-ing in PQP is the semiconductor manufacturing. Giventhe complexity of the products, the industrial settings inthis area have progressed from single-stage manufacturingto multistage manufacturing systems involving multipleworkstations (Arif et al., 2013). The current PQP methodsin semiconductor industry face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-per"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_60", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 60, "text": "y face limitations due to delayed ‚ãÜThis research was supported by Innosuisse - Swiss Innovation Agency, Inno- suisse Grant no: 51514.1 IP-ENG , entitled PreTune, Predictive Process Tuning by multi-perspective data analysis using a Digital Twin in collaboration with Hitachi Energy Switzerland. 1Zurich University of Applied Sciences, 8400 Winterthur, Switzerland. 2Chair of Information and Automation Systems for Process and Material Technology, RWTH Aachen University, 52064 Aachen, Germany.3Hitachi Energy Semiconductors, 5600 Lenzburg, Switzerland.availability of the data from different production stages. Regardless of the source of information (process data,alarm data, etc.), they rely on the complete information from the production line (Melhem et al., 2017; Jebrilet al., 2022). However, the complete process informationis seldomly available. These methods are thus impracticalfor manufacturing settings where performance, sustain-ability and detection of errors at earliest occurrence areof utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production s"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_61", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 61, "text": "f utmost importance (Wang et al., 2022b). As a viablealternative, we start by training separate PQP models onthe data accumulated during the initial production stage(see Fig. 1). Once the production starts, i.e., as soon as data from any (new) stages of production is available,the test results from all of the test units (TUs) in themanufacturing process are predicted using these initiallytrained PQP models. We then continuously accumulateinformation from the production line to acquire more Stage 1 PQP Data: Stage 1 TU 1 PQP model (PQP 1.1) TU 2 PQP model (PQP 1.2) Final test PQP model (PQP 1.3)Stage 2 PQP Data: Stages 1 & 2 TU 1 PQP model (PQP 2.1) TU 2 PQP model (PQP 2.2) Final test PQP model (PQP 2.3)Stage 3 PQP Data: Stages 1, 2 & 3 TU 1 PQP model (PQP 3.1) TU 2 PQP model (PQP 3.2) Final test PQP model (PQP 3.3)Stage 4 PQP Data: Stage 1, 2, 3 & 4 TU 1 PQP model (PQP 4.1) TU 2 PQP model (PQP 4.2) Final test PQP model (PQP 4.3)Stage 5 PQP Data: Stage 1, untill 5 TU 2 PQP model (PQP 5.2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachaccurate estimation of the product quality measured at the last TU. As our PQP models are"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_62", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 62, "text": "2) Final test PQP model (PQP 5.3) Ensemble model Calibrated ensemble model Fig. 1. Overview of our PQP approachaccurate estimation of the product quality measured at the last TU. As our PQP models are trained for differentstages of the production, we do not have to wait for theprocesses to finish to make a reliable and accurate PQP. Additionally, there are sources of uncertainties in the semiconductor production lines which need to be takeninto account for achieving reliable estimations. Calibrat-ing probability estimations of the trained classifiers iscommonly used to mitigate this issue in safety-criticalsystems (Vaicenavicius et al., 2019). To the best of ourknowledge, calibrated probability estimations for PQP inthe context of the industrial manufacturing has not beenstudied. We refer to them as the Production Success Prob- ability (PSP) in this particular setting for clarity. To demonstrate the utility of PSP, we study an operatingproduction line as a use case. The production line containsmultiple TUs with only the final TU having a fixedfail-pass criteria. Consequently, the results of the TUspreceding the final TU give us only blurred information,and therefore represent a sou"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_63", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 63, "text": " containsmultiple TUs with only the final TU having a fixedfail-pass criteria. Consequently, the results of the TUspreceding the final TU give us only blurred information,and therefore represent a source of uncertainty. The rawmaterials coming from different vendors also impact thequality, and are another source of uncertainty. This allmakes it hard for the process engineer to make decisionsabout the final product quality. To help reduce the uncertainties and improve the decision making, we propose to stack multiple PQP models anduse their PSPs to predict the output of the final TU.We use model stacking (Dong et al., 2020) via logisticregression (LR) at the heart of our method, which givesus interpretability and also a boost in reliability withoutsacrificing the accuracy of the final PQP model. Using thePSP values for the stacked model (SM) also makes ourapproach demonstratively more data-efficient and evadesmuch of the unwanted bias compared to the conventionalcalibration methods, which need separate datasets forcalibration to reach a comparable level of reliability andaccuracy. Our main contributions are thus three-fold. We: (1)Propose a PQP model which operates on partial in- fo"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_64", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 64, "text": "ch need separate datasets forcalibration to reach a comparable level of reliability andaccuracy. Our main contributions are thus three-fold. We: (1)Propose a PQP model which operates on partial in- formation from the production line and at its earliestavailability, (2)Provide analysis on the performance boost given theinformation available from production line, (3)Formulate an interpretable and data-efficient SMfrom the PQP predictions for better accuracy andincreased reliability for industry. The high accuracy of our approach as well as its abilityto operate on incomplete data and handle uncertaintiesmake it possible to use cost-effective PQP models inthe industry. While the method is demonstrated on asemiconductor production line, it is easily generalizableto other fields of manufacturing as well. 2. PRODUCTION LINE UNDER STUDY We demonstrate our approach on an operational produc-tion line from a working factory. It has important charac-teristics that guided the design of our method which weexamine here. However, our method is not restricted tothis line, and can be applied in a much wider range ofsettings. The fail-pass criteria for intermediate quality tests are not fixed and ar"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_65", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 65, "text": "which weexamine here. However, our method is not restricted tothis line, and can be applied in a much wider range ofsettings. The fail-pass criteria for intermediate quality tests are not fixed and are improved as more products are produced.However, the final TU is a fixed criteria which ensures therequired specifications of the semiconductor are met whenoffered to the customers. Moreover, some processes whichimpact the final product quality are not monitored, seeFig. 2. Given the high uncertainty induced by the unmon-itored processes, a probability value showing the chancesof producing a successful product is far more practicalthan a simple binary output of the PQP (Vaicenaviciuset al., 2019). By focusing on the probability values, wecan infer the confidence of the classifier for predictingthe final product quality given the currently availableprocess information. Additionally, when trained and cali-brated correctly, these well-adjusted probability values willalso increase the accuracy of the predictions. The above-mentioned issues and characteristics make the methoddeveloped in this paper fundamentally different from singleTU, observable and fixed quality criteria evaluation inse"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_66", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 66, "text": "y of the predictions. The above-mentioned issues and characteristics make the methoddeveloped in this paper fundamentally different from singleTU, observable and fixed quality criteria evaluation insemiconductor quality prediction research papers Jebrilet al. (2022); Wang et al. (2022b); Heo et al. (2021). 3. RELATED WORK There are mainly two families of approaches to PQP ofmultistage production lines. The first family leveragesknowledge-based systems and the second family encom-passes data-driven approaches. Data-driven approachesneed only enough data and dispense of the domain knowl-edge, thus tend to be faster to develop and less error-prone.Mdet al. provide a thorough analysis of both families (Md et al., 2022). Our work follows the data-driven approachfor its benefits. Given the limited quality and quantity of the available process and TU data from production lines, data-drivenPQP can be challenging. In particular, the following issueshave to be addressed according to the literature from boththe data-driven PQP and process monitoring communities. Unbalanced data: The available data from a production line is usually highly unbalanced, with either failed or successful products u"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_67", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 67, "text": "re from boththe data-driven PQP and process monitoring communities. Unbalanced data: The available data from a production line is usually highly unbalanced, with either failed or successful products under-represented. At the beginning,there are many failed products, but their rate diminishesstrongly with more experience and the quality monitoringof the production (Wang et al., 2022b). Consequently,PQP system must inherently deal with unbalanced data,either with under/oversampling, sample weighting, orother problem-specific solutions (Kov¬¥ acs, 2019). More-over, accuracy measures which realistically reflect modelperformance are critical. Though these issues are welladdressed in the machine learning community, they arestill understudied in the domain of PQP (Melhem et al.,2017; Wang et al., 2019; Gu et al., 2023). We use different Process 1: Subprocess 1 Subprocess 2 Subprocess 3 Process 2: Subprocess 1Stage 1 Process 3: Subprocess 1Stage 2 Process 1: Subprocess 4 Process 2: Subprocess 2Stage 3 Process 3: Subprocess 2Stage 4 Process 4: All subprocessesStage 5 Unmonitored processes Final test unitTest unit 1 Test unit 2Production start Fig. 2. Semiconductor production processes and TU"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_68", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 68, "text": "Stage 3 Process 3: Subprocess 2Stage 4 Process 4: All subprocessesStage 5 Unmonitored processes Final test unitTest unit 1 Test unit 2Production start Fig. 2. Semiconductor production processes and TUs 176 Kiavash Fathi et al. / IF AC PapersOnLine 58-4 (2024) 174‚Äì179 sample weighting, among other parameters, in grid search to acquire the highest possible balanced accuracy. Generalization and model interpretability: In the current Industry 4.0 settings, individualized batch productions are increasingly favored. This trend makes quality data scarcewhile simultaneously increasing its structural complexity.Data-driven models need to thus handle high-dimensionaland small samples of quality information from the pro-duction line (Yu et al., 2021). One of the most effectiveways to increase the generalization capability and sta-bility of the trained models in this scenario is ensemblelearning (Li et al., 2021). This method ensembles multiplemodels, called base learners , to boost performance. More- over, interpretable ensemble models give insights on theimportance of individual base learners (Dong et al., 2020).We embrace ensemble learning in our work to achieve bothhigh accuracy and good i"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_69", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 69, "text": "ore- over, interpretable ensemble models give insights on theimportance of individual base learners (Dong et al., 2020).We embrace ensemble learning in our work to achieve bothhigh accuracy and good interpretability. Model reliability requirements: Serving as a consultant to the process engineer, the trained PQP model should both be accurate and indicate the confidence of the pre-diction (Silva Filho et al., 2023). Many learning algo-rithms extensively used in PQP, such as support vectormachines (SVM) and boosted trees, push the predictedprobability values away from 0 and 1. The predictionprobabilities cluster closer to 0 .5 which deteriorates their quality (Niculescu-Mizil and Caruana, 2005). With thisshortcoming of the used boosted models in mind, wecalibrate the PSP values coming from base learners andprevent the accuracy loss due to PSP binary quantizationby stacking the PSP values. Deployability of the model: In the similar vein, Yu et al. propose to stack different methods such as SVM, boosted tree, etc.to boost performance (Yu et al., 2021). Despite promising results in a fixed and stationary setting, suchmethods neglect the complexity of model maintenance inan ever-changing"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_70", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 70, "text": "s SVM, boosted tree, etc.to boost performance (Yu et al., 2021). Despite promising results in a fixed and stationary setting, suchmethods neglect the complexity of model maintenance inan ever-changing industrial setting (Huyen, 2022; Sculleyet al., 2015). Instead of using different algorithms fortraining base learners, which is operationally difficult, weexploit the the fact that base learners trained for differentstages use different subsets of the sensor readings from theproduction line. This allows us to train base learners inseparation and greatly simplifies the maintenance in termsof machine learning operations (MLOps). 4. PRELIMINARIES Model calibration: According to Dimitriadis et al. (2020) a binary probabilistic classifier f:X‚Üí[0,1] with the instant space Xand binary target space Y={‚àí,+}is calibrated if ‚àÄs‚àà[0,1] :P(Y=+|f(X)=s)=s (1) In numerous applications, especially safety-critical systemswhich employ machine learning, it is of great importancethat the trained model expresses its true predictive un-certainty which raises the need for well calibrated mod-els (Vaicenavicius et al., 2019). The reliability diagramserves as the main diagnostic tool to assess calibration.This"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_71", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 71, "text": "es its true predictive un-certainty which raises the need for well calibrated mod-els (Vaicenavicius et al., 2019). The reliability diagramserves as the main diagnostic tool to assess calibration.This diagram depicts the correlation between the observedevent frequencies and the predictive probabilities. In thecase of a well calibrated model, the aforementioned quanti-ties must match and thus the plotted points in a reliabilitydiagram are expected to lie close to the diagonal (Br¬® ocker,2008). In what follows, the best performing method usedfor model calibration in this paper is presented. For moredetails regarding other methods used in this paper pleaserefer to Silva Filho et al. (2023). Platt calibration: This method tries to calibrate a model by passing its posterior probabilities through a sigmoid function by minimizing the following cost function viagradient descent for a given set ( f(x i),yi) A, B argmin{‚àí/summationdisplay iyilog(pi)+( 1 ‚àíyi)log(1‚àípi)} (2) where pi=1 1+exp(Af(xi)+B )(3) Binary estimated calibration error (Binary-ECE): In this paper, we have used the Binary-ECE as the performancemeasure for model calibration: Binary ECE =M/summationdisplay m=1|Bm| N|¬Øy(Bm)‚àí¬Øs("}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_72", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 72, "text": "+B )(3) Binary estimated calibration error (Binary-ECE): In this paper, we have used the Binary-ECE as the performancemeasure for model calibration: Binary ECE =M/summationdisplay m=1|Bm| N|¬Øy(Bm)‚àí¬Øs(Bm)| (4) where Mdenotes the number of bins in the reliability diagram, Nis the number of data points, Bmrepresents the number of data points in each bin, and lastly ¬Ø y(Bm) and ¬Øs(Bm) represent the proportion of positives and the average probability respectively. 5. PROPOSED METHOD 5.1 Data preparation The process information along with the test results from different TUs in the production line, are stored separatelyin different tables of a database. As it can be seen in Fig. 2,many processes are revisited so that different subprocessescan be carried out on the currently produced batch. Thus,for generating input/output data for model training, thefollowing steps have to be completed. (1)Separating subprocess data: Based on factors such as part name, recipe name, etc., the data from a process table is divided into different subprocessdatasets. (2)Cleaning and annotating the subprocess data:Given any arbitrary product, it is possible to findall the subprocess and, if available, test resu"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_73", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 73, "text": "ss table is divided into different subprocessdatasets. (2)Cleaning and annotating the subprocess data:Given any arbitrary product, it is possible to findall the subprocess and, if available, test results usingthe product‚Äôs ID. However, due to data storage, testand sensor reading errors, in some cases there will bemissing information which has to be handle when theproduct quality model is deployed. (3)Subprocess data preprocessing: Features which are categorical, e.g., program name, recipe name, nuzzle ID, etc., need to be encoded so that they can be used in input vector. In addition, the encoders mustbe stored so that they can be used in real-time asthe production is in progress. Moreover, time stampsand delta time also need to be converted to integeror float values. 5.2 Model training In this industrial project, for each stage of processes, separate models for predicting the test results for all Kiavash Fathi et al. / IF AC PapersOnLine 58-4 (2024) 174‚Äì179 177 sample weighting, among other parameters, in grid search to acquire the highest possible balanced accuracy. Generalization and model interpretability: In the current Industry 4.0 settings, individualized batch productions ar"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_74", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 74, "text": "other parameters, in grid search to acquire the highest possible balanced accuracy. Generalization and model interpretability: In the current Industry 4.0 settings, individualized batch productions are increasingly favored. This trend makes quality data scarcewhile simultaneously increasing its structural complexity.Data-driven models need to thus handle high-dimensionaland small samples of quality information from the pro-duction line (Yu et al., 2021). One of the most effectiveways to increase the generalization capability and sta-bility of the trained models in this scenario is ensemblelearning (Li et al., 2021). This method ensembles multiplemodels, called base learners , to boost performance. More- over, interpretable ensemble models give insights on theimportance of individual base learners (Dong et al., 2020).We embrace ensemble learning in our work to achieve bothhigh accuracy and good interpretability. Model reliability requirements: Serving as a consultant to the process engineer, the trained PQP model should both be accurate and indicate the confidence of the pre-diction (Silva Filho et al., 2023). Many learning algo-rithms extensively used in PQP, such as support vector"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_75", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 75, "text": "neer, the trained PQP model should both be accurate and indicate the confidence of the pre-diction (Silva Filho et al., 2023). Many learning algo-rithms extensively used in PQP, such as support vectormachines (SVM) and boosted trees, push the predictedprobability values away from 0 and 1. The predictionprobabilities cluster closer to 0 .5 which deteriorates their quality (Niculescu-Mizil and Caruana, 2005). With thisshortcoming of the used boosted models in mind, wecalibrate the PSP values coming from base learners andprevent the accuracy loss due to PSP binary quantizationby stacking the PSP values. Deployability of the model: In the similar vein, Yu et al. propose to stack different methods such as SVM, boosted tree, etc.to boost performance (Yu et al., 2021). Despite promising results in a fixed and stationary setting, suchmethods neglect the complexity of model maintenance inan ever-changing industrial setting (Huyen, 2022; Sculleyet al., 2015). Instead of using different algorithms fortraining base learners, which is operationally difficult, weexploit the the fact that base learners trained for differentstages use different subsets of the sensor readings from theproduction lin"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_76", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 76, "text": "s fortraining base learners, which is operationally difficult, weexploit the the fact that base learners trained for differentstages use different subsets of the sensor readings from theproduction line. This allows us to train base learners inseparation and greatly simplifies the maintenance in termsof machine learning operations (MLOps). 4. PRELIMINARIES Model calibration: According to Dimitriadis et al. (2020) a binary probabilistic classifier f:X‚Üí[0,1] with the instant space Xand binary target space Y={‚àí,+}is calibrated if ‚àÄs‚àà[0,1] :P(Y=+|f(X)=s)=s (1) In numerous applications, especially safety-critical systemswhich employ machine learning, it is of great importancethat the trained model expresses its true predictive un-certainty which raises the need for well calibrated mod-els (Vaicenavicius et al., 2019). The reliability diagramserves as the main diagnostic tool to assess calibration.This diagram depicts the correlation between the observedevent frequencies and the predictive probabilities. In thecase of a well calibrated model, the aforementioned quanti-ties must match and thus the plotted points in a reliabilitydiagram are expected to lie close to the diagonal (Br¬® ocker,2"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_77", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 77, "text": "obabilities. In thecase of a well calibrated model, the aforementioned quanti-ties must match and thus the plotted points in a reliabilitydiagram are expected to lie close to the diagonal (Br¬® ocker,2008). In what follows, the best performing method usedfor model calibration in this paper is presented. For moredetails regarding other methods used in this paper pleaserefer to Silva Filho et al. (2023). Platt calibration: This method tries to calibrate a model by passing its posterior probabilities through a sigmoid function by minimizing the following cost function viagradient descent for a given set ( f(x i),yi) A, B argmin{‚àí/summationdisplay iyilog(pi)+( 1 ‚àíyi)log(1‚àípi)} (2) where pi=1 1+exp(Af(xi)+B )(3) Binary estimated calibration error (Binary-ECE): In this paper, we have used the Binary-ECE as the performancemeasure for model calibration: Binary ECE =M/summationdisplay m=1|Bm| N|¬Øy(Bm)‚àí¬Øs(Bm)| (4) where Mdenotes the number of bins in the reliability diagram, Nis the number of data points, Bmrepresents the number of data points in each bin, and lastly ¬Ø y(Bm) and ¬Øs(Bm) represent the proportion of positives and the average probability respectively. 5. PROPOSED METHOD 5.1 Data "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_78", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 78, "text": "a points, Bmrepresents the number of data points in each bin, and lastly ¬Ø y(Bm) and ¬Øs(Bm) represent the proportion of positives and the average probability respectively. 5. PROPOSED METHOD 5.1 Data preparation The process information along with the test results from different TUs in the production line, are stored separatelyin different tables of a database. As it can be seen in Fig. 2,many processes are revisited so that different subprocessescan be carried out on the currently produced batch. Thus,for generating input/output data for model training, thefollowing steps have to be completed. (1)Separating subprocess data: Based on factors such as part name, recipe name, etc., the data from a process table is divided into different subprocessdatasets. (2)Cleaning and annotating the subprocess data:Given any arbitrary product, it is possible to findall the subprocess and, if available, test results usingthe product‚Äôs ID. However, due to data storage, testand sensor reading errors, in some cases there will bemissing information which has to be handle when theproduct quality model is deployed. (3)Subprocess data preprocessing: Features which are categorical, e.g., program name, recip"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_79", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 79, "text": "ome cases there will bemissing information which has to be handle when theproduct quality model is deployed. (3)Subprocess data preprocessing: Features which are categorical, e.g., program name, recipe name, nuzzle ID, etc., need to be encoded so that they can be used in input vector. In addition, the encoders mustbe stored so that they can be used in real-time asthe production is in progress. Moreover, time stampsand delta time also need to be converted to integeror float values. 5.2 Model training In this industrial project, for each stage of processes, separate models for predicting the test results for all Fig. 3. Balanced accuracy of the trained base learners three TUs are trained. Furthermore, given the additional challenges of unmonitored processes and the significantreduction of the number of available samples for training,from 2267 samples to only 756 samples, the developmentof the PQP models used for predicting the results from thelast TU, depicted as green blocks in Fig. 1, are discussedextensively in subsections 5.4 and 5.5 of this paper. Inshort, in the current configuration, the PQP models forpredicting the output of the first and second TU are merelygradient boosted "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_80", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 80, "text": "are discussedextensively in subsections 5.4 and 5.5 of this paper. Inshort, in the current configuration, the PQP models forpredicting the output of the first and second TU are merelygradient boosted trees trained separately for each stage.These models are also referred to as the base learners.For the final TU, in addition to the gradient boostedtrees trained for each stage, these models are stacked andcalibrated for enhancing the performance of the trainedmodels and also to increase their reliability. 5.3 Base learners In the conducted study, the base learners are gradient boosted trees, which are implemented using the XGBoostlibrary (Chen and Guestrin, 2016). The potential changesin the production, e.g., recipe changes, and also the need for a model suitably trained for a given manufacturingsetting, raises the need for a generalizable solution whichis perfectly tailored to the production line settings. There-fore, the hyperparameters of the base learners are acquiredusing grid search. In the current implementation, thehyperparameters maximum tree depth, learning rate and number of estimators are determined using grid search. Furthermore, to address the issue with imbalanced datai"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_81", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 81, "text": ". In the current implementation, thehyperparameters maximum tree depth, learning rate and number of estimators are determined using grid search. Furthermore, to address the issue with imbalanced datain the production line and also promote the generalizationcapability of the base learners, the grid search also containsthe hyperparameter class weight. Moreover, to keep the ratio of the positive and negativeclasses almost constant during training and testing andalso to avoid optimistic accuracy estimates, while splittingthe available data from the production line, the methodused for splitting the data is stratified. In addition, giventhe fact that the number of labeled samples in a productionline is normally limited, in the proposed method, k-foldcross validation with is used to further increase the gener-alization power of the trained base learner. The balancedaccuracy of the trained base learners is depicted in Fig. 3.The numbers next to each plotted point denote the numberof features used in the predictor. As it can be seen in Fig. 3,the information attained during the second stage of assem-bly does not increase the PQP model prediction accuracyfor any of the TUs. Furthermore, the "}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_82", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 82, "text": "sed in the predictor. As it can be seen in Fig. 3,the information attained during the second stage of assem-bly does not increase the PQP model prediction accuracyfor any of the TUs. Furthermore, the accumulated infor-mation from stages three and four does not significantlyincrease the accuracy of the first PQP model. The secondPQP model on the other hand shows a slight improvementin accuracy as more information is available from the pro-duction line compared to its accuracy when only trainedwith the data from the first stage. In addition, the resultsdepicted in Fig. 3 clearly demonstrate the importance ofaccumulated stage data on the accuracy of predicting thefinal TU‚Äôs output. Starting from the third stage, as morefeatures are exposed to the base learners, the accuracy ofthe predictions is increased. This step-wise model trainingprovides insight to the improved accuracy given the cost(number of features) while accumulating stage informationwhich facilitates cost-effective PQP model developmentfor multistage semiconductor production. Despite the highaccuracy of the base learners (outperforming the similarwork with the balanced accuracy of 71 .15% and 64.56% in Melhem et al. (2017)"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_83", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 83, "text": "evelopmentfor multistage semiconductor production. Despite the highaccuracy of the base learners (outperforming the similarwork with the balanced accuracy of 71 .15% and 64.56% in Melhem et al. (2017) and Tin et al. (2022) respectively),no assumption or prior knowledge from the productionline is imposed on the training algorithm. In addition, theinput vector to base learners in each step is also differentwhich further promotes decorrelated bagging (James et al.(2013)). 5.4 Ensemble model We tested several data fusion and model stacking strate- gies. The domain knowledge from the production linesuggested that by fusing the first and second TU resultsin the input vector of the PQP model for the final TU, theaccuracy should potentially increase; however, the resultsof the training rejected this hypothesis. For inspectingthis issue, the Pearson correlation (Cohen et al. (2009))between the TUs‚Äô results are calculated and a maximumcorrelation value of 0. 091 between the first TU and Final TU is acquired. This denotes the fact that, given theinformation from an arbitrary TU, it is not possible to inferanything substantial for the other TUs in the productionline. This issue can be blamed o"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_84", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 84, "text": " is acquired. This denotes the fact that, given theinformation from an arbitrary TU, it is not possible to inferanything substantial for the other TUs in the productionline. This issue can be blamed on the fact that these TUsinspect different key performance aspects of the producedsemiconductors and thus their values are not correlated.Similarly, concatenating the predictions from the baselearners for the different TUs to the input vector did notincrease the accuracy of the ensemble model either. As the last attempt, unlike conventional stacking ap- proaches found in the related work, in this paper we use thepredicted PSP of the last three base learners for predictingthe results of the final TU, and map the generated vectorfrom these PQP model to the final TU result. By employ-ing the predicted PSP values from the PQP models, it ispossible to prevent the potential information loss due tothe quantization of the output to two possible outputs.This idea originates from knowledge distillation, wherein the vanilla knowledge distillation case, the logits of alarge deep model as the teacher are used to train a smallernetwork (Wang et al., 2022a). However, instead of traininga smaller mode"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_85", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 85, "text": "ion, wherein the vanilla knowledge distillation case, the logits of alarge deep model as the teacher are used to train a smallernetwork (Wang et al., 2022a). However, instead of traininga smaller model and trying to make the distribution ofthe logits as close as possible, we merely use this so-calledknowledge from different base learners to make better pre-dictions. The results of the aforementioned model stackingresulted in a 0.18% increase in the balanced accuracy anda 19. 49% reduction in binary-ECE. In addition, stack- 178 Kiavash Fathi et al. / IF AC PapersOnLine 58-4 (2024) 174‚Äì179 Table 1. SM parameters Stage 3 Stage 4 Stage 5 Intercept 0.000 2.526 12.685 -7.630 Table 2. Balanced accuracy and binary-ECE Model name Balanced accuracy Binary-ECE Base learner (baseline) 73.32% 0.159 SM 73.50% 0.128 Isotonic - base learner 71.94% 0.161 Sigmoid - SM 74.23% 0.128 Binning - base leaner 68.41% 0.112 Binning - SM 70.67% 0.143 ing the base learners with LR addresses the issue of the boosted trees with the predicted probability values whichare pushed away from 0 and 1 (Fig. 4(a) and Fig. 4(b))resulting in a more reliable model than the base learners.The reliability test diagrams are gen"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_86", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 86, "text": "d trees with the predicted probability values whichare pushed away from 0 and 1 (Fig. 4(a) and Fig. 4(b))resulting in a more reliable model than the base learners.The reliability test diagrams are generated from the testdata which is not exposed to any steps of data cleaning,data preprocessing and model training. Fig. 4(a) clearlyindicates the fact that the majority of the predicted PSPvalues, 112 data points, from a base learner are between40% and 60% which reflect the model uncertainty whilepredicting the final product quality. The coefficient of different PSP values and the intercept of the SM is depicted in Table 1. LR as one of themost interpretable models, provides insight into the mostimportant PSP values and also how their combinationhelps predict the output of the final TU. Additionally, fromMLOps point of view, our choice of LR simplifies ensemblemodel maintenance as a LR model is both straightforwardto (re-)train and interpretable (Huyen (2022)). 5.5 Model calibration As the last step of PQP model development, we aim to increase the reliability of the trained models via modelcalibration. We have used the Scikit-learn and PyCaliblibraries (Pedregosa et al., 2011; Silva Fi"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_87", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 87, "text": " last step of PQP model development, we aim to increase the reliability of the trained models via modelcalibration. We have used the Scikit-learn and PyCaliblibraries (Pedregosa et al., 2011; Silva Filho et al., 2023)for model calibration. The reliability diagram of the bestperforming model can be seen in Fig. 4(c). 6. RESULTS In this section, the balanced accuracy and the binary-ECEas the reliability criteria are compared for the developedPQP models. As can be seen in Table. 2, the proposedmodel stacking significantly increases the reliability of thebase learners as the binary-ECE is reduced by 19 .49%. In addition compared to the best base learner as thebaseline, there is a 0 .91% increase in the balanced accuracy of the model. The model with the lowest binary-ECE isthe binning calibrated base learner. However, given thefact that the training data used for training the PQPmodels are eventually also used for calibrating the model,there is the unavoidable introduced bias in the modeltraining (Niculescu-Mizil and Caruana, 2005). In case thatthe training data points were not as limited as in thecurrent study, 756 samples each containing 878 features, asubset of the training data poin"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_88", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 88, "text": "aining (Niculescu-Mizil and Caruana, 2005). In case thatthe training data points were not as limited as in thecurrent study, 756 samples each containing 878 features, asubset of the training data points should be set aside formodel calibration to avoid performance drop. 7. DISCUSSION Interpretability and reliability of data-driven models playa significant role in their acceptance as a solution indecision-making-related tasks. As in the studied produc-tion line, many industrial use cases suffer from the inher-ent uncertainty induced by factors such as raw materialvendors, and also the lack of knowledge about unmoni-tored processes in their production line. In these stochasticand complex settings, it is vital to train models whichclearly pinpoint the most important predictors in theirdecisions and also indicate how confident they are abouttheir predictions. The model stacking from PSP values andthe post hoc calibration presented in this paper aimedto shed light on the importance of reliability tests fordata-driven models used in critical and cost sensitive mul-tistage production settings. During development of theproposed method, we focused on having all the steps fromdata preprocess"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_89", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 89, "text": "bility tests fordata-driven models used in critical and cost sensitive mul-tistage production settings. During development of theproposed method, we focused on having all the steps fromdata preprocessing up to model training as modular andgeneralizable as possible given the potential changes inthe production lines which include, but are not limitedto, updates in the recipe and optimization of productionprocedure. In addition, we did not incorporate any domainknowledge from semiconductor industry in model trainingand merely aimed to account for high stochasticity of theentire production. 8. CONCLUSION The results of this study demonstrate a significant reduc-tion in the binary-ECE by 19 .49% with the side benefit of 0.91% increase in the balanced accuracy of the calibrated SM. We also demonstrate the steps needed to developimpactful PQP models for settings with limited and un-balanced training samples such that they can be easilyreproduced in practice to other settings. In the future, wewant to focus more on the maintenance of the developedPQP models. In particular, we plan to inspect the impactof data distribution shifts on the confidence levels of thePQP models. Moreover, we aim t"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_90", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 90, "text": "ewant to focus more on the maintenance of the developedPQP models. In particular, we plan to inspect the impactof data distribution shifts on the confidence levels of thePQP models. Moreover, we aim to develop a module fortriggering a retraining process for either the base learneror the SM, or to trigger a recalibration of the PQP models.This would finally close the MLOps loop for effective data-driven solutions. REFERENCES Arif, F., Suryana, N., and Hussin, B. (2013). A data mining approach for developing quality prediction modelin multi-stage manufacturing. International Journal of Computer Applications, 69(22). Bai, C., Dallasega, P., Orzes, G., and Sarkis, J. (2020). Industry 4.0 technologies assessment: A sustainabilityperspective. International journal of production eco- nomics , 229, 107776. Br¬® ocker, J. (2008). Some remarks on the reliability of categorical probability forecasts. Monthly weather review, 136(11), 4488‚Äì4502. Chen, T. and Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discoveryand data mining, 785‚Äì794. Cohen, I., Huang, Y., Chen, J., Benesty, J., Benesty, J., Chen, J.,"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_91", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 91, "text": "tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discoveryand data mining, 785‚Äì794. Cohen, I., Huang, Y., Chen, J., Benesty, J., Benesty, J., Chen, J., Huang, Y., and Cohen, I. (2009). Pearson cor-relation coefficient. Noise reduction in speech processing, 1‚Äì4. Dimitriadis, T., Gneiting, T., and Jordan, A.I. (2020). Evaluating probabilistic classifiers: Reliability diagrams Kiavash Fathi et al. / IF AC PapersOnLine 58-4 (2024) 174‚Äì179 179 Table 1. SM parameters Stage 3 Stage 4 Stage 5 Intercept 0.000 2.526 12.685 -7.630 Table 2. Balanced accuracy and binary-ECE Model name Balanced accuracy Binary-ECE Base learner (baseline) 73.32% 0.159 SM 73.50% 0.128 Isotonic - base learner 71.94% 0.161 Sigmoid - SM 74.23% 0.128 Binning - base leaner 68.41% 0.112 Binning - SM 70.67% 0.143 ing the base learners with LR addresses the issue of the boosted trees with the predicted probability values whichare pushed away from 0 and 1 (Fig. 4(a) and Fig. 4(b))resulting in a more reliable model than the base learners.The reliability test diagrams are generated from the testdata which is not exposed to any steps of data cleaning,data preprocessing and mode"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_92", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 92, "text": "))resulting in a more reliable model than the base learners.The reliability test diagrams are generated from the testdata which is not exposed to any steps of data cleaning,data preprocessing and model training. Fig. 4(a) clearlyindicates the fact that the majority of the predicted PSPvalues, 112 data points, from a base learner are between40% and 60% which reflect the model uncertainty whilepredicting the final product quality. The coefficient of different PSP values and the intercept of the SM is depicted in Table 1. LR as one of themost interpretable models, provides insight into the mostimportant PSP values and also how their combinationhelps predict the output of the final TU. Additionally, fromMLOps point of view, our choice of LR simplifies ensemblemodel maintenance as a LR model is both straightforwardto (re-)train and interpretable (Huyen (2022)). 5.5 Model calibration As the last step of PQP model development, we aim to increase the reliability of the trained models via modelcalibration. We have used the Scikit-learn and PyCaliblibraries (Pedregosa et al., 2011; Silva Filho et al., 2023)for model calibration. The reliability diagram of the bestperforming model can be seen"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_93", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 93, "text": "calibration. We have used the Scikit-learn and PyCaliblibraries (Pedregosa et al., 2011; Silva Filho et al., 2023)for model calibration. The reliability diagram of the bestperforming model can be seen in Fig. 4(c). 6. RESULTS In this section, the balanced accuracy and the binary-ECEas the reliability criteria are compared for the developedPQP models. As can be seen in Table. 2, the proposedmodel stacking significantly increases the reliability of thebase learners as the binary-ECE is reduced by 19 .49%. In addition compared to the best base learner as thebaseline, there is a 0 .91% increase in the balanced accuracy of the model. The model with the lowest binary-ECE isthe binning calibrated base learner. However, given thefact that the training data used for training the PQPmodels are eventually also used for calibrating the model,there is the unavoidable introduced bias in the modeltraining (Niculescu-Mizil and Caruana, 2005). In case thatthe training data points were not as limited as in thecurrent study, 756 samples each containing 878 features, asubset of the training data points should be set aside formodel calibration to avoid performance drop. 7. DISCUSSION Interpretability a"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_94", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 94, "text": " in thecurrent study, 756 samples each containing 878 features, asubset of the training data points should be set aside formodel calibration to avoid performance drop. 7. DISCUSSION Interpretability and reliability of data-driven models playa significant role in their acceptance as a solution indecision-making-related tasks. As in the studied produc-tion line, many industrial use cases suffer from the inher-ent uncertainty induced by factors such as raw materialvendors, and also the lack of knowledge about unmoni-tored processes in their production line. In these stochasticand complex settings, it is vital to train models whichclearly pinpoint the most important predictors in theirdecisions and also indicate how confident they are abouttheir predictions. The model stacking from PSP values andthe post hoc calibration presented in this paper aimedto shed light on the importance of reliability tests fordata-driven models used in critical and cost sensitive mul-tistage production settings. During development of theproposed method, we focused on having all the steps fromdata preprocessing up to model training as modular andgeneralizable as possible given the potential changes inthe prod"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_95", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 95, "text": " During development of theproposed method, we focused on having all the steps fromdata preprocessing up to model training as modular andgeneralizable as possible given the potential changes inthe production lines which include, but are not limitedto, updates in the recipe and optimization of productionprocedure. In addition, we did not incorporate any domainknowledge from semiconductor industry in model trainingand merely aimed to account for high stochasticity of theentire production. 8. CONCLUSION The results of this study demonstrate a significant reduc-tion in the binary-ECE by 19 .49% with the side benefit of 0.91% increase in the balanced accuracy of the calibrated SM. We also demonstrate the steps needed to developimpactful PQP models for settings with limited and un-balanced training samples such that they can be easilyreproduced in practice to other settings. In the future, wewant to focus more on the maintenance of the developedPQP models. In particular, we plan to inspect the impactof data distribution shifts on the confidence levels of thePQP models. Moreover, we aim to develop a module fortriggering a retraining process for either the base learneror the SM, or to trigg"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_96", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 96, "text": "e impactof data distribution shifts on the confidence levels of thePQP models. Moreover, we aim to develop a module fortriggering a retraining process for either the base learneror the SM, or to trigger a recalibration of the PQP models.This would finally close the MLOps loop for effective data-driven solutions. REFERENCES Arif, F., Suryana, N., and Hussin, B. (2013). A data mining approach for developing quality prediction modelin multi-stage manufacturing. International Journal of Computer Applications, 69(22). Bai, C., Dallasega, P., Orzes, G., and Sarkis, J. (2020). Industry 4.0 technologies assessment: A sustainabilityperspective. International journal of production eco- nomics , 229, 107776. Br¬® ocker, J. (2008). Some remarks on the reliability of categorical probability forecasts. Monthly weather review, 136(11), 4488‚Äì4502. Chen, T. and Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discoveryand data mining, 785‚Äì794. Cohen, I., Huang, Y., Chen, J., Benesty, J., Benesty, J., Chen, J., Huang, Y., and Cohen, I. (2009). Pearson cor-relation coefficient. Noise reduction in speech processin"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_97", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 97, "text": "veryand data mining, 785‚Äì794. Cohen, I., Huang, Y., Chen, J., Benesty, J., Benesty, J., Chen, J., Huang, Y., and Cohen, I. (2009). Pearson cor-relation coefficient. Noise reduction in speech processing, 1‚Äì4. Dimitriadis, T., Gneiting, T., and Jordan, A.I. (2020). Evaluating probabilistic classifiers: Reliability diagrams (a) Base learner (b) SM (c) Sigmoid-calibrated SM Fig. 4. Reliability diagrams of different models. The numbers in the boxes represent the number of samples in each bin. and score decompositions revisited. arXiv preprint arXiv:2008.03033. Dong, X., Yu, Z., Cao, W., Shi, Y., and Ma, Q. (2020). A survey on ensemble learning. front comput sci 14: 241‚Äì 258. Gu, J., Zhao, L., Yue, X., Arshad, N.I., and Mohamad, U.H. (2023). Multistage quality control in manufactur-ing process using blockchain with machine learning tech-nique. Information Processing & Management , 60(4), 103341. Heo, T., Kim, Y., and Kim, C.O. (2021). A modified lasso model for yield analysis considering the interac-tion effect in a multistage manufacturing line. IEEE Transactions on Semiconductor Manufacturing, 35(1),32‚Äì39. Huyen, C. (2022). Designing machine learning systems .‚Äù O‚ÄôReilly Media, Inc.‚Äù. J"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_98", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 98, "text": " interac-tion effect in a multistage manufacturing line. IEEE Transactions on Semiconductor Manufacturing, 35(1),32‚Äì39. Huyen, C. (2022). Designing machine learning systems .‚Äù O‚ÄôReilly Media, Inc.‚Äù. James, G., Witten, D., Hastie, T., Tibshirani, R., et al. (2013). An introduction to statistical learning, volume 112. Springer. Jebril, H.T., Pleschberger, M., and Susto, G.A. (2022). An autoencoder-based approach for fault detection in multi-stage manufacturing: a sputter deposition and rapidthermal processing case study. IEEE Transactions on Semiconductor Manufacturing, 35(2), 166‚Äì173. Kov¬¥ acs, G. (2019). An empirical comparison and eval- uation of minority oversampling techniques on a largenumber of imbalanced datasets. Applied Soft Comput- ing, 83, 105662. Li, Z., Chen, X., Wu, L., Ahmed, A.S., Wang, T., Zhang, Y., Li, H., Li, Z., Xu, Y., and Tong, Y. (2021). Erroranalysis of air-core coil current transformer based onstacking model fusion. Energies , 14(7), 1912. Lieber, D., Stolpe, M., Konrad, B., Deuse, J., and Morik, K. (2013). Quality prediction in interlinked manufac-turing processes based on supervised & unsupervisedmachine learning. Procedia Cirp , 7, 193‚Äì198. Md, A.Q., Jha"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_99", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 99, "text": "., Konrad, B., Deuse, J., and Morik, K. (2013). Quality prediction in interlinked manufac-turing processes based on supervised & unsupervisedmachine learning. Procedia Cirp , 7, 193‚Äì198. Md, A.Q., Jha, K., Haneef, S., Sivaraman, A.K., and Tee, K.F. (2022). A review on data-driven quality predictionin the production process with machine learning forindustry 4.0. Processes, 10(10), 1966. Melhem, M., Ananou, B., Ouladsine, M., Combal, M., and Pinaton, J. (2017). Product quality predictionusing alarm data: Application to the semiconductormanufacturing process. In 2017 25th Mediterranean Conference on Control and Automation (MED) , 1332‚Äì 1338. IEEE. Niculescu-Mizil, A. and Caruana, R. (2005). Predicting good probabilities with supervised learning. In Proceed- ings of the 22nd international conference on Machinelearning, 625‚Äì632. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,Weiss, R., Dubourg, V., Vanderplas, J., Passos, A.,Cournapeau, D., Brucher, M., Perrot, M., and Duches-nay, E. (2011). Scikit-learn: Machine learning in Python.Journal of Machine Learning Research, 12, 2825‚Äì2830. Schulze Struchtrup, A., Kvaktun, D., and"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_100", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 100, "text": "urnapeau, D., Brucher, M., Perrot, M., and Duches-nay, E. (2011). Scikit-learn: Machine learning in Python.Journal of Machine Learning Research, 12, 2825‚Äì2830. Schulze Struchtrup, A., Kvaktun, D., and Schiffers, R. (2020). A holistic approach to part quality predictionin injection molding based on machine learning. InAdvances in Polymer Processing 2020: Proceedings ofthe International Symposium on Plastics Technology,137‚Äì149. Springer. Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., Chaudhary, V., Young, M., Crespo, J.F.,and Dennison, D. (2015). Hidden technical debt in ma-chine learning systems. Advances in neural information processing systems, 28. Silva Filho, T., Song, H., Perello-Nieto, M., Santos- Rodriguez, R., Kull, M., and Flach, P. (2023). Classifiercalibration: a survey on how to assess and improvepredicted class probabilities. Machine Learning, 1‚Äì50. Tin, T.C., Tan, S.C., and Lee, C.K. (2022). Virtual metrology in semiconductor fabrication foundry usingdeep learning neural networks. IEEE Access , 10, 81960‚Äì 81973. Vaicenavicius, J., Widmann, D., Andersson, C., Lindsten, F., Roll, J., and Sch¬® on, T. (2019). Evaluating model cali-bration in clas"}
{"id": "Sustainability-in-semiconductor-production.pdf::chunk_101", "source": "Sustainability-in-semiconductor-production.pdf", "chunk_index": 101, "text": "usingdeep learning neural networks. IEEE Access , 10, 81960‚Äì 81973. Vaicenavicius, J., Widmann, D., Andersson, C., Lindsten, F., Roll, J., and Sch¬® on, T. (2019). Evaluating model cali-bration in classification. In The 22nd International Con- ference on Artificial Intelligence and Statistics , 3459‚Äì 3467. PMLR. Wang, C., Zhang, S., Song, S., and Huang, G. (2022a). Learn from the past: Experience ensemble knowledgedistillation. In 2022 26th International Conference on Pattern Recognition (ICPR) , 4736‚Äì4743. IEEE. Wang, G., Ledwoch, A., Hasani, R.M., Grosu, R., and Brintrup, A. (2019). A generative neural network modelfor the quality prediction of work in progress products.Applied Soft Computing, 85, 105683. Wang, H.Y., Tsung, C.K., Hung, C.H., and Chen, C.H. (2022b). Designing the rule classification with oversam-pling approach with high accuracy for imbalanced datain semiconductor production lines. Multimedia Tools and Applications , 81(25), 36437‚Äì36452. Yu, J., Pan, R., and Zhao, Y. (2021). High-dimensional, small-sample product quality prediction method basedon mic-stacking ensemble learning. Applied Sciences , 12(1), 23."}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_0", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 0, "text": "416 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 SWaCo: Safe Wafer Bin Map ClassiÔ¨Åcation With Self-Supervised Contrastive Learning Min Gu Kwak, Young Jae Lee , and Seoung Bum Kim Abstract ‚ÄîDefect patterns exhibited in wafer bin maps (WBMs) can provide essential clues about critical process failures to Ô¨Åeldengineers. In modern manufacturing processes, the automatic WBM defect pattern classiÔ¨Åcation is critical for yield improve- ment. Although it is difÔ¨Åcult to collect sufÔ¨Åcient labels while alot of unlabeled data is given, most existing studies have mainlyused only labeled WBM data. Moreover, the unlabeled out-of-distribution (OOD) WBMs are inevitably collected. It degradesthe performance of semi-supervised models. To this end, wepropose a method for safe wafer bin map classiÔ¨Åcation with self-supervised contrastive learning (SWaCo) to effectively exploit theunlabeled data with OOD. We propose a loss function to utilizelabel information in the pre-training step to learn more suitablerepresentations for the downstream WBM classiÔ¨Åcation task. Thenegative labeled examples of the same class as the anchor areused for additional positive examples. Moreover,"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_1", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 1, "text": "g step to learn more suitablerepresentations for the downstream WBM classiÔ¨Åcation task. Thenegative labeled examples of the same class as the anchor areused for additional positive examples. Moreover, we investigateproper data augmentation for WBM self-supervised contrastivelearning. To evaluate the performance and the applicability ofthe proposed method, experiments are conducted on a publicbenchmark WBM dataset, WM-811K. The results demonstratethat the proposed method achieves better classiÔ¨Åcation accuracythan existing methods, especially when only a small amount ofclass information is given. Index Terms ‚ÄîWafer bin map defect pattern classiÔ¨Åcation, semiconductor manufacturing, self-supervised contrastive learn-ing, semi-supervised learning, class distribution mismatch, out-of-distribution. I. I NTRODUCTION IN THE semiconductor industry, wafer fabrication is a lengthy procedure that consists of thousands of compli- cated processes to produce integrated circuits (IC) on eachwafer. Demand for high-performance semiconductor products is increasing worldwide; accordingly, many companies are making numerous efforts to improve productivity [1]. The pri- mary approach to increasing produc"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_2", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 2, "text": "nd for high-performance semiconductor products is increasing worldwide; accordingly, many companies are making numerous efforts to improve productivity [1]. The pri- mary approach to increasing productivity is to reduce the size of IC chips (dies) and put more IC chips on a single wafer. Manuscript received 29 January 2023; revised 13 April 2023; accepted 25 May 2023. Date of publication 29 May 2023; date of current version4 August 2023. This work was supported in part by Brain Korea 21 FOUR; in part by the Ministry of Science and ICT (MSIT), South Korea, through the ITRC Support Program supervised by the IITP under Grant IITP-2020-0-01749; and in part by the Agency for Defense Development under GrantUI2100062D. (Corresponding author: Seoung Bum Kim.) Min Gu Kwak is with the School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA (e-mail: mkwak35@gatech.edu). Young Jae Lee and Seoung Bum Kim are with the School of Industrial Management Engineering, Korea University, Seoul 02841, Republic of Korea (e-mail: jae601@korea.ac.kr; sbkim1@korea.ac.kr). Color versions of one or more Ô¨Ågures in this article are available at https://doi.org/10.1109"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_3", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 3, "text": "eering, Korea University, Seoul 02841, Republic of Korea (e-mail: jae601@korea.ac.kr; sbkim1@korea.ac.kr). Color versions of one or more Ô¨Ågures in this article are available at https://doi.org/10.1109/TSM.2023.3280891. Digital Object IdentiÔ¨Åer 10.1109/TSM.2023.3280891As a result, the production process becomes more sophisti- cated. However, this made the production process difÔ¨Åcult, andeven a slight error could cause severe inline defects, eventually causing circuit failures and reducing overall yield [2]. For quality management and evaluation of wafers, manu- facturing companies perform various inspections. After wafer fabrication before the packaging process, some of the wafers are randomly sampled. Then various types of electrical testsare performed to evaluate whether each IC chip meets the product speciÔ¨Åcations. An electrical die sorting (EDS) test is one of the widely used test methods, which inspects the elec-trical characteristics of each die of a wafer to check whether it is operating correctly. The EDS test results can be expressed as a wafer bin map (WBM). WBM portraits each die as zero if it passed the test and one if it failed. WBM can be regarded as a one-channel and "}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_4", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 4, "text": "perating correctly. The EDS test results can be expressed as a wafer bin map (WBM). WBM portraits each die as zero if it passed the test and one if it failed. WBM can be regarded as a one-channel and two-dimensional image con-taining information about the size of a wafer, the position of dies, and the inspection results. Defective dies sometimes form a local pattern distinct from global random noises that appearover a wafer. Identifying the spatial and local defective pat- terns is highly important in the Ô¨Åeld because they are usually caused by corresponding processes [3]. A local defect pattern indicates that some systematic errors exist. Therefore, classi- fying WBM defect patterns can provide hints on which parts of the current operating processes have problems based ondomain knowledge. It helps experienced process engineers to take appropriate maintenance in time. Conventionally, semiconductor process engineers manually look at WBM images and classify defective patterns directly. However, modern fabs with highly complex manufacturing processes produce thousands of wafers daily. Even if an engi- neer samples only a small portion of the entire wafers, the amount is too large to c"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_5", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 5, "text": "owever, modern fabs with highly complex manufacturing processes produce thousands of wafers daily. Even if an engi- neer samples only a small portion of the entire wafers, the amount is too large to check every WBM with the nakedeye. Furthermore, the defect patterns have also become more diverse, and there are cases where it is even hard to classify into a speciÔ¨Åc category. Therefore, it is time-consuming andinconsistent for engineers to determine defect patterns man- ually. Many data-driven studies based on statistical learning, machine learning, and deep learning have been proposed toaddress these issues that occur in manual approaches [4],[5], [6],[7]. In particular, many recent studies have been built upon convolutional neural networks (CNNs) to leverage and analyzethe graphical characteristics of WBM as images [8],[9],[10], [11],[12]. However, most studies assume a fully-supervised problem in which all WBMs have properly assigned classes. In the real-world industry, the demand for wafer map analysis is incredibly high to improve yield, especially in 0894-6507 c/circlecopyrt2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_6", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 6, "text": " wafer map analysis is incredibly high to improve yield, especially in 0894-6507 c/circlecopyrt2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. KWAK et al.: SWaCo: SAFE WAFER BIN MAP CLASSIFICATION 417 Fig. 1. Class distribution mismatch in the semiconductor manufacturing process when a new process is added. The class information that engineers hav e remains the same, but new defect patterns may be caused by the added process. the process of development or early production. However, collecting enough WBM classes for model training in the ini- tial production stage is difÔ¨Åcult. Several methods have been proposed to address this issue in an unsupervised manner.Even if unsupervised learning could be an alternative strategy without labels, the performance is by far unsatisfactory with- out label guidance. Semi-supervised learning (SSL) methodshave been proposed to reduce human annotation of label- ing and improve model p"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_7", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 7, "text": "without labels, the performance is by far unsatisfactory with- out label guidance. Semi-supervised learning (SSL) methodshave been proposed to reduce human annotation of label- ing and improve model performance by utilizing unlabeled data [13]. SSL methods learn the data representation from a large amount of unlabeled data and classify new observa- tions into pre-deÔ¨Åned classes by taking clues from a smallamount of labeled data. The methods have been widely used in many areas, including image classiÔ¨Åcation, person iden- tiÔ¨Åcation, natural language processing, and health care [14], [15],[16]. However, only a few studies have been reported on wafer classiÔ¨Åcation. Furthermore, here we state a mismatch problem that might be easily found in the semi-supervised WBM classiÔ¨Åcation task. There are several causes of the mismatch problem that existing studies have overlooked or assumed to be nonexistent.First, as a new fabrication process is added or an exist- ing process becomes sophisticated, a new defective pattern that did not exist before may occur. Second, some defectivepatterns may be unclear to be classiÔ¨Åed into a speciÔ¨Åc cate- gory. Third, even some defective patterns may not occur s"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_8", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 8, "text": " new defective pattern that did not exist before may occur. Second, some defectivepatterns may be unclear to be classiÔ¨Åed into a speciÔ¨Åc cate- gory. Third, even some defective patterns may not occur so well that they have not yet been observed in the early pro- duction stages when the WBM defect pattern classiÔ¨Åcation model is most necessary. These causes are likely to exist inunlabeled WBM data. Namely, the distribution of the target classes to be classiÔ¨Åed by a model and the unlabeled data distribution may differ. It is also called the class distributionmismatch problem. We could also denote the target classes as in-distribution (ID) and the classes of unlabeled data that does not present in the labeled data as out-of-distribution (OOD).Fig. 1shows the class distribution mismatch problem in WBM when a new fabrication process is added. This problem often occurs in practice, violating the basic and strict assumptionof SSL that the distributions of labeled and unlabeled data are identical. Many studies have shown that the performances of SSL methods signiÔ¨Åcantly decrease when the unlabeled OOD data exist [17],[18],[19]. It is essential to consider the class distribution mismatch for "}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_9", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 9, "text": "l. Many studies have shown that the performances of SSL methods signiÔ¨Åcantly decrease when the unlabeled OOD data exist [17],[18],[19]. It is essential to consider the class distribution mismatch for WBM classiÔ¨Åcation for prac- tical applications. However, to the best of our knowledge, no study has been conducted yet. In this paper, we propose a safe wafer bin map clas- siÔ¨Åcation with self-supervised contrastive learning (SWaCo) using proper data augmentations to solve the class distribu- tion mismatch problem. We hypothesize that self-supervised contrastive learning (SSCL) can provide proper initial networkparameters for downstream WBM classiÔ¨Åcation tasks by uti- lizing a large amount of unlabeled data with OOD. Unlike SSL methods, SWaCo does not assume identical distributions anddoes not use supervised classiÔ¨Åcation loss in the pre-training stage. It leads the model to avoid the negative effect of the mismatch class included in the unlabeled data. Furthermore,unlike existing safe SSL methods addressing the class distribu- tion mismatch problem by focusing on removing the unlabeled OOD data [17],[18],[20], the proposed method leverages the whole unlabeled data with OOD based on SS"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_10", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 10, "text": " methods addressing the class distribu- tion mismatch problem by focusing on removing the unlabeled OOD data [17],[18],[20], the proposed method leverages the whole unlabeled data with OOD based on SSCL framework. Thus, the data representations could be effectively learned without losing information in the unlabeled data. We alsopropose a contrastive loss function to learn more suitable rep- resentations for WBM defect pattern classiÔ¨Åcation by using class information in the pre-training step. The proposed loss function allows pre-training by mapping the ID samples with the same defective pattern class together while separating themfrom the OOD samples. We demonstrate the effectiveness of the proposed method with experiments on a real-world public WBM dataset, WM-811K. II. R ELATED WORKS WBM classiÔ¨Åcation is a fundamental task in the semi- conductor industry because it gives meaningful clues for root-cause analysis. Because of its importance, the literature Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 418 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 con"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_11", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 11, "text": "ed to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 418 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 contains a lot of studies for classifying WBM defect pat- terns. To date, many studies have focused on using neuralnetworks, especially based on CNNs, which are excellent for image analysis. Convolution Ô¨Ålters are useful for capturing local characteristics, which effectively detect locally existingdefective patterns. CNN was conÔ¨Årmed as an effective and powerful neural network to classify defect patterns based on a synthetic WBM dataset [11]. A framework using CNNs was proposed to detect mixed-type defect patterns that are found in real wafers [10]. WBM oversampling strategy based on data augmentation was applied to CNN to solve the class imbalanceproblem [12]. Another oversampling method using only clear defect patterns to avoid the negative effect of unclear samples was proposed [21]. CNN classiÔ¨Åer was applied to unsupervised embeddings of WBMS to classify different defect patterns on a real dataset [9]. Combining the predictions from a machine learning classiÔ¨Åer based on handcrafted fe"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_12", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 12, "text": "lassiÔ¨Åer was applied to unsupervised embeddings of WBMS to classify different defect patterns on a real dataset [9]. Combining the predictions from a machine learning classiÔ¨Åer based on handcrafted features and CNN out- puts enhanced the classiÔ¨Åcation accuracy [8]. Although the existing studies have yielded great performances in each set-ting, they are limited to supervised training when sufÔ¨Åcient clean labels are available. SSL methods perform class classiÔ¨Åcation with a small amount of label data while extracting semantic data struc- ture from a large amount of unlabeled data to improve the generalization performance. Recent deep SSL methods apply-ing neural networks have been studied in various application areas. An expectation maximization-based deep SSL method was proposed for histopathological image segmentation [22]. A CNN network based on dilated temporal convolutions effec- tively estimated 3D human poses in the video when labeled data are scarce [23]. A two-stage framework based on label propagation was applied for energy consumption prediction in steel industry [24]. An autoencoder was used in a semi- supervised manner for end-to-end neural machine translation when a limi"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_13", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 13, "text": "ed on label propagation was applied for energy consumption prediction in steel industry [24]. An autoencoder was used in a semi- supervised manner for end-to-end neural machine translation when a limited quantity of labeled parallel corpora is avail- able [25]. A CNN with an uncertainty Ô¨Ålter to select reliable unlabeled samples was used to detect fa√ßade defects [26]. Despite these various application cases, there are few SSL studies on WBM defect pattern classiÔ¨Åcation. A deep genera-tive SSL model based on CNN was proposed for multi-label classiÔ¨Åcation by adopting multiple latent class variables [27]. A hybrid method using a ladder network and semi-supervisedvariational autoencoder was proposed for WBM classiÔ¨Åca- tion [28]. An enhanced labeling method for questionable WBM samples using both unsupervised and supervised mod-els was proposed to improve classiÔ¨Åcation accuracy [29].A semi-automatic framework supported by the process engineer‚Äôs manual classiÔ¨Åcation of uncertain samples was proposed [30]. However, the existing studies do not consider the scenario when OOD data exists in the unlabeled WBM data. Recently, safe SSL methods have been proposed to address the class distributio"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_14", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 14, "text": "proposed [30]. However, the existing studies do not consider the scenario when OOD data exists in the unlabeled WBM data. Recently, safe SSL methods have been proposed to address the class distribution mismatch problem. Deep safe semi- supervised learning (DS3L) imposes different weights on theunlabeled data by a be-level meta-learning optimization. It reduces the impact of the unlabeled OOD data during model training [18]. The uncertainty-aware self-distillation (UASD) dynamically Ô¨Ålters out the unlabeled OOD data based on con- Ô¨Ådence scores calculated from labeled validation samples. TheconÔ¨Ådence scores in a moving average manner for stabilizing the Ô¨Åltering process [17]. An end-to-end multi-task curriculum model was proposed to simultaneously conduct classiÔ¨Åcation and OOD detection. It selects the unlabeled samples by their OOD scores to calculate SSL loss [20]. OpenMatch proposed to utilize one-vs-all classiÔ¨Åers to learn ID representations while rejecting OOD [31]. The existing safe SSL methods are lim- ited to natural image classiÔ¨Åcation task. Moreover, they focuson discarding or minimizing the effect of the unlabeled OOD data, which might lead to the loss of common informatio"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_15", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 15, "text": "e SSL methods are lim- ited to natural image classiÔ¨Åcation task. Moreover, they focuson discarding or minimizing the effect of the unlabeled OOD data, which might lead to the loss of common information in data. SSCL is a research Ô¨Åeld that has recently received huge attention because of its excellent performance, especially in computer vision. It exploits the unlabeled data while reducing the labeling costs. The key concept is to make the features obtained by using different data augmentation strategies on one observation similar to each other and different from the features obtained from the other observations. It is known that general data features can be extracted without classinformation through the concept. With its excellence, there are many applications using SSCL. A multi-model method for ultrasound video-speech data in medical imaging wasproposed to reduce expensive manual annotations [32].T h e transformation of a video into a set of audio-visual objects for self-supervised learning enhanced model performances inseveral speech-oriented tasks [33]. The self-supervised learn- ing model using the distinct characteristics of histopathology images that are distinguished from n"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_16", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 16, "text": "earning enhanced model performances inseveral speech-oriented tasks [33]. The self-supervised learn- ing model using the distinct characteristics of histopathology images that are distinguished from natural images showedpromising effects in many datasets [34]. A SSCL method that exploits the spatio-temporal structure of geo-located remote sensing dataset improved classiÔ¨Åcation, object detection, and semantic segmentation performances [35]. The use of SSCL methods in WBM classiÔ¨Åcation has rarely been reported.Pretext-invariant representation learning (PIRL)-based model with proper data augmentation techniques for WBM was proposed [36]. However, the previous SSCL works do not take account of the class distribution mismatch problem in the wafer manufacturing process. We demonstrate that our method based on the SSCL framework can improve the classiÔ¨Åca-tion performance under class distribution mismatch scenario by utilizing the favorable characteristic of SSCL. Our method leverages the whole unlabeled data to learn a good data repre-sentation as well as avoid the negative effect of the mismatch unlabeled samples. III. P ROPOSED METHOD We propose SWaCo when OOD WBM exists in the unla- be"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_17", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 17, "text": "e unlabeled data to learn a good data repre-sentation as well as avoid the negative effect of the mismatch unlabeled samples. III. P ROPOSED METHOD We propose SWaCo when OOD WBM exists in the unla- beled data. SWaCo is built upon MoCo [37],[38], one of the SSCL methods with prominent model performance. Thekey idea of the proposed method is the semi-supervised con- trastive loss function that uses the labeled negative examples of an anchor‚Äôs class as additional positive examples. In thissection, we give a brief review of MoCo and introduce the proposed loss function for WBM defect classiÔ¨Åcation with class distribution mismatch. In SSL settings, labeled WBM data D L={(xi,yi)}n i=1ofn samples and unlabeled WBM data DU={xj}m j=1ofmsamples Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. KWAK et al.: SWaCo: SAFE WAFER BIN MAP CLASSIFICATION 419 are given. D=DL‚à™DUis a total training WBM data. x‚àà Rh√ów,y‚àà{1,2,..., C}, and m/greatermuchnwhere h,w, and Care the height, width of a wafer, and the number of defect pattern classes, respectively. A deep SSL method trains a network by leveraging both DLa"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_18", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 18, "text": "√ów,y‚àà{1,2,..., C}, and m/greatermuchnwhere h,w, and Care the height, width of a wafer, and the number of defect pattern classes, respectively. A deep SSL method trains a network by leveraging both DLandDU. SSCL model is pre-trained with Dwithout any class information to capture the overall data representations. Then, it is Ô¨Åne-tuned with DLfor a speciÔ¨Åc downstream task. In the pre-training step, MoCo aims to learn the semantic data representations through instance discrimination without any class information. Namely, it assumes that each instancebelongs to its own class. It is based on the intuitive concept of making similar instances pull each other together and dis- similar instances push each other away. Primarily, given an image x i‚ààD, a stochastic data augmentation is applied to the same image twice to generate two different views: xa iand x+ i, which are denoted as anchor and positive example, respec- tively. Similarly, Knegative examples {x‚àí i,k}K k=1can be obtained by also applying data augmentation to a subset of images sam-pled from D i=D‚àí{xi}. Namely, negative examples denote the augmented views generated from images other than xi. Each augmented view goes through a netw"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_19", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 19, "text": "ying data augmentation to a subset of images sam-pled from D i=D‚àí{xi}. Namely, negative examples denote the augmented views generated from images other than xi. Each augmented view goes through a network fto achieve a nonlinear mapping f:Rh√ów‚ÜíRPfrom the data space to aP-dimensional representation space. The embedded repre- sentation vector z=f(x)is L2-normalized to easily calculate the similarity between representations. A positive representa- tion pair (za i,z+ i)is desired to be closely located because it is originated from the same source image xi, while any neg- ative representation pair (za i,z‚àí i,k)is desired to be located far away. To meet this purpose, the contrastive loss function for the sample xiis formulated as follows: Li,MoCo=‚àí logexp/parenleftbig za i¬∑z+ i/œÑ/parenrightbig exp/parenleftbig za i¬∑z+ i/œÑ/parenrightbig +/summationtextK k=1exp/parenleftBig za i¬∑z‚àí i,k/œÑ/parenrightBig, (1) where œÑis a temperature hyperparameter for scaling. The inner dot product between the L2-normalized z representations canbe regarded as cosine similarity. We can intuitively understand that L i,MoCo is related to the probability that the anchor is classiÔ¨Åed as the positive example with th"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_20", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 20, "text": "normalized z representations canbe regarded as cosine similarity. We can intuitively understand that L i,MoCo is related to the probability that the anchor is classiÔ¨Åed as the positive example with the same source as itselfamong one positive and Knegative examples. It makes MoCo perform instance discrimination in an unsupervised manner to learn the subtle semantic data structure. It is important to note that MoCo uses two kinds of networks that share an identical architecture: key network f œÜ(¬∑)and query network fŒ∏(¬∑), where œÜandŒ∏refer to the corresponding network weight parameters. The anchor representation za iis obtained by the query network while the positive representa- tionz+ iand negative representation z‚àí i,kare obtained by the key network. MoCo updates œÜby a momentum update strategy of Œ∏as follows: œÜ‚ÜêŒª¬∑œÜ+(1‚àíŒª)¬∑Œ∏, (2) where Œª‚àà[0,1)is the momentum coefÔ¨Åcient. Œªis typically set by a large value, such as 0.950 or 0.999, to slightly change the key representations. The momentum update does not change the key representation signiÔ¨Åcantly and consequently makesthe instance discrimination task difÔ¨Åcult enough. It allows MoCo to generate proper and general data representations [38].F"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_21", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 21, "text": "te does not change the key representation signiÔ¨Åcantly and consequently makesthe instance discrimination task difÔ¨Åcult enough. It allows MoCo to generate proper and general data representations [38].Finally, MoCo stores the past representations obtained from the key network in a memory queue. The memory queueenables MoCo to store and retrieve past representations easily during training with practicable computational costs. After pre-training, MoCo is trained on D Lthrough the Ô¨Åne- tuning step. The projection layer located at the end of the network is replaced with a single layer with a softmax activa- tion function. Namely, a softmax classiÔ¨Åer is attached to theMoCo‚Äôs backbone network. The network parameters obtained from the pre-training step are used as initial parameter values. The classiÔ¨Åcation training task is performed on the labeleddata, and the entire network is trained. It is known that MoCo learns a representation in the pre- training step that can be extensively used regardless of the type of downstream task. Therefore, MoCo could be simply used for SSL. However, it is desired to obtain more suit-able features for the semi-supervised classiÔ¨Åcation task with unlabeled OOD"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_22", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 22, "text": "ess of the type of downstream task. Therefore, MoCo could be simply used for SSL. However, it is desired to obtain more suit-able features for the semi-supervised classiÔ¨Åcation task with unlabeled OOD WBM data. In this problem, we expect the model to map the ID samples with the same defective patternclass together while separating them from the OOD samples. To address this consideration, we propose a contrastive loss function that exploits the label information in the pre-trainingstep. Under the SSL scenario, we can explicitly use the given limited class information to learn representations for down- stream classiÔ¨Åcation task. In the proposed method, the classinformation is paired with the representation vectors of nega- tive examples and stored together in the memory queue. Using this information, the labeled negative examples with the sameclass as anchor can be used as additional positive examples. From the perspective of training the SSCL model, select- ing additional positive examples should be done very carefully. Selecting a sample with semantic characteristics different from the anchor could severely degrade the training performance.This problem is more likely to occur in th"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_23", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 23, "text": "les should be done very carefully. Selecting a sample with semantic characteristics different from the anchor could severely degrade the training performance.This problem is more likely to occur in the class distribu- tion mismatch scenario. Therefore, we select samples with the same class from negative examples as additional positiveexamples when the class information of the anchor is given. With a representation z mthat has the same class as the anchor, the loss function is formulated as follows: Li,Class=‚àíI(i) |M(i;t)|log/summationdisplay m‚ààM(i;t)exp(za i¬∑zm/œÑ) exp/parenleftbig za i¬∑z+ i/œÑ/parenrightbig +/summationtextK k=1exp/parenleftBig za i¬∑z‚àí i,k/œÑ/parenrightBig, (3) where I(i)is an indicator function that is one if an xa ihas a label, otherwise zero. M(i;t)refers to the indices of nega- tive examples having the same class as the anchor of sampleiin the memory queue at iteration t. Note that the memory queue is continuously updated throughout the training itera- tions. Namely, z min the nominator of indicates the additional positive example. Fig. 2presents an overview of the proposed loss function Li,Class. The Ô¨Ånal loss function for SWaCo is formulated as follows: Li,SWaCo"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_24", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 24, "text": "z min the nominator of indicates the additional positive example. Fig. 2presents an overview of the proposed loss function Li,Class. The Ô¨Ånal loss function for SWaCo is formulated as follows: Li,SWaCo =Œ±w(t)Li,Class+Li,MoCo, (4) where Œ±is a hyperparameter for balancing two loss functions. After pre-training is complete, the proposed model is Ô¨Åne- tuned using DL, the same as vanilla MoCo. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 420 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 Fig. 2. Graphical overview of SWaCo. The anchor and positive example are generated by applying data augmentation twice to the same image, and are embedded as representation vectors by query and key network, respectively. Negative examples are also generated by applying data augmentation to Ksampled images and go through the key network. Every representation vector is L2-normalized. Based on the class information stored in a memory queue, the nega tive examples with the same class as the anchor are aggregated as additional positive examples. TABLE I CLASS DISTRIBUTION OF LABELE"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_25", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 25, "text": ". Based on the class information stored in a memory queue, the nega tive examples with the same class as the anchor are aggregated as additional positive examples. TABLE I CLASS DISTRIBUTION OF LABELED DATA IN WM-811K. ID AND OOD CLASSES OF EACH SCENARIO AREINDICATED IV . E XPERIMENTS A. Data To demonstrate the performance of the proposed method, we conducted experiments on the public WBM dataset, WM- 811K [39]. A total of 811,457 samples are obtained from real-world wafer fabrication processes. As demonstrated inTable I, only a subset of 172,950 samples has the correspond- ing class information, while the rest of 638,507 samples are unlabeled. We divided the labeled subset into ID and OOD subsets to examine the performance of the proposed method in the class distribution mismatch scenario. Note that we consid-ered the frequency of each defect pattern to deÔ¨Åne the subsets. Although it is necessary to classify all defect patterns in prac- tice, collecting labels becomes challenging for rarer defectpatterns. Therefore, we primarily included high-frequency classes in an ID subset for experimental purposes.Among the given nine classes of the labeled dataset shown in Table I, we have co"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_26", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 26, "text": "rarer defectpatterns. Therefore, we primarily included high-frequency classes in an ID subset for experimental purposes.Among the given nine classes of the labeled dataset shown in Table I, we have constructed experimental datasets using the WM-811K dataset according to three distinct scenarios for a comprehensive evaluation. It is important to note that all sce- narios include None , a normal or white noise defect pattern, in the ID dataset. From the perspective of applying the model to the real industry, it is important to develop a model that can distinguish between normal and defective wafers and classifybetween the defective wafer types. In Scenario A, we deÔ¨Åned edge-ring ,edge-loc , and none as ID or target classes, and oth- ers as OOD classes. Edge-ring andedge-loc have local defect patterns on the edge of the wafer in common. Edge-ring refers to a defective pattern with defective ICs along the edge of the wafer, and edge-loc refers to a defective pattern with defective ICs clustered around the edge of the wafer. Moreover, they could be considered as frequently caused defect patterns in terms of their proportions greater than or equal to 3%. Scenario B extends this by additi"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_27", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 27, "text": "tered around the edge of the wafer. Moreover, they could be considered as frequently caused defect patterns in terms of their proportions greater than or equal to 3%. Scenario B extends this by additionally incorporating center and loc classes with proportions greater than or equal to 2%. Lastly,in a reverse approach, Scenario C employs none ,scratch ,ran- dom,donut , and near-full classes as ID classes, which were not designated as such in Scenarios A and B. This methodologyallows for a thorough and diverse evaluation of the dataset, ensuring robust and reliable results. We randomly split the dataset into three subsets: 80% for training, 10% for validation, and 10% for testing while preserving the class distribution. To construct the dataset for SSL under class distribution mismatch, only 10% of the labelsin the training dataset were left, and the rest were discarded. Because OOD classes are not of interest, we only used the labeled ID data as D L.DUwas made with unlabeled ID and Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. KWAK et al.: SWaCo: SAFE WAFER BIN MAP CLASSIFICATION 421 OO"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_28", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 28, "text": "orized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. KWAK et al.: SWaCo: SAFE WAFER BIN MAP CLASSIFICATION 421 OOD class data. The WM-811K dataset consists of WBMs with diverse spatial resolutions and most samples are notsquare. As training CNNs with applying data augmentations such as rotation requires a Ô¨Åxed square input image size, we resized WBMs to a size of 64 √ó64 using nearest-neighbor interpolation. B. Model ConÔ¨Åguration and Training Hyperparameters We compared SWaCo with the supervised classiÔ¨Åcation, two SSL methods, and two safe SSL methods. Virtual adversarialtraining (V AT) is a well-known SSL method that enhances model robustness against local perturbations by measuring the local smoothness of conditional class distribution [40]. Stochastic weight averaging (SWA) is an SSL method that shows great classiÔ¨Åcation performance. It improves model generalization over stochastic gradient descent by averag-ing network parameters along the training procedure [41]. DS3L [18] and UASD [17] are recently proposed safe SSL methods. DS3L utilizes an extra network updated in a meta-learning manner to"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_29", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 29, "text": " by averag-ing network parameters along the training procedure [41]. DS3L [18] and UASD [17] are recently proposed safe SSL methods. DS3L utilizes an extra network updated in a meta-learning manner to control the inÔ¨Çuence of unlabeled data adaptively. UASD is a self-distillation framework to Ô¨Ålter out the OOD data during training based on conÔ¨Ådence scores. The models were trained for 100 epochs with a batch size of 512. The balancing coefÔ¨Åcients for the unlabeled loss function wereset to one. We optimized the network parameters with the stochastic gradient descent (SGD) optimizer with a learning rate of 0.03. The learning rate gradually decreases to zero byfollowing a half-period cosine schedule. For the proposed method, we followed the network struc- ture and hyperparameters recommended in MoCo-v2 unlessotherwise speciÔ¨Åed [37]. We selected a ResNet-18 as the base architecture [42] and adjusted the network to Ô¨Åt WBM data smaller than ImageNet [43]. We removed the max-pooling layer and replaced the Ô¨Årst 7 √ó7 convolution Ô¨Ålter with a 3√ó3 convolution Ô¨Ålter with a stride of one and zero padding of one. Ghost normalization was applied to mimic the batchshufÔ¨Çing normalization in multiple"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_30", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 30, "text": "replaced the Ô¨Årst 7 √ó7 convolution Ô¨Ålter with a 3√ó3 convolution Ô¨Ålter with a stride of one and zero padding of one. Ghost normalization was applied to mimic the batchshufÔ¨Çing normalization in multiple GPUs used in the orig- inal MoCo [44]. In all experiments, we split a batch into eight sub-batches to follow MoCo‚Äôs eight-GPU setting. We setŒª=0.999, and 4,096 as the size of the memory queue. Because œÑis a critical hyperparameter in SSCL and depends on the speciÔ¨Åc dataset, we determined the value of 0.1 by grid search as demonstrated in Section V-B. We pre-trained the model for 100 epochs with a batch size of 512. We usedan SGD optimizer with a learning rate of 0.001. Starting from the initial learning rate, the learning rate gradually decreases to zero by following a half-period cosine schedule. C. Model Evaluation We evaluated the quality of representations obtained from the pre-trained model by using linear classiÔ¨Åcation, a com- monly used evaluation protocol [45],[46]. Like the Ô¨Åne-tuning step, the projection layer of MoCo is replaced with a softmax classiÔ¨Åer. The parameters of the backbone network are frozen to extract the learned representations in the pre-training stepand only"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_31", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 31, "text": "uning step, the projection layer of MoCo is replaced with a softmax classiÔ¨Åer. The parameters of the backbone network are frozen to extract the learned representations in the pre-training stepand only the replaced classiÔ¨Åer is trained using D L.I tc a n be considered as training a logistic regression model with theTABLE II PERFORMANCE COMPARISONS OF MOCOTRAINED WITHDIFFERENT DATA AUGMENTATION UNDER SCENARIO A. L INEAR CLASSIFICATION ON THE VALIDATION DATASET ISCONDUCTED .BOLDFACE VALUE REPRESENTS THE BESTPERFORMANCE extracted features from the pre-trained network. We trained the linear classiÔ¨Åer for 100 epochs with an SGD optimizer with a learning rate of 30. Eventually, we conducted a supervised Ô¨Åne-tuning to eval- uate the model‚Äôs classiÔ¨Åcation performance. With the labeled data DL, we optimized the classiÔ¨Åer with an SGD optimizer with a learning rate of 0.03. The learning rate graduallydecreases to zero by following a half-period cosine sched- ule. For all experiments, we conducted ten repeated trials with different random seeds. We reported the average values ofmacro F1-score, the arithmetic mean of class-wise F1 scores, to reÔ¨Çect the class imbalance. V. E XPERIMENTAL RESULTS W"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_32", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 32, "text": "ten repeated trials with different random seeds. We reported the average values ofmacro F1-score, the arithmetic mean of class-wise F1 scores, to reÔ¨Çect the class imbalance. V. E XPERIMENTAL RESULTS We conducted experiments with Scenario A to select optimal hyperparameters and evaluate the model performances along different proportions of labeled data. Then, we also eval- uated the classiÔ¨Åcation performances with Scenarios B and Cto investigate the robustness of our model. A. Data Augmentation Selection We conducted an experiment to select the proper data aug- mentation for WBM classiÔ¨Åcation. Most SSCL models havebeen studied using natural image datasets, such as ImageNet. The model performances signiÔ¨Åcantly change depending on which data augmentation is applied. Some well-known dataaugmentations might not be suitable or even cannot be applied for WBM classiÔ¨Åcation. Color jittering and grey scaling are not applicable for single-channel WBM data. Cutout might harmthe class characteristics of WBM data [47]. For instance, if the circular defect pattern of center image is removed by cutout, it becomes an image with the same characteristics as none . Among widely used geometric data aug"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_33", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 33, "text": "cs of WBM data [47]. For instance, if the circular defect pattern of center image is removed by cutout, it becomes an image with the same characteristics as none . Among widely used geometric data augmentations, we compared the effect of rotation ,cropping ,translation , and shearing . Because translation andshearing slightly modify an image, we applied them at the same time and denoted them as perturbation . We also compared the compositions of the indi- vidual data augmentations. To examine the effect of the choice of data augmentation on the SSCL model, we conducted the linear classiÔ¨Åcation with MoCo. Table IIshows the result of linear classiÔ¨Åcation on the validation dataset. Fig. 3shows the augmented images of WBM images in ID classes. As shown in Table II,rotation showed the best performance among the augmentation methods applied individually, while cropping showed the worst performance. We interpreted that Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 422 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 Fig. 3. Data augmentations in our work. The comb"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_34", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 34, "text": "ptember 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 422 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 Fig. 3. Data augmentations in our work. The combinations of the data augmentations were also applied. TABLE III LINEAR CLASSIFICATION RESULTS OF MOCOOBTAINED OVER DIFFERENT VALUES OF œÑUNDER SCENARIO A.BOLDFACE VALUE REPRESENTS THE BESTPERFORMANCE cropping performed the worst because, depending on the crop- ping scale and position, images might sometimes lose class information. For instance, if the opposite side of the defectpattern of an edge-loc image is cropped, it loses the defect pattern. For this reason, performance degraded when rota- tion andcropping were applied together. We could Ô¨Ånd that adding perturbation enhanced the model performances. As a result, using rotation and perturbation together showed the best performance, and we used this data augmentation in all remaining experiments. B. Hyperparameter Selection In the context of SSCL, the temperature hyperparameter œÑplays a key role in enhancing the representation qual- ity. To identify the most suitable value of œÑfor the WBM classiÔ¨Åcation problem, we conducted a experime"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_35", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 35, "text": " of SSCL, the temperature hyperparameter œÑplays a key role in enhancing the representation qual- ity. To identify the most suitable value of œÑfor the WBM classiÔ¨Åcation problem, we conducted a experiment by train- ing MoCo with various œÑvalues, including 0.03, 0.05, 0.07, 1.0, 2.0, and 3.0. Subsequently, we employed linear classi- Ô¨Åcation. Table IIIdemonstrates the results on the validation dataset. The best performance of 74.55 was achieved withœÑ=0.1. Consequently, we Ô¨Åxed œÑto 0.1 for all subsequent experiments. With the Ô¨Åxed data augmentation and œÑ, we investigated the effect of hyperparameter Œ±for pre-training by linear classiÔ¨Åca- tion on the validation dataset. Selecting proper Œ±is important because the balancing hyperparameter of additional loss func- tion generally affects model performance a lot. We conducted experiments varying the values of Œ±from 0.5 to 10. Table IV shows the results. The representation qualities obtained from the proposed method were better than the performance of 74.55% of the MoCo described in Table III, regardless of theŒ±value. We achieved the best result of 88.93% when Œ±=5. The model performance gradually increased until theTABLE IV LINEAR CLASSIFICATI"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_36", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 36, "text": "e of 74.55% of the MoCo described in Table III, regardless of theŒ±value. We achieved the best result of 88.93% when Œ±=5. The model performance gradually increased until theTABLE IV LINEAR CLASSIFICATION RESULTS OF SWACOOBTAINED OVER DIFFERENT VALUES OF Œ±UNDER SCENARIO A.BOLDFACE VALUE REPRESENTS THE BESTPERFORMANCE TABLE V COMPARISONS OF THE REPRESENTATION QUALITY BETWEEN MOCO AND SWACOUNDER SCENARIO A. M ACRO F1-S CORES FROM THE LINEAR CLASSIFICATION AREREPORTED .THEBESTVALUE FOR EACH LABEL PROPORTION ISI N BOLD Œ±became Ô¨Åve, but it tended to be saturated and decreased when it was greater than Ô¨Åve. It can be interpreted that too much weight was given to grouping samples of the same class, and thus learning the overall pattern of the data was not per- formed effectively. With the results, we Ô¨Åxed Œ±to Ô¨Åve for all remaining experiments. C. Representation Quality of SWaCo With the Ô¨Åxed data augmentation, œÑ, andŒ±, we compared the representations obtained from the proposed method withthose from vanilla MoCo. Linear classiÔ¨Åcation for pre-trained MoCo and SWaCo was conducted on the validation dataset. Moreover, because our method uses the class informationin the pre-training step, it is im"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_37", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 37, "text": "rom vanilla MoCo. Linear classiÔ¨Åcation for pre-trained MoCo and SWaCo was conducted on the validation dataset. Moreover, because our method uses the class informationin the pre-training step, it is important to investigate how our method scales with the proportion of the labeled data. Following the standard SSL evaluation protocol, we varied the label proportion of training data from 20% to 1%. Note that the previous experiments were conducted with a label propor-tion of 10%. In Table V, it can be observed that the proposed model performs better than MoCo regardless of the label pro- portion of the training data. Overall, the proposed model shows15.82% higher model performance than MoCo on average. Because the model performance does not signiÔ¨Åcantly degrade along the label proportion, we can extract representations suit-able for the downstream task by the proposed method even when only a small amount of class information is given. D. ClassiÔ¨Åcation Accuracy Table VIpresents the classiÔ¨Åcation results of the compara- tive models and the proposed method on the testing dataset. MoCo and SWaCo were Ô¨Åne-tuned. Supervised refers to a model that trained with only labeled data D L. V AT and "}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_38", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 38, "text": "ation results of the compara- tive models and the proposed method on the testing dataset. MoCo and SWaCo were Ô¨Åne-tuned. Supervised refers to a model that trained with only labeled data D L. V AT and SWA are SSL methods, DSL and UASD are safe SSL meth- ods, and MoCo and SWaCo are SSCL methods. Overall,the model performance is high in the order of SSCL, safe SSL, SSL, and supervised learning, regardless of label pro- portion. UASD showed the best performance among existingmethods. Nevertheless, when MoCo was simply applied, about 1% ‚àº2% performance improvements were obtained. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. KWAK et al.: SWaCo: SAFE WAFER BIN MAP CLASSIFICATION 423 TABLE VI CLASSIFICATION PERFORMANCE OBTAINED OVER DIFFERENT LABEL PROPORTIONS UNDER SCENARIO A.BOLDFACE VALUES REPRESENT THE BESTMACRO F1-S CORE FOR EACH LABEL PROPORTION TABLE VII CLASSIFICATION PERFORMANCE OBTAINED UNDER SCENARIOS B AND C.BOLDFACE VALUES REPRESENT THE BESTMACRO F1-S CORE FOR SCENARIO MoCo can effectively learn good representations even though OOD samples are included in the unlabeled data. More"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_39", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 39, "text": " UNDER SCENARIOS B AND C.BOLDFACE VALUES REPRESENT THE BESTMACRO F1-S CORE FOR SCENARIO MoCo can effectively learn good representations even though OOD samples are included in the unlabeled data. Moreover, SWaCo further improved the classiÔ¨Åcation per- formances. Although the performance gaps between the proposed model and MoCo are not as signiÔ¨Åcant as inthe linear classiÔ¨Åcation experiments because the pre-trained networks are not frozen, the proposed model yielded sub- stantial improvements. It is important to note that SWaCoperformed better by a large gap than the existing meth- ods in challenging scenarios when only 1% or 2% of class information is available. Furthermore, in Tables VandVI,i t can also be observed that the linear classiÔ¨Åcation results of SWaCo are better than the existing safe SSL methods in a low class regime. For instance, when there is only 1% of classinformation, the linear classiÔ¨Åcation of the proposed method yielded 83.74%, while UASD yielded 83.39%. Recall that the linear classiÔ¨Åcation can be considered as training a logis-tic regression model with the extracted representations. Thus, we claim that SWaCo can be usefully applied in the wafer manufacturing pr"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_40", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 40, "text": " the linear classiÔ¨Åcation can be considered as training a logis-tic regression model with the extracted representations. Thus, we claim that SWaCo can be usefully applied in the wafer manufacturing process, where labeling cost is expensive. Lastly, Table VII displays the classiÔ¨Åcation performance results for Scenarios B and C. The results exhibit aperformance trend similar to Scenario A, with SSCL, safe SSL, SSL, and supervised learning ranking in that order. Especially, under the Scenario C, which has the smallest sam-ple size for ID subset classes among the scenarios, SWaCo achieved a substantial performance enhancement compared toother models. This illustrates that SWaCo consistently delivers high performance across various dataset conÔ¨Ågurations. VI. C ONCLUSION In this paper, we proposed a method for safe wafer bin map classiÔ¨Åcation with SSCL to address the class distribution mis-match problem that can be frequently encountered in WBM defect pattern classiÔ¨Åcation. To the best of our knowledge, it is the Ô¨Årst study to consider the SSL problem in the presence of OOD in the unlabeled WBM data and to use a SSCL approach for the problem. SWaCo, the proposed method, contributes tocon"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_41", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 41, "text": "r knowledge, it is the Ô¨Årst study to consider the SSL problem in the presence of OOD in the unlabeled WBM data and to use a SSCL approach for the problem. SWaCo, the proposed method, contributes toconsiderable gains in classiÔ¨Åcation performance. We proposed a contrastive loss function to generate suitable data represen- tations for the downstream WBM defect pattern classiÔ¨Åcationtasks. In particular, the negative labeled examples of the same class as the anchor were used for additional positive examples. Furthermore, we investigated the effect of data augmentationselection for WBM defect pattern classiÔ¨Åcation and found that using rotation, translation, and shearing simultaneously led the SSCL model to provide better representations. To verify theproposed method, we conducted experiments on the publicly accessible WBM dataset, WM-811K, with various scenarios. It was conÔ¨Årmed that the proposed method consistently achievedbetter performances than existing SSL and safe SSL methods, especially when labels are scarce. Although the proposed method achieved good results, sev- eral interesting research directions exist. First, we can consider the class imbalance problem. As observed from the"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_42", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 42, "text": "ly when labels are scarce. Although the proposed method achieved good results, sev- eral interesting research directions exist. First, we can consider the class imbalance problem. As observed from the WM-811K dataset, the frequency of defect patterns occurring in the semi- conductor industry is highly imbalanced. It is well known that the classiÔ¨Åcation performance for a minority class is relativelylow in an imbalanced classiÔ¨Åcation problem. In product quality control, the minority defective patterns should be effectively detected. It is worth developing a method to explicitly reÔ¨Çectthe class imbalance problem in the pre-training step of SSCL. Furthermore, the proposed method can be extended to a multi- label classiÔ¨Åcation model for classifying mixed-type defectpatterns. Because of dense circuits and complex wafer design, mixed-type defect patterns are easily observed in recently pro- duced wafers. Because one WBM has several types of classinformation, it is necessary to design a new strategy to select the additional positive examples for the proposed loss function in the pre-training step. R EFERENCES [1] J. Shim, S. Cho, E. Kum, and S. Jeong, ‚ÄúAdaptive fault detection frame- work "}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_43", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 43, "text": "rategy to select the additional positive examples for the proposed loss function in the pre-training step. R EFERENCES [1] J. Shim, S. Cho, E. Kum, and S. Jeong, ‚ÄúAdaptive fault detection frame- work for recipe transition in semiconductor manufacturing,‚Äù Comput. Ind. Eng. , vol. 161, Nov. 2021, Art. no. 107632. [2] T. Yuan, W. Kuo, and S. J. Bae, ‚ÄúDetection of spatial defect patterns gen- erated in semiconductor fabrication processes,‚Äù IEEE Trans. Semicond. Manuf. , vol. 24, no. 3, pp. 392‚Äì403, Aug. 2011. [3] M. H. Hansen, V . N. Nair, and D. J. Friedman, ‚ÄúMonitoring wafer map data from integrated circuit fabrication processes for spatially clustered defects,‚Äù Technometrics , vol. 39, no. 3, pp. 241‚Äì253, 1997. [4] F. Adly, P. D. Yoo, S. Muhaidat, Y . Al-Hammadi, U. Lee, and M. Ismail, ‚ÄúRandomized general regression network for identiÔ¨Åcation of defect pat- terns in semiconductor wafer maps,‚Äù IEEE Trans. Semicond. Manuf. , vol. 28, no. 2, pp. 145‚Äì152, May 2015. [5] C.-F. Chien, S.-C. Hsu, and Y .-J. Chen, ‚ÄúA system for online detection and classiÔ¨Åcation of wafer bin map defect patterns for manufacturing intelligence,‚Äù Int. J. Prod. Res. , vol. 51, no. 8, pp. 2324‚Äì2338, 2013. Authoriz"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_44", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 44, "text": ", and Y .-J. Chen, ‚ÄúA system for online detection and classiÔ¨Åcation of wafer bin map defect patterns for manufacturing intelligence,‚Äù Int. J. Prod. Res. , vol. 51, no. 8, pp. 2324‚Äì2338, 2013. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply. 424 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 36, NO. 3, AUGUST 2023 [6] C.-S. Liao, T.-J. Hsieh, Y .-S. Huang, and C.-F. Chien, ‚ÄúSimilarity search- ing for defective wafer bin maps in semiconductor manufacturing,‚Äù IEEE Trans. Autom. Sci. Eng. , vol. 11, no. 3, pp. 953‚Äì960, Jul. 2014. [7] M. Piao, C. H. Jin, J. Y . Lee, and J.-Y . Byun, ‚ÄúDecision tree ensemble-based wafer map failure pattern recognition based on radon transform-based features,‚Äù IEEE Trans. Semicond. Manuf. , vol. 31, no. 2, pp. 250‚Äì257, May 2018. [8] H. Kang and S. Kang, ‚ÄúA stacking ensemble classiÔ¨Åer with handcrafted and convolutional features for wafer map pattern classiÔ¨Åcation,‚Äù Comput. Ind., vol. 129, Aug. 2021, Art. no. 103450. [9] J. Kim, H. Kim, J. Park, K. Mo, and P. Kang, ‚ÄúBin2Vec: A better wafer bin map coloring scheme for comprehensible visualization and effecti"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_45", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 45, "text": "ion,‚Äù Comput. Ind., vol. 129, Aug. 2021, Art. no. 103450. [9] J. Kim, H. Kim, J. Park, K. Mo, and P. Kang, ‚ÄúBin2Vec: A better wafer bin map coloring scheme for comprehensible visualization and effective bad wafer classiÔ¨Åcation,‚Äù Appl. Sci. , vol. 9, no. 3, p. 597, 2019. [10] K. Kyeong and H. Kim, ‚ÄúClassiÔ¨Åcation of mixed-type defect patterns in wafer bin maps using convolutional neural networks,‚Äù IEEE Trans. Semicond. Manuf. , vol. 31, no. 3, pp. 395‚Äì402, Aug. 2018. [11] T. Nakazawa and D. V . Kulkarni, ‚ÄúWafer map defect pattern clas- siÔ¨Åcation and image retrieval using convolutional neural network,‚ÄùIEEE Trans. Semicond. Manuf. , vol. 31, no. 2, pp. 309‚Äì314, May 2018. [12] M. Saqlain, Q. Abbas, and J. Y . Lee, ‚ÄúA deep convolutional neural network for wafer defect identiÔ¨Åcation on an imbalanced dataset in semi-conductor manufacturing processes,‚Äù IEEE Trans. Semicond. Manuf. , vol. 33, no. 3, pp. 436‚Äì444, Aug. 2020. [13] O. Chapelle, B. Scholkopf, and A. Zien, ‚ÄúSemi-supervised learning (Chapelle, O. et al., Eds.; 2006) [book reviews],‚Äù IEEE Trans. Neural Netw. , vol. 20, no. 3, p. 542, Mar. 2009. [14] M.-F. Balcan et al., ‚ÄúPerson identiÔ¨Åcation in Webcam images: An appli- cation of sem"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_46", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 46, "text": "hapelle, O. et al., Eds.; 2006) [book reviews],‚Äù IEEE Trans. Neural Netw. , vol. 20, no. 3, p. 542, Mar. 2009. [14] M.-F. Balcan et al., ‚ÄúPerson identiÔ¨Åcation in Webcam images: An appli- cation of semi-supervised learning,‚Äù in Proc. Workshop Learn. Partially ClassiÔ¨Åed Training Data , vol. 2, 2005, p. 6. [15] D. Garrette, J. Mielens, and J. Baldridge, ‚ÄúReal-world semi-supervised learning of POS-taggers for low-resource languages,‚Äù in Proc. 51st Annu. Meeting Assoc. Comput. Linguist. (Long Papers) , vol. 1, 2013, pp. 583‚Äì592. [16] D. Sen, A. Aghazadeh, A. Mousavi, S. Nagarajaiah, R. Baraniuk, and A. Dabak, ‚ÄúData-driven semi-supervised and supervised learning algo-rithms for health monitoring of pipes,‚Äù Mech. Syst. Signal Process. , vol. 131, pp. 524‚Äì537, 2019. [17] Y . Chen, X. Zhu, W. Li, and S. Gong, ‚ÄúSemi-supervised learning under class distribution mismatch,‚Äù in Proc. AAAI Conf. Artif. Intell. , vol. 34, 2020, pp. 3569‚Äì3576. [18] L.-Z. Guo, Z.-Y . Zhang, Y . Jiang, Y .-F. Li, and Z.-H. Zhou, ‚ÄúSafe deep semi-supervised learning for unseen-class unlabeled data,‚Äù in Proc. Int. Conf. Mach. Learn. , 2020, pp. 3897‚Äì3906. [19] A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, and I. J. Go"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_47", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 47, "text": "H. Zhou, ‚ÄúSafe deep semi-supervised learning for unseen-class unlabeled data,‚Äù in Proc. Int. Conf. Mach. Learn. , 2020, pp. 3897‚Äì3906. [19] A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, and I. J. Goodfellow, ‚ÄúRealistic evaluation of deep semi-supervised learning algorithms,‚Äù in Proc. Adv. Neural Inf. Process. Syst. , vol. 31, 2018, pp. 1‚Äì12. [20] Q. Yu, D. Ikami, G. Irie, and K. Aizawa, ‚ÄúMulti-task curriculum framework for open-set semi-supervised learning,‚Äù in Proc. Eur. Conf. Comput. Vis. , 2020, pp. 438‚Äì454. [21] E.-S. Kim, S.-H. Choi, D.-H. Lee, K.-J. Kim, Y .-M. Bae, and Y .-C. Oh, ‚ÄúAn oversampling method for wafer map defect pattern classiÔ¨Åcationconsidering small and imbalanced data,‚Äù Comput. Ind. Eng. , vol. 162, Dec. 2021, Art. no. 107767. [22] J. Li et al., ‚ÄúAn EM-based semi-supervised deep learning approach for semantic segmentation of histopathological images from radicalprostatectomies,‚Äù Comput. Med. Imag. Graph. , vol. 69, pp. 125‚Äì133, Nov. 2018. [23] D. Pavllo, C. Feichtenhofer, D. Grangier, and M. Auli, ‚Äú3D human pose estimation in video with temporal convolutions and semi-supervisedtraining,‚Äù in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2019, pp"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_48", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 48, "text": "tenhofer, D. Grangier, and M. Auli, ‚Äú3D human pose estimation in video with temporal convolutions and semi-supervisedtraining,‚Äù in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2019, pp. 7745‚Äì7754. [24] C. Chen, Y . Liu, M. Kumar, J. Qin, and Y . Ren, ‚ÄúEnergy consump- tion modelling using deep learning embedded semi-supervised learning,‚ÄùComput. Ind. Eng. , vol. 135, pp. 757‚Äì765, Sep. 2019. [25] Y . Cheng, ‚ÄúSemi-supervised learning for neural machine translation,‚Äù inJoint Training for Neural Machine Translation . Singapore: Springer, 2019, pp. 25‚Äì40.[26] J. Guo, Q. Wang, and Y . Li, ‚ÄúSemi-supervised learning based on convolutional neural network and uncertainty Ô¨Ålter for fa√ßade defectsclassiÔ¨Åcation,‚Äù Comput.-Aided Civil Infrastruct. Eng. , vol. 36, no. 3, pp. 302‚Äì317, 2021. [27] H. Lee and H. Kim, ‚ÄúSemi-supervised multi-label learning for classiÔ¨Å- cation of wafer bin maps with mixed-type defect patterns,‚Äù IEEE Trans. Semicond. Manuf. , vol. 33, no. 4, pp. 653‚Äì662, Nov. 2020. [28] Y . Kong and D. Ni, ‚ÄúA semi-supervised and incremental modeling frame- work for wafer map classiÔ¨Åcation,‚Äù IEEE Trans. Semicond. Manuf. , vol. 33, no. 1, pp. 62‚Äì71, Feb. 2020. [29] K. S.-M. Li"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_49", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 49, "text": "20. [28] Y . Kong and D. Ni, ‚ÄúA semi-supervised and incremental modeling frame- work for wafer map classiÔ¨Åcation,‚Äù IEEE Trans. Semicond. Manuf. , vol. 33, no. 1, pp. 62‚Äì71, Feb. 2020. [29] K. S.-M. Li et al., ‚ÄúWafer defect pattern labeling and recognition using semi-supervised learning,‚Äù IEEE Trans. Semicond. Manuf. , vol. 35, no. 2, pp. 291‚Äì299, May 2022. [30] S. Yoon and S. Kang, ‚ÄúSemi-automatic wafer map pattern classiÔ¨Åca- tion with convolutional neural networks,‚Äù Comput. Ind. Eng. , vol. 166, Apr. 2022, Art. no. 107977. [31] K. Saito, D. Kim, and K. Saenko, ‚ÄúOpenmatch: Open-set semi- supervised learning with open-set consistency regularization,‚Äù in Proc. Adv. Neural Inf. Process. Syst. , vol. 34, 2021, pp. 25956‚Äì25967. [32] J. Jiao, Y . Cai, M. Alsharid, L. Drukker, A. T. Papageorghiou, and J. A. Noble, ‚ÄúSelf-supervised contrastive video-speech representationlearning for ultrasound,‚Äù in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervention , 2020, pp. 534‚Äì543. [33] T. Afouras, A. Owens, J. S. Chung, and A. Zisserman, ‚ÄúSelf-supervised learning of audio-visual objects from video,‚Äù in Proc. Eur. Conf. Comput. Vis., 2020, pp. 208‚Äì224. [34] O. Ciga, T. Xu, and A. L. Marte"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_50", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 50, "text": "ouras, A. Owens, J. S. Chung, and A. Zisserman, ‚ÄúSelf-supervised learning of audio-visual objects from video,‚Äù in Proc. Eur. Conf. Comput. Vis., 2020, pp. 208‚Äì224. [34] O. Ciga, T. Xu, and A. L. Martel, ‚ÄúSelf supervised contrastive learn- ing for digital histopathology,‚Äù Mach. Learn. Appl. , vol. 7, Mar. 2022, Art. no. 100198. [35] K. Ayush et al., ‚ÄúGeography-aware self-supervised learning,‚Äù in Proc. IEEE/CVF Int. Conf. Comput. Vis. , 2021, pp. 10181‚Äì10190. [36] H. Kahng and S. B. Kim, ‚ÄúSelf-supervised representation learning for wafer bin map defect pattern classiÔ¨Åcation,‚Äù IEEE Trans. Semicond. Manuf. , vol. 34, no. 1, pp. 74‚Äì86, Feb. 2021. [37] X. Chen, H. Fan, R. Girshick, and K. He, ‚ÄúImproved baselines with momentum contrastive learning,‚Äù 2020, arXiv:2003.04297 . [38] K. He, H. Fan, Y . Wu, S. Xie, and R. Girshick, ‚ÄúMomentum contrast for unsupervised visual representation learning,‚Äù in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2020, pp. 9726‚Äì9735. [39] M.-J. Wu, J.-S. R. Jang, and J.-L. Chen, ‚ÄúWafer map failure pattern recognition and similarity ranking for large-scale data sets,‚Äù IEEE Trans. Semicond. Manuf. , vol. 28, no. 1, pp. 1‚Äì12, Feb. 2015. [40] T. Miy"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_51", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 51, "text": "J.-S. R. Jang, and J.-L. Chen, ‚ÄúWafer map failure pattern recognition and similarity ranking for large-scale data sets,‚Äù IEEE Trans. Semicond. Manuf. , vol. 28, no. 1, pp. 1‚Äì12, Feb. 2015. [40] T. Miyato, S.-I. Maeda, M. Koyama, and S. Ishii, ‚ÄúVirtual adversarial training: A regularization method for supervised and semi-supervisedlearning,‚Äù IEEE Trans. Pattern Anal. Mach. Intell. , vol. 41, no. 8, pp. 1979‚Äì1993, Aug. 2019. [41] B. Athiwaratkun, M. Finzi, P. Izmailov, and A. G. Wilson, ‚ÄúThere are many consistent explanations of unlabeled data: Why you shouldaverage,‚Äù in Proc. Int. Conf. Learn. Represent. , 2018, pp. 1‚Äì22. [42] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep residual learning for image recognition,‚Äù in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2016, pp. 770‚Äì778. [43] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ‚ÄúImageNet: A large-scale hierarchical image database,‚Äù in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. 2009, pp. 248‚Äì255. [44] E. Hoffer, I. Hubara, and D. Soudry, ‚ÄúTrain longer, generalize bet- ter: Closing the generalization gap in large batch training of neural networks,‚Äù in Proc. Adv. Neural Inf. Process. Syst. , vol. 30, 2017, pp. 1"}
{"id": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf::chunk_52", "source": "SWaCo Safe Wafer Bin Map Classification With Self-Supervised Contrastive Learning.pdf", "chunk_index": 52, "text": ". Hubara, and D. Soudry, ‚ÄúTrain longer, generalize bet- ter: Closing the generalization gap in large batch training of neural networks,‚Äù in Proc. Adv. Neural Inf. Process. Syst. , vol. 30, 2017, pp. 1‚Äì11. [45] M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski, and A. Joulin, ‚ÄúUnsupervised learning of visual features by contrasting cluster assign- ments,‚Äù in Proc. Adv. Neural Inf. Process. Syst. , vol. 33, 2020, pp. 9912‚Äì9924. [46] Z. Wu, Y . Xiong, X. Y . Stella, and D. Lin, ‚ÄúUnsupervised feature learn- ing via non-parametric instance discrimination,‚Äù in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2018, pp. 3733‚Äì3742. [47] T. DeVries and G. W. Taylor, ‚ÄúImproved regularization of convolutional neural networks with cutout,‚Äù 2017, arXiv:1708.04552 . Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 16,2025 at 06:32:57 UTC from IEEE Xplore. Restrictions apply."}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_0", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 0, "text": "Tailoring Tests for Functional Binning of Integrated Circuits Suraj Sindia‚àóVishwani D. Agrawal‚Ä† Department of Electrical and Computer Engineering Auburn University, Alabama, AL 36849, USA ‚àóEmail: szs0063@auburn.edu‚Ä†Email: vagrawal@eng.auburn.edu Abstract ‚ÄîIn recent years, a number of high level applications have been reported to be tolerant to errors resulting from a sizable fraction of all single stuck-at faults in hardware. Produc- tion testing of devices targeted towards such applications callsfor a test vector set that is tailored to maximize the coverage of faults that lead to functionally malignant errors while minimizing the coverage of faults that produce functionally benign errors. Given a partitioning of the fault set as benign and malignant, and a complete test vector set that covers all faults, in this paper ,we formulate an integer linear programming (ILP) problem to Ô¨Ånd an optimal test vector set that ensures 100% coverage of malignant faults and minimizes coverage of benign faults. We alsopropose a test strategy based on selectively masking appropriate outputs of the circuit to partition the circuits at production test into three bins - malignant, benign, and fault-f"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_1", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 1, "text": "ign faults. We alsopropose a test strategy based on selectively masking appropriate outputs of the circuit to partition the circuits at production test into three bins - malignant, benign, and fault-free. As a casestudy, we demonstrate the proposed ILP based test optimization and functional binning on three adder circuits: 16-bit ripple carry adder , 16-bit carry lookahead adder , and 16-bit carry selectadder . We Ô¨Ånd that the proposed ILP based optimization gives a reduction of about 90% in fault coverage of benign faults while ensuring 100% coverage of malignant faults. This typicallytranslates to an (early manufacturing) yield improvement of over 20% over what would have been the yield if both malignant and benign faults are targeted without distinction by the test vectorset. I. I NTRODUCTION Scaling of MOS transistor dimensions (thanks to Moore‚Äôs law) has led to a steady increase in functions offered by microprocessor chips. Additionally, the performance (or speed)offered by these scaled devices has also been exponentially increasing. The unprecedented growth in performance of com- puters, however, has come at a price of an exponential increasein power density (power per unit a"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_2", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 2, "text": "scaled devices has also been exponentially increasing. The unprecedented growth in performance of com- puters, however, has come at a price of an exponential increasein power density (power per unit area). After a point, roughlystarting from the later half of the last decade, manufacturers have restrained from increasing the operating frequency of microprocessor chips. This stalling in frequency has promptedmicroprocessor industry to shift to an alternative computing paradigm such as parallel computing, where individual com-puters perform at a slower rate, but manage to accomplish functional tasks concurrently to be counted as an individual computer operating at a much faster rate (being roughly equal to number of parallel processors √óoperating frequency of individual processor). Another possible route to mitigate the increase in power density with successive generations of a microprocessor chip,without stalling frequency scaling, is to downscale the supplyvoltage. Such a scaling model is popularly referred to asconstant electric Ô¨Åeld scaling [5]. Regardless of the route taken to minimize power density to keep up the performance gains, the semiconductor industryis beginning to hit "}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_3", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 3, "text": " is popularly referred to asconstant electric Ô¨Åeld scaling [5]. Regardless of the route taken to minimize power density to keep up the performance gains, the semiconductor industryis beginning to hit a road-block attributed to increased manu-facturing process related variations. Reference [1] presents aninsightful discussion on the trends in frequency and voltagescaling in the face of increased process variation in advancedCMOS technology nodes. Table I (reproduced from [1]) showsscaling trends in CMOS and its impact on energy, and speed inthe advanced CMOS nodes. It predicts variability in transistorcharacteristics, both within-die and across dice, as the single most important impediment to performance gains in highly scaled CMOS nodes. V ariability in transistor characteristicswithin the chip has led to a few gates (also referred to in literature as ‚Äúoutliers‚Äù), located at spatially disjoint locations to offer delays that are signiÔ¨Åcantly higher, and in many cases,these ‚Äúoutlier‚Äù gates lie on the critical path, or paths that would nominally (without any process variation) have haddelays that are comparable to critical path delay. Presence of an ‚Äúoutlier‚Äù on critical path or close"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_4", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 4, "text": "es lie on the critical path, or paths that would nominally (without any process variation) have haddelays that are comparable to critical path delay. Presence of an ‚Äúoutlier‚Äù on critical path or close to critical path leads to an abrupt increase in the delay offered by these paths,consequently, reducing the maximum operable frequency at which functionality of the circuit is guaranteed to be correct. However, if one can trade functionality for speed, that is, under the assumption that only a few paths may havethese ‚Äúoutliers,‚Äù then we should still be able to operate the 2012 IEEE 21st Asian Test Symposium 1081-7735/12 $26.00 ¬© 2012 IEEE DOI 10.1109/ATS.2012.7895 TABLE I TECHNOLOGY SCALING PREDICTIONS FOR THE END -OF-CMOS ERA [1]. M ANUFACTURING PROCESS V ARIA TION IS PROJECTED AS THE SINGLE BIGGEST IMPEDIMENT FOR PERFORMANCE AND ENERGY IMPROVEMENT WITH DEVICE SCALING . High V olume Manufacturing 2006 2008 2010 2012 2014 2016 2018 Technology node (nm) 65 45 32 22 16 11 8 Integration 4 8 16 32 64 128 256 capacity Delay =ùê∂ùëâ ùêº‚âà0.7 >0.7 Delay scaling will slow down scaling Energy/Logic >0.5 >0.5 Energy scaling will slow down Op scaling V ariability Medium High Ve r y H i g h circuit at i"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_5", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 5, "text": "16 32 64 128 256 capacity Delay =ùê∂ùëâ ùêº‚âà0.7 >0.7 Delay scaling will slow down scaling Energy/Logic >0.5 >0.5 Energy scaling will slow down Op scaling V ariability Medium High Ve r y H i g h circuit at its maximum speed (as if there were no process variation) albeit with a few errors. The difÔ¨Åculty, however, is that most test procedures in manufacturing Ô¨Çows today target the coverage of all possible faults‚Äìincluding those that donot necessarily impact the functioning of the application thatruns on the digital system. Such a framework for test leadsto yield loss that can be avoidable, if the test vectors usedonly cover faults that cause the application to violate certainspeciÔ¨Åcations. The increased interest in research communityon this problem of test generation for only a subset of allfaults is evident from the number of papers that have appearedin the recent years [2], [3], [6], [7], [8], [9], [10], [11], [12],[13]. Research has ranged from proposing criteria that can be used to classify faults as benign (acceptable) and malignant (unacceptable) to efÔ¨Åcient test generation algorithms. Thecontribution of this work is the proposal of a technique un-derpinned by integer linear programmi"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_6", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 6, "text": " faults as benign (acceptable) and malignant (unacceptable) to efÔ¨Åcient test generation algorithms. Thecontribution of this work is the proposal of a technique un-derpinned by integer linear programming (ILP) for optimizing test coverage to target faults that only cause functional errors (or violations), while minimizing the coverage of faults that donot cause functional errors. As a case study, we demonstrate error resilient testing of 16-bit ripple carry adder. We begin by generating all possible faults and then classifying theminto two heaps: 1) benign faults - those that cause no error or an acceptable amount of error, and 2) malignant faults - those faults that cause a signiÔ¨Åcant departure from acceptablebehavior. The metric used for classifying faults into these twoheaps is a simple measure ‚Äì error magnitude, which is thedifference between actual value (with the fault present) andthe ideal value. Once the two heaps of faults are generated, we use an automatic test pattern generation (A TPG) tool togenerate tests for all malignant faults in the circuit. By fault simulation we create a spreadsheet of all benign faults thatare also covered by each of the generated test vectors. "}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_7", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 7, "text": "ion (A TPG) tool togenerate tests for all malignant faults in the circuit. By fault simulation we create a spreadsheet of all benign faults thatare also covered by each of the generated test vectors. Finally we use an ILP to only choose those test vectors that minimizecoverage of benign faults while ensuring 100% coverage ofall malignant faults. The paper is organized as follows. Section II formulates the test optimization problem for yield enhancement, constrained by 100% fault coverage of all malignant faults as an ILP . Section III describes this ILP as applied to an 16-bit ripplecarry adder. In Section IV we propose a strategy for functional binning of the circuit using selective output masking. We discuss the impact on yield by dropping tests for benign faultsin Section V. We conclude in Section VI. II. P ROBLEM FORMULA TION Let us consider a scenario where we have a total of ùëÅ faults (including both, benign and malignant faults) that are completely covered by ùëÄtest vectors. We want to Ô¨Ånd a partitioning of ùëÄtest vectors that maximizes the coverage of all malignant faults while minimizing the coverage of benignfaults. Note that in partitioning the test vector set, we do not tr"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_8", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 8, "text": "nt to Ô¨Ånd a partitioning of ùëÄtest vectors that maximizes the coverage of all malignant faults while minimizing the coverage of benignfaults. Note that in partitioning the test vector set, we do not try to minimize the overall test set as the objective here isonly to increase the fault coverage of malignant faults with zero or little coverage of the benign faults. To achieve such a partitioning of the test vector space, we use an integer linearprogramming formulation of the problem. Before proceedingto formulate the objective function, we clarify our notation. ùúÇ: Objective function of the ILP ùëì ùëñ: denotes the ùëñùë°‚Ñéfault for allùëñ=1‚ãÖ‚ãÖ‚ãÖùëÅ Œõ: set of all malignant faults Œì: set of all benign faults ùëáùëó: denotes the ùëóùë°‚Ñétest vector for all ùëó=1‚ãÖ‚ãÖ‚ãÖùëÄ ùë°ùëó: takes a value 1 if the test vector ùëáùëóis included in the test set for all ùëó=1‚ãÖ‚ãÖ‚ãÖùëÄ ùëéùëñùëó: takes the value 1 if test vector ùëáùëócan detect fault ùëìùëñ, and takes a value 0 if test vector ùëáùëócannot detect fault ùëìùëñ ùúèùëñ: an indicator function that takes the value ùõºif fault ùëìùëñis malignant, and takes the value ( ‚àíùõΩ)i ff a u l t ùëìùëñis benign ùõº, ùõΩ : Optimization parameters whose values lie in the range 96 [0,1], such that ùõº+ùõΩ=1 , and are selected based on what needs"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_9", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 9, "text": "if fault ùëìùëñis malignant, and takes the value ( ‚àíùõΩ)i ff a u l t ùëìùëñis benign ùõº, ùõΩ : Optimization parameters whose values lie in the range 96 [0,1], such that ùõº+ùõΩ=1 , and are selected based on what needs to be weighted more ‚Äì a higher ùõºallows greater effort to maximize coverage of malignant faults while a higher ùõΩ allows greater effort to minimize coverage of benign faults. Objective function, ùúÇ(to be maximized), of the ILP can now be put down as: ùúÇ=Œ£ùëÅ ùëñ=1ùëôùëñùúèùëñ, (1) with the constraints: Œ£ùëÄ ùëó=1(ùëéùëñùëóùë°ùëó)‚â•ùëôùëñ;‚àÄùëìùëñ‚ààŒõ, (2) Œ£ùëÄ ùëó=1(ùëéùëñùëóùë°ùëó)‚â§ùëôùëñ;‚àÄùëìùëñ‚ààŒì, (3) ùëôùëñ‚â•0, (4) 0‚â§ùë°ùëñ,ùë°ùëó‚â§1. (5) III. C ASE STUDY : 16- BIT RIPPLE CARRY ADDER In order to evaluate the proposed ILP formulation for test set partitioning into benign and malignant faults, we considera 16-bit ripple carry adder. Exhaustive functional simulation is carried out with all (collapsed) single stuck-at faults introducedin the circuit. We use ‚Äúerror signiÔ¨Åcance,‚Äù originally deÔ¨Åned in [2], as a metric for establishing whether a particular faultis to be considered benign or malignant. That is, if the result of an addition operation deviates from the fault free value by more than a pre-speciÔ¨Åed threshold ùúÖ, then we consider such a fault malignant, o"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_10", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 10, "text": "e considered benign or malignant. That is, if the result of an addition operation deviates from the fault free value by more than a pre-speciÔ¨Åed threshold ùúÖ, then we consider such a fault malignant, otherwise it is consideredbenign. For example, in the 16-bit adder, let us say we Ô¨Åx an error threshold value at ùúÖ=¬±5; then any fault whose addition results in an error value higher than ¬±5for any pair of input vectors is considered a malignant fault. Clearly, with such a deÔ¨Ånition for ‚Äúerror signiÔ¨Åcance,‚Äù the union ofmalignant and benign faults encompasses the entire fault set(with any redundant faults counted as benign faults). In thesubsequent sections, we describe fault simulation to Ô¨Ånd errorsigniÔ¨Åcance of each single stuck at fault to categorize theminto two groups, namely benign faults and malignant faults. We use the proposed integer linear programming formulation to optimize the test set partition for maximizing fault coverage ofmalignant faults and minimizing the fault coverage of benignfaults.‚àí20 ‚àí15 ‚àí10 ‚àí5 0 5 10 15 20 2512345678910 Deviation from fault free value Test vector index fault f1 fault f2 Fig. 1. Scatter plot of errors produced by the 16-bit adder in the presence "}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_11", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 11, "text": " benignfaults.‚àí20 ‚àí15 ‚àí10 ‚àí5 0 5 10 15 20 2512345678910 Deviation from fault free value Test vector index fault f1 fault f2 Fig. 1. Scatter plot of errors produced by the 16-bit adder in the presence of two single stuck-at faults ùëì1andùëì2for 10 test vectors. Notice that fault ùëì1(shown in red marker) results in errors in excess of the threshold ùúÖ=¬±5 on either side of 0, while the benign (acceptable) fault ùëì2(shown in blue marker) results in errors which are within the threshold ùúÖ=¬±5about 0 for all test vectors. A. Fault Simulation for Fault Partitioning Based on the deÔ¨Ånition of error signiÔ¨Åcance, we use an error threshold ùúÖ=5 as a qualiÔ¨Åcation metric to partition faults into benign and malignant. While the threshold ùúÖis chosen dependent on application, our choice here stems froman image processing perspective, where absolute errors ofaround 5 intensity levels (or less) out of a total of 256 intensity levels produce no perceptual change for the human eye [4]. In our example here we use a 16-bit adder‚Äìsum has a word lengthof 16‚Äìwhich corresponds to 65536 levels, so an absolute errorof 5 is well within the limit of perception. There are a total of 432 single stuck at faults (after faul"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_12", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 12, "text": " 16-bit adder‚Äìsum has a word lengthof 16‚Äìwhich corresponds to 65536 levels, so an absolute errorof 5 is well within the limit of perception. There are a total of 432 single stuck at faults (after fault collapsing) in the 16 bit adder. Figure 1 is a scatter plot showing the differencebetween ideal value and output value with two different stuck at faults ùëì 1andùëì2for each input test vector. Faults that result in an output value that lies within the two vertical blue lines (in Fig. 1) are benign and those that lie outside this band are malignant faults. B. T est V ector Partitioning for Optimum Coverage of Malig- nant Faults Given that we have a test set that covers all the malignant and benign faults, the ILP formulated earlier, conjures a newtest set that maximizes coverage of malignant faults whileminimizing coverage of benign faults. Figures 2, 3 and 4 showthe pre-optimized and post-optimized fault coverage based on 97 Fig. 2. Fault coverage as a function of test pattern count, before optimization (top) and after optimization (bottom), for 16-bit ripple carry adder. the objective function given in Eqn. 1 on a ripple carry adder, carry look ahead adder, and carry save adder respect"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_13", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 13, "text": " optimization (top) and after optimization (bottom), for 16-bit ripple carry adder. the objective function given in Eqn. 1 on a ripple carry adder, carry look ahead adder, and carry save adder respectively. Wesee an average reduction in the benign fault coverage by about90%, while the malignant fault coverage is still at 100% with a penalty of test pattern count increase by about 25%. IV . S ELECTIVE OUTPUT MASKING FOR FUNCTIONAL BINNING The previous section dealt with optimizing the test set for targeting malignant faults while minimizing the test coverage for benign faults. However, for applications where circuitsare to be binned, for instance into three categories, namely- malignant, benign, and fault-free, one can can propagate faults to speciÔ¨Åc outputs and selectively observe them, whileignoring the remaining outputs of the circuit. This can be explained as follows. For an adder, a circuit having a malignantfault, by deÔ¨Ånition, has at least one input vector whose output Fig. 3. Fault coverage as a function of test pattern count, before optimization (top) and after optimization (bottom), for 16-bit carry lookahead adder. deviates from the fault free value by more than some tole"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_14", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 14, "text": "ult coverage as a function of test pattern count, before optimization (top) and after optimization (bottom), for 16-bit carry lookahead adder. deviates from the fault free value by more than some tolerance threshold ( ùúÖ). So, beginning the test Ô¨Çow by testing the circuit for all malignant faults by using vectors that propagate the fault only to the more signiÔ¨Åcant bit positions (MSB)(precisely bit positions that have value ‚â•ùúÖ) will weed out any circuits that have malignant faults, and can be binned into malignant category. Note that since all tests are propagate faults only to the more signiÔ¨Åcant bits, the lower signiÔ¨Åcantbits (LSB) (i.e., bit positions that have value <ùúÖ ) can be masked or need not be observed during this portion of thetest Ô¨Çow. Circuits that pass all the malignant fault tests canthen be tested for all the benign faults. Now only the lowersigniÔ¨Åcant bits need to be observed. This is because benignfaults, by deÔ¨Ånition, have no input vector that results in anoutput whose value deviates from the fault free value by morethan tolerance threshold ( ùúÖ). Circuits that fail any of these benign fault tests are binned into benign category. Circuits 98 Fig. 4. Fault coverage "}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_15", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 15, "text": "e value deviates from the fault free value by morethan tolerance threshold ( ùúÖ). Circuits that fail any of these benign fault tests are binned into benign category. Circuits 98 Fig. 4. Fault coverage as a function of test pattern count, before optimization (top) and after optimization (bottom), for 16-bit carry save adder. that pass all the benign fault tests are binned into the fault- free category. Figure 5 illustrates the test Ô¨Çow for functionalbinning into three categories. Note that this procedure canbe extended to more binning levels by Ô¨Årst partitioning theentire fault set into desired number of benignity levels, then selectively propagating faults in each of these benignity levels to speciÔ¨Åc outputs and masking the rest. The test Ô¨Çow alwaysbegins by testing malignant faults (by propagating them tothe MSB) and then proceeds towards benign faults (that arepropagated to LSB). V. I MPACT OF TEST SETOPTIMIZA TION ON YIELD The most notable gain in optimizing test set to target only functionally malignant faults is yield improvement. We now demonstrate with a simple example, the gain in yield bytailoring test set to cover only malignant faults. Let ùëå,b et h e yield of a manufactur"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_16", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 16, "text": "unctionally malignant faults is yield improvement. We now demonstrate with a simple example, the gain in yield bytailoring test set to cover only malignant faults. Let ùëå,b et h e yield of a manufactured die in production. The die consists ofa circuit that has a total of ùëÅpossible single stuck-at-faults. Fig. 5. Test Ô¨Çow for functional binning into three categories, namely malignant, benign, and fault-free by selective masking. For simplicity, let us assume that each of these ùëÅfaults can occur independent of others and with the same probability ofoccurrence ùëù. Then we have the yield ùëå, which is simply the probability of none of these faults occurring, given by: ùëå=( 1‚àíùëù) ùëÅ. (6) Now suppose there are ùëèfaults out of ùëÅthat are functionally benign. If we have a test set that targets only the remaining(ùëÅ‚àíùëè)malignant faults, then the modiÔ¨Åed yield expression becomes: ùëå ùëöùëúùëë=( 1‚àíùëù)ùëÅ‚àíùëè. (7) To get a numerical feel for this result, let us plug in some hypothetical numbers. Though hypothetical, these numbersstill preserve Ô¨Çavor of the problem and its solution. Letthe probability of fault occurrence be ùëù=0.01when the integrated circuit (IC) manufacturing begins. Let ùëÅ= 100 be the total number of"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_17", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 17, "text": "se numbersstill preserve Ô¨Çavor of the problem and its solution. Letthe probability of fault occurrence be ùëù=0.01when the integrated circuit (IC) manufacturing begins. Let ùëÅ= 100 be the total number of single-stuck-at-faults, out of whichùëè=2 5 are functionally benign. Yield obtained without the test set being cognizant of functionally benign faults is calculated from 6 as ùëå=3.66%.If the test set is cognizant of the 25 faults as being functionally benign, then the modiÔ¨Åedyield ùëå ùëöùëúùëë=4.7%.This results in a yield improvement of 4.7‚àí3.66 3.66√ó100 = 22 .12%.Now suppose, as the manufacturing Ô¨Çow matures, the probability of fault occurrence drops toùëù=0.005. Then the traditional yield ùëå=6 0 .58% and modiÔ¨Åed yield becomes ùëå ùëöùëúùëë=6 8 .66% . Despite the smaller percentage yield improvement only 13.34%, this occurs during the maturity period of the manufacturing process, resulting ingreater absolute number of chips being classiÔ¨Åed as good. Thisimplies that if the number of targeted faults is reduced by about25%, then the nominal yield improvement can be anywhere 99 Fig. 6. New yield, obtained by not testing benign faults, is plotted as a function of the original yield. New yield numbers are calc"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_18", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 18, "text": " by about25%, then the nominal yield improvement can be anywhere 99 Fig. 6. New yield, obtained by not testing benign faults, is plotted as a function of the original yield. New yield numbers are calculated assuming uniform probability of occurrence of all faults in a circuit. between 10% and 20%. For the examples we studied earlier, namely, ripple carry adder, carry lookahead adder and carrysave adder, as plotted in Fig. 6, the improvements in yield canbe as much as 15% ‚Äì 30% depending on the individual faultprobabilities. VI. C ONCLUSION AND FUTURE WORK The paper proposed an ILP formulation for optimizing the test set to increase the fault coverage of malignant faults whileminimizing the coverage of functionally benign faults. Weused three 16-bit adders, namely, ripple carry, carry lookahead,and carry save adders as examples to demonstrate the proposedoptimization scheme. We found that in the presented examples,an average reduction in fault coverage of benign faults wasabout 90%, with malignant fault coverage still at 100%. Theaverage increase in test pattern count to achieve this is about30%. We also discussed the yield improvement obtained byusing an optimized test set that tar"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_19", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 19, "text": "h malignant fault coverage still at 100%. Theaverage increase in test pattern count to achieve this is about30%. We also discussed the yield improvement obtained byusing an optimized test set that targets only a subset of faultsthat are functionally malignant. We found that improvement inyield can be as much as 15% ‚Äì 30% depending on individual fault probabilities. The area of error resilient testing is still at its infancy and there is sufÔ¨Åcient scope for future work alongthe lines of establishing appropriate error metrics for faultclassiÔ¨Åcation for different functional blocks or applications,and test vector generation that is cognizant of benign faults.R EFERENCES [1] S. Borkar, ‚ÄúDesign Perspectives on 22nm CMOS and Beyond,‚Äù inProc. 46th ACM/IEEE Design Automation Conference ,J u l y 2009, pp. 93‚Äì94. [2] M. A. Breuer, S. K. Gupta, and T. M. Mak, ‚ÄúDefect and Error Tolerance in the Presence of Massive Numbers of Defects,‚Äù IEEE Design & T est of Computers , vol. 21, no. 3, pp. 216‚Äì227, May 2004. [3] M. A. Breuer and H. Zhu, ‚ÄúAn Illustrated Methodology for Analysis of Error Tolerance,‚Äù IEEE Design & T est of Computers , vol. 25, no. 2, pp. 168‚Äì177, Mar. 2008. [4] C. H. Chou and Y . C"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_20", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 20, "text": "May 2004. [3] M. A. Breuer and H. Zhu, ‚ÄúAn Illustrated Methodology for Analysis of Error Tolerance,‚Äù IEEE Design & T est of Computers , vol. 25, no. 2, pp. 168‚Äì177, Mar. 2008. [4] C. H. Chou and Y . C. Li, ‚ÄúA Perceptually Tuned Subband Im- age Coder Based on the Measure of Just-Noticeable-Distortion ProÔ¨Åle,‚Äù IEEE Transactions on Circuits and Systems for Video T echnology , vol. 5, no. 6, pp. 467‚Äì476, Dec. 1995. [5] B. Davari, R. H. Dennard, and G. G. Shahidi, ‚ÄúCMOS Scaling for High Performance and Low Power-the Next Ten Years,‚Äù Proceedings IEEE , vol. 83, no. 4, pp. 595‚Äì606, Apr. 1995. [6] T.-Y . Hsieh, K.-J. Lee, and M. A. Breuer, ‚ÄúAn Error-Tolerance- Based Test Methodology to Support Product Grading for Yield Enhancement,‚Äù IEEE Trans. on Computer-Aided Design of In- tegrated Circuits and Systems , vol. 30, no. 6, pp. 930‚Äì934, June 2011. [7] H. Ichihara, K. Sutoh, Y . Y oshikawa, and T. Inoue, ‚ÄúA Practical Approach to Threshold Test Generation for Error Tolerant Cir-cuits,‚Äù in IEEE Asian T est Symposium , Nov. 2009, pp. 171‚Äì176. [8] T. Inoue, N. Izumi, Y . Y oshikawa, and H. Ichihara, ‚ÄúA Fast Threshold Test Generation Algorithm Based on 5-V alued Logic,‚Äù inIEEE International Sympo"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_21", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 21, "text": "ian T est Symposium , Nov. 2009, pp. 171‚Äì176. [8] T. Inoue, N. Izumi, Y . Y oshikawa, and H. Ichihara, ‚ÄúA Fast Threshold Test Generation Algorithm Based on 5-V alued Logic,‚Äù inIEEE International Symposium on Electronic Design, T est and Application , Jan. 2010, pp. 345‚Äì349. [9] Z. Jiang and S. K. Gupta, ‚ÄúThreshold Testing: Improving Yield for Nanoscale VLSI,‚Äù IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , vol. 28, no. 12, pp. 1883‚Äì1895, Dec. 2009. [10] K. J. Lee, T. Y . Hsieh, and M. A. Breuer, ‚ÄúA Novel Test Methodology Based on Error-Rate to Support Error-Tolerance,‚Äù inProc. International T est Conference , Nov. 2005, pp. 1‚Äì9. Paper 44.1. [11] K.-J. Lee, T.-Y . Hsieh, and M. A. Breuer, ‚ÄúEfÔ¨Åcient Overdetec- tion Elimination of Acceptable Faults for Yield Improvement,‚Äù IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , vol. 31, no. 5, pp. 754‚Äì764, May 2012. [12] Z. Pan and M. A. Breuer, ‚ÄúEstimating Error Rate in Defective Logic Using Signature Analysis,‚Äù IEEE Transactions on Com- puters , vol. 56, no. 5, pp. 650‚Äì661, May 2007. [13] S. Shahidi and S. K. Gupta, ‚ÄúERTG: A Test Generator for Error- Rate Testing,‚Äù in Proc. Inte"}
{"id": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf::chunk_22", "source": "Tailoring Tests for Functional Binning of Integrated Circuits.pdf", "chunk_index": 22, "text": "ic Using Signature Analysis,‚Äù IEEE Transactions on Com- puters , vol. 56, no. 5, pp. 650‚Äì661, May 2007. [13] S. Shahidi and S. K. Gupta, ‚ÄúERTG: A Test Generator for Error- Rate Testing,‚Äù in Proc. International T est Conference , Oct. 2007, pp. 1‚Äì10. Paper 27.1. 100"}
{"id": "Test and Yield Loss.pdf::chunk_0", "source": "Test and Yield Loss.pdf", "chunk_index": 0, "text": "JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 1 Test and Yield Loss Reduction of AI and Deep Learning Accelerators Mehdi Sadi, Member, IEEE, and Ujjwal Guin, Member , IEEE Abstract ‚ÄîWith data-driven analytics becoming mainstream, the global demand for dedicated AI and Deep Learning acceler- ator chips is soaring. These accelerators, designed with densely packed Processing Elements (PE), are especially vulnerable to the manufacturing defects and functional faults common in the advanced semiconductor process nodes resulting in signiÔ¨Åcant yield loss. In this work, we demonstrate an application-driven methodology of binning the AI accelerator chips, and yield loss reduction by correlating the circuit faults in the PEs of the accelerator with the desired accuracy of the target AI workload. We exploit the inherent fault tolerance features of trained deep learning models and a strategy of selective deactivation of faulty PEs to develop the presented yield loss reduction and test methodology. An analytical relationship is derived between fault location, fault rate, and the AI task‚Äôs accuracy for deciding if the accelerator chip can pass the Ô¨Ånal yield test. A yield- loss reduc"}
{"id": "Test and Yield Loss.pdf::chunk_1", "source": "Test and Yield Loss.pdf", "chunk_index": 1, "text": "methodology. An analytical relationship is derived between fault location, fault rate, and the AI task‚Äôs accuracy for deciding if the accelerator chip can pass the Ô¨Ånal yield test. A yield- loss reduction aware fault isolation, ATPG, and test Ô¨Çow are presented for the multiply and accumulate units of the PEs. Results obtained with widely used AI/deep learning benchmarks demonstrate that the accelerators can sustain 5% fault-rate in PE arrays while suffering from less than 1% accuracy loss, thus enabling product-binning and yield loss reduction of these chips. Index Terms ‚ÄîAI accelerators, Yield, Test, Fault-tolerant AI and Deep Learning. I. I NTRODUCTION The demand for ArtiÔ¨Åcial Intelligence (AI) and deep learning is growing at a rapid pace across a wide range of applications such, as self-driving vehicles, image and voice recognition, medical imaging and diagnosis, Ô¨Ånance and banking, natural resource explorations, defense operations, etc. Because of these data-driven analytics and AI boom, demands in deep learning and AI will emerge at both data centers and the edge [ 1]-[8]. In a recent market research [ 8], it has been reported that AI-related semiconductors will see a growth o"}
{"id": "Test and Yield Loss.pdf::chunk_2", "source": "Test and Yield Loss.pdf", "chunk_index": 2, "text": " boom, demands in deep learning and AI will emerge at both data centers and the edge [ 1]-[8]. In a recent market research [ 8], it has been reported that AI-related semiconductors will see a growth of about 18 percent annually over the next few years - Ô¨Åve times greater than the rate for non-AI applications. By 2025, AI-related semiconductors could account for almost 20 percent of all semiconductor demand, which would translate into about $67 billion in revenue [8]. Although GPU was adopted by the AI community, by design GPUs were not optimized for AI workloads [ 8][9]. As a result signiÔ¨Åcant R&D efforts in developing AI accelerators - optimized to achieve much higher throughput in deep learning compared to GPUs - are underway from academia [ 2][3], big This work was supported in part by the IGP grant from Auburn University, Auburn, AL. Mehdi Sadi and Ujjwal Guin are with the Department of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849, USA (e-mail: mehdi.sadi@auburn.edu, ujjwal.guin@auburn.edu) Manuscript received August 05, 2020; revised October 11, 2020; accepted XX XX, 20XX.techs [ 4]-[6], as well as startups [ 7][10]. Dedicated accelerators are in hi"}
{"id": "Test and Yield Loss.pdf::chunk_3", "source": "Test and Yield Loss.pdf", "chunk_index": 3, "text": "i@auburn.edu, ujjwal.guin@auburn.edu) Manuscript received August 05, 2020; revised October 11, 2020; accepted XX XX, 20XX.techs [ 4]-[6], as well as startups [ 7][10]. Dedicated accelerators are in high demand for both the cloud-based training, and inference tasks on edge devices. The training procedure is time-consuming as it requires many learning samples to adapt the network parameters. For instance, a self-driving car‚Äôs neural network has to be trained with many images of possible objects it can encounter on the road, and this will require multiple high- performance AI accelerators on the cloud. During inference, AI algorithms handle less data but rapid responses are required as they are often used in critical time-sensitive applications. For example, an autonomous vehicle has to make immediate decisions on objects it sees during driving, a medical device must interpret a trauma patient‚Äôs brain scans immediately. As a result, high throughput accelerators running on edge devices and capable of fast inference are required. In AI technology innovation and leadership, high-throughput AI accelerator hardware chips will serve as the differentiator [8][10]. Millions of Multiply and Ac"}
{"id": "Test and Yield Loss.pdf::chunk_4", "source": "Test and Yield Loss.pdf", "chunk_index": 4, "text": " capable of fast inference are required. In AI technology innovation and leadership, high-throughput AI accelerator hardware chips will serve as the differentiator [8][10]. Millions of Multiply and Accumulate (MAC) operations are needed in modern AI tasks, for example, AlexNet [ 11] and ResNET-50 [ 12] require 0.7 Billion and 3.7 Billion MAC operations, respectively, to classify a single image from the Im- ageNet [ 14] dataset. Modern AI accelerators contain thousands of Processing Elements (PE) distributed in densely packed arrays in a single chip/die [ 1]-[5] or in a multi-chiplet based chip [ 10]. To accommodate as many PEs as possible in the AI accelerator, a large chip (e.g., wafer-scale) would be the best solution [ 10]. However, manufacturing large chips is difÔ¨Åcult due to the long interconnect wires and the possibility of particle defects. Aggressive scaling of design rules [ 15], lithography imperfections [ 16], local edge roughness, interconnect pitch reduction, etc., in 10nm and newer semiconductor technologies [15] have caused yield (i.e., the fraction of total manufactured chips that can be sold to the customer) to become as important as the conventional design metrics"}
{"id": "Test and Yield Loss.pdf::chunk_5", "source": "Test and Yield Loss.pdf", "chunk_index": 5, "text": " and newer semiconductor technologies [15] have caused yield (i.e., the fraction of total manufactured chips that can be sold to the customer) to become as important as the conventional design metrics of Power, Performance, Area (PPA) for the process to be economically viable [ 17][18]. More- over, internal cell defects have become a major yield limiter because of aggressive scaling of design rules and lithography limitations in printing the features, giving rise to cell-aware test [19]. In addition to the regular stuck-at and timing faults at the cell I/O level, at advanced technologies, the transistor-level and other cell-internal faults need to be added to the fault list as yield has become more vulnerable to internal cell defects [ 20]. Although yield data of semiconductor process are considered a well-guarded trade secret and not published, it is well known that yield loss has caused signiÔ¨Åcant delays in product readiness, and loss in market share and revenue for a leading processor manufacturer at 10nm and 7nm [ 21]. To integrate more PE in the accelerator, a two-level chiplet [ 22] based approach,arXiv:2006.04798v3 [cs.DC] 22 Oct 2020 JOURNAL OF L ATEX CLASS FILES, VOL. XX, "}
{"id": "Test and Yield Loss.pdf::chunk_6", "source": "Test and Yield Loss.pdf", "chunk_index": 6, "text": "or manufacturer at 10nm and 7nm [ 21]. To integrate more PE in the accelerator, a two-level chiplet [ 22] based approach,arXiv:2006.04798v3 [cs.DC] 22 Oct 2020 JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 2 where many PE are placed on a smaller chiplet, and then multiple chiplets are connected with silicon interconnect fabric [23] to form the accelerator is a viable solution. Although a relatively smaller size would minimize particle-induced random defects on upper metal layers in the chiplets and improve defect-induced yield loss, the individual PEs - internal to the chiplet - will still be susceptible to systematic defects [ 17] and lithography imperfections [ 15] that impact the transistor layers or the ultra-dense lower metal layers. As many PEs are densely placed in the AI accelerators, defects and circuit faults are likely to occur in some PEs. Fortunately, the stochasticity inherent in the backpropagation- based training of Deep Neural Networks (NN) and Deep Convolutional Neural Networks (CNN) - the primary building blocks of AI systems - offers a certain degree of resilience and error tolerance to deep learning tasks. Moreover, the intelligent application of t"}
{"id": "Test and Yield Loss.pdf::chunk_7", "source": "Test and Yield Loss.pdf", "chunk_index": 7, "text": "utional Neural Networks (CNN) - the primary building blocks of AI systems - offers a certain degree of resilience and error tolerance to deep learning tasks. Moreover, the intelligent application of techniques such as dropout, pruning, and quantization during training can further increase the robustness of a trained NN/CNN against variations and noise during inference [ 24]-[27]. The error-resilience properties of well-trained deep NN/CNNs can be exploited in hardware by allowing the PE of the dense AI accelerator to incur some circuit faults - caused by semiconductor manufacturing process variation induced defects - and still function correctly within an accuracy bound. As a result, a fault-tolerance aware test Ô¨Çow is required for these accelerators that can test the individual PEs, and certify if the fault of the PE is acceptable or unacceptable depending on how many of the rest of the PEs are fault-free or faulty, and the impact of faults on AI accuracy. An innovative solution would be to implement a Ô¨Åne-grained fault tolerance scheme that allows the deactivation of individual PEs in the event that the PE fault rate (i.e., the fraction of PEs that are faulty) exceeds a threshold"}
{"id": "Test and Yield Loss.pdf::chunk_8", "source": "Test and Yield Loss.pdf", "chunk_index": 8, "text": " be to implement a Ô¨Åne-grained fault tolerance scheme that allows the deactivation of individual PEs in the event that the PE fault rate (i.e., the fraction of PEs that are faulty) exceeds a threshold. Following this approach, an AI accelerator with some faulty PEs to still function, and will not cause the discard of the whole AI accelerator chip, resulting in a signiÔ¨Åcant reduction in yield loss [15]-[18]. In this paper, we propose YAOTA :Yield and Accuracy aware Optimum Test of AI accelerators , which considers the accuracy-sensitivity and fault-tolerance of AI applications into test pattern generation for the accelerators in deciding whether it will pass the yield test. The key contributions and highlights of this paper are as follows, \u000fAn analytical relationship is established - based on the actual AI workload to be executed - between the (i) faults of the MAC modules, (ii) the rate of faults, and the accuracy of the AI task. This relationship is used in demonstrating that AI ac- celerator chips can still function correctly despite having few faulty PEs, thus enabling product-binning and yield saving. \u000fAn accuracy-aware fault isolation and test pattern generation methodology is"}
{"id": "Test and Yield Loss.pdf::chunk_9", "source": "Test and Yield Loss.pdf", "chunk_index": 9, "text": "elerator chips can still function correctly despite having few faulty PEs, thus enabling product-binning and yield saving. \u000fAn accuracy-aware fault isolation and test pattern generation methodology is presented to group the MAC faults by their logic cones into categories: (i) critical (unacceptable), and (ii) non-critical (acceptable), according to their impact on the accuracy of AI workload. Responses from these test patterns dictate yield decisions - whether to ship to the customer at reduced throughput, or discard as yield loss. Using the reduced test pattern set for critical faults, only the critical faults of the AI accelerator can be tested as a quick method to assess the yield. Next, the chips that passed the Ô¨Årstyield-test can be tested for non-critical faults to grade those into different speed/throughput bins. The accelerators in the top bin (i.e., without any fault) can be sold at a premium price for safety-critical applications such as self-driving cars, whereas accelerators in the lower bins (with few faults, e.g., less than 5% fault rate) can be used in other AI/deep-learning tasks that can tolerate errors with minimal performance loss. \u000fA strategy of fault-aware trai"}
{"id": "Test and Yield Loss.pdf::chunk_10", "source": "Test and Yield Loss.pdf", "chunk_index": 10, "text": "s in the lower bins (with few faults, e.g., less than 5% fault rate) can be used in other AI/deep-learning tasks that can tolerate errors with minimal performance loss. \u000fA strategy of fault-aware training and selective deactivation of faulty PEs during inference is presented to minimize the accuracy loss due to faulty MACs. \u000fSimulation results from 50,000 image samples on widely used CNN (AlexNet, ResNet-50, VGG16, LeNet5) [ 44], and 10,000 data samples on different NN architectures are pre- sented to demonstrate the relationship between fault rate and accuracy. Results show that with 5% fault rate the normalized accuracy of NN and CNN only degrade by less than 1%. The rest of the paper is organized as follows. Related work and AI/Deep learning accelerator backgrounds are covered in Section II. The proposed YAOTA methodology, test Ô¨Çow, and hardware control scheme are presented in Section III. Simulation results are presented in Section IV followed by conclusions in Section V . II. B ACKGROUND A. Related Work The error-tolerance nature of AI algorithms has been exploited in hardware to design energy-efÔ¨Åcient AI accelerator architectures with approximate MACs [ 28]-[31]. In [ 28][29]"}
{"id": "Test and Yield Loss.pdf::chunk_11", "source": "Test and Yield Loss.pdf", "chunk_index": 11, "text": "KGROUND A. Related Work The error-tolerance nature of AI algorithms has been exploited in hardware to design energy-efÔ¨Åcient AI accelerator architectures with approximate MACs [ 28]-[31]. In [ 28][29], using benchmark-driven analysis each neuron was ranked according to its sensitivity and error contribution to the output, and neurons that contributed the least to the error were then approximated and the network was retrained to recover accuracy loss. In hardware, neurons that were approximated were assigned to approximate PEs, while others were assigned to exact PEs [ 28][29]. However, the challenges with these approximate approaches are, (i) sensitivity-based sorting, ap- proximation, and retraining of neurons are always dependent on the workload [ 29][31]. (ii) Assigning less sensitive neurons to approximate PEs will require runtime hardware reconÔ¨Åguration for different tasks. (iii) In [ 28]-[31] pruning was not considered, but in modern NN/CNN pruning is applied as a well-established method to reduce network size where less important/sensitive connections are already pruned/removed during training [24]-[26]. Hence, the techniques of [ 28]-[31] will be much less effective when ap"}
{"id": "Test and Yield Loss.pdf::chunk_12", "source": "Test and Yield Loss.pdf", "chunk_index": 12, "text": "d method to reduce network size where less important/sensitive connections are already pruned/removed during training [24]-[26]. Hence, the techniques of [ 28]-[31] will be much less effective when applied on an already pruned NN/CNN. (iv) Most importantly, since these approximate CNN/NN assume that the only source of error is the deterministic approximate multiplier and adders, any additional faults in the PE/MAC from process variation induced defects will cause a signiÔ¨Åcant amount of inaccuracy in the prediction during inference. With the widespread use application AI accelerators, the testing of these hardware has become an emerging research problem [ 32][33]. In [ 32], a comprehensive structural test Ô¨Çow was proposed that Ô¨Årst identiÔ¨Åed critical faults by comparing the accuracies of the exact fault-free gate-level circuit of the neural network, and that of a faulty version. Next, the entire circuit was converted into an Boolean satisÔ¨Åability (SAT) instance JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 3 and solved with SAT solver with test patterns for the critical faults only. Since this approach is expensive and not scalable, a functional test method was proposed"}
{"id": "Test and Yield Loss.pdf::chunk_13", "source": "Test and Yield Loss.pdf", "chunk_index": 13, "text": "ILES, VOL. XX, NO. X, AUGUST 202X 3 and solved with SAT solver with test patterns for the critical faults only. Since this approach is expensive and not scalable, a functional test method was proposed [ 32], where real workloads - the test images from MNIST and CIFAR10 benchmarks - are applied as test input to the gate-level netlist of the implemented neural network. To Ô¨Ånd if a fault was critical or ignorable, the fault was Ô¨Årst injected into a neuron module and the test image set was applied. If the prediction accuracy of the test image set was within a certain threshold, the fault was considered unim- portant, otherwise, it was a critical fault. However, the proposed simple approach of creating RTL of the full neural network, followed by gate-level synthesis and fault injection may not be scalable for mainstream CNNs [ 44] such as AlexNet, VGG, ResNet, MobileNet, etc. that are used for real-world computer vision tasks of image recognition with many classes [ 1][2][14]. In [33] the authors Ô¨Årst identiÔ¨Åed the location of faulty MACs (i.e., MAC i;j), in the TPU systolic array and then all weights that were mapped to those faulty MACs were pruned (i.e.,8wi;j=0,where i;j=location of "}
{"id": "Test and Yield Loss.pdf::chunk_14", "source": "Test and Yield Loss.pdf", "chunk_index": 14, "text": "uthors Ô¨Årst identiÔ¨Åed the location of faulty MACs (i.e., MAC i;j), in the TPU systolic array and then all weights that were mapped to those faulty MACs were pruned (i.e.,8wi;j=0,where i;j=location of faulty MAC), followed by retraining. Extra bypass MUX was required for each MAC to bypass it in case it was faulty. However, the major challenges of this approach are, (i) the pruning with retraining technique can preserve the model accuracy when only the small magnitude weights are pruned [ 24]-[26]. If a large magnitude weight is mapped to a faulty MAC, this method will result in accuracy degradation. (ii) Moreover, in modern AI/deep learning the models are already pruned [ 24]-[26] to reduce energy consumption and storage requirements, as a result further pruning of weights - corresponding to the faulty MACs - of an already pruned model will signiÔ¨Åcantly reduce its accuracy. (iii) Another drawback of [ 33] is that weight pruning and retraining needs to be performed for each TPU chip based on its unique fault map and each individual workload. In contrast to permanent stuck-at faults, for low-energy operations where voltage is scaled down, possible timing [34] and memory errors [ 35] "}
{"id": "Test and Yield Loss.pdf::chunk_15", "source": "Test and Yield Loss.pdf", "chunk_index": 15, "text": "ed on its unique fault map and each individual workload. In contrast to permanent stuck-at faults, for low-energy operations where voltage is scaled down, possible timing [34] and memory errors [ 35] can also occur. However, by using appropriate PV guard-band, using circuits with shorter critical-paths and memory ECC these faults can be avoided. B. AI/Deep Learning Accelerator Architecture and Processing Element Faults At the essence of AI/Deep Learning algorithms are the backpropagation-based NN and CNN. As shown in Fig. 1 (a), a deep NN consists of an input layer, followed by several hidden layers and a Ô¨Ånal output layer. Depending on the data size, the complexity of training, dropout, and pruning rate, some layers in the NN are fully connected and others sparsely connected [ 24]-[27]. The connection strengths between the adjacent layers are represented by a weight matrix W, and the matrix parameters wiare learned by the backpropagation equation, Dwi=\u0000a\u0003¬∂Error ¬∂wi, where ais learning rate and Error is the prediction error. During the forward pass of training and inference phases, the output activation of a layer, Xo, is obtained by multiplying the input activation vector with the"}
{"id": "Test and Yield Loss.pdf::chunk_16", "source": "Test and Yield Loss.pdf", "chunk_index": 16, "text": " rate and Error is the prediction error. During the forward pass of training and inference phases, the output activation of a layer, Xo, is obtained by multiplying the input activation vector with the weight matrix followed by addition of a bias term, and Ô¨Ånally passing the result through an non-linear function such as ReLU, Xo=ReLu (Xi\u0003W+b). It is evident from this equation that the dominant operation in NN is Multiply & Accumulate (MAC) in Convolution + ReLU Pooling Kernel and filters Feature maps Repeat: Convolution + ReLU + Pooling Fully connected Neural Network Class 1 (probability) 1 Class 1000 (probability) 1 Outputs Class 1 (probability) 1 Input Dot products Partial sum accumulation Kernel/Filter Input feature map (c) Multiply and accumulate (MAC) in convolution operation (b) Deep Convolutional Neural Network (CNN) (a) Deep Neural Network (NN) Input layer Hidden layer Output layer Class1 Class2 ClassN Multiply and accumulate (at each layer of NN ) Figure 1. (a) Deep NN; (b) Deep CNN; (c) Convolution in CNN [1][44]. matrix multiplications and bias term additions, of which multi- plication is the most hardware intensive. For a fully connected NN with input layer of size Ninpu"}
{"id": "Test and Yield Loss.pdf::chunk_17", "source": "Test and Yield Loss.pdf", "chunk_index": 17, "text": "p CNN; (c) Convolution in CNN [1][44]. matrix multiplications and bias term additions, of which multi- plication is the most hardware intensive. For a fully connected NN with input layer of size Ninput,Khhidden layers each of sizeNhidden , and output layer of size Nout put , the total number of required multiplications to classify a single sample is, (Ninput\u0003 Nhidden ) + (Nhidden\u0003Nhidden )\u0003(Kh\u00001) + (Nhidden\u0003Nout put ). Due to their robustness and accuracy, deep CNNs have become the standard for image and pattern recognition [ 1][44]. The operation of a deep CNN is brieÔ¨Çy shown in Fig. 1(b). During training and inference, each image or pattern is convolved successively with a set of Ô¨Ålters where each Ô¨Ålter has a set of kernels. After ReLU activation and pooling, the con- volution operation is repeated with a new set of Ô¨Ålters. Finally, before the output stage, fully connected NNs are used. The convolution operation is shown in Fig. 1(c) and it consists of dot products between the input feature-maps and Ô¨Ålter weights, mathematically, fout(m;n) =√•j√•kh(j;k)fin(m\u0000j;n\u0000k). For a single convolution layer, the total number of multiplications is given by, Ninchannel\u0003Dk\u0003Dk\u0003Df\u0003Df\u0003Noutchannel ,"}
{"id": "Test and Yield Loss.pdf::chunk_18", "source": "Test and Yield Loss.pdf", "chunk_index": 18, "text": "feature-maps and Ô¨Ålter weights, mathematically, fout(m;n) =√•j√•kh(j;k)fin(m\u0000j;n\u0000k). For a single convolution layer, the total number of multiplications is given by, Ninchannel\u0003Dk\u0003Dk\u0003Df\u0003Df\u0003Noutchannel , where Dkis kernel dimension, Dfis output feature map dimension, Ninchannel is number of input channels, and number of output channels is Noutchannel . For deep CNNs, the total number required multiplications to classify each input image/pattern is a substantial number, and MAC operations account for 90% or more of the total computational cost [1]-[4]. ùë¶‡Øá‡Øû MAC MAC MAC Weight Memory Partial Sums Activation Data Accumulator s Adder Multiplier Zero Detector Enable Partial Sum Weight activation 8 8 16 16 MAC MAC MAC MAC MAC MAC MAC Activation Memory Global Memory and Control (a) (b) PE/MAC with local control logic Figure 2. AI accelerator with PE/MAC arrays. (a) Systolic architecure; (b) SIMD architecture. Since the computations in NN/CNN are mostly dominated JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 4 by MAC operations, the AI accelerators are primarily occupied with arrays of Processing Elements (PE) optimized for fast MAC function [ 1]. Depending on if the accelerators "}
{"id": "Test and Yield Loss.pdf::chunk_19", "source": "Test and Yield Loss.pdf", "chunk_index": 19, "text": ". XX, NO. X, AUGUST 202X 4 by MAC operations, the AI accelerators are primarily occupied with arrays of Processing Elements (PE) optimized for fast MAC function [ 1]. Depending on if the accelerators are for training and inference or only for inference on edge devices, the MAC units can be of 32 bits supporting FP32 or 8 bits for int8 [39] quantized operations [ 1][38]. As shown in Fig. 2, the ac- celerator architectures can be categorized into two domains, (i) tightly-coupled 2D systolic-arrays (e.g., Google‚Äôs TPU) [ 4][9], and (ii) loosely coupled spatial arrays with independent PEs interconnected with NoC/mesh and using SIMD architecture [2][37]. While spatial SIMD designs offer higher Ô¨Çexibility by allowing independent control and deactivation of PEs as needed, systolic arrays must work in lock-step and need more sophisticated techniques to deactivate individual PEs [ 33][36]. To optimize silicon utilization, the large number of PE/MACs are densely placed on the chip die [ 1]-[4]. As a result, the yield of the accelerator will be primarily dictated by circuit faults in MAC modules of the PEs. Categorization of the location and rate of the faults as critical or non-critical with"}
{"id": "Test and Yield Loss.pdf::chunk_20", "source": "Test and Yield Loss.pdf", "chunk_index": 20, "text": "As a result, the yield of the accelerator will be primarily dictated by circuit faults in MAC modules of the PEs. Categorization of the location and rate of the faults as critical or non-critical with respect to the desired accuracy of the AI task, and corresponding fault-criticality-aware test pattern generation can save costs associated with Ô¨Ånal yield evaluation. Also, this will allow more chips to pass the functional test (within an accuracy bound of the AI task) resulting in improved yield (i.e., more accelerator passing the quality test at different specs or product bins). III. YAOTA: Y IELD AND ACCURACY AWARE OPTIMUM TEST FOR AI A CCELERATORS The semiconductor manufacturing defects and corresponding circuit faults in the AI accelerator need a deeper investigation with regards to its impact on the accuracy of AI and deep learning workloads. The key modules of accelerators that are susceptible to defects are the weight storage SRAM/Register Files (RF) and the MACs. For SRAM/RF, the faults are generally repaired with ECC and spare cells. The timing-faults in MAC can be solved by appropriate timing guard-band and run-time frequency adjustment. The stuck-at faults in the MAC are "}
{"id": "Test and Yield Loss.pdf::chunk_21", "source": "Test and Yield Loss.pdf", "chunk_index": 21, "text": "e faults are generally repaired with ECC and spare cells. The timing-faults in MAC can be solved by appropriate timing guard-band and run-time frequency adjustment. The stuck-at faults in the MAC are permanent and severe, and thus in this work, we focus on stuck-at faults. Any stuck-at faults on the bÔ¨Çoat16/Ô¨Çoat32 format [ 41] or 8-bit (for int8 quantization [39]) multipliers and adders will cause a certain precision loss and inaccuracy at the output of MAC. The important question is,‚Äúin an AI accelerator with thousands of PEs with MAC units, will the presence of a few faulty MACs cause the whole accelerator chip to be discarded, resulting in the loss of yield and revenue?‚Äù A scientiÔ¨Åcally pragmatic solution would be to assess the impact of MAC circuit faults on the training and inference accuracy of AI workloads executed on these accelerators. The key factors to consider in this assessment are, (i) location of the faults inside the PE and its impact on the precision of MAC output, (ii) the fraction of the total PEs that have faulty MACs, (iii) the type of AI workload, and (iv) if the accelerator is for both training and inference, or inference-only. A. Fault location, MAC Precisio"}
{"id": "Test and Yield Loss.pdf::chunk_22", "source": "Test and Yield Loss.pdf", "chunk_index": 22, "text": ") the fraction of the total PEs that have faulty MACs, (iii) the type of AI workload, and (iv) if the accelerator is for both training and inference, or inference-only. A. Fault location, MAC Precision and AI Accuracy Systematic defects and yield losses are caused by layout- sensitive lithographic hotspots and other process imperfections,variations, and are generally independent of the layout area [ 17]. On the other hand, random defect generated yield losses are caused by defect particles and are dependent on the standard- cell or the layout area as well as the defect particle size [ 16][18]. These defects (e.g., short/open defect, poor contact/via, etc.) and corresponding circuit faults can occur at different sites inside the MAC circuit block. The precision loss - due to the presence of circuit faults - at the output of multiply and accumulate operation will depend on the location of the fault inside MAC circuit and the logic cone impacted by the fault. For example, if a multiplier circuit that performs the multiplication of two 8-bit numbers, has faults impacting upto KLSB bits, then it will sustain worst-case error of \u0006√•K+1 i=02i(the last 2K+1 term comes from worst-case carry-"}
{"id": "Test and Yield Loss.pdf::chunk_23", "source": "Test and Yield Loss.pdf", "chunk_index": 23, "text": "circuit that performs the multiplication of two 8-bit numbers, has faults impacting upto KLSB bits, then it will sustain worst-case error of \u0006√•K+1 i=02i(the last 2K+1 term comes from worst-case carry-in path of partial product addition, as explained in the next subsection). As Kincreases, the faults impact the more signiÔ¨Åcant digits causing the worst-case error of the multiplier to increase. Similarly, errors will also occur in the adder circuit of the MAC if it is corrupted by faults. Since the multiplier is the more dominant block in a MAC, it will be more prone to faults and computation errors. As explained in Section II(B), the computations in NNs and CNNs for an AI workload execution are heavily dominated by the MAC operations. Any inaccuracy in MAC output will impact the accuracy and efÔ¨Åcacy of the AI task running on the accelerator. From the matrix multiplications in NN and convolution operations in CNN, it can be inferred that despite a certain amount of error in a few MAC modules, the AI tasks can be accomplished with minimum accuracy loss. The relationship between worst-case error per faulty MAC, percentage of MACs that are faulty and the AI workload‚Äôs accuracy loss due t"}
{"id": "Test and Yield Loss.pdf::chunk_24", "source": "Test and Yield Loss.pdf", "chunk_index": 24, "text": "les, the AI tasks can be accomplished with minimum accuracy loss. The relationship between worst-case error per faulty MAC, percentage of MACs that are faulty and the AI workload‚Äôs accuracy loss due to these errors are correlated, and will depend on the speciÔ¨Åcs of the NN/CNN architecture and the workload as will be demonstrated in Section IV . B. Yield and Accuracy Aware Fault Isolation and Test Pattern Generation P0 P1 A0 A1 B7 B0 B1 C0 C1 A2 C0 C1 C2 C3 S0 S1 S2 S3 A0 B0 A1 A2 A3 B1 B2 B3 Carry Lookahead Logic (Generate, Propagate, Carry) Full Adder Full Adder Full Adder Full Adder Logic cone of non-critical bits 16-bit Lookahead Carry Unit 4-bit CLA Adder 4-bit CLA Adder 4-bit CLA Adder 4-bit CLA Adder S15:12 S11:8 S 7:4 S3:0 C0 P0 G0 P4 P8 P12 G4 G8 G12 Logic Cone of non-critical bits (b) Cout Sout Cin A B Sin (c) Logic Cone of non- critical bits (Pnon-crit) Logic Cone of critical bits (Pcrit) (a) A B Psum Adder Multiplier P8 P15 P9 A7 LSB0 LSB1 LSBK MSB N P3(G )crit (G )non-crit Figure 3. SimpliÔ¨Åed block diagram of MAC unit with logic cones. The precision loss and the extent of computational error in a MAC will depend on the output bit positions that were corrupted by the cir"}
{"id": "Test and Yield Loss.pdf::chunk_25", "source": "Test and Yield Loss.pdf", "chunk_index": 25, "text": "Figure 3. SimpliÔ¨Åed block diagram of MAC unit with logic cones. The precision loss and the extent of computational error in a MAC will depend on the output bit positions that were corrupted by the circuit faults (e.g., stuck-at and delay). In this paper, we focus on stuck-at faults as they are more destructive compared to delay faults. By analyzing the fan-in logic cone of an output bit, we can isolate the circuit paths and standard-cell logic gates that can contribute to a stuck-at fault at that output bit. This can be explained with the multiplier and adder circuit of Fig. 3, and Algorithm 1. In Fig. 3 the green (shaded) logic cone consists of all the logic gates that are exclusively located (i.e, not overlapped with the fan-in cone of the rest of the bits) JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 5 Algorithm 1 Isolate critical and non-critical faults, and generate test patterns accordingly for Multiplier and Adder 1:procedure GENERATE TEST PATTERNS FOR CRITICAL AND NON -CRITICAL FAULTS 2:Input: Gate-level netlist of the MAC module 3:Input: Maximum LSB bit position of MAC output that can tolerate errors, K 4:Output: List of critical faults, Fcrit 5:Output: List "}
{"id": "Test and Yield Loss.pdf::chunk_26", "source": "Test and Yield Loss.pdf", "chunk_index": 26, "text": " NON -CRITICAL FAULTS 2:Input: Gate-level netlist of the MAC module 3:Input: Maximum LSB bit position of MAC output that can tolerate errors, K 4:Output: List of critical faults, Fcrit 5:Output: List of non-critical faults, Fnon\u0000crit 6:Output: ATPG test patterns for critical faults, Tcrit 7:Output: ATPG test patterns for non-critical faults, Tnon\u0000crit 8: Initialization: , G1=fg 9: Initialization: , G2=fg 10: fori= 0 to max. LSB position Kdo 11: gi all gates in the fan-in logic cone of output LSB of position i 12: G1 G1[gi 13: end for 14: fori=K+1 to MSB position Ndo 15: hi all gates in the fan-in logic cone of output bit of position i 16: G2 G2[hi 17: end for 18: Gnon\u0000crit=G1\u0000G2 19: Gcarryin bitK+1 all gates in the logic cone of carry in pin of output bit K+1 20: Gcrit=G2\u0000Gcarryin bitK+121: Fcrit list of all faults (e.g., stuck-at) for gates in Gcrit 22: Fnon\u0000crit list of all faults (e.g., stuck-at) for gates in Gnon\u0000crit 23: Tcrit ATPG tool generated test patterns for faults in list Fcrit 24: Tnon\u0000crit ATPG tool generated test patterns for faults in list Fnon\u0000crit 25: end procedure in the fan-in cone of the Ô¨Årst KLeast SigniÔ¨Åcant Bits (LSB) of the output . The red cone contains th"}
{"id": "Test and Yield Loss.pdf::chunk_27", "source": "Test and Yield Loss.pdf", "chunk_index": 27, "text": "crit 24: Tnon\u0000crit ATPG tool generated test patterns for faults in list Fnon\u0000crit 25: end procedure in the fan-in cone of the Ô¨Årst KLeast SigniÔ¨Åcant Bits (LSB) of the output . The red cone contains the standard-cells that are present in the fan-in logic cone of output bits at positions K+1to the MSB bit N, where N>K. From an extensive execution of AI benchmarks, we identify the acceptable error range of a faulty MAC and the fault rate that will not cause the AI task‚Äôs accuracy loss to exceed a threshold. We deÔ¨Åne output bit up to KLSBs to be non-critical from this workload- driven analysis. If circuit faults located within the logic cone of the Ô¨Årst Koutput bits are non-critical then the resulting worst-case error of the MAC is \u0006√•K+1 i=02i, because each bit position i- depending on whether stuck-at-1 or stuck-at-0 - will introduce error \u00062i, and an additional worst-case error of \u00062K+1may occur because of possibly wrong carry propagation to the critical output bit position K+1from non-critical bit K. The Ô¨Çow to isolate the critical and non-critical faults of a MAC for AI tasks, and corresponding ATPG pattern generation is presented in Algorithm 1. The inputs to the algorithm are the"}
{"id": "Test and Yield Loss.pdf::chunk_28", "source": "Test and Yield Loss.pdf", "chunk_index": 28, "text": "ritical bit K. The Ô¨Çow to isolate the critical and non-critical faults of a MAC for AI tasks, and corresponding ATPG pattern generation is presented in Algorithm 1. The inputs to the algorithm are the gate-level netlist of the MAC and the bit position Kup to which the error is acceptable. The outputs of Algorithm 1 in Lines 4 to 7, are the lists of critical ( Fcrit) and non-critical ( Fnon\u0000crit) faults, and the ATPG patterns ( Tcrit,Tnon\u0000crit) that can detect these faults. In Lines 10 to 13, for each bit position from 0 to K, the standard-cell logic gates in the logic cone of that bit are identiÔ¨Åed and added to the list G1. Similarly, in Lines 14 to 17 the logic gates in the fan-in cone of the rest of the bits, K+1 toN(MSB), are obtained in the list G2. In Line 18, the list G2 is subtracted from G1to obtain the list of non-critical gate list Gnon\u0000crit, thus removing any overlap with rest of the critical group. In Lines 18 to 19, the gates in the carry-in path of bit K+1are identiÔ¨Åed and subtracted from G2to obtain the list of error critical gates Gcrit. Finally, in Lines 21 to 24, the fault lists for these gates - FcritandFnon\u0000crit- are fed to the ATPG tool to obtain the test patte"}
{"id": "Test and Yield Loss.pdf::chunk_29", "source": "Test and Yield Loss.pdf", "chunk_index": 29, "text": "d subtracted from G2to obtain the list of error critical gates Gcrit. Finally, in Lines 21 to 24, the fault lists for these gates - FcritandFnon\u0000crit- are fed to the ATPG tool to obtain the test pattern sets TcritandTnon\u0000critto test the AI-accuracy critical and non-critical faults, respectively. In this logic cone analysis, we assume ripple-carry adders are not used in the MAC module as the width of theadder/multiplier required for the AI tasks are at least 8 bits, and ripple-carry structures in these cases will cause long critical paths and hence slower speeds. Our analysis assumes the use of faster carry-lookahead or tree adders (the standard type used in 8 bit or wider cases) in the MAC. Note that, in the unusual event that a slower ripple-carry structure is used, the logic cone of LSB bits will completely overlap with the rest of the bits. However, still in this scenario, our above method of non-critical gate identiÔ¨Åcation will hold if we break the ripple carry path after KLSB bits, and it will incur max error of\u0006√•K+1 i=02ias discussed above. P0 P1 A0 A1 B7 B0 B1 C0 C1 A2 C0 C1 C2 C3 S0 S1 S2 S3 A0 B0 A1 A2 A3 B1 B2 B3 Carry Lookahead Logic (Generate, Propagate, Carry) Full Add"}
{"id": "Test and Yield Loss.pdf::chunk_30", "source": "Test and Yield Loss.pdf", "chunk_index": 30, "text": ", and it will incur max error of\u0006√•K+1 i=02ias discussed above. P0 P1 A0 A1 B7 B0 B1 C0 C1 A2 C0 C1 C2 C3 S0 S1 S2 S3 A0 B0 A1 A2 A3 B1 B2 B3 Carry Lookahead Logic (Generate, Propagate, Carry) Full Adder Full Adder Full Adder Full Adder Logic cone of non-critical bits 16-bit Lookahead Carry Unit 4-bit CLA Adder 4-bit CLA Adder 4-bit CLA Adder 4-bit CLA Adder S15:12 S11:8 S 7:4 S3:0 C0 P0 G0 P4 P8 P12 G4 G8 G12 Logic Cone of non-critical bits (b) Cout Sout Cin A B Sin (c) Logic Cone of non- critical bits (Pnon-crit) Logic Cone of critical bits (Pcrit) (a) A B Psum Adder Multiplier P8 P15 P9 A7 LSB0 LSB1 LSBK MSB N P3(G )crit (G )non-crit (a) (b) Figure 4. Int8 [ 39] multiplication and addition. (a) 8-bit Baugh-Wooly signed multiplier (logic cones of two LSBs are shown); (b) Ô¨Årst 4 bits of the 16-bit CLA adder (logic cones of two LSBs are shown.) Logic cone of non-critical bits of mantissa Logic cone of critical bits Result of Addition Result of Multiplication(a) (b) Figure 5. Logic cones of critical and non-critical bits are shown for bÔ¨Çoat16/Ô¨Çoat32, (a) Ô¨Çoating point multiplication; (b) Ô¨Çoating point addition. The standard data type used in the AI domain to represent the NN connecti"}
{"id": "Test and Yield Loss.pdf::chunk_31", "source": "Test and Yield Loss.pdf", "chunk_index": 31, "text": " of critical and non-critical bits are shown for bÔ¨Çoat16/Ô¨Çoat32, (a) Ô¨Çoating point multiplication; (b) Ô¨Çoating point addition. The standard data type used in the AI domain to represent the NN connections, CNN Ô¨Ålter weights, and activation outputs are the 8-bit int8 quantized format or bÔ¨Çoat16/Ô¨Çoat32 format [ 1][4][38][41]. BÔ¨Çoat16/Ô¨Çoat32 can be used for both training and inference, but for inference-only devices (e.g., mobile and other edge devices) the training is generally done in BÔ¨Çoat16/Ô¨Çoat32 [ 40][41] and then the learned parameters are quantized to int8 and loaded in these devices [ 3][38]. The Baugh-Wooly multiplier [ 45] - widely used for multiplying two 8-bit signed numbers - is shown in Fig. 4 (a). If acceptable faults can only affect the two LSBs (i.e., K=1in Algorithm 1), all circuits in logic-cones of outputs P0andP1- highlighted with red dots in Fig. 4 (a) - are considered non-critical, and the JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 6 rest of the circuits are fault-critical. Similarly, in Fig. 4 (b) for the 16-bit Carry Look-ahead Adder (CLA) of the MAC, the logic cones containing the non-critical circuits and faults are shown for K=1. For wide-bi"}
{"id": "Test and Yield Loss.pdf::chunk_32", "source": "Test and Yield Loss.pdf", "chunk_index": 32, "text": "uits are fault-critical. Similarly, in Fig. 4 (b) for the 16-bit Carry Look-ahead Adder (CLA) of the MAC, the logic cones containing the non-critical circuits and faults are shown for K=1. For wide-bit addition (i.e. 16-bit), CLA or tree adder are used instead of the slower ripple carry structure [45]. For AI accelerators using bÔ¨Çoat16/Ô¨Çoat32 format multiplier and adder [ 40][41], as shown in Fig. 5, circuit faults in logic cones of some of the lower order (i.e., LSBs) bits of mantissa can be considered as non-critical, and the circuit faults present in the logic cones of the rest of the bits of mantissa, the exponent and sign bits are considered critical as they can introduce large errors in the result. The number of bits in mantissa that can be considered non-critical will depend on the amount of error introduced by stuck-at faults on those bits and the impact of this error in AI task‚Äôs accuracy loss. Next, we propose the test Ô¨Çow to identify faulty PEs, and the use of a low area-overhead register memory to store the IDs of the faulty PEs. A control scheme is presented to deactivate some of the faulty PEs during inference and test, if required. TVLSI_20 showed performance of AM d"}
{"id": "Test and Yield Loss.pdf::chunk_33", "source": "Test and Yield Loss.pdf", "chunk_index": 33, "text": "rhead register memory to store the IDs of the faulty PEs. A control scheme is presented to deactivate some of the faulty PEs during inference and test, if required. TVLSI_20 showed performance of AM data dependent. Fault Status Register (FSR) Control signals to deactivate and bypass PE/MAC Memory, and Control Unit Array of PEs (Systolic or SIMD architecture) Figure 6. Proposed Failure Status Register (FSR) and controls to deactivate and bypass faulty PEs in the accelerator as needed. C. Post-fab Test of the AI Accelerator After manufacturing, the accelerator chip/die is subjected to structural and functional tests to identify if the PEs in the densely packed arrays are functionally correct. Because of defects from imperfections in the semiconductor manufacturing process, some of the PEs will have faulty MAC units. First, the test patterns Tcritobtained using Algorithm 1, are applied in a broadcast mode to all the PE/MACs to identify which units will introduce large errors during matrix multiplications or dot products in convolutions. The IDs of these faulty PEs are recorded in the list Fail IDcrit. Next, the test patterns Tnon\u0000crit are applied parallelly to all the PEs that passed "}
{"id": "Test and Yield Loss.pdf::chunk_34", "source": "Test and Yield Loss.pdf", "chunk_index": 34, "text": " multiplications or dot products in convolutions. The IDs of these faulty PEs are recorded in the list Fail IDcrit. Next, the test patterns Tnon\u0000crit are applied parallelly to all the PEs that passed the Ô¨Årst test. The IDs of the PEs that failed this second test are recorded in the listFail IDnon\u0000crit. Since the PEs that belong to Fail IDcrit have large MAC errors, they can be permanently disabled by the manufacturer (similar to the practice of disabling faulty cores in many-core processors [ 43]), or their Fail IDcritdata can be written to an on-chip non-volatile memory - Fault Status Register (FSR) shown in Fig. 6 - for the customer to decide if they want to use those PEs or not. The PEs belonging to Fail IDnon\u0000crithave relatively small MAC errors and can be acceptable depending on, (i) how many such errors exist (i.e., number of elements in Fail IDnon\u0000crit), (ii) the type of AI workload that will be executed by the customer and their accuracy tolerance limits. Hence, the Fail IDnon\u0000critcontents are written into the on-chip FSR for the customer to disable a fraction of these faulty PEs with software at runtime and still accomplish the AI tasks with minimal accuracy loss. The deac"}
{"id": "Test and Yield Loss.pdf::chunk_35", "source": "Test and Yield Loss.pdf", "chunk_index": 35, "text": "critcontents are written into the on-chip FSR for the customer to disable a fraction of these faulty PEs with software at runtime and still accomplish the AI tasks with minimal accuracy loss. The deactivation protocol and the complete map of faulty PE locations are programmed in Ô¨Årmware/software by the manufacturer. With the user-given input of acceptable fault rate (in non-critical LSBs, analyzed in Section IV) and the stored PE fault map, the protocol will automatically disable a few faulty PEs to ensure that the overall faulty PE rate of the accelerator does not exceed a threshold. When deactivating some faulty PEs, the Ô¨Årmware/software will ensure that the remaining faulty PEs are not clustered. We deÔ¨Åne the deactivation protocol such that after deactivation, the remaining faulty PEs (with non- critical faults) are uniformly distributed across the columns. As shown in Fig. 6, control signals are transmitted from the FSR to all the PEs to selectively disable the faulty PEs when needed. By adopting this scheme, the manufacturer can avoid discarding the full accelerator chip/die only because of the presence of few PEs with faulty MACs, and thereby increase yield. The overhead in t"}
{"id": "Test and Yield Loss.pdf::chunk_36", "source": "Test and Yield Loss.pdf", "chunk_index": 36, "text": "ed. By adopting this scheme, the manufacturer can avoid discarding the full accelerator chip/die only because of the presence of few PEs with faulty MACs, and thereby increase yield. The overhead in this yield loss reduction are the extra on-chip register (FSR) to store the IDs and the control signal routes to disable faulty PEs. AI/Deep Learning models trained on the cloud with GPU/CPU Target Workload CPU Deactivate all Faulty PEs Train_Enable Data Bus [1] Trained weights and connections [2] Acceptable fault rate for PEs in the accelerator for inference (FRmax_non.crit) Training Phase CPU Inference Phase [1] Trained weights and connections [2] Acceptable fault rate for PEs in the accelerator for inference ( FRmax_non.crit) CPU Inference on Edge Device with AI Accelerator Training off-line in the cloud with high-performance computing Figure 7. Accelerator used for Inference on edge/mobile devices with cloud-trained parameters. 1) Accelerator used for Inference Only: For large datasets, the training of deep NN/CNN is computationally intensive and very time consuming, and generally requires many accelerators or CPU/GPUs working in parallel. For example, training the popular CNN model"}
{"id": "Test and Yield Loss.pdf::chunk_37", "source": "Test and Yield Loss.pdf", "chunk_index": 37, "text": " the training of deep NN/CNN is computationally intensive and very time consuming, and generally requires many accelerators or CPU/GPUs working in parallel. For example, training the popular CNN model of AlexNet on imageNet [ 14] dataset required 6 days with 2 GPUs [ 11]. Since mobile and other edge devices cannot sustain this computational overhead, the general trend for these devices is to use a pre-trained model during inference. In this mode, using many CPU/GPUs and dedicated accelerators the AI model is trained on the cloud, and after training the model parameters and weights are loaded in the edge device where a local AI accelerator is used to perform the MAC operations required for inference [ 1][38]. Our proposed ‚Äòfault-aware cloud-trained edge-inferred‚Äô inference Ô¨Çow is shown in Fig. 7. In this approach, after the model has been completely trained in the cloud with high-performance computing, an additional analysis is performed to obtain the impact of MAC errors on inference accuracy. This can be achieved by injecting on the post-trained model in the cloud the same MAC errors that would occur in the inference accelerator of the edge device, and obtaining the corresponding "}
{"id": "Test and Yield Loss.pdf::chunk_38", "source": "Test and Yield Loss.pdf", "chunk_index": 38, "text": "ccuracy. This can be achieved by injecting on the post-trained model in the cloud the same MAC errors that would occur in the inference accelerator of the edge device, and obtaining the corresponding accuracy changes as a look-up table of fault rate vs. accuracy changes. In JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 7 summary, the proposed Ô¨Çow will not only generate the trained parameters of the AI model - similar to the regular cloud- training and edge-inference paradigm [ 1] - but also report the maximum allowed fault rate FRmax non\u0000critto be subsequently loaded into the accelerator hardware of the edge device as a bitstream. During inference, the mobile/edge accelerator‚Äôs FSR and control unit reads the FRmax non\u0000critand if it is lower than the current fault rate FRnon\u0000crit, then the control unit sends deactivation signals to disable some of the PEs such that the fault rate is reduced to FRmax non\u0000critas shown in Fig. 7. AI/Deep Learning models trained on the cloud with GPU/CPU Target Workload CPU Deactivate all Faulty PEs Train_Enable Data Bus [1] Trained weights and connections [2] Acceptable fault rate for PEs in the accelerator for inference (FRmax_non.crit) T"}
{"id": "Test and Yield Loss.pdf::chunk_39", "source": "Test and Yield Loss.pdf", "chunk_index": 39, "text": "th GPU/CPU Target Workload CPU Deactivate all Faulty PEs Train_Enable Data Bus [1] Trained weights and connections [2] Acceptable fault rate for PEs in the accelerator for inference (FRmax_non.crit) Training Phase CPU Inference Phase [1] Trained weights and connections [2] Acceptable fault rate for PEs in the accelerator for inference ( FRmax_non.crit) CPU Inference on Edge Device with AI Accelerator Training off-line in the cloud with high-performance computing Figure 8. Accelerator used in both Training and Inference. Algorithm 2 Fault-aware training and inference on AI accelerator 1:procedure IDENTIFY THE MAXIMUM ACCEPTABLE FAULT RATE OF PROCESSING ELEMENTS (PE) IN THE ACCELERATOR FOR A GIVEN ACCURACY TARGET 2:Input: Minimum acceptable accuracy for inference, Acc In fthreshold 3:Input: Training dataset for the deep CNN/NN 4:Input: Fault rate (i.e., rate of non-critical faulty PEs ) of the accelarator, FRnon\u0000crit 5:Input: IDs of all faulty PEs in the accelerator, FID=fFail IDnon\u0000crit;Fail IDcritg 6:Input: Fault rate adjustment step size, dstep 7:Output: Maximum allowed fault rate in the AI accelerator for inference at desired accuracy, FRmax non\u0000crit 8: Initialization: Training a"}
{"id": "Test and Yield Loss.pdf::chunk_40", "source": "Test and Yield Loss.pdf", "chunk_index": 40, "text": ";Fail IDcritg 6:Input: Fault rate adjustment step size, dstep 7:Output: Maximum allowed fault rate in the AI accelerator for inference at desired accuracy, FRmax non\u0000crit 8: Initialization: Training accuracy, Acc Train =0 9: Initialization: Deactivate all faulty PEs in FIDduring training mode 10: Initialization: FRmax non\u0000crit=FRnon\u0000crit 11: while (Acc Train <Acc In fthreshold )do 12: Acc Train training accuracy for the given dataset with FRmax non\u0000crit modeled in the backpropagation 13: if(Acc Train <Acc In fthreshold )then 14: FRmax non\u0000crit=FRmax non\u0000crit\u0000dstep 15: end if 16: end while 17: end procedure 2) Accelerator used in Training and Inference: For cases where the accelerator will be used for both training and infer- ence, further improvement in accuracy degradation caused by MAC errors can be accomplished with fault-aware training. Re- training is a popular tool in deep learning, and primarily used to reduce the size of the NN/CNN by pruning [ 24]-[26]. In retrain- ing, the forward pass and backward passes are made aware of the changes in the network, and this directs Stochastic Gradient Descent based backpropagation Ô¨Çow to evolve the weights of the NN/CNN accordingly to m"}
{"id": "Test and Yield Loss.pdf::chunk_41", "source": "Test and Yield Loss.pdf", "chunk_index": 41, "text": "rward pass and backward passes are made aware of the changes in the network, and this directs Stochastic Gradient Descent based backpropagation Ô¨Çow to evolve the weights of the NN/CNN accordingly to minimize any accuracy loss stem- ming from these changes [ 25][28][29]. The proposed methodol- ogy is shown in Fig. 8 and explained in Algorithm 2. The pres- ence of possible errors in MAC calculations during inference is modeled mathematically and fed to the backpropagation weight- update Ô¨Çows similar to [ 28]-[31]. During the training phase, Ô¨Årst, the control unit reads the FSR to obtain the IDs of faulty PEs. To ensure that the CNN/NN will be trained to achieve thebest accuracy, all faulty PEs (both critical and non-critical) are disabled during the training phase as shown in Fig. 8 and Line 9 in Algorithm 2. In Algorithm 2 the fault-aware AI training and inference Ô¨Çow is shown for the accelerator. The minimum acceptable inference accuracy ( Acc In fthreshold ), the train- ing data set, accelerator‚Äôs non-critical fault rate ( FRnon\u0000crit), IDs of all faulty PEs and a fault adjustment step size ( dstep) are provided as inputs to the algorithm in Lines 2 to 6. The algo- rithm reports th"}
{"id": "Test and Yield Loss.pdf::chunk_42", "source": "Test and Yield Loss.pdf", "chunk_index": 42, "text": "accelerator‚Äôs non-critical fault rate ( FRnon\u0000crit), IDs of all faulty PEs and a fault adjustment step size ( dstep) are provided as inputs to the algorithm in Lines 2 to 6. The algo- rithm reports the maximum allowed faulty (non-criticalin LSBs) PE rate (i.e., the fraction of the total PEs in the accelerator that have non-critical faults), FRmax non\u0000critthat will allow the achievement of desired inference accuracy Acc In fthreshold . In Lines 11 to 16, after each iteration of fault-aware training - with fault effect modeled in the backpropagation - the obtained accuracy is compared with the desired inference accuracy Acc In fthreshold . If the accuracy goal is not met, the fault rateFRmax non\u0000critis reduced by a small step dstep, until the desired accuracy goal is met. After the training converges and the inference accuracy target is reached, the trained weights of the NN/CNN are obtained. Additionally, the maximum allowed faulty PE rate, FRmax non\u0000crit, is reported. During inference, the control unit and FSR will read this FRmax non\u0000critand disable some faulty PE to achieve this FRmax non\u0000critrate. The beneÔ¨Åts from this combined training-inference methodology are, (i) in achievin"}
{"id": "Test and Yield Loss.pdf::chunk_43", "source": "Test and Yield Loss.pdf", "chunk_index": 43, "text": " the control unit and FSR will read this FRmax non\u0000critand disable some faulty PE to achieve this FRmax non\u0000critrate. The beneÔ¨Åts from this combined training-inference methodology are, (i) in achieving the same inference accuracy, the fault-aware training approach will allow the accelerator to endure a higher FRmax non\u0000critcompared to the scenario where no fault-aware training is used. This will allow the availability of more PEs during inference if fault-aware training was used. (ii) Although there will be additional time required for this training step, this extra cost will be amortized on the multiple inference runs. Because, the general trend in AI is to train the NN/CNN once accurately, and then this pre-trained model is used many times during inference. As a result, the extra PEs - made available by the fault-aware training - present during each inference will signiÔ¨Åcantly speed up the inference tasks. (a) (b) Figure 9. Software-level bypass method for faulty PE in Systolic array. (a) Normal mode without fault. (b) Faulty PE bypassed by shifting input data. JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 8 D. Deactivation and Bypass of Faulty PE The FSR holds the I"}
{"id": "Test and Yield Loss.pdf::chunk_44", "source": "Test and Yield Loss.pdf", "chunk_index": 44, "text": ". (a) Normal mode without fault. (b) Faulty PE bypassed by shifting input data. JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 8 D. Deactivation and Bypass of Faulty PE The FSR holds the IDs of faulty PEs. On demand deactivation and bypass of these PEs require different strategies for SIMD and Systolic architectures. 1) SIMD Architectures: In SIMD architecture the loosely coupled independent PEs are connected with NoC or mesh and can be individually switched off and bypassed with wires [1][37]. Using the results from the FSR, all PEs with critical faults and few PEs with non-critical faults are deactivated. If after deactivation, ‚Äò Nremaining PE‚Äô PEs remain out of ‚ÄòNtotal PE‚Äô, then throughput of the accelerator will be scaled by the factor (Nremaining PE=Ntotal PE). 2) Systolic Architectures: The tightly-coupled 2D systolic- arrays in TPU introduce challenges in deactivating and bypassing individual PEs. A common technique is to use spare PE blocks to substitute for faulty PEs [ 36]. However, this approach requires complex wiring between spare and faulty PEs. In this work, we propose an innovative software-level technique to deactivate and bypass faulty PEs in systolic "}
{"id": "Test and Yield Loss.pdf::chunk_45", "source": "Test and Yield Loss.pdf", "chunk_index": 45, "text": "PEs [ 36]. However, this approach requires complex wiring between spare and faulty PEs. In this work, we propose an innovative software-level technique to deactivate and bypass faulty PEs in systolic array without any hardware-level modiÔ¨Åcations. Unlike [ 33], as discussed in details in Section II(A), this approach does not require the NN/CNN weights that are mapped on the faulty PEs to be pruned (i.e., set to zero). The fault-free scenario is shown in Fig. 9(a), where the weights are pre-loaded in the PEs of the systolic array in regular manner. In Fig. 9(b), the PE in row 2, column 4 of the systolic array has a critical fault or non-critical fault exceeding acceptable fault-rate (marked with a red cross) and needs to be bypassed. In software, this is accomplished by shifting the column of the weight matrix to the right by inserting a dummy row of zeros. The activation matrix, X, is also shifted accordingly as shown in Fig. 9(b). Moreover, this software-level approach does not require complex wiring resources as needed in hardware-level spare replacement techniques [ 36]. However, the execution throughput will decrease as some faulty PEs are deactivated. For the largest weight mat"}
{"id": "Test and Yield Loss.pdf::chunk_46", "source": "Test and Yield Loss.pdf", "chunk_index": 46, "text": " complex wiring resources as needed in hardware-level spare replacement techniques [ 36]. However, the execution throughput will decrease as some faulty PEs are deactivated. For the largest weight matrix in CNN/NN multiple iteration steps ( Nsteps ) are required in the accelerator array to complete the MAC operations. For example, in AlexNet largest weight matrix is of size 4096 by 9216, and this will require multiple iterations to complete in a systolic array with 256 by 256 PEs (e.g., Google TPU [ 4]). If the row/column size of systolic array is ‚Äò Ndim sysarr‚Äô and the number of columns in accelerator PE array that has atleast one PE requiring fault-induced deactivation is ‚Äò Nsysarr f aulty cols‚Äô, then software-level deactivation will require extra (Ndim sysarr\u0003Nsysarr f aulty cols)\u0003Nsteps MAC operations. IV. R ESULTS AND ANALYSIS To identify the impact of the number of LSBs having faults in their logic cones, we varied the number of LSBs from 2 to 4 for int8 [ 39] and 3 to 5 for bÔ¨Çoat16 [ 40][41] data formats for the CNN model AlexNet with the ImageNet test set. These experiments were done with PyTorch [ 49]. The results are shown in Fig. 10, where X-axis is fault-rate in non-cri"}
{"id": "Test and Yield Loss.pdf::chunk_47", "source": "Test and Yield Loss.pdf", "chunk_index": 47, "text": "t16 [ 40][41] data formats for the CNN model AlexNet with the ImageNet test set. These experiments were done with PyTorch [ 49]. The results are shown in Fig. 10, where X-axis is fault-rate in non-critical logic cones (the LSBs). From this analysis, we conservatively selected 2 LSBs for int8 and 4 mantissa LSBs for the recent bÔ¨Çoat16 hardware models. In our experiments the acceleratorhardware comprised of 128 by 128 array of PE/MACs as shown in Fig. 11. The faulty PEs are modeled as uniformly distributed across the rows and columns with fault probability ofFR%, the fault rate. This implies that for FR%fault rate, each column of the accelerator has 0:01\u0003FR\u0003NRowfaulty PEs randomly distributed across that column. The reported results here are the average of 10 independent fault injection experiments done in MATLAB [ 48] (for NN) and PyTorch [ 49] (for CNN) according to this hardware and fault distribution model. The prediction accuracy data reported in subsequent experiments are independent of the SIMD/Systolic architecture of the accelerator. However, the throughput will vary based on architecture type and fault rate as discussed in Section III-D. In identifying the critical and non-"}
{"id": "Test and Yield Loss.pdf::chunk_48", "source": "Test and Yield Loss.pdf", "chunk_index": 48, "text": "nt of the SIMD/Systolic architecture of the accelerator. However, the throughput will vary based on architecture type and fault rate as discussed in Section III-D. In identifying the critical and non-critical circuit faults in the MAC of a PE and corresponding test pattern generation, we used the RTL of the MAC unit present in each PE and analyzed both int8 and recent bÔ¨Çoat16 format implementations. Top-1 Accuracy (for bfloat16 case) Top-1 Accuracy (for int8 case) Top-5 Accuracy (for int8 case) Top-5 Accuracy (for bfloat16 case) (a) (b) (d) (c) NLSB = 2 NLSB = 3 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 4 NLSB = 3 NLSB = 5 NLSB = 4 NLSB = 3 NLSB = 5 Figure 10. Impact of faults in logic cones of LSB positions on inference accuracy for AlexNet with ImageNet data set. (a), (b) int8 data format and MAC type.; (c), (d) bÔ¨Çoat16 data format and MAC type. TVLSI_20 showed performance of AM data dependent. MAC MAC MAC MAC MAC MAC MAC MAC MAC MAC MAC MAC Memory and Control 128 MAC/PEs 128 MAC/PEs (a) (b) Figure 11. Accelerator with 128x128 MAC/PEs. Faulty MAC/PEs are randomly distributed across the columns. (a) Systolic, (b) SIMD architec"}
{"id": "Test and Yield Loss.pdf::chunk_49", "source": "Test and Yield Loss.pdf", "chunk_index": 49, "text": " MAC MAC MAC Memory and Control 128 MAC/PEs 128 MAC/PEs (a) (b) Figure 11. Accelerator with 128x128 MAC/PEs. Faulty MAC/PEs are randomly distributed across the columns. (a) Systolic, (b) SIMD architecture. For int8 quantized data format, Ô¨Årst, the RTL of signed 8-bit MAC unit was developed, followed by gate-level synthesis with SAED [ 46] 28nm standard cell library with Synopsys Design Compiler (DC) [ 46]. During synthesis, DC tool implemented the signed multiplier using the Baugh-Wooly architecture avail- able in DesignWare [ 46] IP library. The 16-bit adder unit was implemented using the Carry Look Ahead (CLA) structure from the DesignWare IP library. After the complete gate-level netlist of the MAC was available, a custom TCL script was developed for the logic cone analysis of the output bits. From analysis of Fig.10, we selected the Ô¨Årst two bits of the LSB (i.e., bits 0 and bit 1) as non-critical and bit positions 2 to 7 as critical, implying JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 9 Table I FAULT STATISITICS FOR SIGNED INT 8MULTIPLIER AND ADDER CaseTotal cellsNumber of stuck-at faultsTotal test patternsTest coverage All faults included 206 878 24 100% Criti"}
{"id": "Test and Yield Loss.pdf::chunk_50", "source": "Test and Yield Loss.pdf", "chunk_index": 50, "text": ", NO. X, AUGUST 202X 9 Table I FAULT STATISITICS FOR SIGNED INT 8MULTIPLIER AND ADDER CaseTotal cellsNumber of stuck-at faultsTotal test patternsTest coverage All faults included 206 878 24 100% Critical faults only ( Fcrit)198 854 23 100% Non-critical faults only ( Fnon\u0000crit)8 24 4 100% Table II FAULT STATS FOR MAC WITH BFLOAT 16 M ULTIPLIER AND FP32 ADDER CaseTotal cellsNumber of stuck-at faultsTotal test patternsTest coverage All faults included 1669 8755 217 98.74% Critical faults only ( Fcrit)1443 7552 195 98.65% Non-critical faults only ( Fnon\u0000crit)226 1188 32 99.83% that the worst-case total MAC error resulting from these two bits is\u0006(20+21+22) as explained in Section III(B). Next, using the developed TCL script with DC we obtained critical (Gcrit) and non-critical ( Gnon\u0000crit) standard cell logic gates present in the logic cones of critical and non-critical bits, respec- tively, as described in Algorithm 1 in Section 3(B). Next, the gate-level netlist and the critical and non-critical fault lists were taken to TestMAX ATPG tool [ 46] and three sets of ATPG test patterns were generated ‚Äì (i) with all faults, (ii) only with the critical faults, (iii) considering only the non-"}
{"id": "Test and Yield Loss.pdf::chunk_51", "source": "Test and Yield Loss.pdf", "chunk_index": 51, "text": "ritical fault lists were taken to TestMAX ATPG tool [ 46] and three sets of ATPG test patterns were generated ‚Äì (i) with all faults, (ii) only with the critical faults, (iii) considering only the non-critical faults. The results are shown in Table I. The reason that the number of test patterns for the all-faults case is lower than the sum of critical- only and non-critical-only cases is due to the method of ATPG pattern generation, where a single pattern can sometimes detect faults from both critical and non-critical groups. However, the test pattern counts to test the critical-only faults is less than the all-faults case in Table I. This critical pattern set can be applied Ô¨Årst to all the PEs in a broadcast manner to identify if there are any PEs that must be disabled, this is because, having a critical fault in MAC introduces a large magnitude of error. Next, for the PEs that passed the Ô¨Årst test, we apply the test patterns from Row 4 of Table I to test the presence of any non-critical faults. If faults are detected by this pattern set, the IDs of the faulty PEs are recorded in FSR memory as explained in Section III(c). ` 02.557.5 10 12.5 15 Fault Rate (%)0.980.9850.990.9951 With"}
{"id": "Test and Yield Loss.pdf::chunk_52", "source": "Test and Yield Loss.pdf", "chunk_index": 52, "text": "al faults. If faults are detected by this pattern set, the IDs of the faulty PEs are recorded in FSR memory as explained in Section III(c). ` 02.557.5 10 12.5 15 Fault Rate (%)0.980.9850.990.9951 Without Re-training With Re-training 02.5 57.5 10 12.5 15 Fault Rate (%)0.970.9750.980.9850.990.9951 Exact Multiplier ApproxMul (mul8_134) (a) (b) (c) (d) (e) (f) (g) (h) (a) (b) (c) (d) Top-1 Accuracy (with pruning) Top-5 Accuracy (with pruning) Top-1 Accuracy (with pruning) Top-5 Accuracy (with pruning) Top-5 Accuracy ( without pruning) Top-1 Accuracy ( without pruning) Top-1 Accuracy ( without pruning) Top-5 Accuracy (without pruning) 0 2.5 5 7.5 10 Fault Rate (%)949596979899Prune 784-100-100-10 784-200-200-10 784-300-300-10 784-400-400-10 Figure 12. Inference accuracy changes with fault (non-critical) rates for NN running MNIST: (a) Without pruning, (b) With 30% pruning and retraining As discussed in [ 40][41], recently, for training NN/CNN bÔ¨Çoat16 method is used where maultiplier is bÔ¨Çoat16 and accumulator is Ô¨Çoat32 type. To isolate the critical and non- critical faults of a Ô¨Çoating-point MAC, we obtained a Ô¨Çoating- point MAC benchmark circuit from OpenCores [ 47] andTable III MULTIPL"}
{"id": "Test and Yield Loss.pdf::chunk_53", "source": "Test and Yield Loss.pdf", "chunk_index": 53, "text": "16 and accumulator is Ô¨Çoat32 type. To isolate the critical and non- critical faults of a Ô¨Çoating-point MAC, we obtained a Ô¨Çoating- point MAC benchmark circuit from OpenCores [ 47] andTable III MULTIPLICATION AND ADDITIONS IN CNN TO CLASSIFY ONE IMAGE CNN ArchitectureConv2d LayersLinear LayersNumber of MultiplicationsNumber of Additions LeNet-5 3 2 416,520 416,520 AlexNet 5 3 714,188,480 714,188,480 VGG-16 13 3 15,470,264,320 15,470,264,320 ResNet-50 53 1 3,729,522,688 1,761,820,672 modiÔ¨Åed it for above mentioned bÔ¨Çoat format. We synthesized a gate-level netlist of the Ô¨Çoating point MAC using the DesignWare IP library. For the Ô¨Çoating-point MAC, we took the Ô¨Årst 4 LSB bits (bits 0 to 5) of the mantissa as non-critical (from analysis in Fig. 10), and the rest of the bits of mantissa, the exponent and sign bit are considered critical. After identifying the critical and non-critical gates and corresponding faults, the fault lists and the gate-level netlist were taken to the ATPG tool and test patterns were generated similar to the int8 case above. The results are shown in Table II. First, the test patterns from Row 3 of Table II are applied to identify all faulty PEs that must be disab"}
{"id": "Test and Yield Loss.pdf::chunk_54", "source": "Test and Yield Loss.pdf", "chunk_index": 54, "text": "est patterns were generated similar to the int8 case above. The results are shown in Table II. First, the test patterns from Row 3 of Table II are applied to identify all faulty PEs that must be disabled to prevent signiÔ¨Åcant accuracy loss in AI tasks. After that, the non-critical faults are identiÔ¨Åed with the patterns from Row 4 of Table II. All PEs that failed this second test have non-critical faults and their IDs are recorded in FSR. To analyze the impact of PE/MAC faults on the inference accuracy of NN, we implemented a 4-layer NN with two hidden layers, and varied the number of neurons in the hidden layers. Also, both un-pruned and 30% pruned (with-retraining) [24]-[26] versions were implemented. For NN experiments we used MATLAB deep learning toolbox [ 48]. All weights and activations were quantized in int8 format using MATLAB Fixed-Point tool [ 48]. To incorporate the worst-case non- critical MAC faults - obtained from the gate-level netlist above - into the NN inference task, the matrix multiplication function in forward pass of the NN used in inference was modiÔ¨Åed in MATLAB to inject faults according to the hardware model of Fig. 11. The relationship between accuracy and "}
{"id": "Test and Yield Loss.pdf::chunk_55", "source": "Test and Yield Loss.pdf", "chunk_index": 55, "text": "the matrix multiplication function in forward pass of the NN used in inference was modiÔ¨Åed in MATLAB to inject faults according to the hardware model of Fig. 11. The relationship between accuracy and fault rates are shown in Fig. 12. It can be seen from Fig. 12 (a) that, other than the smaller 100 hidden layer case, the rest of the NNs are robust to faults in the MAC, with normalized accuracy changes less than 0.5% at 5% fault rate. With pruning (Fig. 12 (b)), the accuracy degrades slightly more with faults. This is because with pruning less number of neurons are present, and those that are present become more important. To assess the impact of MAC circuit faults on the accuracy of CNN, we used several key benchmark CNNs ‚Äì AlexNet [11], VGG-16 [ 13], ResNet-50 [ 12] and LeNet-5 [ 44]. The number of convolution, linear layers and the total number of multiplication and additions required (without pruning) to classify each image in these networks are tabulated in Table III. These results were obtained using custom functions developed in Pytorch [ 49]. For the smaller CNN, LeNet-5, we performed both training and inference with MNIST dataset [44]. For the complex architectures - AlexNet"}
{"id": "Test and Yield Loss.pdf::chunk_56", "source": "Test and Yield Loss.pdf", "chunk_index": 56, "text": "were obtained using custom functions developed in Pytorch [ 49]. For the smaller CNN, LeNet-5, we performed both training and inference with MNIST dataset [44]. For the complex architectures - AlexNet, VGG-16 and ResNet-50 - training takes several days and requires multiple GPUs [ 11]-[13]. In Pytorch [ 49] library, pre-trained versions of these CNNs are available where they were already trained with ImageNet [ 14] dataset having millions of training JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 10 ` 02.557.5 10 12.5 15 Fault Rate (%)0.980.9850.990.9951 Without Re-training With Re-training 02.5 57.5 10 12.5 15 Fault Rate (%)0.970.9750.980.9850.990.9951 Exact Multiplier ApproxMul (mul8_134) (a) (b) (c) (d) (e) (f) (g) (h) (a) (b) (c) (d) Top-1 Accuracy (with pruning) Top-5 Accuracy (with pruning) Top-1 Accuracy (with pruning) Top-5 Accuracy (with pruning) Top-5 Accuracy ( without pruning) Top-1 Accuracy ( without pruning) Top-1 Accuracy ( without pruning) Top-5 Accuracy (without pruning) 0 2.5 5 7.5 10 Fault Rate (%)949596979899Prune 784-100-100-10 784-200-200-10 784-300-300-10 784-400-400-10 Figure 13. Inference accuracy changes with fault (non-critical) rates for CNNs"}
{"id": "Test and Yield Loss.pdf::chunk_57", "source": "Test and Yield Loss.pdf", "chunk_index": 57, "text": "thout pruning) 0 2.5 5 7.5 10 Fault Rate (%)949596979899Prune 784-100-100-10 784-200-200-10 784-300-300-10 784-400-400-10 Figure 13. Inference accuracy changes with fault (non-critical) rates for CNNs running imagenet dataset. (a), (b) Top-1 and Top-5 accuracy changes ; (c), (d) Top-1 and Top-5 accuracy changes with model pruning; (e) to (h) normalized accuracy changes in Top-1 and Top-5 (with and without pruning) for fault rates. images and 1000 possible classes. In our experiments we used these pre-trained models and performed inference with the 50,000 images from the ImageNet [14] validation dataset. During inference, the models were quantized into int8 format using Pytorch‚Äôs ‚Äò torch :nn:quantized ‚Äô library. To incorporate the worst-case non-critical MAC faults - obtained from the gate-level netlist above - in the inference function of the CNN, we used Pytorch‚Äôs ‚Äò register f orward hook ‚Äô feature to access the data in Conv2d function and injected the MAC faults according to the hardware model of Fig. 11. The accuracy changes - in the standard Top-1 and Top-5 format - with MAC faults are shown in Fig. 13 for 50,000 test images from ImageNet [ 14]. Top-1 accuracy implies that the "}
{"id": "Test and Yield Loss.pdf::chunk_58", "source": "Test and Yield Loss.pdf", "chunk_index": 58, "text": "ware model of Fig. 11. The accuracy changes - in the standard Top-1 and Top-5 format - with MAC faults are shown in Fig. 13 for 50,000 test images from ImageNet [ 14]. Top-1 accuracy implies that the predicted class matches exactly the actual class (out of 1000 possible classes) and Top-5 refers to the case where the actual class is within the top 5 predicted classes [ 11]-[13][49]. From Fig. 13 (e), it can be seen that the normalized accuracy in Top-1 category changes by less than 1.5% for all networks when fault rates are within 5%. For the Top-5 category in Fig. 13 (f), except for the computationally intensive VGG-16 network, the normalized accuracy degradation was conÔ¨Åned within 1% for fault rates up to 5%. Next, we pruned 30% of the Ô¨Ålter weights of the convolution layers and repeated our fault injection experiments. Form Fig. 13 (g)-(h), it can be seen that, with pruning, the normalized Top-1 accuracy degraded by a small amount with worst-case happening for ResNet-50 where it degraded by 2.2% for fault rate 5%. Even with pruning, the Top-5 normalized accuracy degradation was within 1% for fault rates up to 5%. Note that, during our pruning experiments on AlexNet/VGG-16/ResNet"}
{"id": "Test and Yield Loss.pdf::chunk_59", "source": "Test and Yield Loss.pdf", "chunk_index": 59, "text": "raded by 2.2% for fault rate 5%. Even with pruning, the Top-5 normalized accuracy degradation was within 1% for fault rates up to 5%. Note that, during our pruning experiments on AlexNet/VGG-16/ResNet-50 retraining was not done, because it would have required us to retrain the networks with 14 million images using a large number of GPUs. Retraining during pruning would improve the accuracy further [24]-[26]. As discussed in Section III(c)(2), using our proposed fault-aware training Ô¨Çow some of the accuracy loss due to faults in MAC units can be recovered by incorporating the fault effects in the backpropagation-based weight update segment and allowing the CNN to adapt accordingly. To experimentally demonstrate this technique, we used the LeNet-5 CNN Top-1 Accuracy (for bfloat16 case) Top-1 Accuracy (for int8 case) Top-5 Accuracy (for int8 case) Top-5 Accuracy (for bfloat16 case) (a) (b) (d) (c) NLSB = 2 NLSB = 3 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 3 NLSB = 2 NLSB = 4 NLSB = 4 NLSB = 3 NLSB = 5 NLSB = 4 NLSB = 3 NLSB = 5 Figure 14. Improvement in accuracy with fault-aware training on LeNet-5. 02.557.5 10 12.5 15 Fault Rate (%)0.980.9850.990.9951 Wit"}
{"id": "Test and Yield Loss.pdf::chunk_60", "source": "Test and Yield Loss.pdf", "chunk_index": 60, "text": "SB = 2 NLSB = 4 NLSB = 4 NLSB = 3 NLSB = 5 NLSB = 4 NLSB = 3 NLSB = 5 Figure 14. Improvement in accuracy with fault-aware training on LeNet-5. 02.557.5 10 12.5 15 Fault Rate (%)0.980.9850.990.9951 Without Re-training With Re-training 02.5 57.5 10 12.5 15 Fault Rate (%)0.970.9750.980.9850.990.9951 Exact Multiplier ApproxMul (mul8_134) 784-100-100-10 784-200-200-10 784-300-300-10 784-400-400-10 (a) (b) (c) (d) (e) (f) (g) (h) With Pruning With Pruning Figure 15. Accuracy change of LeNet-5 CNN with faults for approximate and exact multipliers without retraining. architecture. We picked the simpler LeNet-5 architecture over AlexNet/VGG-16/ResNet-50 because of the computational complexity of training. Whereas AlexNet/VGG-16/ResNet-50 would require multiple GPUs and several days of training with ImageNet data [ 11]-[13], the LeNet-5 can be trained in several minutes on MNIST dataset using CPU. We used 6-core Intel core i7 CPU with 24GB RAM in this training experiment. We modeled the equivalent worst-case MAC error - corresponding to faults occurring in the logic cones of 4 LSB bits of mantissa - in the forward and backpropagation segment using Pytorch‚Äôs ‚Äò register hook ‚Äô feature [ 49]. R"}
{"id": "Test and Yield Loss.pdf::chunk_61", "source": "Test and Yield Loss.pdf", "chunk_index": 61, "text": "nt worst-case MAC error - corresponding to faults occurring in the logic cones of 4 LSB bits of mantissa - in the forward and backpropagation segment using Pytorch‚Äôs ‚Äò register hook ‚Äô feature [ 49]. Results from this fault-aware training are shown in Fig. 14. The results in Fig. 14, corresponds to the bÔ¨Çoat16 format training and inference hardware model as presented in [ 40][41] where multiplier is of bÔ¨Çoat16 type and accumulator is of Ô¨Çoat32. It can be seen that for 7.5% fault rate the normalized accuracy loss improved JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 11 from 0.5% to 0.22% due to fault-aware training. In Section II(A), we explained that the presence of defect- induced circuit faults in approximate NN/CNN will deteriorate the AI task‚Äôs accuracy as errors from approximations in MAC were already introduced in the model, and any further error from circuit faults will be detrimental. In Fig. 15, the normalized change of accuracy with respect to faults for LeNet-5 on MNIST dataset is shown for cases of exact and approximate multipliers. In [ 31] a comprehensive analysis (with approximation aware retraining) of different types approximate multipliers on the efÔ¨Åc"}
{"id": "Test and Yield Loss.pdf::chunk_62", "source": "Test and Yield Loss.pdf", "chunk_index": 62, "text": "on MNIST dataset is shown for cases of exact and approximate multipliers. In [ 31] a comprehensive analysis (with approximation aware retraining) of different types approximate multipliers on the efÔ¨Åciency of neural networks were performed, and the best approx. multipliers in terms of prediction accuracy were reported. Based on these Ô¨Åndings [ 31], in our experiment as an approx. multiplier, we chose mul8134 from the open-source library of EvoApprox8b [ 42]. As discussed in [28][31], the accuracy of CNN/NN using approximate multipliers are very sensitive to proper training compared to regular multipliers, and the backpropagation training phase must be updated to account for approximate computing. In our experiment, the initial training phase was updated (using Pytorch‚Äôs hook functions [ 49]) to account for the use of 8-bit approx. multiplier, also int8 quantization was used. From Fig. 15, it can be observed that the presence of faults will degrade the performance of NNs with approx. multipliers signiÔ¨Åcantly. Hence, if yield loss reduction is the primary goal, exact MAC units need to be used to account for possible circuit faults. From these detailed analyses of gate-level synthesis"}
{"id": "Test and Yield Loss.pdf::chunk_63", "source": "Test and Yield Loss.pdf", "chunk_index": 63, "text": "ltipliers signiÔ¨Åcantly. Hence, if yield loss reduction is the primary goal, exact MAC units need to be used to account for possible circuit faults. From these detailed analyses of gate-level synthesis, fault isolation, ATPG pattern generation for the MAC circuit, and corresponding simulation of fault effects on standard NN/CNN benchmarks, it can be observed that certain circuit faults - based on their locations in the circuit - have minimal impact on the AI task‚Äôs accuracy when the fault rate is within an upper limit. For example, with 5% fault rate in non-critical gates, the normalized Top-5 accuracy loss in CNNs is less than 1% (Fig. 13(f)(h)). If this 1% accuracy loss is acceptable, and if there are more than 5% faulty PEs, then using the IDs of faulty PEs stored in the Fault Status Register, some faulty PEs can de deactivated on each column of the accelerator such that the fault rate is within 5% on each column of the PE array. For instance, in Fig. 13(h), at 10% fault-rate the normalized Top-5 accuracy degradation is 3.2% for AlexNet, but after deactivating few faulty PEs uniformly in each column of the accelerator the fault-rate per column can be reduced to 5% and this will r"}
{"id": "Test and Yield Loss.pdf::chunk_64", "source": "Test and Yield Loss.pdf", "chunk_index": 64, "text": "malized Top-5 accuracy degradation is 3.2% for AlexNet, but after deactivating few faulty PEs uniformly in each column of the accelerator the fault-rate per column can be reduced to 5% and this will result in improved Top-5 accuracy degradation to less than 1%. As a result, an AI accelerator chip with few faulty PEs can be binned accordingly and shipped, improving valuable yield and revenue. The tradeoff in this yield saving would be the lower number of PE blocks in the accelerator due to the deactivation of few faulty PEs to keep the fault rate within an acceptable limit (i.e., 5%), however, this will not have any functional impact, and will only reduce the throughput marginally. Furthermore, the reduced throughput PEs can be binned and priced differently without totally discarding the chip, thus saving yield. For example, the accelerators with no fault at all can be placed in the top bin and sold at a premium price to be used in safety-critical applications such as self-driving cars, whereas accelerators in the lower bins (with few faults, e.g., less than 5% fault rate) can be used in other AI/deep-learningtasks that can tolerate errors with minimal performance loss. In [33] when"}
{"id": "Test and Yield Loss.pdf::chunk_65", "source": "Test and Yield Loss.pdf", "chunk_index": 65, "text": " whereas accelerators in the lower bins (with few faults, e.g., less than 5% fault rate) can be used in other AI/deep-learningtasks that can tolerate errors with minimal performance loss. In [33] when considering faults, authors assumed the complete MAC unit (i.e., all bits) was faulty, in contrast, our approach is more pragmatic and conservative. We analyzed our faults within groups of bits (i.e., logic cone of certain LSBs Vs. logic cone of the rest). If there are any errors beyond a certain LSB position we deactivate that PE to avoid a large extent of error in the accuracy. The complexity and cost of our approach are also minimal. For identifying the allowable non-critical fault rate and the number of LSBs, our search space is limited as we choose few LSB bits and fault rates (Fig. 10). Moreover, inference is not necessarily time-consuming and if such an analysis is performed once per hardware with an exhaustive benchmark like ImageNet [ 14], then it will sufÔ¨Åce for any other benchmark. For the fault-aware training part, only the forward pass function needs to be updated to reÔ¨Çect the MAC fault rate that would be present during inference, and this is done for only one fault rate"}
{"id": "Test and Yield Loss.pdf::chunk_66", "source": "Test and Yield Loss.pdf", "chunk_index": 66, "text": "ark. For the fault-aware training part, only the forward pass function needs to be updated to reÔ¨Çect the MAC fault rate that would be present during inference, and this is done for only one fault rate (e.g., 2.5% or 5% in Fig. 14). Hence, our fault-aware training does not add extra complexity compared to regular training. As we conÔ¨Åne our faults within a few LSBs, our approach does not require hardware fault location-aware AI workload mapping and retraining as in [ 33]. In our experiments we used the state-of-the-art CNNs that were pre-trained with 1 million images from ImageNet [ 14]. Be- cause of the large training set, these CNNs are very well-trained for any other type of pattern recognition/AI task (i.e., similar to the concept of ‚Äútransfer learning‚Äù where ImageNet pre-trained networks can be used for any other pattern recognition problem by adjusting and training the Ô¨Ånal layers). Also, for validation of our fault effects, we used the 50K sample validation images from ImageNet with PyTorch. As we have shown our approach works on various CNNs trained with ImageNet, it sufÔ¨Åces that for any other AI workload the concept is applicable. V. C ONCLUSION In this paper, we presented a"}
{"id": "Test and Yield Loss.pdf::chunk_67", "source": "Test and Yield Loss.pdf", "chunk_index": 67, "text": "th PyTorch. As we have shown our approach works on various CNNs trained with ImageNet, it sufÔ¨Åces that for any other AI workload the concept is applicable. V. C ONCLUSION In this paper, we presented a yield loss reduction and test methodology for AI accelerator chips densely packed with PEs. Exploiting the error-healing properties of backpropagation during training and the inherent fault tolerance features of trained AI models during inference, we obtained an analytical relationship between fault location and fault rate of MAC, and the AI task‚Äôs accuracy to guide yield decisions. Simulation results on NN/CNN show that the proposed YAOTA approach will allow up to 5% faulty PEs in the accelerator at the expense of less than 1% loss in the AI task‚Äôs accuracy. Furthermore, the presented fault-aware binning strategy allows accelerators to be binned, with the goal of yield loss reduction, according to the fault-rate and target end-user applications. REFERENCES [1]V . Sze, Y . Chen, T. Yang and J. S. Emer, ‚ÄúEfÔ¨Åcient Processing of Deep Neural Networks: A Tutorial and Survey,‚Äù in Proceedings of the IEEE, vol. 105, no. 12, pp. 2295-2329, Dec. 2017 [2]Y . Chen, T. Yang, J. Emer and V . Sze, ‚Äú"}
{"id": "Test and Yield Loss.pdf::chunk_68", "source": "Test and Yield Loss.pdf", "chunk_index": 68, "text": "nd J. S. Emer, ‚ÄúEfÔ¨Åcient Processing of Deep Neural Networks: A Tutorial and Survey,‚Äù in Proceedings of the IEEE, vol. 105, no. 12, pp. 2295-2329, Dec. 2017 [2]Y . Chen, T. Yang, J. Emer and V . Sze, ‚ÄúEyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices,‚Äù in IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 2019 [3]J. Lee et. al., ‚ÄúLNPU: A 25.3TFLOPS/W Sparse Deep-Neural-Network Learning Processor with Fine-Grained Mixed Precision of FP8-FP16,‚Äù IEEE International Solid- State Circuits Conference - (ISSCC), 2019 JOURNAL OF L ATEX CLASS FILES, VOL. XX, NO. X, AUGUST 202X 12 [4]N. Jouppi et. al., ‚ÄúA domain-speciÔ¨Åc architecture for deep neural networks,‚Äù Commun. ACM 61, vol 9, pp. 50‚Äì59, 2018 [5] AWS Inferentia Chip: https://aws.amazon.com/ [6]S. Markidis, et. al., ‚ÄúNVIDIA Tensor Core Programmability, Performance & Precision,‚Äù IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), 2018 [7] Gorq Tensor Processor: https://groq.com/technology/ [8]G. Batra et. al., ‚ÄúArtiÔ¨Åcial-intelligence hardware: New opportunities for semiconductor companies,‚Äù McKinsey & Company, January 2019 [9]Liam Tung, ‚ÄúGPU Killer: Goo"}
{"id": "Test and Yield Loss.pdf::chunk_69", "source": "Test and Yield Loss.pdf", "chunk_index": 69, "text": "sor: https://groq.com/technology/ [8]G. Batra et. al., ‚ÄúArtiÔ¨Åcial-intelligence hardware: New opportunities for semiconductor companies,‚Äù McKinsey & Company, January 2019 [9]Liam Tung, ‚ÄúGPU Killer: Google reveals just how powerful its TPU2 chip really is,‚Äù ZDNet, December 14, 2017 [10] S. Moore, ‚ÄúCerebras‚Äôs Giant Chip Will Smash Deep Learning‚Äôs Speed Barrier,‚Äù IEEE Spectrum January, 2020 [11] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‚Äú ImageNet classiÔ¨Åcation with deep convolutional neural networks,‚Äù in NIPS, 2012 [12] K. He et. al, ‚ÄúDeep Residual Learning for Image Recognition,‚Äù Computer Vision and Pattern Recognition (CVPR), 2016 [13] K. Simonyan and A. Zisserman,‚ÄúVery Deep Convolutional Networks for Large-Scale Image Recognition,‚Äù in ICLR 2015 [14] J. Deng, W. Dong, R. Socher, L. Li, Kai Li and Li Fei-Fei, ‚ÄúImageNet: A large-scale hierarchical image database,‚Äù IEEE CVPR, 2009 [15] A. J. Strojwas, K. Doong and D. Ciplickas, ‚ÄúYield and Reliability Challenges at 7nm and Below,‚Äù Electron Devices Technology and Manufacturing Conference (EDTM), 2019 [16] S. Kobayashi, et. al., ‚ÄúYield-centric layout optimization with precise quantiÔ¨Åcation of lithographic yield loss,‚Äù Proc. SPIE, Pho"}
{"id": "Test and Yield Loss.pdf::chunk_70", "source": "Test and Yield Loss.pdf", "chunk_index": 70, "text": "tron Devices Technology and Manufacturing Conference (EDTM), 2019 [16] S. Kobayashi, et. al., ‚ÄúYield-centric layout optimization with precise quantiÔ¨Åcation of lithographic yield loss,‚Äù Proc. SPIE, Photomask and Next-Generation Lithography Mask Technology, 2008 [17] M. Nero, C. Shan, L. Wang and N. Sumikawa, ‚ÄúConcept Recognition in Production Yield Data Analytics,‚Äù International Test Conference, 2018 [18] G. Moore et al.,, ‚ÄúAccelerating 14nm device learning and yield ramp using parallel test structures as part of a new inline parametric test strategy,‚Äù ICMTS, 2015 [19] P. Maxwell, F. Hapke and H. Tang, ‚ÄúCell-aware diagnosis: Defective inmates exposed in their cells,‚Äù European Test Symposium (ETS), 2016 [20] Z. Gao et al., ‚ÄúApplication of Cell-Aware Test on an Advanced 3nm CMOS Technology Library,‚Äù International Test Conference (ITC), 2019 [21] B. Jorgenson, ‚ÄúIntel‚Äôs 2020 Forecast is Grim,‚Äù in EE Times, April, 2020 [22] S. Moore, ‚Äú3 Ways Chiplets Are Remaking Processors,‚Äù IEEE Spectrum, April, 2020 [23] P. Gupta and S. Iyer ‚ÄúGoodbye, Motherboard. Hello, Silicon-Interconnect Fabric,‚Äù IEEE Spectrum, October 2019 [24] S. Han, J. Pool, J. Tran, and W. Dally, ‚ÄúLearning both weights and co"}
{"id": "Test and Yield Loss.pdf::chunk_71", "source": "Test and Yield Loss.pdf", "chunk_index": 71, "text": "April, 2020 [23] P. Gupta and S. Iyer ‚ÄúGoodbye, Motherboard. Hello, Silicon-Interconnect Fabric,‚Äù IEEE Spectrum, October 2019 [24] S. Han, J. Pool, J. Tran, and W. Dally, ‚ÄúLearning both weights and connections for efÔ¨Åcient neural networks,‚Äù in International Conference on Neural Information Processing Systems (NIPS‚Äô15), 2015 [25] N. Lee, T. Ajanthan and P. Torr, ‚ÄúSNIP: Single-shot network pruning based on connection sensitivity,‚Äù in proceedings of International Conference on Learning Representations (ICLR) 2019 [26] S. Han, H. Mao, W. Dally, ‚ÄúDeep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding‚Äù, in ICLR 2016 [27] N. Srivastava et. al., ‚ÄúDropout: A Simple Way to Prevent Neural Networks from OverÔ¨Åtting‚Äù Journal of Machine Learning Research, 2014 [28] S. Venkataramani, A. Ranjan, K. Roy and A. Raghunathan, ‚ÄúAxNN: Energy-efÔ¨Åcient neuromorphic systems using approximate computing,‚Äù 2014 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED), pp. 27-32, 2014. [29] Q. Zhang et. al., ‚ÄúApproxANN: An approximate computing framework for artiÔ¨Åcial neural network,‚Äù 2015 Design, Automation & Test in Europe Conference & Exh"}
{"id": "Test and Yield Loss.pdf::chunk_72", "source": "Test and Yield Loss.pdf", "chunk_index": 72, "text": "ics and Design (ISLPED), pp. 27-32, 2014. [29] Q. Zhang et. al., ‚ÄúApproxANN: An approximate computing framework for artiÔ¨Åcial neural network,‚Äù 2015 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 701-706, 2015. [30] V . Mrazek et. al,, ‚ÄúDesign of power-efÔ¨Åcient approximate multipliers for approximate artiÔ¨Åcial neural networks,‚Äù in International Conference on Computer-Aided Design (ICCAD ‚Äô16), Article 81, 1‚Äì7, 2016 [31] M. S. Ansari et. al, ‚ÄúImproving the Accuracy and Hardware EfÔ¨Åciency of Neural Networks Using Approximate Multipliers,‚Äù IEEE Transactions on Very Large Scale Integration (VLSI) Systems, Feb. 2020. [32] A. Gebregiorgis and M. B. Tahoori, ‚ÄúTesting of Neuromorphic Circuits: Structural vs Functional,‚Äù International Test Conference (ITC), 2019 [33] J. Zhang, K. Basu and S. Garg, ‚ÄúFault-Tolerant Systolic Array Based Accelerators for Deep Neural Network Execution,‚Äù in IEEE Design & Test, vol. 36, no. 5, pp. 44-53, Oct. 2019. [34] J. Zhang, K. Rangineni, Z .Ghodsi, and S Garg, ‚ÄúThundervolt: enabling aggressive voltage underscaling and timing error resilience for energy efÔ¨Åcient deep learning accelerators,‚Äù in Proceedings of the 55th Annual Design Autom"}
{"id": "Test and Yield Loss.pdf::chunk_73", "source": "Test and Yield Loss.pdf", "chunk_index": 73, "text": " .Ghodsi, and S Garg, ‚ÄúThundervolt: enabling aggressive voltage underscaling and timing error resilience for energy efÔ¨Åcient deep learning accelerators,‚Äù in Proceedings of the 55th Annual Design Automation Conference, 2018. [35] S. Kim et. al., ‚ÄúEnergy-EfÔ¨Åcient Neural Network Acceleration in the Presence of Bit-Level Memory Errors,‚Äù in IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 65, Dec. 2018.[36] J. Kim and S. M. Reddy, ‚ÄúOn the design of fault-tolerant two-dimensional systolic arrays for yield enhancement,‚Äù in IEEE Transactions on Computers, vol. 38, no. 4, pp. 515-525, April 1989. [37] R.Das and T. Krishna ‚ÄúDNN Accelerator Architecture ‚Äì SIMD or Systolic?, ‚Äù in Computer Architecture Today, ACM SIGARCH, 2018 [38] J. Wu et. al.,‚ÄúQuantized Convolutional Neural Networks for Mobile Devices,‚Äù Computer Vision and Pattern Recognition (CVPR), 2016 [39] S. Migacz, ‚Äú8-bit Inference with TensorRT,‚Äù NVIDIA, 2017 [40] P. Micikevicius et. al., ‚ÄúMixed Precision Training,‚Äù in ICLR 2018 [41] S. Wang and P. Kanwar, ‚ÄúBFloat16: The secret to high performance on Cloud TPUs,‚Äù in Google Cloud Blog, 2019 [42] V . Mrazek et. al.,, ‚ÄúEvoApprox8b: Library of Approximate Adders and Multi"}
{"id": "Test and Yield Loss.pdf::chunk_74", "source": "Test and Yield Loss.pdf", "chunk_index": 74, "text": "LR 2018 [41] S. Wang and P. Kanwar, ‚ÄúBFloat16: The secret to high performance on Cloud TPUs,‚Äù in Google Cloud Blog, 2019 [42] V . Mrazek et. al.,, ‚ÄúEvoApprox8b: Library of Approximate Adders and Multipliers for Circuit Design and Benchmarking of Approximation Methods,‚Äù in DATE, pp. 258-261, 2017. [43] R. Ray Ramadorai, et. al., ‚ÄúMethod and apparatus for disabling and swapping cores in a multi-core microprocessor,‚Äù, Intel Corporation, US Patent: US20070255985A1 [44] online: http://cs231n.stanford.edu/slides/2017/cs231n 2017 lecture9.pdf [45] Designware IP, online: https://www.synopsys.com/designware-ip.html [46] Synopsys: https://www.synopsys.com/ [47] Opencores: https://opencores.org/ [48] MATLAB: https://www.mathworks.com/products/matlab.html [49] Pytorch: https://pytorch.org/ Mehdi Sadi (S‚Äô12-M‚Äô17) is currently an Assistant Professor at the Department of Electrical and Computer Engineering (ECE) at Auburn University, Auburn, AL. Dr. Sadi earned his PhD in ECE from University of Florida, Gainesville, USA in 2017, MS from University of California at Riverside, USA in 2011 and BS from Bangladesh University of Engineering and Technology in 2010. Prior to joining Auburn University, he"}
{"id": "Test and Yield Loss.pdf::chunk_75", "source": "Test and Yield Loss.pdf", "chunk_index": 75, "text": "da, Gainesville, USA in 2017, MS from University of California at Riverside, USA in 2011 and BS from Bangladesh University of Engineering and Technology in 2010. Prior to joining Auburn University, he was a Senior R&D SoC Design Engineer in the Xeon Design team at Intel Corporation in Oregon. Dr. Sadi‚Äòs research focus is on developing algorithms and Computer-Aided-Design (CAD) techniques for implementation, design, test & reliability of AI, and brain-inspired computing hardware. His research also spans into developing Machine Learning/AI enabled System-on-Chip (SoC) design Ô¨Çows, and Design-for-Reliability for safety- critical AI hardware systems. He has published more than 20 peer-reviewed research papers. He was the recipient of Semiconductor Research Corporation best in session award and Intel Xeon Design Group recognition awards. Ujjwal Guin (S‚Äô10‚ÄìM‚Äô16) received his PhD degree from the Electrical and Computer Engineering Department, University of Connecticut, in 2016. He is currently an Assistant Professor in the Electrical and Computer Engineering Department of Auburn University, Auburn, AL, USA. He received his BE degree from the Department of Electronics and Telecommunication"}
{"id": "Test and Yield Loss.pdf::chunk_76", "source": "Test and Yield Loss.pdf", "chunk_index": 76, "text": "y an Assistant Professor in the Electrical and Computer Engineering Department of Auburn University, Auburn, AL, USA. He received his BE degree from the Department of Electronics and Telecommunication Engineering, Bengal Engineering and Science University, Howrah, India, in 2004, and his MS degree from the Department of Electrical and Computer Engineering, Temple University, Philadelphia, PA, USA, in 2010. Dr. Guin has developed several on-chip structures and techniques to improve the security, trustworthiness, and reliability of integrated circuits. His current research interests include Hardware Security & Trust, Blockchain, Supply Chain Security, Cybersecurity, and VLSI Design & Test. He is a co-author of the book Counterfeit Integrated Circuits: Detection and Avoidance . He has authored several journal articles and refereed conference papers. He was actively involved in developing a web-based tool, Counterfeit Defect Coverage Tool (CDC Tool), http://www.sae.org/standardsdev/cdctool/ , to evaluate the effectiveness of different test methods used for counterfeit IC detection. He is an active participant in the SAE International G-19A Test Laboratory Standards Development Committe"}
{"id": "Test and Yield Loss.pdf::chunk_77", "source": "Test and Yield Loss.pdf", "chunk_index": 77, "text": "/ , to evaluate the effectiveness of different test methods used for counterfeit IC detection. He is an active participant in the SAE International G-19A Test Laboratory Standards Development Committee and G-32 Cyber-Physical Systems Security Committee. He is a member of the IEEE and ACM."}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_0", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 0, "text": "104 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 Test and Yield Loss Reduction of AI and Deep Learning Accelerators Mehdi Sadi ,Member, IEEE , and Ujjwal Guin ,Member, IEEE Abstract ‚ÄîWith data-driven analytics becoming mainstream, the global demand for dedicated artiÔ¨Åcial intelligence (AI) anddeep learning accelerator chips is soaring. These accelerators,designed with densely packed processing elements (PE), are espe-cially vulnerable to the manufacturing defects and functionalfaults common in the advanced semiconductor process nodesresulting in signiÔ¨Åcant yield loss. In this work, we demonstratean application-driven methodology of binning the AI acceler-ator chips, and yield loss reduction by correlating the circuitfaults in the PEs of the accelerator with the desired accuracyof the target AI workload. We exploit the inherent fault toler-ance features of trained deep learning models and a strategy ofselective deactivation of faulty PEs to develop the presented yieldloss reduction and test methodology. An analytical relationship isderived between fault location, fault rate, and the AI task‚Äôs accu-racy for deciding if th"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_1", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 1, "text": "of faulty PEs to develop the presented yieldloss reduction and test methodology. An analytical relationship isderived between fault location, fault rate, and the AI task‚Äôs accu-racy for deciding if the accelerator chip can pass the Ô¨Ånal yieldtest. A yield-loss reduction-aware fault isolation, ATPG, and test Ô¨Çow are presented for the multiply and accumulate units of the PEs. Results obtained with widely used AI/deep learning bench-marks demonstrate that the accelerators can sustain 5% faultrate in PE arrays while suffering from less than 1% accuracyloss, thus enabling product binning and yield loss reduction ofthese chips. Index Terms ‚ÄîArtiÔ¨Åcial intelligence (AI) accelerators, fault- tolerant AI, test, yield. I. I NTRODUCTION THE DEMAND for artiÔ¨Åcial intelligence (AI) and deep learning is growing at a rapid pace across a wide range of applications such, as self-driving vehicles, image and voicerecognition, medical imaging and diagnosis, Ô¨Ånance and bank-ing, natural resource explorations, defense operations, etc. Because of these data-driven analytics and AI boom, demands in deep learning and AI will emerge at both data centersand the edge [1]‚Äì[8]. In a recent market research [8], it"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_2", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 2, "text": ", defense operations, etc. Because of these data-driven analytics and AI boom, demands in deep learning and AI will emerge at both data centersand the edge [1]‚Äì[8]. In a recent market research [8], it hasbeen reported that AI-related semiconductors will see a growthof about 18% annually over the next few years‚ÄîÔ¨Åve timesgreater than the rate for non-AI applications. By 2025, AI-related semiconductors could account for almost 20% of all semiconductor demand, which would translate into about $67 billion in revenue [8]. Manuscript received August 5, 2020; revised October 11, 2020 and December 15, 2020; accepted January 10, 2021. Date of publication January 14, 2021; date of current version December 23, 2021. This work was supported by the IGP grant from Auburn University, Auburn, AL, USA. Thisarticle was recommended by Associate Editor A. E. Gattiker. (Corresponding author: Mehdi Sadi.) The authors are with the Department of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849 USA (e-mail:mehdi.sadi@auburn.edu; ujjwal.guin@auburn.edu). Digital Object IdentiÔ¨Åer 10.1109/TCAD.2021.3051841Although GPU was adopted by the AI community, by design GPUs were not optimized fo"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_3", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 3, "text": "L 36849 USA (e-mail:mehdi.sadi@auburn.edu; ujjwal.guin@auburn.edu). Digital Object IdentiÔ¨Åer 10.1109/TCAD.2021.3051841Although GPU was adopted by the AI community, by design GPUs were not optimized for AI workloads [8], [9]. As aresult signiÔ¨Åcant research and development efforts in devel-oping AI accelerators‚Äîoptimized to achieve much higherthroughput in deep learning compared to GPUs‚Äîare under- way from academia [2], [3], big techs [4]‚Äì[6], as well as startups [7], [10]. Dedicated accelerators are in high demandfor both the cloud-based training, and inference tasks onedge devices. The training procedure is time-consuming as itrequires many learning samples to adapt the network parame-ters. For instance, a self-driving car‚Äôs neural network has to betrained with many images of possible objects it can encounteron the road, and this will require multiple high-performance AI accelerators on the cloud. During inference, AI algorithms handle less data but rapid responses are required as they areoften used in critical time-sensitive applications. For example,an autonomous vehicle has to make immediate decisions onobjects it sees during driving, a medical device must interpreta trauma pati"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_4", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 4, "text": " areoften used in critical time-sensitive applications. For example,an autonomous vehicle has to make immediate decisions onobjects it sees during driving, a medical device must interpreta trauma patient‚Äôs brain scans immediately. As a result, highthroughput accelerators running on edge devices and capable of fast inference are required. In AI technology innovation and leadership, high-throughput AI accelerator hardware chips willserve as the differentiator [8], [10]. Millions of multiply and accumulate (MAC) operations are needed in modern AI tasks, for example, AlexNet [11] andResNET-50 [12] require 0.7 Billion and 3.7 Billion MACoperations, respectively, to classify a single image from theImageNet [14] dataset. Modern AI accelerators contain thou- sands of processing elements (PE) distributed in densely packed arrays in a single chip/die [1]‚Äì[5] or in a multichiplet-based chip [10]. To accommodate as many PEs as possible inthe AI accelerator, a large chip (e.g., wafer-scale) would be thebest solution [10]. However, manufacturing large chips is dif-Ô¨Åcult due to the long interconnect wires and the possibility ofparticle defects. Aggressive scaling of design rules [15], lithog- rap"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_5", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 5, "text": "e thebest solution [10]. However, manufacturing large chips is dif-Ô¨Åcult due to the long interconnect wires and the possibility ofparticle defects. Aggressive scaling of design rules [15], lithog- raphy imperfections [16], local edge roughness, interconnect pitch reduction, etc., in 10 nm and newer semiconductor tech-nologies [15] have caused yield (i.e., the fraction of totalmanufactured chips that can be sold to the customer) tobecome as important as the conventional design metrics ofpower, performance, area (PPA) for the process to be eco-nomically viable [17], [18]. Moreover, internal cell defects have become a major yield limiter because of aggressive scal- ing of design rules and lithography limitations in printingthe features, giving rise to cell-aware test [19]. In addi-tion to the regular stuck-at and timing faults at the cell I/Olevel, at advanced technologies, the transistor level and othercell-internal faults need to be added to the fault list as yieldhas become more vulnerable to internal cell defects [20].Although yield data of semiconductor process are considered 1937-4151 c/circlecopyrt2021 IEEE. Personal use is permitted, but republication/redistribution requires I"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_6", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 6, "text": "able to internal cell defects [20].Although yield data of semiconductor process are considered 1937-4151 c/circlecopyrt2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 105 a well-guarded trade secret and not published, it is well known that yield loss has caused signiÔ¨Åcant delays in product readi- ness, and loss in market share and revenue for a leadingprocessor manufacturer at 10 nm and 7 nm [21]. To inte-grate more PE in the accelerator, a two-level chiplet [22]based approach, where many PE are placed on a smallerchiplet, and then multiple chiplets are connected with siliconinterconnect fabric [23] to form the accelerator is a viablesolution. Although a relatively smaller size would minimize particle-induced random defects on upper metal layers in the chiplets and improve defect-induced yield loss, the individ-ual PEs‚Äîinternal to the "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_7", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 7, "text": "ion. Although a relatively smaller size would minimize particle-induced random defects on upper metal layers in the chiplets and improve defect-induced yield loss, the individ-ual PEs‚Äîinternal to the chiplet‚Äîwill still be susceptible tosystematic defects [17] and lithography imperfections [15]that impact the transistor layers or the ultradense lower metallayers. As many PEs are densely placed in the AI accelerators, defects and circuit faults are likely to occur in some PEs. Fortunately, the stochasticity inherent in the backpropagation-based training of deep neural networks (NNs) and deepconvolutional NN (CNN)‚Äîthe primary building blocks ofAI systems‚Äîoffers a certain degree of resilience and errortolerance to deep learning tasks. Moreover, the intelligentapplication of techniques, such as dropout, pruning, and quan- tization during training can further increase the robustness of a trained NN/CNN against variations and noise during infer-ence [24]‚Äì[27]. The error-resilience properties of well-traineddeep NN/CNNs can be exploited in hardware by allowingthe PE of the dense AI accelerator to incur some circuitfaults‚Äîcaused by semiconductor manufacturing process vari-ation induced defe"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_8", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 8, "text": "of well-traineddeep NN/CNNs can be exploited in hardware by allowingthe PE of the dense AI accelerator to incur some circuitfaults‚Äîcaused by semiconductor manufacturing process vari-ation induced defects‚Äîand still function correctly within anaccuracy bound. As a result, a fault-tolerance aware test Ô¨Çow is required for these accelerators that can test the individual PEs, and certify if the fault of the PE is acceptable or unac-ceptable depending on how many of the rest of the PEs arefault-free or faulty, and the impact of faults on AI accuracy.An innovative solution would be to implement a Ô¨Åne-grainedfault tolerance scheme that allows the deactivation of individ-ual PEs in the event that the PE fault rate (i.e., the fraction of PEs that are faulty) exceeds a threshold. Following this approach, an AI accelerator with some faulty PEs to stillfunction, and will not cause the discard of the whole AIaccelerator chip, resulting in a signiÔ¨Åcant reduction in yieldloss [15]‚Äì[18]. In this article, we propose yield and accuracy-aware opti- mum test of AI accelerators (YAOTA), which considers the accuracy-sensitivity and fault-tolerance of AI applications into test pattern generation for the ac"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_9", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 9, "text": ", we propose yield and accuracy-aware opti- mum test of AI accelerators (YAOTA), which considers the accuracy-sensitivity and fault-tolerance of AI applications into test pattern generation for the accelerators in deciding whether it will pass the yield test. The key contributions and highlights of this article are as follows. 1) An analytical relationship is established‚Äîbased on the actual AI workload to be executed‚Äîbetween the a) faults of the MAC modules and b) the rate of faults,and the accuracy of the AI task. This relationship is used in demonstrating that AI accelerator chips can stillfunction correctly despite having few faulty PEs, thusenabling product binning and yield saving. 2) An accuracy-aware fault isolation and test pattern gener- ation methodology is presented to group the MAC faults by their logic cones into categories: a) critical (unac-ceptable) and b) noncritical (acceptable), according totheir impact on the accuracy of AI workload. Responsesfrom these test patterns dictate yield decisions‚Äîwhether to ship to the customer at reduced throughput, or discard as yield loss. Using the reduced test pattern set for crit-ical faults, only the critical faults of the AI a"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_10", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 10, "text": "s dictate yield decisions‚Äîwhether to ship to the customer at reduced throughput, or discard as yield loss. Using the reduced test pattern set for crit-ical faults, only the critical faults of the AI acceleratorcan be tested as a quick method to assess the yield.Next, the chips that passed the Ô¨Årst yield-test can betested for noncritical faults to grade those into differ-ent speed/throughput bins. The accelerators in the topbin (i.e., without any fault) can be sold at a premium price for safety-critical applications, such as self-driving cars, whereas accelerators in the lower bins (with fewfaults, e.g., less than 5% fault rate) can be used inother AI/deep-learning tasks that can tolerate errors withminimal performance loss. 3) A strategy of fault-aware training and selective deac- tivation of faulty PEs during inference is presented to minimize the accuracy loss due to faulty MACs. 4) Simulation results from 50 000 image samples on widely used CNN (AlexNet, ResNet-50, VGG16, LeNet5) [44],and 10 000 data samples on different NN architecturesare presented to demonstrate the relationship betweenfault rate and accuracy. Results show that with 5% faultrate the normalized accuracy of NN "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_11", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 11, "text": "4],and 10 000 data samples on different NN architecturesare presented to demonstrate the relationship betweenfault rate and accuracy. Results show that with 5% faultrate the normalized accuracy of NN and CNN only degrade by less than 1%. The remainder of this article is organized as follows. Related work and AI/deep learning accelerator backgrounds are cov-ered in Section II. The proposed YAOTA methodology, testÔ¨Çow, and hardware control scheme are presented in Section III.Simulation results are presented in Section IV followed byconclusions in Section V. II. B ACKGROUND A. Related Work The error-tolerance nature of AI algorithms has been exploited in hardware to design energy-efÔ¨Åcient AI acceler-ator architectures with approximate MACs [28]‚Äì[31]. In [28]and [29], using benchmark-driven analysis each neuron wasranked according to its sensitivity and error contribution to the output, and neurons that contributed the least to the error were then approximated and the network was retrained to recoveraccuracy loss. In hardware, neurons that were approximatedwere assigned to approximate PEs, while others were assignedto exact PEs [28], [29]. However, the challenges with theseapproximate a"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_12", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 12, "text": "to recoveraccuracy loss. In hardware, neurons that were approximatedwere assigned to approximate PEs, while others were assignedto exact PEs [28], [29]. However, the challenges with theseapproximate approaches are as follows. 1) Sensitivity-based sorting, approximation, and retrain- ing of neurons are always dependent on the workload [29], [31]. 2) Assigning less sensitive neurons to approximate PEs will require runtime hardware reconÔ¨Åguration for differenttasks. 3) In [28]‚Äì[31], pruning was not considered, but in mod- ern NN/CNN pruning is applied as a well-establishedmethod to reduce network size where less impor- tant/sensitive connections are already pruned/removed during training [24]‚Äì[26]. Hence, the techniquesof [28]‚Äì[31] will be much less effective when appliedon an already pruned NN/CNN. 4) Most importantly, since these approximate CNN/NN assume that the only source of error is the determin-istic approximate multiplier and adders, any additional Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 106 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL."}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_13", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 13, "text": " to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 106 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 faults in the PE/MAC from process variation induced defects will cause a signiÔ¨Åcant amount of inaccuracy in the prediction during inference. With the widespread use application AI accelerators, the testing of these hardware has become an emerging researchproblem [32], [33]. In [32], a structural test Ô¨Çow was proposedthat Ô¨Årst identiÔ¨Åed critical faults by comparing the accuraciesof the exact fault-free gate-level circuit of the neural network,and that of a faulty version. Next, the entire circuit was con- verted into an Boolean satisÔ¨Åability (SAT) instance and solved with SAT solver with test patterns for the critical faults only.Since this approach is expensive and not scalable, a functionaltest method was proposed [32], where real workloads‚Äîthe testimages‚Äîare applied as test input to the gate-level netlist ofthe implemented neural network. To Ô¨Ånd if a fault was criticalor ignorable, the fault was Ô¨Årst injected into a neuron module and the test image set was ap"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_14", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 14, "text": "ied as test input to the gate-level netlist ofthe implemented neural network. To Ô¨Ånd if a fault was criticalor ignorable, the fault was Ô¨Årst injected into a neuron module and the test image set was applied. If the prediction accuracy of the test image set was within a certain threshold, the faultwas considered unimportant, otherwise, it was a critical fault.However, the proposed simple approach of creating RTL ofthe full neural network, followed by gate-level synthesis andfault injection is not scalable for mainstream CNNs [44], suchas AlexNet, VGG, ResNet, MobileNet, etc., that are used for real-world computer vision tasks of image recognition with many classes [1], [2], [14]. Zhang et al. [33] Ô¨Årst identiÔ¨Åed the location of faulty MACs (i.e., MAC i,j), in the TPU systolic array and then all weights that were mapped to those faulty MACs were pruned (i.e.,‚àÄw i,j=0, where i,j= location of faulty MAC), followed by retraining. Extra bypass MUX was required for each MAC tobypass it in case it was faulty. However, the major challenges of this approach are as follows. 1) The pruning with retraining technique can preserve the model accuracy when only the small magnitude weightsare pruned "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_15", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 15, "text": " it was faulty. However, the major challenges of this approach are as follows. 1) The pruning with retraining technique can preserve the model accuracy when only the small magnitude weightsare pruned [24]‚Äì[26]. If a large magnitude weight ismapped to a faulty MAC, this method will result inaccuracy degradation. 2) Moreover, in modern AI/deep learning the models are already pruned [24]‚Äì[26] to reduce energy consumption and storage requirements, as a result further prun-ing of weights‚Äîcorresponding to the faulty MACs‚Äîofan already pruned model will signiÔ¨Åcantly reduce itsaccuracy. 3) Another drawback of [33] is that weight pruning and retraining needs to be performed for each TPU chipbased on its unique fault map and each individual workload. In contrast to permanent stuck-at faults, for low-energy operations where voltage is scaled down, possible timing [34]and memory errors [35] can also occur. However, by usingappropriate PV guard band, using circuits with shorter critical-paths and memory ECC these faults can be avoided. B. AI/Deep Learning Accelerator Architecture and Processing Element Faults At the essence of AI/deep learning algorithms are the backpropagation-based NN and CNN."}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_16", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 16, "text": "mory ECC these faults can be avoided. B. AI/Deep Learning Accelerator Architecture and Processing Element Faults At the essence of AI/deep learning algorithms are the backpropagation-based NN and CNN. As shown in Fig. 1(a),a deep NN consists of an input layer, followed by several hid-den layers and a Ô¨Ånal output layer. Depending on the datasize, the complexity of training, dropout, and pruning rate,some layers in the NN are fully connected and others sparsely (a) (b) (c) Fig. 1. (a) Deep NN. (b) Deep CNN. (c) Convolution in CNN [1], [44]. connected [24]‚Äì[27]. The connection strengths between the adjacent layers are represented by a weight matrix W, and the matrix parameters wiare learned by the backpropagation equa- tion,/Delta1wi=‚àí a‚àó[(‚àÇError)/(‚àÇwi)], where ais learning rate andError is the prediction error. During the forward pass of training and inference phases, the output activation of a layer, Xo, is obtained by multiplying the input activation vector with the weight matrix followed by addition of a bias term, andÔ¨Ånally passing the result through an nonlinear function, suchas ReLU, X o=ReLu(Xi‚àóW+b). It is evident from this equation that the dominant operation in NN is MAC in "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_17", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 17, "text": "wed by addition of a bias term, andÔ¨Ånally passing the result through an nonlinear function, suchas ReLU, X o=ReLu(Xi‚àóW+b). It is evident from this equation that the dominant operation in NN is MAC in matrixmultiplications and bias term additions, of which multiplica- tion is the most hardware intensive. For a fully connected NN with input layer of size N input,Khhidden layers each of size Nhidden , and output layer of size Noutput , the total number of required multiplications to classify a single sample is, (Ninput‚àó Nhidden)+(Nhidden‚àóNhidden)‚àó(Kh‚àí1)+(Nhidden‚àóNoutput). Due to their robustness and accuracy, deep CNNs have become the standard for image and pattern recognition [1], [44]. The operation of a deep CNN is brieÔ¨Çy shown in Fig. 1(b). During training and inference,each image or pattern is convolved successively with a setof Ô¨Ålters where each Ô¨Ålter has a set of kernels. After ReLUactivation and pooling, the convolution operation is repeatedwith a new set of Ô¨Ålters. Finally, before the output stage,fully connected NNs are used. The convolution operation isshown in Fig. 1(c) and it consists of dot products between the input feature-maps and Ô¨Ålter weights, mathematically, f out("}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_18", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 18, "text": "e the output stage,fully connected NNs are used. The convolution operation isshown in Fig. 1(c) and it consists of dot products between the input feature-maps and Ô¨Ålter weights, mathematically, f out(m,n)=/summationtext j/summationtext kh(j,k)fin(m‚àíj,n‚àík). For a single convolution layer, the total number of multiplications is givenby,N in_channel ‚àóDk‚àóDk‚àóDf‚àóDf‚àóNout_channel , where Dk is kernel dimension, Dfis output feature map dimension, Nin_channel is number of input channels, and number of output channels is Nout_channel . For deep CNNs, the total number required multiplications to classify each input image/pattern is a substantial number, and MAC operations account for90% or more of the total computational cost [1]‚Äì[4]. Since the computations in NN/CNN are mostly dominated by MAC operations, the AI accelerators are primarily occu-pied with arrays of PE optimized for fast MAC function [1].Depending on if the accelerators are for training and inference Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 107 (a"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_19", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 19, "text": "to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 107 (a) (b) Fig. 2. AI accelerator with PE/MAC arrays. (a) Systolic architecture. (b) SIMD architecture. or only for inference on edge devices, the MAC units can be of 32 bit supporting FP32 or 8 bit for int8 [39] quantized opera- tions [1], [38]. As shown in Fig. 2, the accelerator architectures can be categorized into two domains: 1) tightly coupled 2-Dsystolic-arrays (e.g., Google‚Äôs TPU) [4], [9] and 2) looselycoupled spatial arrays with independent PEs interconnectedwith NoC/mesh and using SIMD architecture [2], [37]. Whilespatial SIMD designs offer higher Ô¨Çexibility by allowing inde-pendent control and deactivation of PEs as needed, systolicarrays must work in lock step and need more sophisticated techniques to deactivate individual PEs [33], [36]. To optimize silicon utilization, the large number of PE/MACs are densely placed on the chip die [1]‚Äì[4]. As aresult, the yield of the accelerator will be primarily dictatedby circuit faults in MAC modules of the PEs. Categorizationof the loca"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_20", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 20, "text": " number of PE/MACs are densely placed on the chip die [1]‚Äì[4]. As aresult, the yield of the accelerator will be primarily dictatedby circuit faults in MAC modules of the PEs. Categorizationof the location and rate of the faults as critical or noncriticalwith respect to the desired accuracy of the AI task, and cor- responding fault-criticality-aware test pattern generation can save costs associated with Ô¨Ånal yield evaluation. Also, this willallow more chips to pass the functional test (within an accu-racy bound of the AI task) resulting in improved yield (i.e.,more accelerator passing the quality test at different specs orproduct bins). III. YAOTA: Y IELD AND ACCURACY AWARE OPTIMUM TEST FOR AI A CCELERATORS The semiconductor manufacturing defects and correspond- ing circuit faults in the AI accelerator need a deeper investiga-tion with regards to its impact on the accuracy of AI and deeplearning workloads. The key modules of accelerators that aresusceptible to defects are the weight storage SRAM/registerÔ¨Åles (RF) and the MACs. For SRAM/RF, the faults are gen- erally repaired with ECC and spare cells. The timing-faults in MAC can be solved by appropriate timing guard band andruntime "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_21", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 21, "text": "rage SRAM/registerÔ¨Åles (RF) and the MACs. For SRAM/RF, the faults are gen- erally repaired with ECC and spare cells. The timing-faults in MAC can be solved by appropriate timing guard band andruntime frequency adjustment. The stuck-at faults in the MACare permanent and severe, and thus in this work, we focus onstuck-at faults. Any stuck-at faults on the bÔ¨Çoat16/Ô¨Çoat32 for-mat [41] or 8 bit (for int8 quantization [39]) multipliers andadders will cause a certain precision loss and inaccuracy at the output of MAC. The important question is, ‚Äúin an AI acceler- ator with thousands of PEs with MAC units, will the presenceof a few faulty MACs cause the whole accelerator chip to bediscarded, resulting in the loss of yield and revenue?‚Äù A sci-entiÔ¨Åcally pragmatic solution would be to assess the impact ofMAC circuit faults on the training and inference accuracy ofAI workloads executed on these accelerators. The key factors Fig. 3. SimpliÔ¨Åed block diagram of MAC unit with logic cones. to consider in this assessment are: 1) location of the faultsinside the PE and its impact on the precision of MAC out-put; 2) the fraction of the total PEs that have faulty MACs;3) the type of AI workload; and 4"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_22", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 22, "text": " in this assessment are: 1) location of the faultsinside the PE and its impact on the precision of MAC out-put; 2) the fraction of the total PEs that have faulty MACs;3) the type of AI workload; and 4) if the accelerator is forboth training and inference, or inference-only. A. Fault Location, MAC Precision and AI Accuracy Systematic defects and yield losses are caused by layout- sensitive lithographic hotspots and other process imperfec- tions, variations, and are generally independent of the layoutarea [17]. On the other hand, random defect generated yieldlosses are caused by defect particles and are dependent on thestandard-cell or the layout area as well as the defect particlesize [16], [18]. These defects (e.g., short/open defect, poorcontact/via, etc.) and corresponding circuit faults can occur at different sites inside the MAC circuit block. The precision loss‚Äîdue to the presence of circuit faults‚Äîat the output ofMAC operation will depend on the location of the fault insideMAC circuit and the logic cone impacted by the fault. Forexample, if a multiplier circuit that performs the multiplica-tion of two 8-bit numbers, has faults impacting upto KLSB bits, then it will sustain wo"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_23", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 23, "text": "rcuit and the logic cone impacted by the fault. Forexample, if a multiplier circuit that performs the multiplica-tion of two 8-bit numbers, has faults impacting upto KLSB bits, then it will sustain worst case error of ¬±/summationtext K+1 i=02i(the last 2K+1term comes from worst case carry-in path of par- tial product addition, as explained in the next section). As K increases, the faults impact the more signiÔ¨Åcant digits causingthe worst case error of the multiplier to increase. Similarly, errors will also occur in the adder circuit of the MAC if it is corrupted by faults. Since the multiplier is the more dom-inant block in a MAC, it will be more prone to faults andcomputation errors. As explained in Section II-B, the computations in NNs and CNNs for an AI workload execution are heavily dominatedby the MAC operations. Any inaccuracy in MAC output willimpact the accuracy and efÔ¨Åcacy of the AI task running on the accelerator. From the matrix multiplications in NN and convolution operations in CNN, it can be inferred that despitea certain amount of error in a few MAC modules, the AItasks can be accomplished with minimum accuracy loss. Therelationship between worst case error per fault"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_24", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 24, "text": "ns in CNN, it can be inferred that despitea certain amount of error in a few MAC modules, the AItasks can be accomplished with minimum accuracy loss. Therelationship between worst case error per faulty MAC, percent-age of MACs that are faulty and the AI workload‚Äôs accuracyloss due to these errors are correlated, and will depend on the speciÔ¨Åcs of the NN/CNN architecture and the workload as will be demonstrated in Section IV . B. Yield and Accuracy Aware Fault Isolation and Test Pattern Generation The precision loss and the extent of computational error in a MAC will depend on the output bit positions that were cor-rupted by the circuit faults (e.g., stuck-at and delay). In thisarticle, we focus on stuck-at faults as they are more destructivecompared to delay faults. By analyzing the fan-in logic cone ofan output bit, we can isolate the circuit paths and standard-cell Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 108 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 Algorithm 1 Isolate Critical and Noncritical Faults, and Generat"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_25", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 25, "text": "re. Restrictions apply. 108 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 Algorithm 1 Isolate Critical and Noncritical Faults, and Generate Test Patterns Accordingly for Multiplier and Adder 1:procedure GENERATE TEST PATTERNS FOR CRITICAL AND NON -CRITICAL FAULTS 2:Input: Gate-level netlist of the MAC module 3:Input: Maximum LSB bit position of MAC output that can tolerate errors, K 4:Output: List of critical faults, Fcrit 5:Output: List of non-critical faults, Fnon‚àícrit 6:Output: ATPG test patterns for critical faults, Tcrit 7:Output: ATPG test patterns for non-critical faults, Tnon‚àícrit 8: Initialization: , G1={ } 9: Initialization: , G2={ } 10: fori=0to max. LSB position Kdo 11: gi‚Üêall gates in the fan-in logic cone of output LSB of position i 12: G1‚ÜêG1‚à™gi 13: end for 14: fori=K+1to MSB position Ndo 15: hi‚Üêall gates in the fan-in logic cone of output bit of position i 16: G2‚ÜêG2‚à™hi 17: end for 18: Gnon‚àícrit=G1‚àíG2 19: Gcarryin _bitK+1‚Üêall gates in the logic cone of carry_in pin of output bit K+1 20: Gcrit=G2‚àíGcarryin _bitK+121: Fcrit‚Üêlist of all faults (e.g., stuck-at) for gates in Gcrit 22: Fnon‚àícrit‚Üêlist of all faults"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_26", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 26, "text": "yin _bitK+1‚Üêall gates in the logic cone of carry_in pin of output bit K+1 20: Gcrit=G2‚àíGcarryin _bitK+121: Fcrit‚Üêlist of all faults (e.g., stuck-at) for gates in Gcrit 22: Fnon‚àícrit‚Üêlist of all faults (e.g., stuck-at) for gates in Gnon‚àícrit 23: Tcrit‚ÜêATPG tool generated test patterns for faults in list Fcrit 24: Tnon‚àícrit‚ÜêATPG tool generated test patterns for faults in list Fnon‚àícrit 25: end procedure logic gates that can contribute to a stuck-at fault at that output bit. This can be explained with the multiplier and adder circuitof Fig. 3, and Algorithm 1. In Fig. 3 the green (shaded) logiccone consists of all the logic gates that are exclusively located (i.e., not overlapped with the fan-in cone of the rest of the bits) in the fan-in cone of the Ô¨Årst Kleast signiÔ¨Åcant bits (LSB) of the output . The red cone contains the standard-cells that arepresent in the fan-in logic cone of output bits at positions K+1 to the MSB bit N, where N>K. From an extensive execution of AI benchmarks, we identify the acceptable error range ofa faulty MAC and the fault rate that will not cause the AItask‚Äôs accuracy loss to exceed a threshold. We deÔ¨Åne output bit up to KLSBs to be noncritical from this "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_27", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 27, "text": "identify the acceptable error range ofa faulty MAC and the fault rate that will not cause the AItask‚Äôs accuracy loss to exceed a threshold. We deÔ¨Åne output bit up to KLSBs to be noncritical from this workload-driven analysis. If circuit faults located within the logic cone of theÔ¨ÅrstKoutput bits are noncritical then the resulting worst case e r r o ro ft h eM A Ci s ¬±/summationtext K+1 i=02i, because each bit position i‚Äî depending on whether stuck-at-1 or stuck-at-0‚Äîwill introduce error¬±2i, and an additional worst case error of ¬±2K+1may occur because of possibly wrong carry propagation to the crit-ical output bit position K+1 from noncritical bit K. The Ô¨Çow to isolate the critical and noncritical faults of a MAC for AItasks, and corresponding ATPG pattern generation is presentedin Algorithm 1. The inputs to the algorithm are the gate-levelnetlist of the MAC and the bit position Kup to which the error is acceptable. The outputs of Algorithm 1 in lines 4‚Äì7, are the lists of critical ( F crit) and noncritical ( Fnon‚àícrit) faults, and the ATPG patterns ( Tcrit,Tnon‚àícrit) that can detect these faults. In lines 10‚Äì13, for each bit position from 0 to K,t h e standard-cell logic gates in t"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_28", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 28, "text": "crit) and noncritical ( Fnon‚àícrit) faults, and the ATPG patterns ( Tcrit,Tnon‚àícrit) that can detect these faults. In lines 10‚Äì13, for each bit position from 0 to K,t h e standard-cell logic gates in the logic cone of that bit are iden-tiÔ¨Åed and added to the list G 1. Similarly, in lines 14‚Äì17 the logic gates in the fan-in cone of the rest of the bits, K+1t o N(MSB), are obtained in the list G2. In line 18, the list G2 is subtracted from G1to obtain the list of noncritical gate list Gnon‚àícrit, thus removing any overlap with rest of the critical group. In lines 18 and 19, the gates in the carry-in path of bitK+1 are identiÔ¨Åed and subtracted from G 2to obtain the list of error critical gates Gcrit. Finally, in lines 21‚Äì24, the fault lists for these gates‚Äî FcritandFnon‚àícrit‚Äî a r ef e dt ot h eA T P G (a) (b) Fig. 4. Int8 [39] multiplication and addition. (a) 8-bit Baugh-Wooly signed multiplier (logic cones of two LSBs are shown). (b) First four bits of the16-bit CLA adder (logic cones of two LSBs are shown.) (a) (b) Fig. 5. Logic cones of critical and noncritical bits are shown forbÔ¨Çoat16/Ô¨Çoat32. (a) Floating point multiplication. (b) Floating point addition. tool to obtain the test pa"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_29", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 29, "text": "wo LSBs are shown.) (a) (b) Fig. 5. Logic cones of critical and noncritical bits are shown forbÔ¨Çoat16/Ô¨Çoat32. (a) Floating point multiplication. (b) Floating point addition. tool to obtain the test pattern sets TcritandTnon‚àícritto test the AI-accuracy critical and noncritical faults, respectively. In this logic cone analysis, we assume ripple-carry adders are not used in the MAC module as the width of theadder/multiplier required for the AI tasks are at least 8 bits,and ripple-carry structures in these cases will cause long crit-ical paths and hence slower speeds. Our analysis assumes theuse of faster carry-lookahead or tree adders (the standard type used in 8 bit or wider cases) in the MAC. Note that, in the unusual event that a slower ripple-carry structure is used, thelogic cone of LSB bits will completely overlap with the rest ofthe bits. However, still in this scenario, our above method ofnoncritical gate identiÔ¨Åcation will hold if we break the ripplecarry path after KLSB bits, and it will incur max error of ¬±/summationtext K+1 i=02ias discussed above. The standard data type used in the AI domain to represent the NN connections, CNN Ô¨Ålter weights, and activation outputsare the"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_30", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 30, "text": "d it will incur max error of ¬±/summationtext K+1 i=02ias discussed above. The standard data type used in the AI domain to represent the NN connections, CNN Ô¨Ålter weights, and activation outputsare the 8 bit int8 quantized format or bÔ¨Çoat16/Ô¨Çoat32 for-mat [1], [4], [38], [41]. BÔ¨Çoat16/Ô¨Çoat32 can be used for bothtraining and inference, but for inference-only devices (e.g., mobile and other edge devices) the training is generally done in BÔ¨Çoat16/Ô¨Çoat32 [40], [41] and then the learned parametersare quantized to int8 and loaded in these devices [3], [38].The Baugh-Wooly multiplier [45]‚Äîwidely used for multi-plying two 8-bit signed numbers‚Äîis shown in Fig. 4(a). Ifacceptable faults can only affect the two LSBs (i.e., K=1 in Algorithm 1), all circuits in logic-cones of outputs P 0 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 109 andP1‚Äîhighlighted with red dots in Fig. 4(a)‚Äîare consid- ered noncritical, and the rest of the circuits are fault-critical. Similarly, in Fig. 4(b) for the 16-bit carry look-ahead adder"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_31", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 31, "text": "CELERATORS 109 andP1‚Äîhighlighted with red dots in Fig. 4(a)‚Äîare consid- ered noncritical, and the rest of the circuits are fault-critical. Similarly, in Fig. 4(b) for the 16-bit carry look-ahead adder(CLA) of the MAC, the logic cones containing the noncrit-ical circuits and faults are shown for K=1. For wide-bit addition (i.e., 16-bit), CLA or tree adder are used insteadof the slower ripple carry structure [45]. For AI acceleratorsusing bÔ¨Çoat16/Ô¨Çoat32 format multiplier and adder [40], [41],as shown in Fig. 5, circuit faults in logic cones of some of the lower order (i.e., LSBs) bits of mantissa can be considered as noncritical, and the circuit faults present in the logic conesof the rest of the bits of mantissa, the exponent and sign bitsare considered critical as they can introduce large errors in theresult. The number of bits in mantissa that can be considerednoncritical will depend on the amount of error introduced bystuck-at faults on those bits and the impact of this error in AI task‚Äôs accuracy loss. Next, we propose the test Ô¨Çow to identify faulty PEs, and the use of a low area-overhead register memory to store the IDsof the faulty PEs. A control scheme is presented to deacti"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_32", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 32, "text": "ask‚Äôs accuracy loss. Next, we propose the test Ô¨Çow to identify faulty PEs, and the use of a low area-overhead register memory to store the IDsof the faulty PEs. A control scheme is presented to deactivatesome of the faulty PEs during inference and test, if required. C. Post-Fab Test of the AI Accelerator After manufacturing, the accelerator chip is subjected to structural and functional tests to identify if the PEs are func- tionally correct. Because of defects from imperfections in the semiconductor manufacturing process, some of the PEswill have faulty MACs. First, the test patterns T critobtained using Algorithm 1, are applied in a broadcast mode to all thePE/MACs to identify which units will introduce large errorsduring matrix multiplications or dot products in convolutions.The IDs of these faulty PEs are recorded in the list Fail_ID crit. Next, the test patterns Tnon‚àícritare applied parallelly to all the PEs that passed the Ô¨Årst test. The IDs of the PEs that failedthis second test are recorded in the list Fail_ID non‚àícrit. Since the PEs that belong to Fail_IDcrithave large MAC errors, they can be permanently disabled by the manufacturer (sim-ilar to the practice of disabling f"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_33", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 33, "text": " are recorded in the list Fail_ID non‚àícrit. Since the PEs that belong to Fail_IDcrithave large MAC errors, they can be permanently disabled by the manufacturer (sim-ilar to the practice of disabling faulty cores in many-coreprocessors [43]), or their Fail_ID critdata can be written to an on-chip nonvolatile memory‚Äîfault status register (FSR) shown in Fig. 6‚Äîfor the customer to decide if they want to usethose PEs or not. The PEs belonging to Fail_ID non‚àícrithave relatively small MAC errors and can be acceptable dependingon: 1) how many such errors exist (i.e., number of elementsinFail_ID non‚àícrit) and 2) the type of AI workload that will be executed by the customer and their accuracy tolerance lim-its. Hence, the Fail_ID non‚àícritcontents are written into the on-chip FSR for the customer to disable a fraction of these faulty PEs with software at runtime and still accomplish theAI tasks with minimal accuracy loss. The deactivation protocoland the complete map of faulty PE locations are programmedin Ô¨Årmware/software by the manufacturer. With the user-giveninput of acceptable fault rate (in noncritical LSBs, analyzed inSection IV) and the stored PE fault map, the protocol will auto- mat"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_34", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 34, "text": "ogrammedin Ô¨Årmware/software by the manufacturer. With the user-giveninput of acceptable fault rate (in noncritical LSBs, analyzed inSection IV) and the stored PE fault map, the protocol will auto- matically disable a few faulty PEs to ensure that the overall faulty PE rate of the accelerator does not exceed a threshold.When deactivating some faulty PEs, the Ô¨Årmware/software willensure that the remaining faulty PEs are not clustered. WedeÔ¨Åne the deactivation protocol such that after deactivation,the remaining faulty PEs (with noncritical faults) are uniformlydistributed (i.e., not clustered) across the columns. As shown Fig. 6. Proposed failure status register (FSR) and controls to deactivate and bypass faulty PEs in the accelerator as needed. Fig. 7. Accelerator used for inference on edge/mobile devices with cloud- trained parameters. in Fig. 6, control signals are transmitted from the FSR to all the PEs to selectively disable the faulty PEs when needed. Byadopting this scheme, the manufacturer can avoid discarding the full accelerator chip/die only because of the presence of few PEs with faulty MACs, and thereby increase yield. Theoverhead in this yield loss reduction are the extr"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_35", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 35, "text": "ufacturer can avoid discarding the full accelerator chip/die only because of the presence of few PEs with faulty MACs, and thereby increase yield. Theoverhead in this yield loss reduction are the extra on-chip reg-ister (FSR) to store the IDs and the control signal routes todisable faulty PEs. 1) Accelerator Used for Inference Only: For large datasets, the training of deep NN/CNN is computationally intensive andvery time consuming, and generally requires many accelera-tors or CPU/GPUs working in parallel. For example, trainingthe popular CNN model of AlexNet on imageNet [14] datasetrequired six days with two GPUs [11]. Since mobile and other edge devices cannot sustain this computational overhead, the general trend for these devices is to use a pretrained modelduring inference. In this mode, using many CPU/GPUs anddedicated accelerators the AI model is trained on the cloud,and after training the model parameters and weights are loadedin the edge device where a local AI accelerator is used to per-form the MAC operations required for inference [1], [38]. Ourproposed ‚Äúfault-aware cloud-trained edge-inferred‚Äù inference Ô¨Çow is shown in Fig. 7. In this approach, after the model has been "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_36", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 36, "text": "sed to per-form the MAC operations required for inference [1], [38]. Ourproposed ‚Äúfault-aware cloud-trained edge-inferred‚Äù inference Ô¨Çow is shown in Fig. 7. In this approach, after the model has been completely trained in the cloud with high-performancecomputing, an additional analysis is performed to obtain theimpact of MAC errors on inference accuracy. This can beachieved by injecting on the post-trained model in the cloudthe same MAC errors that would occur in the inference accel-erator of the edge device, and obtaining the corresponding accuracy changes as a look-up table of fault rate versus accu- racy changes. In summary, the proposed Ô¨Çow will not onlygenerate the trained parameters of the AI model‚Äîsimilar tothe regular cloud-training and edge-inference paradigm [1]‚Äîbut also report the maximum allowed fault rate FR max_ non‚àícrit to be subsequently loaded into the accelerator hardware of the edge device as a bitstream. During inference, the mobile/edge Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 110 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, V"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_37", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 37, "text": "ted to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 110 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 accelerator‚Äôs FSR and control unit reads the FRmax_ non‚àícrit and if it is lower than the current fault rate FRnon‚àícrit, then the control unit sends deactivation signals to disable some ofthe PEs such that the fault rate is reduced to FR max_ non‚àícritas shown in Fig. 7. 2) Accelerator Used in Training and Inference: For cases where the accelerator will be used for both training and infer-ence, further improvement in accuracy degradation caused byMAC errors can be accomplished with fault-aware training. Retraining is a popular tool in deep learning, and primarily used to reduce the size of the NN/CNN by pruning [24]‚Äì[26].In retraining, the forward pass and backward passes are madeaware of the changes in the network, and this directs StochasticGradient Descent-based backpropagation Ô¨Çow to evolve theweights of the NN/CNN accordingly to minimize any accu-racy loss stemming from these changes [25], [28], [29]. The proposed methodology is shown in Fig. 8 and explai"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_38", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 38, "text": "d backpropagation Ô¨Çow to evolve theweights of the NN/CNN accordingly to minimize any accu-racy loss stemming from these changes [25], [28], [29]. The proposed methodology is shown in Fig. 8 and explained in Algorithm 2. The presence of possible errors in MAC calcu-lations during inference is modeled mathematically and fed tothe backpropagation weight-update Ô¨Çows similar to [28]‚Äì[31].During the training phase, Ô¨Årst, the control unit reads the FSRto obtain the IDs of faulty PEs. To ensure that the CNN/NNwill be trained to achieve the best accuracy, all faulty PEs(both critical and noncritical) are disabled during the train- ing phase as shown in Fig. 8 and line 9 in Algorithm 2. In Algorithm 2 the fault-aware AI training and inference Ô¨Çow isshown for the accelerator. The minimum acceptable inferenceaccuracy ( Acc_Inf_threshold ), the training data set, accelera- tor‚Äôs noncritical fault rate ( FR non‚àícrit), IDs of all faulty PEs and a fault adjustment step size ( Œ¥step) are provided as inputs to the algorithm in lines 2‚Äì6. The algorithm reports the maximum allowed faulty (noncriticalin LSBs) PE rate (i.e., the fraction of the total PEs in the accelerator that have noncritical faults),"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_39", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 39, "text": "puts to the algorithm in lines 2‚Äì6. The algorithm reports the maximum allowed faulty (noncriticalin LSBs) PE rate (i.e., the fraction of the total PEs in the accelerator that have noncritical faults),FR max_ non‚àícritthat will allow the achievement of desired infer- ence accuracy Acc_Inf_threshold . In lines 11‚Äì16, after each iteration of fault-aware training‚Äîwith fault effect modeledin the backpropagation‚Äîthe obtained accuracy is comparedwith the desired inference accuracy Acc_Inf_threshold .I ft h e accuracy goal is not met, the fault rate FR max_ non‚àícritis reduced by a small step Œ¥step, until the desired accuracy goal is met. After the training converges and the inference accu-racy target is reached, the trained weights of the NN/CNN areobtained. Additionally, the maximum allowed faulty PE rate,FR max_ non‚àícrit, is reported. During inference, the control unit and FSR will read this FRmax_ non‚àícritand disable some faulty PE to achieve this FRmax_ non‚àícritrate. The beneÔ¨Åts from this combined training-inference method- ology are as follows. 1) In achieving the same inference accuracy, the fault-aware training approach will allow the accelerator to endure ahigher FR max_ non‚àícritcom"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_40", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 40, "text": "ombined training-inference method- ology are as follows. 1) In achieving the same inference accuracy, the fault-aware training approach will allow the accelerator to endure ahigher FR max_ non‚àícritcompared to the scenario where no fault-aware training is used. This will allow the availabil-ity of more PEs during inference if fault-aware training was used. 2) Although there will be additional time required for this training step, this extra cost will be amortized on themultiple inference runs. Because, the general trend inAI is to train the NN/CNN once accurately, and thenthis pretrained model is used many times during infer-ence. As a result, the extra PEs‚Äîmade available by the Fig. 8. Accelerator used in both training and inference. Algorithm 2 Fault-Aware Training and Inference on AI Accelerator 1:procedure IDENTIFY THE MAXIMUM ACCEPTABLE FAULT RATE OF PE IN THE ACCELERATOR FOR A GIVEN ACCURACY TARGET 2:Input: Minimum acceptable accuracy for inference, Acc_Inf_threshold 3:Input: Training dataset for the deep CNN/NN 4:Input: Fault rate (i.e., rate of non-critical faulty PEs ) of the accelarator, FRnon‚àícrit 5:Input: IDs of all faulty PEs in the accelerator, F_ID={Fail_IDnon‚àícrit,Fa"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_41", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 41, "text": "ning dataset for the deep CNN/NN 4:Input: Fault rate (i.e., rate of non-critical faulty PEs ) of the accelarator, FRnon‚àícrit 5:Input: IDs of all faulty PEs in the accelerator, F_ID={Fail_IDnon‚àícrit,Fail_IDcrit} 6:Input: Fault rate adjustment step size, Œ¥step 7:Output: Maximum allowed fault rate in the AI accelerator for inference at desired accuracy, FRmax_ non‚àícrit 8: Initialization: Training accuracy, Acc_Train=0 9: Initialization: Deactivate all faulty PEs in F_IDduring training mode 10: Initialization: FRmax_ non‚àícrit=FRnon‚àícrit 11: while (Acc_Train<Acc_Inf_threshold )do 12: Acc_Train ‚Üêtraining accuracy for the given dataset with FRmax_ non‚àícrit modeled in the backpropagation 13: if(Acc_Train<Acc_Inf_threshold )then 14: FRmax_ non‚àícrit=FRmax_ non‚àícrit‚àíŒ¥step 15: end if 16: end while 17: end procedure fault-aware training‚Äîpresent during each inference will signiÔ¨Åcantly speed up the inference tasks. D. Deactivation and Bypass of Faulty PE The FSR holds the IDs of faulty PEs. On demand deacti- vation and bypass of these PEs require different strategies for SIMD and Systolic architectures. 1) SIMD Architectures: In SIMD architecture the loosely coupled independent PEs are connected "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_42", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 42, "text": " deacti- vation and bypass of these PEs require different strategies for SIMD and Systolic architectures. 1) SIMD Architectures: In SIMD architecture the loosely coupled independent PEs are connected with NoC or meshand can be individually switched off and bypassed withwires [1], [37]. Using the results from the FSR, all PEs withcritical faults and few PEs with noncritical faults are deacti-vated. If after deactivation, N_remaining _PEPEs remain out ofN_total_PE, then throughput of the accelerator will be scaled by the factor (N_remaining _PE/N_total_PE). 2) Systolic Architectures: The tightly coupled 2-D systolic- arrays in TPU introduce challenges in deactivating and bypass-ing individual PEs. A common technique is to use spare PEblocks to substitute for faulty PEs [36]. However, this approachrequires complex wiring between spare and faulty PEs. In thiswork, we propose an innovative software-level technique todeactivate and bypass faulty PEs in systolic array without any hardware-level modiÔ¨Åcations. Unlike [33], as discussed in details in Section II-A, this approach does not require theNN/CNN weights that are mapped on the faulty PEs to bepruned (i.e., set to zero). The fault-fre"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_43", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 43, "text": "el modiÔ¨Åcations. Unlike [33], as discussed in details in Section II-A, this approach does not require theNN/CNN weights that are mapped on the faulty PEs to bepruned (i.e., set to zero). The fault-free scenario is shown inFig. 9(a), where the weights are preloaded in the PEs of thesystolic array in regular manner. In Fig. 9(b), the PE in row 2,column 4 of the systolic array has a critical fault or noncritical Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 111 (a) (b) Fig. 9. Software-level bypass method for faulty PE in systolic array. (a) Normal mode without fault. (b) Faulty PE bypassed by shifting input data. fault exceeding acceptable fault rate (marked with a red cross) and needs to be bypassed. In software, this is accomplishedby shifting the column of the weight matrix to the right byinserting a dummy row of zeros. The activation matrix, X, is also shifted accordingly as shown in Fig. 9(b). Moreover,this software-level approach does not require complex wiringresources as needed in hardware-level spa"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_44", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 44, "text": "ow of zeros. The activation matrix, X, is also shifted accordingly as shown in Fig. 9(b). Moreover,this software-level approach does not require complex wiringresources as needed in hardware-level spare replacement tech- niques [36]. However, the execution throughput will decrease as some faulty PEs are deactivated. For the largest weightmatrix in CNN/NN multiple iteration steps ( N_steps )a r e required in the accelerator array to complete the MAC oper-ations. For example, in AlexNet largest weight matrix is ofsize 4096 by 9216, and this will require multiple iterationsto complete in a systolic array with 256 by 256 PEs (e.g., Google TPU [4]). If the row/column size of systolic array is N_dim_sys_arrand the number of columns in accelerator PE array that has atleast one PE requiring fault-induced deactiva-tion is N_sys_arr_faulty _cols, then software-level deactivation will require extra (N_dim_sys_arr‚àóN_sys_arr_faulty _cols)‚àó N_steps MACs. IV . R ESULTS AND ANALYSIS To identify the impact of the number of LSBs having faults in their logic cones, we varied the number of LSBs from 2 to 4 for int8 [39] and 3 to 5 for bÔ¨Çoat16 [40], [41] data for-mats for the CNN model AlexNet with the"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_45", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 45, "text": "pact of the number of LSBs having faults in their logic cones, we varied the number of LSBs from 2 to 4 for int8 [39] and 3 to 5 for bÔ¨Çoat16 [40], [41] data for-mats for the CNN model AlexNet with the ImageNet test set.These experiments were done with PyTorch [49]. The resultsare shown in Fig. 10, where x-axis is fault rate in noncritical logic cones (the LSBs). From this analysis, we conservativelyselected 2 LSBs for int8 and 4 mantissa LSBs for the recent bÔ¨Çoat16 hardware models. In our experiments the accelera- tor hardware comprised of 128 by 128 array of PE/MACs asshown in Fig. 11. The faulty PEs are modeled as uniformlydistributed across the accelerator columns with fault probabil-ity of FR%, the fault rate. This implies that for FR% fault rate, each column of the accelerator has 0 .01‚àóFR‚àóN Rowfaulty PEs randomly distributed across that column. The reported results (a) (b) (c) (d) Fig. 10. Impact of faults in logic cones of LSB positions on inference accuracy for AlexNet with ImageNet data set. (a) and (b) Int8 data format and MAC type. (c) and (d) BÔ¨Çoat16 data format and MAC type. (a) (b) Fig. 11. Accelerator with 128x128 MAC/PEs. Faulty MAC/PEs are randomlydistributed acros"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_46", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 46, "text": "geNet data set. (a) and (b) Int8 data format and MAC type. (c) and (d) BÔ¨Çoat16 data format and MAC type. (a) (b) Fig. 11. Accelerator with 128x128 MAC/PEs. Faulty MAC/PEs are randomlydistributed across the columns. (a) Systolic. (b) SIMD architecture. here are the average of 10 independent fault injection experi- ments done in MATLAB [48] (for NN) and PyTorch [49] (for CNN) according to this hardware and fault distribution model.The prediction accuracy data reported in subsequent experi-ments are independent of the SIMD/Systolic architecture ofthe accelerator. However, the throughput will vary based onarchitecture type and fault rate as discussed in Section III-D.In identifying the critical and noncritical circuit faults in the MAC of a PE and corresponding test pattern generation, we used the RTL of the MAC unit present in each PE and analyzedboth int8 and recent bÔ¨Çoat16 format implementations. For int8 quantized data format, Ô¨Årst, the RTL of signed 8-bit MAC unit was developed, followed by gate-level syn-thesis with SAED [46] 28-nm standard cell library withSynopsys design compiler (DC) [46]. During synthesis, DCtool implemented the signed multiplier using the Baugh-Wooly archite"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_47", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 47, "text": "wed by gate-level syn-thesis with SAED [46] 28-nm standard cell library withSynopsys design compiler (DC) [46]. During synthesis, DCtool implemented the signed multiplier using the Baugh-Wooly architecture available in DesignWare [46] IP library. The 16-bit adder unit was implemented using the Carry Look Ahead(CLA) structure from the DesignWare IP library. After thecomplete gate-level netlist of the MAC was available, a cus-tom TCL script was developed for the logic cone analysis ofthe output bits. From analysis of Fig. 10, we selected the Ô¨Årsttwo bits of the LSB (i.e., bit 0 and bit 1) as noncritical and bit positions 2‚Äì7 as critical, implying that the worst case total MAC error resulting from these two bits is ¬±(2 0+21+22)a s explained in Section III-B. Next, using the developed TCLscript with DC we obtained critical ( G crit) and noncritical (Gnon‚àícrit) standard cell logic gates present in the logic cones of critical and noncritical bits, respectively, as described inAlgorithm 1 in Section III-B. Next, the gate-level netlist and Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 112 IEEE"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_48", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 48, "text": "Section III-B. Next, the gate-level netlist and Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 112 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 TABLE I FAULT STATISTICS FOR SIGNED INT8M ULTIPLIER AND ADDER TABLE II FAULT STATS FOR MAC W ITHBFLOAT 16 M ULTIPLIER AND FP32 A DDER (a) (b) Fig. 12. Inference accuracy changes with fault (noncritical) rates for NN running MNIST. (a) Without pruning. (b) With 30% pruning and retraining the critical and noncritical fault lists were taken to TestMAX ATPG tool [46] and three sets of ATPG test patterns weregenerated ‚Äì 1) with all faults; 2) only with the critical faults;and 3) considering only the noncritical faults. The results areshown in Table I. The reason that the number of test patternsfor the all-faults case is lower than the sum of critical-only and noncritical-only cases is due to the method of ATPG pat- tern generation, where a single pattern can sometimes detectfaults from both critical and noncritical groups. However, thetest pattern counts to test the critical-only faults i"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_49", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 49, "text": "the method of ATPG pat- tern generation, where a single pattern can sometimes detectfaults from both critical and noncritical groups. However, thetest pattern counts to test the critical-only faults is less thanthe all-faults case in Table I. This critical pattern set can beapplied Ô¨Årst to all the PEs in a broadcast manner to identifyif there are any PEs that must be disabled, this is because,having a critical fault in MAC introduces a large magnitude of error. Next, for the PEs that passed the Ô¨Årst test, we apply the test patterns from Row 4 of Table I to test the presenceof any noncritical faults. If faults are detected by this patternset, the IDs of the faulty PEs are recorded in FSR memory asexplained in Section III-C. As discussed in [40] and [41], recently, for training NN/CNN bÔ¨Çoat16 method is used where multiplier is bÔ¨Çoat16 and accumulator is Ô¨Çoat32 type. To isolate the critical and noncritical faults of a Ô¨Çoating-point MAC, we obtained aÔ¨Çoating-point MAC benchmark circuit from OpenCores [47]and modiÔ¨Åed it for above mentioned bÔ¨Çoat format. We synthe-sized a gate-level netlist of the Ô¨Çoating point MAC using theDesignWare IP library. For the Ô¨Çoating-point MAC, we tookthe Ô¨Års"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_50", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 50, "text": "m OpenCores [47]and modiÔ¨Åed it for above mentioned bÔ¨Çoat format. We synthe-sized a gate-level netlist of the Ô¨Çoating point MAC using theDesignWare IP library. For the Ô¨Çoating-point MAC, we tookthe Ô¨Årst 4 LSB bits (bits 0‚Äì5) of the mantissa as noncriticalTABLE III MULTIPLICATION AND ADDITIONS IN CNN TOCLASSIFY ONEIMAGE (a) (b) Fig. 14. (a) Improvement in accuracy with fault-aware training on LeNet-5.(b) Accuracy change of LeNet-5 CNN with faults for approximate and exactmultipliers without retraining. (from analysis in Fig. 10), and the rest of the bits of man- tissa, the exponent and sign bit are considered critical. Afteridentifying the critical and noncritical gates and correspond-ing faults, the fault lists and the gate-level netlist were taken to the ATPG tool and test patterns were generated similar to the int8 case above. The results are shown in Table II. First,the test patterns from Row 3 of Table II are applied to iden-tify all faulty PEs that must be disabled to prevent signiÔ¨Åcantaccuracy loss in AI tasks. After that, the noncritical faults areidentiÔ¨Åed with the patterns from Row 4 of Table II. All PEsthat failed this second test have noncritical faults and their IDs are "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_51", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 51, "text": "Ô¨Åcantaccuracy loss in AI tasks. After that, the noncritical faults areidentiÔ¨Åed with the patterns from Row 4 of Table II. All PEsthat failed this second test have noncritical faults and their IDs are recorded in FSR. To analyze the impact of PE/MAC faults on the infer- ence accuracy of NN, we implemented a 4-layer NN withtwo hidden layers, and varied the number of neurons in thehidden layers. Also, both unpruned and 30% pruned (with-retraining) [24]‚Äì[26] versions were implemented. For NNexperiments we used MATLAB deep learning toolbox [48]. All weights and activations were quantized in int8 format using MATLAB Ô¨Åxed-point tool [48]. To incorporate the worst casenoncritical MAC faults‚Äîobtained from the gate-level netlistabove‚Äîinto the NN inference task, the matrix multiplicationfunction in forward pass of the NN used in inference was mod-iÔ¨Åed in MATLAB to inject faults according to the hardwaremodel of Fig. 11. The relationship between accuracy and faultrates are shown in Fig. 12. It can be seen from Fig. 12(a) that, other than the smaller 100 hidden layer case, the rest of the NNs are robust to faults in the MAC, with normal-ized accuracy changes less than 0.5% at 5% fault rate. Wit"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_52", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 52, "text": " be seen from Fig. 12(a) that, other than the smaller 100 hidden layer case, the rest of the NNs are robust to faults in the MAC, with normal-ized accuracy changes less than 0.5% at 5% fault rate. Withpruning [Fig. 12(b)], the accuracy degrades slightly more withfaults. This is because with pruning less number of neuronsare present, and those that are present become more important. To assess the impact of MAC circuit faults on the accuracy of CNN, we used several key benchmark CNNs ‚Äì AlexNet [11], VGG-16 [13], ResNet-50 [12] and LeNet-5 [44]. The number ofconvolution, linear layers and the total number of multiplicationand additions required (without pruning) to classify each imagein these networks are tabulated in Table III. These results wereobtained using custom functions developed in Pytorch [49].For the smaller CNN, LeNet-5, we performed both training Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 113 (a) (b) (c) (d) (e) (f) (g) (h) Fig. 13. Inference accuracy changes with fault (noncritical) rates fo"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_53", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 53, "text": "tions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 113 (a) (b) (c) (d) (e) (f) (g) (h) Fig. 13. Inference accuracy changes with fault (noncritical) rates for CNNs running imagenet dataset. (a) and (b) Top-1 and Top-5 accuracy changes. (c) and (d) Top-1 and Top-5 accuracy changes with model pruning. (e) to (h) normalized accuracy changes in Top-1 and Top-5 (with and without pruning) for fault rates. and inference with MNIST dataset [44]. For the complex architectures‚ÄîAlexNet, VGG-16, and ResNet-50‚Äîtrainingtakes several days and requires multiple GPUs [11]‚Äì[13]. InPytorch [49] library, pretrained versions of these CNNs are avail- able where they were already trained with ImageNet [14] dataset having millions of training images and 1000 possible classes. Inour experiments we used these pretrained models and performedinference with the 50 000 images from the ImageNet [14] val-idation dataset. During inference, the models were quantizedinto int8 format using Pytorch‚Äôs torch.nn.quantized library. To incorporate the worst case noncritical MAC faults‚Äîobtainedfrom the gate-level netlist above‚Äîin the inference function of the CNN, we used Pytorch‚Äôs"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_54", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 54, "text": "ormat using Pytorch‚Äôs torch.nn.quantized library. To incorporate the worst case noncritical MAC faults‚Äîobtainedfrom the gate-level netlist above‚Äîin the inference function of the CNN, we used Pytorch‚Äôs register _forward _hook feature to access the data in Conv2d function and injected the MACfaults according to the hardware model of Fig. 11. The accu-racy changes‚Äîin the standard Top-1 and Top-5 format‚ÄîwithMAC faults are shown in Fig. 13 for 50 000 test images fromImageNet [14]. Top-1 accuracy implies that the predicted classmatches exactly the actual class (out of 1000 possible classes) and Top-5 refers to the case where the actual class is within the top 5 predicted classes [11]‚Äì[13], [49]. From Fig. 13(e),it can be seen that the normalized accuracy in Top-1 categorychanges by less than 1.5% for all networks when fault ratesare within 5%. For the Top-5 category in Fig. 13(f), except forthe computationally intensive VGG-16 network, the normal-ized accuracy degradation was conÔ¨Åned within 1% for faultrates up to 5%. Next, we pruned 30% of the Ô¨Ålter weights of the convolution layers and repeated our fault injection exper- iments. Form Fig. 13(g) and (h), it can be seen that, withpruning"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_55", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 55, "text": "1% for faultrates up to 5%. Next, we pruned 30% of the Ô¨Ålter weights of the convolution layers and repeated our fault injection exper- iments. Form Fig. 13(g) and (h), it can be seen that, withpruning, the normalized Top-1 accuracy degraded by a smallamount with worst case happening for ResNet-50 where itdegraded by 2.2% for fault rate 5%. Even with pruning, theTop-5 normalized accuracy degradation was within 1% for faultrates up to 5%. Note that, during our pruning experiments on AlexNet/VGG-16/ResNet-50 retraining was not done, because it would have required us to retrain the networks with 14 mil-lion images using a large number of GPUs. Retraining duringpruning would improve the accuracy further [24]‚Äì[26]. As discussed in Section III-C2, using our proposed fault- aware training Ô¨Çow some of the accuracy loss due to faultsin MAC units can be recovered by incorporating the fault effects in the backpropagation-based weight update segmentand allowing the CNN to adapt accordingly. To experimen-tally demonstrate this technique, we used the LeNet-5 CNN architecture. We picked the simpler LeNet-5 architecture over AlexNet/VGG-16/ResNet-50 because of the computationalcomplexity of trainin"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_56", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 56, "text": "rimen-tally demonstrate this technique, we used the LeNet-5 CNN architecture. We picked the simpler LeNet-5 architecture over AlexNet/VGG-16/ResNet-50 because of the computationalcomplexity of training. Whereas AlexNet/VGG-16/ResNet-50would require multiple GPUs and several days of trainingwith ImageNet data [11]‚Äì[13], the LeNet-5 can be trainedin several minutes on MNIST dataset using CPU. We used6-core Intel core i7 CPU with 24-GB RAM in this train-ing experiment. We modeled the equivalent worst case MAC error‚Äîcorresponding to faults occurring in the logic cones of four LSB bits of mantissa‚Äîin the forward and backprop-agation segment using Pytorch‚Äôs register _hook feature [49]. Results from this fault-aware training are shown in Fig. 14(a).The results in Fig. 14(a), corresponds to the bÔ¨Çoat16 formattraining and inference hardware model as presented in [40]and [41] where multiplier is of bÔ¨Çoat16 type and accumulator is of Ô¨Çoat32. It can be seen that for 7.5% fault rate the nor- malized accuracy loss improved from 0.5% to 0.22% due tofault-aware training. In Section II-A, we explained that the presence of defect- induced circuit faults in approximate NN/CNN will deterioratethe AI t"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_57", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 57, "text": "d accuracy loss improved from 0.5% to 0.22% due tofault-aware training. In Section II-A, we explained that the presence of defect- induced circuit faults in approximate NN/CNN will deterioratethe AI task‚Äôs accuracy as errors from approximations in MACwere already introduced in the model, and any further errorfrom circuit faults will be detrimental. In Fig. 14(b), the nor- malized change of accuracy with respect to faults for LeNet-5 on MNIST dataset is shown for cases of exact and approx-imate multipliers. In [31] a comprehensive analysis (withapproximation aware retraining) of different types approxi-mate multipliers on the efÔ¨Åciency of NN were performed, andthe best approx. multipliers in terms of prediction accuracywere reported. Based on these Ô¨Åndings [31], in our exper- iment as an approx. multiplier, we chose mul8_134 from the open-source library of EvoApprox8b [42]. As discussedin [28] and [31], the accuracy of CNN/NN using approxi-mate multipliers are very sensitive to proper training comparedto regular multipliers, and the backpropagation training phasemust be updated to account for approximate computing. In Authorized licensed use limited to: Hochschule Heilbronn. Downloa"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_58", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 58, "text": "raining comparedto regular multipliers, and the backpropagation training phasemust be updated to account for approximate computing. In Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. 114 IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, VOL. 41, NO. 1, JANUARY 2022 our experiment, the initial training phase was updated (using Pytorch‚Äôs hook functions [49]) to account for the use of 8- bit approx. multiplier, also int8 quantization was used. FromFig. 14(b), it can be observed that the presence of faultswill degrade the performance of NNs with approx. multiplierssigniÔ¨Åcantly. Hence, if yield loss reduction is the primary goal,exact MAC units need to be used to account for possiblecircuit faults. From these detailed analyses of gate-level synthesis, fault isolation, ATPG pattern generation for the MAC circuit, and corresponding simulation of fault effects on standard NN/CNNbenchmarks, it can be observed that certain circuit faults‚Äîbased on their locations in the circuit‚Äîhave minimal impacton the AI task‚Äôs accuracy when the fault rate is within anupper limit. For"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_59", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 59, "text": "d NN/CNNbenchmarks, it can be observed that certain circuit faults‚Äîbased on their locations in the circuit‚Äîhave minimal impacton the AI task‚Äôs accuracy when the fault rate is within anupper limit. For example, with 5% fault rate in noncriticalgates, the normalized Top-5 accuracy loss in CNNs is less than 1% [Fig. 13(f) and (h)]. If this 1% accuracy loss is accept- able, and if there are more than 5% faulty PEs, then usingthe IDs of faulty PEs stored in the Fault Status Register, somefaulty PEs can de deactivated on each column of the acceler-ator such that the fault rate is within 5% on each column ofthe PE array. For instance, in Fig. 13(h), at 10% fault rate thenormalized Top-5 accuracy degradation is 3.2% for AlexNet, but after deactivating few faulty PEs uniformly in each column of the accelerator the fault-rate per column can be reduced to5% and this will result in improved Top-5 accuracy degra-dation to less than 1%. As a result, an AI accelerator chipwith few faulty PEs can be binned accordingly and shipped,improving valuable yield and revenue. The tradeoff in thisyield saving would be the lower number of PE blocks in theaccelerator due to the deactivation of few faulty PEs "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_60", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 60, "text": "inned accordingly and shipped,improving valuable yield and revenue. The tradeoff in thisyield saving would be the lower number of PE blocks in theaccelerator due to the deactivation of few faulty PEs to keep the fault rate within an acceptable limit (i.e., 5%), however, this will not have any functional impact, and will only reducethe throughput marginally. Furthermore, the reduced through-put PEs can be binned and priced differently without totallydiscarding the chip, thus saving yield. For example, the accel-erators with no fault at all can be placed in the top bin andsold at a premium price to be used in safety-critical appli- cations, such as self-driving cars, whereas accelerators in the lower bins (with few faults, e.g., less than 5% fault rate) canbe used in other AI/deep-learning tasks that can tolerate errorswith minimal performance loss. In [33] when considering faults, authors assumed the com- plete MAC unit (i.e., all bits) was faulty, in contrast, ourapproach is more pragmatic and conservative. We analyzed our faults within groups of bits (i.e., logic cone of certain LSBs Vs. logic cone of the rest). If there are any errors beyond a certain LSB position we deactivate t"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_61", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 61, "text": "atic and conservative. We analyzed our faults within groups of bits (i.e., logic cone of certain LSBs Vs. logic cone of the rest). If there are any errors beyond a certain LSB position we deactivate that PE to avoid a large extent of error in the accuracy. The complexity and cost of our approach are also minimal. For identifying the allowable noncritical fault rate and the number of LSBs, our search space is limited as we choose few LSB bits and fault rates (Fig. 10). Moreover, inference is not necessarily time-consuming and if such an analysis is performed once per hardware with an exhaustive benchmark like ImageNet [14], then it will sufÔ¨Åce for any other benchmark. For the fault-aware training part, only the forward pass function needs to be updated to reÔ¨Çect the MAC fault rate that would be present during inference, and thisis done for only one fault rate (e.g., 2.5% or 5% in Fig. 14). Hence, our fault-aware training does not add extra complexity compared to regular training. As we conÔ¨Åne our faults withina few LSBs, our approach does not require hardware fault location-aware AI workload mapping and retraining as in [33]. In our experiments we used the state-of-the-art CNNs that"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_62", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 62, "text": "conÔ¨Åne our faults withina few LSBs, our approach does not require hardware fault location-aware AI workload mapping and retraining as in [33]. In our experiments we used the state-of-the-art CNNs that were pretrained with one million images from ImageNet [14].Because of the large training set, these CNNs are very well-trained for any other type of pattern recognition/AI task (i.e.,similar to the concept of ‚Äútransfer learning‚Äù where ImageNetpretrained networks can be used for any other pattern recog-nition problem by adjusting and training the Ô¨Ånal layers). Also, for validation of our fault effects, we used the 50K sample validation images from ImageNet with PyTorch. Aswe have shown our approach works on various CNNs trainedwith ImageNet, it sufÔ¨Åces that for any other AI workload theconcept is applicable. V. C ONCLUSION In this article, we presented a yield loss reduction and test methodology for AI accelerator chips densely packed with PEs. Exploiting the error-healing properties ofbackpropagation during training and the inherent fault tol-erance features of trained AI models during inference, weobtained an analytical relationship between fault location andfault rate of MAC, and th"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_63", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 63, "text": "kpropagation during training and the inherent fault tol-erance features of trained AI models during inference, weobtained an analytical relationship between fault location andfault rate of MAC, and the AI task‚Äôs accuracy to guideyield decisions. Simulation results on NN/CNN show that theproposed YAOTA approach will allow up to 5% faulty PEs in the accelerator at the expense of less than 1% loss in the AI task‚Äôs accuracy. Furthermore, the presented fault-aware bin-ning strategy allows accelerators to be binned, with the goalof yield loss reduction, according to the fault rate and targetend-user applications. R EFERENCES [1] V . Sze, Y .-H. Chen, T.-J. Yang, and J. S. Emer, ‚ÄúEfÔ¨Åcient processing of deep neural networks: A tutorial and survey,‚Äù in Proc. IEEE , vol. 105, no. 12, pp. 2295‚Äì2329, Dec. 2017. [2] Y .-H. Chen, T.-J. Yang, J. Emer, and V . Sze, ‚ÄúEyeriss v2: A Ô¨Çexible accelerator for emerging deep neural networks on mobile devices,‚Äù IEEE J. Emerg. Sel. Topics Circuits Syst. , vol. 9, no. 2, pp. 292‚Äì308, Jun. 2019 [3] J. Lee, J. Lee, D. Han, J. Lee, G. Park, and H.-J. Yoo, ‚Äú7.7 LNPU: A 25.3TFLOPS/W sparse deep-neural-network learning proces-sor with Ô¨Åne-grained mixed precision o"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_64", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 64, "text": "9, no. 2, pp. 292‚Äì308, Jun. 2019 [3] J. Lee, J. Lee, D. Han, J. Lee, G. Park, and H.-J. Yoo, ‚Äú7.7 LNPU: A 25.3TFLOPS/W sparse deep-neural-network learning proces-sor with Ô¨Åne-grained mixed precision of FP8-FP16,‚Äù in Proc. IEEE Int. Solid- State Circuits Conf. (ISSCC) , 2019, pp. 142‚Äì144. [4] N. P. Jouppi, C. Young, N. Patil, and D. Patterson, ‚ÄúA domain-speciÔ¨Åc architecture for deep neural networks,‚Äù Commun. ACM , vol. 61, no. 9, pp. 50‚Äì59, 2018. [5]AWS Inferentia Chip . Accessed : 15, May 2020. [Online]. Available: https://aws.amazon.com/ [6] S. Markidis, S. Wei Der Chien, E. Laure, I. Bo Peng, and J. S. Vetter, ‚ÄúNVIDIA tensor core programmability, performance & precision,‚Äù inProc. IEEE Int. Parallel Distrib. Process. Symp. Workshops (IPDPSW) , 2018, pp. 522‚Äì531. [7]Gorq Tensor Processor . Accessed : 15, May 2020. [Online]. Available: https://groq.com/technology/ [8] G. Batra, Z. Jacobson, S. Madhav, A. Queirolo, and N. Santhanam, ArtiÔ¨Åcial-Intelligence Hardware: New Opportunities for SemiconductorCompanies , McKinsey & Company, New York, NY , USA, Jan. 2019. [9] L. Tung, GPU Killer: Google Reveals Just How Powerful Its TPU2 Chip Really is , ZDNet, New York, NY , USA, Dec. 2017. [1"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_65", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 65, "text": "SemiconductorCompanies , McKinsey & Company, New York, NY , USA, Jan. 2019. [9] L. Tung, GPU Killer: Google Reveals Just How Powerful Its TPU2 Chip Really is , ZDNet, New York, NY , USA, Dec. 2017. [10] S. Moore, Cerebras‚Äôs Giant Chip Will Smash Deep Learning‚Äôs Speed Barrier , IEEE Spectrum, New York, NY , USA, Jan. 2020. [11] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‚ÄúImageNet classiÔ¨Åca- tion with deep convolutional neural networks,‚Äù in Proc. NIPS , 2012, pp. 1106‚Äì1114. [12] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep residual learning for image recognition,‚Äù in Proc. Comput. Vis. Pattern Recognit. (CVPR) , 2016, pp. 770‚Äì778. [13] K. Simonyan and A. Zisserman, ‚ÄúVery deep convolutional networks for large-scale image recognition,‚Äù in Proc. ICLR , 2015. [14] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and F. F. Li, ‚ÄúImageNet: A large-scale hierarchical image database,‚Äù in Proc. IEEE CVPR , 2009, pp. 248‚Äì255. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 115 [15] A. J. Strojwas, K. Doong, and D. J. Cip"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_66", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 66, "text": "ptember 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply. SADI AND GUIN: TEST AND YIELD LOSS REDUCTION OF AI AND DEEP LEARNING ACCELERATORS 115 [15] A. J. Strojwas, K. Doong, and D. J. Ciplickas, ‚ÄúYield and reliability challenges at 7nm and below,‚Äù in Proc. Electron Devices Technol. Manuf. Conf. (EDTM) , 2019, pp. 179‚Äì181. [16] S. Kobayashi et al. , ‚ÄúYield-centric layout optimization with precise quantiÔ¨Åcation of lithographic yield loss,‚Äù in Proc. SPIE Photomask Next Gener. Lithogr. Mask Technol. , 2008, p. 8. [17] M. Nero, C. Shan, L.-C. Wang, and N. Sumikawa, ‚ÄúConcept recogni- tion in production yield data analytics,‚Äù in Proc. Int. Test Conf. , 2018, pp. 1‚Äì10. [18] G. Moore, J.-H. Liao, S. McDade, and B. Verzi, ‚ÄúAccelerating 14nm device learning and yield ramp using parallel test structures as part of anew inline parametric test strategy,‚Äù in Proc. ICMTS , 2015, pp. 44‚Äì49. [19] P. C. Maxwell, F. Hapke, and H. Tang, ‚ÄúCell-aware diagnosis: Defective inmates exposed in their cells,‚Äù in Proc. Eur. Test Symp. (ETS) , 2016, pp. 1‚Äì6. [20] Z. Gao et al. , ‚ÄúApplication of cell-aware test on an advanced 3nm CMOS technology library,‚Äù in Proc. Int. Test Conf. (ITC) , 2019, pp. 1‚Äì"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_67", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 67, "text": " cells,‚Äù in Proc. Eur. Test Symp. (ETS) , 2016, pp. 1‚Äì6. [20] Z. Gao et al. , ‚ÄúApplication of cell-aware test on an advanced 3nm CMOS technology library,‚Äù in Proc. Int. Test Conf. (ITC) , 2019, pp. 1‚Äì6. [21] B. Jorgenson, Intel‚Äôs 2020 Forecast is Grim , EE Times, San Francisco, CA, USA, Apr. 2020. [22] S. Moore, 3 Ways Chiplets Are Remaking Processors , IEEE Spectrum, New York, NY , USA, Apr. 2020. [23] P. Gupta and S. Iyer, Goodbye, Motherboard. Hello, Silicon-Interconnect Fabric , IEEE Spectrum, New York, NY , USA, Oct. 2019. [24] S. Han, J. Pool, J. Tran, and W. J. Dally, ‚ÄúLearning both weights and connections for efÔ¨Åcient neural networks,‚Äù in Proc. Int. Conf. Neural Inf. Process. Syst. (NIPS) , 2015, pp. 1135‚Äì1143. [25] N. Lee, T. Ajanthan, and P. H. S. Torr, ‚ÄúSNIP: Single-shot network pruning based on connection sensitivity,‚Äù in Proc. Int. Conf. Learn. Representations (ICLR) , 2019. [26] S. Han, H. Mao, and W. Dally, ‚ÄúDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding,‚Äù inProc. ICLR , 2016. [27] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, ‚ÄúDropout: A simple way to prevent neural networksfrom"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_68", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 68, "text": ", trained quantization and huffman coding,‚Äù inProc. ICLR , 2016. [27] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, ‚ÄúDropout: A simple way to prevent neural networksfrom overÔ¨Åtting,‚Äù J. Mach. Learn. Res. , vol. 15, no. 56, pp. 1929‚Äì1958, 2014. [28] S. Venkataramani, A. Ranjan, K. Roy, and A. Raghunathan, ‚ÄúAxNN: Energy-efÔ¨Åcient neuromorphic systems using approximate computing,‚ÄùinProc. IEEE/ACM Int. Symp. Low Power Electron. Design (ISLPED) , 2014, pp. 27‚Äì32. [29] Q. Zhang, T. Wang, Y . Tian, F. Yuan, and Q. Xu, ‚ÄúApproxANN: An approximate computing framework for artiÔ¨Åcial neural network,‚ÄùinProc. Design Autom. Test Europe Conf. Exhibition (DATE) , 2015, pp. 701‚Äì706. [30] V . Mrazek, S. S. Sarwar, L. Sekanina, Z. Vas√≠cek, and K. Roy, ‚ÄúDesign of power-efÔ¨Åcient approximate multipliers for approximate artiÔ¨Åcial neuralnetworks,‚Äù in Proc. Int. Conf. Comput. Aided Design (ICCAD) , 2016, p. 81. [31] M. S. Ansari, V . Mrazek, B. F. Cockburn, L. Sekanina, Z. Vasicek, and J. Han, ‚ÄúImproving the accuracy and hardware efÔ¨Åciency of neuralnetworks using approximate multipliers,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 28, no. 2, pp. 317‚Äì328, Feb. 2020."}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_69", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 69, "text": "and J. Han, ‚ÄúImproving the accuracy and hardware efÔ¨Åciency of neuralnetworks using approximate multipliers,‚Äù IEEE Trans. Very Large Scale Integr. (VLSI) Syst. , vol. 28, no. 2, pp. 317‚Äì328, Feb. 2020. [32] A. Gebregiorgis and M. B. Tahoori, ‚ÄúTesting of neuromorphic circuits: Structural vs functional,‚Äù in Proc. Int. Test Conf. (ITC) , 2019, pp. 1‚Äì10. [33] J. J. Zhang, K. Basu, and S. Garg, ‚ÄúFault-tolerant systolic array based accelerators for deep neural network execution,‚Äù IEEE Design Test , vol. 36, no. 5, pp. 44‚Äì53, Oct. 2019. [34] J. Zhang, K. Rangineni, Z. Ghodsi, and S. Garg, ‚ÄúThUnderV olt: Enabling aggressive voltage underscaling and timing error resilience for energyefÔ¨Åcient deep learning accelerators,‚Äù in Proc. 55th Annu. Design Autom. Conf. , 2018, pp. 1‚Äì6. [35] S. Kim, P. Howe, T. Moreau, A. Alaghi, L. Ceze, and V . S. Sathe, ‚ÄúEnergy-efÔ¨Åcient neural network acceleration in the presence of bit-level memory errors,‚Äù IEEE Trans. Circuits Syst. I, Reg. Papers , vol. 65, no. 12, pp. 4285‚Äì4298, Dec. 2018. [36] J. H. Kim and S. M. Reddy, ‚ÄúOn the design of fault-tolerant two- dimensional systolic arrays for yield enhancement,‚Äù IEEE Trans. Comput. , vol. 38, no. 4, pp. 515‚Äì525, Ap"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_70", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 70, "text": "p. 4285‚Äì4298, Dec. 2018. [36] J. H. Kim and S. M. Reddy, ‚ÄúOn the design of fault-tolerant two- dimensional systolic arrays for yield enhancement,‚Äù IEEE Trans. Comput. , vol. 38, no. 4, pp. 515‚Äì525, Apr. 1989. [37] R. Das and T. Krishna, DNN Accelerator Architecture‚ÄîSIMD or Systolic? Computer Architecture Today, ACM SIGARCH, Sep. 2018. [38] J. Wu, C. Leng, Y . Wang, Q. Hu, and J. Cheng, ‚ÄúQuantized convolu- tional neural networks for mobile devices,‚Äù in Proc. Comput. Vis. Pattern Recognit. (CVPR) , 2016, pp. 4820‚Äì4828. [39] S. Migacz, 8-bit Inference with TensorRT , NVIDIA, Santa Clara, CA, USA, 2017. [40] P. Micikevicius et al. , ‚ÄúMixed precision training,‚Äù in Proc. ICLR , 2018. [41] S. Wang and P. Kanwar, BFloat16: The Secret to High Performance on Cloud TPUs , Google Cloud Blog, Mountain View, CA, USA, 2019. [42] V . Mrazek, R. Hrbacek, Z. Vasicek, and L. Sekanina, ‚ÄúEvoApprox8b: Library of approximate adders and multipliers for circuit designand benchmarking of approximation methods,‚Äù in Proc. DATE , 2017, pp. 258‚Äì261.[43] R. Ramadorai, D. Feltham, and J. Douglas, ‚ÄúMethod and apparatus for disabling and swapping cores in a multi-core microprocessor,‚Äù U.S. Patent 20 070 255 985 A1,"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_71", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 71, "text": " in Proc. DATE , 2017, pp. 258‚Äì261.[43] R. Ramadorai, D. Feltham, and J. Douglas, ‚ÄúMethod and apparatus for disabling and swapping cores in a multi-core microprocessor,‚Äù U.S. Patent 20 070 255 985 A1, 2006. [44] Lecture 9: CNN Architectures . Accessed : 15, May 2020. [Online]. Available: http://cs231n. stanford.edu/slides/2017/cs231n_2017_ lecture9.pdf [45] Designware IP . Accessed : 15, May 2020. [Online]. Available: https: //www.synopsys.com/designware-ip.html [46] Synopsys . Accessed : 15, May 2020. [Online]. Available: https://www. synopsys.com/ [47] Opencores . Accessed : 15, May 2020. [Online]. Available: https:// opencores.org/ [48] MATLAB . Accessed : 15, May 2020. [Online]. Available: https://www. mathworks.com/products/matlab.html [49] Pytorch . Accessed : 15, May 2020. [Online]. Available: https://pytorch. org/ Mehdi Sadi (Member, IEEE) received the B.S. degree from the Bangladesh University of Engineering and Technology, Dhaka, Bangladesh,in 2010, the M.S. degree from the University of California at Riverside, Riverside, CA, USA, in 2011, and the Ph.D. degree from the Departmentof Electrical and Computer Engineering (ECE),University of Florida, Gainesville, FL, USA, in "}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_72", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 72, "text": "niversity of California at Riverside, Riverside, CA, USA, in 2011, and the Ph.D. degree from the Departmentof Electrical and Computer Engineering (ECE),University of Florida, Gainesville, FL, USA, in 2017. He was a Senior Research and Development SoC Design Engineer with the Xeon Design Team, Intel Corporation, Hillsboro, OR, USA. He is currently an Assistant Professor with the ECE, Auburn University, Auburn, AL, USA. He has published more than 20 peer-reviewed research papers. His research focus is on developingalgorithms and computer-aided-design techniques for implementation, design,test & reliability of AI, and brain-inspired computing hardware. His research also spans into developing machine learning/AI-enabled system-on-Chip (SoC) design Ô¨Çows, and design-for-reliability for safety-critical AI hardwaresystems. Dr. Sadi was a recipient of the Semiconductor Research Corporation Best in Session Award and the Intel Xeon Design Group recognition awards. Ujjwal Guin (Member, IEEE) received the B.E. degree from the Department of Electronicsand Telecommunication Engineering, BengalEngineering and Science University, Howrah, India, in 2004, the M.S. degree from the Department of Electr"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_73", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 73, "text": "ved the B.E. degree from the Department of Electronicsand Telecommunication Engineering, BengalEngineering and Science University, Howrah, India, in 2004, the M.S. degree from the Department of Electrical and Computer Engineering, TempleUniversity, Philadelphia, PA, USA, in 2010, andthe Ph.D. degree from the Electrical and Computer Engineering Department, University of Connecticut, MansÔ¨Åeld, CT, USA, in 2016. He is currently an Assistant Professor with the Electrical and Computer Engineering Department, Auburn University, Auburn, AL, USA. He has developed several on-chip structures and techniques to improve the security, trustworthiness, and reliability ofintegrated circuits. He has authored several journal articles and refereed conference papers. He has coauthored the book Counterfeit Integrated Circuits: Detection and Avoidance . He was actively involved in developing a Web-based tool, Counterfeit Defect Coverage Tool (CDC Tool), to evaluatethe effectiveness of different test methods used for counterfeit IC detection. His current research interests include hardware security and trust, blockchain, supply chain security, cybersecurity, and VLSI design and test. Dr. Guin is an activ"}
{"id": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf::chunk_74", "source": "Test_and_Yield_Loss_Reduction_of_AI_and_Deep_Learning_Accelerators.pdf", "chunk_index": 74, "text": " used for counterfeit IC detection. His current research interests include hardware security and trust, blockchain, supply chain security, cybersecurity, and VLSI design and test. Dr. Guin is an active participant in the SAE International G-19A Test Laboratory Standards Development Committee and G-32 Cyber-Physical Systems Security Committee. He is a member of ACM. Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:54:14 UTC from IEEE Xplore. Restrictions apply."}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_0", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 0, "text": "IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 LETTER UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect Recognition of Wafer Bin Maps Qingqing Yu1a) Abstract Defect pattern detection of wafer bin maps (WBMs) is vital in wafer quality improvement owing to preventing further defects and resource waste. We proposed two Mixup approaches to train Vision Transformer under only single defect WBM samples for mixed-type defects recognition. We use UnionMixup and Token level Max-Min-Saliency Mixup to generate mixed-type defect WBMs to feed Vision Transformers. In the recognition of two-mixed defect types WBMs, our method improves 17.1 % compared to baseline (none mixup) and we have 1.7% accuracy gain compared with state-of-the-art mixup approaches. In the recognition mixed defect samples containing more than two-mixed defects (three-mixed and four-mixed), we gain at least 24.7% (compared with baseline) and 11.1% (compared with single SOTA mixup) respectively. The combination of Union Mixup and Token level Max-Min-Saliency Mixup become better than other SOTA mixup methods obviously in mixed patterns including more than three defects. key words: Defect pattern classification, Mixed-ty"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_1", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 1, "text": "xup and Token level Max-Min-Saliency Mixup become better than other SOTA mixup methods obviously in mixed patterns including more than three defects. key words: Defect pattern classification, Mixed-type defects , WBM classification, Mixup, Vision Transformer Classification: Electron devices, circuits and modules (silicon, compound semiconductor, organic and novel materials) 1. Introduction The requirement and manufacture outputs of wafers have boosted in the latest decades which results in manual detec- tion inadequate. Each wafer has thousands of chips which should be analyzed by several detection devices at different phases of manufacturing procedure for defect detection. A wafer bin map (WBM) is a two dimensional binary map illustrates the electrical detection outcomes. Correct dies are specified a value of zero, while error dies are speci- fied a value of one. We classify these defect WBM patterns into 9 categories: Edge-Loc, Edge-Ring, Center, Scratch, Donut, Loc, Random, Near-Full, and Normal (with none defect) as shown in Fig.1. To achieve high outputs and high quality in wafer manufacture, we need better automatic ap- paratuses with high recognition accuracy of WBMs defect "}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_2", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 2, "text": "l, and Normal (with none defect) as shown in Fig.1. To achieve high outputs and high quality in wafer manufacture, we need better automatic ap- paratuses with high recognition accuracy of WBMs defect patterns [1, 2]. So far, most researches focus on design- ing data-oriented models for WBM defect patterns classifi- cation [3, 4]. A supervised model of convolutional neural 1Dept. of Information Management, MinNan University of Sci- ence and Technology, Quanzhou 999001-362700, China a)476931017@qq.com DOI: 10.1587/elex.XX.XXXXXXXX Received January 26, 2024 Accepted February 01, 2024 Published March 01, 2024 Fig. 1. Visualization of the nine single defect patterns in WM-811 K networks trained by an end-to-end way with minimal feature [5] is one of the most efficient methods. Since obtaining the huge size datasets for training are time-costly and labour- intensively, various efforts have been made on synthesis of two labelled samples. Moreover, the work of label the sam- ples of two or more type defect patterns is more difficult for mixed-type patterns grow exponentially according to the number of single-defect patterns. So the build of a labelled WBM dataset containing mixed-type defe"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_3", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 3, "text": "e type defect patterns is more difficult for mixed-type patterns grow exponentially according to the number of single-defect patterns. So the build of a labelled WBM dataset containing mixed-type defect labels is im- practical. To solve this issue, we propose an architecture that training vision transformers only by single-defect sam- ples and classify samples containing mixed-type defects. We use improved inputMixup [6] methods and Token-level mixup which makes significant improvements in recogniz- ing mixed-type defect WBMs that have not appeared in the single-type dataset. We propose Max-Min saliency Token Mixup(MMSTM for short) to improve the recognition ac- curacy of three or four mixed-types. MMSTM surpasses state-of-the-art mixup approaches on five different vision transformer models, and it demonstrates that our approach is not restricted to specific framework. After we have done UnionMixup of two type defect patterns, when the mixed WBMs are further mixed in MMSTM, three-mixed defect patterns or four-mixed patterns will be generated to feed the transformer. Specially, compared with other SOTA meth- ods, the architecture we proposed perform more efficiently in classificatio"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_4", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 4, "text": " defect patterns or four-mixed patterns will be generated to feed the transformer. Specially, compared with other SOTA meth- ods, the architecture we proposed perform more efficiently in classification of mixed type containing three defect pat- terns or more than three type defect patterns. In short, our contributions are as follows: (1) We propose UnionMixup which is effective for mixed type defect patterns classifica- tion in WBMs in the early stage. (2) We propose MMSTM a Token level Mixup method based on Max-Min saliency opti- mal assignment which is efficient in augmenting the training of Vision Transformer. (3) The architecture of UnionMixup Copyright ¬©2024 The Institute of Electronics, Information and Communication Engineers1 This article has been accepted and published on J -STAGE in advance of copyediting. Content is final as presented. Copyright ¬© The Institute of Electronics, Information and Communication Engineers 2024 IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 Fig. 2. Framework of the combination of Union Mixup and MMSTM. (Here, xùëé,xùëè,xùëê,xùëë‚ààDùëôùëúùë§ ,xùëé,ùëè,is the Union Mixup of xùëéandxùëè ,and xùëê,ùëëis the Union Mixup of xùëêandxùëë.xùëÄùëñùë• is the Token level mixup with Max-Min Sali"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_5", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 5, "text": "ramework of the combination of Union Mixup and MMSTM. (Here, xùëé,xùëè,xùëê,xùëë‚ààDùëôùëúùë§ ,xùëé,ùëè,is the Union Mixup of xùëéandxùëè ,and xùëê,ùëëis the Union Mixup of xùëêandxùëë.xùëÄùëñùë• is the Token level mixup with Max-Min Saliency optimal assignment of xùëé,ùëèandxùëê,ùëë.) combined with MMSTM improve the robustness of Vision Transformer‚Äôs capability in WBM defect pattern classifi- cation, especially when three or more type defect patterns are mixed. The framework of this approach is illustrated in Fig.2. 2. Related work So far, most works focused on recognition of single-defect pattern WBMs, our target is the classification of mixed- type defect patterns in this paper. Seldom approaches have been suggested for the classification of mixed-type WBM defects. [7] trained individual CNN models for single defect and then combined the result of single-type CNNs for pre- dictions of the mixed-type defects classification. [8] adopted semi-supervised deep generative network in training unla- beled data for recognition of mixed-type wafer defect pat- tern. Memory-augmented CNN model containing a triplet loss function had been mentioned in [9] to obtain effective low-dimensional embedding perform efficiently in imbal- anced W"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_6", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 6, "text": "type wafer defect pat- tern. Memory-augmented CNN model containing a triplet loss function had been mentioned in [9] to obtain effective low-dimensional embedding perform efficiently in imbal- anced WBM dataset. For the mixed-type WBM defects di- versify vastly in angles and positions, correct detection of defect patterns is challenging. Due to standard training in CNNs and transformers can only learn the common features while neglecting the rare features, as a result it brings bad generalization performance. [10] have shown that Mixup can successfully mix the common and rare features so that the gradients along these two features are correlated. Therefore, learning of rare feature can be boosted by the fast learning of common features, and eventually reaches a rather high level to outweigh the influences of noise on test samples. In order to detect mixed-type defect patterns, we propose a unique framework to incorporate UnionMixup and MMSTM into training Vision Transformers based on only single de- fect dataset. Mixup firstly introduced for data augmentation by interpolate two instances linearly [6, 11, 12]. Nonlinear mixup of two different random areas is one replacement of maski"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_7", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 7, "text": "nly single de- fect dataset. Mixup firstly introduced for data augmentation by interpolate two instances linearly [6, 11, 12]. Nonlinear mixup of two different random areas is one replacement of masking square areas [13] in cutMix method [14], while some variants considering arbitrary regions [15, 16, 17]. To avoid selecting localities randomly, saliency is applied to de- tect objects from different instances and combine them into one sample [18, 19, 20, 21]. And we do Token level Mixupbased on Max-Min saliency optimal assignment in trans- formers. We proposed a novel architecture to solve more challenging task like the detection of mixed-type patterns WBMs composed of four defects. The Transformer model will converges faster when the architecture has two phases of mixup algorithms: UnionMixup and MMSTM. 3. Methodology Here, we introduce UnionMixup and MMSTM. The goal of our method is to augment intermediate tokens while max- imizing the saliency level. The whole architecture can be accomplished in three major steps: 1) Calculate defect ratio, 2) The samples whose defect ratio lower than 0.5 can be used to do UnionMixup, 3) All samples no matter whether de- fect ratio is lower 0.5 "}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_8", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 8, "text": "complished in three major steps: 1) Calculate defect ratio, 2) The samples whose defect ratio lower than 0.5 can be used to do UnionMixup, 3) All samples no matter whether de- fect ratio is lower 0.5 participate in MMSTM. The following subsections provide detailed descriptions of the steps. 3.1 Problem formulation Suppose that a single labelled defect dataset including ùëö WBMs in which each image is labelled with one of the ùëê classes. The ùëñùë°‚ÑéWBM, xùëñ‚ààRùêª√óùëä(ùëñ=1,2,...,ùëö). Let (x,y)be an WBM image x‚ààX with its one-hot encoded class label y‚ààY, whereXis the input image space, Y= [0,1]ùëêandùëêis denoted as the defective pattern categories in the classification of WBMs. Suppose a trainable parameters ùúÉ, the object of WBM defect pattern recognition is to learn a functionùëìùúÉ(e.g., Vision Transformer or CNN) based on a training datasetD={(x(ùëñ),y(ùëñ))ùëö ùëñ=1}only containing single defect-labeled samples. So as to correctly map WBMs to their corresponding target labels. 3.2 Defect ratio of WBM Defect ratio ùëüùëëùëíùëìùëíùëêùë° for wafer bin map can be defined as Equation (1). For normal dies and null dies (outside the circular distribution) are defined a value of zero. So, all dies in a normal WBM are zero while con"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_9", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 9, "text": "ùëüùëëùëíùëìùëíùëêùë° for wafer bin map can be defined as Equation (1). For normal dies and null dies (outside the circular distribution) are defined a value of zero. So, all dies in a normal WBM are zero while considering none noise in the image of WBM. ùëü(ùëë) ùëëùëíùëìùëíùëêùë°=ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëë) ùëñ,ùëó ùêª√óùëäx(ùëë) ùëñ,ùëó‚àà{0,1},ùëë=1,2,...,ùëö (1) Here,ùëöis the total amount of WBMs. x(ùëë)is theùëëùë°‚ÑéWBM in the single defect-labeled training dataset D,ùëü(ùëë) ùëëùëíùëìùëíùëêùë° is defined as the defect ratio of x(ùëë). Ifx(ùëë) ùëëùëíùëìùëíùëêùë°<0.5, x(ùëë)‚ààDùëôùëúùë§that is x(ùëë)will be included in set Dùëôùëúùë§which is the image space of WBM with low defect degree. And inputMixup and its variants can be adopted based on the datasetDùëôùëúùë§. Based on the defect ratio defined in Equation (1), the defect complexity is determined. Considering the damage severity degree is rather high when defect ratio is larger than 0.5, so the high degree damaged wafers does not need to be mixed in the inputMixup process. However, all wafers will be trained in the transformer. 2 IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 3.3 Union-Mixup for WBMs Let(x(ùëñ),y(ùëñ))be an WBM image x(ùëñ)‚àà Dùëôùëúùë§with its one-hot encoded class label y(ùëñ)‚ààY. Union Mixup vir- tually train instances are synthesized by tak"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_10", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 10, "text": "Express, Vol.VV, No.NN, 1‚Äì6 3.3 Union-Mixup for WBMs Let(x(ùëñ),y(ùëñ))be an WBM image x(ùëñ)‚àà Dùëôùëúùë§with its one-hot encoded class label y(ùëñ)‚ààY. Union Mixup vir- tually train instances are synthesized by taking the union of defect dies sets within two WBMs. Considering the bi- nary characteristics of WBM data, we can only calculate the union of abnormal dies sets included in two source data instances(x(ùëé),y(ùëé))and(x(ùëè),y(ùëè)). Union Mixup ùëà(x(ùëé),x(ùëè))is denoted as the union of dies sets of two data instances(x(ùëé),y(ùëé))and(x(ùëè),y(ùëè)). Here, x(ùëé,ùëè) ùëöùëñùë•= ùëà(x(ùëé),x(ùëè)),y(ùëé,ùëè) ùëöùëñùë•=ùëìùúÉ(ùëà(x(ùëé),x(ùëè))). Because abnor- mal dies are defined a value of one, while normal dies and null dies (outside the circular distribution) are defined a value of zero. ùëà(ùë•(ùëé),ùë•(ùëè))can be defined as x(ùëé)||x(ùëè)to avoid unpractical values that exceed one. y(ùëé,ùëè) ùëöùëñùë•=ùúÜy(ùëé)+(1‚àíùúÜ)y(ùëè). Here,ùúÜ=ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëó. y(ùëé,ùëè) ùëöùëñùë•=ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëóy(ùëé)+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëó ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëóy(ùëè). Whereùëé=1,2,...,ùëö,ùëè =1,2,...,ùëö . Substitute equation(1), we can get the following equation to simplify the algorithm. y(ùëé,ùëè) ùëöùëñùë•=ùëü"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_11", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 11, "text": "ùëé)+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëó ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëé) ùëñ,ùëó+ùêª√ç ùëñ=1ùëä√ç ùëó=1x(ùëè) ùëñ,ùëóy(ùëè). Whereùëé=1,2,...,ùëö,ùëè =1,2,...,ùëö . Substitute equation(1), we can get the following equation to simplify the algorithm. y(ùëé,ùëè) ùëöùëñùë•=ùëü(ùëé) ùëëùëíùëìùëíùëêùë° ùëü(ùëé) ùëëùëíùëìùëíùëêùë°+ùëü(ùëè) ùëëùëíùëìùëíùëêùë°y(ùëé)+ ùëü(ùëè) ùëëùëíùëìùëíùëêùë° ùëü(ùëé) ùëëùëíùëìùëíùëêùë°+ùëü(ùëè) ùëëùëíùëìùëíùëêùë°y(ùëè). The Union mixed up samples will be added to the original dataset of WBMs Dto generate new dataset of WBM is defined as Dùëõùëíùë§. 3.4 Max-Min Saliency optimal assignment Given a pair of training samples (x(ùëé),y(ùëé))and(x(ùëè),y(ùëè)), We first partition the input image xinto non-overlapping patches xùëù‚ààRùêª ùëÉ√óùëä ùëÉ√óùëÉ2,(ùëÉ,ùëÉ)is the resolution of each image patch. The flattened 2D patches is xùëù‚ààRùëõ√óùëë, here ùëë=ùëÉ2,ùëõ=ùêª ùëÉ√óùëä ùëÉis the resulting number of patches. [22, 23, 24, 25] investigated the imbalanced information of tokens, and token level mixing randomly induces signifi- cant information loss and useless token exchanges. Rather than using gradient-based saliency detectors which requires substantial computation [18, 19], we exploit the benefit of self-attention map, an inherent saliency approximation in transformer modules. So we can deduce the saliency of the tokens from the attention imposed on the tokens as A=1 ùëÅ‚Ñé√çùëÅ‚Ñé ‚Ñé=1A‚Ñé,"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_12", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 12, "text": "t the benefit of self-attention map, an inherent saliency approximation in transformer modules. So we can deduce the saliency of the tokens from the attention imposed on the tokens as A=1 ùëÅ‚Ñé√çùëÅ‚Ñé ‚Ñé=1A‚Ñé, whereùëÅ‚Ñéis the number of heads in the multi-head attention layer, and A‚Ñéis the‚Ñéùë°‚Ñéatten- tion head. Then, the saliency score Sùë°can be computed asSùë°=1 ùëõùëõ√ç ùëñ=1Aùëñ,ùë°, whereùë°=1,2,...,ùëõ is the token index. Based on the estimated saliency of tokens, we aim at maximizing the overall saliency level by optimally assign- ing a different mixup target for each instance. Max-Min saliency optimal assignment is carried out between two in- stances: primary WBM and auxiliary WBM. It replaces a minimum-scored rectangle area of the primary image witha maximum-scored rectangle area of the auxiliary image, so as to maximize saliency of mixed WBMs. The visual- ization is in Fig.2, we partition the primary image xùëùùëüùëñand the auxiliary image xùëéùë¢ùë•into non-overlapping patches of sizeùëÉ√óùëÉ. We define ùëõùëüùëúùë§=ùêª ùëÉandùëõùëêùëúùëô=ùëä ùëÉto sim- plify the formulas. A total of ùëõ=ùëõùëüùëúùë§√óùëõùëêùëúùëôpatches are obtained for each image. However, xùëùùëüùëñandxùëéùë¢ùë•are re- organized as xùëùùëüùëñ,xùëéùë¢ùë•‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô√óùëÉ2, one element of which is a token in vision transf"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_13", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 13, "text": "o sim- plify the formulas. A total of ùëõ=ùëõùëüùëúùë§√óùëõùëêùëúùëôpatches are obtained for each image. However, xùëùùëüùëñandxùëéùë¢ùë•are re- organized as xùëùùëüùëñ,xùëéùë¢ùë•‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô√óùëÉ2, one element of which is a token in vision transformer. Then, they are the input for a Vision Transformer to get the corresponding image saliency scores Sùëùùëüùëñ‚ààRùëõandSùëéùë¢ùë•‚ààRùëõ. Simi- larly, we rearrange the shape of their image saliency score vectors, SùëùùëüùëñandSùëéùë¢ùë•, to matrices of ùëõùëüùëúùë§√óùëõùëêùëúùëô. This method clips a rectangle area from the auxiliary WBM and pastes the rectangle area into the primary WBM to rebuild a mixed WBM. For optimal assignment, we use a selection ratioùúå, sampled from a uniform distribution (0.15, 0.85), to determine the total ‚åäùúåùëõùëüùëúùë§‚åã√ó‚åäùúåùëõùëêùëúùëô‚åãpatches within the selected rectangle area. The kernel of the optimal al- gorithm is to choose the most informative rectangle area in the auxiliary WBM, and the least informative rectan- gle area in the primary WBM. The start indices of these two rectangle areas are defined as the following equations. ùëñ‚àó ùëùùëüùëñ,ùëó‚àó ùëùùëüùëñ=ùëéùëüùëîùëöùëñùëõ ùëñ,ùëó√ç ùëù,ùëûSùëñ+ùëù,ùëó+ùëû ùëùùëüùëñ,Sùëùùëüùëñ‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô ùëñ‚àó ùëùùëüùëñ,ùëó‚àó ùëùùëüùëñ=ùëéùëüùëîùëöùëñùëõ ùëñ,ùëó√ç ùëù,ùëûS(ùëñ‚àí1+ùëù)√óùëõùëêùëúùëô+ùëó+ùëû ùëùùëüùëñ,Sùëùùëüùëñ‚ààRùëõ ùëñ‚àó ùëéùë¢ùë•,ùëó‚àó ùëéùë¢ùë•=ùëéùëüùëîùëöùëéùë• ùëñ,ùëó√ç ùëù,ùëûSùëñ+ùëù,ùëó+ùëû ùëéùë¢ùë•,Sùëéùë¢ùë•‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô ùëñ‚àó ùëéùë¢ùë•,ùëó‚àó ùëéùë¢ùë•"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_14", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 14, "text": " equations. ùëñ‚àó ùëùùëüùëñ,ùëó‚àó ùëùùëüùëñ=ùëéùëüùëîùëöùëñùëõ ùëñ,ùëó√ç ùëù,ùëûSùëñ+ùëù,ùëó+ùëû ùëùùëüùëñ,Sùëùùëüùëñ‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô ùëñ‚àó ùëùùëüùëñ,ùëó‚àó ùëùùëüùëñ=ùëéùëüùëîùëöùëñùëõ ùëñ,ùëó√ç ùëù,ùëûS(ùëñ‚àí1+ùëù)√óùëõùëêùëúùëô+ùëó+ùëû ùëùùëüùëñ,Sùëùùëüùëñ‚ààRùëõ ùëñ‚àó ùëéùë¢ùë•,ùëó‚àó ùëéùë¢ùë•=ùëéùëüùëîùëöùëéùë• ùëñ,ùëó√ç ùëù,ùëûSùëñ+ùëù,ùëó+ùëû ùëéùë¢ùë•,Sùëéùë¢ùë•‚ààRùëõùëüùëúùë§√óùëõùëêùëúùëô ùëñ‚àó ùëéùë¢ùë•,ùëó‚àó ùëéùë¢ùë•=ùëéùëüùëîùëöùëéùë• ùëñ,ùëó√ç ùëù,ùëûS(ùëñ‚àí1+ùëù)√óùëõùëêùëúùëô+ùëó+ùëû ùëéùë¢ùë• ,Sùëéùë¢ùë•‚ààRùëõ Here,1‚â§ùëñ‚â§ùëõùëüùëúùë§,1‚â§ùëñ‚â§ùëõùëêùëúùëô,‚Ñéùëü=‚åäùúåùëõùëüùëúùë§‚åã,ùë§ùëü= ‚åäùúåùëõùëêùëúùëô‚åã,ùëù‚àà{0,1,...,‚Ñéùëü‚àí1}, andùëû‚àà{0,1,...,ùë§ùëü‚àí1}. 3.5 Token level Mixup Intuitively, the selected rectangle area contains patches with the maximum saliency score of the auxiliary WBM and the minimum saliency score of the primary WBM. Then, we obtain the new mixed training instance xùëÄùëñùë•,yùëÄùëñùë•as follows: Firstly we set xùëÄùëñùë•=xùëùùëüùëñ, then xùëñ‚àó ùëùùëüùëñ+ùëù,ùëó‚àó ùëùùëüùëñ+ùëû ùëÄùëñùë•= xùëñ‚àó ùëéùë¢ùë•+ùëù,ùëó‚àó ùëéùë¢ùë•+ùëû ùëéùë¢ùë• .(ùëù‚àà{0,1,...,‚Ñéùëü‚àí1},ùëû‚àà{0,1,...,ùë§ùëü‚àí 1}).yùëÄùëñùë•=ùúÜùëÄùëñùë•yùëùùëüùëñ+(1‚àíùúÜùëÄùëñùë•)yùëéùë¢ùë•, whereùúÜùëÄùëñùë• is defined in the following section. Similarly to CutMix, we then generate an appropriate binary mask M‚ààùëõùëüùëúùë§√óùëõùëêùëúùëô according to the selection ratio ùúå. The mixed new training sample(xùëöùëñùë•,yùëöùëñùë•)is created as follows: xùëöùëñùë•=M‚äôxùëùùëüùëñ+(1‚àíM)‚äôxùëéùë¢ùë•, yùëÄùëñùë•=√çùëõ ùë°=1Mùë°¬∑Sùë° ùëùùëüùëñ√çùëõ ùë°=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•)¬∑yùëùùëüùëñ +√çùëõ ùë°=1(1‚àíMùë°)¬∑Sùë° ùëéùë¢ùë•√çùëõ ùë°=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•)¬∑yùëéùë¢ùë• SoùúÜùëÄùëñùë•=√çùëõ ùë°=1Mùë°¬∑Sùë° ùëùùëüùëñ√çùëõ ùë°=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•). where Sindicates the set of saliency scores of all tokens,"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_15", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 15, "text": "=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•)¬∑yùëùùëüùëñ +√çùëõ ùë°=1(1‚àíMùë°)¬∑Sùë° ùëéùë¢ùë•√çùëõ ùë°=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•)¬∑yùëéùë¢ùë• SoùúÜùëÄùëñùë•=√çùëõ ùë°=1Mùë°¬∑Sùë° ùëùùëüùëñ√çùëõ ùë°=1(Mùë°¬∑Sùë° ùëùùëüùëñ+(1‚àíMùë°)¬∑Sùë°ùëéùë¢ùë•). where Sindicates the set of saliency scores of all tokens, Sùë° ùëùùëüùëñ,Sùë° ùëéùë¢ùë•indicates 3 IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 Table I. Labeled samples distribution of 9 categories in WM-811k Class label Count Proportion(%) Class label Count Proportion(%) Donut 555 0.32 Near-Full 149 0.09 Center 4294 2.48 Random 866 0.50 Edge-Loc 5189 3.00 Scratch 1193 0.69 Loc 3593 2.08 None 147431 85.25 Total 172950 100 theùë°ùë°‚Ñé(ùë°=1,2,...,ùëõ)saliency score of primary WBM and auxiliary WBM respectively. ‚äôdenotes element-wise multiplication, Mùë°denotes theùë°ùë°‚Ñétoken of the mask M. 4. Experiments 4.1 Dataset We use WM-811 K dataset an open real-world dataset of 811,457 WBM samples to demonstrate the efficiency of our method. The dataset has a subset of 172,950 wafer images with single-defect labels. As shown in Fig.1, the labelled single-defect pattern has nine categories: Normal (none error die), Center ,Edge-Loc, Loc, Edge-Ring, Donut , Scratch, Random, and Near-Full. WBMs in the WM-811 K have different resolutions varying from 6 √ó21 to 300 √ó302, we change the "}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_16", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 16, "text": "ories: Normal (none error die), Center ,Edge-Loc, Loc, Edge-Ring, Donut , Scratch, Random, and Near-Full. WBMs in the WM-811 K have different resolutions varying from 6 √ó21 to 300 √ó302, we change the size of every WBM to 64 √ó64 resolution by nearest neighbor interpolation for experiment. Fig. 3. Visualization of 15 possible mixed categories generated by two distinct defect patterns. As illustrated in Table I, the Near-Full pattern occupies merely 0.09% and the Normal pattern has the highest propor- tion of 85% in WM-811 K dataset. The category distribution of labelled data is imbalance. So, we use the inverse class frequencies to calculate WBM sample weights and dynam- ically do sampling from multinomial distribution to acquire balanced mini-batches to feed Transformer. We do not need mixed-type defect data in transformer training, but some mixed-type data are needed for testing to demonstrate the final accuracy. To get the mixed-type test samples, we ap- ply the following approach to build test datasets containing mixed-type defect pattern data. Firstly, among WM-811 K, we get samples of two different WBMs in six single-defect pattern categories including: Scratch, Loc, Donut,Cent"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_17", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 17, "text": "build test datasets containing mixed-type defect pattern data. Firstly, among WM-811 K, we get samples of two different WBMs in six single-defect pattern categories including: Scratch, Loc, Donut,Center, Edge-Ring, and Edge-Loc. We do not inspect mix-type about Fig. 4. Visualization of 20 categories of three-mixed different defect patterns (D: Donut, C: Center,ER: Edge-Ring, EL: Edge-Loc, L:Loc, S: Scratch.) Fig. 5. Visualization of 15 categories of four-mixed different defect patterns Table II. WBM classification Accuracy of test dataset including two-mixed defect pattern. Accuracy(%) ViTLite CVT CCT Swin LeViT Baseline 74.6 79.1 81.1 81.3 83.2 InputMixup 85.4 86.3 88.2 88.1 89 Cutmix 84.9 86.3 87.9 88 88.6 PuzzleMix 89.4 89.6 91 90.5 91.4 ManifoldMixup 85.7 86.9 88.2 87.4 89 UnionMix 85.6 86.4 89.2 88.1 90.1 TokenMix 86.2 87.4 88.9 88.1 90.2 MMSTM 89.1 90.1 92.1 91.2 92.5 Input-CutMix 88.3 89.3 90.1 89.7 91.3 Input-TokenMix 89.5 90.3 92.4 91.9 92.8 Union-TokenMix 90.4 91.6 93.1 92.5 93.4 Input-MMSTM 90.8 91.7 93.4 93.1 93.8 Union-MMSTM 91.7 92.1 93.8 94.3 94.7 Random and Near-Full for most of the time they dominate the map while mixing with any other types.Moreover, we synthesize"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_18", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 18, "text": "93.4 Input-MMSTM 90.8 91.7 93.4 93.1 93.8 Union-MMSTM 91.7 92.1 93.8 94.3 94.7 Random and Near-Full for most of the time they dominate the map while mixing with any other types.Moreover, we synthesize two WBMs to generate a mixed-type defect pat- tern WBM and then sort out and pick up the most realistic WBMs for test. So, we have 15 mixed-type defect patterns WBMs as illustrated in Fig.3. We chosen 200 wafer bin maps in each of 15 possible compositions of mixed-type defect patterns. At last, we examine our approach by test dataset consisting of 3000 samples. We also get 20 cate- gories samples of three mixed type patterns visualized in Fig.4. Similarly 15 categories of four mixed type samples visualized in Fig.5. 4 IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 Table III. WBM classification Accuracy of test dataset including two- mixed and three-mixed defect pattern. Accuracy(%) ViTLite CVT CCT Swin LeViT Baseline 65.3 66.3 70.1 69.1 70.4 InputMixup 78.2 81.2 84.3 84.2 85.3 Cutmix 77.5 80.1 82.4 83.6 84.2 PuzzleMix 80.8 81.9 82.7 83.4 84.9 ManifoldMixup 78.6 80.1 82.2 82.9 83.5 UnionMix 80.2 82.3 84.2 84.7 85.3 TokenMix 82.2 84.1 85.2 85.8 86.3 MMSTM 83.1 84.9 86.6 86.2 87.4 Input-C"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_19", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 19, "text": "80.1 82.4 83.6 84.2 PuzzleMix 80.8 81.9 82.7 83.4 84.9 ManifoldMixup 78.6 80.1 82.2 82.9 83.5 UnionMix 80.2 82.3 84.2 84.7 85.3 TokenMix 82.2 84.1 85.2 85.8 86.3 MMSTM 83.1 84.9 86.6 86.2 87.4 Input-CutMix 82.5 84.1 86.1 85.6 87.2 Input-TokenMix 84.3 85.2 86.8 87.1 87.4 Union-TokenMix 85.3 85.7 87.5 87.8 88.3 Input-MMSTM 86.2 87.1 88.7 89.2 89.8 Union-MMSTM 89.1 90.1 91.9 92.4 93.6 Table IV. WBM classification accuracy of test dataset including two- mixed, three-mixed, four-mixed defect pattern. Accuracy(%) ViTLite CVT CCT Swin LeViT Baseline 53.2 55.7 58.2 59.7 60.8 InputMixup 62.5 64.6 66.1 65.7 66.3 Cutmix 61.4 63.8 66.2 66.1 68.1 PuzzleMix 64.2 66.2 68.4 68.9 69.3 ManifoldMixup 62.5 64.3 66.8 67.4 69.1 UnionMix 62.8 64.7 66.3 67.1 68.6 TokenMix 64.1 65.8 67.8 66.9 68.9 MMSTM 66.8 68.3 70.4 69.8 71.2 Input-CutMix 69.3 70.2 72.5 72.1 73.6 Input-TokenMix 71.4 72.2 74.5 74.3 75.1 Union-TokenMix 73.5 75.2 77.8 77.5 78.9 Input-MMSTM 75.8 77.2 79.5 79.8 81.2 Union-MMSTM 77.9 82.8 86.5 87.3 89.1 4.2 Implementation Details We evaluate our method on several recent vision transformer architectures, including ViT Lite, Compact Vision Trans- former (CVT) [26], Compact Convolution Transforme"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_20", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 20, "text": "3 89.1 4.2 Implementation Details We evaluate our method on several recent vision transformer architectures, including ViT Lite, Compact Vision Trans- former (CVT) [26], Compact Convolution Transformer (CCT) [26], Swin Transformer [27], LeViT [28]. The batch size is set to 1024. We adopt AdamW [29] as the opti- mizer and set the learning rate as 0.001 with 5 warm-up epochs. The learning rate is decayed following a cosine scheduler down to 10‚àí6. Without other specification, we train the models for 300 epochs. For training architectures with smaller model sizes: ViT-Lite-6/4 [26], CVT-6/4 [26], CCT-7/3√ó1 [26], Swin-T [27], LeViT-192 [28]. Considering the mixed images are more likely to contain multiple labels, we adopt binary cross-entropy (BCE) loss rather than the cross-entropy (CE) loss [30, 31]. In order to examine the performance of Union Mixup and MMSTM, we try to com- bine MMSTM with other mixup algorithms, also try the combination of UnionMixup with other mixup methods. In TableII, Input-CutMix is the combination of inputMixup and CutMix. Similarly, Input-TokenMix is inputMixup + Token- Mixup, Union-TokenMix is UnionMixup + TokenMixup, and Union-MMSTM is UnionMixup + MMSTM. 4"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_21", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 21, "text": "I, Input-CutMix is the combination of inputMixup and CutMix. Similarly, Input-TokenMix is inputMixup + Token- Mixup, Union-TokenMix is UnionMixup + TokenMixup, and Union-MMSTM is UnionMixup + MMSTM. 4.3 Classification of mixed-defect pattern WBMs We apply the official code designed by the authors to execute the experiment of the state-of-the-art (SOTA) approaches Fig. 6. Compared with Baseline and single mixup algorithm, the accuracy gain of UnionMMSTM under different mixed-type datasets.(e.g. Com- pared with baseline(no mixup), the accuracy gain of UnionMMSTM based on ViTLite-6/4 under dataset containing 2-mixed type defect patterns is 17.1%) of mixup including: baseline network (none mixup), input mixup [6], CutMix [14], Manifold mixup [32], PuzzleMix [19], TokenMix[33] , our Union-Mixup and MMSTM. Us- ing top-1 accuracy(%) for judgement, we examine the ef- fectiveness of Union-Mixup and MMSTM in WBMs defect classification. WBMs defect classification of test dataset in- cluding two-mixed type defect samples are illustrated in TableII, UnionMixup performs better than the inputmixup and CutMix. When only consider single mixup algorithm, MMSTM achieves the highest recognition accura"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_22", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 22, "text": "ixed type defect samples are illustrated in TableII, UnionMixup performs better than the inputmixup and CutMix. When only consider single mixup algorithm, MMSTM achieves the highest recognition accuracy. While using two mixup algorithms, Union-MMSTM get the best performance in the classification of WBMs. Based on ViT- Lite-6/4, Union-MMSTM performs better than baseline by 17.1%. However, Union-MMSTM performs better than the method of only using sing mixup at least 1.7%. In addition, as shown in TableIII, when considering three-mixed type samples, Compared with none mixup and single mxiup, Union-MMSTM gain at least 21.8% and 5.2% respectively. Furthermore, in the classification including four-mixed type patterns, compared with none mixup and single mxiup, Union-MMSTM gain at least 24.7% and 11.1% respectively. As illustrated in Fig.6, when the mixed pattern become more complicated, our method make greater increment of classi- fication accuracy. It proves that Union-MMSTM works effi- cient in the defect classification of WBMs, especially when the defect pattern mixed. 5. Conclusion In this paper, we have proposed two mixup methods for training transformers based on single-defect patt"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_23", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 23, "text": "nt in the defect classification of WBMs, especially when the defect pattern mixed. 5. Conclusion In this paper, we have proposed two mixup methods for training transformers based on single-defect pattern data to classify mixed-type defect WBMs. In the early stage, Union- Mixup can be used to do the mixup of WBMs with low de- fect ratio. Later, MMSTM is applied during the training of Vision Transformer. Our approaches solve the difficulty of obtaining mixed-type defect training dataset of WBMs in the recognition of WBM defect patterns. In addition, we have proved that the combination of different mixup algorithms is 5 IEICE Electronics Express, Vol.VV, No.NN, 1‚Äì6 a very effective data augmentation method. Especially when the test data become more complicated with three or more mixed type patterns, the framework composed of Union- Mixup and MMSTM performs much more better than other approaches. Though the classification accuracy of WBMs has been improved by our methods, the time complexity of algorithm still need to be improved in the following research. So, the issue of how to guarantee the accuracy of classifi- cation of mixed-type WBMs without compromising speed and simplicity sti"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_24", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 24, "text": "ty of algorithm still need to be improved in the following research. So, the issue of how to guarantee the accuracy of classifi- cation of mixed-type WBMs without compromising speed and simplicity still need more efforts in the next step. Acknowledgments This work was supported by Fujian Province Program of Youth and Middle- aged Education under Grant(JAT210509). References [1] C.W. Liu and C.F. Chien, ‚ÄúAn intelligent system for wafer bin map defect diagnosis: An empirical study for semiconduc- tor manufacturing,‚Äù Engineering Applications of Artificial Intelligence, vol.26, no.5-6, pp.1479‚Äì1486, 2013. [2] C.F. Chien, C.Y. Hsu, and K.H. Chang, ‚ÄúOverall wafer effec- tiveness (owe): A novel industry standard for semiconductor ecosystem as a whole,‚Äù Computers and Industrial Engineer- ing, vol.65, no.1, pp.117‚Äì127, 2013. [3] J.C.H. Pan and D.H. Tai, ‚ÄúA new strategy for defect in- spection by the virtual inspection in semiconductor wafer fabrication,‚Äù Computers and Industrial Engineering, vol.60, no.1, pp.16‚Äì24, 2011. [4] I. Tirkel, ‚ÄúThe efficiency of inspection based on out of con- trol detection in wafer fabrication,‚Äù Computers and Industrial Engineering, vol.99, pp.458‚Äì464, 2016. [5] "}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_25", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 25, "text": "l.60, no.1, pp.16‚Äì24, 2011. [4] I. Tirkel, ‚ÄúThe efficiency of inspection based on out of con- trol detection in wafer fabrication,‚Äù Computers and Industrial Engineering, vol.99, pp.458‚Äì464, 2016. [5] Z. Kang, C. Catal, and B. Tekinerdogan, ‚ÄúMachine learn- ing applications in production lines: A systematic literature review,‚Äù Computers and Industrial Engineering, vol.149, p.106773, 2020. [6] H. Zhang, M. Cisse, Y.N. Dauphin, and D. Lopez-Paz, ‚Äúmixup: Beyond empirical risk minimization,‚Äù Int. Conf. Learning Representations, 2018. [7] K. Kyeong and H. Kim, ‚ÄúClassification of mixed-type de- fect patterns in wafer bin maps using convolutional neural networks,‚Äù IEEE Trans. on Semiconductor Manufacturing, vol.31, no.3, pp.395‚Äì402, 2018. [8] H. Lee and H. Kim, ‚ÄúSemi-supervised multi-label learning for classification of wafer bin maps with mixed-type defect patterns,‚Äù IEEE Trans. on Semiconductor Manufacturing, vol.33, no.4, pp.653‚Äì662, 2020. [9] Y. Hyun and H. Kim, ‚ÄúMemory-augmented convolutional neural networks with triplet loss for imbalanced wafer de- fect pattern classification,‚Äù IEEE Trans. on Semiconductor Manufacturing, vol.33, no.4, pp.622‚Äì634, 2020. [10] D. Zou, Y. Cao, Y. Li, and"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_26", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 26, "text": "nal neural networks with triplet loss for imbalanced wafer de- fect pattern classification,‚Äù IEEE Trans. on Semiconductor Manufacturing, vol.33, no.4, pp.622‚Äì634, 2020. [10] D. Zou, Y. Cao, Y. Li, and Q. Gu, ‚ÄúThe benefits of mixup for feature learning,‚Äù 2023. [11] H. Inoue, ‚ÄúData augmentation by pairing samples for images classification,‚Äù arXiv preprint arXiv:1801.02929, 2018. [12] Y. Tokozume, Y. Ushiku, and T. Harada, ‚ÄúLearning from between-class examples for deep sound recognition,‚Äù vol.abs/1711.10282, 2017. [13] T. Devries and G.W. Taylor, ‚ÄúImproved regulariza- tion of convolutional neural networks with cutout,‚Äù vol.abs/1708.04552, 2017. [14] S. Yun, D. Han, S. Chun, S.J. Oh, Y. Yoo, and J. Choe, ‚ÄúCut- mix: Regularization strategy to train strong classifiers withlocalizable features,‚Äù Int. Conf. Computer Vision), pp.6022‚Äì 6031, 2019. [15] E. Harris, A. Marcu, M. Painter, M. Niranjan, A. Pr¬® ugel- Bennett, and J.S. Hare, ‚ÄúUnderstanding and enhancing mixed sample data augmentation,‚Äù vol.abs/2002.12047, 2020. [16] C. Summers and M.J. Dinneen, ‚ÄúImproved mixed-example data augmentation,‚Äù vol.abs/1805.11272, 2018. [17] R. Takahashi, T. Matsubara, and K. Uehara, ‚ÄúRicap: Random image c"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_27", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 27, "text": "vol.abs/2002.12047, 2020. [16] C. Summers and M.J. Dinneen, ‚ÄúImproved mixed-example data augmentation,‚Äù vol.abs/1805.11272, 2018. [17] R. Takahashi, T. Matsubara, and K. Uehara, ‚ÄúRicap: Random image cropping and patching data augmentation for deep cnns,‚Äù Proc.10th Asian Conf. Machine Learning, ed. J. Zhu and I. Takeuchi, pp.786‚Äì798, PMLR, 14-16 Nov 2018. [18] J. Kim, W. Choo, H. Jeong, and H.O. Song, ‚ÄúCo-mixup: Saliency guided joint mixup with supermodular diversity,‚Äù vol.abs/2102.03065, 2021. [19] J. Kim, W. Choo, and H.O. Song, ‚ÄúPuzzle mix: Exploiting saliency and local statistics for optimal mixup,‚Äù Proc. 37th Int. Conf. Machine Learning, 2020. [20] J. Qin, J. Fang, Q. Zhang, W. Liu, X. Wang, and X. Wang, ‚ÄúResizemix: Mixing data with preserved object information and true labels,‚Äù vol.abs/2012.11101, 2020. [21] A.F.M.S. Uddin, M.S. Monira, W. Shin, T. Chung, and S. Bae, ‚ÄúSaliencymix: A saliency guided data augmenta- tion strategy for better regularization,‚Äù vol.abs/2006.01791, 2020. [22] B. Heo, S. Yun, D. Han, S. Chun, J. Choe, and S.J. Oh, ‚ÄúRethinking spatial dimensions of vision transformers,‚Äù Int. Conf. Computer Vision, pp.11916‚Äì11925, 2021. [23] T. Wang, L. Yuan, Y. Chen, J."}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_28", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 28, "text": "[22] B. Heo, S. Yun, D. Han, S. Chun, J. Choe, and S.J. Oh, ‚ÄúRethinking spatial dimensions of vision transformers,‚Äù Int. Conf. Computer Vision, pp.11916‚Äì11925, 2021. [23] T. Wang, L. Yuan, Y. Chen, J. Feng, and S. Yan, ‚ÄúPnp-detr: Towards efficient visual analysis with transformers,‚Äù Proc. Int. Conf. Computer Vision, 2021. [24] B. Roh, J. Shin, W. Shin, and S. Kim, ‚ÄúSparse DETR: ef- ficient end-to-end object detection with learnable sparsity,‚Äù vol.abs/2111.14330, 2021. [25] Y. Rao, W. Zhao, B. Liu, J. Lu, and C.J. Hsieh, ‚ÄúDynamicvit: Efficient vision transformers with dynamic token sparsifica- tion,‚Äù Proc. 35th Int. Conf. Neural Information Processing Systems. [26] A. Hassani, S. Walton, N. Shah, A. Abuduweili, J. Li, and H. Shi, ‚ÄúEscaping the big data paradigm with compact trans- formers,‚Äù vol.abs/2104.05704, 2021. [27] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, ‚ÄúSwin transformer: Hierarchical vision trans- former using shifted windows,‚Äù Int. Conf. Computer Vision, pp.9992‚Äì10002, 2021. [28] B. Graham, A. El-Nouby, H. Touvron, P. Stock, A. Joulin, H. J¬¥egou, and M. Douze, ‚ÄúLevit: a vision transformer in convnet‚Äôs clothing for faster inference,‚Äù Int. Conf. C"}
{"id": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf::chunk_29", "source": "UnionMixup and Max-Min-Saliency Mixup for Mixed-type Defect.pdf", "chunk_index": 29, "text": "sion, pp.9992‚Äì10002, 2021. [28] B. Graham, A. El-Nouby, H. Touvron, P. Stock, A. Joulin, H. J¬¥egou, and M. Douze, ‚ÄúLevit: a vision transformer in convnet‚Äôs clothing for faster inference,‚Äù Int. Conf. Computer Vision, pp.12239‚Äì12249, 2021. [29] D. Kingma and J. Ba, ‚ÄúAdam: A method for stochastic opti- mization,‚Äù Proc. 15th Int. Conf. Learning Representations. [30] L. Beyer, O.J. H ¬¥enaff, A. Kolesnikov, X. Zhai, and A. van den Oord, ‚ÄúAre we done with imagenet?,‚Äù vol.abs/2006.07159, 2020. [31] R. Wightman, H. Touvron, and H. J ¬¥egou, ‚ÄúResnet strikes back: An improved training procedure in timm,‚Äù vol.abs/2110.00476, 2021. [32] V. Verma, A. Lamb, C. Beckham, A. Najafi, A. Courville, I. Mitliagkas, and Y. Bengio, ‚ÄúManifold mixup: Better rep- resentations by interpolating hidden states,‚Äù 2019. [33] J.C. Hyeong Kyu Choi and H.J. Kim, ‚ÄúTokenmixup: Ef- ficient attention-guided token-level data augmentation for transformers,‚Äù Proc. 36th Int. Conf. Neural Information Pro- cessing Systems, 2022. 6"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_0", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 0, "text": "1 Variation-A wareSpeed Binning ofMulti-core Processors John Sartori\u0003,Aashish Pant¬Ü,RakeshKumar\u0003,Puneet Gupta¬Ü \u0003ECE Department, University ofIllinois atUrbana Champaign ¬ÜEEDepartment, University ofCalifornia atLosAngeles \u0003E-mail:sartori2@illinois.edu ¬ÜE-mail:apant@ee.ucla.edu Abstract ¬óNumber ofcoresper multi-cor eprocessor die, as well asvariation between themaximum operating frequency of individual cores,israpidly increasing .This makesperformance binning ofmulti-cor eprocessors anon-tri vialtask. Inthispaper , westudy ,forthe \u0002rst time, multi-cor ebinning metrics and strategies toevaluate them ef\u0002ciently .Wediscuss twomulti-cor e binning metrics with high correlation toprocessor throughput fordiffer enttypes ofworkloads and differ entprocess variation scenarios. Moreimportantly ,wedemonstrate the importance ofleveraging variation model data inthe binning process to signi\u0002cantly reduce thebinning overhead with anegligible loss inbinning quality .Forexample, wedemonstrate that the performance binning overhead ofa64-cor eprocessor can be decreased by51% and 36% using the proposed variation- awar ecoreclustering and curve\u0002tting strategies respecti vely. Experiments wereperformed usi"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_1", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 1, "text": "formance binning overhead ofa64-cor eprocessor can be decreased by51% and 36% using the proposed variation- awar ecoreclustering and curve\u0002tting strategies respecti vely. Experiments wereperformed using amanufacturing variation model based onreal65nm silicon data. Index Terms ¬óMulti-cor e,Binning, Performance, Process Vari- ations I.Introduction Performance (orspeed) binning refers totestprocedures to determine themaximum operating frequenc yofaprocessor . Itiscommon practice tospeed binprocessors forgraded pricing. Asaresult, eveninthepresence ofmanuf acturing process variation, processors canbedesigned atthetypical ¬ìcorners¬î, unlik eASICs, which aredesigned attheworst-case corners. Binning aprocessor also setstheexpectations forthe consumer about theperformance thatshould beexpected from theprocessor chip. Inthecase ofuniprocessors, theperformance ofaprocessor isstrongly correlated with itsfrequenc yofoperation. Asa result, processors havetraditionally been binned according to frequenc y[8].However,forchip multiprocessors, theappro- priate binning metrics aremuch less clear due totwomain considerations. 1)Ifbinning isdone according tothehighest common operating frequenc yofallcor"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_2", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 2, "text": "nc y[8].However,forchip multiprocessors, theappro- priate binning metrics aremuch less clear due totwomain considerations. 1)Ifbinning isdone according tothehighest common operating frequenc yofallcores (one obvious extension totheuniprocessor binning metric), good performance correlation ofthebinning metric would only beobserv ed when themaximum operating frequencies ofallcores areverysimilar .Wespeculate thatthisassumption will not hold true inthefuture based onthefollo wing observ ations. \u000fThe transition from multi-core tomany-core would mean severaltens tohundreds ofcores onasingledie.Inthiscase, allthecores areunlik elytohave similar maximum safe operating frequencies. \u000fWithscaling, technology process variation isin- creasing. There isnoobvious process solution to variability insight. ITRS [16]predicts that circuit performance variability will increase from 48% to 66% inthenexttenyears. Moreo ver,many-core diesizes may scale faster than geometric technol- ogy scaling [10],facilitated byfuture adoption of 450mm wafers and3Dintegration. Asaresult, core- to-core frequenc yvariation islikelytoincrease in coming technology generations. 2)The second reason why binning metrics may ne"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_3", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 3, "text": "ted byfuture adoption of 450mm wafers and3Dintegration. Asaresult, core- to-core frequenc yvariation islikelytoincrease in coming technology generations. 2)The second reason why binning metrics may need to bere-evaluated formulti-core processors isthatagood binning metric should notonly correlate well with the maximum performance ofthechip (inorder tomaximize producer pro\u0002ts andconsumer satisf action), butshould also haveacceptable time overhead forthebinning process. Asweshowinthis paper ,different binning metrics havedifferent binning overheads, andtherefore, thetradeof fbetween correlation toperformance and timing overhead should beevaluated carefully . Inthesimplest and most general form ofspeed binning, speed tests areapplied andoutputs arecheck edforfailure at different frequencies [29].The testing may bestructural or functional innature [5],[8],[9].The total testtime depends onthesearch procedure, thenumber ofspeed bins, andthe frequenc ydistrib ution oftheprocessor .Tothebest ofour knowledge, thisisthe\u0002rst workdiscussing speed binning in theconte xtofmulti-core processors. Inthispaper ,wemakethefollo wing contrib utions. \u000fWeexplore, forthe\u0002rsttime, speed binning intheconte "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_4", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 4, "text": "four knowledge, thisisthe\u0002rst workdiscussing speed binning in theconte xtofmulti-core processors. Inthispaper ,wemakethefollo wing contrib utions. \u000fWeexplore, forthe\u0002rsttime, speed binning intheconte xt ofmulti-core processors. \u000fWepropose twomulti-core binning metrics andquantify their correlation with absolute performance aswell as their testing time overheads forvarious kinds ofwork- loads. \u000fWedemonstrate that leveraging data from theprocess variation model canhaveasigni\u0002cant impact onbinning ef\u0002cienc yand propose several variation-a warebinning strate gies. Ourresults showthatvariation-a warebinning strate gies can reduce testing time signi\u0002cantly with little ornodegradation 2 inperformance correlation. II.Modeling Variation Anaccurate, physically justi\u0002able model ofspatial variabil- ityiscritical inreliably predicting and leveraging core-to- core variation inthebinning process. Though most design- end efforts tomodel spatial variation haveconcentrated on spatial correlation (e.g., [14],[15]),recent silicon results indicate that spatial dependence largely stems from across- wafer and across-\u0002eld trends [12].[6]assumes thesource ofcore-to-core variation tobelithography-dependen t"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_5", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 5, "text": "[14],[15]),recent silicon results indicate that spatial dependence largely stems from across- wafer and across-\u0002eld trends [12].[6]assumes thesource ofcore-to-core variation tobelithography-dependen tacross- \u0002eld variation. Though acontrib utor,across-\u0002eld variation issmaller compared toacross wafer variation [11](even more sowith strong RET and advanced scanners). Inlight ofthese facts, weuseapolynomial variation model [4]for chip delay ,similar tothose proposed in[11],[12],[13], having three components: (1)systematic (bowl-shaped) across wafer variation1;(2)random core-to-core variation (arising from random within-die variation); and(3)random die-to-die variation (e.g., from wafer-to-w afer orlot-to-lot variation). Vd(x;y)=A(Xc+x)2+B(Yc+y)2+C(Xc+x) (1) +D(Yc+y)+E(Xc+x)(Yc+y)+F+R+M where Vd(x;y)isthevariation ofchip delay atdielocation x;y; Xc;Ycarethewafercoordinates ofthecenter ofthedie((0;0) iscenter ofwafer); x;yarediecoordinates ofapoint within thedie; Misthedie-to-die variation and Ristherandom core-to-core variation. A;B;C;D;E;Fare\u0002tted coef\u0002cients for systematic across-w afer variation. Weusea\u0002tted model as abovebased onrealsilicon data froma65nm industrial process [4]2.Th"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_6", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 6, "text": "and Ristherandom core-to-core variation. A;B;C;D;E;Fare\u0002tted coef\u0002cients for systematic across-w afer variation. Weusea\u0002tted model as abovebased onrealsilicon data froma65nm industrial process [4]2.The goal ofthebinning process istoaccurately classify achip into oneofnbins (where nisdecided based onbusiness/economic reasons) inlight oftheabovevariation model. III.Binning Metrics Traditional uniprocessor binning strate gies, which sortchips according tomaximum operating frequenc y,may failtoade- quately characterize multicore processors, inwhich within die process variation givenbyEquation 1canbesubstantial. In thissection, wepropose anddiscuss twosimple binning met- ricsthatrecognize thefrequenc yeffects ofprocess variation. Weassume that individual cores aretestable andrunnable at independent operating frequencies [22],[23],[24],[25],[26], [27]though ourdiscussion and analysis would continue to hold inother scenarios. A.Min-Max andSf Min-Max stands fortheminimum ofthemaximum safe operating frequencies forvarious cores ofachip multipro- cessor .The min-max metric iscomputed using equation 2, where nrepresents thenumber offrequenc ybins, mrepresents 1Example physical sources ofacros"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_7", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 7, "text": "ating frequencies forvarious cores ofachip multipro- cessor .The min-max metric iscomputed using equation 2, where nrepresents thenumber offrequenc ybins, mrepresents 1Example physical sources ofacross-w afer bowl-shaped variation include plasma etch, resist spin coat, post exposure bake[4]. 2Forthismodel, mean =4GHz, sbowl=0:128GHz, sR=0:121GHz, sM= 0:09GHz.thenumber ofprocessor cores, and fijisasuccessful test frequenc yor0ifcore jfailstheithtest. min-max =min[max[fijjn i=1]jm j=1] (2) The second binning metric that weevaluate isSf.While frequenc yrepresents theprimary means ofincreasing the performance ofuniprocessors, newconventional wisdom dic- tates that theperformance ofmultiprocessors depends on increasing parallelism [17].Thus, ranking processors accord- ingtomaximum attainable aggre gate throughput represents a \u0002tting binning strate gy.Ideally ,aggre gate throughput should bemaximized when everycore operates atitsmaximum frequenc y.Consequently ,wecalculate theSfmetric using equation 3. Sf=m √• j=1max[fijjn i=1] (3) B.Corr elation toThroughput Interms ofcorrelation ofthemetric with thethroughput ofthechip, min-max isconserv ativeand therefore, should demonstrate good corre"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_8", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 8, "text": "equation 3. Sf=m √• j=1max[fijjn i=1] (3) B.Corr elation toThroughput Interms ofcorrelation ofthemetric with thethroughput ofthechip, min-max isconserv ativeand therefore, should demonstrate good correlation only forworkloads with reg- ular partitioning (parallel ormulti-threaded workloads) in which theload isdistrib uted evenly between allcores. For other workloads that haveinherent heterogeneity (multi- programmed workloads), Sfshould demonstrate good correla- tion, especially when runtimes aredesigned totakeadvantage oftheheterogeneity inherent insystems andthread character - istics. Infact,formulti-programmed workloads, themagnitude ofmiscorrelation between actual throughput andSfdepends ontheextent ofdisparity between theworkloads thatrunon various cores. One drawback ofSfisthatitmay increase the binning overhead, although weshowinthispaper thatutilizing knowledge ofvariation trends canhelp tokeeptheoverhead incheck. 0 10 20 30 40 50 60 700.70.750.80.850.90.9511.05 Number of BinsCorrelation to Throughput Sigma‚àíF, Multi‚àíprogrammed Min‚àímax, Multi‚àíprogrammed Sigma‚àíF, Multi‚àíthreaded Min‚àímax, Multi‚àíthreaded Fig. 1.Correlation ofmin-max andSftothroughput formulti-programmed andmulti-"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_9", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 9, "text": "rrelation to Throughput Sigma‚àíF, Multi‚àíprogrammed Min‚àímax, Multi‚àíprogrammed Sigma‚àíF, Multi‚àíthreaded Min‚àímax, Multi‚àíthreaded Fig. 1.Correlation ofmin-max andSftothroughput formulti-programmed andmulti-threaded workloads. Figure 1compares thecorrelation ofmin-max and Sfto actual throughput formulti-programmed and multi-threaded workloads using Monte-carlo simulations on100,000 dice, each diebeing a64core processor in65nm technology ona 300mm wafer (please refer tosection Vforfurther details on experimental setup). Itisevident thatSfisabetter metric for multi-programmed workloads while min-max performs better 3 formulti-threaded workloads formoderate tolargenumber ofbins. This isbecause theperformance ofmulti-threaded benchmarks depends onthespeed oftheslowest executing thread (because ofthread synchronizations inthebenchmarks) which isnicely captured bymin-max .Also, thecorrelation ofSfand min-max tothethroughput ofmulti-programmed and multi-threaded workloads respecti vely,converges to1 asymptotically with thenumber ofbins. This isbecause, \u0002ner binning granularity leads tomore precise estimation of maximum core frequencies. Conversely ,when thenumber of bins issmall, weobserv erathe"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_10", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 10, "text": " asymptotically with thenumber ofbins. This isbecause, \u0002ner binning granularity leads tomore precise estimation of maximum core frequencies. Conversely ,when thenumber of bins issmall, weobserv erather poor performance correlation forthemetrics. Tocompare thetwometrics, consider theasymptotic case ofverylargenand mand completely random core-to-core variation (i.e., A,B,C,D,E,F,Mallequal zero inequation 1). Inthissimpli\u0002ed case, Sfconvergestom\u0002mean frequency while min-max convergesto(E(Mini=1:::¬•fi)=0,i.e., for multi-programmed workloads, weexpect themin-max tobe aprogressi velyworse metric asthenumber ofcores inadie increases orthevariation increases. C.Binning Overhead The binning overhead depends onthe speci\u0002c testing methodology thatisused. Ononeextreme liesthecase where individual cores aretested one atatime and ontheother extreme isthecase where allcores aretested simultaneuosly inparallel. While thelatter reduces testtime compared tothe former ,itresults inhigher power consumption ofthecircuit during test. Witheverincreasing number ofcores within a multiprocessor ,parallel testing ofallcores leads toveryhigh testpower.Hence, testing isusually performed bypartitioning thedesig"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_11", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 11, "text": "n ofthecircuit during test. Witheverincreasing number ofcores within a multiprocessor ,parallel testing ofallcores leads toveryhigh testpower.Hence, testing isusually performed bypartitioning thedesign into blocks andtesting them oneatatime [2],[1], [3].Forourwork, weassume that cores aretested oneata time. Note thattheanalysis isalso extensible tocases where agroup ofcores aretested together inparallel. Tocalculate thebinning overhead formin-max onaproces- sorwith nfrequenc ybins andmcores, weusebinary search3 (i.e. frequenc ytests areapplied inabinary search fashion) to \u0002nd fmaxforeverycore. However,thesearch range willreduce progressi vely.The worstcase arises when fmaxforeverycore is1binsize less than thefmaxfound fortheprevious core. Inthiscase, theworst-case number oftests that need tobe performed canbecomputed as(log(n!)+m\u0000n)(assuming m\u0015n).The best case binning overhead formin-max would bemtests. Tofully evaluate theSfmetric, themaximum operating frequenc yofeach core must belearned. Using binary search, thisprocess performs, atworst, m\u0002logntests4.The best case isstillmtests. Wewill showtheaverage case runtime results ofboth these testing strate gies using monte-carlo analys"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_12", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 12, "text": "rned. Using binary search, thisprocess performs, atworst, m\u0002logntests4.The best case isstillmtests. Wewill showtheaverage case runtime results ofboth these testing strate gies using monte-carlo analysis. 3Inthiswork, weassume thatifacore works atacertain frequenc y,itis guaranteed toworkatalllowerfrequencies. This stems from thespeci\u0002c case ofusing binary search inconjunction with theminmax metric. Theconstraint canbeeasily avoided byadding onemore testpercore (i.e., testing itatthe minmax frequenc y) 4Note that thisexpression andtheexpressions corresponding tomin-max ignore thebias introduced inbinary search bytheprobability distrib ution of thefrequencies themselv es.Itshould benoted from theabovediscussion that the binning overhead forSfisalwaysequal toorhigher than that ofmin-max and this remains true evenwhen simple linear search (i.e. frequenc ytests areapplied inasimple linear fashion, which isthecase with most industrial testing schemes) isused instead ofbinary search. Moreo ver,the disparity between binning times formin-max andSfisnever higher forbinary search than forlinear search. Formin-max , theworst case overhead isontheorder ofn2and thebest case ismtests. ForSf,thewo"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_13", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 13, "text": "r,the disparity between binning times formin-max andSfisnever higher forbinary search than forlinear search. Formin-max , theworst case overhead isontheorder ofn2and thebest case ismtests. ForSf,theworstcase number oftests ison theorder ofm\u0002nandthebest case ismtests. This isalso showninFigure 2byperforming Monte-Carlo simulations on a64core multi-processor in65nm technology with a300mm wafer.Inthiswork, weusebinary search forcomparing test time overheads ofvarious binning strate gies butasexplained above,ourproposed analysis andresults will hold forlinear search aswell. 0 510 15 20 25 30 35102103 Number of BinsAverage Number of Tests Per Die Sigma‚àíF,Binary Sigma‚àíF,Linear Min‚àíMax,Binary Min‚àíMax,Linear Fig. 2. The increase inoverhead because oflinear search forfrequenc y binning ishigher forSfthan min-max . IV.Using theVariation Model toReduce Binning Overhead The binning metrics described above,aswell asthebin- ning strate gies forthose metrics, areagnostic oftheprocess variation model. Theoverhead ofbinning using those metrics, however,depends strongly ontheprocess variation model. In thissection, weadvocate theuseofvariation-a warebinning strate gies. Wearguethattheoverhead ofbinn"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_14", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 14, "text": " Theoverhead ofbinning using those metrics, however,depends strongly ontheprocess variation model. In thissection, weadvocate theuseofvariation-a warebinning strate gies. Wearguethattheoverhead ofbinning canbecon- siderably reduced bymaking thebinning strate gies variation model-a ware.The maximum safe operating frequenc y(fmax) ofacore canbestrongly predicted (i.e. mean with standard deviation around it)based ontheprocess variation model. Therefore, theprocess variation model can giveasmaller frequenc yrange within which thesearch should beperformed. A.Curve Fitting Wepropose curve\u0002tting asatechnique forreducing testing time overhead bytrimming therange offrequencies atwhich acore must betested. The curve-\u0002tting strate gyinvolves using thevariation model (equation 1)toapproximate the expected frequenc y(inGHz) aswell asthestandard deviation (=p (s2 M+s2 R))ofacore, givenitslocation within adieand dielocation within thewafer.Therefore, wecanidentify the center (=mean) aswell asthecorners (=+/-ks)ofanew, 4 tighter search range. Ifthecore falls outside ofthis range (decided byk),weassign thecore tothelowest frequenc ybin. Curv e\u0002tting reduces both theaverage andworst-case testing tim"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_15", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 15, "text": "rs (=+/-ks)ofanew, 4 tighter search range. Ifthecore falls outside ofthis range (decided byk),weassign thecore tothelowest frequenc ybin. Curv e\u0002tting reduces both theaverage andworst-case testing time foreach core. B.Clustering Another strate gyforreducing thebinning overhead canbe tocreate ahybrid metric which incorporates theadvantages of each oftheoriginal metrics ¬ñnamely ,thelowtesting overhead ofmin-max andthehigh performance correlation ofSf.This beha vior canbeachie vedbyclustering thecores inachip multiprocessor and then using min-max within theclusters (lowbinning overhead advantage) while using Sfoverall clusters (high correlation tomaximum throughput advantage). Tofurther reduce theoverhead ofbinning, aprocess likecurve \u0002tting canbeapplied, where theprocess variation model is used toidentify thesearch range forfmaxofacore. Werefer tothis combination ofclustering and curve\u0002tting assmart clustering Inorder toimpro vetheperformance correlation within thecluster and minimize thebinning overhead (especially when across-w afervariations arehigh), clusters canbechosen intelligently tominimize frequenc yvariation (and hence loss ofcorrelation) within acluster .Tothisend, theclu"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_16", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 16, "text": "ebinning overhead (especially when across-w afervariations arehigh), clusters canbechosen intelligently tominimize frequenc yvariation (and hence loss ofcorrelation) within acluster .Tothisend, thecluster sizecan besettobeinversely proportional tothespread offrequenc y mean (calculated from thebowl-shape inequation 1)within thecluster .Ingeneral, thedice close tothecenter ofthebowl (typically close tothecenter ofthewafer) willseelargecluster sizes, while clusters aresmaller forthedice closer totheedge ofthewafer.Wedonotevaluate variable clustering inthis paper due totherelati velylowacross-w afer variations that ourcurrent process variation models suggest. V.Methodology Wemodel chip multiprocessors with various numbers of cores onthediefordifferent technologies. Each core isa dual-issue Alpha 21064-lik ein-order core with 16KB, 2-way set-associati veinstruction cache anddata cache. Each core (1 mm2at65nm) onamultiprocessor hasaprivate1MB L2 cache (0:33MB=mm2at65nm). Weassumed agshare branch- predictor [7]with 8kentries forallthecores. The various miss penalties andL2cache access latencies forthesimulated cores were determined using CACTI [18].Wemodel thearea consumption oftheproces"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_17", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 17, "text": "ranch- predictor [7]with 8kentries forallthecores. The various miss penalties andL2cache access latencies forthesimulated cores were determined using CACTI [18].Wemodel thearea consumption oftheprocessors fordifferent technologies using themethodology in[19]. Weconsidered twotypes ofworkloads ¬ñmulti-programmed workloads andmulti-threaded workloads. Table Ilists theten benchmarks used forconstructing multi-programmed work- loads and thethree multi-threaded benchmarks. The bench- marks arechosen from different suites (SPEC, IBS, OOCSB, andMediabench) fordiversity .The parallel applications (CG, FT,MG) arechosen from theNASbenchmark suite andrun tocompletion. The class Bimplementations havebeen used. Multi-programmed workloads arecreated using thesliding windo wmethodology in[21].Formulti-programmed work- loads, theperformance ofamultiprocessor isassumed tobe thesum oftheperformance ofeach core ofthemultiprocessor ,TABLE I Benc hmarks used Program Description ammp Computational Chemistry (SPEC) crafty Game Playing: Chess (SPEC) eon Computer Visualization (SPEC) mcf Combinatorial Optimization (SPEC) twolf Place andRoute Simulator (SPEC) mgrid Multi-grid Solver:3DPotential Field (SPEC) "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_18", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 18, "text": "(SPEC) crafty Game Playing: Chess (SPEC) eon Computer Visualization (SPEC) mcf Combinatorial Optimization (SPEC) twolf Place andRoute Simulator (SPEC) mgrid Multi-grid Solver:3DPotential Field (SPEC) mesa 3-D Graphics Library (SPEC) groff Typesetting Package (IBS) deltablue Constraint Hierarchy Solver(OOCSB) adpcmc Adapti veDifferential PCM (MediaBench) CG Parallel Conjugate Gradient (NAS) FT Parallel FastFourier Transform (NAS) MG Parallel Multigrid Solver(NAS) derated byaconstant factor .The methodology isaccurate forourcase, where each core isassumed tohaveaprivate L2cache and amemory controller [19].The methodology wasshowntobereasonable forourbenchmarks evenfor processors with shared L2[19],duetothederating factor . After fast-forw arding anappropriate number ofinstruc- tions [20],multi-programmed simulations arerun for250 million cycles. Asmentioned before, parallel applications are runtocompletion. The frequenc yofeach core isdetermined bythevariation model. Simulations useamodi\u0002ed version of SMTSIM [21]. VI.Analysis ofResults Inthis section, wecompare thebinning metrics and the various evaluation strate gies interms oftheir overheads as well astheir correlation tothroughput"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_19", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 19, "text": "\u0002ed version of SMTSIM [21]. VI.Analysis ofResults Inthis section, wecompare thebinning metrics and the various evaluation strate gies interms oftheir overheads as well astheir correlation tothroughput. WerunMonte-Carlo simulations using 100,000 dice. Unless speci\u0002ed otherwise, each dieisa64-core processor (256 mm2)ina65nm tech- nology 300mm wafer,binned using 8frequenc ybins. Curve \u0002tting andsmart clustering useasearch range of\u00063s(where saccounts fortherandom dietodieandwithin dievariations), while Sfand thebaseline clustering approach search the entire frequenc yrange forfmax.Weusetheprocess variation model asdescribed byEquation 1,with sbowl=0:128GHz, sR=0:121GHz, sM=0:09GHz, based ona\u0002tted model from a65nm industrial process. A.Dependence onNumber ofBins Figure 3showshowbinning overhead and throughput correlation varywith thenumber offrequenc ybins formulti- programmed (Fig. 3(a)) andmulti-threaded (Fig. 3(b)) work- loads. Using 100,000 data points (processor dice), wecalculate correlation between theaverage ofthemaximum throughput ofthevarious workloads onaprocessor (where cores runat different frequencies dictated bythevariation model) andthe value ofthemetric when follo wing "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_20", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 20, "text": "elation between theaverage ofthemaximum throughput ofthevarious workloads onaprocessor (where cores runat different frequencies dictated bythevariation model) andthe value ofthemetric when follo wing agivenbinning strate gy. Note thatperformance ofathread often does notvarylinearly with frequenc yduetopipeline hazards, memory accesses, etc., soitisunlik elythat correlation will be1foranybinning metric. There areseveralthings tonote inthese graphs. 5 0.00.10.20.30.40.50.60.70.80.91.0 2 4 8 16 32 Number of binsCorrelation to Throughput . 050100150200250300Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average Number of Tests / Die (a)multi-programmed 0.00.10.20.30.40.50.60.70.80.91.0 2 4 8 16 32 Number of binsCorrelation to Throughput . 050100150200250300Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average Number of Tests / Die (b)multi-threaded Fig. 3. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),multi-programmed benchmarks and, (b)multi- threaded benchmarks, with varying number ofbins. \u000fFirst,Sfachieves signi\u0002cantly bette"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_21", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 21, "text": "s binning metrics toactual throughput and their binning overhead for(a),multi-programmed benchmarks and, (b)multi- threaded benchmarks, with varying number ofbins. \u000fFirst,Sfachieves signi\u0002cantly better correlation to throughput than min-max formulti-pr ogrammed work- loads .This isnotsurprising, considering thatthethrough- putofathread often depends onthefrequenc yofthecore itisrunning on,and formulti-programmed workloads, everythread execution isindependent. min-max failsto account forvariation infrequenc y(and therefore, average throughput) between individual cores. \u000fWhile thecorrelation ofmin-max tothroughput suffers formulti-programmed workloads, min-max actually sur- passes Sfformulti-thr eaded benc hmarks asthenumber ofbins increases .This isdue tothefactthat synchro- nization intheparallel benchmarks causes performance to beconstrained bytheslowest thread, since faster threads must waitatsynchronization points until allthreads have arrived. \u000fCorrelation isespecially lowforasmall number of frequenc ybins. This isbecause thebinning process picks0.750.800.850.900.951.00 16 64 256 Number of CoresCorrelation to Throughput . 0100200300400500600Thr(sigmaf) Thr(minmax) Thr(curve_fit"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_22", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 22, "text": " number of frequenc ybins. This isbecause thebinning process picks0.750.800.850.900.951.00 16 64 256 Number of CoresCorrelation to Throughput . 0100200300400500600Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average Number of Tests / Die (a)multi-programmed 0.910.920.930.940.950.960.970.980.991.00 16 64 256 Number of CoresCorrelation to Throughput . 0100200300400500600Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average number of tests / die (b)multi-threaded Fig. 4. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),multi-programmed benchmarks and, (b)multi- threaded benchmarks, with varying number ofcores inthemulti-processor . anoverly conserv ativefrequenc yasfmaxforadiein that case. Eventherelati veperformance ofmin-max (as compared toSf)worsens asthenumber offrequenc y bins isdecreased. \u000fInterms ofbinning overhead, min-max issigni\u0002cantly faster than Sf,especially forlargenumber ofbins (70% faster for32bins) .This isbecause while Sfinvolves doing binary search overthefullfrequenc yrange (over allfrequenc ybins) foreveryc"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_23", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 23, "text": "issigni\u0002cantly faster than Sf,especially forlargenumber ofbins (70% faster for32bins) .This isbecause while Sfinvolves doing binary search overthefullfrequenc yrange (over allfrequenc ybins) foreverycore, min-max progressi vely reduces thesearch range and requires veryfewtests percore, onaverage. minmax andSfhavecomparable overheads forsmall number ofbins since thesearch range isreduced. \u000fThe graph also showsthat curvefit(the approachof using variation model awar ecurve \u0002tting toapproximate Sf)hasperformance correlation tothroughput that is equivalent tothat ofSf.This isbecause arange of 6s(\u00063s)issearched forcurvefit,which isoften big 6 0.750.800.850.900.951.00 2 4 8 16 32 64 Number of Cores Per ClusterCorrelation to Throughput . 020406080100120140160 Average Testing Time / Die .Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Thr(smart clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Test(smart clust) (a)multi-programmed 0.900.910.920.930.940.950.960.970.980.991.00 2 4 8 16 32 64 Number of Cores Per ClusterCorrelation to Throughput . 020406080100120140160 Average Testing Time / Die .Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Thr(smart clust) Test(sigmaf) Test(m"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_24", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 24, "text": "16 32 64 Number of Cores Per ClusterCorrelation to Throughput . 020406080100120140160 Average Testing Time / Die .Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Thr(smart clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Test(smart clust) (b)multi-threaded Fig. 5. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),multi-programmed benchmarks and, (b)multi- threaded benchmarks, with varying number ofcores percluster .This just affects clustering andother plots areshownforreference. enough toallowthedisco veryofthetrue fmaxofacore. Interms ofbinning overhead, curvefitissigni\u0002cantly faster than Sf(36% forourbaseline architectur e).This isbecause therange offrequencies that aresearched forcurvefitisdirected bythevariation model and is therefore, relati velysmall. Overhead isgreater than that formin-max because oftheneed toestimate thefmaxfor everycore. \u000fClustering-based strategies (the approachofusing clus- tering toapproximate Sf)result inasmaller binning overhead than curvefit(26% forthebaseline ,results areshown foracluster sizeof16).Clustering thatrelies onthevariation model toreduce thesearch range for fmaxofthecores (smart cl"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_25", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 25, "text": "lt inasmaller binning overhead than curvefit(26% forthebaseline ,results areshown foracluster sizeof16).Clustering thatrelies onthevariation model toreduce thesearch range for fmaxofthecores (smart clust )isfaster than thenaive approach thatperforms search overthefullrange forall cores (6% impro vement intesttime forthebaseline case). Interms ofcorrelation tothroughput, clustering-based0.00.10.20.30.40.50.60.70.80.91.0 1-sigma 2-sigma 3-sigma 4-sigma Search RangeCorrelation to Throughput . 020406080100120140160Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Thr(smart clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Test(smart clust) Average Number of Tests / Die (a)8frequenc ybins 0.00.10.20.30.40.50.60.70.80.91.0 1-sigma 2-sigma 3-sigma 4-sigma Search RangeCorrelation to Throughput . 050100150200250300350Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Thr(smart clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Test(smart clust) Average Number of Tests / Die (b)64frequenc ybins Fig. 6. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),8bins and, (b)64bins, with varying search range. Here, srefers tototal standard "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_26", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 26, "text": "(b)64frequenc ybins Fig. 6. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),8bins and, (b)64bins, with varying search range. Here, srefers tototal standard deviation ofdie-to-die andcore-to-core variation. This justaffects variation-a warebinning strate gies andother plots areshownforreference. strate gies liebetween Sfand min-max forboth types ofworkloads. This isnotsurprising, considering that clustering represents ahybrid between thetwoschemes. B.Dependence onNumber ofCores Figure 4showshowcorrelation and binning overhead change with thenumber ofcores ontheprocessor dice. The results areshownfor16frequenc ybins. There areseveral things tonote from these graphs. \u000fFormulti-programmed workloads, the correlation to throughput increases with thenumber ofcores forboth clustering-based strate gies. Better correlation with more cores isaresult ofhaving a\u0002xedcluster size, which results inalargernumber ofclusters perchip (note that with more clusters, thegranularity ofclustering becomes \u0002ner). Tocon\u0002rm this, wealso performed experiments toseehowthecorrelation andbinning overhead change 7 0.00.10.20.30.40.50.60.70.80.91.0 Baseline Only Inter-Core"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_27", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 27, "text": "s, thegranularity ofclustering becomes \u0002ner). Tocon\u0002rm this, wealso performed experiments toseehowthecorrelation andbinning overhead change 7 0.00.10.20.30.40.50.60.70.80.91.0 Baseline Only Inter-Core RandomOnly Inter-Die RandomOnly Across- Wafer SystematicVariationsCorrelation to Throughput . 020406080100120140160Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average Number of Tests / Die (a)multi-programmed 0.00.10.20.30.40.50.60.70.80.91.0 Baseline Only Inter-Core RandomOnly Inter-Die RandomOnly Across- Wafer Systematic VariationsCorrelation to Throughput . 020406080100120140160Thr(sigmaf) Thr(minmax) Thr(curve_fit) Thr(clust) Test(sigmaf) Test(minmax) Test(curve_fit) Test(clust) Average Number of Tests / Die (b)multi-threaded Fig. 7. Correlation ofvarious binning metrics toactual throughput and their binning overhead for(a),multi-programmed benchmarks and, (b)multi- threaded benchmarks, fordifferent process variation scenarios. when thenumber ofcores percluster (and, therefore, thenumber ofclusters) ischanged fora\u0002xedsized chip (with 64cores). Figure 5showstheresults. Weindeed observ ethatthebinning overhead ofclustering "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_28", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 28, "text": "s. when thenumber ofcores percluster (and, therefore, thenumber ofclusters) ischanged fora\u0002xedsized chip (with 64cores). Figure 5showstheresults. Weindeed observ ethatthebinning overhead ofclustering decreases with increasing number ofcores percluster .Similarly ,the correlation tothroughput decreases formulti-programmed workloads with increasing cores perclusters. \u000fInterestingly ,theroles ofthemetrics arereversed for multi-programmed andmulti-threaded workloads. While Sfand curve\u0002tting dowell formulti-programmed workloads, min-max andclustering dobetter formulti- threaded workloads. This reversal canbeexplained by thefactthatSfandcurve\u0002tting (aclose approximation) characterize themaximum throughput ofadie,which is strongly correlated toperformance formulti-programmed workloads. However,when workload performance corre- lates more strongly totheperformance oftheweak est core, min-max wins out. Since clustering uses themin-max metric asitsbackbone, trends forclustering are similar tothose formin-max. \u000fAsthenumber ofcores percluster increases, weseean interesting difference between thetwotypes ofcluster - ingformulti-threaded benchmarks. Forclustering that bounds thesearchrangebased o"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_29", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 29, "text": "e formin-max. \u000fAsthenumber ofcores percluster increases, weseean interesting difference between thetwotypes ofcluster - ingformulti-threaded benchmarks. Forclustering that bounds thesearchrangebased onperceived variation (smart clust), throughput correlation levelsoffandbegins todecrease asthenumber ofcorespercluster becomes large.This isbecause thelimited search range may notbe wide enough tocapture thevariation range inalargeclus- ter.However,when theentire search range isconsidered, correlation continues toincrease evenasthenumber of cores percluster increases. This isbecause performance iscorrelated totheperformance oftheslowest core on thedieforourmulti-threaded benchmarks, and larger clusters result inlessover-estimation ofperformance for aprocessor running such benchmarks. C.Dependence onSearchRang eforVariation-Model Aware Appr oaches Figure 6showshowperformance correlation and binning overhead change asthesearch range isvaried for8and64fre- quenc ybins (weonly showtheresults formulti-programmed workloads asmulti-threaded benchmarks beha vesimilarly). Both techniques that rely onthevariation model tocome upwith aggressi vesearch ranges (curvefitandsmart clust) havebetter co"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_30", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 30, "text": "ormulti-programmed workloads asmulti-threaded benchmarks beha vesimilarly). Both techniques that rely onthevariation model tocome upwith aggressi vesearch ranges (curvefitandsmart clust) havebetter correlation asthesearch range isincreased. The impro vement ishigher forlargernumber offrequenc ybins. Forexample, when moving from 2sto3s,correlation to throughput forcurve\u0002tting impro vesby30% for64bins butjustby6%for8bins. However,theincrease inbinning overhead isalso higher foralargernumber ofbins. Therefore, unless thevariation islargeenough tojustify anincrease in thebincount, \u0002xed searchrangeof2sor3sisgood enough . D.Dependence onNatur eofVariations InFigure 7,weshowtheeffectthatthenature ofvariations hasonbinning metrics andtheir evaluation. The four cases: baseline (incorporates allvariation model components), only inter-corerandom ,only inter-die random ,and only across- wafer systematic (i.e., thebowl-shaped variation) allhave thesame variance. Aswithin-die (i.e. core-to-core) variation increases, thecorrelation ofmin-max tothethroughput of multi-programmed workloads decreases, since itgrossly un- derestimates throughput (because ittakestheminimum fmaxof allcores). However,for"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_31", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 31, "text": "iation increases, thecorrelation ofmin-max tothethroughput of multi-programmed workloads decreases, since itgrossly un- derestimates throughput (because ittakestheminimum fmaxof allcores). However,formulti-threaded workloads, Sfshows poor performance correlation when inter-core variation dom- inates, since itoverestimates thethroughput oftheprocessor . Therefore,increase inrandom coretocorevariation magni\u0002es thedifference between thetwometrics with theworkload types. This implies thatinsuchavariation scenario, choice ofmetric willstrongly depend ontheexpected workload type.Note that variation-a warebinning strate gies thatusethevariation model forprediction (i.e., curve\u0002tting) achie vemaximum reduction ofbinning overhead incases where there issystematic varia- tion (baseline andonly across-wafer systematic ). 8 VII.CONCLUSION Inthis paper ,wehavestudied forthe\u0002rst time, speed binning formulti-core processors. Wehavecompared two intuiti vemetrics ¬ñmin-max and Sf¬ñinterms oftheir correlation toactual throughput forvarious kinds ofwork- loads aswell astheir testing overheads. Furthermore, we haveproposed binning strate gies which leverage theextent of variation (clustering) aswell asth"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_32", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 32, "text": "ion toactual throughput forvarious kinds ofwork- loads aswell astheir testing overheads. Furthermore, we haveproposed binning strate gies which leverage theextent of variation (clustering) aswell asthepartially systematic nature ofvariation (curv e\u0002tting). From ouranalysis, weconclude thefollo wing \u000fInterms ofcorrelation toactual throughput, Sfisan overall better metric except fortwocases where min-max performs well: 1)multi-threaded benchmarks, with large number ofbins (largerthan 8)and, 2)multi-threaded benchmarks when within-die variations aredominant. However,min-max hasasigni\u0002cantly lowerbinning over- head than Sf(lowerbyasmuch as70%). \u000fClustering based strate gies which areahybrid ofSfand min-max reduce thebinning overhead byasmuch as51% with asmall loss (5% points for8bins) incorrelation to throughput. \u000fVariation-model awarestrate gies help inreducing the binning overhead signi\u0002cantly with thesame correlation tothroughput asSf.Variation awarecurve\u0002tting reduces thebinning overhead byasmuch as36%. Ouroverall conclusion isthatuniprocessor binning methods donotscale well formulti-core processors inthepresence of variations. Multi-core binning metrics and testing strate gies sho"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_33", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 33, "text": "ad byasmuch as36%. Ouroverall conclusion isthatuniprocessor binning methods donotscale well formulti-core processors inthepresence of variations. Multi-core binning metrics and testing strate gies should becarefully chosen tostrikeagood balance between goodness ofthemetric andtime required toevaluate it.Most importantly ,theef\u0002cienc yofspeed binning canbeimpro ved signi\u0002cantly byleveraging process variation knowledge to optimize thebinning procedure. Insome cases, power and memory/cache size arealso important binning metrics. Forlowpower embedded ap- plications where power isanequally important metric as performance, thesame notion ofbinning canbeemplo yedto categorize processors. Thevariation model canbeused tobin processors based onpowerdissipation. Theconcept ofvoltage binning [28][29]canbeextended formulticore processors by making useofsimilar techniques assuggested inthispaper . This ispart ofourongoing workonef\u0002cient characterization ofmulticore processors. VIII.Ackno wledgement Wewould liketothank Dr.Lerong Cheng fordiscussions onthevariability model. WorkatUIUC wassupported inpart byIntel, NSF,GSRC, andanArnold OBeckman Research Award. WorkatUCLA waspartly supported bySRC. "}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_34", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 34, "text": "Wewould liketothank Dr.Lerong Cheng fordiscussions onthevariability model. WorkatUIUC wassupported inpart byIntel, NSF,GSRC, andanArnold OBeckman Research Award. WorkatUCLA waspartly supported bySRC. REFERENCES [1]Girard, P.,¬ìSurv eyoflow-po wertesting ofVLSI circuits¬î, Design &Test ofComputer s,IEEE ,2002. [2]Y.Bonhomme, P.Girard, C.Landrault and S.Pravossoudo vitch, ¬ìTest Power: aBigIssue inLargeSOC Designs¬î, Electr onic Design, Testand Applications, IEEE International Workshop on,2002. [3]Nicolici, Nicola, Al-Hashimi andBashir M.,¬ìPower-Constrained Testing ofVLSI Circuits¬î, Series: Frontier sinElectr onic Testing ,2003.[4]L.Cheng, P.Gupta, K.Qian, C.Spanos, andL.He,¬ìPhysically Justi\u0002able Die-Le velModeling ofSpatial Variation inViewofSystematic Across Wafer Variability¬î, IEEE/A CMDAC,2009. [5]B.D. Cory ,R.Kapur andB.Underw ood, ¬ìSpeed Binning with PathDelay Testin150nm Technology¬î, IEEE Design &TestofComputer s,2003, pp.41-45. [6]E.Humenay ,D.Tarjan andK.Skadron, ¬ìImpact ofProcess Variations on Multicore Performance Symmetry¬î, Proc.IEEE/A CM DATE,2007, pp. 1653-1658. [7]S.McFarling, ¬ìCombining branch predictors¬î, Technical Report TN-36m, Digital Western Resear chLabor atory ,Jun"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_35", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 35, "text": "ariations on Multicore Performance Symmetry¬î, Proc.IEEE/A CM DATE,2007, pp. 1653-1658. [7]S.McFarling, ¬ìCombining branch predictors¬î, Technical Report TN-36m, Digital Western Resear chLabor atory ,June 1993. [8]D.Belete, A.Razdan, W.Schw arz, R.Raina, C.Hawkins and J. Morehead, ¬ìUse ofDFT Techniques inSpeed Grading a1GHz+ Mi- croprocessor¬î, Proc.IEEE ITC,2002, pp.1111-1118. [9]J.Zeng, M.Abadir ,G.Vandling, L.Wang, A.Kolhatkar andJ.Abraham, ¬ìOn Correlating Structural Testswith Functional TestsforSpeed Binning ofHigh Performance Design¬î, Proc.IEEE ITC,2004, pp.31-37. [10] S.Borkar ,¬ìDesign Challenges ofTechnology Scaling¬î, IEEE Micr o, 1999. [11] K.Qian and C.J. Spanos, ¬ìAComprehensi veModel ofProcess Vari- ability forStatistical Timing Optimization¬î, Proc.SPIE Design for Manufactur ability through Design-Pr ocess Integration ,2008. [12] P.Friedber g,W.Cheung andC.J.Spanos, ¬ìSpatial Modeling ofMicron- Scale Gate Length Variation¬î, Proc.SPIE Data Analysis and Modeling forProcess Contr ol,2006. [13] B.E. Stine, D.S. Boning andJ.E.Chung, ¬ìAnalysis andDecomposition ofSpatial Variation inIntegrated Circuit Processes andDevices¬î, IEEE Trans. Semiconductor Manufacturing ,10(1), 1997. [14] J"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_36", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 36, "text": "2006. [13] B.E. Stine, D.S. Boning andJ.E.Chung, ¬ìAnalysis andDecomposition ofSpatial Variation inIntegrated Circuit Processes andDevices¬î, IEEE Trans. Semiconductor Manufacturing ,10(1), 1997. [14] J.Xiong, V.Zoloto vandL.He,¬ìRob ustExtraction ofSpatial Correla- tion¬î, Proc.ACMISPD ,2006. [15] F.Liu, ¬ìAGeneral Frame workforSpatial Correlation Modeling inVLSI Design¬î, Proc.IEEE/A CMDAC,2007. [16] ITRS, 2007, http://public.itrs.net. [17] Asano vic, Krste and Bodik, Ras and Catanzaro, Bryan Christopher and Gebis, Joseph James and Husbands, Parry and Keutzer ,Kurtand Patterson, DavidA.and Plishk er,William Lester and Shalf, John and Williams, Samuel Webb and Yelick, Katherine A.,¬ìThe Landscape of Parallel Computing Research: AViewfrom Berk eley¬î,EECS Depart- ment, University ofCalifornia, Berk eley,2006. [18] S.J.E.Wilton andN.P.Jouppi, ¬ìCACTI: anenhanced cache access and cycle time model, ¬îIEEE Journal ofSolid-State Circuits,vol.31, pp.677¬ñ688, May 1996. [19] RakeshKumar andDean M.Tullsen, ¬ìCore architecture optimization forheterogeneous chip multiprocessors¬î, International Confer ence on Parallel Architectur esandCompilation Techniques, PACT,2006. [20] Timothy Sherw ood and Erez Per"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_37", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 37, "text": "n, ¬ìCore architecture optimization forheterogeneous chip multiprocessors¬î, International Confer ence on Parallel Architectur esandCompilation Techniques, PACT,2006. [20] Timothy Sherw ood and Erez Perelman and GregHamerly and Brad Calder ,¬ìAutomatically Characterizing LargeScale Program Beha vior¬î, ASPLOS, 2002. [21] D.M. Tullsen, ¬ìSimulation and Modeling ofaSimultaneous Multi- threading Processor¬î, 1996, 22nd Annual Computer Measur ement Group Confer ence. [22] J.Dorse y,etal.,¬ìAnIntegrated Quad-core Opteron Processor¬î, ISSCC 07,2007. [23] Herbert, S.andMarculescu, D.¬ìAnalysis ofDynamic Voltage/Frequenc y Scaling inChip-Multiprocessors¬î, ISLPED '07.2007. [24] C.Isci, etal,¬ìAnAnalysis ofEf\u0002cient Multi-Core Global PowerMan- agement Policies: Maximizing Performance foraGivenPowerBudget¬î, MICR O,2006. [25] Juang, etal.,¬ìCoordinated, Distrib uted, Formal EnergyManagement of Chip Multiprocessors¬î, ISLPED '05,2005. [26] J.Sartori and R.Kumar ,¬ìDistrib uted Peak Power Management for Many-core Architectures¬î, DATE'09,2009. [27] J.Sartori and R.Kumar ,¬ìThree Scalable Approaches toImpro ving Many-core Throughput foraGivenPeak PowerBudget¬î, HiPC '09,2009. [28] J.Tschanz, K.Bowman, andV.De,¬ìVa"}
{"id": "Variation-Aware Speed Binning of Multi-core.pdf::chunk_38", "source": "Variation-Aware Speed Binning of Multi-core.pdf", "chunk_index": 38, "text": " Architectures¬î, DATE'09,2009. [27] J.Sartori and R.Kumar ,¬ìThree Scalable Approaches toImpro ving Many-core Throughput foraGivenPeak PowerBudget¬î, HiPC '09,2009. [28] J.Tschanz, K.Bowman, andV.De,¬ìVariation-tolerant circuits: circuit solutions andtechniques¬î, DACACM,2005. [29] Paul, S.,Krishnamurthy ,S.,Mahmoodi, H.,and Bhunia, S,¬ìLow- overhead design technique forcalibration ofmaximum frequenc yat multiple operating points¬î, ICCAD ,2007."}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_0", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 0, "text": "Wafer-level Variation Modeling for Multi-site RF IC Testing via Hierarchical Gaussian Process Michihiro Shintani, Riaz-Ul-Haque Mian, and Michiko Inoue Graduate School of Science and Technology Nara Institute of Science and Technology 8916-5 Takayama-cho, Ikoma 630-0192, Japan Email: fshintani g@is.naist.jpTomoki Nakamura, Masuo Kajiyama, and Makoto Eiki Sony Semiconductor Manufacturing Corporation Nagasaki TEC 1883-43 Tsukuba-machi, Isahaya-shi, Nagasaki 854-0065, Japan Email: fTomoki.Nakamura,Masuo.Kajiyama, Makoto.Eiki g@sony.com Abstract ‚ÄîWafer-level performance prediction has been at- tracting attention to reduce measurement costs without compro- mising test quality in production tests. Although several efÔ¨Åcient methods have been proposed, the site-to-site variation, which is often observed in multi-site testing for radio frequency circuits, has not yet been sufÔ¨Åciently addressed. In this paper, we propose a wafer-level performance prediction method for multi-site testing that can consider the site-to-site variation. The proposed method is based on the Gaussian process, which is widely used for wafer- level spatial correlation modeling, improving the prediction ac- curacy by e"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_1", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 1, "text": " consider the site-to-site variation. The proposed method is based on the Gaussian process, which is widely used for wafer- level spatial correlation modeling, improving the prediction ac- curacy by extending hierarchical modeling to exploit the test site information provided by test engineers. In addition, we propose an active test-site sampling method to maximize measurement cost reduction. Through experiments using industrial production test data, we demonstrate that the proposed method can reduce the estimation error to 1=19of that obtained using a conventional method. Moreover, we demonstrate that the proposed sampling method can reduce the number of the measurements by 97% while achieving sufÔ¨Åcient estimation accuracy. I. INTRODUCTION Large-scale integrated circuits (LSIs) are now embedded in every product to support the smooth functioning of our daily lives. In addition to automobiles, healthcare, and aerospace, which are directly related to human life, the LSIs are uti- lized in social infrastructure that supports our daily lives, such as computer networks, power transmission systems, and transportation control systems. However, with the spread of the LSIs, their reliabilit"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_2", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 2, "text": "n social infrastructure that supports our daily lives, such as computer networks, power transmission systems, and transportation control systems. However, with the spread of the LSIs, their reliability has become a crucial issue, and faulty LSIs that do not operate properly not only interrupt the services of the systems that include them but also lead to a serious impact on our society. To guarantee the LSI reliability, multiple test items are tested and/or measured under various conditions during several stages of LSI manufacturing. With the increase in scale and multi-functionality of the LSIs, an increasing number of items need to be tested, leading to test cost inÔ¨Çation. Thus, it has become a serious problem because the test cost accounts for most of the LSI manufacturing cost. Various test cost reduction methods have been proposed that apply data analytics, machine learning algorithms, and statistical methods [1]‚Äì[3]. In particular, the wafer-level char- acteristic modeling method based on a statistical algorithm isthe most promising candidate that reduces the test cost, that is, measurement cost, without impairing the test quality [4]‚Äì [11]. In these studies, a statistical mo"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_3", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 3, "text": " based on a statistical algorithm isthe most promising candidate that reduces the test cost, that is, measurement cost, without impairing the test quality [4]‚Äì [11]. In these studies, a statistical modeling technique was used to predict the entire measurement on a wafer from a small number of sample measurements. Because the estimation eliminates the need for measurement, it not only reduces the cost of measurement but also can be used to reduce the number of test items and/or change the test limits, which is expected to improve the efÔ¨Åciency of adaptive testing [12]‚Äì[15]. In [4], the expectation-maximization (EM) algorithm [16] was used to predict the measurement. In [5]‚Äì[8], a statistical prediction method, called a virtual prove , based on compressed sens- ing [17], [18] was proposed. The Gaussian process (GP)-based method [19] provides more accurate prediction results [9]‚Äì [11]. The use of GP modeling has another side beneÔ¨Åt. As it calculates the conÔ¨Ådence of a prediction, the user can conÔ¨Årm whether the number and location of measurement samples are sufÔ¨Åcient, which is a signiÔ¨Åcant advantage from a practical viewpoint. Most of these methods assume that the device character- is"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_4", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 4, "text": " can conÔ¨Årm whether the number and location of measurement samples are sufÔ¨Åcient, which is a signiÔ¨Åcant advantage from a practical viewpoint. Most of these methods assume that the device character- istics on the wafer gradually change with wafer coordinates; however, this assumption does not hold for the measurement of radio frequency (RF) circuits under multi-site testing [20]‚Äì [22], in which a probe card is adapted to simultaneously probe multiple devices under test (DUTs). The contact of the probe card with the DUTs to be tested is called a touchdown . Moreover, the position of the needles in a touchdown is called asite. During the measurement of the RF circuit, a calibration circuit for impedance matching is added on the probe card, causing a much larger variation than the spatial variation due to its parasitic components, as shown in Fig. 1. Figure 1(a) shows the histograms of the characteristics of an industrial RF circuits, which are fabricated using a 28 nm process technology, measured by a multi-site test with 16 sites per measurement in the Ô¨Årst fabrication lot. The histograms are shown in different colors for each site. While low variance can be seen for each histogram, "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_5", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 5, "text": "measured by a multi-site test with 16 sites per measurement in the Ô¨Årst fabrication lot. The histograms are shown in different colors for each site. While low variance can be seen for each histogram, it is clear that there are signiÔ¨Åcant differences between the histograms, that is, differences in sites. Most of the existing methods fail to model this measurement result because of the discontinuous change between the sites. Regular Paper 1032021 IEEE International Test Conference (ITC) 978-1 -6654-1695-5 /21/$31.00 ¬©2021 IEEE DOI 10.1109/ITC50571.2021.000182021 IEEE International Test Conference (ITC) | 978-1-6654-1695-5/21/$31.00 ¬©2021 IEEE | DOI: 10.1109/ITC50571.2021.00018 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. 125 100 75 50 25 0Counts 0.0 0.2 0.4 0.6 0.8 1.0 Arbitrary unit(a)First lot 125 100 75 50 25 0Counts 0.0 0.2 0.4 0.6 0.8 1.0 Arbitrary unit (b)Sixth lot Fig. 1. Histograms of measured characteristics of industrial RF circuit on a wafer, measured by multi-site testing with 16 sites. The histograms of each site are shown with different colors, i.e., 16 histograms are pres"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_6", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 6, "text": "of measured characteristics of industrial RF circuit on a wafer, measured by multi-site testing with 16 sites. The histograms of each site are shown with different colors, i.e., 16 histograms are presented here. We can observe the signiÔ¨Åcant variations in the histogram between sites. Furthermore, the locations of the black histograms are much different between the early and latest lots. The horizontal axis is expressed in arbitrary unit. Only the work in [11] attempted to solve this issue of the discontinuous change. In [11], a two-step modeling method using k-means clustering [23] and the GP was proposed. In the Ô¨Årst step, all dies on a wafer are explicitly measured, and then the k-means clustering algorithm is applied to divide the measurements into kmeasurement groups, and the wafer coordinates are also clustered according to the k measurement groups. In the second step, for the subsequently fabricated wafers, a GP is applied to each cluster individually. Because the spatial variation is modeled according to the par- titioned magnitude of the measured value, even discontinuous changes can be reproduced accurately. In addition, there is a method [24] dealing with variations betwe"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_7", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 7, "text": "on is modeled according to the par- titioned magnitude of the measured value, even discontinuous changes can be reproduced accurately. In addition, there is a method [24] dealing with variations between the sites. In [24], in order to set outlier limits in a test, there is a method of eliminating the variation between sites by normalizing each site [24]. However, it is difÔ¨Åcult to set the normalization constant appropriately in small sampling, and thus it is difÔ¨Åcult to apply the site normalization to the wafer-level modeling. However, this method relies heavily on the assumption that the k-means clustering results obtained from the Ô¨Årst wafer are applicable to all subsequent lots. In fact, some site histograms drastically change in the latest fabrication lot, as shown in Fig. 1(b), which is the histograms in the sixth lot. For example, the highlighted black histogram should belong to a different cluster than that shown in Fig. 1(a) to achieve accurate prediction. While the possibility of recalibrating k- means clustering is described brieÔ¨Çy, no speciÔ¨Åc solution has been provided in [11].Herein, we propose a novel wafer-level spatial variation modeling method for RF circuits under "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_8", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 8, "text": " of recalibrating k- means clustering is described brieÔ¨Çy, no speciÔ¨Åc solution has been provided in [11].Herein, we propose a novel wafer-level spatial variation modeling method for RF circuits under multi-site testing. Test engineers usually have the site information of the probing; thus, we exploit it as a cluster in the proposed method, to predict spatial variation through the hierarchical GP modeling of each site. Therefore, the proposed method requires no clustering algorithm and no measurement corresponding to the Ô¨Årst step. The use of site information is straightforward, but it is efÔ¨Åcient under multi-site testing. Because the characteristics measured within one cluster have the same additional parasitic components of the calibration circuit, only spatial changes on the wafer are modeled; as a result, using the proposed method, accurate modeling can be achieved even across wafers. We also propose an active sampling method based on active learning [25] while considering the measurement of multi- site testing. Through the active sampling method utilizing the predictive variance of each site, the proposed method achieves optimal estimation with a small number of measured sample"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_9", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 9, "text": "rement of multi- site testing. Through the active sampling method utilizing the predictive variance of each site, the proposed method achieves optimal estimation with a small number of measured samples. The main contributions of this work are summarized as follows: \u000fHierarchical GP modeling using site information: Our method enables us to accurately model the spatial correlation on the wafer even for the measurement of RF circuits with the discontinuous changes for any lots by applying the GP separately to the correct clusters obtained from the site information. \u000fActive sampling algorithm under multi-site testing environment: We propose an efÔ¨Åcient sampling algo- rithm based on the predictive variance of the estimation to determine the sample location. \u000fComparison with the conventional method using industrial production data: We experimentally con- Ô¨Årm that the assumption of the two-step modeling method [11], where the k-means clustering result can be applicable for subsequent wafers, does not hold in a more miniaturized fabrication process. We also demonstrate that the proposed method can reduce the prediction error to an average of 1=19:4compared to that obtained using the two-st"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_10", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 10, "text": "does not hold in a more miniaturized fabrication process. We also demonstrate that the proposed method can reduce the prediction error to an average of 1=19:4compared to that obtained using the two-step modeling method. \u000fThorough evaluation of the proposed active location selection algorithm: The experimental results also show that the proposed sampling method successfully reduces the number of touchdowns compared to the random sam- pling method without sacriÔ¨Åcing the prediction accuracy. To the best of our knowledge, this is the Ô¨Årst study to successfully demonstrate spatial variation modeling in a multi-site testing environment. The remainder of this paper is organized as follows. Sec- tion II brieÔ¨Çy explains GP, which plays a central role in the proposed method. In addition, we review the existing wafer-level spatial variation modeling based on the two-step approach [11], as a previous work. Then, in Section III, a hierarchical GP based on site information and an active sampling method for multi-site testing are proposed. The experimental results using industrial production test data of RF IC fabricated by a 28 nm process technology are presented Regular Paper104 Authorized lice"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_11", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 11, "text": "hod for multi-site testing are proposed. The experimental results using industrial production test data of RF IC fabricated by a 28 nm process technology are presented Regular Paper104 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. Algorithm 1Gaussian process regression Input: Training dataset: (Xtrain;ytrain), Test dataset: Xtest, Kernel function: fkern Output: Mean and variance of predicted values: \u0016= (\u00161; \u00162;\u0001 \u0001 \u0001; \u0016M)andv= (v1; v2;\u0001 \u0001 \u0001; vM) 1:forn= 1toNdo 2: forn‚Ä≤= 1toNdo 3: Calculate (n; n‚Ä≤)-th element of a kernel matrix Z asfkern(xn;x‚Ä≤ n) 4: end for 5:end for 6:Calculate Ô¨Åtting parameters of fkernto Ô¨Åt (Xtrain;ytrain) 7:form= 1toMdo 8: forn= 1toNdo 9: Calculate n-th element of z\u0003asfkern(xn;x\u0003m) 10: end for 11: z\u0003\u0003=fkern(x\u0003m;x\u0003m) 12: Append \u0016m=zT \u0003Z\u00001ytrain to\u0016 13: Append vm=z\u0003\u0003\u0000Z\u00001z\u0003tov 14:end for inSection IV to quantitatively evaluate the effectiveness of the proposed method by comparing it with conventional methods. Finally, we conclude the paper in Section V. II. P RELIMINARIES A. Gaussian process First, we quickly review a GP [19], which is an integral part of the convention"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_12", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 12, "text": "paring it with conventional methods. Finally, we conclude the paper in Section V. II. P RELIMINARIES A. Gaussian process First, we quickly review a GP [19], which is an integral part of the conventional method [11] and our method. The GP model is used for estimating the function y=f(x) from the input variable xto the output variable y, which is often used for regression. In the GP model, the function fis assumed to follow a multidimensional normal distribution and is expressed as f\u0018 N(0;Z)using a kernel matrix Z. One of its advantages is its ability to deal with nonlinear estimation problems. Another important advantage is the use of Bayesian inference [26]. Because the estimated function is obtained as a distribution of functions, not as a single function, the uncertainty of the estimation can be expressed as a predictive variance. The outline of a GP-based multiple regression is summarized in Algorithm 1. We consider (Xtrain;ytrain) = f(x1; y1);(x2; y2);\u0001 \u0001 \u0001;(xN; yN)g andXtest= (x\u00031;x\u00032;\u0001 \u0001 \u0001;x\u0003M)as the training and test datasets, respectively, where M‚â´N. In addition, a kernel function fkern is given as an input. Using the predicted model fcalculated based on (Xtrain;ytrain), th"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_13", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 13, "text": ";x\u00032;\u0001 \u0001 \u0001;x\u0003M)as the training and test datasets, respectively, where M‚â´N. In addition, a kernel function fkern is given as an input. Using the predicted model fcalculated based on (Xtrain;ytrain), the algorithm returns the mean values and variances of the predicted y\u0003= (y\u0003 1; y\u0003 2;\u0001 \u0001 \u0001; y\u0003 M)forXtest,\u0016= (\u00161; \u00162;\u0001 \u0001 \u0001\u0016M)and v= (v1; v2;\u0001 \u0001 \u0001vM). In lines 1 to 5, the kernel matrix Zof the training dataset is calculated for each element of Xtrain using the kernelfunction. Subsequently, in lines 7 to 14, the probability den- sity function of the predicted y\u0003 mcorresponding to x\u0003mis derived by modeling a multidimensional normal distribution as follows: p(y\u0003 mjx\u0003 m;Xtrain;ytrain) (1) =N(zT \u0003Z\u00001ytrain;z\u0003\u0003\u0000zT \u0003Z\u00001z\u0003); where z\u0003andz\u0003\u0003are the covariances between the training and test datasets and between the test datasets, respectively. As can be seen in Eq. (1), the mean value and variance of y\u0003 m can be analytically derived. The expected values are used in the prediction, but the variances can also be used to conÔ¨Årm the uncertainty of the prediction. There are several kernel functions, such as the linear, squared exponential, and Mat ¬¥ern kernels. For example, the radial basis function (RB"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_14", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 14, "text": " also be used to conÔ¨Årm the uncertainty of the prediction. There are several kernel functions, such as the linear, squared exponential, and Mat ¬¥ern kernels. For example, the radial basis function (RBF) kernel is as follows [27], [28]: fkern(x;x‚Ä≤) =\u00121exp( \u0000(x\u0000x‚Ä≤)2 \u00122) ; (2) where \u00121and\u00122arethe Ô¨Åtting parameters calculated using an iterative optimization routine, as shown in line 6. As Z is a variance-covariance matrix, when xandx‚Ä≤are close, fkern(x;x‚Ä≤)becomes large and, as a result, f(x)andf(x‚Ä≤) are also close. The predictive mean \u0016is used in wafer-level characteristics modeling. It can be expected that GP regression can be incorporated into the wafer-level spatial variation modeling in IC characteristics with high afÔ¨Ånity, as the characteristics of adjacent dies on the wafer are similar because of the systematic components of process variation [29], [30]. B. Related work Owing to the intensive research on wafer-level spatial variation correlation modeling, the prediction accuracy of the spatial measurement variation has been improved, thereby, enabling the successful reduction of measurement costs in production tests [4]‚Äì[11]. Among others, in [11], a two- step modeling approach h"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_15", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 15, "text": "he spatial measurement variation has been improved, thereby, enabling the successful reduction of measurement costs in production tests [4]‚Äì[11]. Among others, in [11], a two- step modeling approach has been proposed to handle the discontinuous effect induced by multi-site testing and reticle shot, etc., in wafer-level modeling. The objective of the Ô¨Årst step is to partition the wafer into kgroups, which reÔ¨Çect the klevels of wafer measurement induced by discontinuous effects. For this purpose, the k- means algorithm is exploited as follows: y=fy(1);y(2);\u0001 \u0001 \u0001;y(k)g; (3) where yrepresents the vector of the measured characteristics of all the dies on the wafer. Consequently, Xcorresponding toyis partitioned as: X=fX(1);X(2);\u0001 \u0001 \u0001;X(k)g: (4) Note that Eq. (4) indicates that the coordinates on the wafer are divided according to the measured characteristics. Once thekclusters are identiÔ¨Åed, in the second step for subsequent wafers, the GP is applied to each cluster individually based on Algorithm 1. Because the changes in each y(k)can be Regular Paper105 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restricti"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_16", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 16, "text": "gorithm 1. Because the changes in each y(k)can be Regular Paper105 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. Lot ID0.00.20.40.60.81.0Arbitrary unit Fig.2. Measured characteristics of 16 sites from the Ô¨Årst lot to the sixth lot. The solid lines and shaded regions represent the means and the three standard deviations of the variations, respectively. The vertical axis denotes arbitrary units. expected to be smooth, the GP regression will work success- fully, and thus the two-step approach can handle discontinuous changes. Note that determining the optimal kis not trivial. Although several methods, such as silhouette value [31] and the elbow method [32], are well known to determine optimal k, in [11], kis determined based on the following equation: k= arg max gCH(g); (5) where CH(g)is the Calinski and Harabasz index when g clusters are considered [33]. However, the two-step modeling is not always applicable because it keeps using the kclusters for subsequent wafers, assuming that the content of the clusters will not change for other wafers/lots. Because the experiment in [11] uses the "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_17", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 17, "text": " always applicable because it keeps using the kclusters for subsequent wafers, assuming that the content of the clusters will not change for other wafers/lots. Because the experiment in [11] uses the industrial data fabricated using a relatively mature process technology, the assumption might hold true; in contrast, for our production data on immature process technology, the process is inapplicable, as shown in Fig. 1. Another observation in Fig. 1 is shown in Fig 2. In this Ô¨Ågure, the measured characteristics for each site are shown as functions of the lot ID from the Ô¨Årst lot to the sixth lot. Here, the Ô¨Årst wafer is used for each lot. The lines and shaded regions represent the mean and three standard deviations of each site, respectively. It can be seen that the distributions within the site are comparatively maintained up to the Ô¨Årst two lots; however, they Ô¨Çuctuate greatly from the third lot. This suggests that the two-step modeling may work well up to the Ô¨Årst two lots, whereas the clusters need to be recalibrated for the third and sixth lots, thus resulting in additional measurement costs. In addition, the early stage lots generally have low production yields, making it difÔ¨Å"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_18", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 18, "text": "he clusters need to be recalibrated for the third and sixth lots, thus resulting in additional measurement costs. In addition, the early stage lots generally have low production yields, making it difÔ¨Åcult to apply the two-step modeling method. III. W AFER -LEVEL VARIATION MODELING FOR RF IC UNDER MULTI -SITE TESTING We propose a novel spatial variation model based on the site information provided by test engineers, which can give us the correct cluster without applying clustering algorithms.Algorithm 2Site-based hierarchical spatial variation modeling Input: \u0016andvTraining dataset: (Xtrain;ytrain)measured under multi-site testing, Test dataset: Xtest, Kernel func- tion:fkern, site information Output: Mean and variance of predicted values: \u0016= (\u00161; \u00162;\u0001 \u0001 \u0001; \u0016M)andv= (v1; v2;\u0001 \u0001 \u0001; vM) 1:Cluster (Xtrain;ytrain)andXtestintoSgroups according to the site information 2:fors= 1toSdo 3: \u0016(s),v(s)= gpr( (X(s) train;y(s) train);X(s) test; fkern) 4:end for 5:Concatenate all \u0016(s)andv(s)into\u0016andv TheGP-based prediction is hierarchically performed for each site cluster. Site-to-site variations are caused by parasitic components in the calibration circuit during multi-site testing. Ideally, they s"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_19", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 19, "text": "eGP-based prediction is hierarchically performed for each site cluster. Site-to-site variations are caused by parasitic components in the calibration circuit during multi-site testing. Ideally, they should be eliminated during measurement, which is impractical due to the design and manufacturing costs of the probe card. They also can be solved by considering them one at a time, but the beneÔ¨Åts of multi-site testing cannot be obtained. The proposed method applies hierarchical GP mod- eling by clustering using site information and achieves highly accurate modeling while considering the actual measurement environment. As observed in Fig. 2, the measurements at the same site have a small deviation. The site-based hierarchical clustering can always be expected to be a good model without recalibration. In addition, we propose an active sampling algorithm to achieve a small sampling ratio based on variance computed by GP-based regression in a multi-site testing environment. In contrast to all the existing studies that assume sampling one at a time, the proposed algorithm can effectively reduce the measurement cost. A. Modeling based on site-based hierarchical GP Algorithm 2 presents the p"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_20", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 20, "text": " the existing studies that assume sampling one at a time, the proposed algorithm can effectively reduce the measurement cost. A. Modeling based on site-based hierarchical GP Algorithm 2 presents the proposed spatial correlation mod- eling through a site-based hierarchical GP in detail. We assume that the measurement is conducted by multi-site testing. The distinction from the conventional method is that the clus- tering is performed according to the site information in a single touchdown as listed in line 1, i.e., the conventional method needs to measure the characteristics of an entire wafer, whereas the proposed method requires no measurement for clustering. In Algorithm 2, Srepresents the number of the sites in a single touchdown, and the training and test datasets are grouped into Sgroups as follows: (Xtrain;ytrain) =f(X(1) train;y(1) train);(X(2) train;y(2) train); \u0001 \u0001 \u0001;(X(S) train;y(S) train)g (6) and Xtest=fX(1) test;X(2) test;\u0001 \u0001 \u0001;X(S) testg; (7) Regular Paper106 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. Single touchdown MeasuredSite information12 34(a)Eight sampled touch"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_21", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 21, "text": "icensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. Single touchdown MeasuredSite information12 34(a)Eight sampled touchdown locations in multi- site testing Training PredictedTraining Predicted Training PredictedTraining Predicted1 2 4 3 (b)Modeling and prediction using hierarchical GP regression (c)All-site concatenation Fig. 3. Example of the site-based hierarchical GP regression, where a single touchdown has four sites. respectively. The GP-based regression is performed individu- ally by modeling each site hierarchically as listed in lines 2 to 4 based on the gprfunction listed in Algorithm 1, where the mean and variance of the prediction for the test dataset are returned. Finally, the prediction result for the entire wafer is obtained through the concatenation of each prediction result. Figure 3 depicts an example of the modeling using the proposed method when S= 4 (sites 1 to 4). First, the eight positions are selected and measured as the training as shown in Fig. 3(a). In total, 32 dies ( = 8\u00024) are measured using the eight touchdowns. Then, according to the site, the GP- based modeling and predi"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_22", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 22, "text": "tions are selected and measured as the training as shown in Fig. 3(a). In total, 32 dies ( = 8\u00024) are measured using the eight touchdowns. Then, according to the site, the GP- based modeling and prediction are individually applied, as in Fig. 3(b). In other words, for site 1, the measured value belonging to site 1 is used as training data to build a GP model, and the measured value of the unmeasured die belonging to site 1 is predicted. The measurements and predictions for theAlgorithm 3Active location selection with site-based hierar- chical Gaussian process regression 1:\u0016,v=hgpr((Xtrain;ytrain);Xtest; fkern) 2:forp= 1toPdo 3: \u0016p,vp= hgpr( Xtrain+X(p) add;Xtest; fkern) 4: Calculate the Euclidean distance between vandvpas ‚àÜ(p) var 5:end for 6:Select Xpwith the largest ‚àÜ(p) varas the next touchdown location other sites are also similar. The entire prediction result is obtained through the concatenation as shown in Fig. 3(c). B. Active sampling under the multi-site testing In the wafer-level spatial modeling, it is desirable to be given a small input training dataset to maximize the cost reduction of the measurement. In [10], an aggressive sampling method that preferentially measures"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_23", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 23, "text": "evel spatial modeling, it is desirable to be given a small input training dataset to maximize the cost reduction of the measurement. In [10], an aggressive sampling method that preferentially measures the location with the largest predictive variance calculated by the GP regression is proposed. In addition, in [7], a Latin hypercube sampling approach [34] is employed to evenly choose random sample points over the entire wafer. However, these methods are straightforward, and most importantly, they do not consider multi-site testing environment. A good model should be one with a small error between the model and the actual measurement. The mean squared error (MSE) against the test dataset can be expressed as: EMSE=jjvjj+jj\u0016\u0000ytruejj2; (8) where jj \u0001 jj is the Euclidean norm, and ytrueis the correct value at the location of Xtestand unknown, i.e., unmeasured value. Assuming that the model is correct, the contribution of the second term in Eq. (8) to EMSE is small compared to the variance contribution, that is, the Ô¨Årst term. Thus, to minimize EMSE, we have to select Xsuch that the overall variance of the estimator is minimized [25]. Based on the aforementioned discussion, we propose an"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_24", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 24, "text": "ontribution, that is, the Ô¨Årst term. Thus, to minimize EMSE, we have to select Xsuch that the overall variance of the estimator is minimized [25]. Based on the aforementioned discussion, we propose an active sampling method as outlined in Algorithm 3, which is incorporated into the site-based hierarchical spatial modeling (hgpr) shown in Algorithm 2. The proposed sampling method focuses on the Euclidean distance between before and after measurements. The proposed method proceeds as follows. The numbers on the left indicate the corresponding line numbers in Algorithm 3. 1) Calculate \u0016andvthrough the hierarchical GP regres- sion using (Xtrain;ytrain)andXtestas in Algorithm 2. Xtrain can be obtained through multi-site testing. 2) Repeat steps 3) and 4) for all touchdown location candi- dates. Here, the p-th touchdown candidate has X(p) test= fx\u0003(p) 1;x\u0003(p) 2;\u0001 \u0001 \u0001;x\u0003(p) Sgwith the Ssites. Regular Paper107 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. DIE_XDIE_Y 0.00.20.40.60.81.0Fig. 4. Heat map of fully measured characterization. The measured values are normalized. 1 2 3 4 5 6 7 8 910111"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_25", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 25, "text": ",2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. DIE_XDIE_Y 0.00.20.40.60.81.0Fig. 4. Heat map of fully measured characterization. The measured values are normalized. 1 2 3 4 5 6 7 8 910111213141516 Fig.5. Single touchdown with 16 sites in our multi-site testing. 3) Add the touchdown candidate X(p) addby assuming it as measured and perform the hierarchical GP re- gression. Note that because it is not actually mea- sured, we assume the mean values are measured as X(p) add=f(x\u0003(p) 1; \u0016(p) 1);(x\u0003(p) 2; \u0016(p) 2);\u0001 \u0001 \u0001;(x\u0003(p) S; \u0016(p) S)g, where \u0016(p) Sis the predicted mean corresponding to x\u0003(p) S, and is one of the elements of \u0016given by hgpr in step 1). In this step, \u0016pandvpare obtained as in step 1). 4,5) Calculate the Euclidean distance of vandvpas‚àÜ(p) var. Note that steps 2) to 5) are iterated for all the touchdown candidates. 6) Select Xpwith the largest ‚àÜ(p) varas the next measurement location. The mentioned procedure is iterated until an exit condition is satisÔ¨Åed, for example, a sufÔ¨Åcient number of iterations are obtained. Because the reduction of the whole deviation for the test dataset is compared in step 6), a more accurate modeling can be expected with a smaller num"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_26", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 26, "text": "le, a sufÔ¨Åcient number of iterations are obtained. Because the reduction of the whole deviation for the test dataset is compared in step 6), a more accurate modeling can be expected with a smaller number of measurements compared to simply checking the location of the highest variance according to [25]. IV. N UMERICAL EXPERIMENTS A. Setup To demonstrate the effectiveness of the proposed method, we conducted experiments using an industrial production test dataset of a 28 nm analog/RF device. Our dataset contains six lots. The Ô¨Årst wafer of each lot was used for the evaluation; thus, we used six wafers with different lots. A single wafer has approximately 6,000 DUTs. In this experiment, we used a measured character for an item of the dynamic current test, in which site-to-site variability due to the multi-site test is noticeably observed, as shown in Figs. 1 and 2. A heat map of the full measurement results for the Ô¨Årst wafer of the sixthlot is shown in Fig. 4. For the ease of experimentation, faulty dies were removed from the dataset. The number of sites in a single touchdown is 16, i.e., S= 16 . The form of a single touchdown is illustrated in Fig. 5. This is different from the rect"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_27", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 27, "text": "tion, faulty dies were removed from the dataset. The number of sites in a single touchdown is 16, i.e., S= 16 . The form of a single touchdown is illustrated in Fig. 5. This is different from the rectangular touchdown illustrated in Fig. 3, which prevents interference on the probe of the impedance-matching circuits. As a result, a special pattern is observed during the multi-site test as shown in Fig. 4. To fully measure all DUTs on a single wafer, approximately 600 touchdowns are required. All experiments were implemented in the Python language. The RBF kernel was used as the kernel function fkernfor the GP-based regression. The experiments were conducted on a Linux PC with an Intel Xeon Platinum 8160 2.10 GHz central processing unit using a single thread. To quantitatively evaluate the modeling accuracy, we deÔ¨Åne the error \u000ebetween the correct ytrueand the predicted mean \u0016normalized by the maximum and minimum values of ytrue as follows: \u000e=\u0016\u0000ytrue dspec; (9) where dspecis the range between the minimum and maximum values of the fully measured characteristics in Fig. 4. B. Experimental results on site-based hierarchical spatial modeling We Ô¨Årst evaluated the site-based hierarchical "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_28", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 28, "text": "tween the minimum and maximum values of the fully measured characteristics in Fig. 4. B. Experimental results on site-based hierarchical spatial modeling We Ô¨Årst evaluated the site-based hierarchical spatial mod- eling presented in Algorithm 2. For comparison, naive GP regression-based approach (hereafter called naive GP ) [9] and the two-step approach (hereafter called 2-step GP ) [11] are also applied. Here, it should be noted that we do not consider the touchdown, that is, one-by-one measurement is conducted. The experimental result based on the touchdown is described later in Section IV-C. For the 2-step GP method, the Ô¨Årst wafer of the Ô¨Årst lot is used to obtain kclusters through k-means clustering. For the subsequent wafers, kclusters were used to predict the device characteristics. In the experiment, the optimal kwas determined using the silhouette value and elbow method [31], [32] instead of Eq. (5), resulting in seven clusters. In Fig. 6, the prediction results for the wafer of the sixth lot using each method are shown. They were predicted using ran- domly sampled values at a 10% spatial sampling rate. Clearly, the naive GP method fails to capture the site-to-site variatio"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_29", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 29, "text": "f the sixth lot using each method are shown. They were predicted using ran- domly sampled values at a 10% spatial sampling rate. Clearly, the naive GP method fails to capture the site-to-site variation as shown in Fig. 6(a). In contrast, the speciÔ¨Åc pattern shown in Fig. 4 caused by the site-to-site variation can be conÔ¨Årmed in the 2-step GP method and our method as shown in Figs. 6(b) and 6(c). Figure 7 shows the box-plots of \u000eusing Eq. (9) for each method. In the Ô¨Ågure, the top and bottom of the line represent the maximum and minimum values, respectively. The average is shown as a dot. The top and bottom of the box are 75% quantile and 25% quantile, respectively. The line represents the median. The average errors of \u000eof the naive GP, 2-step GP method, and our method are 18.59%, 13.43%, and 0.69%, respectively. The proposed method can also drastically reduce the variance in the predictions. From Regular Paper108 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. 0.00.20.40.60.81.0 DIE_XDIE_Y(a) Naive GP 0.00.20.40.60.81.0 DIE_XDIE_Y (b) 2-step GP 0.00.20.40.60.81.0 DIE_XDIE_Y (c) Ours Fig."}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_30", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 30, "text": "eptember 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. 0.00.20.40.60.81.0 DIE_XDIE_Y(a) Naive GP 0.00.20.40.60.81.0 DIE_XDIE_Y (b) 2-step GP 0.00.20.40.60.81.0 DIE_XDIE_Y (c) Ours Fig. 6. Heat maps of the predicted characteristics by naive GP, 2-step GP, and the proposed method at the 10% spatial sampling rate. It can be visibly conÔ¨Årmed that the prediction results are closer to the actual measurements in the order of naive GP, 2-step GP, and the proposed method. The measured values are normalized. 2-step Ours Naive GP Methods19.41Œ¥ 010203040[%]50 Maximum 75% q. 25% q. MinimumMedianAverage Fig. 7. Box-plots of \u000efor each method, where the maximum, 75% quantile, median, average, 25% quantile, and minimum values are shown. the results, we can conclude that the proposed method can reduce the average error by approximately 5.13% compared to the 2-step GP method, i.e., 19:46times (= 13 :43=0:69) more accurately. Ours Naive GP 2-step GP 051015Average of Œ¥ [%] 10 Spatial sampling rate [%]20 30 40 50 60 70 80 90 1000.00.51.0 Fig. 8. Averages of \u000eobtained by naive GP, 2-step GP, and the proposed method at various sampling rates. The gray part is enlarged at the bottom of this"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_31", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 31, "text": "ng rate [%]20 30 40 50 60 70 80 90 1000.00.51.0 Fig. 8. Averages of \u000eobtained by naive GP, 2-step GP, and the proposed method at various sampling rates. The gray part is enlarged at the bottom of this Ô¨Ågure. 05101520 Ours Naive GP 2-step GP Lot ID1 2 3 4 5 612 0Average of Œ¥ [%] Fig. 9. Changes of the averages of \u000efor each lot. The gray part is enlarged at the bottom of this Ô¨Ågure. Figure 8 shows the averages of \u000eas a function of the spatial sampling rate using the three methods for the wafer of the sixth lot. Note that the prediction methods are not applied when the spatial sampling rate is 100% and the sampling rate is incrementally increased, that is, the measured locations at the 10% sampling rate are always contained at subsequent rates. As the spatial sampling rate increases, the averages of all the methods decrease monotonically. We also Ô¨Ånd that the average errors of the proposed method always achieves better prediction results for all the sampling rates. The averages of \u000efor the wafer at the 10% sampling rate as a function of the lot ID are shown in Fig. 9. From the Ô¨Ågure, it can be observed that the proposed method achieves the best estimation results for all the lots amon"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_32", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 32, "text": "e wafer at the 10% sampling rate as a function of the lot ID are shown in Fig. 9. From the Ô¨Ågure, it can be observed that the proposed method achieves the best estimation results for all the lots among the three methods. The prediction performance of the 2-step GP degrades as the production lot progresses, while the proposed method maintains a low prediction error below 2% regardless of the lot. This result implies that the k-means clustering result obtained in the Ô¨Årst lot is inappropriate for subsequent lots. We evaluated the calculation time of the prediction for each method. Figure 10 summarizes the calculation time of each method for the sixth lot at various sampling rates. We can see that the proposed method and 2-step method can signiÔ¨Åcantly reduce the calculation time compared to the naive GP method. This is due to the side beneÔ¨Åts of hierarchical GP modeling Regular Paper 109 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. Fig. 10. Calculation time. The gray part is enlarged at the bottom of this Ô¨Ågure. 10 0 20 30 40 50 Number of touchdownsOurs RandomAverage of Œ¥ [%] 1101001000 "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_33", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 33, "text": "UTC from IEEE Xplore. Restrictions apply. Fig. 10. Calculation time. The gray part is enlarged at the bottom of this Ô¨Ågure. 10 0 20 30 40 50 Number of touchdownsOurs RandomAverage of Œ¥ [%] 1101001000 18 touchdowns Fig. 11. Averages of \u000eas a function of the number of the touchdowns. The vertical axis is shown in log scale. The proposed method converges more quickly. approaches. In general, the inference time of GP is O(N3) scaled because of the computation of the matrix inverse [35], [36]. In the proposed method, GP modeling is conducted for each site individually, and thus the calculation time can be drastically reduced because the training samples are reduced toN=S in each GP modeling, where Sis 16 for the proposed. The reduction becomes N=k for the 2-step method, where k= 7. Note that this calculation was conducted using a single thread. Therefore, the calculation time can be further reduced by implementing parallel processing. C. Experimental result under multi-site testing In the evaluation of the previous section, the sample dies are randomly selected one by one, and thus the multi-site test environment that measurements are conducted per site unit is not considered. We evalua"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_34", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 34, "text": "valuation of the previous section, the sample dies are randomly selected one by one, and thus the multi-site test environment that measurements are conducted per site unit is not considered. We evaluated the sampling method listed in Algorithm 3 under the multi-site test environment. Here, it is assumed that the touchdown shown in Fig. 5 is performed in a single measurement. In all the existing researches of the wafer-level variation modeling, sampling is assumed one DUT at a time, and thus this work is the Ô¨Årst to consider a multi-site testing environment for wafer-level variation modeling. In this experiment, the random sampling was used for comparison. First, we measured one randomly sampled touchdown and then selected the next one by the proposed method and random sampling. Figure 11 shows the average of \u000eas a function of the number of the touchdowns that incrementally increased. The Œ¥ 010203040[%]50 Random Ours Methods Maximum 75% q. 25% q. MinimumMedianAverage Fig. 12. Box-plots of \u000efor each method, where the maximum, 75% quantile, median, average, 25% quantile, and minimum values are shown. Because \u000e of the random sampling is a multimodal distribution, the average is plotted"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_35", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 35, "text": "of \u000efor each method, where the maximum, 75% quantile, median, average, 25% quantile, and minimum values are shown. Because \u000e of the random sampling is a multimodal distribution, the average is plotted out of the box. DIE_XDIE_Y 0.00.20.40.60.81.0 0.2 (a) Random sampling DIE_XDIE_Y 0.00.20.40.60.81.0 (b) Ours Fig. 13. Heat maps of the predicted characteristics for the 18 touchdowns. Ô¨Årst wafer in the sixth lot was used. Though, an error of over 3000% is observed for both the methods at the Ô¨Årst touch- down, the error is decreasing as increasing the number of the touchdowns for both methods. However, the random sampling method converges slowly, whereas the proposed method con- verges further quickly. More speciÔ¨Åcally, the proposed method has an average error of 0.80% or less with the 18 touchdowns, in contrast, the random sampling still has an average of 5.03%. The 18 touchdowns correspond to approximately 3% of the number of the touchdowns for full measurement. In addition, the random sampling does not converge even at the 50 touchdowns. It can be seen from the Ô¨Ågure that the proposed sampling method can successfully reduce the number of the necessary touchdowns while achieving bett"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_36", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 36, "text": "ampling does not converge even at the 50 touchdowns. It can be seen from the Ô¨Ågure that the proposed sampling method can successfully reduce the number of the necessary touchdowns while achieving better prediction accuracy. The box-plots for the random sampling and the proposed method for the 18 touchdowns are shown in Fig. 12. It is Regular Paper 110 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. clear that not only the average of \u000ebut also the variance of the estimation errors can be reduced by the proposed method. Although the random sampling has a maximum error of approximately 50%, the proposed method has only 4.77%. In Fig. 13, the prediction results for each method for the 18 touchdowns are shown. Although they are visually similar, in Fig. 13(a), the predicted values exceed the range of the normalized range, (i.e., 0 to 1), indicating that the predictions by the random sampling are not sufÔ¨Åcient. On the other hand, excellent agreement is observed between Figs. 13(b) and 4. It shows that the proposed method successfully achieves highly accurate wafer-level variation modeling even"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_37", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 37, "text": "not sufÔ¨Åcient. On the other hand, excellent agreement is observed between Figs. 13(b) and 4. It shows that the proposed method successfully achieves highly accurate wafer-level variation modeling even in a multi-site test environment. V. C ONCLUSION In this paper, we proposed a novel wafer-level spatial correlation modeling method for multi-site RF IC testing. The proposed method employs GP regression, which is an efÔ¨Åcient statistical modeling method used to predict the value for an unmeasured point from small sampling data. In the proposed method, GP is applied individually by partitioning the die location on a wafer according to the site information provided by the test engineers. In addition, we propose an active sampling method based on the predictive variance calculated by GP to achieve better prediction results while maintaining a small measurement cost. Experimental results using an industrial production test dataset demonstrated that the proposed method achieves a 19.46 times smaller prediction error than the conventional method. Moreover, we demon- strated that the proposed sampling method provides sufÔ¨Åcient prediction accuracy with 18 touchdown measurements, which corresp"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_38", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 38, "text": "maller prediction error than the conventional method. Moreover, we demon- strated that the proposed sampling method provides sufÔ¨Åcient prediction accuracy with 18 touchdown measurements, which corresponds to 3% of the number of touchdowns for full measurement. In contrast, the prediction accuracy by random sampling required over 50 measurements. Although all the existing methods were evaluated with one DUT measurement, the proposed method achieved better prediction results by considering an actual touchdown under multi-site testing. REFERENCES [1] L.-C. Wang, ‚ÄúExperience of data analytics in EDA and test‚Äîprinciples, promises, and challenges,‚Äù IEEE Transactions on Computer-Aided De- sign of Integrated Circuits and Systems , vol. 36, no. 6, pp. 885‚Äì898, 2017. [2] H.-G. Stratigopoulos, ‚ÄúMachine learning applications in IC testing,‚Äù in Proceedings of IEEE European Test Symposium , 2018. [3] M. Shintani, M. Inoue, and Y. Nakamura, ‚ÄúArtiÔ¨Åcial neural network based test escape screening using generative model,‚Äù in Proceedings of IEEE International Test Conference , 2018, p. 9.2. [4] S. Reda and S. R. Nassif, ‚ÄúAccurate spatial estimation and decomposi- tion techniques for variability charac"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_39", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 39, "text": "generative model,‚Äù in Proceedings of IEEE International Test Conference , 2018, p. 9.2. [4] S. Reda and S. R. Nassif, ‚ÄúAccurate spatial estimation and decomposi- tion techniques for variability characterization,‚Äù IEEE Transactions on Semiconductor Manufacturing , vol. 23, no. 3, pp. 345‚Äì357, 2010. [5] X. Li, R. R. Rutenbar, and R. D. Blanton, ‚ÄúVirtual probe: A statisti- cally optimal framework for minimum-cost silicon characterization of nanoscale integrated circuits,‚Äù in Proceedings of IEEE/ACM Interna- tional Conference on Computer-Aided Design , 2009, pp. 433‚Äì440. [6] W. Zhang, X. Li, and R. A. Rutenbar, ‚ÄúBayesian virtual probe: Min- imizing variation characterization cost for nanoscale IC technologies via Bayesian inference,‚Äù in Proceedings of ACM/EDAC/IEEE Design Automation Conference , 2010, pp. 262‚Äì267.[7] W. Zhang, X. Li, F. Liu, E. Acar, R. A. Rutenbar, and R. D. Blanton, ‚ÄúVirtual probe: A statistical framework for low-cost silicon characteriza- tion of nanoscale integrated circuits,‚Äù IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems , vol. 30, no. 7, pp. 1814‚Äì1827, 2011. [8] S. Zhang, F. Lin, C.-K. Hsu, K.-T. Cheng, and H. Wang, ‚ÄúJoint virtual"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_40", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 40, "text": "rcuits,‚Äù IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems , vol. 30, no. 7, pp. 1814‚Äì1827, 2011. [8] S. Zhang, F. Lin, C.-K. Hsu, K.-T. Cheng, and H. Wang, ‚ÄúJoint virtual probe: Joint exploration of multiple test items‚Äô spatial patterns for efÔ¨Åcient silicon characterization and test prediction,‚Äù in Proceedings of IEEE Design Automation and Test in Europe , 2014. [9] N. Kupp, K. Huang, J. M. Carulli, Jr., and Y. Makris, ‚ÄúSpatial correlation modeling for probe test cost reduction in RF devices,‚Äù in Proceedings of IEEE/ACM International Conference on Computer-Aided Design , 2012, pp. 23‚Äì29. [10] A. Ahmadi, K. Huang, S. Natarajan, C. John M., Jr., and Y. Makris, ‚ÄúSpatio-temporal wafer-level correlation modeling with progressive sam- pling: A pathway to HVM yield estimation,‚Äù in Proceedings of IEEE International Test Conference , 2014, p. 18.1. [11] K. Huang, N. Kupp, C. John M., Jr., and Y. Makris, ‚ÄúHandling discon- tinuous effects in modeling spatial correlation of wafer-level analog/RF tests,‚Äù in Proceedings of IEEE Design Automation and Test in Europe , 2013, pp. 553‚Äì558. [12] E. J. Marinissen, A. Singh, D. Glotter, M. Esposito, J. M. C. Jr., A. Nahar, "}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_41", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 41, "text": "ion of wafer-level analog/RF tests,‚Äù in Proceedings of IEEE Design Automation and Test in Europe , 2013, pp. 553‚Äì558. [12] E. J. Marinissen, A. Singh, D. Glotter, M. Esposito, J. M. C. Jr., A. Nahar, K. M. Butler, D. Appello, and C. Portelli, ‚ÄúAdapting to adaptive testing,‚Äù in Proceedings of IEEE Design Automation and Test in Europe , 2010, pp. 556‚Äì561. [13] K. R. Gotkhindikar, W. R. Daasch, K. M. Butler, J. M. Carulli, Jr., and A. Nahar, ‚ÄúDie-level adaptive test: Real-time test reordering and elimination,‚Äù in Proceedings of IEEE International Test Conference , 2011, p. 15.1. [14] E. Yilmaz, S. Ozev, O. Sinanoglu, and P. Maxwell, ‚ÄúAdaptive testing: Conquering process variations,‚Äù in Proceedings of IEEE European Test Symposium , 2012. [15] M. Shintani, T. Uezono, T. Takahashi, K. Hatayama, T. Aikyo, K. Masu, and T. Sato, ‚ÄúA variability-aware adaptive test Ô¨Çow for test quality im- provement,‚Äù IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems , vol. 33, no. 7, pp. 1056‚Äì1066, 2014. [16] A. P. Dempster, N. M. Laird, and D. B. Rubin, ‚ÄúMaximum likelihood from incomplete data via the EM algorithm,‚Äù Journal of the Royal Statistical Society. Series B (Methodologic"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_42", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 42, "text": "pp. 1056‚Äì1066, 2014. [16] A. P. Dempster, N. M. Laird, and D. B. Rubin, ‚ÄúMaximum likelihood from incomplete data via the EM algorithm,‚Äù Journal of the Royal Statistical Society. Series B (Methodological) , vol. 39, no. 1, pp. 1‚Äì38, 1977. [17] D. L. Donoho, ‚ÄúCompressed sensing,‚Äù IEEE Transactions on Informa- tion Theory , vol. 52, no. 4, pp. 1289‚Äì1306, 2006. [18] E. J. Candes and M. B. Wakin, ‚ÄúAn introduction to compressive sampling,‚Äù IEEE Signal Processing Magazine , vol. 25, no. 2, pp. 21‚Äì30, 2008. [19] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for Machine Learning . MIT Press, 2006. [20] N. Sumikawa, L.-C. Wang, and M. S. Abadir, ‚ÄúAn experiment of burn- in time reduction based on parametric test analysis,‚Äù in Proceedings of IEEE International Test Conference , 2012, p. 19.3. [21] T. Lehner, A. Kuhr, M. Wahl, and R. Br ¬®uck, ‚ÄúSite dependencies in a multisite testing environment,‚Äù in Proceedings of IEEE European Test Symposium , 2014. [22] P. O. Farayola, S. K. Chaganti, A. O. Obaidi, A. Sheikh, S. Ravi, and D. Chen, ‚ÄúQuantile ‚Äì quantile Ô¨Åtting approach to detect site to site variations in massive multi-site testing,‚Äù in Proceedings of IEEE VLSI Test Symposium , 202"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_43", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 43, "text": ", A. O. Obaidi, A. Sheikh, S. Ravi, and D. Chen, ‚ÄúQuantile ‚Äì quantile Ô¨Åtting approach to detect site to site variations in massive multi-site testing,‚Äù in Proceedings of IEEE VLSI Test Symposium , 2020. [23] D. Steinley, ‚ÄúK-means clustering: A half-century synthesis,‚Äù British Journal of Mathematical and Statistical Psychology , vol. 59, no. 1, pp. 1‚Äì34, 2006. [24] K. M. Butler, A. Nahar, and W. R. Daasch, ‚ÄúWhat we know after twelve years developing and deploying test data analytics solutions,‚Äù inProceedings of IEEE International Test Conference , 2016. [25] S. Seo, M. Wallat, T. Graepel, and K. Obermayer, ‚ÄúGaussian process re- gression: active data selection and test point rejection,‚Äù in Proceedings of IEEE-INNS-ENNS International Joint Conference on Neural Networks , 2000, pp. 241‚Äì246. [26] C. M. Bishop, Pattern Recognition and Machine Learning . Springer, 2006. [27] D. Duvenaud, ‚ÄúThe kernel cookbook,‚Äù [Online]. Available: https://www.cs.toronto.edu/ duvenaud/cookbook/. [28] M. G. Genton, ‚ÄúClasses of kernels for machine learning: A statistics perspective,‚Äù The Journal of Machine Learning Research , vol. 2, pp. 299‚Äì312, 2001. Regular Paper111 Authorized licensed use limited to: Hoc"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_44", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 44, "text": "ton, ‚ÄúClasses of kernels for machine learning: A statistics perspective,‚Äù The Journal of Machine Learning Research , vol. 2, pp. 299‚Äì312, 2001. Regular Paper111 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply. [29] S. Ohkawa, M. Aoki, and H. Masuda, ‚ÄúAnalysis and characterization of device variations in an LSI chip using an integrated device matrix array,‚Äù IEEE Transactions on Semiconductor Manufacturing , vol. 17, no. 2, pp. 155‚Äì165, 2004. [30] S. Saxena, C. Hess, H. Karbasi, A. Rossoni, S. Tonello, P. McNamara, S. Lucherini, S. Minehane, C. Dolainsky, and M. Quarantelli, ‚ÄúVariation in transistor performance and leakage in nanometer-scale technologies,‚Äù IEEE Transactions on Electron Devices , vol. 55, no. 1, pp. pp131‚Äìpp144, 2008. [31] P. J. Rousseeuw, ‚ÄúSilhouettes: A graphical aid to the interpretation and validation of cluster analysis,‚Äù in Journal of Computational & Applied Mathematics , 1987, pp. 53‚Äì65. [32] C. Goutte, P. Toft, E. Rostrup, F. A. Nielsen, and L. K. Hansen, ‚ÄúOn clustering fMRI time series,‚Äù NeuroImage , vol. 9, pp. 298‚Äì310, 1999. [33] T. Calinski and J. Harabasz, ‚ÄúA de"}
{"id": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf::chunk_45", "source": "Wafer-level_Variation_Modeling_for_Multi-site_RF_IC_Testing_via_Hierarchical_Gaussian_Process.pdf", "chunk_index": 45, "text": "1987, pp. 53‚Äì65. [32] C. Goutte, P. Toft, E. Rostrup, F. A. Nielsen, and L. K. Hansen, ‚ÄúOn clustering fMRI time series,‚Äù NeuroImage , vol. 9, pp. 298‚Äì310, 1999. [33] T. Calinski and J. Harabasz, ‚ÄúA dendrite method for cluster analysis,‚Äù Communications in Statistics , vol. 3, pp. 1‚Äì27, 1974. [34] B. Tang, ‚ÄúOrthogonal array-based latin hypercubes,‚Äù Journal of the American Statistical Association , vol. 88, no. 424, pp. 1392‚Äì1397, 1991. [35] S. Park and S. Choi, ‚ÄúHierarchical Gaussian process regression,‚Äù in Proceedings of Asian Conference on Machine Learning , 2010, pp. 95‚Äì 110. [36] D.-T. Nguyen, M. Filippone, and P. Michiardi, ‚ÄúExact Gaussian pro- cess regression with distributed computations,‚Äù in Proceedings of ACM/SIGAPP Symposium on Applied Computing , 2019, pp. 1286‚Äì1295. Regular Paper112 Authorized licensed use limited to: Hochschule Heilbronn. Downloaded on September 12,2025 at 21:52:56 UTC from IEEE Xplore. Restrictions apply."}
